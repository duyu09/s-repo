# The Mathematics of of Time-Series Analysis

A time-series model is one which postulates a relationship amongst a number of temporal sequences or time series. An example is provided by the simple regression model

$$
y (t) = x (t) \beta + \varepsilon (t), \tag {1}
$$

where $y ( t ) = \{ y _ { t } ; t = 0 , \pm 1 , \pm 2 , . . . \}$ is a sequence, indexed by the time subscript $t$ , which is a combination of an observable signal sequence $x ( t ) = \{ x _ { t } \}$ and an unobservable white-noise sequence $\varepsilon ( t ) = \{ \varepsilon _ { t } \}$ of independently and identically distributed random variables.

A more general model, which we shall call the general temporal regression model, is one which postulates a relationship comprising any number of consecutive elements of $x ( t )$ , $y ( t )$ and $\varepsilon ( t )$ . The model may be represented by the equation

$$
\sum_ {i = 0} ^ {p} \alpha_ {i} y (t - i) = \sum_ {i = 0} ^ {k} \beta_ {i} x (t - i) + \sum_ {i = 0} ^ {q} \mu_ {i} \varepsilon (t - i), \tag {2}
$$

where it is usually taken for granted that $\alpha _ { 0 } = 1$ . This normalisation of the leading coefficient on the LHS identifies $y ( t )$ as the output sequence. Any of the sums in the equation can be infinite, but if the model is to be viable, the sequences of coefficients $\left\{ \alpha _ { i } \right\}$ , $\{ \beta _ { i } \}$ and $\{ \mu _ { i } \}$ can depend on only a limited number of parameters.

Although it is convenient to write the general model in the form of (2), it is also common to represent it by the equation

$$
y (t) = \sum_ {i = 1} ^ {p} \phi_ {i} y (t - i) + \sum_ {i = 0} ^ {k} \beta_ {i} x (t - i) + \sum_ {i = 0} ^ {q} \mu_ {i} \varepsilon (t - i), \tag {3}
$$

where $\phi _ { i } = - \alpha _ { i }$ for $i = 1 , \dotsc , p$ . This places the lagged versions of the sequence $y ( t )$ on the RHS in the company of the input sequence $x ( t )$ and its lags.

Whereas engineers are liable to describe this as a feedback model, economists are more likely to describe it as a model with lagged dependent variables.

The foregoing models are termed regression models by virtue of the inclusion of the observable explanatory sequence $x ( t )$ . When $x ( t )$ is deleted, we obtain a simpler unconditional linear stochastic model:

$$
\sum_ {i = 0} ^ {p} \alpha_ {i} y (t - i) = \sum_ {i = 0} ^ {q} \mu_ {i} \varepsilon (t - i). \tag {4}
$$

This is the autoregressive moving-average (ARMA) model.

A time-series model can often assume a variety of forms. Consider a simple dynamic regression model of the form

$$
y (t) = \phi y (t - 1) + x (t) \beta + \varepsilon (t), \tag {5}
$$

where there is a single lagged dependent variable. By repeated substitution, we obtain

$$
\begin{array}{l} y (t) = \phi y (t - 1) + \beta x (t) + \varepsilon (t) \\ = \phi^ {2} y (t - 2) + \beta \left\{x (t) + \phi x (t - 1) \right\} + \varepsilon (t) + \phi \varepsilon (t - 1) \\ \end{array}
$$

$$
\begin{array}{l} (6) \quad \vdots \\ = \phi^ {n} y (t - n) + \beta \left\{x (t) + \phi x (t - 1) + \dots + \phi^ {n - 1} x (t - n + 1) \right\} \\ + \varepsilon (t) + \phi \varepsilon (t - 1) + \dots + \phi^ {n - 1} \varepsilon (t - n + 1). \\ \end{array}
$$

If $| \phi | < 1$ , then $\operatorname * { l i m } ( n  \infty ) \phi ^ { n } = 0$ ; and it follows that, if $x ( t )$ and $\varepsilon ( t )$ are bounded sequences, then, as the number of repeated substitutions increases indefinitely, the equation will tend to the limiting form of

$$
y (t) = \beta \sum_ {i = 0} ^ {\infty} \phi^ {i} x (t - i) + \sum_ {i = 0} ^ {\infty} \phi^ {i} \varepsilon (t - i). \tag {7}
$$

It is notable that, by this process of repeated substitution, the feedback structure has been eliminated from the model. As a result, it becomes easier to assess the impact upon the output sequence of changes in the values of the input sequence. The direct mapping from the input sequence to the output sequence is described by engineers as a transfer function or as a filter.

For models more complicated than the one above, the method of repeated substitution, if pursued directly, becomes intractable. Thus we are motivated to use more powerful algebraic methods to effect the transformation of the equation. This leads us to consider the use of the so-called lag operator. A proper understanding of the lag operator depends upon a knowledge of the algebra of polynomials and of rational functions.

# The Algebra of the Lag Operator

A sequence $x ( t ) = \{ x _ { t } ; t = 0 , \pm 1 , \pm 2 , . . . \}$ is any function mapping from the set of integers $\mathcal { Z } = \{ 0 , \pm 1 , \pm 2 , . . . \}$ to the real line. If the set of integers represents a set of dates separated by unit intervals, then $x ( t )$ is described as a temporal sequence or a time series.

The set of all time series represents a vector space, and various linear transformations or operators can be defined over the space. The simplest of these is the lag operator $L$ which is defined by

$$
(8) L x (t) = x (t - 1).
$$

Now, $L \{ L x ( t ) \} = L x ( t - 1 ) = x ( t - 2 )$ ; so it makes sense to define $L ^ { 2 }$ by $L ^ { 2 } x ( t ) = x ( t - 2 )$ . More generally, $L ^ { k } x ( t ) = x ( t - k )$ and, likewise, $L ^ { - k } x ( t ) =$ $x ( t + k )$ . Other operators are the difference operator $\nabla = I - L$ which has the effect that

$$
\begin{array}{r l} & {\nabla x (t) = x (t) - x (t - 1),} \end{array}
$$

the forward-difference operator $\Delta = L ^ { - 1 } - I$ , and the summation operator $S = ( I - L ) ^ { - 1 } = \{ I + L + L ^ { 2 } + \cdots \}$ which has the effect that

$$
S x (t) = \sum_ {i = 0} ^ {\infty} x (t - i). \tag {10}
$$

In general, we can define polynomials of the lag operator of the form $p ( L ) =$ $p _ { 0 } + p _ { 1 } L + \cdot \cdot \cdot + p _ { n } L ^ { n } = \sum p _ { i } L ^ { i }$ having the effect that

$$
p (L) x (t) = p _ {0} x (t) + p _ {1} x (t - 1) + \dots + p _ {n} x (t - n)
$$

$$
= \sum_ {i = 0} ^ {n} p _ {i} x (t - i). \tag {11}
$$

In these terms, the equation under (2) of the general temporal model becomes

$$
\alpha (L) y (t) = \beta (L) x (t) + \mu (L) \varepsilon (t). \tag {12}
$$

The advantage which comes from defining polynomials in the lag operator stems from the fact that they are isomorphic to the set of ordinary algebraic polynomials. Thus we can rely upon what we know about ordinary polynomials to treat problems concerning lag-operator polynomials.

# Algebraic Polynomials

Consider the equation $\phi _ { 0 } + \phi _ { 1 } z + \phi _ { 2 } z ^ { 2 } = 0$ . Once the equation has been divided by $\phi _ { 2 }$ , it can be factorised as $( z - \lambda _ { 1 } ) ( z - \lambda _ { 2 } )$ where $\lambda _ { 1 }$ , $\lambda _ { 2 }$ are the roots or zeros of the equation which are given by the formula

$$
\lambda = \frac {- \phi_ {1} \pm \sqrt {\phi_ {1} ^ {2} - 4 \phi_ {2} \phi_ {0}}}{2 \phi_ {2}}. \tag {13}
$$

If $\phi _ { 1 } ^ { 2 } \ge 4 \phi _ { 2 } \phi _ { 0 }$ , then the roots $\lambda _ { 1 }$ , $\lambda _ { 2 }$ are real. If $\phi _ { 1 } ^ { 2 } = 4 \phi _ { 2 } \phi _ { 0 }$ , then $\lambda _ { 1 } = \lambda _ { 2 }$ . If $\phi _ { 1 } ^ { 2 } < 4 \phi _ { 2 } \phi _ { 0 }$ , then the roots are the conjugate complex numbers $\lambda = \alpha + i \beta$ , $\lambda ^ { * } = \alpha - i \beta$ , where $i = \sqrt { - 1 }$ .

There are three alternative ways of representing the conjugate complex numbers $\lambda$ and $\lambda ^ { * }$ :

$$
\lambda = \alpha + i \beta = \rho (\cos \theta + i \sin \theta) = \rho e ^ {i \theta}, \tag {14}
$$

$$
\lambda^ {*} = \alpha - i \beta = \rho (\cos \theta - i \sin \theta) = \rho e ^ {- i \theta},
$$

where

$$
\rho = \sqrt {\alpha^ {2} + \beta^ {2}} \quad \text {a n d} \quad \theta = \tan^ {- 1} \left(\frac {\beta}{\alpha}\right). \tag {15}
$$

These are called, respectively, the Cartesian form, the trigonometrical form and the exponential form.

The Cartesian and trigonometrical representations are understood by considering the Argand diagram:

![](images/386ca951a3de58491dc70ae2e39f9d23e4b530a609939220aadff38e5acd5279.jpg)  
Figure 1. The Argand Diagram showing a complex number $\lambda = \alpha + i \beta$ and its conjugate $\lambda ^ { * } = \alpha - i \beta$ .

The exponential form is understood by considering the following series expansions of $\cos \theta$ and $i \sin \theta$ about the point $\theta = 0$ :

$$
\cos \theta = \left\{1 - \frac {\theta^ {2}}{2 !} + \frac {\theta^ {4}}{4 !} - \frac {\theta^ {6}}{6 !} + \dots \right\}, \tag {16}
$$

$$
i \sin \theta = \left\{i \theta - \frac {i \theta^ {3}}{3 !} + \frac {i \theta^ {5}}{5 !} - \frac {i \theta^ {7}}{7 !} + \dots \right\}.
$$

Adding these gives

$$
\begin{array}{l} \cos \theta + i \sin \theta = \left\{1 + i \theta - \frac {\theta^ {2}}{2 !} - \frac {i \theta^ {3}}{3 !} + \frac {\theta^ {4}}{4 !} + \dots \right\} \tag {17} \\ = e ^ {i \theta}. \\ \end{array}
$$

Likewise, by subtraction, we get

$$
\begin{array}{l} \cos \theta - i \sin \theta = \left\{1 - i \theta - \frac {\theta^ {2}}{2 !} + \frac {i \theta^ {3}}{3 !} + \frac {\theta^ {4}}{4 !} - \dots \right\} \tag {18} \\ = e ^ {- i \theta}. \\ \end{array}
$$

These are Euler’s equations. It follows from adding (17) and (18) that

$$
\cos \theta = \frac {e ^ {i \theta} + e ^ {- i \theta}}{2}. \tag {19}
$$

Subtracting (18) from (17) gives

$$
\begin{array}{l} \sin \theta = \frac {- i}{2} \left(e ^ {i \theta} - e ^ {- i \theta}\right) \tag {20} \\ = \frac {1}{2 i} (e ^ {i \theta} - e ^ {- i \theta}). \\ \end{array}
$$

Now consider the general equation of the $_ n$ th order:

$$
\phi_ {0} + \phi_ {1} z + \phi_ {2} z ^ {2} + \dots + \phi_ {n} z ^ {n} = 0. \tag {21}
$$

On dividing by $\phi _ { n }$ , we can factorise this as

$$
(z - \lambda_ {1}) (z - \lambda_ {2}) \dots (z - \lambda_ {n}) = 0, \tag {22}
$$

where some of the roots may be real and others may be complex. The complex roots come in conjugate pairs, so that, if $\lambda = \alpha + i \beta$ is a complex root, then there is a corresponding root $\lambda ^ { * } = \alpha - i \beta$ such that the product $( z - \lambda ) ( z - \lambda ^ { * } ) =$ $z ^ { 2 } - 2 \alpha z + ( \alpha ^ { 2 } + \beta ^ { 2 } )$ is real and quadratic. When we multiply the $_ n$ factors together, we obtain the expansion

$$
0 = z ^ {n} - \sum_ {i} \lambda_ {i} z ^ {n - 1} + \sum_ {i} \sum_ {j} \lambda_ {i} \lambda_ {j} z ^ {n - 2} - \dots (- 1) ^ {n} \lambda_ {1} \lambda_ {2} \dots \lambda_ {n}. \tag {23}
$$

# D.S.G. POLLOCK: ECONOMETRICS

This can be compared with the expression $( \phi _ { 0 } / \phi _ { n } ) + ( \phi _ { 1 } / \phi _ { n } ) z + \cdot \cdot \cdot + z ^ { n } =$ 0. By equating coefficients of the two expressions, we find that $\left( \phi _ { 0 } / \phi _ { n } \right) =$ $( - 1 ) ^ { n } \prod \lambda _ { i }$ or, equivalently,

$$
\phi_ {n} = \phi_ {0} \prod_ {i = 1} ^ {n} (- \lambda_ {i}) ^ {- 1}. \tag {24}
$$

Thus we can express the polynomial in any of the following forms:

$$
\begin{array}{l} \sum \phi_ {i} z ^ {i} = \phi_ {n} \prod (z - \lambda_ {i}) \\ = \phi_ {0} \prod (- \lambda_ {i}) ^ {- 1} \prod (z - \lambda_ {i}) \tag {25} \\ = \phi_ {0} \prod \left(1 - \frac {z}{\lambda_ {i}}\right). \\ \end{array}
$$

We should also note that, if $\lambda$ is a root of the primary equation $\sum \phi _ { i } z ^ { i } = 0$ , where rising powers of $z$ are associated with rising indices on the coefficients, then $\mu = 1 / \lambda$ is a root of the equation $\sum \phi _ { i } z ^ { n - i } = 0$ , which has declining powers of $z$ instead. This follows since $\sum \phi _ { i } \lambda ^ { i } = \sum \phi _ { i } \mu ^ { - i } = 0$ implies that $\textstyle \mu ^ { n } \sum \phi _ { i } \mu ^ { - i } = \sum \phi _ { i } \mu ^ { n - i } = 0$ . Confusion can arise from not knowing which of the two equations one is dealing with.

# Rational Functions of Polynomials

If $\delta ( z )$ and $\gamma ( z )$ are polynomial functions of $z$ of degrees $d$ and $g$ respectively with $d < g$ , then the ratio $\delta ( z ) / \gamma ( z )$ is described as a proper rational function. We shall often encounter expressions of the form

$$
y (t) = \frac {\delta (L)}{\gamma (L)} x (t). \tag {26}
$$

For this to have a meaningful interpretation in the context of a time-series model, we normally require that $y ( t )$ should be a bounded sequence whenever $x ( t )$ is bounded. The necessary and sufficient condition for the boundedness of $y ( t )$ , in that case, is that the series expansion of $\delta ( z ) / \gamma ( z )$ should be convergent whenever $| z | \le 1$ . We can determine whether or not the sequence will converge by expressing the ratio $\delta ( z ) / \gamma ( z )$ as a sum of partial fractions. The basic result is as follows:

$$
\text {I f} \delta (z) / \gamma (z) = \delta (z) / \left\{\gamma_ {1} (z) \gamma_ {2} (z) \right\} \text {i s a p r o p e r r a t i o n a l f u n c t i o n , a n d} \text {i f} \gamma_ {1} (z) \text {a n d} \gamma_ {2} (z) \text {h a v e n o c o m m o n f a c t o r , t h e n t h e f u n c t i o n c a} \tag {3.27}
$$

$$
\frac {\delta (z)}{\gamma (z)} = \frac {\delta_ {1} (z)}{\gamma_ {1} (z)} + \frac {\delta_ {2} (z)}{\gamma_ {2} (z)},
$$

where $\delta _ { 1 } ( z ) / \gamma _ { 1 } ( z )$ and $\delta _ { 2 } ( z ) / \gamma _ { 2 } ( z )$ are proper rational functions.

# D.S.G. POLLOCK: MATHEMATICS FOR TIME SERIES

Imagine that $\gamma ( z ) = \prod ( 1 - z / \lambda _ { i } )$ . Then repeated applications of this basic result enables us to write

$$
\frac {\delta (z)}{\gamma (z)} = \frac {\kappa_ {1}}{1 - z / \lambda_ {1}} + \frac {\kappa_ {2}}{1 - z / \lambda_ {2}} + \dots + \frac {\kappa_ {g}}{1 - z / \lambda_ {g}}. \tag {28}
$$

By adding the terms on the RHS, we find an expression with a numerator of degree $n - 1$ . By equating the terms of the numerator with the terms of $\delta ( z )$ , we can find the values $\kappa _ { 1 }$ , $\kappa _ { 2 } , \ldots , \kappa _ { g }$ . The convergence of the expansion of $\delta ( z ) / \gamma ( z )$ is a straightforward matter. For the series converges if and only if the expansion of each of the partial fractions converges. For the expansion

$$
\frac {\kappa}{1 - z / \lambda} = \kappa \left\{1 + z / \lambda + (z / \lambda) ^ {2} + \dots \right\} \tag {29}
$$

to converge when $| z | \le 1$ , it is necessary and sufficient that $| \lambda | > 1$ .

Example. Consider the function

$$
\begin{array}{l} \frac {3 z}{1 + z - 2 z ^ {2}} = \frac {3 z}{(1 - z) (1 + 2 z)} \\ = \frac {\kappa_ {1}}{1 - z} + \frac {\kappa_ {2}}{1 + 2 z} \tag {30} \\ = \frac {\kappa_ {1} (1 + 2 z) + \kappa_ {2} (1 - z)}{(1 - z) (1 + 2 z)}. \\ \end{array}
$$

Equating the terms of the numerator gives

$$
3 z = \left(2 \kappa_ {1} - \kappa_ {2}\right) z + \left(\kappa_ {1} + \kappa_ {2}\right), \tag {31}
$$

so $\kappa _ { 2 } = - \kappa _ { 1 }$ , which gives $3 = ( 2 \kappa _ { 1 } - \kappa _ { 2 } ) = 3 \kappa _ { 1 }$ ; and thus we have $\kappa _ { 1 } = 1$ , $\kappa _ { 2 } = - 1$ .

# Linear Difference Equations

An $n$ th-order linear difference equation is a relationship amongst $n + 1$ consecutive elements of a sequence $x ( t )$ of the form

$$
\alpha_ {0} x (t) + \alpha_ {1} x (t - 1) + \dots + \alpha_ {n} x (t - n) = u (t), \tag {32}
$$

where $u ( t )$ is some specified sequence which is described as the forcing function. The equation can be written, in a summary notation, as

$$
\alpha (L) x (t) = u (t), \tag {33}
$$

where $\alpha ( L ) = \alpha _ { 0 } + \alpha _ { 1 } L + \cdot \cdot \cdot + \alpha _ { n } L ^ { n }$ . If $_ n$ consecutive values of $x ( t )$ are given, say $x _ { 1 } , x _ { 2 } , \ldots , x _ { n }$ , then the relationship can be used to find the succeeding value $x _ { n + 1 }$ . In this way, so long as $u ( t )$ is fully specified, it is possible to generate any number of the succeeding elements of the sequence. The values of the sequence prior to $t = 1$ can be generated likewise; and thus, in effect, we can deduce the function $x ( t )$ from the difference equation. However, instead of a recursive solution, we often seek an analytic expression for $x ( t )$ .

The function $x ( t ; c )$ , expressing the analytic solution, will comprise a set of $_ n$ constants in $c = [ c _ { 1 } , c _ { 2 } , \ldots , c _ { n } ] ^ { \prime }$ which can be determined once we are given a set of $n$ consecutive values of $x ( t )$ which are called initial conditions. The general analytic solution of the equation $\alpha ( L ) x ( t ) = u ( t )$ is expressed as $x ( t ; c ) = y ( t ; c ) + z ( t )$ , where $y ( t )$ is the general solution of the homogeneous equation $\alpha ( L ) y ( t ) = 0$ , and $z ( t ) = \alpha ^ { - 1 } ( L ) u ( t )$ is called a particular solution of the inhomogeneous equation.

We may solve the difference equation in three steps. First, we find the general solution of the homogeneous equation. Next, we find the particular solution $z ( t )$ which embodies no unknown quantities. Finally, we use the $_ n$ initial values of $x$ to determine the constants $c _ { 1 } , c _ { 2 } , \ldots , c _ { n }$ . We shall discuss in detail only the solution of the homogeneous equation.

# Solution of the Homogeneous Difference Equation

If $\lambda _ { j }$ is a root of the equation $\alpha ( z ) = \alpha _ { 0 } + \alpha _ { 1 } z + \cdot \cdot \cdot + \alpha _ { n } z ^ { n } = 0$ such that $\alpha ( \lambda _ { j } ) = 0$ , then $y _ { j } ( t ) = ( 1 / \lambda _ { j } ) ^ { t }$ is a solution of the equation $\alpha ( L ) y ( t ) = 0$ . This can be see this by considering the expression

$$
\begin{array}{l} \alpha (L) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} = \left(\alpha_ {0} + \alpha_ {1} L + \dots + \alpha_ {n} L ^ {n}\right) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} \\ = \alpha_ {0} \left(\frac {1}{\lambda_ {j}}\right) ^ {t} + \alpha_ {1} \left(\frac {1}{\lambda_ {j}}\right) ^ {t - 1} + \dots + \alpha_ {n} \left(\frac {1}{\lambda_ {j}}\right) ^ {t - n} \\ = \left(\alpha_ {0} + \alpha_ {1} \lambda_ {j} + \dots + \alpha_ {n} \lambda_ {j} ^ {n}\right) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} \\ = \alpha (\lambda_ {j}) \left(\frac {1}{\lambda_ {j}}\right) ^ {t}. \\ \end{array}
$$

Alternatively, one may consider the factorisation $\alpha ( L ) = \alpha _ { 0 } \prod _ { i } ( 1 - L / \lambda _ { i } )$ Within this product is the term $1 - L / \lambda _ { j }$ ; and since

$$
\left(1 - \frac {L}{\lambda_ {j}}\right) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} = \left(\frac {1}{\lambda_ {j}}\right) ^ {t} - \left(\frac {1}{\lambda_ {j}}\right) ^ {t} = 0,
$$

it follows that $\alpha ( L ) ( 1 / \lambda _ { j } ) ^ { t } = 0$ .

The general solution, in the case where $\alpha ( L ) = 0$ has distinct real roots, is given by

$$
y (t; c) = c _ {1} \left(\frac {1}{\lambda_ {1}}\right) ^ {t} + c _ {2} \left(\frac {1}{\lambda_ {2}}\right) ^ {t} + \dots + c _ {n} \left(\frac {1}{\lambda_ {n}}\right) ^ {t}, \tag {35}
$$

where $c _ { 1 } , c _ { 2 } , \ldots , c _ { n }$ are the constants which are determined by the initial conditions.

In the case where two roots coincide at a value of $\lambda _ { j }$ , the equation $\alpha ( L ) y ( t )$ $= 0$ has the solutions $y _ { 1 } ( t ) = ( 1 / \lambda _ { j } ) ^ { t }$ and $y _ { 2 } ( t ) = t ( 1 / \lambda _ { j } ) ^ { t }$ . To show this, let us extract the term $( 1 - L / \lambda _ { j } ) ^ { 2 }$ from the factorisation $\begin{array} { r } { \alpha ( L ) = \alpha _ { 0 } \prod _ { i } ( 1 - L / \lambda _ { i } ) } \end{array}$ . Then, according to the previous argument, we have $( 1 - L / \lambda _ { j } ) ^ { 2 } ( 1 / \lambda _ { j } ) ^ { t } = 0$ , but, also, we have

$$
\begin{array}{l} \left(1 - \frac {L}{\lambda_ {j}}\right) ^ {2} t \left(\frac {1}{\lambda_ {j}}\right) ^ {t} = \left(1 - \frac {2 L}{\lambda_ {j}} + \frac {L ^ {2}}{\lambda_ {j} ^ {2}}\right) t \left(\frac {1}{\lambda_ {j}}\right) ^ {t} \tag {36} \\ = t \left(\frac {1}{\lambda_ {j}}\right) ^ {t} - 2 (t - 1) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} + (t - 2) \left(\frac {1}{\lambda_ {j}}\right) ^ {t} = 0. \\ \end{array}
$$

In general, if there are $r$ repeated roots with a value of $\lambda _ { j }$ , then all of $( 1 / \lambda _ { j } ) ^ { t }$ , $t ( 1 / \lambda _ { j } ) ^ { t }$ , $t ^ { 2 } ( 1 / \lambda _ { j } ) ^ { t }$ , . . . , $t ^ { r - 1 } ( 1 / \lambda _ { j } ) ^ { t }$ are solutions to the equation $\alpha ( L ) y ( t ) = 0$ .

A particularly important special case arises when there are $r$ repeated roots of unit value. Then the functions $1 , t , t ^ { 2 } , \ldots , t ^ { r - 1 }$ are all solutions to the homogeneous equation. With each solution is associated a coefficient which can be determined in view of the initial conditions. If these coefficients are $d _ { 0 } , d _ { 1 } , d _ { 2 } , \dots , d _ { r - 1 }$ then, within the general solution of the homogeneous equation, there will be found the term $d _ { 0 } + d _ { 1 } t + d _ { 2 } t ^ { 2 } + \cdot \cdot \cdot + d _ { r - 1 } t ^ { r - 1 }$ which represents a polynomial in $t$ of degree $r - 1$ .

# The 2nd-order Difference Equation with Complex Roots

Imagine that the 2nd-order equation $\alpha ( L ) y ( t ) = \alpha _ { 0 } y ( t ) + \alpha _ { 1 } y ( t - 1 ) +$ $\alpha _ { 2 } y ( t - 2 ) = 0$ is such that $\alpha ( z ) = 0$ has complex roots $\lambda = 1 / \mu$ and $\lambda ^ { * } = 1 / \mu ^ { * }$ . If $\lambda , \lambda ^ { * }$ are conjugate complex numbers, then so too are $\mu , \mu ^ { * }$ . Therefore, let us write

$$
\begin{array}{l} \mu = \gamma + i \delta = \kappa (\cos \omega + i \sin \omega) = \kappa e ^ {i \omega}, \tag {37} \\ \mu^ {*} = \gamma - i \delta = \kappa (\cos \omega - i \sin \omega) = \kappa e ^ {- i \omega}. \\ \end{array}
$$

These will appear in a general solution of the difference equation of the form

$$
y (t) = c \mu^ {t} + c ^ {*} \left(\mu^ {*}\right) ^ {t}. \tag {38}
$$

![](images/831e43b5476793f3cab5395bf59f385804b83c0e113d44c2c1fae51c128054ab.jpg)  
Figure 2. The solution of the homogeneous difference equation $( 1 \textrm { -- }$ $1 . 6 9 L + 0 . 8 1 L ^ { 2 } ) y ( t ) = 0$ for the initial conditions $y _ { 0 } = 1$ and $y _ { 1 } = 3 . 6 9$ . The time lag of the phase displacement $p _ { 1 }$ and the duration of the cycle $p _ { 2 }$ are also indicated.

This represents a real-valued sequence; and, since a real term must equal its own conjugate, it follows that $c$ and $c ^ { * }$ must be conjugate numbers of the form

$$
\begin{array}{l} c ^ {*} = \rho (\cos \theta + i \sin \theta) = \rho e ^ {i \theta}, \tag {39} \\ c = \rho (\cos \theta - i \sin \theta) = \rho e ^ {- i \theta}. \\ \end{array}
$$

Thus the general solution becomes

$$
\begin{array}{l} c \mu^ {t} + c ^ {*} (\mu^ {*}) ^ {t} = \rho e ^ {- i \theta} (\kappa e ^ {i \omega}) ^ {t} + \rho e ^ {i \theta} (\kappa e ^ {- i \omega}) ^ {t} \\ = \rho \kappa^ {t} \left\{e ^ {i (\omega t - \theta)} + e ^ {- i (\omega t - \theta)} \right\} \tag {40} \\ = 2 \rho \kappa^ {t} \cos (\omega t - \theta). \\ \end{array}
$$

To analyse the final expression, consider first the factor $\cos ( \omega t - \theta )$ . This is a displaced cosine wave. The value $\omega$ , which is a number of radians per unit period, is called the angular velocity or the angular frequency of the wave. The value $f = \omega / 2 \pi$ is its frequency in cycles per unit period. The duration of one cycle, also called the period, is $r = 2 \pi / \omega$ .

The term $\theta$ is called the phase displacement of the cosine wave, and it serves to shift the cosine function along the axis of $t$ so that, in the absence of damping, the peak would occur at the value of $t = \theta / \omega$ instead of at $t = 0$ .

Next consider the term $\kappa ^ { t }$ wherein $\kappa = \sqrt { ( \gamma ^ { 2 } + \delta ^ { 2 } ) }$ is the modulus of the complex roots. When $\kappa$ has a value of less than unity, it becomes a damping factor which serves to attenuate the cosine wave as $t$ increases. The damping also serves to shift the peaks of the cosine function slightly to the left.

Finally, the factor $2 \rho$ affects the initial amplitude of the cosine wave which is the value which it assumes when $t = 0$ . Since $\rho$ is just the modulus of the values $c$ and $c ^ { * }$ , this amplitude reflects the initial conditions. The phase angle $\theta$ is also a product of the initial conditions.

It is instructive to derive an expression for the second-order difference equation which is in terms of the parameters of the trigonometrical or exponential representations of a pair of complex roots. Consider

$$
\begin{array}{l} \alpha (z) = \alpha_ {0} (1 - \mu z) \left(1 - \mu^ {*} z\right) (411) \\ = \alpha_ {0} \left\{1 - \left(\mu + \mu^ {*}\right) z + \mu \mu^ {*} z ^ {2} \right\}, (41) \\ \end{array}
$$

From (37) it follows that

$$
\mu + \mu^ {*} = 2 \kappa \cos \omega \quad \text {a n d} \quad \mu \mu^ {*} = \kappa^ {2}. \tag {42}
$$

Therefore the polynomial operator which is entailed by the difference equation is

$$
\alpha_ {0} + \alpha_ {1} L + \alpha_ {2} L ^ {2} = \alpha_ {0} (1 - 2 \kappa \cos \omega L + \kappa^ {2} L ^ {2}); \tag {43}
$$

and it is usual to set $\alpha _ { 0 } = 1$ . This representation indicates that a necessary condition for the roots to be complex, which is not a sufficient condition, is that $\alpha _ { 2 } / \alpha _ { 0 } > 0$ .

It is easy to ascertain by inspection whether or not the second-order difference equation is stable. The condition that the roots of $\alpha ( z ) = 0$ must lie outside the unit circle, which is necessary and sufficient for stability, imposes certain restrictions on the coefficients of $\alpha ( z )$ which can be checked easily.

We can reveal these conditions most readily by considering the auxiliary polynomial $\rho ( z ) = z ^ { 2 } \alpha ( z ^ { - 1 } )$ whose roots, which are the inverses of those of $\alpha ( z )$ , must lie inside the unit circle. Let the roots of $\rho ( z )$ , which might be real or complex, be denoted by $\mu _ { 1 } , \mu _ { 2 }$ . Then we can write

$$
\rho (z) = \alpha_ {0} z ^ {2} + \alpha_ {1} z + \alpha_ {2}
$$

$$
\begin{array}{l} = \alpha_ {0} (z - \mu_ {1}) (z - \mu_ {2}) \tag {44} \\ = \alpha_ {0} \left\{z ^ {2} - (\mu_ {1} + \mu_ {2}) z + \mu_ {1} \mu_ {2} \right\}, \\ \end{array}
$$

where is is assumed that $\alpha _ { 0 } > 0$ . This indicates that $\alpha _ { 2 } / \alpha _ { 0 } = \mu _ { 1 } \mu _ { 2 }$ . Therefore the conditions $| \mu _ { 1 } |$ , $| \mu _ { 2 } | < 1$ imply that

$$
- \alpha_ {0} <   \alpha_ {2} <   \alpha_ {0}. \tag {45}
$$

If the roots are complex conjugate numbers $\mu , \mu ^ { * } = \gamma \pm i \delta$ , then this condition will ensure that $\mu ^ { * } \mu = \alpha _ { 2 } / \alpha _ { 0 } < 1$ , which is the condition that they are within the unit circle.

Now consider the fact that, if $\alpha _ { 0 } > 0$ , then the function $\rho ( z )$ will have a minimum value over the real line which is greater than zero if the roots are complex and no greater than zero if they are real. If the roots are real, then they will be found in the interval $( - 1 , 1 )$ if and only if

$$
\rho (- 1) = \alpha_ {0} - \alpha_ {1} + \alpha_ {2} > 0 \quad \text {a n d} \tag {46}
$$

$$
\rho (1) = \alpha_ {0} + \alpha_ {1} + \alpha_ {2} > 0.
$$

If the roots are complex then these conditions are bound to be satisfied.

From these arguments, it follows that the conditions under (45) and (46) in combination are necessary and sufficient to ensure that the roots of $\rho ( z ) = 0$ are within the unit circle and that the roots of $\alpha ( z ) = 0$ are outside.

# State-Space Models

An $\boldsymbol { n }$ th-order difference equation in a single variable can be transformed into a first-order system in $_ n$ variables which are the elements of a so-called state vector.

There is a wide variety of alternative forms which can be assumed by a first-order vector difference equation corresponding to the $\boldsymbol { n }$ th-order scalar equation. However, certain of these are described as canonical forms by virtue of special structures in the matrix.

In demonstrating one of the more common canonical forms, let us consider again the $n$ th-order difference equation of (32), in reference to which we may define the following variables:

$$
\begin{array}{l} \xi_ {1} (t) = x (t), \\ \xi_ {2} (t) = \xi_ {1} (t - 1) = x (t - 1), \end{array} \tag {47}
$$

$$
\xi_ {n} (t) = \xi_ {n - 1} (t - 1) = x (t - n + 1).
$$

On the basis of these definitions, a first-order vector equation may be constructed in the form of

$$
\left[ \begin{array}{c} \xi_ {1} (t) \\ \xi_ {2} (t) \\ \vdots \\ \xi_ {n} (t) \end{array} \right] = \left[ \begin{array}{c c c c} - \alpha_ {1} & \dots & - \alpha_ {n - 1} & - \alpha_ {n} \\ 1 & \dots & 0 & 0 \\ \vdots & \ddots & \vdots & \vdots \\ 0 & \dots & 1 & 0 \end{array} \right] \left[ \begin{array}{c} \xi_ {1} (t - 1) \\ \xi_ {2} (t - 1) \\ \vdots \\ \xi_ {n} (t - 1) \end{array} \right] + \left[ \begin{array}{c} 1 \\ 0 \\ \vdots \\ 0 \end{array} \right] \varepsilon (t). \tag {48}
$$

# D.S.G. POLLOCK: MATHEMATICS FOR TIME SERIES

The matrix in this structure is sometimes described as the companion form. Here it is manifest, in view of the definitions under (47), that the leading equation of the system, which is

$$
\xi_ {1} (t) = - \alpha_ {1} \xi_ {1} (t - 1) + \dots + \alpha_ {n} \xi_ {n} (t - 1) + \varepsilon (t), \tag {49}
$$

is precisely the equation under (32).

Example. An example of a system which is not in a canonical form is provided by the following matrix equation:

$$
\left[ \begin{array}{c} y (t) \\ z (t) \end{array} \right] = \kappa \left[ \begin{array}{c c} \cos \omega & - \sin \omega \\ \sin \omega & \cos \omega \end{array} \right] \left[ \begin{array}{c} y (t - 1) \\ z (t - 1) \end{array} \right] + \left[ \begin{array}{c} v (t) \\ \zeta (t) \end{array} \right]. \tag {50}
$$

With the use of the lag operator, the equation can also be written as

$$
\left[ \begin{array}{c c} 1 - \kappa \cos \omega L & \kappa \sin \omega L \\ - \kappa \sin \omega L & 1 - \kappa \cos \omega L \end{array} \right] \left[ \begin{array}{c} y (t) \\ z (t) \end{array} \right] = \left[ \begin{array}{c} v (t) \\ \zeta (t) \end{array} \right]. \tag {51}
$$

On premultiplying the equation by the inverse of the matrix on the LHS, we get

$$
\begin{array}{r l} (5 2) & {\left[ \begin{array}{c} y (t) \\ z (t) \end{array} \right] = \frac {1}{1 - 2 \kappa \cos \omega L + \kappa^ {2} L ^ {2}} \left[ \begin{array}{c c} 1 - \kappa \cos \omega L & - \kappa \sin \omega L \\ \kappa \sin \omega L & 1 - \kappa \cos \omega L \end{array} \right] \left[ \begin{array}{c} v (t) \\ \zeta (t) \end{array} \right].} \end{array}
$$

A special case arises when

$$
\left[ \begin{array}{c} \upsilon (t) \\ \zeta (t) \end{array} \right] = \left[ \begin{array}{c} - \sin \omega \\ \cos \omega \end{array} \right] \eta (t), \tag {53}
$$

where $\eta ( t )$ is a white-noise sequence. Then the equation becomes

$$
\left[ \begin{array}{c} y (t) \\ z (t) \end{array} \right] = \frac {1}{1 - 2 \kappa \cos \omega L + \kappa^ {2} L ^ {2}} \left[ \begin{array}{c} - \sin \omega \\ \cos \omega \end{array} \right] \eta (t). \tag {54}
$$

On defining $\varepsilon ( t ) = - \sin \omega \eta ( t )$ we may write the first of these equations as

$$
(5 5) \qquad (1 - 2 \kappa \cos \omega L + \kappa^ {2} L ^ {2}) y (t) = \varepsilon (t).
$$

This is just a second-order difference equation with a white-noise forcing function; and, by virtue of the inclusion of the damping factor $\kappa \in \left[ 0 , 1 \right)$ , it represents a generalisation of the equation to be found under (2.24).

# Transfer Functions

Consider again the simple dynamic model of equation (5):

$$
y (t) = \phi y (t - 1) + x (t) \beta + \varepsilon (t). \tag {56}
$$

With the use of the lag operator, this can be rewritten as

$$
(1 - \phi L) y (t) = \beta x (t) + \varepsilon (t) \tag {57}
$$

or, equivalently, as

$$
y (t) = \frac {\beta}{1 - \phi L} x (t) + \frac {1}{1 - \phi L} \varepsilon (t). \tag {58}
$$

The latter is the so-called rational transfer-function form of the equation. The operator $L$ within the transfer functions or filters can be replaced by a complex number $z$ . Then the transfer function which is associated with the signal $x ( t )$ becomes

$$
\frac {\beta}{1 - \phi z} = \beta \left\{1 + \phi z + \phi^ {2} z ^ {2} + \dots \right\}, \tag {59}
$$

where the RHS comes from a familiar power-series expansion.

The sequence $\{ \beta , \beta \phi , \beta \phi ^ { 2 } , \ldots \}$ of the coefficients of the expansion constitutes the impulse response of the transfer function. That is to to say, if we imagine that, on the input side, the signal is a unit-impulse sequence of the form

$$
x (t) = \{... 0, 1, 0, 0, ... \}, \tag {60}
$$

which has zero values at all but one instant, then its mapping through the transfer function would result in an output sequence of

$$
r (t) = \{\dots , 0, \beta , \beta \phi , \beta \phi^ {2}, \dots \}. \tag {61}
$$

Another important concept is the step response of the filter. We may imagine that the input sequence is zero-valued up to a point in time when it assumes a constant unit value:

$$
x (t) = \{... 0, 1, 1, 1, \dots \}. \tag {62}
$$

The mapping of this sequence through the transfer function would result in an output sequence of

$$
s (t) = \{\dots , 0, \beta , \beta + \beta \phi , \beta + \beta \phi + \beta \phi^ {2}, \dots \} \tag {63}
$$

# D.S.G. POLLOCK: MATHEMATICS FOR TIME SERIES

whose elements, from the point when the step occurs in $x ( t )$ , are simply the partial sums of the impulse-response sequence. This sequence of partial sums $\{ \beta , \beta + \beta \phi , \beta + \beta \phi + \beta \phi ^ { 2 } , \ldots \}$ is described as the step response. Given that $| \phi | < 1$ , the step response converges to a value

$$
\gamma = \frac {\beta}{1 - \phi} \tag {64}
$$

which is described as the steady-state gain or the long-term multiplier of the transfer function.

These various concepts apply to models of any order. Consider the equation

$$
\alpha (L) y (t) = \beta (L) x (t) + \varepsilon (t), \tag {65}
$$

where

$$
\alpha (L) = 1 + \alpha_ {1} L + \dots + \alpha_ {p} L ^ {p}
$$

$$
= 1 - \phi_ {1} L - \dots - \phi_ {p} L ^ {p}, \tag {66}
$$

$$
\beta (L) = \beta_ {0} + \beta_ {1} L + \dots + \beta_ {k} L ^ {k}
$$

are polynomials of the lag operator. The transfer-function form of the model is simply

$$
y (t) = \frac {\beta (L)}{\alpha (L)} x (t) + \frac {1}{\alpha (L)} \varepsilon (t), \tag {67}
$$

The rational function associated with $x ( t )$ has a series expansion

$$
\begin{array}{l} \frac {\beta (z)}{\alpha (z)} = \omega (z) \tag {68} \\ = \left\{\omega_ {0} + \omega_ {1} z + \omega_ {2} z ^ {2} + \dots \right\}; \\ \end{array}
$$

and the sequence of the coefficients of this expansion constitutes the impulseresponse function. The partial sums of the coefficients constitute the stepresponse function. The gain of the transfer function is defined by

$$
\gamma = \frac {\beta (1)}{\alpha (1)} = \frac {\beta_ {0} + \beta_ {1} + \cdots + \beta_ {k}}{1 + \alpha_ {1} + \cdots + \alpha_ {p}}. \tag {69}
$$

The method of finding the coefficients of the series expansion of the transfer function in the general case can be illustrated by the second-order case:

$$
\frac {\beta_ {0} + \beta_ {1} z}{1 - \phi_ {1} z - \phi_ {2} z ^ {2}} = \left\{\omega_ {0} + \omega_ {1} z + \omega_ {2} z ^ {2} + \dots \right\}. \tag {70}
$$

We rewrite this equation as

$$
\beta_ {0} + \beta_ {1} z = \left\{1 - \phi_ {1} z - \phi_ {2} z ^ {2} \right\} \left\{\omega_ {0} + \omega_ {1} z + \omega_ {2} z ^ {2} + \dots \right\}. \tag {71}
$$

Then, by performing the multiplication on the RHS, and by equating the coefficients of the same powers of $z$ on the two sides of the equation, we find that

$$
\beta_ {0} = \omega_ {0}, \quad \omega_ {0} = \beta_ {0},
$$

$$
\beta_ {1} = \omega_ {1} - \phi_ {1} \omega_ {0}, \quad \omega_ {1} = \beta_ {1} + \phi_ {1} \omega_ {0},
$$

$$
0 = \omega_ {2} - \phi_ {1} \omega_ {1} - \phi_ {2} \omega_ {0}, \quad \omega_ {2} = \phi_ {1} \omega_ {1} + \phi_ {2} \omega_ {0}, \tag {72}
$$

$$
\vdots \qquad \qquad \qquad \qquad \qquad \qquad \vdots
$$

$$
0 = \omega_ {n} - \phi_ {1} \omega_ {n - 1} - \phi_ {2} \omega_ {n - 2}, \quad \omega_ {n} = \phi_ {1} \omega_ {n - 1} + \phi_ {2} \omega_ {n - 2}.
$$

The necessary and sufficient condition for the convergence of the sequence $\left\{ \omega _ { i } \right\}$ is that the roots of the primary polynomial equation $1 - \phi _ { 1 } z - \phi _ { 2 } z ^ { 2 } = 0$ should lie outside the unit circle or, equivalently, that the roots of the auxiliary equation $z ^ { 2 } - \phi _ { 1 } z - \phi _ { 2 } = 0$ —which are the inverses of the former roots—should lie inside the unit circle. If the roots of these equations are real, then the sequence will converge monotonically to zero whereas, if the roots are complexvalued, then the sequence will converge in the manner of a damped sinusoid.

It is clear that the equation

$$
\omega (n) = \phi_ {1} \omega (n - 1) + \phi_ {2} \omega (n - 2), \tag {73}
$$

which serves to generate the elements of the impulse response, is nothing but a second-order homogeneous difference equation. In fact, Figure 2, which has been presented as the solution to a homogeneous difference equation, represents the impulse response of the transfer function $( 1 + 2 L ) / ( 1 - 1 . 6 9 L + 0 . 8 1 L ^ { 2 } )$ ).

In the light of this result, it is apparent that the coefficients of the denominator polynomial $1 - \phi _ { 1 } z - \phi _ { 2 } z ^ { 2 }$ serve to determine the period and the damping factor of a complex impulse response. The coefficients in the numerator polynomial $\beta _ { 0 } + \beta _ { 1 } z$ serve to determine the initial amplitude of the response and its phase lag. It seems that all four coefficients must be present if a secondorder transfer function is to have complete flexibility in modelling a dynamic response.

# The Frequency Response

In many applications within forecasting and time-series analysis, it is of interest to consider the response of a transfer function to a signal which is a simple sinusoid. As we have indicated in a previous lecture, it is possible

![](images/c2e9e1ede5b5168e1677cdc2ae75390fca70e7c5b00036bebda345df7891b7b4.jpg)  
Figure 3.The gain of the transfer function $( 1 + 2 L ^ { 2 } ) / ( 1 - 1 . 6 9 L + 0 . 8 1 L ^ { 2 } )$ .

![](images/11925609a818c85837f9cc460cc80cb2c5a5612651fb0019ebad52a1b9fe84f0.jpg)  
Figure 4.The phase diagram of the transfer function $( 1 + 2 L ^ { 2 } ) / ( 1 - 1 . 6 9 L + 0 . 8 1 L ^ { 2 } )$ ).

to represent a finite sequence as a sum of sine and cosine functions whose frequencies are integer multiples of a fundamental frequency. More generally, it is possible, as we shall see later, to represent an arbitrary stationary stochastic process as a combination of an infinite number of sine and cosine functions whose frequencies range continuously in the interval $[ 0 , \pi ]$ . It follows that the effect of a transfer function upon stationary signals can be characterised in terms of its effect upon the sinusoidal functions.

Consider therefore the consequences of mapping the signal $x ( t ) = \cos ( \omega t )$ through the transfer function $\gamma ( L ) = \gamma _ { 0 } + \gamma _ { 1 } L + \cdot \cdot \cdot + \gamma _ { g } L ^ { g }$ . The output is

$$
\begin{array}{l} y (t) = \gamma (L) \cos (\omega t) \\ = \sum_ {j = 0} ^ {g} \gamma_ {j} \cos (\omega [ t - j ]). \tag {74} \\ \end{array}
$$

The trigonometrical identity $\cos ( A - B ) = \cos A \cos B + \sin A \sin B$ enables us to write this as

$$
\begin{array}{l} y (t) = \left\{\sum_ {j} \gamma_ {j} \cos (\omega j) \right\} \cos (\omega t) + \left\{\sum_ {j} \gamma_ {j} \sin (\omega j) \right\} \sin (\omega t) \tag {75} \\ = \alpha \cos (\omega t) + \beta \sin (\omega t) = \rho \cos (\omega t - \theta). \\ \end{array}
$$

Here we have defined

$$
\alpha = \sum_ {j = 0} ^ {g} \gamma_ {j} \cos (\omega j), \quad \beta = \sum_ {j = 0} ^ {g} \gamma_ {j} \sin (\omega j), \tag {76}
$$

$$
\rho = \sqrt {\alpha^ {2} + \beta^ {2}} \qquad \text {a n d} \qquad \theta = \tan^ {- 1} \left(\frac {\beta}{\alpha}\right).
$$

It can be seen from (75) that the effect of the filter upon the signal is twofold. First there is a gain effect whereby the amplitude of the sinusoid has been increased or diminished by a factor of $\rho$ . Also there is a phase effect whereby the peak of the sinusoid is displaced by a time delay of $\theta / \omega$ periods. Figures 3 and 4 represent the two effects of a simple rational transfer function on the set of sinusoids whose frequencies range from 0 to $\pi$ .

# 25 Years of Time Series Forecasting

# Jan G De Gooijer

Department of Quantitative Economics

University of Amsterdam, Roetersstraat 11, 1018 WB Amsterdam, The Netherlands

Telephone: +31–20–525–4244; Fax: +31–20–525–4349

Email: j.g.degooijer@uva.nl

# Rob J Hyndman

Department of Econometrics and Business Statistics,

Monash University, VIC 3800, Australia.

Telephone: +61–3–9905–2358; Fax: +61–3–9905–5474

Email: Rob.Hyndman@buseco.monash.edu

Revised: 6 January 2006

# 25 Years of Time Series Forecasting

Abstract: We review the past 25 years of research into time series forecasting. In this silver jubilee issue, we naturally highlight results published in journals managed by the International Institute of Forecasters (Journal of Forecasting 1982–1985; International Journal of Forecasting 1985–2005). During this period, over one third of all papers published in these journals concerned time series forecasting. We also review highly influential works on time series forecasting that have been published elsewhere during this period. Enormous progress has been made in many areas, but we find that there are a large number of topics in need of further development. We conclude with comments on possible future research directions in this field.

Keywords: Accuracy measures; ARCH; ARIMA; Combining; Count data; Densities; Exponential smoothing; Kalman filter; Long memory; Multivariate; Neural nets; Nonlinearity; Prediction intervals; Regime-switching; Robustness; Seasonality; State space; Structural models; Transfer function; Univariate; VAR.

1 Introduction 1   
2 Exponential smoothing 2   
3 ARIMA 5   
4 Seasonality 10   
5 State space and structural models and the Kalman filter 11   
6 Nonlinear 13   
7 Long memory 17   
8 ARCH/GARCH 18   
9 Count data forecasting 20   
10 Forecast evaluation and accuracy measures 21   
11 Combining 23   
12 Prediction intervals and densities 24   
13 A look to the future 25

Acknowledgments 28

References 29

# 1 Introduction

The International Institute of Forecasters (IIF) was established 25 years ago and its silver jubilee provides an opportunity to review progress on time series forecasting. We highlight research published in journals sponsored by the Institute, although we also cover key publications in other journals. In 1982 the IIF set up the Journal of Forecasting (JoF), published with John Wiley & Sons. After a break with Wiley in $1 9 8 5 ^ { 1 }$ the IIF decided to start the International Journal of Forecasting (IJF), published with Elsevier since 1985. This paper provides a selective guide to the literature on time series forecasting, covering the period 1982–2005 and summarizing about 340 papers published under the “IIF-flag” out of a total of over 940 papers. The proportion of papers that concern time series forecasting has been fairly stable over time. We also review key papers and books published elsewhere that have been highly influential to various developments in the field. The works referenced comprise 380 journal papers, and 20 books and monographs.

It was felt convenient to first classify the papers according to the models (e.g. exponential smoothing, ARIMA) introduced in the time series literature, rather than putting papers under a heading associated with a particular method. For instance, Bayesian methods in general can be applied to all models. Papers not concerning a particular model were then classified according to the various problems (e.g. accuracy measures, combining) they address. In only a few cases was a subjective decision on our part needed to classify a paper under a particular section heading. To facilitate a quick overview in a particular field, the papers are listed in alphabetical order under each of the section headings.

Determining what to include and what not to include in the list of references has been a problem. There may be papers that we have missed, and papers that are also referenced by other authors in this Silver Anniversary issue. As such the review is somewhat “selective”, although this does not imply that a particular paper is unimportant if it is not reviewed.

The review is not intended to be critical, but rather a (brief) historical and personal tour of the main developments. Still, a cautious reader may detect certain areas where the fruits of 25 years of intensive research interest has been limited. Conversely, clear explanations for many previously anomalous time series forecasting results have been provided by the end of 2005. Section 13 discusses some current research directions that hold promise for the future, but of course the list is far from exhaustive.

# 2 Exponential smoothing

# 2.1 Preamble

Twenty five years ago, exponential smoothing methods were often considered a collection of ad hoc techniques for extrapolating various types of univariate time series. Although exponential smoothing methods were widely used in business and industry, they had received little attention from statisticians and did not have a well-developed statistical foundation. These methods originated in the 1950s and 1960s with the work of Brown (1959, 1963), Holt (1957, reprinted 2004) and Winters (1960). Pegels (1969) provided a simple but useful classification of the trend and the seasonal patterns depending on whether they are additive (linear) or multiplicative (nonlinear).

Muth (1960) was the first to suggest a statistical foundation for simple exponential smoothing (SES) by demonstrating that it provided the optimal forecasts for a random walk plus noise. Further steps towards putting exponential smoothing within a statistical framework were provided by Box & Jenkins (1970, 1976), Roberts (1982) and Abraham and Ledolter (1983, 1986), who showed that some linear exponential smoothing forecasts arise as special cases of ARIMA models. However, these results did not extend to any nonlinear exponential smoothing methods.

Exponential smoothing methods received a boost by two papers published in 1985, which laid the foundation for much of the subsequent work in this area. First, Gardner (1985) provided a thorough review and synthesis of work in exponential smoothing to that date, and extended Pegels’ classification to include damped trend. This paper brought together a lot of existing work which stimulated the use of these methods and prompted a substantial amount of additional research. Later in the same year, Snyder (1985) showed that SES could be considered as arising from an innovation state space model (i.e., a model with a single source of error). Although this insight went largely unnoticed at the time, in recent years it has provided the basis for a large amount of work on state space models underlying exponential smoothing methods.

Most of the work since 1985 has involved studying the empirical properties of the methods (e.g. Bartolomei & Sweet, 1989; Makridakis & Hibon, 1991), proposals for new methods of estimation or initialization (Ledolter & Abraham, 1984), evaluation of the forecasts (Sweet & Wilson, 1988; McClain, 1988), or has concerned statistical models that can be considered to underly the methods (e.g. McKenzie, 1984). The damped multiplicative methods of Taylor (2003) provide the only genuinely new exponential smoothing methods over this period. There have, of course, been numerous studies applying exponential smoothing methods in various contexts including computer components (Gardner, 1993), air passengers (Grubb & Masa, 2001) and production planning (Miller & Liberatore, 1993).

Hyndman et al.’s (2002) taxonomy (extended by Taylor, 2003) provides a helpful categorization in describing the various methods. Each method consists of one of five types of trend (none,

additive, damped additive, multiplicative and damped multiplicative) and one of three types of seasonality (none, additive and multiplicative). Thus, there are 15 different methods, the best known of which are SES (no trend, no seasonality), Holt’s linear method (additive trend, no seasonality), Holt-Winters’ additive method (additive trend, additive seasonality) and Holt-Winters’ multiplicative method (additive trend, multiplicative seasonality).

# 2.2 Variations

Numerous variations on the original methods have been proposed. For example, Carreno & Madinaveitia (1990) and Williams & Miller (1999) proposed modifications to deal with discontinuities, and Rosas & Guerrero (1994) looked at exponential smoothing forecasts subject to one or more constraints. There are also variations in how and when seasonal components should be normalized. Lawton (1998) argued for renormalization of the seasonal indices at each time period, as it removes bias in estimates of level and seasonal components. Slightly different normalization schemes were given by Roberts (1982) and McKenzie (1986). Archibald & Koehler (2003) developed new renormalization equations that are simpler to use and give the same point forecasts as the original methods.

One useful variation, part way between SES and Holt’s method, is SES with drift. This is equivalent to Holt’s method with the trend parameter set to zero. Hyndman & Billah (2003) showed that this method was also equivalent to Assimakopoulos & Nikolopoulos’s (2000) “Theta method” when the drift parameter is set to half the slope of a linear trend fitted to the data. The Theta method performed extremely well in the M3-competition, although why this particular choice of model and parameters is good has not yet been determined.

There has been remarkably little work in developing multivariate versions of the exponential smoothing methods for forecasting. One notable exception is Pfeffermann & Allon (1989) who looked at Israeli tourism data. Multivariate SES is used for process control charts (e.g. Pan, 2005), where it is called “multivariate exponentially weighted moving averages”, but here the focus is not on forecasting.

# 2.3 State space models

Ord et al. (1997) built on the work of Snyder (1985) by proposing a class of innovation state space models which can be considered as underlying some of the exponential smoothing methods. Hyndman et al. (2002) and Taylor (2003) extended this to include all of the 15 exponential smoothing methods. In fact, Hyndman et al. (2002) proposed two state space models for each method, corresponding to the additive error and the multiplicative error cases. These models are not unique, and other related state space models for exponential smoothing methods are presented in Koehler et al. (2001) and Chatfield et al. (2001). It has long been known that some ARIMA models give equivalent forecasts to the linear exponential smoothing methods. The significance of the recent work on innovation state space models is that the nonlinear exponen-

tial smoothing methods can also be derived from statistical models.

# 2.4 Method selection

Gardner & McKenzie (1988) provided some simple rules based on the variances of differenced time series for choosing an appropriate exponential smoothing method. Tashman & Kruk (1996) compared these rules with others proposed by Collopy & Armstrong (1992) and an approach based on the BIC. Hyndman et al. (2002) also proposed an information criterion approach, but using the underlying state space models.

# 2.5 Robustness

The remarkably good forecasting performance of exponential smoothing methods has been addressed by several authors. Satchell & Timmermann (1995) and Chatfield et al. (2001) showed that SES is optimal for a wide range of data generating processes. In a small simulation study, Hyndman (2001) showed that simple exponential smoothing performed better than first order ARIMA models because it is not so subject to model selection problems, particularly when data are non-normal.

# 2.6 Prediction intervals

One of the criticisms of exponential smoothing methods 25 years ago was that there was no way to produce prediction intervals for the forecasts. The first analytical approach to this problem was to assume the series were generated by deterministic functions of time plus white noise (Brown, 1963; Sweet, 1985; McKenzie, 1986; Gardner, 1985). If this was so, a regression model should be used rather than exponential smoothing methods; thus, Newbold & Bos (1989) strongly criticized all approaches based on this assumption.

Other authors sought to obtain prediction intervals via the equivalence between exponential smoothing methods and statistical models. Johnston & Harrison (1986) found forecast variances for the simple and Holt exponential smoothing methods for state space models with multiple sources of errors. Yar & Chatfield (1990) obtained prediction intervals for the additive Holt-Winters’ method, by deriving the underlying equivalent ARIMA model. Approximate prediction intervals for the multiplicative Holt-Winters’ method were discussed by Chatfield & Yar (1991) making the assumption that the one-step-ahead forecast errors are independent. Koehler et al. (2001) also derived an approximate formula for the forecast variance for the multiplicative Holt-Winters’ method, differing from Chatfield & Yar (1991) only in how the standard deviation of the one-step-ahead forecast error is estimated.

Ord et al. (1997) and Hyndman et al. (2002) used the underlying innovation state space model to simulate future sample paths and thereby obtained prediction intervals for all the exponential smoothing methods. Hyndman et al. (2005) used state space models to derive analytical

prediction intervals for 15 of the 30 methods, including all the commonly-used methods. They provide the most comprehensive algebraic approach to date for handling the prediction distribution problem for the majority of exponential smoothing methods.

# 2.7 Parameter space and model properties

It is common practice to restrict the smoothing parameters to the range 0 to 1. However, now that underlying statistical models are available, the natural (invertible) parameter space for the models can be used instead. Archibald (1990) showed that it is possible for smoothing parameters within the usual intervals to produce non-invertible models. Consequently, when forecasting, the impact of change in the past values of the series is non-negligible. Intuitively, such parameters produce poor forecasts and the forecast performance deteriorates. Lawton (1998) also discussed this problem.

# 3 ARIMA

# 3.1 Preamble

Early attempts to study time series, particularly in the nineteenth century, were generally characterized by the idea of a deterministic world. It was the major contribution of Yule (1927) who launched the notion of stochasticity in time series by postulating that every time series can be regarded as the realization of a stochastic process. Based on this simple idea, a number of time series methods have been developed since then. Workers such as Slutsky, Walker, Yaglom, and Yule first formulated the concept of autoregressive (AR) and moving average (MA) models. Wold’s decomposition theorem leads to the formulation and solution of the linear forecasting problem by Kolmogorov (1941). Since then, a considerable body of literature in the area of time series dealing with the parameter estimation, identification, model checking, and forecasting has appeared; see, e.g., Newbold (1983) for an early survey.

The publication Time Series Analysis: Forecasting and Control by Box & Jenkins (1970, 1976)2 integrated the existing knowledge. Moreover, these authors developed a coherent, versatile three-stage iterative cycle for time series identification, estimation, and verification (rightly known as the Box-Jenkins approach). The book has had an enormous impact on the theory and practice of modern time series analysis and forecasting. With the advent of the computer, it has popularised the use of autoregressive integrated moving average (ARIMA) models, and its extensions, in many areas of science. Indeed, forecasting discrete time series processes through univariate ARIMA models, transfer function (dynamic regression) models and multivariate (vector) ARIMA models has generated quite a few IJF papers. Often these studies were of an

Table 1: A list of examples of real applications.   

<table><tr><td>Data set</td><td>Forecast horizon</td><td>Benchmark</td><td>Reference</td></tr><tr><td colspan="4">Univariate ARIMA</td></tr><tr><td>Electricity load (minutes)</td><td>1-30 minutes</td><td>Wiener filter</td><td>Di Caprio et al. (1983)</td></tr><tr><td>Quarterly automobile insurance paid claim costs</td><td>8 quarters</td><td>log-linear regression</td><td>Cummins &amp; Griebentrog (1985)</td></tr><tr><td>Daily federal funds rate</td><td>1 day</td><td>random walk</td><td>Hein &amp; Spudeck (1988)</td></tr><tr><td>Quarterly macroeconomic data</td><td>1-8 quarters</td><td>Wharton model</td><td>Dhrymes &amp; Peristiani (1988)</td></tr><tr><td>Monthly department store sales</td><td>1 month</td><td>simple exponential smoothing</td><td>Geurts &amp; Kelly (1986, 1990); Pack (1990)</td></tr><tr><td>Monthly demand for telephone services</td><td>3 years</td><td>univariate state space</td><td>Grambsch &amp; Stahel (1990)</td></tr><tr><td>Yearly population totals</td><td>20-30 years</td><td>demographic models</td><td>Pflaumer (1992)</td></tr><tr><td>Monthly tourism demand</td><td>1-24 months</td><td>univariate state space; multivariate state space</td><td>du Preez &amp; Witt (2003)</td></tr><tr><td colspan="4">Dynamic regression/Transfer function</td></tr><tr><td>Monthly telecommunications traffic</td><td>1 month</td><td>univariate ARIMA</td><td>Layton et al. (1986)</td></tr><tr><td>Weekly sales data</td><td>2 years</td><td>n.a.</td><td>Leone (1987)</td></tr><tr><td>Daily call volumes</td><td>1 week</td><td>Holt-Winters</td><td>Bianchi et al. (1998)</td></tr><tr><td>Monthly employment levels</td><td>1-12 months</td><td>univariate ARIMA</td><td>Weller (1989)</td></tr><tr><td>Monthly and quarterly consumption of natural gas</td><td>1 month/1 quarter</td><td>univariate ARIMA</td><td>Liu &amp; Lin (1991)</td></tr><tr><td>Monthly electricity consumption</td><td>1-3 years</td><td>univariate ARIMA</td><td>Harris &amp; Liu (1993)</td></tr><tr><td colspan="4">VARIMA</td></tr><tr><td>Yearly municipal budget data</td><td>yearly (in-sample)</td><td>univariate ARIMA</td><td>Downs &amp; Rocke (1983)</td></tr><tr><td>Monthly accounting data</td><td>1 month</td><td>regression, univariate, ARIMA, transfer function</td><td>Hillmer et al. (1983)</td></tr><tr><td>Quarterly macroeconomic data</td><td>1-10 quarters</td><td>judgmental methods, univariate ARIMA</td><td>Öller (1985)</td></tr><tr><td>Monthly truck sales</td><td>1-13 months</td><td>univariate ARIMA, Holt-Winters</td><td>Heuts &amp; Bronckers (1988)</td></tr><tr><td>Monthly hospital patient movements</td><td>2 years</td><td>univariate ARIMA, Holt-Winters</td><td>Lin (1989)</td></tr><tr><td>Quarterly unemployment rate</td><td>1-8 quarters</td><td>transfer function</td><td>Edlund &amp; Karlsson (1993)</td></tr></table>

empirical nature, using one or more benchmark methods/models as a comparison. Without pretending to be complete, Table 1 gives a list of these studies. Naturally, some of these studies are more successful than others. In all cases, the forecasting experiences reported are valuable. They have also been the key to new developments which may be summarized as follows.

# 3.2 Univariate

The success of the Box-Jenkins methodology is founded on the fact that the various models can, between them, mimic the behaviour of diverse types of series—and do so adequately without usually requiring very many parameters to be estimated in the final choice of the model. However, in the mid sixties the selection of a model was very much a matter of researcher’s judgment; there was no algorithm to specify a model uniquely. Since then, many techniques and

methods have been suggested to add mathematical rigour to the search process of an ARMA model, including Akaike’s information criterion (AIC), Akaike’s final prediction error (FPE), and the Bayes information criterion (BIC). Often these criteria come down to minimizing (insample) one-step-ahead forecast errors, with a penalty term for overfitting. FPE has also been generalized for multi-step-ahead forecasting (see, e.g., Bhansali, 1996, 1999), but this generalization has not been utilized by applied workers. This also seems to be the case with criteria based on cross-validation and split-sample validation (see, e.g., West, 1996) principles, making use of genuine out-of-sample forecast errors; see Pena & S ˜ anchez (2005) for a related approach ´ worth considering.

There are a number of methods (cf. Box, et al., 1994) for estimating parameters of an ARMA model. Although these methods are equivalent asymptotically, in the sense that estimates tend to the same normal distribution, there are large differences in finite sample properties. In a comparative study of software packages, Newbold et al. (1994) showed that this difference can be quite substantial and, as a consequence, may influence forecasts. They recommended the use of full maximum likelihood. The effect of parameter estimation errors on probability limits of the forecasts was also noticed by Zellner (1971). He used a Bayesian analysis and derived the predictive distribution of future observations treating the parameters in the ARMA model as random variables. More recently, Kim (2003) considered parameter estimation and forecasting of AR models in small samples. He found that (bootstrap) bias-corrected parameter estimators produce more accurate forecasts than the least squares estimator. Landsman & Damodaran (1989) presented evidence that the James-Stein ARIMA parameter estimator improves forecast accuracy relative to other methods, under an MSE loss criterion.

If a time series is known to follow a univariate ARIMA model, forecasts using disaggregated observations are, in terms of MSE, at least as good as forecasts using aggregated observations. However, in practical applications there are other factors to be considered, such as missing values in disaggregated series. Both Ledolter (1989) and Hotta (1993) analysed the effect of an additive outlier on the forecast intervals when the ARIMA model parameters are estimated. When the model is stationary, Hotta & Cardoso Neto (1993) showed that the loss of efficiency using aggregated data is not large, even if the model is not known. Thus, prediction could be done by either disaggregated or aggregated models.

The problem of incorporating external (prior) information in the univariate ARIMA forecasts have been considered by Cholette (1982), Guerrero (1991) and de Alba (1993).

As an alternative to the univariate ARIMA methodology, Parzen (1982) proposed the ARARMA methodology. The key idea is that a time series is transformed from a long memory AR filter to a short-memory filter, thus avoiding the “harsher” differencing operator. In addition, a different approach to the ‘conventional’ Box-Jenkins identification step is used. In the M-competition (Makridakis et al., 1982), the ARARMA models achieved the lowest MAPE for longer forecast horizons. Hence it is surprising to find that, apart from the paper by Meade & Smith (1985), the ARARMA methodology has not really taken off in applied work. Its ultimate value may per-

haps be better judged by assessing the study by Meade (2000) who compared the forecasting performance of an automated and non-automated ARARMA method.

Automatic univariate ARIMA modelling has been shown to produce one-step-ahead forecasting as accurate as those produced by competent modellers (Hill & Fildes, 1984; Libert, 1984; Poulos et al., 1987; Texter & Ord, 1989). Several software vendors have implemented automated time series forecasting methods (including multivariate methods); see, e.g., Geriner & Ord (1991), Tashman & Leach (1991) and Tashman (2000). Often these methods act as black boxes. The technology of expert systems (Melard & Pasteels, 2000) can be used to avoid this ´ problem. Some guidelines on the choice of an automatic forecasting method are provided by Chatfield (1988).

Rather than adopting a single AR model for all forecast horizons, Kang (2003) empirically investigated the case of using a multi-step ahead forecasting AR model selected separately for each horizon. The forecasting performance of the multi-step ahead procedure appears to depend on, among other things, optimal order selection criteria, forecast periods, forecast horizons, and the time series to be forecast.

# 3.3 Transfer function

The identification of transfer function models can be difficult when there is more than one input variable. Edlund (1984) presented a two-step method for identification of the impulse response function when a number of different input variables are correlated. Koreisha (1983) established various relationships between transfer functions, causal implications and econometric model specification. Gupta (1987) identified the major pitfalls in causality testing. Using principal component analysis, a parsimonious representation of a transfer function model was suggested by del Moral & Valderrama (1997). Krishnamurthi et al. (1989) showed how more accurate estimates of the impact of interventions in transfer function models can be obtained by using a control variable.

# 3.4 Multivariate

The vector ARIMA (VARIMA) model is a multivariate generalization of the univariate ARIMA model. The population characteristics of VARMA processes appear to have been first derived by Quenouille (1957, 1968), although software to implement them only became available in the 1980s and 1990s. Since VARIMA models can accommodate assumptions on exogeneity and on contemporaneous relationships, they offered new challenges to forecasters and policy makers. Riise & Tjøstheim (1984) addressed the effect of parameter estimation on VARMA forecasts. Cholette & Lamy (1986) showed how smoothing filters can be built into VARMA models. The smoothing prevents irregular fluctuations in explanatory time series from migrating to the forecasts of the dependent series. To determine the maximum forecast horizon of VARMA processes, De Gooijer & Klein (1991) established the theoretical properties of cumu-

lated multi-step-ahead forecasts and cumulated multi-step-ahead forecast errors. Lutkepohl ¨ (1986) studied the effects of temporal aggregation and systematic sampling on forecasting, assuming that the disaggregated (stationary) variable follows a VARMA process with unknown order. Later, Bidarkota (1998) considered the same problem but with the observed variables integrated rather than stationary.

Vector autoregressions (VARs) constitute a special case of the more general class of VARMA models. In essence, a VAR model is a fairly unrestricted (flexible) approximation to the reduced form of a wide variety of dynamic econometric models. VAR models can be specified in a number of ways. Funke (1990) presented five different VAR specifications and compared their forecasting performance using monthly industrial production series. Dhrymes & Thomakos (1998) discussed issues regarding the identification of structural VARs. Hafer & Sheehan (1989) showed the effect on VAR forecasts of changes in the model structure. Explicit expressions for VAR forecasts in levels are provided by Arino & Franses (2000); see also Wieringa & Horv ˜ ath ´ (2005). Hansson et al. (2005) used a dynamic factor model as a starting point to obtain forecasts from parsimoniously parametrised VARs.

In general, VAR models tend to suffer from ‘overfitting’ with too many free insignificant parameters. As a result, these models can provide poor out-of-sample forecasts, even though within-sample fitting is good; see, e.g., Liu et al. (1994) and Simkins (1995). Instead of restricting some of the parameters in the usual way, Litterman (1986) and others imposed a prior distribution on the parameters expressing the belief that many economic variables behave like a random walk. BVAR models have been chiefly used for macroeconomic forecasting (Ashley, 1988; Kunst & Neusser, 1986; Artis & Zhang, 1990; Holden & Broomhead, 1990), for forecasting market shares (Ribeiro Ramos, 2003), for labor market forecasting (LeSage & Magura, 1991), for business forecasting (Spencer, 1993), or for local economic forecasting (LeSage, 1989). Kling & Bessler (1985) compared out-of-sample forecasts of several then-known multivariate time series methods, including Litterman’s BVAR model.

The Engle-Granger (1987) concept of cointegration has raised various interesting questions regarding the forecasting ability of error correction models (ECMs) over unrestricted VARs and BVARs. Shoesmith (1992, 1995), Tegene & Kuchler (1994) and Wang & Bessler (2004) provided empirical evidence to suggest that ECMs outperform VARs in levels, particularly over longer forecast horizons. Shoesmith (1995), and later Villani (2001), also showed how Litterman’s (1986) Bayesian approach can improve forecasting with cointegrated VARs. Reimers (1997) studied the forecasting performance of seasonally cointegrated vector time series processes using an ECM in fourth differences. Poskitt (2003) discussed the specification of cointegrated VARMA systems. Chevillon & Hendry (2005) analyzed the relation between direct multi-step estimation of stationary and non-stationary VARs and forecast accuracy.

# 4 Seasonality

The oldest approach to handling seasonality in time series is to extract it using a seasonal decomposition procedure such as the X-11 method. Over the past 25 years, the X-11 method and its variants (including the most recent version, X-12-ARIMA, Findley et al., 1998) have been studied extensively.

One line of research has considered the effect of using forecasting as part of the seasonal decomposition method. For example, Dagum (1982) and Huot et al. (1986) looked at the use of forecasting in X-11-ARIMA to reduce the size of revisions in the seasonal adjustment of data, and Pfeffermann et al. (1995) explored the effect of the forecasts on the variance of the trend and seasonally adjusted values.

Quenneville et al. (2003) took a different perspective and looked at forecasts implied by the asymmetric moving average filters in the X-11 method and its variants.

A third approach has been to look at the effectiveness of forecasting using seasonally adjusted data obtained from a seasonal decomposition method. Miller & Williams (2003, 2004) showed that greater forecasting accuracy is obtained by shrinking the seasonal component towards zero. The commentaries on the latter paper (Findley et al., 2004; Ladiray & Quenneville, 2004; Hyndman, 2004; Koehler, 2004; and Ord, 2004) gave several suggestions regarding implementation of this idea.

In addition to work on the X-11 method and its variants, there have also been several new methods for seasonal adjustment developed, the most important being the model based approach of TRAMO-SEATS (Gomez & Maravall, 2001; Kaiser & Maravall, 2005) and the nonparamet-´ ric method STL (Cleveland et al., 1990). Another proposal has been to use sinusoidal models (Simmons, 1990).

When forecasting several similar series, Withycombe (1989) showed that it can be more efficient to estimate a combined seasonal component from the group of series, rather than individual seasonal patterns. Bunn & Vassilopoulos (1993) demonstrated how to use clustering to form appropriate groups for this situation, and Bunn & Vassilopoulos (1999) introduced some improved estimators for the group seasonal indices.

Twenty five years ago, unit root tests had only recently been invented, and seasonal unit root tests were yet to appear. Subsequently, there has been considerable work done on the use and implementation of seasonal unit root tests including Hylleberg & Pagan (1997), Taylor (1997) and Franses & Koehler (1998). Paap et al. (1997) and Clements & Hendry (1997) studied the forecast performance of models with unit roots, especially in the context of level shifts.

Some authors have cautioned against the widespread use of standard seasonal unit root models for economic time series. Osborn (1990) argued that deterministic seasonal components are more common in economic series than stochastic seasonality. Franses & Romijn (1993) sug-

gested that seasonal roots in periodic models result in better forecasts. Periodic time series models were also explored by Wells (1997), Herwartz (1997) and Novales & de Fruto (1997), all of whom found that periodic models can lead to improved forecast performance compared to non-periodic models under some conditions. Forecasting of multivariate periodic ARMA processes is considered by Ula (1993).

Several papers have compared various seasonal models empirically. Chen (1997) explored the robustness properties of a structural model, a regression model with seasonal dummies, an ARIMA model, and Holt-Winters’ method, and found that the latter two yield forecasts that are relatively robust to model misspecification. Noakes et al. (1985), Albertson & Aylen (1996), Kulendran & King (1997) and Franses & van Dijk (2005) each compared the forecast performance of several seasonal models applied to real data. The best performing model varies across the studies, depending on which models were tried and the nature of the data. There appears to be no consensus yet as to the conditions under which each model is preferred.

# 5 State space and structural models and the Kalman filter

At the start of the 1980s, state space models were only beginning to be used by statisticians for forecasting time series, although the ideas had been present in the engineering literature since Kalman’s (1960) ground-breaking work. State space models provide a unifying framework in which any linear time series model can be written. The key forecasting contribution of Kalman (1960) was to give a recursive algorithm (known as the Kalman filter) for computing forecasts. Statisticians became interested in state space models when Schweppe (1965) showed that the Kalman filter provides an efficient algorithm for computing the one-step-ahead prediction errors and associated variances needed to produce the likelihood function. Shumway & Stoffer (1982) combined the EM algorithm with the Kalman filter to give a general approach to forecasting time series using state space models, including allowing for missing observations.

A particular class of state space models, known as “dynamic linear models” (DLM), was introduced by Harrison & Stevens (1976), who also proposed a Bayesian approach to estimation. Fildes (1983) compared the forecasts obtained using Harrison & Steven’s method with those from simpler methods such as exponential smoothing, and concluded that the additional complexity did not lead to improved forecasting performance. The modelling and estimation approach of Harrison & Stevens was further developed by West, Harrison & Migon (1985) and West & Harrison (1989). Harvey (1984, 1989) extended the class of models and followed a non-Bayesian approach to estimation. He also renamed the models as “structural models”, although in later papers he uses the term “unobserved component models”. Harvey (2006) provides a comprehensive review and introduction to this class of models including continuous-time and non-Gaussian variations.

These models bear many similarities with exponential smoothing methods, but have multiple

sources of random error. In particular, the “basic structural model” (BSM) is similar to Holt-Winters’ method for seasonal data and includes a level, trend and seasonal component.

Ray (1989) discussed convergence rates for the linear growth structural model and showed that the initial states (usually chosen subjectively) have a non-negligible impact on forecasts. Harvey & Snyder (1990) proposed some continuous-time structural models for use in forecasting lead time demand for inventory control. Proietti (2000) discussed several variations on the BSM and compared their properties and evaluated the resulting forecasts.

Non-Gaussian structural models have been the subject of a large number of papers, beginning with the power steady model of Smith (1979) with further development by West, Harrison & Migon (1985). For example, these models were applied to forecasting time series of proportions by Grunwald, Raftery & Guttorp (1993) and to counts by Harvey & Fernandes (1989). However, Grunwald, Hamza & Hyndman (1997) showed that most of the commonly used models have the substantial flaw of all sample paths converging to a constant when the sample space is less than the whole real line, making them unsuitable for anything other than point forecasting.

Another class of state space models, known as “balanced state space models”, has been used primarily for forecasting macroeconomic time series. Mittnik (1990) provided a survey of this class of models, and Vinod & Basu (1995) obtained forecasts of consumption, income and interest rates using balanced state space models. These models have only one source of random error and subsume various other time series models including ARMAX models, ARMA models and rational distributed lag models. A related class of state space models are the “single source of error” models that underly exponential smoothing methods; these were discussed in Section 2.

As well as these methodological developments, there have been several papers proposing innovative state space models to solve practical forecasting problems. These include Coomes (1992) who used a state space model to forecast jobs by industry for local regions, and Patterson (1995) who used a state space approach for forecasting real personal disposable income.

Amongst this research on state space models, Kalman filtering, and discrete/continuous time structural models, the books by Harvey (1989), West & Harrison (1989, 1997) and Durbin & Koopman (2001) have had a substantial impact on the time series literature. However, forecasting applications of the state space framework using the Kalman filter has been rather limited in the IJF. In that sense, it is perhaps not too surprising that even today, some textbook authors do not seem to realize that the Kalman filter can, for example, track a nonstationary process stably.

# 6 Nonlinear

# 6.1 Preamble

Compared to the study of linear time series, the development of nonlinear time series analysis and forecasting is still in its infancy. The beginning of nonlinear time series analysis has been attributed to Volterra (1930). He showed that any continuous nonlinear function in $t$ could be approximated by a finite Volterra series. Wiener (1958) became interested in the ideas of functional series representation, and further developed the existing material. Although the probabilistic properties of these models have been studied extensively, the problems of parameter estimation, model fitting, and forecasting, have been neglected for a long time. This neglect can largely be attributed to the complexity of the proposed Wiener model, and its simplified forms like the bilinear model (Poskitt & Tremayne, 1986). At the time, fitting these models led to what were insurmountable computational difficulties.

Although linearity is a useful assumption and a powerful tool in many areas, it became increasingly clear in the late 1970s and early 1980s that linear models are insufficient in many real applications. For example, sustained animal population size cycles (the well-known Canadian lynx data), sustained solar cycles (annual sunspot numbers), energy flow and amplitudefrequency relations were found not to be suitable for linear models. Accelerated by practical demands, several useful nonlinear time series models were proposed in this same period. De Gooijer & Kumar (1992) provided an overview of the developments in this area to the beginning of the 1990s. These authors argued that the evidence for the superior forecasting performance of nonlinear models is patchy.

One factor that has probably retarded the widespread reporting of nonlinear forecasts is that up to that time it was not possible to obtain closed-form analytic expressions for multi-stepahead forecasts. However, by using the so-called Chapman-Kolmogorov relation, exact least squares multi-step-ahead forecasts for general nonlinear AR models can, in principle, be obtained through complex numerical integration. Early examples of this approach are reported by Pemberton (1987) and Al-Quassem & Lane (1989). Nowadays, nonlinear forecasts are obtained by either Monte Carlo simulation or by bootstrapping. The latter approach is preferred since no assumptions are made about the distribution of the error process.

The monograph by Granger & Terasvirta (1993) has boosted new developments in estimating, ¨ evaluating, and selecting among nonlinear forecasting models for economic and financial time series. A good overview of the current state-of-the-art is IJF Special Issue 20:2 (2004). In their introductory paper Clements et al. (2004) outlined a variety of topics for future research. They concluded that “. . . the day is still long off when simple, reliable and easy to use nonlinear model specification, estimation and forecasting procedures will be readily available”.

# 6.2 Regime-switching models

The class of (self-exciting) threshold AR (SETAR) models has been prominently promoted through the books by Tong (1983, 1990). These models, which are piecewise linear models in their most basic form, have attracted some attention in the IJF. Clements & Smith (1997) compared a number of methods for obtaining multi-step-ahead forecasts for univariate discretetime SETAR models. They concluded that forecasts made using Monte Carlo simulation are satisfactory in cases were it is known that the disturbances in the SETAR model come from a symmetric distribution. Otherwise the bootstrap method is to be preferred. Similar results were reported by De Gooijer & Vidiella-i-Anguera (2004) for threshold VAR models. Brockwell & Hyndman (1992) obtained one-step-ahead forecasts for univariate continuous-time threshold AR models (CTAR). Since the calculation of multi-step-ahead forecasts from CTAR models involves complicated higher dimensional integration, the practical use of CTARs is limited. The out-of-sample forecast performance of various variants of SETAR models relative to linear models has been the subject of several IJF papers, including Astatkie et al. (1997), Boero & Marrocu (2004) and Enders & Falk (1998).

One drawback of the SETAR model is that the dynamics change discontinuously from one regime to the other. In contrast, a smooth transition AR (STAR) model allows for a more gradual transition between the different regimes. Sarantis (2001) found evidence that STAR-type models can improve upon linear AR and random walk models in forecasting stock prices at both short term and medium term horizons. Interestingly, the recent study by Bradley & Jansen (2004) seems to refute Sarantis’ conclusion.

Can forecasts for macroeconomic aggregates like total output or total unemployment be improved by using a multi-level panel smooth STAR model for disaggregated series? This is the key issue examined by Fok et al (2005). The proposed STAR model seems to be worth investigating in more detail since it allows the parameters that govern the regime-switching to differ across states. Based on simulation experiments and empirical findings, the authors claim that improvements in one-step-ahead forecasts can indeed be achieved.

Franses et al. (2004) proposed a threshold AR(1) model that allows for plausible inference about the specific values of the parameters. The key idea is that the values of the AR parameter depend on a leading indicator variable. The resulting model outperforms other time-varying nonlinear models, including the Markov regime-switching model, in terms of forecasting.

# 6.3 Functional-coefficient model

A functional coefficient AR (FCAR or FAR) model is an AR model in which the AR coefficients are allowed to vary as a measurable smooth function of another variable, such as a lagged value of the time series itself or an exogenous variable. The FCAR model includes TAR, and STAR models as special cases, and is analogous to the generalised additive model of Hastie & Tibshirani (1991). Chen & Tsay (1993) proposed a modeling procedure using ideas from

both parametric and nonparametric statistics. The approach assumes little prior information on model structure without suffering from the “curse of dimensionality”; see also Cai et al. (2000). Harvill & Ray (2005) presented multi-step ahead forecasting results using univariate and multivariate functional coefficient (V)FCAR models. These authors restricted their comparison to three forecasting methods: the naive plug-in predictor, the bootstrap predictor, and the multi-stage predictor. Both simulation and empirical results indicate that the bootstrap method appears to give slightly more accurate forecast results. A potentially useful area of future research is whether the forecasting power of VFCAR models can be enhanced by using exogenous variables.

# 6.4 Neural nets

The artificial neural network (ANN) can be useful for nonlinear processes that have an unknown functional relationship and as a result are difficult to fit (Darbellay & Slama, 2000). The main idea with ANNs is that inputs, or dependent variables, get filtered through one or more hidden layers each of which consist of hidden units, or nodes, before they reach the output variable. Next the intermediate output is related to the final output. Various other nonlinear models are specific versions of ANNs, where more structure is imposed; see JoF Special Issue 17:5/6 (1998) for some recent studies.

One major application area of ANNs is forecasting; see Zhang et al. (1998) and Hippert et al. (2001) for good surveys of the literature. Numerous studies outside the IJF have documented the successes of ANNs in forecasting financial data. However, in two editorials in this Journal, Chatfield (1993, 1995) questioned whether ANNs had been oversold as a miracle forecasting technique. This was followed by several papers documenting that na¨ıve models such as the random walk can outperform ANNs (see, e.g., Church & Curram, 1996; Callen et al., 1996; Conejo et al., 2005; Gorr et al., 1994; Tkacz, 2001). These observations are consistent with the results of an evaluating research by Adya and Collopy (1998), on the effectiveness of ANNbased forecasting in 48 studies done between 1988 and 1994.

Gorr (1994) and Hill et al. (1994) suggested that future research should investigate and better define the borderline between where ANNs and “traditional” techniques outperform one other. That theme is explored by several authors. Hill et al. (1994) noticed that ANNs are likely to work best for high frequency financial data and Balkin & Ord (2000) also stressed the importance of a long time series to ensure optimal results from training ANNs. Qi (2001) pointed out that ANNs are more likely to outperform other methods when the input data is kept as current as possible, using recursive modelling (see also Olson & Mossman, 2003).

A general problem with nonlinear models is the “curse of model complexity and model overparametrization”. If parsimony is considered to be really important, then it is interesting to compare the out-of-sample forecasting performance of linear versus nonlinear models, using a wide variety of different model selection criteria. This issue was considered in quite some

depth by Swanson & White (1997). Their results suggested that a single hidden layer ‘feedforward’ ANN model, which has been by far the most popular in time series econometrics, offers a useful and flexible alternative to fixed specification linear models, particularly at forecast horizons greater than one-step-ahead. However, in contrast to Swanson & White, Heravi et al. (2004) found that linear models produce more accurate forecasts of monthly seasonally unadjusted European industrial production series than ANN models. Ghiassa et al. (2005) presented a dynamic ANN and compared its forecasting performance against the traditional ANN and ARIMA models.

Times change, and it is fair to say that the risk of over-parametrization and overfitting is now recognized by many authors; see, e.g., Hippert et al. (2005) who use a large ANN (50 inputs, 15 hidden neurons, 24 outputs) to forecast daily electricity load profiles. Nevertheless, the question of whether or not an ANN is over-parametrised still remains unanswered. Some potential valuable ideas for building parsimoniously parametrised ANNs, using statistical inference, are suggested by Terasvirta et al. (2005). ¨

# 6.5 Deterministic versus stochastic dynamics

The possibility that nonlinearities in high-frequency financial data (e.g. hourly returns) are produced by a low-dimensional deterministic chaotic process has been the subject of a few studies published in the IJF. Cecen & Erkal (1996) showed that it is not possible to exploit deterministic nonlinear dependence in daily spot rates in order to improve short-term forecasting. Lisi & Medio (1997) reconstructed the state space for a number of monthly exchange rates and, using a local linear method, approximated the dynamics of the system on that space. One-step-ahead out-of-sample forecasting showed that their method outperforms a random walk model. A similar study was performed by Cao & Soofi (1999).

# 6.6 Miscellaneous

A host of other, often less well known, nonlinear models have been used for forecasting purposes. For instance, Ludlow & Enders (2000) adopted Fourier coefficients to approximate the various types of nonlinearities present in time series data. Herwartz (2001) extended the linear vector ECM to allow for asymmetries. Dahl & Hylleberg (2004) compared Hamilton’s (2001) flexible nonlinear regression model, ANNs, and two versions of the projection pursuit regression model. Time-varying AR models are included in a comparative study by Marcellino (2004). The nonparametric, nearest-neighbour method was applied by Fernandez-Rodr ´ ´ıguez et al. (1999).

# 7 Long memory

When the integration parameter $d$ in an ARIMA process is fractional and greater than zero, the process exhibits long memory in the sense that observations a long time-span apart have nonnegligible dependence. Stationary long-memory models $0 < d < 0 . 5$ ), also termed fractionally differenced ARMA (FARMA) or fractionally integrated ARMA (ARFIMA) models, have been considered by workers in many fields; see Granger & Joyeux (1980) for an introduction. One motivation for these studies is that many empirical time series have a sample autocorrelation function which declines at a slower rate than for an ARIMA model with finite orders and integer $d$ .

The forecasting potential of fitted FARMA/ARFIMA models, as opposed to forecast results obtained from other time series models, has been a topic of various $I J F$ papers and a special issue (2002, 18:2). Ray (1993) undertook such a comparison between seasonal FARMA/ARFIMA models and standard (non-fractional) seasonal ARIMA models. The results show that higher order AR models are capable of forecasting the longer term well when compared with ARFIMA models. Following Ray (1993), Smith & Yadav (1994) investigated the cost of assuming a unit difference when a series is only fractionally integrated with $d \neq 1$ . Over-differencing a series will produce a loss in forecasting performance one-step-ahead, with only a limited loss thereafter. By contrast, under-differencing a series is more costly with larger potential losses from fitting a mis-specified AR model at all forecast horizons. This issue is further explored by Andersson (2000) who showed that misspecification strongly affects the estimated memory of the ARFIMA model, using a rule which is similar to the test of Oller (1985). Man (2003) argued ¨ that a suitably adapted ARMA(2,2) model can produce short-term forecasts that are competitive with estimated ARFIMA models. Multi-step ahead forecasts of long memory models have been developed by Hurvich (2002), and compared by Bhansali & Koskoska (2002).

Many extensions of ARFIMA models and a comparison of their relative forecasting performance have been explored. For instance, Franses & Ooms (1997) proposed the so-called periodic ARFIMA $( 0 , d , 0 )$ model where $d$ can vary with the seasonality parameter. Ravishankar & Ray (2002) considered the estimation and forecasting of multivariate ARFIMA models. Baillie & Chung (2002) discussed the use of linear trend-stationary ARFIMA models, while the paper by Beran et al. (2002) extended this model to allow for nonlinear trends. Souza & Smith (2002) investigated the effect of different sampling rates, such as monthly versus quarterly data, on estimates of the long-memory parameter $d$ . In a similar vein, Souza & Smith (2004) looked at the effects of temporal aggregation on estimates and forecasts of ARFIMA processes. Within the context of statistical quality control, Ramjee et al. (2002) introduced a hyperbolically weighted moving average forecast-based control chart, designed specifically for nonstationary ARFIMA models.

# 8 ARCH/GARCH

A key feature of financial time series is that large (small) absolute returns tend to be followed by large (small) absolute returns, that is, there are periods which display high (low) volatility. This phenomenon is referred to as volatility clustering in econometrics and finance. The class of autoregressive conditional heteroscedastic (ARCH) models, introduced by Engle (1982), describe the dynamic changes in conditional variance as a deterministic (typically quadratic) function of past returns. Because the variance is known at time $t - 1$ , one-step-ahead forecasts are readily available. Next, multi-step-ahead forecasts can be computed recursively. A more parsimonious model than ARCH is the so-called generalized ARCH (GARCH) model (Bollerslev, 1986; Taylor, 1986) where additional dependencies are permitted on lags of the conditional variance. A GARCH model has an ARMA-type representation, so that many of the properties of both models are similar.

The GARCH family, and many of its extensions, are extensively surveyed in, e.g., Bollerslev et al. (1992), Bera & Higgins (1993), and Diebold & Lopez (1995). Not surprising many of the theoretical works appeared in the econometric literature. On the other hand, it is interesting to note that neither the IJF nor the JoF became an important forum for publications on the relative forecasting performance of GARCH-type models and the forecasting performance of various other volatility models in general. As can be seen below, only very few IJF/JoF-papers dealt with this topic.

Sabbatini & Linton (1998) showed that the simple (linear) GARCH(1,1) model provides a good parametrization for the daily returns on the Swiss market index. However, the quality of the out-of-sample forecasts suggests that this result should be taken with caution. Franses & Ghijsels (1999) stressed that this feature can be due to neglected additive outliers (AO). They noted that GARCH models for AO-corrected returns result in improved forecasts of stock market volatility. Brooks (1998) finds no clear-cut winner when comparing one-step-ahead forecasts from standard (symmetric) GARCH-type models, with those of various linear models, and ANNs. At the estimation level, Brooks et al. (2001) argued that standard econometric software packages can produce widely varying results. Clearly, this may have some impact on the forecasting accuracy of GARCH models. This observation is very much in the spirit of Newbold et al (1994), referenced in Subsection 3.2, for univariate ARMA models. Outside the IJF, multi-step-ahead prediction in ARMA models with GARCH in mean effects was considered by Karanasos (2001). His method can be employed in the derivation of multi-step predictions from more complicated models, including multivariate GARCH.

Using two daily exchange rates series, Galbraith & Kisinbay (2005) compared the forecast content functions both from the standard GARCH model and from a fractionally integrated GARCH (FIGARCH) model (Baillie et al., 1996). Forecasts of conditional variances appear to have information content of approximately 30 trading days. Another conclusion is that forecasts by autoregressive projection on past realized volatilities provide better results than fore-

casts based on GARCH, estimated by quasi-maximum likelihood, and FIGARCH models. This seems to confirm earlier results of Bollerslev and Wright (2001), for example. One often heard criticism of these models (FIGARCH and its generalizations) is that there is no economic rationale for financial forecast volatitility to have long memory. For a more fundamental point of criticism of the use of long-memory models we refer to Granger (2002).

Empirically, returns and conditional variance of next period’s returns are negatively correlated. That is, negative (positive) returns are generally associated with upward (downward) revisions of the conditional volatility. This phenomenon is often referred to as asymmetric volatility in the literature; see, e.g., Engle and $\mathrm { N g }$ (1993). It motivated researchers to develop various asymmetric GARCH-type models (including regime-switching GARCH); see, e.g., Hentschel (1995) and Pagan (1996) for overviews. Awartani & Corradi (2005) investigated the impact of asymmetries on the out-of-sample forecast ability of different GARCH models, at various horizons.

Besides GARCH many other models have been proposed for volatility-forecasting. Poon & Granger (2003), in a landmark paper, provide an excellent and carefully conducted survey of the research in this area in the last 20 years. They compared the volatility forecast findings in 93 published and working papers. Important insights are provided on issues like forecast evaluation, the effect of data frequency on volatility forecast accuracy, measurement of “actual volatility”, the confounding effect of extreme values, and many more. The survey found that option-implied volatility provides more accurate forecasts than time series models. Among the time series models (44 studies) there was no clear winner between the historical volatility models (including random walk, historical averages, ARFIMA, and various forms of exponential smoothing) and GARCH-type models (including ARCH and its various extensions), but both classes of models outperform the stochastic volatility model; see also Poon & Granger (2005) for an update on these findings.

The Poon & Granger survey paper contains many issues for further study. For example, asymmetric GARCH models came out relatively well in the forecast contest. However, it is unclear to what extent this is due to asymmetries in the conditional mean, asymmetries in the conditional variance, and/or asymmetries in high order conditional moments. Another issue for future research concerns the combination of forecasts. The results in two studies (Doidge & Wei, 1998; Kroner et al., 1995) find combining to be helpful, but another study (Vasilellis & Meade, 1996) does not. It will be also useful to examine the volatility-forecasting performance of multivariate GARCH-type models and multivariate nonlinear models, incorporating both temporal and contemporaneous dependencies; see also Engle (2002) for some further possible areas of new research.

# 9 Count data forecasting

Count data occur frequently in business and industry, especially in inventory data where they are often called “intermittent demand data”. Consequently, it is surprising that so little work has been done on forecasting count data. Some work has been done on ad hoc methods for forecasting count data, but few papers have appeared on forecasting count time series using stochastic models.

Most work on count forecasting is based on Croston (1972) who proposed using SES to independently forecast the non-zero values of a series and the time between non-zero values. Willemain et al. (1994) compared Croston’s method to SES and found that Croston’s method was more robust, although these results were based on MAPEs which are often undefined for count data. The conditions under which Croston’s method does better than SES were discussed in Johnston & Boylan (1996). Willemain et al. (2004) proposed a bootstrap procedure for intermittent demand data which was found to be more accurate than either SES or Croston’s method on the nine series evaluated.

Evaluating count forecasts raises difficulties due to the presence of zeros in the observed data. Syntetos & Boylan (2005) proposed using the Relative Mean Absolute Error (see Section 10), while Willemain et al. (2004) recommended using the probability integral transform method of Diebold et al. (1998).

Grunwald et al. (2000) surveyed many of the stochastic models for count time series, using simple first-order autoregression as a unifying framework for the various approaches. One possible model, explored by Brann ¨ as (1995), assumes the series follows a Poisson distribu- ¨ tion with a mean that depends on an unobserved and autocorrelated process. An alternative integer-valued MA model was used by Brann ¨ as et al. (2002) to forecast occupancy levels in ¨ Swedish hotels.

The forecast distribution can be obtained by simulation using any of these stochastic models, but how to summarize the distribution is not obvious. Freeland & McCabe (2004) proposed using the median of the forecast distribution, and gave a method for computing confidence intervals for the entire forecast distribution in the case of integer-valued autoregressive (INAR) models of order 1. McCabe & Martin (2005) further extended these ideas by presenting a Bayesian methodology for forecasting from the INAR class of models.

A great deal of research on count time series has also been done in the biostatistical area (see, for example, Diggle et al. 2002). However, this usually concentrates on analysis of historical data with adjustment for autocorrelated errors, rather than using the models for forecasting. Nevertheless, anyone working in count forecasting ought to be abreast of research developments in the biostatistical area also.

Table 2: Commonly used forecast accuracy measures. Here $I \{ u \} = 1$ if $u$ is true and 0 otherwise.   

<table><tr><td>MSE</td><td>Mean Squared Error</td><td>= mean(e2t)</td></tr><tr><td>RMSE</td><td>Root Mean Squared Error</td><td>= √MSE</td></tr><tr><td>MAE</td><td>Mean Absolute Error</td><td>= mean(|et|)</td></tr><tr><td>MdAE</td><td>Median Absolute Error</td><td>= median(|et|)</td></tr><tr><td>MAPE</td><td>Mean Absolute Percentage Error</td><td>= mean(|pt|)</td></tr><tr><td>MdAPE</td><td>Median Absolute Percentage Error</td><td>= median(|pt|)</td></tr><tr><td>sMAPE</td><td>Symmetric Mean Absolute Percentage Error</td><td>= mean(2|yt-FT|/(yt+FT))</td></tr><tr><td>sMdAPE</td><td>Symmetric Median Absolute Percentage Error</td><td>= median(2|yt-FT|/(yt+FT))</td></tr><tr><td>MRAE</td><td>Mean Relative Absolute Error</td><td>= mean(|rt|)</td></tr><tr><td>MdRAE</td><td>Median Relative Absolute Error</td><td>= median(|rt|)</td></tr><tr><td>GMRAE</td><td>Geometric Mean Relative Absolute Error</td><td>= gmean(|rt|)</td></tr><tr><td>RelMAE</td><td>Relative Mean Absolute Error</td><td>= MAE/MAEB.</td></tr><tr><td>RelRMSE</td><td>Relative Root Mean Squared Error</td><td>= RMSE/RMSEb.</td></tr><tr><td>LMR</td><td>Log Mean Squared Error Ratio</td><td>= log(RelMSE)</td></tr><tr><td>PB</td><td>Percentage Better</td><td>= 100 mean(I{|rt|&lt;1})</td></tr><tr><td>PB(MAE)</td><td>Percentage Better (MAE)</td><td>= 100 mean(I{MAE &lt; MAEB})</td></tr><tr><td>PB(MSE)</td><td>Percentage Better (MSE)</td><td>= 100 mean(I{MSE &lt; MSEb})</td></tr></table>

# 10 Forecast evaluation and accuracy measures

A bewildering array of accuracy measures have been used to evaluate the performance of forecasting methods. Some of them are listed in the early survey paper of Mahmoud (1984). We first define the most common measures.

Let $Y _ { t }$ denote the observation at time $t$ and $F _ { t }$ denote the forecast of $Y _ { t }$ . Then define the forecast error $e _ { t } = Y _ { t } - F _ { t }$ and the percentage error as $p _ { t } = 1 0 0 e _ { t } / Y _ { t }$ . An alternative way of scaling is to divide each error by the error obtained with another standard method of forecasting. Let $r _ { t } = e _ { t } / e _ { t } ^ { * }$ denote the relative error where $e _ { t } ^ { * }$ is the forecast error obtained from the base method. Usually, the base method is the “na¨ıve method” where $F _ { t }$ is equal to the last observation. We use the notation mean $\left( { { x } _ { t } } \right)$ to denote the sample mean of $\{ x _ { t } \}$ over the period of interest (or over the series of interest). Analogously, we use median $\left( { { x } _ { t } } \right)$ for the sample median and gmean $\left( { { x } _ { t } } \right)$ for the geometric mean. The mostly commonly used methods are defined in Table 2 on the following page where the subscript $b$ refers to measures obtained from the base method.

Note that Armstrong & Collopy (1992) referred to RelMAE as CumRAE, and that RelRMSE is also known as Theil’s $U$ statistic (Theil, 1966, Chapter 2) and is sometimes called $U 2$ . In addition to these, the average ranking (AR) of a method relative to all other methods considered, has sometimes been used.

The evolution of measures of forecast accuracy and evaluation can be seen through the measures used to evaluate methods in the major comparative studies that have been undertaken. In the original M-competition (Makridakis et al., 1982), measures used included the MAPE, MSE,

AR, MdAPE and PB. However, as Chatfield (1988) and Armstrong & Collopy (1992) pointed out, the MSE is not appropriate for comparison between series as it is scale dependent. Fildes & Makridakis (1988) contained further discussion on this point. The MAPE also has problems when the series has values close to (or equal to) zero, as noted by Makridakis et al. (1998, p.45). Excessively large (or infinite) MAPEs were avoided in the M-competitions by only including data that were positive. However, this is an artificial solution that is impossible to apply in all situations.

In 1992, one issue of IJF carried two articles and several commentaries on forecast evaluation measures. Armstrong & Collopy (1992) recommended the use of relative absolute errors, especially the GMRAE and MdRAE, despite the fact that relative errors have infinite variance and undefined mean. They recommended “winsorizing” to trim extreme values which will partially overcome these problems, but which adds some complexity to the calculation and a level of arbitrariness as the amount of trimming must be specified. Fildes (1992) also preferred the GMRAE although he expressed it in an equivalent form as the square root of the geometric mean of squared relative errors. This equivalence does not seem to have been noticed by any of the discussants in the commentaries of Ahlburg et al. (1992).

The study of Fildes et al. (1998), which looked at forecasting telecommunications data, used MAPE, MdAPE, PB, AR, GMRAE and MdRAE, taking into account some of the criticism of the methods used for the M-competition.

The M3-competition (Makridakis & Hibon, 2000) used three different measures of accuracy: MdRAE, sMAPE and sMdAPE. The “symmetric” measures were proposed by Makridakis (1993) in response to the observation that the MAPE and MdAPE have the disadvantage that they put a heavier penalty on positive errors than on negative errors. However, these measures are not as “symmetric” as their name suggests. For the same value of $Y _ { t } ,$ the value of $2 | Y _ { t } - F _ { t } | / ( Y _ { t } + F _ { t } )$ has a heavier penalty when forecasts are high compared to when forecasts are low. See Goodwin & Lawton (1999) and Koehler (2001) for further discussion on this point.

Notably, none of the major comparative studies have used relative measures (as distinct from measures using relative errors) such as RelMAE or LMR. The latter was proposed by Thompson (1990) who argued for its use based on its good statistical properties. It was applied to the M-competition data in Thompson (1991).

Apart from Thompson (1990), there has been very little theoretical work on the statistical properties of these measures. One exception is Wun & Pearn (1991) who looked at the statistical properties of MAE.

A novel alternative measure of accuracy is “time distance” which was considered by Granger & Jeon (2003a,b). In this measure, the leading and lagging properties of a forecast are also captured. Again, this measure has not been used in any major comparative study.

A parallel line of research has looked at statistical tests to compare forecasting methods. An

early contribution was Flores (1989). The best known approach to testing differences between the accuracy of forecast methods is the Diebold-Mariano (1995) test. A size-corrected modification of this test was proposed by Harvey et al. (1997). McCracken (2004) looked at the effect of parameter estimation on such tests and provided a new method for adjusting for parameter estimation error.

Another problem in forecast evaluation, and more serious than parameter estimation error, is “data sharing”—the use of the same data for many different forecasting methods. Sullivan et al. (2003) proposed a bootstrap procedure designed to overcome the resulting distortion of statistical inference.

An independent line of research has looked at the theoretical forecasting properties of time series models. An important contribution along these lines was Clements & Hendry (1993) who showed that the theoretical MSE of a forecasting model was not invariant to scale-preserving linear transformations such as differencing of the data. Instead, they proposed the “generalized forecast error second moment” (GFESM) criterion which does not have this undesirable property. However, such measures are difficult to apply empirically and the idea does not appear to be widely used.

# 11 Combining

Combining, mixing, or pooling quantitative3 forecasts obtained from very different time series methods and different sources of information has been studied for the past three decades. Important early contributions in this area were made by Bates & Granger (1969), Newbold & Granger (1974) and Winkler & Makridakis (1983). Compelling evidence on the relative efficiency of combined forecasts, usually defined in terms of forecast error variances, was summarized by Clemen (1989) in a comprehensive bibliography review.

Numerous methods for selecting the combining weights have been proposed. The simple average is the most-widely used combining method (see Clemen’s review, and Bunn, 1985), but the method does not utilize past information regarding the precision of the forecasts or the dependence among the forecasts. Another simple method is a linear mixture of the individual forecasts with combining weights determined by OLS (assuming unbiasedness) from the matrix of past forecasts and the vector of past observations (Granger & Ramanathan, 1984). However, the OLS estimates of the weights are inefficient due to the possible presence of serial correlation in the combined forecast errors. Aksu & Gunter (1992) and Gunter (1992) investigated this problem in some detail. They recommended the use of OLS combination forecasts with the weights restricted to sum to unity.

Rather than using fixed weights, Deutsch et al. (1994) allowed them to change through time using regime-switching models and STAR models. Another time-dependent weighting scheme was proposed by Fiordaliso (1998), who used a fuzzy system to combine a set of individual

forecasts in a nonlinear way. Diebold & Pauly (1990) used Bayesian shrinkage techniques to allow the incorporation of prior information into the estimation of combining weights. Combining forecasts from very similar models, with weights sequentially updated, was considered by Zou & Yang (2004).

Combining weights determined from time-invariant methods can lead to relatively poor forecasts if nonstationarity among component forecasts occurs. Miller et al. (1992) examined the effect of ‘location-shift’ nonstationarity on a range of forecast combination methods. Tentatively they concluded that the simple average beats more complex combination devices; see also Hendry & Clements (2002) for more recent results. The related topic of combining forecasts from linear and some nonlinear time series models, with OLS weights as well as weights determined by a time-varying method, was addressed by Terui & van Dijk (2002).

The shape of the combined forecast error distribution and the corresponding stochastic behaviour was studied by de Menezes & Bunn (1998) and Taylor & Bunn (1999). For non-normal forecast error distributions skewness emerges as a relevant criterion for specifying the method of combination. Some insights into why competing forecasts may be fruitfully combined to produce a forecast superior to individual forecasts were provided by Fang (2003), using forecast encompassing tests. Hibon & Evgeniou (2005) proposed a criterion to select among forecasts and their combinations.

# 12 Prediction intervals and densities

The use of prediction intervals, and more recently prediction densities, has become much more common over the past twenty five years as practitioners have come to understand the limitations of point forecasts. An important and thorough review of interval forecasts is given by Chatfield (1993), summarizing the literature to that time.

Unfortunately, there is still some confusion on terminology with many authors using “confidence interval” instead of “prediction interval”. A confidence interval is for a model parameter whereas a prediction interval is for a random variable. Almost always, forecasters will want prediction intervals—intervals which contain the true values of future observations with specified probability.

Most prediction intervals are based on an underlying stochastic model. Consequently, there has been a large amount of work on formulating appropriate stochastic models underlying some common forecasting procedures (see, e.g., Section 2 on Exponential Smoothing).

The link between prediction interval formulae and the model from which they are derived has not always been correctly observed. For example, the prediction interval appropriate for a random walk model was applied by Makridakis & Hibon (1987) and Lefranc¸ois (1989) to forecasts obtained from many other methods. This problem was noted by Koehler (1990) and

Chatfield & Koehler (1991).

With most model-based prediction intervals for time series, the uncertainty associated with model selection and parameter estimation is not accounted for. Consequently, the intervals are too narrow. There has been considerable research on how to make model-based prediction intervals have more realistic coverage. A series of papers on using the bootstrap to compute prediction intervals for an AR model has appeared beginning with Masarotto (1990), and including McCullough (1994, 1996), Grigoletto (1998), Clements & Taylor (2001) and Kim (2004b). Similar procedures for other models have also been considered including ARIMA models (Pascual et al., 2001, 2004, 2005), Wall & Stoffer (2002), VAR (Kim, 1999, 2004a), ARCH (Reeves, 2005) and regression (Lam & Veall, 2002). It seems likely that such bootstrap methods will become more widely used as computing speeds increase due to their better coverage properties.

When the forecast error distribution is non-normal, finding the entire forecast density is useful as a single interval may no longer provide an adequate summary of the expected future. A review of density forecasting is provided by Tay & Wallis (2000), along with several other articles in the same special issue of the JoF. Summarizing, a density forecast has been the subject of some interesting proposals including “fan charts” (Wallis, 1999) and “highest density regions” (Hyndman, 1995). The use of these graphical summaries has grown rapidly in recent years as density forecasts have become relatively widely used.

As prediction intervals and forecast densities have become more commonly used, attention has turned to their evaluation and testing. Diebold et al. (1998) introduced the remarkably simple “probability integral transform” method which can be used to evaluate a univariate density. This approach has become widely used in a very short period of time and has been a key research advance in this area. The idea is extended to multivariate forecast densities in Diebold et al. (1999).

Other approaches to interval and density evaluation are given by Wallis (2003) who proposed chi-squared tests for both intervals and densities, and Clements & Smith (2002) who discussed some simple but powerful tests when evaluating multivariate forecast densities.

# 13 A look to the future

In the preceding sections we have looked back at the time series forecasting history of the IJF, in the hope that the past may shed light on the present. But a silver anniversary is also a good time to look ahead. In doing so, it is interesting to reflect on the proposals for research in time series forecasting identified in a set of related papers by Ord, Cogger and Chatfield published in this Journal more than 15 years ago.4

Chatfield (1988) stressed the need for future research on developing multivariate methods with an emphasis on making them more of a practical proposition. Ord (1988) also noted that not much work had been done on multiple time series models, including multivariate exponential smoothing. Eighteen years later, multivariate time series forecasting is still not widely applied despite considerable theoretical advances in this area. We suspect that two reasons for this are: a lack of empirical research on robust forecasting algorithms for multivariate models; and a lack of software that is easy to use. Some of the methods that have been suggested (e.g. VARIMA models) are difficult to estimate because of the large numbers of parameters involved. Others, such as multivariate exponential smoothing, have not received sufficient theoretical attention to be ready for routine application. One approach to multivariate time series forecasting is to use dynamic factor models. These have recently shown promise in theory (Stock & Watson, 2002; Forni et al., 2005) and application (e.g. Pena & Poncela, 2004), and we suspect they will ˜ become much more widely used in the years ahead.

Ord (1988) also indicated the need for deeper research in forecasting methods based on nonlinear models. While many aspects of nonlinear models have been investigated in the IJF, they merit continued research. For instance, there is still no clear consensus that forecasts from nonlinear models substantively outperform those from linear models (see, e.g., Stock & Watson, 1999).

Other topics suggested by Ord (1988) include the need to develop model selection procedures that make effective use of both data and prior knowledge, and the need to specify objectives for forecasts and develop forecasting systems that address those objectives. These areas are still in need of attention, and we believe that future research will contribute tools to solve these problems.

Given the frequent misuse of methods based on linear models with Gaussian i.i.d. distributed errors, Cogger (1988) argued that new developments in the area of ‘robust’ statistical methods should receive more attention within the time series forecasting community. A robust procedure is expected to work well when there are outliers or location shifts in the data that are hard to detect. Robust statistics can be based on both parametric and nonparametric methods. An example of the latter is the Koenker-Bassett (1978) concept of regression quantiles investigated by Cogger. In forecasting, these can be applied as univariate and multivariate conditional quantiles. One important area of application is in estimating risk management tools such as Value-at-Risk. Recently, Engle & Manganelli (2004) made a start in this direction, proposing a conditional value at risk model. We expect to see much future research in this area.

A related topic in which there has been a great deal of recent research activity is density forecasting (see Section 12), where the focus is on the probability density of future observations rather than the mean or variance. For instance, Yao & Tong (1995) proposed the concept of conditional percentile prediction interval. Its width is no longer a constant, as in the case of linear models, but may vary with respect to the position in the state space from which forecasts

are being made; see also De Gooijer & Gannoun (2000) and Polonik & Yao (2000).

Clearly, the area of improved forecast intervals requires further research. This is in agreement with Armstrong (2001) who listed 23 principles in great need of research including item 14:13: “For prediction intervals, incorporate the uncertainty associated with the prediction of the explanatory variables.”

In recent years, non-Gaussian time series have begun to receive considerable attention and forecasting methods are slowly being developed. One particular area of non-Gaussian time series that has important applications is time series taking positive values only. Two important areas in finance in which these arise are realized volatility and the duration between transactions. Work on such series is still in its infancy. Important contributions to date have been Engle and Russell’s (1998) “Autoregressive Conditional Duration” model and Andersen et al. (2003). Because of the importance of these applications, we expect much more work in this area in the next few years.

While forecasting non-Gaussian time series with a continuous sample space has begun to receive research attention, especially in the context of finance, forecasting time series with a discrete sample space (such as time series of counts) is still its infancy (see Section 9). Such data are very prevalent in business and industry, and there are many unresolved theoretical and practical problems associated with count forecasting, therefore we also expect much productive research in this area in the near future.

In the past fifteen years, some IJF authors have tried to identify new important research topics. Both De Gooijer (1990) and Clements (2003) in two editorials, and Ord as a part of a discussion paper by Dawes et al. (1994), suggested more work on combining forecasts. Although the topic has received a fair amount of attention (see Section 11) there are still several open questions. For instance, what is the “best” combining method for linear and nonlinear models, and what prediction interval can be put around the combined forecast? A good starting point for further research in this area is Terasvirta (2006); see also Armstrong (2001, items 12.5–12.7). Recently, ¨ Stock & Watson (2004) discussed the ‘forecast combination puzzle’, namely the repeated empirical finding that simple combinations such as averages outperform more sophisticated combinations which theory suggests should do better. This is an important practical issue that will no doubt receive further research attention in the future.

Changes in data collection and storage will also lead to new research directions. For example, in the past, panel data (called longitudinal data in biostatistics) have usually been available where the time series dimension $t$ has been small whilst the cross-section dimension $n$ is large. However, nowadays in many applied areas such as marketing, large datasets can be easily collected with $n$ and $t$ both large. Extracting features from megapanels of panel data is the subject of “functional data analysis”; see, e.g., Ramsay & Silverman (1997, 2005). Yet, the problem of making multi-step ahead forecasts based on functional data is still open for both theoretical and applied research. Because of the increasing prevalence of this kind of data, we expect this

to be a fruitful future research area.

Large data sets also lend themselves to highly computationally intensive methods. While neural networks have been used in forecasting for more than a decade now, there are many outstanding issues associated with their use and implementation, including when they are likely to outperform other methods. Other methods involving heavy computation (e.g. bagging and boosting) are even less understood in the forecasting context. With the availability of very large data sets and high powered computers, we expect this to be an important area of research in the coming years.

Looking back, the field of time series forecasting is vastly different from what it was 25 years ago when the IIF was formed. It has grown up with the advent of greater computing power, better statistical models, and more mature approaches to forecast calculation and evaluation. But there is much to be done, with many problems still unsolved and many new problems arising.

When the IIF celebrates its Golden Anniversary in 25 years time, we hope there will be another review paper summarizing the main developments on time series forecasting. Besides the topics mentioned above, we also predict that such a review will shed more light on Armstrong’s 23 open research problems for forecasters. In this sense it is interesting to mention David Hilbert who, in his 1900 address to the Paris International Congress of Mathematicians, listed 23 challenging problems for mathematicians of the twentieth century to work on. Many of Hilbert’s problems have resulted in an explosion of research stemming from the confluence of several areas of mathematics and physics. We hope that the ideas, problems, and observations presented in this review provide a similar research impetus for those working in different areas of time series analysis and forecasting.

# Acknowledgments

We are grateful to Robert Fildes and Andrey Kostenko for valuable comments. We also thank two anonymous referees and the editor for many helpful comments and suggestions that resulted in a substantial improvement of this manuscript.

# References

# Section 2. Exponential smoothing

Abraham, B., & Ledolter, J. (1983). Statistical methods for forecasting, New York: John Wiley & Sons.   
Abraham, B., & Ledolter, J. (1983). Forecast functions implied by autoregressive integrated moving average models and other related forecast procedures. International Statistical Review, 54, 51–66.   
Archibald, B.C. (1990). Parameter space of the Holt-Winters model. International Journal of Forecasting, 6, 199–209.   
Archibald, B.C., & Koehler, A.B. (2003). Normalization of seasonal factors in Winters methods. International Journal of Forecasting, 19, 143–148.   
Assimakopoulos, V., & Nikolopoulos, K. (2000). The theta model: A decomposition approach to forecasting. International Journal of Forecasting, 16, 521–530.   
Bartolomei, S.M., & Sweet, A.L. (1989). A note on a comparison of exponential smoothing methods for forecasting seasonal series. International Journal of Forecasting, 5, 111–116.   
Brown, R.G. (1959). Statistical forecasting for inventory control, New York: McGraw-Hill.   
Brown, R.G. (1963). Smoothing, forecasting and prediction of discrete time series, Englewood Cliffs, NJ: Prentice-Hall.   
Carreno, J., & Madinaveitia, J. (1990). A modification of time series forecasting methods for handling announced price increases. International Journal of Forecasting, 6, 479–484.   
Chatfield, C., Koehler, A.B., Ord, J.K., & Snyder, R.D. (2001). A new look at models for exponential smoothing. The Statistician, 50, 147–159.   
Chatfield, C., & Yar, M. (1991). Prediction intervals for multiplicative Holt-Winters. International Journal of Forecasting, 7, 31–37.   
Collopy, F., & Armstrong, J.S. (1992). Rule-based forecasting: development and validation of an expert systems approach to combining time series extrapolations. Management Science, 38, 1394–1414.   
Gardner, Jr., E.S. (1985). Exponential smoothing: the state of the art. Journal of Forecasting, 4, 1–38 (with commentaries).   
Gardner, Jr., E.S. (1993). Forecasting the failure of component parts in computer systems: A case study. International Journal of Forecasting, 9, 245–253.   
Gardner, Jr., E.S., & McKenzie, E. (1988). Model identification in exponential smoothing. Journal of the Operational Research Society, 39, 863–867.   
Grubb, H., & Masa, A. (2001). Long lead-time forecasting of UK air passengers by Holt-Winters methods with damped trend. International Journal of Forecasting, 17, 71–82.   
Holt, C.C. (1957). Forecasting seasonals and trends by exponentially weighted averages. O.N.R. Memorandum 52/1957, Carnegie Institute of Technology. Reprinted with discussion in 2004, International Journal of Forecasting, 20, 5–13.   
Hyndman, R.J. (2001). Its time to move from what to why. International Journal of Forecasting, 17, 567–570.   
Hyndman, R.J., & Billah, B. (2003). Unmasking the Theta method. International Journal of Forecasting, 19, 287–290.   
Hyndman, R.J., Koehler, A.B., Ord, J.K., & Snyder, R.D. (2005). Prediction intervals for exponential smoothing state space models. Journal of Forecasting, 24, 17–37.   
Hyndman, R.J., Koehler, A.B., Snyder, R.D., & Grose, S. (2002). A state space framework for automatic forecasting using exponential smoothing methods. International Journal of Forecasting, 18, 439–454.   
Johnston, F.R., & Harrison, P.J. (1986). The variance of lead-time demand. Journal of Operational Research Society, 37, 303–308.

Koehler, A.B., Snyder, R.D., & Ord, J.K. (2001). Forecasting models and prediction intervals for the multiplicative Holt-Winters method. International Journal of Forecasting, 17, 269–286.   
Lawton, R. (1998). How should additive Holt-Winters estimates be corrected? International Journal of Forecasting, 14, 393–403.   
Ledolter, J., & Abraham, B. (1984). Some comments on the initialization of exponential smoothing. Journal of Forecasting, 3, 79–84.   
Makridakis, S., & Hibon, M. (1991). Exponential smoothing: The effect of initial values and loss function on post-sample forecasting accuracy. International Journal of Forecasting, 7, 317–330.   
McClain, J.G. (1988). Dominant tracking signals. International Journal of Forecasting, 4, 563–572.   
McKenzie, E. (1984). General exponential smoothing and the equivalent ARMA process. Journal of Forecasting, 3, 333–344.   
McKenzie, E. (1986). Error analysis for Winters additive seasonal forecasting system. International Journal of Forecasting, 2, 373–382.   
Miller, T., & Liberatore, M. (1993). Seasonal exponential smoothing with damped trends. An application for production planning. International Journal of Forecasting, 9, 509–515.   
Muth, J.F. (1960). Optimal properties of exponentially weighted forecasts. Journal of the American Statistical Association, 55, 299–306.   
Newbold, P., & Bos, T. (1989). On exponential smoothing and the assumption of deterministic trend plus white noise data-generating models. International Journal of Forecasting, 5, 523–527.   
Ord, J.K., Koehler, A.B., & Snyder, R.D. (1997). Estimation and prediction for a class of dynamic nonlinear statistical models. Journal of American Statistical Association, 92, 1621–1629.   
Pan, X. (2005). An alternative approach to multivariate EWMA control chart. Journal of Applied Statistics, 32, 695–705.   
Pegels, C.C. (1969). Exponential smoothing: some new variations. Management Science, 12, 311–315.   
Pfeffermann, D., & Allon, J. (1989). Multivariate exponential smoothing: methods and practice. International Journal of Forecasting, 5, 83–98.   
Roberts, S.A. (1982). A general class of Holt-Winters type forecasting models. Management Science, 28, 808–820.   
Rosas, A.L., & Guerrero, V.M. (1994). Restricted forecasts using exponential smoothing techniques. International Journal of Forecasting, 10, 515–527.   
Satchell, S., & Timmermann, A. (1995). On the optimality of adaptive expectations: Muth revisited. International Journal of Forecasting, 11, 407–416.   
Snyder, R.D. (1985). Recursive estimation of dynamic linear statistical models. Journal of the Royal Statistical Society (B), 47, 272–276.   
Sweet, A.L. (1985). Computing the variance of the forecast error for the Holt-Winters seasonal models. Journal of Forecasting, 4, 235–243.   
Sweet, A.L., & Wilson, J.R. (1988). Pitfalls in simulation-based evaluation of forecast monitoring schemes. International Journal of Forecasting, 4, 573–579.   
Tashman, L., & Kruk, J.M. (1996). The use of protocols to select exponential smoothing procedures: A reconsideration of forecasting competitions. International Journal of Forecasting, 12, 235–253.   
Taylor, J.W. (2003). Exponential smoothing with a damped multiplicative trend. International Journal of Forecasting, 19, 273–289.   
Williams, D.W., & Miller, D. (1999). Level-adjusted exponential smoothing for modeling planned discontinuities. International Journal of Forecasting, 15, 273–289.   
Winters, P.R. (1960). Forecasting sales by exponentially weighted moving averages. Management Science,

6, 324–342.   
Yar, M., & Chatfield, C. (1990). Prediction intervals for the Holt-Winters forecasting procedure. International Journal of Forecasting, 6, 127–137.

# Section 3. ARIMA

de Alba, E. (1993). Constrained forecasting in autoregressive time series models: A Bayesian analysis. International Journal of Forecasting, 9, 95–108.   
Arino, M.A., & Franses, P.H. (2000). Forecasting the levels of vector autoregressive log-transformed time ˜ series. International Journal of Forecasting, 16, 111–116.   
Artis, M.J., & Zhang, W. (1990). BVAR forecasts for the G-7. International Journal of Forecasting, 6, 349–362.   
Ashley, R. (1988). On the relative worth of recent macroeconomic forecasts. International Journal of Forecasting, 4, 363–376.   
Bhansali, R.J. (1996). Asymptotically efficient autoregressive model selection for multistep prediction. Annals of the Institute of Statistical Mathematics, 48, 577-602.   
Bhansali, R.J. (1999). Autoregressive model selection for multistep prediction. Journal of Statistical Planning and Inference, 78, 295–305.   
Bianchi, L., Jarrett, J., & Hanumara, T.C. (1998), Improving forecasting for telemarketing centers by ARIMA modeling with interventions. International Journal of Forecasting, 14, 497–504.   
Bidarkota, P.V. (1998). The comparative forecast performance of univariate and multivariate models: An application to real interest rate forecasting. International Journal of Forecasting, 14, 457–468.   
Box, G.E.P., & G.M. Jenkins (1970), Time Series Analysis: Forecasting and Control, San Francisco: Holden Day (revised ed. 1976).   
Box, G.E.P., Jenkins, G.M., & Reinsel, G.C. (1994). Time Series Analysis: Forecasting and Control, 3rd ed., Englewood Cliffs, NJ: Prentice Hall.   
Chatfield, C. (1988). What is the ‘best method of forecasting? Journal of Applied Statistics, 15, 19–38.   
Chevillon, G., & Hendry, D.F. (2005). Non-parametric direct multi-step estimation for forecasting economic processes. International Journal of Forecasting, 21, 201–218.   
Cholette, P.A. (1982). Prior information and ARIMA forecasting. Journal of Forecasting, 1, 375–383.   
Cholette, P.A., & Lamy, R. (1986). Multivariate ARIMA forecasting of irregular time series. International Journal of Forecasting, 2, 201–216.   
Cummins, J.D., & Griepentrog. G.L. (1985). Forecasting automobile insurance paid claims using econometric and ARIMA models. International Journal of Forecasting, 1, 203–215.   
De Gooijer, J.G., & Klein, A. (1991). On the cumulated multi-step-ahead predictions of vector autoregressive moving average processes. International Journal of Forecasting, 7, 501–513.   
Dhrymes, P.J., & Peristiani, S.C. (1988). A comparison of the forecasting performance of WEFA and ARIMA time series methods. International Journal of Forecasting, 4, 81–101.   
Dhrymes, P.J., & Thomakos, D. (1998). Structural VAR, MARMA and open economy models. International Journal of Forecasting, 14, 187–198.   
Di Caprio, U., Genesio, R., Pozzi, S. & Vicino, A. (1983). Short term load forecasting in electric power systems: A comparison of ARMA models and extended Wiener filtering. Journal of Forecasting, 2, 59– 76.   
Downs, G.W., & Rocke, D.M. (1983). Municipal budget forecasting with multivariate ARMA models. Journal of Forecasting, 2, 377–387.   
Edlund, P-O. (1984). Identification of the multi-input Box-Jenkins transfer function model. Journal of Forecasting, 3, 297–308.

Edlund, P-O., & Karlsson, S. (1993). Forecasting the Swedish unemployment rate. VAR vs. transfer function modelling. International Journal of Forecasting, 9, 61–76.   
Engle, R.F., & Granger, C.W.J. (1987). Co-integration and error correction: Representation, estimation, and testing. Econometrica, 55, 1057–1072.   
Funke, M. (1990). Assessing the forecasting accuracy of monthly vector autoregressive models: The case of five OECD countries. International Journal of Forecasting, 6, 363–378.   
Geriner, P.T., & Ord, J.K. (1991). Automatic forecasting using explanatory variables: A comparative study. International Journal of Forecasting, 7, 127–140.   
Geurts, M.D., & Kelly, J.P. (1986). Forecasting retail sales using alternative models. International Journal of Forecasting, 2, 261–272.   
Geurts, M.D., & Kelly, J.P. (1990). Comments on: “In defense of ARIMA modeling by D.J. Pack. International Journal of Forecasting, 6, 497–499.   
Grambsch, P., & Stahel, W.A. (1990). Forecasting demand for special telephone services: a case study. International Journal of Forecasting, 6, 53–64.   
Guerrero, V.M. (1991). ARIMA forecasts with restrictions derived from a structural change. International Journal of Forecasting, 7, 339–347.   
Gupta, S. (1987). Testing causality: Some caveats and a suggestion. International Journal of Forecasting, 3, 195–209.   
Hafer, R.W., & Sheehan, R.G. (1989). The sensitivity of VAR forecasts to alternative lag structures. International Journal of Forecasting, 5, 399–408.   
Hansson, J., Jansson, P., & Lof, M. (2005). Business survey data: Do they help in forecasting GDP growth? ¨ International Journal of Forecasting, 21, 377–389.   
Harris, J.L., & Liu, L-M. (1993). Dynamic structural analysis and forecasting of residential electricity consumption. International Journal of Forecasting, 9, 437–455.   
Hein, S., & Spudeck, R.E. (1988). Forecasting the daily federal funds rate. International Journal of Forecasting, 4, 581–591.   
Heuts, R.M.J., & Bronckers, J.H.J.M. (1988). Forecasting the Dutch heavy truck market: A multivariate approach. International Journal of Forecasting, 4, 57–59.   
Hill, G., & Fildes, R. (1984). The accuracy of extrapolation methods: An automatic Box-Jenkins package SIFT. Journal of Forecasting, 3, 319–323.   
Hillmer, S.C., Larcker, D.F., & Schroeder, D.A. (1983). Forecasting accounting data: A multiple timeseries analysis. Journal of Forecasting, 2, 389–404.   
Holden, K., & Broomhead, A. (1990). An examination of vector autoregressive forecasts for the U.K. economy. International Journal of Forecasting, 6, 11–23.   
Hotta, L.K. (1993). The effect of additive outliers on the estimates from aggregated and disaggregated ARIMA models. International Journal of Forecasting, 9, 85–93.   
Hotta, L.K., & Cardoso Neto, J. (1993). The effect of aggregation on prediction in ARIMA models. Journal of Time Series Analysis, 14, 261–269.   
Kang, I-B. (2003). Multi-period forecasting using different models for different horizons: an application to U.S. economic time series data. International Journal of Forecasting, 19, 387–400.   
Karanasos, M. (2001). Prediction in ARMA models with GARCH in mean effects. Journal of Time Series Analysis, 22, 555–576.   
Kim, J.H. (2003). Forecasting autoregressive time series with bias-corrected parameter estimators. International Journal of Forecasting, 19, 493–502.   
Kling, J.L., & Bessler, D.A. (1985). A comparison of multivariate forecasting procedures for economic time series. International Journal of Forecasting, 1, 5–24.

Kolmogorov, A.N. (1941). Stationary sequences in Hilbert space (in Russian). Bull. Math. Univ. Moscow, 2, No. 6, 1941.   
Koreisha, S.G. (1983). Causal implications: The linkage between time series and econometric modelling. Journal of Forecasting, 2, 151–168.   
Krishnamurthi, L., Narayan, J. & Raj, S.P. (1989). Intervention analysis using control series and exogenous variable in a transfer function model: A case study. International Journal of Forecasting, 5, 21–27.   
Kunst, R., & Neusser, K. (1986). A forecasting comparison of some VAR techniques. International Journal of Forecasting, 2, 447–456.   
Landsman, W.R., & Damodaran, A. (1989). A comparison of quarterly earnings per share forecast using James-Stein and unconditional least squares parameter estimators. International Journal of Forecasting, 5, 491–500.   
Layton, A., Defris, L.V., & Zehnwirth, B. (1986). An international comparison of economic leading indicators of telecommunication traffic. International Journal of Forecasting, 2, 413–425.   
Ledolter, J. (1989). The effect of additive outliers on the forecasts from ARIMA models. International Journal of Forecasting, 5, 231–240.   
Leone, R.P. (1987). Forecasting the effect of an environmental change on market performance: An intervention time-series. International Journal of Forecasting, 3, 463–478.   
LeSage, J.P. (1989). Incorporating regional wage relations in local forecasting models with a Bayesian prior. International Journal of Forecasting, 5, 37–47.   
LeSage, J.P., & Magura, M. (1991). Using interindustry input-output relations as a Bayesian prior in employment forecasting models. International Journal of Forecasting, 7, 231–238.   
Libert, G. (1984). The M-competition with a fully automatic Box-Jenkins procedure. Journal of Forecasting, 3, 325–328.   
Lin, W.T. (1989). Modeling and forecasting hospital patient movements: Univariate and multiple time series approaches. International Journal of Forecasting, 5, 195–208.   
Litterman, R.B. (1986). Forecasting with Bayesian vector autoregressions – Five years of experience. Journal of Business & Economic Statistics, 4, 25–38.   
Liu, L-M., & Lin, M-W. (1991). Forecasting residential consumption of natural gas using monthly and quarterly time series. International Journal of Forecasting, 7, 3–16.   
Liu, T-R., Gerlow, M.E., & Irwin, S.H. (1994). The performance of alternative VAR models in forecasting exchange rates. International Journal of Forecasting, 10, 419–433.   
Lutkepohl, H. (1986). Comparison of predictors for temporally and contemporaneously aggregated time ¨ series. International Journal of Forecasting, 2, 461–475.   
Makridakis, S., Andersen, A., Carbone, R., Fildes, R., Hibon, M., Lewandowski, R., Newton, J., Parzen, E., & Winkler, R. (1982). The accuracy of extrapolation (time series) methods: results of a forecasting competition. Journal of Forecasting, 1, 111–153.   
Meade, N. (2000). A note on the robust trend and ARARMA methodologies used in the M3 competition. International Journal of Forecasting, 16, 517–519.   
Meade, N. (2002). A comparison of the accuracy of short term foreign exchange forecasting methods. International Journal of Forecasting, 18, 67–83.   
Meade, N., & Smith, I. (1985). ARARMA vs ARIMA – a study of the benefits of a new approach to forecasting. Omega, 13, 519–534.   
Melard, G., & Pasteels, J-M. (2000). Automatic ARIMA modeling including interventions, using time ´ series expert software. International Journal of Forecasting, 16, 497–508.   
del Moral, M.J., & Valderrama, M.J. (1997). A principal component approach to dynamic regression models. International Journal of Forecasting, 13, 237–244.

Newbold, P. (1983). ARIMA model building and the time series analysis approach to forecasting. Journal of Forecasting, 2, 23–35.   
Newbold, P., Agiakloglou, C., & Miller, J. (1994). Adventures with ARIMA software. International Journal of Forecasting, 10, 573–581.   
Oller, L-E. (1985). Macroeconomic forecasting with a vector ARIMA model. ¨ International Journal of Forecasting, 1, 143–150.   
Pack, D.J. (1990). Rejoinder to: Comments on: “In defense of ARIMA modeling by M.D. Geurts and J.P. Kelly. International Journal of Forecasting, 6, 501–502.   
Parzen, E. (1982). ARARMA models for time series analysis and forecasting. Journal of Forecasting, 1, 67– 82.   
Pena, D., & S ˜ anchez, I. (2005). Multifold predictive validation in ARMAX time series models. ´ Journal of the American Statistical Association, 100, 135–146.   
Pflaumer, P. (1992). Forecasting US population totals with the Box-Jenkins approach. International Journal of Forecasting, 8, 329–338.   
Poskitt, D.S. (2003). On the specification of cointegrated autoregressive moving-average forecasting systems. International Journal of Forecasting, 19, 503–519.   
Poulos, L., Kvanli, A., & Pavur, R. (1987). A comparison of the accuracy of the Box-Jenkins method with that of automated forecasting methods. International Journal of Forecasting, 3, 261–267.   
du Preez, J., & Witt, S.F. (2003). Univariate versus multivariate time series forecasting: An application to international tourism demand. International Journal of Forecasting, 19, 435–451.   
Quenouille, M.H. (1957). The Analysis of Multiple Time-Series, London: Griffin. (2nd ed. 1968).   
Ribeiro Ramos, F.F. (2003). Forecasts of market shares from VAR and BVAR models: A comparison of their accuracy. International Journal of Forecasting, 119, 95–110.   
Reimers, H-E. (1997). Forecasting of seasonal cointegrated processes. International Journal of Forecasting, 13, 369–380.   
Riise, T., & Tjøstheim, D. (1984). Theory and practice of multivariate ARMA forecasting. Journal of Forecasting, 3, 309–317.   
Shoesmith, G.L. (1992). Non-cointegration and causality: Implications for VAR modeling. International Journal of Forecasting, 8, 187–199.   
Shoesmith, G.L. (1995). Multiple cointegrating vectors, error correction, and forecasting with Littermans model. International Journal of Forecasting, 11, 557–567.   
Simkins, S. (1995). Forecasting with vector autoregressive (VAR) models subject to business cycle restrictions. International Journal of Forecasting, 11, 569–583.   
Spencer, D.E. (1993). Developing a Bayesian vector autoregressive forecasting model. International Journal of Forecasting, 9, 407–421.   
Tashman, L.J., & Leach, M.L. (1991). ‘Automatic forecasting software: a survey and evaluation. International Journal of Forecasting, 7, 209–230.   
Tashman, L.J. (2000). Out-of sample tests of forecasting accuracy: a tutorial and review. International Journal of Forecasting, 16, 437–450.   
Tegene, A., & Kuchler, F. (1994). Evaluating forecasting models of farmland prices. International Journal of Forecasting, 10, 65–80.   
Texter, P.A., & Ord, J.K. (1989). Forecasting using automatic identification procedures: A comparative analysis. International Journal of Forecasting, 5, 209–215.   
Ullah, T.A. (1993). Forecasting of multivariate periodic autoregressive moving-average processes. Journal of Time Series Analysis, 14, 645–657.

Villani, M. (2001). Bayesian prediction with cointegrated vector autoregression. International Journal of Forecasting, 17, 585–605.   
Wall, K.D., & Stoffer, D.S. (2002). A state space approach to bootstrapping conditional forecasts in ARMA models. Journal of Time Series Analysis, 23, 733–751.   
Wang, Z., & Bessler, D.A. (2004). Forecasting performance of multivariate time series models with a full and reduced rank: an empirical examination. International Journal of Forecasting, 20, 683–695.   
Weller, B.R. (1989). National indicator series as quantitative predictors of small region monthly employment levels. International Journal of Forecasting, 5, 241–247.   
West, K.D. (1996). Asymptotic inference about predictive ability. Econometrica, 68, 1097–1084.   
Wieringa, J.E., & Horvath, C. (2005). Computing level-impulse responses of log-specified VAR systems. ´ International Journal of Forecasting, 21, 279–289.   
Yule, G.U. (1927). On the method of investigating periodicities in disturbed series, with special reference to Wolfers sunspot numbers. ¨ Philosophical Transactions of the Royal Society London, Series A, 226, 267– 298.   
Zellner, A. (1971). An Introduction to Bayesian Inference in Econometrics, New York: Wiley.

# Section 4. Seasonality

Albertson, K., & Aylen, J. (1996). Modelling the Great Lake freeze: Forecasting and seasonality in the market for ferrous scrap. International Journal of Forecasting, 12, 345–359.   
Bunn, D.W., & Vassilopoulos, A.I. (1993). Using group seasonal indices in multi-item short-term forecasting. International Journal of Forecasting, 9, 517–526.   
Bunn, D.W., & Vassilopoulos, A.I. (1999). Comparison of seasonal estimation methods in multi-item short-term forecasting. International Journal of Forecasting, 15, 431–443.   
Chen, C. (1997). Robustness properties of some forecasting methods for seasonal time series: A Monte Carlo study. International Journal of Forecasting, 13, 269–280.   
Clements, M.P., & Hendry, D.F. (1997). An empirical study of seasonal unit roots in forecasting. International Journal of Forecasting, 13, 341–355.   
Cleveland, R.B., Cleveland, W.S., McRae, J.E., & Terpenning, I. (1990). STL: A seasonal-trend decomposition procedure based on Loess (with discussion). Journal of Official Statistics, 6, 3–73.   
Dagum, E.B. (1982). Revisions of time varying seasonal filters. Journal of Forecasting, 1, 173–187.   
Findley, D.F., Monsell, B.C., Bell, W.R., Otto, M.C., & Chen, B.-C. (1998). New capabilities and methods of the X-12-ARIMA seasonal adjustment program. Journal of Business & Economics Statistics, 16, 127– 152.   
Findley, D.F., Wills, K.C., & Monsell, B.C. (2004). Seasonal adjustment perspectives on “Damping seasonal factors: shrinkage estimators for the X-12-ARIMA program . International Journal of Forecasting, 20, 551–556.   
Franses, P.H., & Koehler, A.B. (1998). A model selection strategy for time series with increasing seasonal variation. International Journal of Forecasting, 14, 405–414.   
Franses, P.H., & Romijn, G. (1993). Periodic integration in quarterly UK macroeconomic variables. International Journal of Forecasting, 9, 467–476.   
Franses, P.H., & van Dijk, D. (2005). The forecasting performance of various models for seasonality and nonlinearity for quarterly industrial production. International Journal of Forecasting, 21, 87–102.   
Gomez, V., & Maravall, A. (2001). Seasonal adjustment and signal extraction in economic time series. ´ Chapter 8 in A course in time series analysis, ed. D. Pena, G.C. Tiao and R.S. Tsay, John Wiley & Sons: ˜ New York.

Herwartz, H. (1997). Performance of periodic error correction models in forecasting consumption data. International Journal of Forecasting, 13, 421–431.   
Huot, G., Chiu, K., & Higginson, J. (1986). Analysis of revisions in the seasonal adjustment of data using X-11-ARIMA model-based filters. International Journal of Forecasting, 2, 217–229.   
Hylleberg, S., & Pagan, A.R. (1997). Seasonal integration and the evolving seasonals model. International Journal of Forecasting, 13, 329–340.   
Hyndman, R.J. (2004). The interaction between trend and seasonality. International Journal of Forecasting, 20, 561–563.   
Kaiser, R., & Maravall, A. (2005). Combining filter design with model-based filtering (with an application to business-cycle estimation). International Journal of Forecasting, 21, 691–710.   
Koehler, A.B. (2004). Comments on damped seasonal factors and decisions by potential users. International Journal of Forecasting, 20, 565–566.   
Kulendran, N., & King, M.L. (1997). Forecasting international quarterly tourist flows using errorcorrection and time-series models. International Journal of Forecasting, 13, 319–327.   
Ladiray, D., & Quenneville, B. (2004). Implementation issues on shrinkage estimators for seasonal factors within the X-11 seasonal adjustment method. International Journal of Forecasting, 20, 557–560.   
Miller, D.M., & Williams, D. (2003). Shrinkage estimators of time series seasonal factors and their effect on forecasting accuracy. International Journal of Forecasting, 19, 669–684.   
Miller, D.M., & Williams, D. (2004). Damping seasonal factors: Shrinkage estimators for seasonal factors within the X-11 seasonal adjustment method (with commentary). International Journal of Forecasting, 20, 529–550.   
Noakes, D.J., McLeod, A.I. & Hipel, K.W. (1985). Forecasting monthly riverflow time series. International Journal of Forecasting, 1, 179–190.   
Novales, A., & de Fruto, R.F. (1997). Forecasting with time periodic models: A comparison with time invariant coefficient models. International Journal of Forecasting, 13, 393–405.   
Ord, J.K. (2004). Shrinking: when and how? International Journal of Forecasting, 20, 567–568.   
Osborn, D. (1990). A survey of seasonality in UK macroeconomic variables. International Journal of Forecasting, 6, 327–336.   
Paap, R., Franses, P.H., & Hoek, H. (1997). Mean shifts, unit roots and forecasting seasonal time series. International Journal of Forecasting, 13, 357–368.   
Pfeffermann, D., Morry, M., & Wong, P. (1995). Estimation of the variances of X-11 ARIMA seasonally adjusted estimators for a multiplicative decomposition and heteroscedastic variances. International Journal of Forecasting, 11, 271–283.   
Quenneville, B., Ladiray, D., & Lefranc¸ois, B. (2003). A note on Musgrave asymmetrical trend-cycle filters. International Journal of Forecasting, 19, 727–734.   
Simmons, L.F. (1990). Time-series decomposition using the sinusoidal model. International Journal of Forecasting, 6, 485–495.   
Taylor, A.M.R. (1997). On the practical problems of computing seasonal unit root tests. International Journal of Forecasting, 13, 307–318.   
Wells, J.M. (1997). Modelling seasonal patterns and long-run trends in U.S. time series. International Journal of Forecasting, 13, 407–420.   
Withycombe, R. (1989). Forecasting with combined seasonal indices. International Journal of Forecasting, 5, 547–552.

# Section 5. State space and structural models and the Kalman filter

Coomes, P.A. (1992). A Kalman filter formulation for noisy regional job data. International Journal of Forecasting, 7, 473–481.   
Grunwald, G.K., Hamza, K., & Hyndman, R.J. (1997). Some properties and generalizations of nonnegative Bayesian time series models. Journal of the Royal Statistical Society (B), 59, 615–626.   
Grunwald, G.K., Raftery, A.E., & Guttorp, P. (1993). Time series of continuous proportions. Journal of the Royal Statistical Society (B), 55, 103–116.   
Harrison, P.J., & Stevens, C.F. (1976). Bayesian forecasting. Journal of the Royal Statistical Society (B), 38, 205–247.   
Harvey, A.C. (1984). A unified view of statistical forecasting procedures (with discussion). Journal of Forecasting, 3, 245–283.   
Harvey, A.C. (1989). Forecasting, Structural Time Series Models and the Kalman Filter, Cambridge: Cambridge University Press.   
Harvey, A.C. (2006). Forecasting with unobserved component time series models. In Elliot, G., C.W.J. Granger & A. Timmermann (eds.). Handbook of Economic Forecasting, Amsterdam: Elsevier Science.   
Harvey, A.C., & Fernandes, C. (1989). Time series models for count or qualitative observations. Journal of Business & Economic Statistics, 7, 407–422.   
Harvey, A.C., & Snyder. R.D. (1990). Structural time series models in inventory control. International Journal of Forecasting, 6, 187–198.   
Kalman, R.E. (1960). A new approach to linear filtering and prediction problems. Transaction of the ASME – Journal of Basic Engineering, 82D, 35–45.   
Mittnik, S. (1990). Macroeconomic forecasting experience with balanced state space models. International Journal of Forecasting, 6, 337–345.   
Patterson, K.D. (1995). Forecasting the final vintage of real personal disposable income: A state space approach. International Journal of Forecasting, 11, 395–405.   
Proietti, T. (2000). Comparing seasonal components for structural time series models. International Journal of Forecasting, 16, 247–260.   
Ray, W.D. (1989). Rates of convergence to steady state for the linear growth version of a dynamic linear model (DLM). International Journal of Forecasting, 5, 537–545.   
Schweppe, F. (1965). Evaluation of likelihood functions for Gaussian signals. IEEE Transactions on Information Theory, 11(1), 61–70.   
Shumway, R.H., & Stoffer, D.S. (1982). An approach to time series smoothing and forecasting using the EM algorithm. Journal of Time Series Analysis, 3, 253–264.   
Smith, J.Q. (1979). A generalization of the Bayesian steady forecasting model. Journal of the Royal Statistical Society, Series B, 41, 375–387.   
Vinod, H.D., & Basu, P. (1995). Forecasting consumption, income and real interest rates from alternative state space models. International Journal of Forecasting, 11, 217–231.   
West, M., & Harrison, P.J. (1989). Bayesian Forecasting and Dynamic Models, Springer-Verlag, New York. (2nd ed., 1997).   
West, M., Harrison, P.J., & Migon, H.S. (1985). Dynamic generalized linear models and Bayesian forecasting (with discussion). Journal of the American Statistical Association, 80, 73–83.

# Section 6. Nonlinear

Adya, M., & Collopy, F. (1998). How effective are neural networks at forecasting and prediction? A review and evaluation. Journal of Forecasting, 17, 481–495.   
Al-Qassem, M.S., & Lane, J.A. (1989). Forecasting exponential autoregressive models of order 1. Journal of Time Series Analysis, 10, 95–113.   
Astatkie, T., Watts, D.G., & Watt, W.E. (1997). Nested threshold autoregressive (NeTAR) models. International Journal of Forecasting, 13, 105–116.   
Balkin, S.D., & Ord, J.K. (2000). Automatic neural network modeling for univariate time series. International Journal of Forecasting, 16, 509–515.   
Bradley, M.D., & Jansen, D.W. (2004). Forecasting with a nonlinear dynamic model of stock returns and industrial production. International Journal of Forecasting, 20, 321–342.   
Boero, G., & Marrocu, E. (2004). The performance of SETAR models: A regime conditional evaluation of point, interval and density forecasts. International Journal of Forecasting, 20, 305–320.   
Brockwell, P.J., & Hyndman, R.J. (1992). ‘On continuous-time threshold autoregression. International Journal of Forecasting, 8, 157–173.   
Cai, Z., Fan, J. & Yao, Q. (2000). Functional-coefficient regression models for nonlinear time series. Journal of the American Statistical Association, 95, 941–956.   
Callen, J.F., Kwan, C.C.Y., Yip, P.C.Y., & Yuan, Y. (1996). Neural network forecasting of quarterly accounting earnings. International Journal of Forecasting, 12, 475–482.   
Cao, L & Soofi, A.S. (1999). Nonlinear deterministic forecasting of daily dollar exchange rates. International Journal of Forecasting, 15, 421–430.   
Casdagli, M. (1992). Chaos and deterministic versus stochastic non-linear modelling. Journal of the Royal Statistical Society, Series B, 55, 303–328.   
Cecen, A.A., & Erkal, C. (1996). Distinguishing between stochastic and deterministic behavior in high frequency foreign rate returns: Can non-linear dynamics help forecasting. International Journal of Forecasting, 12, 465–473.   
Chatfield, C. (1993). Neural network: forecasting breakthrough or passing fad? International Journal of Forecasting, 9, 1–3.   
Chatfield, C. (1995). Positive or negative. International Journal of Forecasting, 11, 501-502.   
Church, K.B., & Curram, S.P. (1996). Forecasting consumers expenditure: A comparison between econometric and neural network models. International Journal of Forecasting, 12, 255–267.   
Clements, M.P., & Smith, J. (1997). The performance of alternative methods for SETAR models. International Journal of Forecasting, 13, 463–475.   
Clements, M.P., Franses, P.H., & Swanson, N.R. (2004). Forecasting economic and financial time-series with non-linear models. International Journal of Forecasting, 20, 169–183.   
Conejo, A.J., Contreras, J., Esp´ınola, R., & Plazas, M.A. (2005). Forecasting electricity prices for a dayahead pool-based electricity market. International Journal of Forecasting, 21, 435–462.   
Dahl, C.M., & Hylleberg, S. (2004). Flexible regression models and relative forecast performance. International Journal of Forecasting, 20, 201–217.   
Darbellay, G.A., & Slama, M. (2000). Forecasting the short-term demand for electricity: Do neural networks stand a better chance? International Journal of Forecasting, 16, 71–83.   
De Gooijer, J.G., & Kumar, V. (1992). Some recent developments in non-linear time series modelling, testing and forecasting. International Journal of Forecasting, 8, 135–156.   
De Gooijer, J.G., & Vidiella-i-Anguera, A. (2004). Forecasting threshold cointegrated systems. International Journal of Forecasting, 20, 237–253.

Enders, W., & Falk, B. (1998). Threshold-autoregressive, median-unbiased, and cointegration tests of purchasing power parity. International Journal of Forecasting, 14, 171–186.   
Fernandez-Rodr ´ ´ıguez, F., Sosvilla-Rivero, S., & Andrada-Felix, J. (1999). Exchange-rate forecasts with ´ simultaneous nearest-neighbour methods; evidence from the EMS. International Journal of Forecasting, 15, 383–392.   
Fok, D.F., van Dijk, D., & Franses, P.H. (2005). Forecasting aggregated using panels of nonlinear time series. International Journal of Forecasting, 21, 785–794.   
Franses, P.H., Paap, R. & Vroomen, B. (2004). Forecasting unemployment using an autoregression with censored latent effects parameters. International Journal of Forecasting, 20, 255–271.   
Ghiassi, M., Saidane, H., & Zimbra, D.K. (2005). A dynamic artificial neural network model for forecasting series events. International Journal of Forecasting, 21, 341–362.   
Gorr, W. (1994). Research prospective on neural network forecasting. International Journal of Forecasting, 10, 1–4.   
Gorr, W., Nagin, D., & Szczypula, J. (1994). Comparative study of artificial neural network and statistical models for predicting student grade point averages. International Journal of Forecasting, 10, 17–34.   
Granger, C.W.J., & Terasvirta, T. (1993). ¨ Modelling Nonlinear Economic Relationships, Oxford: Oxford University Press.   
Hamilton, J.D. (2001). A parametric approach to flexible nonlinear inference. Econometrica, 69, 537–573.   
Harvill, J.L., & Ray, B.K. (2005). A note on multi-step forecasting with functional coefficient autoregressive models. International Journal of Forecasting, 21, 717–727.   
Hastie, T.J., & Tibshirani, R.J. (1991). Generalized Additive Models, London: Chapman and Hall.   
Heravi, S., Osborn, D.R., & Birchenhall, C.R. (2004). Linear versus neural network forecasting for European industrial production series. International Journal of Forecasting, 20, 435–446.   
Herwartz, H. (2001). Investigating the JPY/DEM-rate: arbitrage opportunities and a case for asymmetry. International Journal of Forecasting, 17, 231–245.   
Hill, T., Marquez, L., OConnor, M., & Remus, W. (1994). Artificial neural network models for forecasting and decision making. International Journal of Forecasting, 10, 5–15.   
Hippert, H.S., Pedreira, C.E., & Souza, R.C. (2001). Neural networks for short-term load forecasting: A review and evaluation. IEEE Transactions on Power Systems, 16, 44–55.   
Hippert, H.S., Bunn, D.W., & Souza, R.C. (2005). Large neural networks for electricity load forecasting: Are they overfitted? International Journal of Forecasting, 21, 425–434.   
Lisi, F., & Medio, A. (1997). Is a random walk the best exchange rate predictor? International Journal of Forecasting, 13, 255–267.   
Ludlow, J., & Enders, W. (2000). Estimating non-linear ARMA models using Fourier coefficients. International Journal of Forecasting, 16, 333–347.   
Marcellino, M. (2004). Forecasting EMU macroeconomic variables. International Journal of Forecasting, 20, 359–372.   
Olson, D., & Mossman, C. (2003). Neural network forecasts of Canadian stock returns using accounting ratios. International Journal of Forecasting, 19, 453–465.   
Pemberton, J. (1987). Exact least squares multi-step prediction from nonlinear autoregressive models. Journal of Time Series Analysis, 8, 443–448.   
Poskitt, D.S., & Tremayne, A.R. (1986). The selection and use of linear and bilinear time series models. International Journal of Forecasting, 2, 101–114.   
Qi, M. (2001). Predicting US recessions with leading indicators via neural network models. International Journal of Forecasting, 17, 383–401.

Sarantis, N. (2001). Nonlinearities, cyclical behaviour and predictability in stock markets: International evidence. International Journal of Forecasting, 17, 459–482.   
Swanson, N.R., & White, H. (1997). Forecasting economic time series using flexible versus fixed specification and linear versus nonlinear econometric models. International Journal of Forecasting, 13, 439–461.   
Terasvirta, T. (2006). Forecasting economic variables with nonlinear models. In Elliot, G., C.W.J. Granger ¨ & A. Timmermann (eds.). Handbook of Economic Forecasting, Amsterdam: Elsevier Science.   
Terasvirta, T., van Dijk, D., & Medeiros, M.C. (2005). Linear models, smooth transition autoregressions, ¨ and neural networks for forecasting macroeconomic time series: A re-examination. International Journal of Forecasting, 21, 755–774.   
Tkacz, G. (2001). Neural network forecasting of Canadian GDP growth. International Journal of Forecasting, 17, 57–69.   
Tong, H. (1983). Threshold Models in Non-linear Time Series Analysis, New York: Springer-Verlag.   
Tong, H. (1990) Non-linear Time Series: A Dynamical System Approach, Oxford: Clarendon Press.   
Volterra, V. (1930). Theory of Functionals and of Integro-differential Equations, Dover, New York.   
Wiener, N. (1958). Non-linear Problems in Random Theory, London: Wiley.   
Zhang, G., Patuwo, B.E., & Hu, M.Y. (1998). Forecasting with artificial networks: The state of the art. International Journal of Forecasting, 14, 35–62.

# Section 7. Long memory

Andersson, M.K. (2000). Do long-memory models have long memory? International Journal of Forecasting, 16, 121–124.   
Baillie, R.T., & Chung, S-K. (2002). Modeling and forecasting from trend-stationary long memory models with applications to climatology. International Journal of Forecasting, 18, 215–226.   
Beran, J., Feng, Y., Ghosh, S., & Sibbertsen, P. (2002). On robust local polynomial estimation with longmemory errors. International Journal of Forecasting, 18, 227–241.   
Bhansali, R.J., & Kokoszka, P.S. (2002). Computation of the forecast coefficients for multistep prediction of long-range dependent time series. International Journal of Forecasting, 18, 181–206.   
Franses, P.H., & Ooms, M. (1997). A periodic long-memory model for quarterly UK inflation. International Journal of Forecasting, 13, 117–126.   
Granger, C.W.J., & Joyeux, R. (1980). An introduction to long memory time series models and fractional differencing. Journal of Time Series Analysis, 1, 15–29.   
Hurvich, C.M. (2002). Multistep forecasting of long memory series using fractional exponential models. International Journal of Forecasting, 18, 167–179.   
Man, K.S. (2003). Long memory time series and short term forecasts. International Journal of Forecasting, 19, 477–491.   
Oller, L-E. (1985). How far can changes in general business activity be forecasted? ¨ International Journal of Forecasting, 1, 135–141.   
Ramjee, R., Crato, N., & Ray, B.K. (2002). A note on moving average forecasts of long memory processes with an application to quality control. International Journal of Forecasting, 18, 291–297.   
Ravishanker, N., & Ray, B.K. (2002). Bayesian prediction for vector ARFIMA processes. International Journal of Forecasting, 18, 207–214.   
Ray, B.K. (1993). Long-range forecasting of IBM product revenues using a seasonal fractionally differenced ARMA model. International Journal of Forecasting, 9, 255–269.   
Ray, B.K. (1993). Modeling long-memory processes for optimal long-range prediction. Journal of Time Series Analysis, 14, 511–525.

Smith, J., & Yadav, S. (1994). Forecasting costs incurred from unit differencing fractionally integrated processes. International Journal of Forecasting, 10, 507–514.   
Souza, L.R., & Smith, J. (2002). Bias in the memory for different sampling rates. International Journal of Forecasting, 18, 299–313.   
Souza, L.R., & Smith, J. (2004). Effects of temporal aggregation on estimates and forecasts of fractionally integrated processes: A Monte-Carlo study. International Journal of Forecasting, 20, 487–502.

# Section 8. ARCH/GARCH

Awartani, B.M.A., & Corradi, V. (2005). Predicting the volatility of the S&P-500 stock index via GARCH models: the role of asymmetries. International Journal of Forecasting, 21, 167–183.   
Baillie, R.T., Bollerslev, T., & Mikkelsen, H.O. (1996). Fractionally integrated generalized autoregressive conditional heteroskedasticity. Journal of Econometrics, 74, 3–30.   
Bera, A., & Higgins, M. (1993). ARCH models: properties, estimation and testing. Journal of Economic Surveys, 7, 305-365.   
Bollerslev, T., & Wright, J.H. (2001). High-frequency data, frequency domain inference, and volatility forecasting. Review of Economic and Statistics, 83, 596–602.   
Bollerslev, T., Chou, R.Y., & Kroner, K.F. (1992). ARCH modeling in finance: a review of the theory and empirical evidence. Journal of Econometrics, 52, 5–59.   
Bollerslev, T., Engle, R.F., & Nelson, D.B. (1994). ARCH models. in Handbook of Econometrics, Vol. IV, eds. R.F. Engle and D.L. McFadden, Amsterdam: North-Holland, pp. 2959–3038.   
Brooks, C. (1998). Predicting stock index volatility: Can market volume help? Journal of Forecasting, 17, 59–80.   
Brooks, C., Burke, S.P., & Persand, G. (2001). Benchmarks and the accuracy of GARCH model estimation. International Journal of Forecasting, 17, 45–56.   
Doidge, C., & Wei, J.Z. (1998). Volatitility forecasting and the efficiency of the Toronto 35 index options market. Canadian Journal of Administrative Sciences, 15, 28–38.   
Engle, R.F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of the United Kingdom inflation. Econometrica, 50, 987–1008.   
Engle, R.F. (2002). New frontiers for ARCH models. Manuscript prepared for the conference “Modeling and Forecasting Financial Volatility (Perth, Australia, 2001). Available at http://pages.stern.nyu.edu/ rengle.   
Engle, R.F., & Ng, V. (1993). Measuring and testing the impact of news on volatility. Journal of Finance, 48, 1749–1778.   
Franses, P.H., & Ghijsels, H. (1999). Additive outliers, GARCH and forecasting volatility. International Journal of Forecasting, 15, 1–9.   
Galbraith, J.W., & Kisinbay, T. (2005). Content horizons for conditional variance forecasts. International Journal of Forecasting, 21, 249–260.   
Granger, C.W.J. (2002). Long memory, volatility, risk and distribution. Manuscript, University of California, San Diego. Available at http://www.cass.city.ac.uk/conferences/esrc2002/Granger.pdf   
Hentschel, L. (1995). All in the family: nesting symmetric and asymmetric GARCH models. Journal of Financial Economics, 39, 71–104.   
Kroner, K.F., Kneafsey, K.P., & Claessens, S. (1995). Forecasting volatility in commodity markets. Journal of Forecasting, 14, 77–95.   
Pagan, A. (1996). The econometrics of financial markets. Journal of Empirical Finance, 3, 15–102.   
Poon, S-H., & Granger, C.W.J. (2003). Forecasting volatility in financial markets: a review. Journal of

Economic Literature, 41, 478–539.   
Poon, S-H., & Granger, C.W.J. (2005). Practical issues in forecasting volatility. Financial Analysts Journal, 61, 45–56.   
Sabbatini, M., & Linton, O. (1998). A GARCH model of the implied volatility of the Swiss market index from option prices. International Journal of Forecasting, 14, 199–213.   
Taylor, S.J. (1987). Forecasting the volati lity of currency exchange rates. International Journal of Forecasting, 3, 159–170.   
Vasilellis, G.A., & Meade, N. (1996). Forecasting volatility for portfolio selection. Journal of Business Finance & Accounting, 23, 125–143.

# Section 9. Count data forecasting

Brann ¨ as, K. (1995). Prediction and control for a time-series count data model. ¨ International Journal of Forecasting, 11, 263–270.   
Brann ¨ as, K., Hellstr ¨ om, J., & Nordstr ¨ om, J. (2002). A new approach to modelling and forecasting ¨ monthly guest nights in hotels. International Journal of Forecasting, 18, 19–30.   
Croston, J.D. (1972). Forecasting and stock control for intermittent demands. Operational Research Quarterly, 23, 289–303.   
Diebold, F.X., Gunther, T.A., & Tay, A.S. (1998). Evaluating density forecasts, with applications to financial risk management. International Economic Review, 39, 863–883.   
Freeland, R.K., & McCabe, B.P.M. (2004). Forecasting discrete valued low count time series. International Journal of Forecasting, 20, 427–434.   
Grunwald, G.K., Hyndman, R.J., Tedesco, L.M., & Tweedie, R.L. (2000). Non-Gaussian conditional linear AR(1) models. Australian and New Zealand Journal of Statistics, 42, 479–495.   
Diggle, P.J., Heagerty, P., Liang, K.-Y., & Zeger, S. (2002). Analysis of longitudinal data, 2nd ed., Oxford University Press: Oxford.   
Johnston, F.R., & Boylan, J.E. (1996). Forecasting intermittent demand: a comparative evaluation of Crostons method. International Journal of Forecasting, 12, 297–298.   
McCabe, B.P.M. & Martin, G.M. (2005). Bayesian predictions of low count time series. International Journal of Forecasting, 21, 315–330.   
Syntetos, A.A., & Boylan, J.E. (2005). The accuracy of intermittent demand estimates. International Journal of Forecasting, 21, 303–314.   
Willemain, T.R., Smart, C.N., Shockor, J.H., & DeSautels, P.A. (1994). Forecasting intermittent demand in manufacturing: a comparative evaluation of Crostons method. International Journal of Forecasting, 10, 529–538.   
Willemain, T.R., Smart, C.N., & Schwarz, H.F. (2004). A new approach to forecasting intermittent demand for service parts inventories. International Journal of Forecasting, 20, 375–387.

# Section 10. Forecast evaluation and accuracy measures

Ahlburg, D.A., Chatfield, C., Taylor, S.J., Thompson, P.A., Winkler, R.L., Murphy, A.H., Collopy, F., & Fildes, R. (1992). A commentary on error measures. International Journal of Forecasting, 8, 99–111.   
Armstrong, J.S., & Collopy, F. (1992). Error measures for generalizing about forecasting methods: Empirical comparisons. International Journal of Forecasting, 8, 69–80.   
Chatfield, C. (1988). Editorial: Apples, oranges and mean square error. International Journal of Forecasting, 4, 515–518.   
Clements, M.P., & Hendry, D.F. (1993). On the limitations of comparing mean square forecast errors.

Journal of Forecasting, 12, 617–637.   
Diebold, F.X., & R.S. Mariano (1995). ‘Comparing Predictive Accuracy. Journal of Business & Economic Statistics, 13, 253–263.   
Fildes, R., & Makridakis, S. (1988). Forecasting and loss functions. International Journal of Forecasting, 4, 545–550.   
Fildes, R. (1992). The evaluation of extrapolative forecasting methods. International Journal of Forecasting, 8, 81–98.   
Fildes, R., Hibon, M., Makridakis, S., & Meade, N. (1998). Generalising about univariate forecasting methods: further empirical evidence. International Journal of Forecasting, 14, 339–358.   
Flores, B. (1989). The utilization of the Wilcoxon test to compare forecasting methods: A note. International Journal of Forecasting, 5, 529–535.   
Goodwin, P., & Lawton, R. (1999). On the asymmetry of the symmetric MAPE. International Journal of Forecasting, 15, 405–408.   
Granger, C.W.J., & Jeon, Y. (2003a). A time-distance criterion for evaluating forecasting models. International Journal of Forecasting, 19, 199–215.   
Granger, C.W.J., & Jeon, Y. (2003b). Comparing forecasts of inflation using time distance. International Journal of Forecasting, 19, 339–349. (Corrigendum: Vol 19:4, p. 767).   
Harvey, D., Leybourne, S., & Newbold, P. (1997). Testing the equality of prediction mean squared errors. International Journal of Forecasting, 13, 281–291.   
Koehler, A.B. (2001). The asymmetry of the sAPE measure and other comments on the M3-Competition. International Journal of Forecasting, 17, 570–574.   
Mahmoud, E. (1984). Accuracy in forecasting: A survey. Journal of Forecasting, 3, 139–159.   
Makridakis, S., Andersen, A., Carbone, R., Fildes, R.. Hibon, M., Lewandowski, R., Newton, J., Parzen, E., & Winkler, R. (1982). The accuracy of extrapolation (time series) methods: results of a forecasting competition. Journal of Forecasting, 1, 111–153.   
Makridakis, S. (1993). Accuracy measures: theoretical and practical concerns. International Journal of Forecasting, 9, 527–529.   
Makridakis, S., & Hibon, M. (2000). The M3-Competition: results, conclusions and implications. International Journal of Forecasting, 16, 451–476.   
Makridakis, S., Wheelwright, S.C., & Hyndman, R.J. (1998). Forecasting: methods and applications, 3rd ed., John Wiley & Sons: New York.   
McCracken, M.W. (2004). Parameter estimation and tests of equal forecast accuracy between non-nested models. International Journal of Forecasting, 20, 503–514.   
Sullivan, R., Timmermann, A., & White, H. (2003). Forecast evaluation with shared data sets. International Journal of Forecasting, 19, 217–227.   
Theil, H. (1966). Applied Economic Forecasting, North-Holland: Amsterdam.   
Thompson, P.A. (1990). An MSE statistic for comparing forecast accuracy across series. International Journal of Forecasting, 6, 219–227.   
Thompson, P.A. (1991). Evaluation of the M-competition forecasts via log mean squared error ratio. International Journal of Forecasting, 7, 331–334.   
Wun, L-M., & Pearn, W.L. (1991). Assessing the statistical characteristics of the mean absolute error of forecasting. International Journal of Forecasting, 7, 335–337.

# Section 11. Combining

Aksu, C., & Gunter, S. (1992). An empirical analysis of the accuracy of SA, OLS, ERLS and NRLS combination forecasts. International Journal of Forecasting, 8, 27–43.   
Bates, J.M., & Granger, C.W.J. (1969). Combination of forecasts. Operations Research Quarterly, 20, 451– 468.   
Bunn, D.W. (1985). Statistical efficiency in the linear combination of forecasts. International Journal of Forecasting, 1, 151–163.   
Clemen, R.T. (1986). Linear constraints and the efficiency of combined forecasts. Journal of Forecasting, 6, 31–38.   
Clemen, R.T. (1989). Combining forecasts: A review and annotated biography (with discussion) International Journal of Forecasting, 5, 559–583.   
Deutsch, M., Granger, C.W.J., & Terasvirta, T. (1994). The combination of forecasts using changing ¨ weights. International Journal of Forecasting, 10, 47–57.   
Diebold, F.X., & Pauly, P. (1990). The use of prior information in forecast combination. International Journal of Forecasting, 6, 503–508.   
Fang, Y. (2003). Forecasting combination and encompassing tests. International Journal of Forecasting, 19, 87–94.   
Fiordaliso, A. (1998). A nonlinear forecast combination method based on Takagi-Sugeno fuzzy systems. International Journal of Forecasting, 14, 367–379.   
Granger, C.W.J. (1989). Combining forecasts — twenty years later. Journal of Forecasting, 8, 167–173.   
Granger, C.W.J., & Ramanathan, R. (1984). Improved methods of combining forecasts. Journal of Forecasting, 3, 197–204.   
Gunter, S.I. (1992). Nonnegativity restricted least squares combinations. International Journal of Forecasting, 8, 45–59.   
Hendry, D.F., & Clements, M.P. (2002). Pooling of forecasts. Econometrics Journal, 5, 1–31.   
Hibon, M., & Evgeniou, T. (2005). To combine or not to combine: selecting among forecasts and their combinations. International Journal of Forecasting, 21, 15–24.   
Kamstra, M., & Kennedy, P. (1998). Combining qualitative forecasts using logit. International Journal of Forecasting, 14, 83–93.   
de Menezes, L.M., & Bunn, D.W. (1998). The persistence of specification problems in the distribution of combined forecast errors. International Journal of Forecasting, 14, 415–426.   
Miller, S.M., Clemen, R.T., & Winkler, R.L. (1992). The effect of nonstationarity on combined forecasts. International Journal of Forecasting, 7, 515–529.   
Newbold, P., & Granger, C.W.J. (1974). Experience with forecasting univariate time series and the combination of forecasts. Journal of the Royal Statistical Society (A), 137, 131–165.   
Taylor, J.W., & Bunn, D.W. (1999). Investigating improvements in the accuracy of prediction intervals for combinations of forecasts: A simulation study. International Journal of Forecasting, 15, 325–339.   
Terui, N., & van Dijk, H.K. (2002). Combined forecasts from linear and nonlinear time series models. International Journal of Forecasting, 18, 421–438.   
Winkler, R.L., & Makridakis, S. (1983). ‘ The combination of forecasts. Journal of the Royal Statistical Society (A), 146, 150–157.   
Zou, H., & Yang, Y. (2004). Combining time series models for forecasting. International Journal of Forecasting, 20, 69–84.

# Section 12. Prediction intervals and densities

Chatfield, C. (1993). Calculating interval forecasts. Journal of Business & Economic Statistics, 11, 121–135.   
Chatfield, C., & Koehler, A.B. (1991). On confusing lead time demand with $h$ -period-ahead forecasts. International Journal of Forecasting, 7, 239–240.   
Clements, M.P., & Smith, J. (2002). Evaluating multivariate forecast densities: A comparison of two approaches. International Journal of Forecasting, 18, 397–407.   
Clements, M.P., & Taylor, N. (2001). Bootstrapping prediction intervals for autoregressive models. International Journal of Forecasting, 17, 247–267.   
Diebold, F.X., Gunther, T.A., & Tay, A.S. (1998). Evaluating density forecasts with applications to financial risk management. International Economic Review, 39, 863–883.   
Diebold, F.X., Hahn, J.Y., & Tay, A.S. (1999). Multivariate density forecast evaluation and calibration in financial risk management: high-frequency returns in foreign exchange. Review of Economics and Statistics, 81, 661–673.   
Grigoletto, M. (1998). Bootstrap prediction intervals for autoregressions: Some alternatives. International Journal of Forecasting, 14, 447–456.   
Hyndman, R.J. (1995). Highest density forecast regions for non-linear and non-normal time series models. Journal of Forecasting, 14, 431–441.   
Kim, J.A. (1999). Asymptotic and bootstrap prediction regions for vector autoregression. International Journal of Forecasting, 15, 393–403.   
Kim, J.A. (2004a). Bias-corrected bootstrap prediction regions for vector autoregression. Journal of Forecasting, 23, 141–154.   
Kim, J.A. (2004b). Bootstrap prediction intervals for autoregression using asymptotically mean-unbiased estimators. International Journal of Forecasting, 20, 85–97.   
Koehler, A.B. (1990). An inappropriate prediction interval. International Journal of Forecasting, 6, 557–558.   
Lam, J.-P., & Veall, M.R. (2002). Bootstrap prediction intervals for single period regression forecasts. International Journal of Forecasting, 18, 125–130.   
Lefranc¸ois, P. (1989). Confidence intervals for non-stationary forecast errors: Some empirical results for the series in the M-competition. International Journal of Forecasting, 5, 553–557.   
Makridakis, S., & Hibon, M. (1987). Confidence intervals: an empirical investigation of the series in the M-competition. International Journal of Forecasting, 3, 489–508.   
Masarotto, G. (1990). Bootstrap prediction intervals for autoregressions. International Journal of Forecasting, 6, 229–239.   
McCullough, B.D. (1994). Bootstrapping forecast intervals: An application to AR(p) models. Journal of Forecasting, 13, 51–66.   
McCullough, B.D. (1996). Consistent forecast intervals when the forecast-period exogenous variables are stochastic. Journal of Forecasting, 15, 293–304.   
Pascual, L., Romo, J., & Ruiz, E. (2001). Effects of parameter estimation on prediction densities: A bootstrap approach. International Journal of Forecasting, 17, 83–103.   
Pascual, L., Romo, J., & Ruiz, E. (2004). Bootstrap predictive inference for ARIMA processes. Journal of Time Series Analysis, 25, 449–465.   
Pascual, L., Romo, J., & Ruiz, E. (2005). Bootstrap prediction intervals for power-transformed time series. International Journal of Forecasting, 21, 219–236.   
Reeves, J.J. (2005). Bootstrap prediction intervals for ARCH models. International Journal of Forecasting, 21, 237–248.   
Tay, A.S., & Wallis, K.F. (2000). Density forecasting: a survey. Journal of Forecasting, 19, 235–254.

Reprinted in Clements, M.P., and Hendry, D.F. (eds.). A Companion to Economic Forecasting, pp. 45- 68. Oxford: Blackwell (2002).   
Taylor, J.W., & Bunn, D.W. (1999). Investigating improvements in the accuracy of prediction intervals for combinations of forecasts: A simulation study. International Journal of Forecasting, 15, 325–339.   
Wallis, K.F. (1999). Asymmetric density forecasts of inflation and the Bank of Englands fan chart. National Institute Economic Review, 167, 106–112.   
Wallis, K.F. (2003). Chi-squared tests of interval and density forecasts, and the Bank of Englands fan charts. International Journal of Forecasting, 19, 165–175.

# Section 13. A look to the future

Armstrong, J.S. (2001). Suggestions for further research. www.forecastingprinciples.com/ researchers.html.   
Andersen, T.G., Bollerslev, T., Diebold, F.X., & Labys, P. (2003). Modeling and forecasting realized volatility. Econometrica, 71, 579–625.   
Casella, G. (Editor) et al. (2000). Vignettes for the Year 2000. Journal of the American Statistical Association, 95, 1269–1368 (with 22 thought-provoking contributions).   
Chatfield, C. (1988). The future of time-series forecasting. International Journal of Forecasting, 4, 411–419.   
Chatfield, C. (1997). Forecasting in the 1990s. The Statistician, 46, 461–473.   
Clements, M.P. (2003). Editorial: Some possible directions for future research. International Journal of Forecasting, 19, 1–3.   
Cogger, K.C. (1988). Proposals for research in time series forecasting. International Journal of Forecasting, 4, 403–410.   
Dawes, R., Fildes, R., Lawrence, M., & Ord, J.K. (1994). The past and the future of forecasting research. International Journal of Forecasting, 10, 151–159.   
De Gooijer, J.G. (1990). Editorial: The role of time series analysis in forecasting: A personal view. International Journal of Forecasting, 6, 449–451.   
De Gooijer, J.G., & Gannoun, A. (2000). Nonparametric conditional predictive regions for time series. Computational Statistics & Data Analysis, 33, 259–275.   
Dekimpe, M.G., & Hanssens, D.M. (2000). Time-series models in marketing: past, present and future. International Journal of Research in Marketing, 17, 183–193.   
Durbin, J., & Koopman, S.J. (2001). Time Series Analysis by State Space Methods, Oxford: Oxford University Press.   
Engle, R.F & Manganelli, S. (2004). CAViaR: Conditional autoregressive value at risk by regression quantiles. Journal of Business & Economic Statistics, 22, 367–381.   
Engle, R.F. & Russell, J.R. (1998). Autoregressive conditional duration: a new model for irregularly spaced transactions data. Econometrica, 66, 1127–1162.   
Forni, M., Hallin, M., Lippi, M., & Reichlin, L. (2005). The generalized dynamic factor model: one-sided estimation and forecasting. Journal of the American Statistical Association, 100, 830–840.   
Harvey, A.C. (1989). Forecasting, Structural Time Series Models and the Kalman Filter, Cambridge: Cambridge University Press.   
Koenker, R.W., & Bassett, G.W. (1978). Regression quantiles. Econometrica, 46, 33–50.   
Ord, J.K. (1988). Future developments in forecasting: The time series connexion. International Journal of Forecasting, 4, 389–401.   
Pena, D., & Poncela, P. (2004). Forecasting with nonstationary dynamic factor models. ˜ Journal of Econometrics, 119, 291–321.

Polonik, W., & Yao, Q. (2000). Conditional minimum volume predictive regions for stochastic processes. Journal of the American Statistical Association, 95, 509–519.   
Ramsay, J.O., & Silverman, B.W. (1997). Functional Data Analysis, New York: Springer-Verlag. (2nd ed. 2005).   
Stock, J.H., & Watson, M.W. (1999). A comparison of linear and nonlinear models for forecasting macroeconomic time series. In R.F. Engle and H. White (eds.). Cointegration, Causality and Forecasting, pp. 1–44. Oxford: Oxford University Press.   
Stock, J.H., & Watson, M.W. (2002). Forecasting using principal components from a large number of predictors. Journal of the American Statistical Association, 97, 1167–1179.   
Stock, J.H., & Watson, M.W. (2004). Combination forecasts of output growth in a seven-country data set. Journal of Forecasting, 23, 405–430.   
Tsay, R.S. (2000). Time series and forecasting: Brief history and future research. Journal of the American Statistical Association, 95, 638–643.   
West, M., & Harrison, P.J. (1989). Bayesian Forecasting and Dynamic Models, New York: Springer Verlag (2nd ed. 1997).   
Yao, Q., & Tong, H. (1995). On initial-condition and prediction in nonlinear stochastic systems. Bulletin International Statistical Institute, IP10.3, 395–412.

# 3

# Time Series Forecasting Techniques

![](images/b1c243bb7d39d87136e855a443a374afd120b587314b880e28e6d5664c876620.jpg)

Back in the 1970s, we were working with a company in the major home appliance industry. In an interview, the person in charge of quantitative forecasting for refrigerators explained that their forecast was based on one time series technique. (It turned out to be the exponential smoothing with trend and seasonality technique that is discussed later in this chapter.) This technique requires the user to specify three “smoothing constants” called α, β, and Y(we will explain what these are later in the chapter). The selection of these values, which must be somewhere between 0 and 1 for each constant, can have a profound effect upon the accuracy of the forecast.

As we talked with this forecast analyst, he explained that he had chosen the values of 0.1 for α, 0.2 for $\beta ,$ and 0.3 for γ. Being fairly new to the world of sales forecasting, we envisioned some sophisticated sensitivity analysis that this analyst had gone through to find the right combination of the values for the three smoothing constants to accurately forecast refrigerator demand.

However, he explained to us that in every article he read about this technique, the three smoothing constants were always referred to as α, $\beta ,$ and γ, in that order. He finally realized that this was because they are the 1st, 2nd, and 3rd letters in the Greek alphabet. Once he realized that, he “simply

took 1, 2, and 3, put a decimal point in front of each, and there were my smoothing constants.”

After thinking about it for a minute, he rather sheepishly said, “You know, it doesn’t work worth a darn, though.”

#  INTRODUCTION

We hope that over the years we have come a long way from this type of time series forecasting. First, it is not realistic to expect that each product in a line like refrigerators would be accurately forecast by the same time series technique—we probably need to select a different time series technique for each product. Second, there are better ways to select smoothing constants than our friend used in the previous example. To understand how to better accomplish both of these, the purpose of this chapter is to provide an overview of the many techniques that are available in the general category of time series analysis. This overview should provide the reader with an understanding of how each technique works and where it should and should not be used.

Time series techniques all have the common characteristic that they are endogenous techniques. This means a time series technique looks at only the patterns of the history of actual sales (or the series of sales through time—thus, the term time series). If these patterns can be identified and projected into the future, then we have our forecast. Therefore, this rather esoteric term of endogenous means time series techniques look inside (that is, endo) the actual series of demand through time to find the underlying patterns of sales. This is in contrast to regression analysis, which is an exogenous technique that we will discuss in Chapter 4. Exogenous means that regression analysis examines factors external (or exo) to the actual sales pattern to look for a relationship between these external factors (like price changes) and sales patterns.

If time series techniques only look at the patterns that are part of the actual history of sales (that is, are endogenous to the sales history), then what are these patterns? The answer is that no matter what time series technique we are talking about, they all examine one or more of only four basic time series patterns: level, trend, seasonality, and noise. Figure 3.1 illustrates these four patterns broken out of a monthly time series of sales for a particular refrigerator model. The

level is a horizontal sales history, or what the sales pattern would be if there were no trend, seasonality, or noise. For a product that is sold to a manufacturing concern as a component in another product whose demand is stable, the sales pattern for this product would be essentially level, with no trend, seasonality, or noise. In our example in Figure 3.1, however, the level is simply the starting point for the time series (the horizontal line), with the trend, seasonality, and noise added to it.

Trend is a continuing pattern of a sales increase or decrease, and that pattern can be a straight line or a curve.

Of course, any business person wants a positive trend that is increasing at an increasing rate, but this is not always the case. If sales are decreasing (either at a constant rate, an increasing rate, or a decreasing rate), we need to know this for forecasting purposes. In our example in Figure 3.1, trend is expressed as a straight line going up from the level.

Seasonality is a repeating pattern of sales increases and decreases that occurs within a one-year period or less (“seasonal patterns” of longer than one year are typically referred to as “cycles,” but can be forecast using the same time series techniques). Examples of seasonality

![](images/4578971490cec6fb45ffd04ad207a01a1b0f2f220c04ac21ddc2a1d54821d3fa.jpg)  
Figure 3.1 Time Series Components

are high sales every summer for air conditioners, high sales of agricultural chemicals in the spring, and high sales of toys in the fall. The point is that the pattern of high sales in certain periods of the year and low sales in other periods repeats itself every year. When broken out of the time series in Figure 3.1, the seasonality line can be seen as a regular pattern of sales increases and decreases around the zero line at the bottom of the graph.

Noise is random fluctuation—that part of the sales history that time series techniques cannot explain. This does not mean the fluctuation could not be explained by regression analysis or some qualitative technique; it means the pattern has not happened consistently in the past, so the time series technique cannot pick it up and forecast it. In fact, one test of how well we are doing at forecasting with time series is whether the noise pattern looks random. If it does not have a random pattern like the one in Figure 3.1, it means there are still trend and/or seasonal patterns in the time series that we have not yet identified.

We can group all time series techniques into two broad categories— open-model time series techniques and fixed model time series techniques— based on how the technique tries to identify and project these four patterns. Open-model time series (OMTS) techniques analyze the time series to determine which patterns exist and then build a unique model of that time series to project the patterns into the future and, thus, to forecast the time series. This is in contrast to fixed-model time series (FMTS) techniques, which have fixed equations that are based upon a priori assumptions that certain patterns do or do not exist in the data.

In fact, when you consider both OMTS and FMTS techniques, there are more than 60 different techniques that fall into the general category of time series techniques. Fortunately, we do not have to explain each of them in this chapter. This is because some of the techniques are very sophisticated and take a considerable amount of data but do not produce any better results than simpler techniques, and they are seldom used in practical sales forecasting situations. In other cases, several different time series techniques may use the same approach to forecasting and have the same level of effectiveness. In these latter cases where several techniques work equally well, we will discuss only the one that is easiest to understand (following the philosophy, why make something complicated if it does not have to be). This greatly reduces the number of techniques that need to be discussed.

Because they are generally easier to understand and use, we will start with FMTS techniques and return to OMTS later in the chapter.

#  FIXED-MODEL TIME SERIES TECHNIQUES

FMTS techniques are often simple and inexpensive to use and require little data storage. Many of the techniques (because they require little data) also adjust very quickly to changes in sales conditions and, thus, are appropriate for short-term forecasting. We can fully understand the range of FMTS techniques by starting with the concept of an average as a forecast (which is the basis on which all FMTS techniques are founded) and move through the levels of moving average, exponential smoothing, adaptive smoothing, and incorporating trend and seasonality.

# The Average as a Forecast

All FMTS techniques are essentially a form of average. The simplest form of an average as a forecast can be represented by the following formula:

$$
\text {F o r e c a s t} _ {\mathrm {t} + 1} = \text {A v e r a g e S a l e s} _ {1 \text {t o t}} = \sum_ {\mathrm {t} = 1} ^ {\mathrm {N}} \mathrm {S} _ {\mathrm {t}} / \mathrm {N} \tag {1}
$$

where: $\mathrm { ~ S ~ } =$ Sales

$$
N = \text {N u m b e r o f P e r i o d s o f S a l e s D a t a (t)}
$$

In other words, our forecast for next month (or any month in the future, for that matter) is the average of all sales that have occurred in the past.

The advantage to the average as a forecast is that the average is designed to “dampen” out any fluctuations. Thus, the average takes the noise (which time series techniques assume cannot be forecast anyway) out of the forecast. However, the average also dampens out of the forecast any fluctuations, including such important fluctuations as trend and seasonality. This principle can be demonstrated with a couple of examples.

Figure 3.2 provides a history of sales that has only the time series components of level and noise. The forecast (an average) does a fairly good job of ignoring the noise and forecasting only the level. However, Figure 3.3 illustrates a history of sales that has the time series components of level and noise, plus trend. As will always happen when

![](images/df6f26599bda5add26a47fc64aeb7556743aa6eb36e18d67457cd31660756307.jpg)  
Figure 3.2 Average as a Forecast: Level and Noise

the average is used to forecast data with a trend, the forecast always lags behind the actual data. Because the average becomes more “sluggish” as more data are added, the lagging of the forecast behind the actual sales gets worse over time. If our example in Figure 3.3 had been a negative trend, lagging behind would have meant the average would have always forecast high.

As a final example, Figure 3.4 illustrates a history of sales that has the time series components of level and noise, plus seasonality. Notice that the average has the unfortunate effect of losing (dampening out) the seasonal pattern. Thus, we would lose this important component of any possible forecast.

The conclusion from these three illustrations is that the average should only be used to forecast sales patterns that contain only the time series components of level and noise. Remember that FMTS techniques assume certain patterns exist in the data. In the case of the average, we are assuming there is no trend or seasonality in the data. This is why we stated earlier that the forecast for the next period is also the forecast for all future periods. Because the data are supposed to be level, there should be no pattern of sales increasing (trend) or increasing and

![](images/0c1a5e4aed7fc653e605b5c858df087762e0bc481b7f9b5b7516d81686f3528e.jpg)  
Figure 3.3 Average as a Forecast: Level, Trend, and Noise

![](images/7ae5ae64049791d0641abbcbb33a350cfdebd1a0ac5cf2b078d6dadbdf8c8ba4.jpg)  
Figure 3.4 Average as a Forecast: Level, Seasonality, and Noise

decreasing (seasonality). Therefore, sales should be the same (level) for each period in the future. If nothing else, this demonstrates the rather naïve assumption that accompanies the use of the average as a forecast.

The average as a forecasting technique has the added disadvantage that it requires an ever-increasing amount of data storage. With each successive month, an additional piece of data must be stored for the calculation. With the data storage capabilities of today’s computers, this may not be too onerous a disadvantage, but it does cause the average to be sluggish to changes in level of demand. One last example should illustrate this point. Figure 3.5 shows a data series with little noise, but the level changes. Notice that the average as a forecast never really adjusts to this new level because we cannot get rid of the “old” data (the data from the previous level).

Thus, the average as a forecast does not consider trend or seasonality, and it is sluggish to react to changes in the level of sales. In fact, it does little for us as a forecasting technique, other than give us an excellent starting point. All FMTS techniques were developed to overcome some disadvantage of the average as a forecast. We next explore the first attempt at improvement, a moving average.

![](images/fdc0b55c2081d68c740129bd6fa68b8f9794b0ac3961a8ca5438f5294b820381.jpg)  
Figure 3.5 Average as a Forecast: Level Change

# Moving Average

Rather than use all the previous data in the calculation of an average as the forecast, why not just use some of the more recent data? This is precisely what a moving average does, with the following formula.

$$
F _ {t + 1} = \left(S _ {t} + S _ {t - 1} + S _ {t - 2} + \dots + S _ {t - N - 1}\right) / N \tag {2}
$$

where: $\mathrm { F } _ { \mathrm { t } + 1 } =$ Forecast for Period t + 1

$\mathsf { S } _ { { \mathrm { t } } - 1 } =$ Sales for Period t − 1

N = Number of Periods in the Moving Average

So a three-period moving average would be:

$$
\mathrm {F} _ {\mathrm {t} + 1} = \left(\mathrm {S} _ {\mathrm {t}} + \mathrm {S} _ {\mathrm {t} - 1} + \mathrm {S} _ {\mathrm {t} - 2}\right) / 3
$$

a four-period moving average would be:

$$
F _ {t + 1} = \left(S _ {t} + S _ {t - 1} + S _ {t - 2} + S _ {t - 3}\right) / 4
$$

a five-period moving average would be:

$$
\mathrm {F} _ {\mathrm {t} + 1} = \left(\mathrm {S} _ {\mathrm {t}} + \mathrm {S} _ {\mathrm {t} - 1} + \mathrm {S} _ {\mathrm {t} - 2} + \mathrm {S} _ {\mathrm {t} - 3} + \mathrm {S} _ {\mathrm {t} - 4}\right) / 5
$$

and so on, for as many periods in the moving average as you would like.

The problem with a moving average is deciding how many periods of sales to use in the forecast. The more periods used, the more it starts to look like an average. The fewer periods used, the more reactive the forecast becomes, but the more it starts to look like our naïve technique from Chapter 2 (the forecast for the next period equals the sales from the last period). Applying 3-period, 6-period, and 12-period moving averages to each of the demand patterns in Figures 3.2, through 3.5 (now Figures 3.6 through 3.9, respectively) should illustrate some of these points.

For a time series that has only level and noise (Figure 3.6), our three moving averages work equally well. This is because all dampen out the relatively small amount of noise, and there is no change in level to which to react. Because it uses the least data, the three-period moving average is superior in this case.

However, for the time series with trend added (Figure 3.7), very different results are obtained. The longer the moving average, the less reactive the forecast, and the more the forecast lags behind the trend (because it is more like the average). Again, this is because moving averages were not really designed to deal with a trend, but the shorter moving averages adjust better (are more reactive) than the longer in this case.

An interesting phenomenon occurs when we look at the use of moving averages to forecast time series with seasonality (Figure 3.8). Notice that both the three-period and the six-period moving averages lag behind the seasonal pattern (forecast low when sales are rising and forecast high when sales are falling) and miss the turning points in the time series. Notice also that the more reactive moving average (three-period) does a better job of both of these. This is because in the short run (defined here as between turning points), the seasonal pattern simply looks like trend to a moving average.

However, the 12-period moving average simply ignores the seasonal pattern. This is due to the fact that any average dampens out

![](images/f5cc290d4fbfec61cef18865903d1d40ea314452f8df8180e58ae460cb91ac2f.jpg)  
Figure 3.6 Moving Average as a Forecast: Level and Noise

![](images/6e3b7c3bf164e689f13812c31fb522b318f51aea680349ab599188c8f29b0bb1.jpg)  
Figure 3.7 Moving Average as a Forecast: Level, Trend, and Noise

![](images/923dd85a5dc8f3d38577cea716eb7ed64617c697b392e8a4807a8cb405bc3e6f.jpg)  
Figure 3.8 Moving Average as a Forecast: Level, Seasonality, and Noise

![](images/184534b2edf24562e46c2336c488d870fdff9a9ae24da5971df4794e50577122.jpg)  
Figure 3.9 Moving Average as a Forecast: Level Changes

random fluctuations (noise) and any patterns that are the same length as the average. Because this time series has a 12-month seasonal pattern, a 12-month moving average completely loses the seasonal component in its forecast. This is particularly dangerous when you consider how many sales managers use a simple 12-month moving average to generate a forecast—they are inadvertently dampening out the seasonal fluctuations from their forecasts.

Finally, let’s look at the time series where the level changes (Figure 3.9). Again, the longer moving average tends to dampen out the noise better than the shorter moving average, but the shorter moving average reacts more quickly to the change in level.

Thus, what we need in a moving average is one that acts like an average when there is only noise in the time series (dampens out the noise but uses less data than an average), but acts like a naïve forecast when the level changes (puts more weight on what happened very recently). The problem with this is how to recognize the difference in a change that is noise, as opposed to a change in level, a trend, or a seasonal pattern.

A final problem with the moving average is that the same weight is put on all past periods of data in determining the forecast. It is more reasonable to put greater weight on the more recent periods than the older periods (especially when a longer moving average is used). Therefore, the question when using a moving average becomes how many periods of data to use and how much weight to put on each of those periods. To answer this question about moving averages, a technique called exponential smoothing was developed.

# Exponential Smoothing

Exponential smoothing is the basis for almost all FMTS techniques in use today. It is easier to understand this technique if we acknowledge that it was originally called an “exponentially weighted moving average.” Obviously, the original name was too much of a mouthful for everyday use, but it helps us to explain how this deceptively complex technique works. We are going to develop a moving average, but we will weight the more recent periods of sales more heavily in the forecast, and the weights for the older periods will decrease at an exponential rate (which is where the “exponential smoothing” term came from).

Regardless of that rather scary statement, we are going to accomplish this with a very simple calculation (Brown & Meyer, 1961).

$$
F _ {t + 1} = \alpha S _ {t} + (1 - \alpha) F _ {t} \tag {3}
$$

where: $\mathrm { F _ { t } } =$ Forecast for Period t

$\mathrm { S _ { t } = }$ Sales for Period t

$0 < \alpha < 1$

In other words, our forecast for next period (or, again, any period in the future) is a function of last period’s sales and last period’s forecast, with this $\alpha$ thing thrown in to confuse us.

What we are actually doing with this exponential smoothing formula is merely a weighted average. Because α is a positive fraction (that is, between 0 and 1), ${ 1 - \alpha }$ is also a positive fraction, and the two of them add up to 1. Any time we take one number and multiply it by a positive fraction, take a second number and multiply it by the reciprocal of the positive fraction (another way of saying 1 − the first

fraction), and add the two results together, we have merely performed a weighted average. Several examples should help:

1. When we want to average two periods’ sales (Period 1 was 50 and Period 2 was 100, for example) and not put more weight on one than the other, we are actually calculating it as $( ( 0 . 5 \times 5 0 ) +$ $( 0 . 5 \times 1 0 0 ) ) = 7 5$ . We simply placed the same weight on each period. Notice that this gives us the same result as if we had done the simpler equal-weight average calculation of $( 5 0 + 1 0 0 ) / 2$ .   
2. When we want the same two periods of sales but want to put three times as much weight on Period 2 (for reasons we will explain later), the calculation would now be $( ( 0 . 2 5 \times 5 0 ) +$ $( 0 . 7 5 \times 1 0 0 ) ) = 8 7 . 5 .$ Notice that in this case $\alpha$ would be 0.25 and ${ 1 - \alpha }$ would be 0.75.   
3. Finally, if we want nine times as much weight on Period 2, the resultant calculation would be $( ( 0 . 1 \times 5 0 ) + ( 0 . 9 \times 1 0 0 ) ) = 9 5 .$ Again, notice that in this case α would be 0.1 and ${ 1 - \alpha }$ would be 0.9.

Therefore, we can control how much emphasis in our forecast is placed on what sales actually were last period. But what is the purpose of using last period’s forecast as part of next period’s forecast? This is where exponential smoothing is “deceptively complex” and requires some illustration.

For the purpose of this illustration, let’s assume that on the evening of the last day of each month, we make a forecast for the next month. Let’s also assume that we have decided to use exponential smoothing and to put $1 0 \%$ of the weight of our forecast on what happened last month. Further, let’s assume this is the evening of the last day of June. Thus, our value for $\alpha$ would be 0.1 and our forecast for July would be:

$$
\mathrm {F} _ {\mathrm {J U L Y}} = . 1 \mathrm {S} _ {\mathrm {J U N E}} +. 9 \mathrm {F} _ {\mathrm {J U N E}}
$$

But where did we get the forecast for June? In fact, a month ago on the evening of the last day of May, we made this forecast:

$$
\mathrm {F} _ {\text {J U N E}} = . 1 \mathrm {S} _ {\text {M A Y}} +. 9 \mathrm {F} _ {\text {M A Y}}
$$

Again, where did we get the forecast for May? And again, a month ago on the evening of the last day of April, we made this forecast:

$$
\mathrm {F} _ {\text {M A Y}} = . 1 \mathrm {S} _ {\text {A P R I L}} +. 9 \mathrm {F} _ {\text {A P R I L}}
$$

We could keep this up forever, but suffice it to say that each month the forecast from the previous month has in it the forecasts (and the sales) from all previous months. Thus, $1 0 \%$ of the forecast for July is made up of sales from June, but the other $9 0 \%$ is made up of the forecast for June. However, the forecast for June was made up of $1 0 \%$ of the sales from May. Thus, $9 0 \%$ times $1 0 \%$ (or $9 \%$ ) of the July forecast is made up of the sales from May. The rest of the forecast for June was made up of $9 0 \%$ of the forecast for May, which in turn was made up of $1 0 \%$ of the sales from April (so April sales comprises $9 0 \%$ times $9 0 \%$ times $1 0 \% ,$ or $8 . 1 \% ,$ of the July forecast) and $9 0 \%$ of the forecast from April, and so on back to where we made our first forecast. This leads us to the fact that the forecast for July is actually made up of the following rather complicated formula:

$$
\begin{array}{l} F _ {J U L Y} = . 1 S _ {J U N E} + (. 9) (. 1) S _ {M A Y} + (. 9) ^ {2} (. 1) S _ {A P R I L} \\ + (. 9) ^ {3} (. 1) S _ {\text {M A R C H}} + \dots + (. 9) ^ {N} (. 1) S _ {\text {J U L Y - (N + 1)}} \\ \end{array}
$$

If we take a second to study this formula, we see that sales from June make up $1 0 \%$ of our forecast, sales from May make up $9 \%$ $( . 9 \times . 1 )$ of our forecast, sales from April make up $8 . 1 \%$ $( . 9 \times . 9 \times . 1 )$ of our forecast, sales from March make up $7 . 2 \%$ $\cdot 9 \times . 9 \times . 9 \times . 1 )$ of our forecast, and so on back to the first month we used this technique.

What is happening with the rather simple-looking exponential smoothing formula is that we are putting α weight on last period’s sales, $\alpha$ times $( 1 - \alpha )$ weight on the previous period’s sales, and changing the weight for each previous period’s sales by multiplying the weight by $( 1 - \alpha )$ for each successive period we go into the past.

For $\alpha = 0 . 1 ,$ , this causes the weights for the previous period’s sales to decrease at the following exponential rate: 0.1, 0.09, 0.081, 0.072, 0.063, . . . and for $ \alpha = 0 . 2$ , the weights for the previous period’s sales to decrease at the following exponential rate: 0.2, 0.16, 0.128, 0.1024, 0.08192, . . .

We could try to develop a similar series for every value of α (by the way, the possible values of $\alpha$ between 0 and 1 are infinite, so our attempt might take a while), but it is not necessary—the simple

exponential smoothing formula does it for us. We do need to remember, however, that the higher the value of $\mathbf { \alpha } _ { \mathrm { ~ \tiny ~ Q ~ } , }$ the more weight we are putting on last period’s sales and the less weight we are putting on all the previous periods combined. In fact, as α approaches one, exponential smoothing puts so much weight on the past period’s sales and so little on the previous periods combined, that it starts to look like our naïve technique $\left( \mathrm { F } _ { \mathrm { t + 1 } } \right) =  { S _ { \mathrm { t } } } ,$ ) from Chapter 2. Conversely, as $\alpha$ approaches zero, exponential smoothing puts more equal weight on all periods and starts to look much like the average as a forecast.

This leads us to some conclusions about what the value of α should be:

1. The more the level changes, the larger α should be, so that exponential smoothing can quickly adjust.   
2. The more random the data, the smaller α should be, so that exponential smoothing can dampen out the noise.

Several examples should help illustrate these conclusions. For our first illustration, we can use the data pattern from Figure 3.9 for the moving average, now Figure 3.10 for exponential smoothing.

![](images/0ae75803c79e4c0726645770c0937206dc864fe8cfaf7ffce1a172e58bca40ca.jpg)  
Figure 3.10 Exponential Smoothing as a Forecast: Level Change

In Figure 3.10, we can see three exponential smoothing forecasts of the time series. All three do a fairly good job when the level is stable, but the higher the value of $\alpha$ in the forecast, the quicker it reacts to the change in level. Because a low value of $\alpha$ is much like an average, the forecast for the low α never quite reaches the new level.

However, a very different result is found when we observe the forecasts of the time series in Figures 3.11 and 3.12. Figure 3.11 is a reproduction of the data series used in Figures 3.2 and 3.6 and represents a time series with no trend and a low amount of noise. In this series, the exponential smoothing forecasts with various levels of α all perform fairly well. However, in the time series of Figure 3.12, which has a stable level but a high amount of noise, the forecasts with the higher values of $\alpha$ overreact to the noise and, as a result, jump around quite a bit. The forecast with the lower level of α does a better job of dampening out the noise.

Given these illustrations of our conclusions about the value of $\alpha$ that should be used, we have in exponential smoothing a technique that overcomes many of the problems with the average and the moving average as forecasting techniques. Exponential smoothing is less

![](images/091b52a2b4543820968fb60b3217d714509f889572a79171cc4b1ec9334ace7e.jpg)  
Figure 3.11 Exponential Smoothing as a Forecast: Low Noise

![](images/f783c92de6176fc1032324edfe5d7b7abba80f924274f320d71a1138aedce5dd.jpg)  
Figure 3.12 Exponential Smoothing Average as a Forecast: High Noise

cumbersome than the average because exponential smoothing only requires the values of last period’s sales and forecast and the value of α. Exponential smoothing solves the problems with the moving average of how much data to use and how to weight it by using an exponentially decreasing weight for all previous periods.

However, with exponential smoothing we are still faced with a dilemma: How do we determine whether the level is changing or if it is simply noise and, thus, what the value of α should be? To answer this dilemma, the next group of techniques (called adaptive smoothing) was developed.

# Adaptive Smoothing

Although a number of adaptive smoothing techniques exist, they all have one thing in common: each is an attempt to automatically select the value of α. Because there are so many adaptive smoothing techniques and they all work essentially equally well, we will only discuss the simplest of this group of techniques here. This adaptive smoothing approach uses the absolute value of the percent error from

the previous period’s forecast to adjust the value of $\alpha$ for the next period’s forecast (Trigg & Leach, 1967). Thus, the original exponential smoothing formula is still used:

$$
F _ {t + 1} = \alpha S _ {t} + (1 - \alpha) F _ {t} \tag {4}
$$

but after each period’s sales are recorded, the value of $\alpha$ is adjusted for the next period by the following formula:

$$
\alpha_ {t + 2} = \left| \left(F _ {t + 1} - S _ {t + 1}\right) / S _ {t + 1} \right| = \left| P E _ {t + 1} \right| \tag {5}
$$

Because Equation (5) can produce values outside the range of $\scriptstyle { \mathfrak { Q } } ,$ this calculation is adjusted by the following rules:

If $| \mathrm { P E } _ { \mathrm { t } + 1 } |$ is equal to or greater than 1.0, then $\alpha _ { { \mathrm { t } } + 2 } = 0 . 9 9 9 9 9$

If $| \mathrm { P E } _ { \mathrm { t } + 1 } |$ is equal to 0.0, then $\alpha _ { { \mathrm { t } } + 2 } = 0 . 0 0 0 0 1$

We can illustrate the adaptability of this technique by forecasting the times series with level change in Figure 3.10, now Figure 3.13 for

![](images/cf4ac54b7f2d5519f1f1aaa5bf850ccc4a175a19d09152722daf509934633935.jpg)  
Figure 3.13 Adaptive Smoothing as a Forecast: Level Change

adaptive smoothing. To illustrate the changes in α that result in this technique, the calculations are also reproduced in Table 3.1.

To get the process started, we used the usual convention of setting the initial value of $\alpha$ at 0.1, although any value can be chosen without changing the resultant forecasts. The reason for this is that we also assume that the initial forecast was equal to the first period demand, so the first forecast becomes:

$$
\mathrm {F} _ {2} = \alpha \mathrm {S} _ {1} + (1 - \alpha) \mathrm {S} _ {1}
$$

So regardless of the initial value of $\alpha$ that is chosen, the forecast for period two is always equal to sales from period one. The true calculation of a forecast and the adapted values of $\alpha$ begin at that point.

Notice that the value of α stays low (well below 0.1) while the time series is level (a low value of $\alpha$ dampens out the noise), but as soon as the level changes, the value of α jumps dramatically to adjust. Once the time series levels off, the value of $\alpha$ again returns to a low level.

This adaptive smoothing technique overcomes one of the major problems with exponential smoothing: what should be the value chosen for α? However, all the techniques we have discussed so far have a common problem: none of them considers trend or seasonality. Since this technique assumes there is no trend or seasonality, our forecast of January 2004 is 1950 and is also our forecast for every month in 2004— we assume there will be no general increase or decrease in sales (trend), nor will there be any pattern of fluctuation in sales (seasonality). Because this is unrealistic for many business demand situations, we need some way to incorporate trend and seasonality into our FMTS forecasts. To do so, we temporarily set aside the concept of smoothing constant adaptability and introduce first trend and then seasonality into our exponential smoothing calculations.

# Exponential Smoothing With Trend

Although we tend to think of trend as a straight or curving line going up or down, for the purposes of exponential smoothing, it is helpful to think of trend as a series of changes in the level. In other words, with each successive period, the level either “steps $\mathrm { u p ^ { \prime \prime } }$ or “steps down.” This “step function,” or changing level pattern, of trend is conceptually illustrated in Figure 3.14. Although demand is going up

Table 3.1 Adaptive Smoothing Forecast Calculations   

<table><tr><td>Month</td><td>Demand</td><td>Forecast</td><td>Percent Error</td><td>Absolute PE or αt+1</td></tr><tr><td>J01</td><td>1010</td><td></td><td></td><td></td></tr><tr><td>F01</td><td>920</td><td>1010</td><td>0.098</td><td>0.098</td></tr><tr><td>M01</td><td>1020</td><td>1002</td><td>-0.018</td><td>0.018</td></tr><tr><td>A01</td><td>1040</td><td>1002</td><td>-0.037</td><td>0.037</td></tr><tr><td>M01</td><td>960</td><td>1003</td><td>0.045</td><td>0.045</td></tr><tr><td>J01</td><td>1000</td><td>1001</td><td>0.001</td><td>0.001</td></tr><tr><td>J01</td><td>960</td><td>1001</td><td>0.043</td><td>0.043</td></tr><tr><td>A01</td><td>960</td><td>999</td><td>0.041</td><td>0.041</td></tr><tr><td>S01</td><td>1040</td><td>998</td><td>-0.041</td><td>0.041</td></tr><tr><td>O01</td><td>960</td><td>999</td><td>0.041</td><td>0.041</td></tr><tr><td>N01</td><td>940</td><td>998</td><td>0.061</td><td>0.061</td></tr><tr><td>D01</td><td>1040</td><td>994</td><td>-0.044</td><td>0.044</td></tr><tr><td>J02</td><td>1920</td><td>996</td><td>-0.481</td><td>0.481</td></tr><tr><td>F02</td><td>2020</td><td>1441</td><td>-0.287</td><td>0.287</td></tr><tr><td>M02</td><td>1920</td><td>1607</td><td>-0.163</td><td>0.163</td></tr><tr><td>A02</td><td>2040</td><td>1658</td><td>-0.187</td><td>0.187</td></tr><tr><td>M02</td><td>2080</td><td>1729</td><td>-0.169</td><td>0.169</td></tr><tr><td>J02</td><td>1920</td><td>1789</td><td>-0.068</td><td>0.068</td></tr><tr><td>J02</td><td>2040</td><td>1798</td><td>-0.119</td><td>0.119</td></tr><tr><td>A02</td><td>2080</td><td>1826</td><td>-0.122</td><td>0.122</td></tr><tr><td>S02</td><td>1920</td><td>1857</td><td>-0.033</td><td>0.033</td></tr><tr><td>O02</td><td>1900</td><td>1859</td><td>-0.021</td><td>0.021</td></tr><tr><td>N02</td><td>2080</td><td>1860</td><td>-0.106</td><td>0.106</td></tr><tr><td>D02</td><td>2080</td><td>1883</td><td>-0.095</td><td>0.095</td></tr><tr><td>J03</td><td>1900</td><td>1902</td><td>-0.001</td><td>0.001</td></tr><tr><td>F03</td><td>2000</td><td>1902</td><td>-0.049</td><td>0.049</td></tr><tr><td>M03</td><td>2040</td><td>1907</td><td>-0.065</td><td>0.065</td></tr><tr><td>A03</td><td>1920</td><td>1916</td><td>-0.002</td><td>0.002</td></tr><tr><td>M03</td><td>1980</td><td>1916</td><td>-0.033</td><td>0.033</td></tr><tr><td>J03</td><td>2100</td><td>1918</td><td>-0.087</td><td>0.087</td></tr><tr><td>J03</td><td>2060</td><td>1933</td><td>-0.061</td><td>0.061</td></tr><tr><td>A03</td><td>1980</td><td>1941</td><td>-0.020</td><td>0.020</td></tr><tr><td>S03</td><td>2000</td><td>1942</td><td>-0.029</td><td>0.029</td></tr><tr><td>O03</td><td>2040</td><td>1944</td><td>-0.047</td><td>0.047</td></tr><tr><td>N03</td><td>1960</td><td>1948</td><td>-0.006</td><td>0.006</td></tr><tr><td>D03</td><td>2000</td><td>1948</td><td>-0.026</td><td>0.026</td></tr><tr><td>J04</td><td></td><td>1950</td><td></td><td></td></tr></table>

![](images/f891e9a89f390bf63d54c0a668f852195525f6219d452ad63d498aab6e27b376.jpg)  
Figure 3.14 Trend in a Time Series

in a straight line, we can conceive of it as a series of increases in the level (the dashed horizontal lines). This is much like climbing a set of stairs. Although we make steady progress up the stairs, we are actually stepping up one step each period (the amount we step up, or the height of each step, on a set of stairs is called the riser). The height of each step (the riser) is what we call “trend” in exponential smoothing, and that trend is designated in Figure 3.14 as T. For period $\mathbf { t } + 1 .$ , the trend is the amount the level changed from period t to period $\mathrm { t } + 1 ( \mathrm { L } _ { \mathrm { t + 1 } } - \mathrm { L } _ { \mathrm { t } } ) ,$ , or $\mathrm { T } _ { { \mathrm { t } } + 1 }$ . Similarly for period $\tan ( 2 ,$ the trend is the amount the level changed from period $\mathbf { t } + 1$ to period $\mathrm { t } + 2$ $( \mathrm { L } _ { { \mathrm { t } } + 2 } - \mathrm { L } _ { { \mathrm { t } } - 1 } ) .$ , or $\mathrm { T } _ { { \mathrm { t } } + 2 }$ .

To understand the calculation of trend in exponential smoothing, we must also understand that an exponential smoothing calculation is just a weighted average of two measures of the same thing. Our original exponential smoothing formula (Equation 4) was:

$$
F _ {t + 1} = \alpha S _ {t} + (1 - \alpha) F _ {t}
$$

In this calculation, $\mathrm { S } _ { \mathrm { t } }$ is one measure of past sales (last period’s sales) and $\mathrm { F _ { t } }$ is another measure of past sales (a weighted average

of sales in all periods prior to t). Thus, we were taking a weighted average of two measures of the same thing. We are now going to do the same thing for level and trend with the following formulae (Holt et al., 1960):

$$
\mathrm {L} _ {\mathrm {t}} = \alpha \mathrm {S} _ {\mathrm {t}} + (1 - \alpha) \left(\mathrm {L} _ {\mathrm {t} - 1} + \mathrm {T} _ {\mathrm {t} - 1}\right) \tag {6}
$$

$$
T _ {t} = \beta \left(L _ {t} - L _ {t - 1}\right) + (1 - \beta) T _ {t - 1} \tag {7}
$$

where: $\mathrm { L } =$ Level

$\mathrm { T } =$ Trend

$$
0 <   \alpha <   1
$$

$$
0 <   \beta <   1
$$

Notice that Equation (6) looks very similar to our earlier exponential smoothing forecast calculation—we still use α in the same way and we still use last period’s sales. This difference is the addition of trend into the second part of Equation (6) and the fact that it is not a forecast for next period $( \mathrm { F } _ { \mathrm { t } + 1 } )$ but rather a measure of level for this period (L ). In fact, in our original exponential smoothing formula (Equation [4]), we did not include trend because we assumed it did not exist. Because trend was assumed not to exist, our estimate of level this period was our forecast of next period.

What we need are two estimates of level for this period so we can exponentially smooth them. The first estimate is simply sales for this period. Since we assume there is no seasonality in the time series (an assumption we will discard in the next section), then this sales value has no seasonality in it. Because the trend is a change in level from one period to the next, any given value of sales does not have trend in it (that is, trend is in the change in sales from one period to the next, not any single sales value). Finally, when we perform the weighted averaging of the exponential smoothing calculation in Equation (6), we get rid of the noise. (Remember that averaging removes noise.) Since this logic says there is no trend or seasonality in the sales value and we will get rid of this noise when we do our exponential smoothing calculation, we are only left with one time series component in the sales value, and that component is level.

The second estimate of level is our estimate of level from last period, plus the estimate of how much level should have changed from

last period to this period (that is, the trend). This gives us two measures of level to exponentially smooth with α.

Our two estimates of trend in Equation (7) are how much the level changed from last period to this period and our estimate of trend from last period. These two measures of trend are exponentially smoothed with our new smoothing constant, β. $\beta$ is just like $\alpha$ in that it is a positive fraction (that is, between zero and one). It is designated by a different Greek symbol to indicate that α and $\beta$ can have different values.

Once we have our new estimates of level (L) and trend (T), we can forecast as far into the future as we want by taking the level and adding to it the trend per period times as many periods into the future as we want the forecast. This can be represented by the following formula:

$$
F _ {t + m} = L _ {t} + \left(T _ {t} \times m\right) \tag {8}
$$

where: $\mathbf { m } =$ the number of periods into the future to forecast.

To illustrate this technique, consider the time series with trend introduced in Figure 3.3, now Figure 3.15 for exponential smoothing with trend. To illustrate the calculations involved in this technique, Table 3.2 provides the calculations of level and trend and a forecast forward for one period throughout the time series (also provided in Figure 3.15). For the purposes of illustration, we arbitrarily chose the value of 0.1 for $\alpha$ and the value of 0.2 for $\beta$ . Notice that to get the process started, we used the usual convention of assuming the level for the first period equaled first period demand, and the trend for the first period equaled the change in demand from the first to the second period.

To provide a forecast for any period more than one in the future (April 2004, for example), it is merely a task of taking the most recent value of level that has been calculated (in this case, December 2003) and adding to it the most recent value of trend that has been calculated (also in this case, December 2003) times the number of months into the future that we wish to forecast (because April is four months past December, it would be times four). For April 2004, the calculations are:

$$
\mathrm {F} _ {\mathrm {A} 0 4} = \mathrm {L} _ {\mathrm {D} 0 3} + (\mathrm {T} _ {\mathrm {D} 0 3} \times \mathrm {m})
$$

$$
F _ {A 0 4} = 4 6 1 4 + (1 0 6 \times 4)
$$

$$
\mathrm {F} _ {\mathrm {A 0 4}} = 5 0 3 8
$$

![](images/edfde9055039849eec6fa51c2da2ddbdbec3d791352531e024e2ddac77229dad.jpg)  
Figure 3.15 Exponential Smoothing With Trend as a Forecast

Now that we have the logic for introducing trend into the exponential smoothing calculations, it is fairly easy to also bring in seasonality.

# Exponential Smoothing With Trend and Seasonality

To introduce seasonality, let’s first think of a simple demand example where we sell 12,000 units of a product every year. If there is no trend, no noise, and no seasonality, we would expect to sell 1,000 units every month (that is, the level). If, however, we noticed that every January we sold, on average, 1,150 units, there is clearly a pattern here of selling more than the level in January. In fact, we are selling 1,150/1,000, or 1.15, times the level.

This value of 1.15 is called a multiplicative seasonal adjustment and means that sales in that month are $1 5 \%$ higher than they would be without a seasonal pattern. Similarly, a seasonal adjustment of 1.00 means that sales are right at the non-seasonal level, and a seasonal adjustment of 0.87 means that sales are $1 3 \%$ below what we would expect if there was no seasonal pattern.

Table 3.2 Exponential Smoothing With Trend Forecast Calculations   

<table><tr><td>Month</td><td>Demand</td><td>Level (α = 0.1)</td><td>Trend (β = 0.2)</td><td>Forecast</td></tr><tr><td>J01</td><td>1010</td><td>1010</td><td>10</td><td></td></tr><tr><td>F01</td><td>1020</td><td>1020</td><td>10</td><td></td></tr><tr><td>M01</td><td>1220</td><td>1049</td><td>14</td><td>1030</td></tr><tr><td>A01</td><td>1340</td><td>1091</td><td>19</td><td>1063</td></tr><tr><td>M01</td><td>1360</td><td>1135</td><td>24</td><td>1110</td></tr><tr><td>J01</td><td>1500</td><td>1193</td><td>31</td><td>1159</td></tr><tr><td>J01</td><td>1560</td><td>1258</td><td>38</td><td>1224</td></tr><tr><td>A01</td><td>1660</td><td>1332</td><td>45</td><td>1296</td></tr><tr><td>S01</td><td>1840</td><td>1424</td><td>54</td><td>1377</td></tr><tr><td>O01</td><td>1860</td><td>1516</td><td>62</td><td>1478</td></tr><tr><td>N01</td><td>1940</td><td>1615</td><td>69</td><td>1578</td></tr><tr><td>D01</td><td>2140</td><td>1729</td><td>78</td><td>1684</td></tr><tr><td>J02</td><td>2120</td><td>1839</td><td>85</td><td>1808</td></tr><tr><td>F02</td><td>2320</td><td>1963</td><td>93</td><td>1924</td></tr><tr><td>M02</td><td>2440</td><td>2094</td><td>100</td><td>2056</td></tr><tr><td>A02</td><td>2420</td><td>2217</td><td>105</td><td>2195</td></tr><tr><td>M02</td><td>2620</td><td>2352</td><td>111</td><td>2322</td></tr><tr><td>J02</td><td>2620</td><td>2478</td><td>114</td><td>2462</td></tr><tr><td>J02</td><td>2840</td><td>2617</td><td>119</td><td>2592</td></tr><tr><td>A02</td><td>2980</td><td>2760</td><td>124</td><td>2736</td></tr><tr><td>S02</td><td>2920</td><td>2887</td><td>124</td><td>2884</td></tr><tr><td>O02</td><td>3000</td><td>3011</td><td>124</td><td>3012</td></tr><tr><td>N02</td><td>3280</td><td>3149</td><td>127</td><td>3135</td></tr><tr><td>D02</td><td>3380</td><td>3287</td><td>129</td><td>3277</td></tr><tr><td>J03</td><td>3300</td><td>3404</td><td>127</td><td>3416</td></tr><tr><td>F03</td><td>3500</td><td>3528</td><td>126</td><td>3531</td></tr><tr><td>M03</td><td>3640</td><td>3653</td><td>126</td><td>3654</td></tr><tr><td>A03</td><td>3620</td><td>3763</td><td>123</td><td>3779</td></tr><tr><td>M03</td><td>3780</td><td>3875</td><td>121</td><td>3886</td></tr><tr><td>J03</td><td>4000</td><td>3996</td><td>121</td><td>3996</td></tr><tr><td>J03</td><td>4060</td><td>4111</td><td>120</td><td>4117</td></tr><tr><td>A03</td><td>4080</td><td>4216</td><td>117</td><td>4231</td></tr><tr><td>S03</td><td>4200</td><td>4319</td><td>114</td><td>4332</td></tr><tr><td>O03</td><td>4340</td><td>4424</td><td>112</td><td>4433</td></tr><tr><td>N03</td><td>4360</td><td>4518</td><td>109</td><td>4536</td></tr><tr><td>D03</td><td>4500</td><td>4614</td><td>106</td><td>4627</td></tr><tr><td>J04</td><td></td><td></td><td></td><td>4720</td></tr></table>

We are now going to use this concept of a multiplicative seasonal adjustment to introduce seasonality into the exponential smoothing calculations. Again, we will develop two different measures of each seasonal adjustment and take a weighted average of them (through exponential smoothing) to come up with our new estimate. To do this, however, we also need to update our formulae for Exponential Smoothing with Trend (Equations [6] and [7]) to take into account the fact that seasonality is now assumed to exist. This leads us to the following formulae (Winters, 1960):

$$
\mathrm {L} _ {\mathrm {t}} = \alpha \left(\mathrm {S} _ {\mathrm {t}} / \mathrm {S A} _ {\mathrm {t} - \mathrm {C}}\right) + (1 - \alpha) \left(\mathrm {L} _ {\mathrm {t} - 1} + \mathrm {T} _ {\mathrm {t} - 1}\right) \tag {9}
$$

$$
\mathrm {T} _ {\mathrm {t}} = \beta \left(\mathrm {L} _ {\mathrm {t}} - \mathrm {L} _ {\mathrm {t} - 1}\right) + (1 - \beta) \mathrm {T} _ {\mathrm {t} - 1} \tag {10}
$$

$$
\mathrm {S A} _ {\mathrm {t}} = \gamma \left(\mathrm {S} _ {\mathrm {t}} / \mathrm {L} _ {\mathrm {t}}\right) + (1 - \gamma) \left(\mathrm {S A} _ {\mathrm {t} - \mathrm {C}}\right) \tag {11}
$$

where: $\mathrm { { L } = }$ Level

$\mathrm { T = }$ Trend

$\mathrm { S A } _ { \mathrm { t } } =$ Seasonal Adjustment for Period t

$C =$ The Cycle Length of the Seasonal Pattern (that is, the cycle length for a 12-month pattern is $C = 1 2$ )

$$
0 <   \alpha <   1
$$

$$
0 <   \beta <   1
$$

$$
0 <   \gamma <   1
$$

We have revised our calculation for level to take seasonality into account in our first estimate of level. Recalling our previous example of annual sales of 12,000, how would we take the seasonality out of January sales? If sales were 1,150 and our previous estimates of the seasonality adjustment for January were 1.15, we can de-seasonalize January sales simply by dividing the sales value of 1,150 by the seasonal adjustment of 1.15. This gives us a de-seasonalized value of 1,000—precisely the value we said was the expected level if there were no seasonality.

Thus, by dividing sales for any period by the seasonal adjustment for the same period last year (that is, divide sales for January 2004 by the seasonal adjustment for January 2003), we have an estimate in the first formula of level with the seasonality taken out (recall that the original formula already took out the trend and the noise). Because the second part of this formula contains the level from the last period,

which was de-seasonalized at that time, we now have two estimates of level to exponentially smooth.

Thankfully, the formula for trend (Equation [10]) does not change. Therefore, we do not have to revisit it here.

However, we now have added a formula to calculate the seasonal adjustments (Equation [11]). Again, we need two estimates of the seasonal adjustment for each period, so we can exponentially smooth each. This means we have 12 of these calculations per year if we are forecasting monthly sales, 52 if we are forecasting weekly, and 4 if we are forecasting quarterly.

The first part of Equation (11) is, again, a throwback to our initial example. If we take the sales value for this period and divide it by the most recently calculated level (which was just done two formulas before and is L ), we have one estimate of the seasonal adjustment for this period. In our initial example, we did the same thing when we divided 1,150 by 1,000 to obtain 1.15 as our estimate of the seasonal adjustment for January.

For our second estimate of the seasonal adjustment for this period, we need to look back one year to the same period last year. We can now exponentially smooth these two estimates of the seasonal adjustment for this period using the smoothing constant, γ. Again, γ is just like α and $\beta$ in that it is a positive fraction (that is, between zero and one). It is designated by a different Greek symbol to indicate that α, β, and $\gamma$ can all have different values.

Once we have our new estimates of level (L), trend (T), and seasonal adjustments (SA), we can forecast as far into the future as we want by taking the level, adding to it the trend per period times as many periods into the future as we want the forecast, and multiplying that result by the most recent seasonal adjustment for that period. This can be represented by the following formula:

$$
F _ {t + m} = \left(L _ {t} + \left(T _ {t} \times m\right)\right) \times S A _ {t - C + m} \tag {12}
$$

where: $\mathbf { m } =$ the number of periods into the future to forecast.

The last component of Equation (12) probably needs a little illustration. If we have just received sales for December 2003 and want to forecast April 2004, we will use the values of L and T calculated in December 2003 (in this case, December 2003 is $\prime \prime { \sf t } ^ { \prime \prime }$ ) for the first part of the forecast. However, our most recent estimate of the seasonal adjustment for April was calculated back in

April 2003. The symbol to represent using this value is to take $\prime \prime { \sf t } ^ { \prime \prime }$ (December 2003); subtract C, or 12, months from it (placing us in December 2002); and add to it m, or 4, months to bring us to the seasonal adjustment for April 2003.

To illustrate this technique, we will go all the way back to our original time series with trend and seasonality introduced in Figure 3.1, now Figure 3.16, for exponential smoothing with trend and seasonality. To illustrate the calculations involved in this technique, Table 3.3 provides the calculation of level, trend, seasonality, and a forecast forward for one period throughout the time series (also provided in Figure 3.16). For the purposes of illustration, we arbitrarily chose the value of 0.1 for $\scriptstyle { \mathfrak { Q } } ,$ the value of 0.2 for $\beta ,$ and the value of 0.15 for $\gamma .$ Notice that to get the process started, we used the usual convention of assuming the level for the first period equaled first period demand, the trend for the first period equaled the change in demand from the first to the second period, and the initial 12 seasonal adjustment values were equal to 1.00. Notice, also, that this technique does a pretty terrible job

![](images/ba22f3b87f2648332a3966849a6e878ff67d0cccb63e14d858732bc6d8f07936.jpg)  
Figure 3.16 Exponential Smoothing With Trend and Seasonality as a Forecast

Table 3.3 Exponential Smoothing With Trend and Seasonality Forecast Calculations   

<table><tr><td>Month</td><td>Demand</td><td>Level (α = 0.1)</td><td>Trend (β = 0.2)</td><td>Seasonality (γ = 0.15)</td><td>Forecast</td></tr><tr><td>J01</td><td>1104</td><td>1104</td><td>-219</td><td>1.00</td><td></td></tr><tr><td>F01</td><td>885</td><td>885</td><td>-219</td><td>1.00</td><td>885</td></tr><tr><td>M01</td><td>976</td><td>697</td><td>-213</td><td>1.06</td><td>666</td></tr><tr><td>A01</td><td>1101</td><td>546</td><td>-200</td><td>1.15</td><td>484</td></tr><tr><td>M01</td><td>1120</td><td>423</td><td>-185</td><td>1.25</td><td>345</td></tr><tr><td>J01</td><td>1276</td><td>342</td><td>-164</td><td>1.41</td><td>238</td></tr><tr><td>J01</td><td>1419</td><td>302</td><td>-139</td><td>1.56</td><td>178</td></tr><tr><td>A01</td><td>1615</td><td>308</td><td>-110</td><td>1.64</td><td>162</td></tr><tr><td>S01</td><td>1836</td><td>361</td><td>-78</td><td>1.61</td><td>197</td></tr><tr><td>O01</td><td>1730</td><td>428</td><td>-49</td><td>1.46</td><td>284</td></tr><tr><td>N01</td><td>1686</td><td>510</td><td>-22</td><td>1.35</td><td>380</td></tr><tr><td>D01</td><td>1769</td><td>616</td><td>3</td><td>1.28</td><td>488</td></tr><tr><td>J02</td><td>1521</td><td>709</td><td>21</td><td>1.17</td><td>619</td></tr><tr><td>F02</td><td>1504</td><td>808</td><td>37</td><td>1.13</td><td>730</td></tr><tr><td>M02</td><td>1478</td><td>899</td><td>48</td><td>1.15</td><td>895</td></tr><tr><td>A02</td><td>1480</td><td>981</td><td>54</td><td>1.21</td><td>1091</td></tr><tr><td>M02</td><td>1726</td><td>1070</td><td>61</td><td>1.30</td><td>1291</td></tr><tr><td>J02</td><td>1759</td><td>1143</td><td>64</td><td>1.43</td><td>1595</td></tr><tr><td>J02</td><td>2137</td><td>1223</td><td>67</td><td>1.58</td><td>1877</td></tr><tr><td>A02</td><td>2436</td><td>1310</td><td>71</td><td>1.67</td><td>2113</td></tr><tr><td>S02</td><td>2425</td><td>1393</td><td>73</td><td>1.63</td><td>2227</td></tr><tr><td>O02</td><td>2355</td><td>1482</td><td>76</td><td>1.48</td><td>2136</td></tr><tr><td>N02</td><td>2499</td><td>1588</td><td>82</td><td>1.38</td><td>2097</td></tr><tr><td>D02</td><td>2442</td><td>1694</td><td>87</td><td>1.30</td><td>2140</td></tr><tr><td>J03</td><td>2069</td><td>1780</td><td>87</td><td>1.17</td><td>2087</td></tr><tr><td>F03</td><td>1992</td><td>1856</td><td>85</td><td>1.12</td><td>2108</td></tr><tr><td>M03</td><td>1958</td><td>1918</td><td>80</td><td>1.13</td><td>2227</td></tr><tr><td>A03</td><td>1990</td><td>1963</td><td>73</td><td>1.18</td><td>2409</td></tr><tr><td>M03</td><td>2222</td><td>2003</td><td>67</td><td>1.27</td><td>2651</td></tr><tr><td>J03</td><td>2525</td><td>2039</td><td>60</td><td>1.40</td><td>2958</td></tr><tr><td>J03</td><td>2789</td><td>2066</td><td>54</td><td>1.55</td><td>3327</td></tr><tr><td>A03</td><td>3017</td><td>2088</td><td>47</td><td>1.64</td><td>3542</td></tr><tr><td>S03</td><td>3232</td><td>2120</td><td>44</td><td>1.62</td><td>3485</td></tr><tr><td>O03</td><td>3198</td><td>2165</td><td>44</td><td>1.48</td><td>3195</td></tr><tr><td>N03</td><td>3028</td><td>2207</td><td>44</td><td>1.38</td><td>3048</td></tr><tr><td>D03</td><td>2985</td><td>2255</td><td>45</td><td>1.31</td><td>2938</td></tr><tr><td>J04</td><td></td><td></td><td></td><td></td><td>2692</td></tr></table>

of forecasting until at least one year of the seasonal pattern is available. Thus, exponential smoothing with trend and seasonality needs at least one complete year of data before it is “warmed $\mathrm { u p ^ { \prime \prime } }$ and can start to forecast fairly effectively.

To provide a forecast for any period more than one in the future (April 2004, for example), it is merely a task of taking the most recent value of level that has been calculated (in this case, December 2003), adding to it the most recent value of trend that has been calculated (also in this case, December 2003), times the number of months into the future we wish to forecast (because April is four months past December, it would be times four), and multiplying this value by the seasonal adjustment for April of last year (2003). For April 2004, the calculations are:

$$
\mathrm {F} _ {\mathrm {A} 0 4} = \left(\mathrm {L} _ {\mathrm {D} 0 3} + \left(\mathrm {T} _ {\mathrm {D} 0 3} \times \mathrm {m}\right)\right) \times \mathrm {S A} _ {\mathrm {A} 0 3}
$$

$$
F _ {A 0 4} = (2 2 5 5 + (4 5 \times 4)) \times 1. 1 8
$$

$$
\mathrm {F} _ {\mathrm {A 0 4}} = 2 8 7 4
$$

Now that we have introduced the components of trend and seasonality into our basic exponential smoothing formula, we can return to the idea of how to set the value of the smoothing constants. However, now it is not simply a matter of choosing a value for $\alpha ,$ but one of choosing values for $\beta$ and $\gamma ,$ as well. In fact, the accuracy of exponential smoothing with trend and seasonality is very sensitive to the values chosen for the smoothing constants, so this is no small matter.

# Adaptive Exponential Smoothing With Trend and Seasonality

As with regular adaptive smoothing, there are several techniques that are adaptive and consider trend and seasonality. One of the most complex computationally is called the Self Adaptive Forecasting Technique (SAFT) and was developed more than 35 years ago (Roberts & Reed, 1969). SAFT is a heuristic technique that examines different combinations of α, β, and $\gamma$ to arrive at the most accurate forecast. For each forecast each period, SAFT tries each combination of $\begin{array} { r } { \alpha , \beta , } \end{array}$ and γ starting with a value of 0.05 for each and incrementally increasing the values by 0.05 until a value of 0.95 for each is reached. For each of these

6,859 $( 1 9 \times 1 9 \times 1 9 )$ , where the 19 is the number of values between 0 and 1, incrementing by 0.05 at a time) combinations, SAFT starts at the beginning of the time series and forecasts using exponential smoothing with trend and seasonality, and it records the resultant value of MAPE. Once the lowest MAPE value combination of α, $\beta ,$ and $\gamma$ is determined, a local search for a lower MAPE is implemented by examining the values of α, β, and $\gamma$ above and below each value (including the original three values) at a rate of change of 0.01.

For example, if the first search found the lowest value of MAPE to come from the combination of $\alpha = 0 . 1 5$ , $\beta = 0 . 2 0 ,$ , and $\gamma = 0 . 3 0 .$ , SAFT would then try all the combinations of $\alpha = 0 . 1 1$ , 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19; $\beta = 0 . 1 6$ , 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24; and $\gamma = 0 . 2 6$ , 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34. These 729 $( 9 \times 9 \times 9 )$ combinations are compared to the original best MAPE combination and, again, the lowest combination is chosen.

It should be clear by now that SAFT is a very computationally cumbersome technique (after all, it requires 7,588 trial forecasts for each product each period before it actually makes a forecast) and, as a result, is in little use today. More computationally efficient versions of SAFT try to calculate values of α, $\beta ,$ or $\gamma$ and use a heuristic similar to SAFT for the smoothing constants that are not directly calculated.

As with adaptive smoothing, because these adaptive exponential smoothing techniques with trend and seasonality essentially all work equally well, we will only discuss the simplest of this group of techniques here. This adaptive smoothing approach, called Adaptive Extended Exponential Smoothing (AEES), uses the absolute value of the percent error from the previous period’s forecast to adjust the value of $\alpha$ for the next period’s forecast and uses the SAFT heuristic to adjust the values of $\beta$ and $\gamma$ (Mentzer, 1988). Thus, the exponential smoothing with trend and seasonality formulae (Equations [9], [10], [11], and [12]) are still used,

$$
\mathrm {L} _ {\mathrm {t}} = \alpha \left(\mathrm {S} _ {\mathrm {t}} / \mathrm {S A} _ {\mathrm {t} - \mathrm {C}}\right) + (1 - \alpha) \left(\mathrm {L} _ {\mathrm {t} - 1} + \mathrm {T} _ {\mathrm {t} - 1}\right)
$$

$$
\mathrm {T} _ {\mathrm {t}} = \beta \left(\mathrm {L} _ {\mathrm {t}} - \mathrm {L} _ {\mathrm {t} - 1}\right) + (1 - \beta) \mathrm {T} _ {\mathrm {t} - 1}
$$

$$
\mathrm {S A} _ {\mathrm {t}} = \gamma \left(\mathrm {S} _ {\mathrm {t}} / \mathrm {L} _ {\mathrm {t}}\right) + (1 - \gamma) (\mathrm {S A} _ {\mathrm {t} - \mathrm {C}})
$$

$$
F _ {t + m} = \left(L _ {t} + \left(T _ {t} \times m\right)\right) \times S A _ {t - C + m}
$$

but after each period’s sales are recorded, the value of $\alpha$ is adjusted for the next period by Equation (5), repeated here as:

$$
\alpha_ {\mathrm {t} + 2} = | \left(\mathrm {F} _ {\mathrm {t} + 1} - \mathrm {S} _ {\mathrm {t} + 1}\right) / \mathrm {S} _ {\mathrm {t} + 1} | = | \mathrm {P E} _ {\mathrm {t} + 1} |
$$

Because this calculation can still produce values outside the range of $\mathbf { \alpha } _ { \mathrm { ~ \tiny ~ Q ~ } , }$ this calculation is again adjusted by the following rules:

If $| \mathrm { P E } _ { \mathrm { t } + 1 } |$ is equal to or greater than 1.0, then $\alpha _ { { \mathrm { t } } + 2 } = 0 . 9 9 9 9 9$

If $| \mathrm { P E } _ { \mathrm { t } + 1 } |$ is equal to 0.0, then $\alpha _ { { \mathrm { t } } + 2 } = 0 . 0 0 0 0 1$

Once the new value of $\alpha$ has been calculated, AEES tries each combination of $\beta$ and $\gamma$ starting with a value of 0.05 for each and incrementally increasing the values by 0.05 until a value of 0.95 for each is reached. For each of these 361 $( 1 9 \times 1 9 _ { \cdot }$ , where the 19 is the number of values between 0 and 1, incrementing by 0.05 at a time) combinations, AEES starts at the beginning of the time series and forecasts using exponential smoothing with trend and seasonality and records the resultant value of MAPE. Once the lowest MAPE value combination of the calculated value of $\alpha$ and the heuristic values of $\beta$ and $\gamma$ is determined, a local search for a lower MAPE is implemented by examining the values of $\beta$ and $\gamma$ above and below each value (including the original two values) at a rate of change of 0.01.

For example, if the first search found the lowest value of MAPE to come from the calculated value of $\mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \beta } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \alpha } \mathbf { \beta } \mathbf { \alpha \alpha } \mathbf { \alpha } \mathbf { \alpha \beta } \mathbf { \alpha \alpha } \mathbf { \alpha \beta } \mathbf { \alpha \alpha } \mathbf { \alpha \beta }$ , and combination of $\beta = 0 . 2 0$ , and $\gamma = 0 . 3 0 .$ , AEES would then try all the combinations of $\beta = 0 . 1 6$ , 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24; and $\gamma = 0 . 2 6$ , 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34. These 81 $( 9 \times 9 )$ combinations are compared to the original best MAPE combination and, again, the lowest combination is chosen.

It should be clear by now that AEES is a much less computationally cumbersome technique than SAFT. AEES requires 442 trial forecasts for each product each period before it actually makes a forecast, rather than the 7,588 trial forecasts of SAFT. Further, the exact value of $\alpha$ is calculated rather than the approximation obtained from the SAFT heuristic.

We can illustrate the adaptability of AEES by forecasting the times series with trend and seasonality used in the last section. (See Figure 3.17.) Notice that the forecast in Figure 3.17 “tracks” the demand better

![](images/a26a254366e38a31d2b479804391c3ff2aa6848f83e2e16c9c72f59f6547b026.jpg)  
Figure 3.17 AEES With Trend and Seasonality as a Forecast

than the forecast in Figure 3.16. This is due to the adaptability of α, β, and $\gamma .$ Also, the year-to-date MAPE for exponential smoothing with trend and seasonality (Figure 3.16) at the end is $9 . 7 3 \%$ , while the same calculation for AEES (Figure 3.17) is $7 . 0 0 \%$ .

#  FIXED-MODEL TIMES SERIES TECHNIQUES SUMMARY

Considerable effort has been devoted over time to testing the various FMTS techniques discussed here (and variations on these techniques as well) over a wide variety of time series and forecasting horizons and intervals. (For a summary of these efforts, see Mentzer & Gomes, 1994.) To date, no FMTS technique has shown itself to be clearly superior to any of the other FMTS techniques across a wide variety of forecasting levels and time horizons. For this reason, it is recommended that FMTS users keep in mind where the general category of techniques works well and the time series scenario for which each technique was designed.

In general, FMTS techniques should be used when a limited amount of data is available on anything other than an actual history

Table 3.4 FMTS Technique Selection Guidelines   

<table><tr><td>Time Series Component Characteristics</td><td>FMTS Technique</td></tr><tr><td>Stable Level, with No Trend or Seasonality</td><td>Exponential Smoothing</td></tr><tr><td>Changing Level, with No Trend or Seasonality</td><td>Adaptive Smoothing</td></tr><tr><td>Level and Trend</td><td>Exponential Smoothing with Trend</td></tr><tr><td>Level, Trend, and Seasonality</td><td>Exponential Smoothing with Trend and Seasonality</td></tr><tr><td>Changing Level, Trend, and Seasonal Patterns</td><td>AEES</td></tr></table>

of sales (that is, little data on outside factors such as price changes, economic activity, promotional programs, and so on). This lack of outside (exogenous) data precludes the use of regression (discussed in the next chapter). Further, FMTS techniques are useful when the time series components change fairly regularly. That is, the trend rate changes, the seasonal pattern changes, or the overall level of demand changes. FMTS is much more effective at adjusting to these changes in time series components than are the OMTS techniques to be discussed next, which require more data with stable time series components over a long period of time.

In terms of which FMTS to use in which situations, a general guideline is provided in Table 3.4. However, remember that these are only general guidelines, and it is best to incorporate these techniques into a system (such as the one discussed in Chapter 6) that allows the system to try each FMTS technique on each forecast to be made and select the one that works best in terms of accuracy.

With these general guidelines established, we will now move on to a discussion of the open-model time series (OMTS) techniques.

#  OPEN-MODEL TIMES SERIES TECHNIQUES

Open-model time series (OMTS) techniques assume that the same components exist in any time series—level, trend, seasonality, and noise— but take a different approach to forecasting these components. Where FMTS techniques assume that certain components exist in the time

series and use one set of formulae to forecast this series (that is, the formulae are “fixed”), OMTS techniques first analyze the components in the time series to see which exist and what is their nature. From this information, a set of forecasting formulae unique to that time series is built (that is, the formulae are “open” until the time series components are analyzed).

Various forms of OMTS exist, including decomposition analysis (Shiskin 1961a, 1961b), spectral analysis (Nelson, 1973), fourier analysis (Bloomfield, 1976), and auto-regressive moving average (ARMA) or Box-Jenkins analysis (Box & Jenkins, 1970). All of these OMTS techniques have in common the fact that they first try to analyze the time series to determine the components and, as a result, require a considerable amount of history before any forecasts can be made. For instance, many OMTS techniques recommend no less than 48 periods of data prior to using the technique. Obviously, this is a disadvantage for situations where a limited amount of history is available.

OMTS techniques also have in common the need for considerable understanding of quantitative methods to properly use the techniques. The analysis with OMTS can become quite complex and require considerable input from the forecaster. For these reasons (large data requirements and considerable user experience), OMTS techniques have seen limited use in practice (Mentzer & Kahn, 1995; Mentzer & Cox, 1984a). Improvements in systems technology have made OMTS techniques easier to use (as we will see in Chapter 6), but the data requirements still limit their use.

As with FMTS techniques, there is no evidence that the performance of one of these OMTS techniques is clearly superior to any of the others. Thus, we will again only discuss the simplest of the OMTS techniques here. This technique is called decomposition analysis. To demonstrate decomposition analysis, we will use the time series presented at the beginning of the chapter in Figure 3.1.

Like all OMTS techniques, the purpose of decomposition analysis is to decompose the data into its time series components. The first step in doing this is to remove noise and seasonality from the original time series. As we discussed earlier in the chapter, one of the characteristics of a moving average is that it dampens out any noise and dampens out any regular pattern of fluctuation that has a pattern length that is equal to the number of periods in the moving average. Thus, one of the first things we have to do in decomposition analysis is make a judgment about how long the seasonal pattern is.

Visual examination of Figure 3.1 will, we hope, lead us to conclude that the seasonal pattern takes 12 months. Therefore, a 12-month moving average should remove noise and seasonality from the time series. As in the discussion earlier in the chapter, the value of the moving average in any given period is our estimate of level, and how much that level estimate changes from one period to the next is our estimate of trend. However, because our purpose here is not to forecast, but to decompose the data, we will perform this moving average calculation in a slightly different way than previously discussed. This calculation is as follows:

$$
\begin{array}{l} \mathrm {M A} _ {\mathrm {t}} = \left(S _ {\mathrm {t} - 5} + S _ {\mathrm {t} - 4} + S _ {\mathrm {t} - 3} + S _ {\mathrm {t} - 2} + S _ {\mathrm {t} - 1} + S _ {\mathrm {t}} + S _ {\mathrm {t} + 1} + \right. \\ \left. \left. S _ {t + 2} + S _ {t + 3} + S _ {t + 4} + S _ {t + 5} + S _ {t + 6}\right) / 1 2 \right. \\ \end{array}
$$

Notice that this is a centered moving average, which means that we take an average of 12 months and assign that value to the month in the center. The purpose of this is to find a more accurate estimate of the level. If we placed the moving average value at the end of the 12 months used in the calculation, it would have too much old data (lower trend) to accurately represent the level for that period. Conversely, if we place the moving average value at the beginning of the 12 months used in the calculation, it would have too much new data (higher trend) to actually represent the level at that period. Thus, the best place to position this estimate of level is in the center of the periods used in its calculation.

Because this moving average contains the level and the trend, we can simply take the difference between each period to determine the trend. Similarly, since the moving average contains the level and the trend, if we subtract it from the original time series (which contained level, trend, seasonality, and noise), the result is a series of data that contains only the seasonality and the noise. These calculations are demonstrated in Table 3.5.

We now have decomposed the original time series into the level and the trend. All that is left is to remove the noise from the data series containing seasonality and noise, and we will have our final component, seasonality. Again, to remove noise we use an average. However, because each month of the year represents a different season, we want to perform this average calculation within each season. Thus, we take all the January values and average them, then take an average of all the February values, and so on for all 12 months. This calculation is shown

Table 3.5 Decomposition Analysis   

<table><tr><td>Month</td><td>Demand</td><td>Level and Trend</td><td>Trend</td><td>Seasonality and Noise</td><td>Seasonality</td><td>Forecast</td></tr><tr><td>J01</td><td>1104</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>F01</td><td>885</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>M01</td><td>976</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>A01</td><td>1101</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>M01</td><td>1120</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>J01</td><td>1276</td><td>1376</td><td></td><td>-100</td><td>-140</td><td></td></tr><tr><td>J01</td><td>1419</td><td>1411</td><td>35</td><td>8</td><td>60</td><td></td></tr><tr><td>A01</td><td>1615</td><td>1463</td><td>52</td><td>152</td><td>261</td><td></td></tr><tr><td>S01</td><td>1836</td><td>1505</td><td>42</td><td>331</td><td>325</td><td></td></tr><tr><td>O01</td><td>1730</td><td>1536</td><td>32</td><td>194</td><td>200</td><td></td></tr><tr><td>N01</td><td>1686</td><td>1587</td><td>51</td><td>99</td><td>204</td><td></td></tr><tr><td>D01</td><td>1769</td><td>1627</td><td>40</td><td>142</td><td>165</td><td></td></tr><tr><td>J02</td><td>1521</td><td>1687</td><td>60</td><td>-166</td><td>-203</td><td></td></tr><tr><td>F02</td><td>1504</td><td>1755</td><td>68</td><td>-251</td><td>-308</td><td></td></tr><tr><td>M02</td><td>1478</td><td>1804</td><td>49</td><td>-326</td><td>-396</td><td></td></tr><tr><td>A02</td><td>1480</td><td>1856</td><td>52</td><td>-376</td><td>-440</td><td></td></tr><tr><td>M02</td><td>1726</td><td>1924</td><td>68</td><td>-198</td><td>-258</td><td></td></tr><tr><td>J02</td><td>1759</td><td>1980</td><td>56</td><td>-221</td><td>-140</td><td></td></tr><tr><td>J02</td><td>2137</td><td>2026</td><td>46</td><td>111</td><td>60</td><td></td></tr><tr><td>A02</td><td>2436</td><td>2067</td><td>41</td><td>370</td><td>261</td><td></td></tr><tr><td>S02</td><td>2425</td><td>2107</td><td>40</td><td>319</td><td>325</td><td></td></tr><tr><td>O02</td><td>2355</td><td>2149</td><td>43</td><td>206</td><td>200</td><td></td></tr><tr><td>N02</td><td>2499</td><td>2190</td><td>41</td><td>309</td><td>204</td><td></td></tr><tr><td>D02</td><td>2442</td><td>2254</td><td>64</td><td>188</td><td>165</td><td></td></tr><tr><td>J03</td><td>2069</td><td>2309</td><td>54</td><td>-240</td><td>-203</td><td></td></tr><tr><td>F03</td><td>1992</td><td>2357</td><td>48</td><td>-365</td><td>-308</td><td></td></tr><tr><td>M03</td><td>1958</td><td>2424</td><td>67</td><td>-466</td><td>-396</td><td></td></tr><tr><td>A03</td><td>1990</td><td>2494</td><td>70</td><td>-504</td><td>-440</td><td></td></tr><tr><td>M03</td><td>2222</td><td>2539</td><td>44</td><td>-317</td><td>-258</td><td></td></tr><tr><td>J03</td><td>2525</td><td>2584</td><td>45</td><td>-59</td><td>-140</td><td></td></tr><tr><td>J03</td><td>2789</td><td></td><td>45</td><td></td><td>60</td><td></td></tr><tr><td>A03</td><td>3017</td><td></td><td>90</td><td></td><td>261</td><td></td></tr><tr><td>S03</td><td>3232</td><td></td><td>135</td><td></td><td>325</td><td></td></tr><tr><td>O03</td><td>3198</td><td></td><td>180</td><td></td><td>200</td><td></td></tr><tr><td>N03</td><td>3028</td><td></td><td>225</td><td></td><td>204</td><td></td></tr><tr><td>D03</td><td>2985</td><td></td><td>270</td><td></td><td>165</td><td></td></tr><tr><td>J04</td><td></td><td></td><td>315</td><td></td><td>-203</td><td>2696</td></tr></table>

Table 3.6 Decomposition of Seasonality   

<table><tr><td>Month</td><td>2001</td><td>2002</td><td>2003</td><td>Average</td></tr><tr><td>January</td><td></td><td>-166</td><td>-240</td><td>-203</td></tr><tr><td>February</td><td></td><td>-251</td><td>-365</td><td>-308</td></tr><tr><td>March</td><td></td><td>-326</td><td>-466</td><td>-396</td></tr><tr><td>April</td><td></td><td>-376</td><td>-504</td><td>-440</td></tr><tr><td>May</td><td></td><td>-198</td><td>-317</td><td>-258</td></tr><tr><td>June</td><td>-100</td><td>-221</td><td>-59</td><td>-140</td></tr><tr><td>July</td><td>8</td><td>111</td><td></td><td>60</td></tr><tr><td>August</td><td>152</td><td>370</td><td></td><td>261</td></tr><tr><td>September</td><td>331</td><td>319</td><td></td><td>325</td></tr><tr><td>October</td><td>194</td><td>206</td><td></td><td>200</td></tr><tr><td>November</td><td>99</td><td>309</td><td></td><td>204</td></tr><tr><td>December</td><td>142</td><td>188</td><td></td><td>165</td></tr></table>

in Table 3.6, and the resultant values are added to Table 3.5 in the Seasonality column. Notice that this is not a multiplicative seasonal adjustment like we used in FMTS. Rather, it is an additive seasonal adjustment; to determine the seasonal adjustment, we add it to (not multiply it by) the level plus trend.

We now have our most recent estimate of level (2,584 in June 2003), our most recent estimate of trend (45 units per month from June 2003), and our most recent estimates of the additive seasonal adjustments for the last 12 months. To forecast a future period (such as January 2004), we take the last estimate of level and add to it the trend times the number of periods into the future. To this value, we add the seasonal adjustment. For January 2004, the calculation is:

$$
\begin{array}{l} \text {F o r c a s t} _ {\text {J a n 0 4}} = \text {L e v e l} _ {\text {J u n e 0 3}} + (7 \times \text {T r e n d} _ {\text {J u n e 0 3}}) + \text {S e a s o n a l i t y} _ {\text {J a n 0 3}} \\ = 2 5 8 4 + (7 \times 4 5) - 2 0 3 = 2 6 9 6 \\ \end{array}
$$

This example illustrates just how much data are required to complete OMTS analysis. Although we have 3 years of monthly data in this example, for all but June, only two values were available to estimate the seasonality adjustment for each season (month). With another year’s data, three values would be available for each season, which should improve the seasonality adjustment estimates. However, one of the primary drawbacks to OMTS is this dependency on a large amount of data.

#  SUMMARY

In this chapter, we have covered a number of time series techniques. All have in common a recognition of the time series components—level, trend, seasonality, noise. FMTS techniques deal with these components by assuming certain components are (and are not) in the data, while OMTS techniques analyze the data to determine which components exist. This greater level of sophistication in OMTS is somewhat ameliorated by the considerable data requirements for analysis.

Another characteristic of all the techniques included in this chapter is the fact that they ignore other factors that might have influenced demand, such as price changes, advertising, trade promotions, sales programs, competitive actions, economic activity, and so on. In many cases, much of what time series techniques classify as noise can be explained by looking at these “exogenous” factors. In the next chapter, we turn our attention to regression analysis, a technique that considers these exogenous factors.

# TIME SERIES ANALYSIS

![](images/94fede07fb54840683a75e98f18e6b28c1f8ad89ccceff3f0f2b4bbf095335c7.jpg)

Alexander Aue

University of California, Davis

# University of California, Davis Time Series Analysis

Alexander Aue

This text is disseminated via the Open Education Resource (OER) LibreTexts Project (https://LibreTexts.org) and like the thousands of other texts available within this powerful platform, it is freely available for reading, printing, and "consuming."

The LibreTexts mission is to bring together students, faculty, and scholars in a collaborative effort to provide an accessible, and comprehensive platform that empowers our community to develop, curate, adapt, and adopt openly licensed resources and technologies; through these efforts we can reduce the financial burden born from traditional educational resource costs, ensuring education is more accessible for students and communities worldwide.

Most, but not all, pages in the library have licenses that may allow individuals to make changes, save, and print this book. Carefully consult the applicable license(s) before pursuing such effects. Instructors can adopt existing LibreTexts texts or Remix them to quickly build course-specific resources to meet the needs of their students. Unlike traditional textbooks, LibreTexts’ web based origins allow powerful integration of advanced features and new technologies to support learning.

![](images/e53b3971b7b906494f721a61de6ed8573fb257fe597638f3214d6ff0cd3305ec.jpg)

# LibreTexts

LibreTexts is the adaptable, user-friendly non-profit open education resource platform that educators trust for creating, customizing, and sharing accessible, interactive textbooks, adaptive homework, and ancillary materials. We collaborate with individuals and organizations to champion open education initiatives, support institutional publishing programs, drive curriculum development projects, and more.

The LibreTexts libraries are Powered by NICE CXone Expert and was supported by the Department of Education Open Textbook Pilot Project, the California Education Learning Lab, the UC Davis Office of the Provost, the UC Davis Library, the California State University Affordable Learning Solutions Program, and Merlot. This material is based upon work supported by the National Science Foundation under Grant No. 1246120, 1525057, and 1413739.

Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation nor the US Department of Education.

Have questions or comments? For information about adoptions or adaptions contact info@LibreTexts.org or visit our main website at https://LibreTexts.org.

This text was compiled on 12/17/2025

# TABLE OF CONTENTS

# Licensing

# 1: Basic Concepts in Time Series

1.1: Introduction and Examples   
1.2: Stationary Time Series   
1.3: Eliminating Trend Components   
1.4: Eliminating Trend and Seasonal Components   
1.5: Assessing the Residuals   
1.6: Summary

# 2: The Estimation of Mean and Covariances

2.1: Estimation of the Mean   
2.2: Estimation of the Autocovariance Function

# 3: ARMA Processes

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes   
3.2: Causality and Invertibility   
3.3: The PACF of a Causal ARMA Process   
3.4: Forecasting   
3.5: Parameter Estimation   
3.6: Model Selection   
3.7: Summary

# 4: Spectral Analysis

4.1: Introduction to Spectral Analysis   
4.2: The Spectral Density and the Periodogram   
4.3: Large Sample Properties   
4.4: Linear Filtering   
4.5: Summary

# Index

# Glossary

Detailed Licensing

# Licensing

A detailed breakdown of this resource's licensing can be found in Back Matter/Detailed Licensing.

# CHAPTER OVERVIEW

# 1: Basic Concepts in Time Series

The first chapter explains the basic notions and highlights some of the objectives of time series analysis. Section 1.1 gives several important examples, discusses their characteristic features and deduces a general approach to the data analysis. In Section 1.2, stationary processes are identified as a reasonably broad class of random variables which are able to capture the main features extracted from the examples. Finally, it is discussed how to treat deterministic trends and seasonal components in Sections 1.3 and 1.4, and how to assess the residuals in Section 1.5. Section 1.6 concludes.

1.1: Introduction and Examples   
1.2: Stationary Time Series   
1.3: Eliminating Trend Components   
1.4: Eliminating Trend and Seasonal Components   
1.5: Assessing the Residuals   
1.6: Summary

# 1.1: Introduction and Examples

The first definition clarifies the notion time series analysis.

# Definition 1.1.1: Time Series

Let $\pmb { T } \neq \pmb { \emptyset }$ be an index set, conveniently being thought of as "time''. A family $( X _ { t } ; t \in T )$ of random variables (random functions) is called a stochastic process. A realization of $( X _ { t } { : } t \in T )$ is called a time series. We will use the notation $( x _ { t } ; t \in T )$ in the discourse.

The most common choices for the index set $T$ include the integers $\mathbb { Z } = \{ 0 , \pm 1 , \pm 2 , . . . \}$ , the positive integers $\mathbb { N } = \{ 1 , 2 , \ldots \}$ , the nonnegative integers $\mathbb { N } _ { 0 } = \{ 0 , 1 , 2 , \ldots \}$ , the real numbers $\mathbb { R } = ( - \infty , \infty )$ and the positive halfline $\mathbb { R } _ { + } = [ 0 , \infty )$ . This class is mainly concerned with the first three cases which are subsumed under the notion discrete time series analysis.

Oftentimes the stochastic process $( X _ { t } ; t \in T )$ is itself referred to as a time series, in the sense that a realization is identified with the probabilistic generating mechanism. The objective of time series analysis is to gain knowledge of this underlying random phenomenon through examining one (and typically only one) realization. This separates time series analysis from, say, regression analysis for independent data.

In the following a number of examples are given emphasizing the multitude of possible applications of time series analysis in various scientific fields.

Example 1.1.1 (W lfer's sunspot numbers). In Figure 1.1, the number of sunspots (that is, dark spots visible on the surface of the sun) observed annually are plotted against time. The horizontal axis labels time in years, while the vertical axis represents the observed values $\pmb { x } _ { t }$ of the random variable

$$
X _ {t} = \# \text {o f s u n s p o t s a t t i m e} t, \quad t = 1 7 0 0, \dots , 1 9 9 4.
$$

The figure is called a time series plot. It is a useful device for a preliminary analysis. Sunspot numbers are used to explain magnetic oscillations on the sun surface.

![](images/6f9a2a927665b99ef1aebedd40c6f994537f972918e2ae0744c3a8a4fcc620d1.jpg)  
Figure 1.1: Wölfer's sunspot from 1700 to 1994.

To reproduce a version of the time series plot in Figure 1.1 using the free software package R (downloads are available at http://cran.r-project.org), download the file sunspots.dat from the course webpage and type the following commands:

$>$ spots $=$ read.table("sunspots.dat")   
$>$ spots $=$ ts(spots, start=1700, frequency=1)   
$>$ plot(spots, xlab $=$ "time", ylab $=$ "", main $=$ "Number of Sun spots")

In the first line, the file sunspots.dat is read into the object spots, which is then in the second line transformed into a time series object using the function ts(). Using start sets the starting value for the $\boldsymbol { x }$ -axis to a prespecified number, while frequency presets the number of observations for one unit of time. (Here: one annual observation.) Finally, plot is the standard plotting command in R, where xlab and ylab determine the labels for the $x \cdot$ -axis and y-axis, respectively, and main gives the headline.

Example 1.1.2 (Canadian lynx data). The time series plot in Figure 1.2 comes from a biological data set. It contains the annual returns of lynx at auction in London by the Hudson Bay Company from 1821--1934 (on a scale). These are viewed as observations of the stochastic process

$$
X _ {t} = \log_ {1 0} (\text {n u m b e r o f l y n x t r a p p e d a t t i m e 1 8 2 0 + t}), \quad t = 1, \dots , 1 1 4.
$$

![](images/7bdc543d0879477fd0e96e7dd11d12afa9cd33b6588d81fae0ded3dfffe76f8d.jpg)  
Figure 1.2: Number of lynx trapped in the MacKenzie River district between 1821 and 1934.

The data is used as an estimate for the number of all lynx trapped along the MacKenzie River in Canada. This estimate, in turn, is often taken as a proxy for the true population size of the lynx. A similar time series plot could be obtained for the snowshoe rabbit, the primary food source of the Canadian lynx, hinting at an intricate predator-prey relationship.

Assuming that the data is stored in the file lynx.dat, the corresponding R commands leading to the time series plot in Figure 1.2 are:

> lynx = read.table("lynx.dat")   
> lynx = ts(log10(lynx), start=1821, frequency $^ { \prime = 1 }$ )   
$>$ plot(lynx, xlab="", ylab="", main $=$ "Number of trapped lynx")

Example 1.1.3 (Treasury bills). Another important field of application for time series analysis lies in the area of finance. To hedge the risks of portfolios, investors commonly use short-term risk-free interest rates such as the yields of three-month, six-month, and twelve-month Treasury bills plotted in Figure 1.3. The (multivariate) data displayed consists of 2,386 weekly observations from July 17, 1959, to December 31, 1999. Here,

$$
X _ {t} = \left(X _ {t, 1}, X _ {t, 2}, X _ {t, 3}\right), \qquad t = 1, \dots , 2 3 8 6,
$$

where $X _ { t , 1 }$ , $X _ { t , 2 }$ and $X _ { t , 3 }$ denote the three-month, six-month, and twelve-month yields at time t, respectively. It can be seen from the graph that all three Treasury bills are moving very similarly over time, implying a high correlation between the components of $X _ { t }$ .

![](images/61f78296eb3e602cca010cd9a05c2de60129b4ca2e9f9e95794aaa288b3dac87.jpg)

![](images/4c13b9899eb172f1be20920992ec6c5dd5de07243310abc1fdf871fe722d7f47.jpg)

![](images/52bde4cb94b73dab0a14b00cb59c76197a2a3669df8aa66505f6321820de9de7.jpg)

![](images/7d2e5d421123a676f1ecb43430a100af2d327a862eb99980a42710ca38476ac4.jpg)  
Figure 1.3: Yields of Treasury bills from July 17, 1959, to December 31, 1999.   
Figure 1.4: S&P 500 from January 3, 1972, to December 31, 1999.

To produce the three-variate time series plot in Figure 1.3, use the R code

```txt
> bills03 = read.table("bills03.dat");
> bills06 = read.table("bills06.dat");
> bills12 = read.table("bills12.dat");
>par(mfrow=c(3,1))
>plot.ts(bills03, xlab=("a"), ylab),"main="Yields of 3-month Treasury Bills")
>plot.ts(bills06, xlab=("b"), ylab),"main="Yields of 6-month Treasury Bills")
>plot.ts(bills12, xlab=("c"), ylab),"main="Yields of 12-month Treasury Bills") 
```

It is again assumed that the data can be found in the corresponding files bills03.dat, bills06.dat and bills12.dat. The command line par(mfrow=c(3,1)) is used to set up the graphics. It enables you to save three different plots in the same file.

Example 1.1.4 (S&P 500). The Standard and Poor's 500 index (S&P 500) is a value-weighted index based on the prices of 500 stocks that account for approximately $7 0 \%$ of the U.S. equity market capitalization. It is a leading economic indicator and is also used to hedge market portfolios. Figure 1.4 contains the 7,076 daily S&P 500 closing prices from January 3, 1972, to December 31, 1999, on a natural logarithm scale. It is consequently the time series plot of the process

# Misplaced '&'

Note that the logarithm transform has been applied to make the returns directly comparable to the percentage of investment return. The time series plot can be reproduced in R using the file sp500.dat

There are countless other examples from all areas of science. To develop a theory capable of handling broad applications, the statistician needs to rely on a mathematical framework that can explain phenomena such as

trends (apparent in Example 1.1.4);   
seasonal or cyclical effects (apparent in Examples 1.1.1 and 1.1.2);   
random fluctuations (all Examples);   
dependence (all Examples?).

The classical approach taken in time series analysis is to postulate that the stochastic process $( X _ { t } ; t \in T )$ under investigation can be divided into deterministic trend and seasonal components plus a centered random component, giving rise to the model

$$
X _ {t} = m _ {t} + s _ {t} + Y _ {t}, \quad t \in T \tag {1.1.1}
$$

where $( m _ { t } ; t \in T )$ denotes the trend function ("mean component''), $( s _ { t } ; t \in T )$ the seasonal effects and $( Y _ { t } ; t \in T )$ a (zero mean) stochastic process. After an appropriate model has been chosen, the statistician may aim at

estimating the model parameters for a better understanding of the time series;   
predicting future values, for example, to develop investing strategies;   
checking the goodness of fit to the data to confirm that the chosen model is appropriate.

Estimation procedures and prediction techniques are dealt with in detail in later chapters of the notes. The rest of this chapter will be devoted to introducing the classes of strictly and weakly stationary stochastic processes (in Section 1.2) and to providing tools to eliminate trends and seasonal components from a given time series (in Sections 1.3 and 1.4), while some goodness of fit tests will be presented in Section 1.5.

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)

# 1.2: Stationary Time Series

Fitting solely independent and identically distributed random variables to data is too narrow a concept. While, on one hand, they allow for a somewhat nice and easy mathematical treatment, their use is, on the other hand, often hard to justify in applications. Our goal is therefore to introduce a concept that keeps some of the desirable properties of independent and identically distributed random variables ("regularity''), but that also considerably enlarges the class of stochastic processes to choose from by allowing dependence as well as varying distributions. Dependence between two random variables $\pmb { X }$ and $\pmb { Y }$ is usually measured in terms of the covariance function

$$
C o v (X, Y) = E \left[ (X - E [ X ]) (Y - E [ Y ]) \right]
$$

and the

$$
C o r r (X, Y) = \frac {C o v (X , Y)}{\sqrt {V a r (X) V a r (Y)}}.
$$

With these notations at hand, the classes of strictly and weakly dependent stochastic processes can be introduced.

Definition 1.2.1 (Strict Stationarity). A stochastic process $( X _ { t } ; t \in T )$ is called strictly stationary if, for all $t _ { 1 } , \ldots , t _ { n } \in T$ and such that $t _ { 1 } + h , \ldots , t _ { n } + h \in T$ , it holds that

$$
\left(X _ {t _ {1}}, \dots , X _ {t _ {n}}\right) \stackrel {\mathcal {D}} {=} \left(X _ {t _ {1} + h}, \dots , X _ {t _ {n} + h}\right).
$$

That is, the so-called finite-dimensional distributions of the process are invariant under time shifts. Here $= ^ { \mathcal { D } }$ indicates equality in distribution.

The definition in terms of the finite-dimensional distribution can be reformulated equivalently in terms of the cumulative joint distribution function equalities

$$
P \left(X _ {t _ {1}} \leq x _ {1}, \dots , X _ {t _ {n}} \leq x _ {n}\right) = P \left(X _ {t _ {1} + h} \leq x _ {1}, \dots , X _ {t _ {n} + h} \leq x _ {n}\right)
$$

holding true for all ${ \pmb x } _ { 1 } , \ldots , { \pmb x } _ { n } \in \mathbb { R }$ , $t _ { 1 } , \dots , t _ { n } \in T$ and $\pmb { h }$ such that $t _ { 1 } + h , \ldots , t _ { n } + h \in T$ . This can be quite difficult to check for a given time series, especially if the generating mechanism of a time series is far from simple, since too many model parameters have to be estimated from the available data, rendering concise statistical statements impossible. A possible exception is provided by the case of independent and identically distributed random variables.

To get around these difficulties, a time series analyst will commonly only specify the first- and second-order moments of the joint distributions. Doing so then leads to the notion of weak stationarity.

Definition 1.2.2 (Weak Stationarity). A stochastic process $( X _ { t } ; t \in T )$ is called weakly stationary if

the second moments are finite: $E [ X _ { t } ^ { 2 } ] < \infty$ for all $\pm \in \pmb { T }$ ;   
the means are constant: $E [ X _ { t } ] = m$ for all $\pm \in \pmb { T }$   
the covariance of $X _ { t }$ and $X _ { t + h }$ depends on only:

$$
\gamma (h) = \gamma_ {X} (h) = C o v \left(X _ {t}, X _ {t + h}\right), \quad h \in T \text {s u c h t h a t} t + h \in T,
$$

is independent of $\pm \in \pmb { T }$ and is called the autocovariance function (ACVF). Moreover,

$$
\rho (h) = \rho_ {X} (h) = \frac {\gamma (h)}{\gamma (0)}, \qquad h \in T,
$$

is called the autocorrelation function (ACF).

Remark 1.2.1. If $( X _ { t } : t \in T ) ,$ is a strictly stationary stochastic process with finite second moments, then it is also weakly stationary. The converse is not necessarily true. If $( X _ { t } ; t \in T )$ , however, is weakly stationary and Gaussian, then it is also strictly

stationary. Recall that a stochastic process is called Gaussian $i f ,$ for any $t _ { 1 } , \dots , t _ { n } \ \in T$ , the random vector $( X _ { t _ { 1 } } , \ldots , X _ { t _ { n } } )$ is multivariate normally distributed.

This section is concluded with examples of stationary and nonstationary stochastic processes.

![](images/5fc09cdba7f810f654b0eaf3c9d2dfc2d288fcd35337be4b08b70ce92e708e02.jpg)

![](images/f07bd849f0cb9edd0e3e813d7152ecf9cd2fe8fc67e5fd98e0cd8c7cf2c1ba83.jpg)

![](images/054e0346ab0578958c142fd1cb1f92673cac456159283a5d95214f81252902e8.jpg)  
Figure 1.5: 100 simulated values of the cyclical time series (left panel), the stochastic amplitude (middle panel), and the sine part (right panel).

Example 1.2.1 (White Noise). Let $( Z _ { t } ; t \in \mathbb { Z } )$ be a sequence of real-valued, pairwise uncorrelated random variables with $\pmb { \cal E } [ Z _ { t } ] = 0$ and $0 < V a r ( Z _ { t } ) = \sigma ^ { 2 } < \infty$ for all $t \in \mathbb { Z }$ . Then $( Z _ { t } ; t \in Z )$ is called white noise, abbreviated by $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \operatorname { W N } ( 0 , \sigma ^ { 2 } )$ . It defines a centered, weakly stationary process with ACVF and ACF given by

$$
\gamma (h) = \left\{ \begin{array}{c c} {\sigma^ {2},} & {h = 0,} \\ {0,} & {h \neq 0,} \end{array} \right. \quad \mathrm {a n d} \quad \rho (h) = \left\{ \begin{array}{c c} {1,} & {h = 0,} \\ {0,} & {h \neq 0,} \end{array} \right.
$$

respectively. If the $( Z _ { t } \colon t \in \mathbb { Z } )$ are moreover independent and identically distributed, they are called iid noise, shortly $( Z _ { t } \colon t \in \mathbb { Z } )$ $\sim \operatorname { I m } ( 0 , \sigma ^ { 2 } )$ . The left panel of Figure 1.6 displays 1000 observations of an iid noise sequence $( Z _ { t } \colon t \in \mathbb { Z } )$ based on standard normal random variables. The corresponding R commands to produce the plot are

$$
\begin{array}{l} > z = \operatorname {r n o r m} (1 0 0 0, 0, 1) \\ > \text {p l o t . t s} (z, x \text {l a b} = ^ {\prime \prime \prime}, y \text {l a b} = ^ {\prime \prime \prime}, \text {m a i n} = ^ {\prime \prime \prime}) \\ \end{array}
$$

The command rnorm simulates here 1000 normal random variables with mean 0 and variance 1. There are various built-in random variable generators in R such as the functions runif(n,a,b) and rbinom $( \mathsf { n } , \mathsf { m } , \mathsf { p } )$ which simulate the $\pmb { n }$ values of a uniform distribution on the interval $( a , b )$ and a binomial distribution with repetition parameter $\pmb { m }$ and success probability $\pmb { p } _ { i }$ , respectively.

![](images/93e4b54a647a48398b2fc27afac86f809dfc96155a3ce4119b6a4d6ae9bfcbdb.jpg)

![](images/ee5878d06c58373e4994c335a32c6bf633695cc76725f088442e1ea434cb89c8.jpg)  
Figure 1.6: 1000 simulated values of iid ${ \mathrm { N } } ( 0 , 1 )$ noise (left panel) and a random walk with iid N(0, 1) innovations (right panel).

Example 1.2.2 (Cyclical Time Series). Let $\pmb { A }$ and $\pmb { B }$ be uncorrelated random variables with zero mean and variances $V a r ( A )$ ${ \bf \xi } = V a r ( B ) = \sigma ^ { 2 } { \bf \beta }$ , and let $\lambda \in \mathbb { R }$ be a frequency parameter. Define

$$
X _ {t} = A \cos (\lambda t) + B \sin (\lambda t), \qquad t \in \mathbb {R}.
$$

The resulting stochastic process $( X _ { t } { : } t \in \mathbb { R } )$ is then weakly stationary. Since $\sin ( \lambda t + \varphi ) = \sin ( \varphi ) \cos ( \lambda t ) + \cos ( \varphi ) \sin ( \lambda t )$ , the process can be represented as

$$
X _ {t} = R \sin (\lambda t + \varphi), \qquad t \in \mathbb {R},
$$

so that $\pmb { R }$ is the stochastic amplitude and $\varphi \in [ - \pi , \pi ]$ the stochastic phase of a sinusoid. Some computations show that one must have $A = R \sin ( \varphi )$ and $B = R \cos ( \varphi )$ . In the left panel of Figure 1.5, 100 observed values of a series $( X _ { t } ) _ { t \in \mathbb { Z } }$ are displayed. Therein, $\lambda$ $= \pi / 2 5$ was used, while $\pmb { R }$ and $\varphi$ were random variables uniformly distributed on the interval $( - . 5 , 1 )$ and , respectively. The middle panel shows the realization of $\scriptstyle { R _ { i } }$ the right panel the realization of $\sin ( \lambda t + \varphi )$ . Using cyclical time series bears great advantages when seasonal effects, such as annually recurrent phenomena, have to be modeled. The following R commands can be applied:

```julia
> t = 1:100; R = runif(100, -.5, 1); phi = runif(100, 0, 1); lambda = pi/25
> cyc = R*sin(lambda*t+phi)
> plot.ts(cyc, xlab="", ylab="") 
```

This produces the left panel of Figure 1.5. The middle and right panels follow in a similar fashion.

Example 1.2.3 (Random Walk). Let $( Z _ { t } \colon t \in \mathbb { N } ) \sim \mathbb { W } \mathbf { N } ( 0 , \sigma ^ { 2 } )$ . Let $\begin{array} { r } { { \cal { S } } _ { 0 } = 0 } \end{array}$ and

$$
S _ {t} = Z _ {1} + \ldots + Z _ {t}, \qquad t \in \mathbb {N}.
$$

The resulting stochastic process $( S _ { t } ; t \in \mathbb { N } _ { 0 } )$ is called a random walk and is the most important nonstationary time series. Indeed, it holds here that, for $h > 0$ ,

$$
C o v \left(S _ {t}, S _ {t + h}\right) = C o v \left(S _ {t}, S _ {t} + R _ {t, h}\right) = t \sigma^ {2},
$$

where $R _ { t , h } = Z _ { t + 1 } + \ldots + Z _ { t + h } ,$ and the ACVF obviously depends on . In R, one may construct a random walk, for example, with the following simple command that utilizes the 1000 normal observations stored in the array z of Example 1.2.1.

> rw = cumsum(z)

The function cumsum takes as input an array and returns as output an array of the same length that contains as its jth entry the sum of the first $j$ input entries. The resulting time series plot is shown in the right panel of Figure 1.6.

Chapter 3 discusses in detail so-called autoregressive moving average processes which have become a central building block in time series analysis. They are constructed from white noise sequences by an application of a set of stochastic difference equations similar to the ones defining the random walk $( S _ { t } ; t \in \mathbb { N } _ { 0 } )$ of Example 1.2.3.

In general, the true parameters of a stationary stochastic process $( X _ { t } ; t \in T )$ are unknown to the statistician. Therefore, they have to be estimated from a realization $\pmb { x } _ { 1 } , \ldots , \pmb { x } _ { n }$ . The following set of estimators will be used here. The sample mean of $\pmb { x } _ { 1 } , \ldots , \pmb { x } _ { n }$ is defined as

$$
\bar {x} = \frac {1}{n} \sum_ {t = 1} ^ {n} x _ {t}.
$$

The sample autocovariance function (sample ACVF) is given by

$$
\hat {\gamma} (h) = \frac {1}{n} \sum_ {t = 1} ^ {n - h} (x _ {t + h} - \bar {x}) (x _ {t} - \bar {x}), \qquad h = 0, 1, \dots , n - 1. \tag {1.2.1}
$$

Finally, the sample autocorrelation function (sample ACF) is

$$
\hat {\rho} (h) = \frac {\hat {\gamma} (h)}{\hat {\gamma} (0)}, \qquad h = 0, 1, \dots , n - 1.
$$

Example 1.2.4. Let $( Z _ { t } \colon t \in \mathbb { Z } )$ be a sequence of independent standard normally distributed random variables (see the left panel of Figure 1.6 for a typical realization of size $n = 1 , 0 0 0 _ { , }$ ). Then, clearly, $\gamma ( 0 ) = \rho ( 0 ) = 1$ and $\gamma ( h ) = \rho ( h ) = 0$ whenever $h \neq 0$ . Table 1.1 gives the corresponding estimated values $\hat { \gamma } ( h )$ and $\hat { \rho } ( h )$ for $h = 0 , 1 , \ldots , 5$ .

<table><tr><td>h</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>\( \hat{\gamma } (h) \)</td><td>1.069632</td><td>0.072996</td><td>-0.000046</td><td>-0.000119</td><td>0.024282</td><td>0.0013409</td></tr><tr><td>\( \hat{p} (h) \)</td><td>1.000000</td><td>0.068244</td><td>-0.000043</td><td>-0.000111</td><td>0.022700</td><td>0.0012529</td></tr></table>

Table1.1:Estimated ACVF and ACF for selected values ofh.

The estimated values are all very close to the true ones, indicating that the estimators work reasonably well for $n = 1 , 0 0 0$ . Indeed it can be shown that they are asymptotically unbiased and consistent. Moreover, the sample autocorrelations ${ \hat { \rho } } ( h )$ are approximately normal with zero mean and variance . See also Theorem 1.2.1 below. In R, the function acf can be used to compute the sample ACF.

Theorem 1.2.1. Let $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W N } ( 0 , \sigma ^ { 2 } )$ and let $h \neq 0$ . Under a general set of conditions, it holds that the sample ACF at lag , $\hat { \rho } ( h )$ , is for large approximately normally distributed with zero mean and variance 1/n.

Theorem 1.2.1 and Example 1.2.4 suggest a first method to assess whether or not a given data set can be modeled conveniently by a white noise sequence: for a white noise sequence, approximately $9 5 \%$ of the sample ACFs should be within the the confidence interval $\pm 2 / { \sqrt { n } } .$ . Using the data files on the course webpage, one can compute with R the corresponding sample ACFs to check for whiteness of the underlying time series. The properties of the sample ACF are revisited in Chapter 2.

![](images/2220b26d06960d7f828738d94a3c62af2569cdd3be8749ade229f469fdc9928a.jpg)

![](images/f274739f9606c088c3599c8472895b02d863e6f76f668b789398f0b3179a0aa3.jpg)  
Figure1.7: Annual water levels of Lake Huron (left panel) and the residual plot obtained from fitting a linear trend to the data (right panel).

This page titled 1.2: Stationary Time Series is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 1.3: Eliminating Trend Components

In this section three different methods are developed to estimate the trend of a time series model. It is assumed that it makes sense to postulate the model (1.1.1) with $\begin{array} { r } { \pmb { \mathscr { s } } _ { t } = \pmb { 0 } } \end{array}$ for all $\smash { \mathbf { \ell } \mathbf { } t \in \mathbf { \mathcal { T } } _ { : } }$ , that is,

$$
X _ {t} = m _ {t} + Y _ {t}, t \in T \tag {1.3.1}
$$

where (without loss of generality) $\pmb { \cal E } [ Y _ { t } ] = 0$ . In particular, three different methods are discussed, (1) the least squares estimation of $\mathbf { \nabla } m _ { t }$ , (2) smoothing by means of moving averages and (3) differencing.

Method 1 (Least squares estimation) It is often useful to assume that a trend component can be modeled appropriately by a polynomial,

$$
m _ {t} = b _ {0} + b _ {1} t + \dots + b _ {p} t ^ {p}, \quad p \in \mathbb {N} _ {0}.
$$

In this case, the unknown parameters $\boldsymbol { b } _ { 0 } , \dots , \boldsymbol { b } _ { p }$ can be estimated by the least squares method. Combined, they yield the estimated polynomial trend

$$
\hat {m} _ {t} = \hat {b} _ {0} + \hat {b} _ {1} t + \dots + \hat {b} _ {p} t ^ {p}, \quad t \in T,
$$

where $\hat { b } _ { 0 } , \ldots , \hat { b } _ { p }$ denote the corresponding least squares estimates. Note that the order $\pmb { p }$ is not estimated. It has to be selected by the statistician---for example, by inspecting the time series plot. The residuals $\hat { Y } _ { t }$ can be obtained as

$$
\hat {Y} _ {t} = X _ {t} - \hat {m} _ {t} = X _ {t} - \hat {b} _ {0} - \hat {b} _ {1} t - \dots - \hat {b} _ {p} t ^ {p}, \quad t \in T.
$$

How to assess the goodness of fit of the fitted trend will be subject of Section 1.5 below.

Example 1.3.1 (Level of Lake Huron). The left panel of Figure 1.7 contains the time series of the annual average water levels in feet (reduced by 570) of Lake Huron from 1875 to 1972. It is a realization of the process

$$
X _ {t} = (\text {A v e r a g e w a t e r l e v e l o f L a k e H u r o n i n t h e y e a r 1 8 7 4 + t}) - 5 7 0, \quad t = 1, \dots , 9 8.
$$

There seems to be a linear decline in the water level and it is therefore reasonable to fit a polynomial of order one to the data. Evaluating the least squares estimators provides us with the values

$$
\hat {b} _ {0} = 1 0. 2 0 2 \quad \text {a n d} \quad \hat {b} _ {1} = - 0. 0 2 4 2
$$

for the intercept and the slope, respectively. The resulting observed residuals $\hat { y } _ { t } = \hat { Y } _ { t } ( \omega )$ are plotted against time in the right panel of Figure 1.7. There is no apparent trend left in the data. On the other hand, the plot does not strongly support the stationarity of the residuals. Additionally, there is evidence of dependence in the data.

To reproduce the analysis in R, assume that the data is stored in the file lake.dat. Then use the following commands.

> lake = read.table("lake.dat")   
> lake $=$ ts(lake, start=1875)   
> t = 1:length(lake)   
> lsfit $=$ lm(lake$^\mathrm{\sim}$t)   
$>$ plot(t, lake, xlab="", ylab="", main="")   
$>$ lines(lsfit{$}fit)

The function lm fits a linear model or regression line to the Lake Huron data. To plot both the original data set and the fitted regression line into the same graph, you can first plot the water levels and then use the lines function to superimpose the fit. The residuals corresponding to the linear model fit can be accessed with the command lsfit$resid.

\end{exmp}

Method 2 (Smoothing with Moving Averages) Let $( X _ { t } ; t \in \mathbb { Z } )$ be a stochastic process following model . Choose $\pmb q \in \mathbb { N } _ { 0 }$ and define the two-sided moving average

$$
W _ {t} = \frac {1}{2 q + 1} \sum_ {j = - q} ^ {q} X _ {t + j}, \quad t \in \mathbb {Z}. \tag {1.3.2}
$$

The random variables $\mathbf { } W _ { t }$ can be utilized to estimate the trend component $\mathbf { \nabla } m _ { t }$ in the following way. First note that

$$
W _ {t} = \frac {1}{2 q + 1} \sum_ {j = - q} ^ {q} m _ {t + j} + \frac {1}{2 q + 1} \sum_ {j = - q} ^ {q} Y _ {t + j} \approx m _ {t},
$$

assuming that the trend is locally approximately linear and that the average of the $\scriptstyle \mathbf { Y } _ { t }$ over the interval $[ t - q , t + q ]$ is close to zero. Therefore, $\mathbf { \nabla } m _ { t }$ can be estimated by

$$
\hat {m} _ {t} = W _ {t}, \qquad t = q + 1, \dots , n - q.
$$

Notice that there is no possibility of estimating the first $\pmb q$ and last ${ \pmb n } - { \pmb q }$ drift terms due to the two-sided nature of the moving averages. In contrast, one can also define one-sided moving averages by letting

$$
\hat {m} _ {1} = X _ {1}, \quad \hat {m} _ {t} = a X _ {t} + (1 - a) \hat {m} _ {t - 1}, \quad t = 2, \dots , n.
$$

![](images/cc564503dfb415ec8be0aebb655f83b70ff329209f5362fad4f8a05e0f50f655.jpg)

![](images/d077d60cff812c08afb2820e8ad306b741310a720cd963bac28e36febdead33c.jpg)

![](images/70882a6bb01c93edaa02ad9e16bfe475d912e944234b7000987cab2b0de398c3.jpg)

![](images/07a222c41bcf9b22fe01ad3c48b3f26647c645dfe92582182c1377d8eeea02cb.jpg)

![](images/07eb61ea9795e7dd7f79ca209fd83885e8d159687fd858c2955f7e73b71f88c5.jpg)

![](images/1068c8a12e22f62b3d7a0571331354b1137a362c8c5ecd30af996ffb69bfbcc1.jpg)

Figure 1.8: The two-sided moving average filters Wt for the Lake Huron data (upper panel) and their residuals (lower panel) with bandwidth ${ \sf q } = 2$ (left), ${ \mathsf q } = 1 0$ (middle) and $\mathtt { q } = 3 5$ (right).

Figure 1.8 contains estimators $\hat { m } _ { t }$ based on the two-sided moving averages for the Lake Huron data of Example 1.3.1. for selected choices of $\pmb q$ (upper panel) and the corresponding estimated residuals (lower panel).

The moving average filters for this example can be produced in R in the following way:

> t = 1:length(lake)   
> ma2 = filter(lake, sides=2, rep(1,5)/5)   
> ma10 = filter(lake, sides=2, rep(1,21)/21)   
> ma35 = filter(lake, sides $^ { = 2 }$ , rep(1,71)/71)   
$>$ plot(t, ma2, xlab="", ylab="",type="l")   
$>$ lines(t,ma10); lines(t,ma35)

Therein, sides determines if a one- or two-sided filter is going to be used. The phrase rep(1,5) creates a vector of length 5 with each entry being equal to 1.

More general versions of the moving average smoothers can be obtained in the following way. Observe that in the case of the twosided version $W _ { t }$ each variable $X _ { t - q } , \ldots , X _ { t + q }$ obtains a "weight" $a _ { j } = ( 2 q + 1 ) ^ { - 1 }$ . The sum of all weights thus equals one. The same is true for the one-sided moving averages with weights $\pmb { a }$ and ${ \bf 1 } - { \pmb a } .$ . Generally, one can hence define a smoother by letting

$$
\hat {m} _ {t} = \sum_ {j = - q} ^ {q} a _ {j} X _ {t + j}, \quad t = q + 1, \dots , n - q, \tag {1.3.3}
$$

where $a _ { - q } + \ldots + a _ { q } = 1$ . These general moving averages (two-sided and one-sided) are commonly referred to as linear filters. There are countless choices for the weights. The one here, $a _ { j } = ( 2 q + 1 ) ^ { - 1 }$ , has the advantage that linear trends pass undistorted. In the next example, a filter is introduced which passes cubic trends without distortion.

Example 1.3.2 (Spencer's 15-point moving average). Suppose that the filter in display is defined by weights satisfying $\mathbf { \delta } \mathbf { a } _ { j } = \mathbf { 0 }$ if $\vert j \vert > 7$ , ${ \pmb a } _ { j } = { \pmb a } _ { - j }$ and

$$
(a _ {0}, a _ {1}, \dots , a _ {7}) = \frac {1}{3 2 0} (7 4, 6 7, 4 6, 2 1, 3, - 5, - 6, - 3).
$$

Then, the corresponding filters passes cubic trends $m _ { t } = b _ { 0 } + b _ { 1 } t + b _ { 2 } t ^ { 2 } + b _ { 3 } t ^ { 3 }$ undistorted. To see this, observe that

$$
\sum_ {j = - 7} ^ {7} a _ {j} = 1 \qquad \text {a n d} \qquad \sum_ {j = - 7} ^ {7} j ^ {r} a _ {j} = 0, \qquad r = 1, 2, 3.
$$

Now apply Proposition 1.3.1 below to arrive at the conclusion. Assuming that the observations are in data, use the R commands

$$
\begin{array}{l} > a = c (- 3, - 6, - 5, 3, 2 1, 4 6, 6 7, 7 4, 6 7, 4 6, 2 1, 3, - 5, - 6, - 3) / 3 2 0 \\ > s 1 5 = f i l t e r (d a t a, s i d e s = 2, a) \\ \end{array}
$$

to apply Spencer's 15-point moving average filter. This example also explains how to specify a general tailor-made filter for a given data set.

Proposition 1.3.1. A linear filter (1.3.3) passes a polynomial of degree if and only if

$$
\sum_ {j} a _ {j} = 1 \qquad \text {a n d} \qquad \sum_ {j} j ^ {r} a _ {j} = 0, \qquad r = 1, \dots , p.
$$

Proof. It suffices to show that $\begin{array} { r } { \sum _ { j } a _ { j } ( t + j ) ^ { r } = t ^ { r } } \end{array}$ for $r = 0 , \ldots , p .$ . Using the binomial theorem, write

$$
\begin{array}{l} \sum_ {j} a _ {j} (t + j) ^ {r} = \sum_ {j} a _ {j} \sum_ {k = 0} ^ {r} {\binom {r} {k}} t ^ {k} j ^ {r - k} \\ = \sum_ {k = 0} ^ {r} \binom {r} {k} t ^ {k} \left(\sum_ {j} a _ {j} j ^ {r - k}\right) \\ = t ^ {r} \\ \end{array}
$$

for any $\boldsymbol { r } = 0 , \ldots , \boldsymbol { p }$ if and only if the above conditions hold.

![](images/33d6fd4c90026b762897b30a7afaf7a25185da914822fbd42dc7c7f85b0e93b9.jpg)

![](images/299b3906d8d37550c180b34f6efefbaa9a86fbb89313846ed52e3657b088461b.jpg)  
Figure 1.9: Time series plots of the observed sequences (∇xt) in the left panel and (∇2xt) in the right panel of the differenced Lake Huron data described in Example 1.3.1.

Method 3 (Differencing) A third possibility to remove drift terms from a given time series is differencing. To this end, introduce the difference operator $\mathbf { v }$ as

$$
\nabla X _ {t} = X _ {t} - X _ {t - 1} = (1 - B) X _ {t}, \qquad t \in T,
$$

where $\pmb { B }$ denotes the backshift operator $B X _ { t } = X _ { t - 1 }$ . Repeated application of $\boldsymbol { \nabla }$ is defined in the intuitive way:

$$
\nabla^ {2} X _ {t} = \nabla (\nabla X _ {t}) = \nabla (X _ {t} - X _ {t - 1}) = X _ {t} - 2 X _ {t - 1} + X _ {t - 2}
$$

and, recursively, the representations follow also for higher powers of . Suppose that the difference operator is applied to the linear trend $m _ { t } = b _ { 0 } + b _ { 1 } t$ , then

$$
\nabla m _ {t} = m _ {t} - m _ {t - 1} = b _ {0} + b _ {1} t - b _ {0} - b _ {1} (t - 1) = b _ {1}
$$

which is a constant. Inductively, this leads to the conclusion that for a polynomial drift of degree , namely $\begin{array} { r } { m _ { t } = \sum _ { j = 0 } ^ { p } b _ { j } t ^ { j } } \end{array}$ , $\nabla ^ { p } m _ { t }$ $= p ! b _ { p }$ and thus constant. Applying this technique to a stochastic process of the form (1.3.1) with a polynomial drift ${ \mathbf { } } m _ { t } ,$ yields then

$$
\nabla^ {p} X _ {t} = p \mathrm {l b} _ {p} + \nabla^ {p} Y _ {t}, \qquad t \in T.
$$

This is a stationary process with mean $\pmb { p } ! b _ { p }$ . The plots in Figure 1.9 contain the first and second differences for the Lake Huron data. In R, they may be obtained from the commands

$>$   
$>$   
$>$

The next example shows that the difference operator can also be applied to a random walk to create stationary data.

Example 1.3.3. Let $( S _ { t } { : } t \in \mathbb { N } _ { 0 } )$ be the random walk of Example 1.2.3. If the difference operator $\mathbf { v }$ is applied to this stochastic process, then

$$
\nabla S _ {t} = S _ {t} - S _ {t - 1} = Z _ {t}, \qquad t \in \mathbb {N}.
$$

In other words, does nothing else but recover the original white noise sequence that was used to build the random walk.

This page titled 1.3: Eliminating Trend Components is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 1.4: Eliminating Trend and Seasonal Components

Recall the classical decomposition (1.1.1),

$$
X _ {t} = m _ {t} + s _ {t} + Y _ {t}, \qquad t \in T,
$$

with $\pmb { \cal E } [ Y _ { t } ] = 0$ . In this section, three methods are discussed that aim at estimating both the trend and seasonal components in the data. As additional requirement on $( s _ { t } ; t \in T )$ , it is assumed that

$$
s _ {t + d} = s _ {t}, \quad \sum_ {j = 1} ^ {d} s _ {j} = 0,
$$

where $\pmb { d }$ denotes the period of the seasonal component. (If dealing with yearly data sampled monthly, then obviously $d = 1 2 .$ .) It is convenient to relabel the observations ${ \pmb x } _ { 1 } , \ldots , { \pmb x } _ { n }$ in terms of the seasonal period $\pmb { d }$ as

$$
x _ {j, k} = x _ {k + d (j - 1)}.
$$

In the case of yearly data, observation $\pmb { x } _ { j , \pmb { k } }$ thus represents the data point observed for the th month of the th year. For convenience the data is always referred to in this fashion even if the actual period is something other than 12.

Method 1 (Small trend method) If the changes in the drift term appear to be small, then it is reasonable to assume that the drift in year $j$ , say, $\mathbf { \Delta } m _ { j }$ is constant. As a natural estimator one can therefore apply

$$
\hat {m} _ {j} = \frac {1}{d} \sum_ {k = 1} ^ {d} x _ {j, k}.
$$

To estimate the seasonality in the data, one can in a second step utilize the quantities

$$
\hat {s} _ {k} = \frac {1}{N} \sum_ {j = 1} ^ {N} \left(x _ {j, k} - \hat {m} _ {j}\right),
$$

where $\pmb { N }$ is determined by the equation $\pmb { n } = \pmb { N } d$ , provided that data has been collected over full cycles. Direct calculations show that these estimators possess the property $\hat { \pmb { s } } _ { 1 } + . . . + \hat { \pmb { s } } _ { d } = 0$ (as in the case of the true seasonal components $\pmb { \mathscr { s } } _ { t }$ ). To further assess the quality of the fit, one needs to analyze the observed residuals

$$
\hat {y} _ {j, k} = x _ {j, k} - \hat {m} _ {j} - \hat {s} _ {k}.
$$

Note that due to the relabeling of the observations and the assumption of a slowly changing trend, the drift component is solely described by the "annual'' subscript ${ \bf { \nabla } } j ,$ while the seasonal component only contains the "monthly'' subscript .

![](images/455ea3b00f66177286a7d20289cf03cd32ef0c7c3338e001ff9156a162fda88a.jpg)

![](images/3b498682bedc647a1ec6cd6b67dc34bab424fba377c692f7dfb576e2cfe98a69.jpg)  
Figure 1.10: Time series plots of the red wine sales in Australia from January 1980 to October 1991 (left) and its log transformation with yearly mean estimates (right).

Example 1.4.1 (Australian Wine Sales). The left panel of Figure 1.10 shows the monthly sales of red wine (in kiloliters) in Australia from January 1980 to October 1991. Since there is an apparent increase in the fluctuations over time, the right panel of the same figure shows the natural logarithm transform of the data. There is clear evidence of both trend and seasonality. In the following, the log transformed data is studied. Using the small trend method as described above, the annual means are estimated first. They are already incorporated in the right time series plot of Figure 1.10. Note that there are only ten months of data available for the year 1991, so that the estimation has to be adjusted accordingly. The detrended data is shown in the left panel of Figure 1.11. The middle plot in the same figure shows the estimated seasonal component, while the right panel displays the residuals. Even though the assumption of small changes in the drift is somewhat questionable, the residuals appear to look quite nice. They indicate that there is dependence in the data (see Section 1.5 below for more on this subject).

![](images/e5ff15f63ef5610f9197923e4c7ebbc670440e5cd09dfab892d462c1ce1ab1a7.jpg)

![](images/c3e419c8fa940bd29ddb6d94c8e2ecdca17f0b5ff6189becb7867cf10798a30c.jpg)

![](images/29741873e2ff92942f339ab1acd549aca3cb016e3777c92eac20188618cef324.jpg)  
Figure 1.11: The detrended log series (left), the estimated seasonal component (center) and the corresponding residuals series (right) of the Australian red wine sales data.

Method 2 (Moving average estimation) This method is to be preferred over the first one whenever the underlying trend component cannot be assumed constant. Three steps are to be applied to the data.

1st Step: Trend estimation. At first, focus on the removal of the trend component with the linear filters discussed in the previous section. If the period $\pmb { d }$ is odd, then one can directly use $\hat { m } _ { t } = \bar { W } _ { t }$ as in (1.3.2) with $\pmb q$ specified by the equation $d = 2 q + 1 .$ . If the period $d = 2 q$ is even, then slightly modify $\mathbf { } W _ { t }$ and use

$$
\hat {m} _ {t} = \frac {1}{d} \left(. 5 x _ {t - q} + x _ {t - q + 1} + \dots + x _ {t + q - 1} +. 5 x _ {t + q}\right), \quad t = q + 1, \dots , n - q.
$$

2nd Step: Seasonality estimation. To estimate the seasonal component, let

$$
\mu_ {k} = \frac {1}{N - 1} \sum_ {j = 2} ^ {N} (x _ {k + d (j - 1)} - \hat {m} _ {k + d (j - 1)}), \qquad k = 1, \ldots , q,
$$

$$
\mu_ {k} = \frac {1}{N - 1} \sum_ {j = 1} ^ {N - 1} \left(x _ {k + d (j - 1)} - \hat {m} _ {k + d (j - 1)}\right), \qquad k = q + 1, \dots , d.
$$

Define now

$$
\hat {s} _ {k} = \mu_ {k} - \frac {1}{d} \sum_ {\ell = 1} ^ {d} \mu_ {\ell}, \quad k = 1, \dots , d,
$$

and set $\hat { s } _ { k } = \hat { s } _ { k - d }$ whenever $k > d$ . This will provide us with deseasonalized data which can be examined further. In the final step, any remaining trend can be removed from the data.

3rd Step: Trend Reestimation. Apply any of the methods from Section 1.3.

Method 3 (Differencing at lag d) Introducing the lag-d difference operator $\nabla _ { d } ,$ , defined by letting

$$
\nabla_ {d} X _ {t} = X _ {t} - X _ {t - d} = (1 - B ^ {d}) X _ {t}, \qquad t = d + 1, \dots , n,
$$

and assuming model (1.1.1), one arrives at the transformed random variables

$$
\nabla_ {d} X _ {t} = m _ {t} - m _ {t - d} + Y _ {t} - Y _ {t - d}, \quad t = d + 1, \dots , n.
$$

Note that the seasonality is removed, since $\begin{array} { r } { \pmb { \mathscr { s } } _ { t } = \pmb { \mathscr { s } } _ { t - d } . } \end{array}$ . The remaining noise variables $Y _ { t } - Y _ { t - d }$ are stationary and have zero mean. The new trend component $m _ { t } - m _ { t - d }$ can be eliminated using any of the methods developed in Section 1.3.

![](images/8407f9d08f920f218ae020c66d8ee8265785180ff527c4a4160a7754a8ac4e0a.jpg)

![](images/b12701c343aa4b16930ae4dcf0b5c2e1fef975a166c777c48d0369a5d6bae23f.jpg)

![](images/af9d8c27ad7cd3fa0ca98e4fdfa0e987db697aaa2131ad6ebb6d461f6c76ecb7.jpg)  
Figure 1.12: The differenced observed series $\nabla _ { 1 2 } x _ { t }$ (left), $\nabla \pmb { x } _ { t }$ (middle) and $\nabla \nabla _ { 1 2 } x _ { t } = \nabla _ { 1 2 } \nabla x _ { t }$ (right) for the Australian red wine sales data.

Example 1.4.2 (Australian wine sales). Revisit the Australian red wine sales data of Example 1.4.1 and apply the differencing techniques just established. The left plot of Figure 1.12 shows the the data after an application of the operator $\nabla _ { 1 2 }$ . If the remaining trend in the data is estimated with the differencing method from Section 1.3, the residual plot given in the right panel of Figure 1.12 is obtained. Note that the order of application does not change the residuals, that is, $\nabla \nabla _ { 1 2 } x _ { t } = \nabla _ { 1 2 } \nabla x _ { t }$ . The middle panel of Figure 1.12 displays the differenced data which still contains the seasonal component.

This page titled 1.4: Eliminating Trend and Seasonal Components is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 1.5: Assessing the Residuals

In this subsection, several goodness-of-fit tests are introduced to further analyze the residuals obtained after the elimination of trend and seasonal components. The main objective is to determine whether or not these residuals can be regarded as obtained from a sequence of independent, identically distributed random variables or if there is dependence in the data. Throughout $Y _ { 1 } , \dots , Y _ { n }$ denote the residuals and $y _ { 1 } , \ldots , y _ { n }$ a typical realization.

Method 1 (The sample ACF) It could be seen in Example 1.2.4 that, for $j \neq 0$ , the estimators $\hat { \rho } ( j )$ of the ACF $\pmb { \rho } ( j )$ are asymptotically independent and normally distributed with mean zero and variance $\pmb { n } ^ { - 1 }$ , provided the underlying residuals are independent and identically distributed with a finite variance. Therefore, plotting the sample ACF for a certain number of lags, say $\begin{array} { r } { \pmb { h } , } \end{array}$ it is expected that approximately $9 5 \%$ of these values are within the bounds $\pm 1 . 9 6 / \sqrt { n }$ . The R function acf helps to perform this analysis. (See Theorem 1.2.1)

Method 2 (The Portmanteau test) The Portmanteau test is based on the test statistic

$$
Q = n \sum_ {j = 1} ^ {h} \hat {\rho} ^ {2} (j).
$$

Using the fact that the variables $\sqrt { n } \hat { \rho } ( j )$ are asymptotically standard normal, it becomes apparent that $\pmb { Q }$ itself can be approximated with a chi-squared distribution possessing $\pmb { h }$ degrees of freedom. The hypothesis of independent and identically distributed residuals is rejected at the level $\pmb { \alpha }$ if $Q > \chi _ { 1 - \alpha } ^ { 2 } ( h )$ , where $x _ { 1 - \alpha } ^ { 2 } ( h )$ is the ${ \bf 1 } - { \pmb \alpha }$ quantile of the chi-squared distribution with $\pmb { h }$ degrees of freedom. Several refinements of the original Portmanteau test have been established in the literature. We refer here only to the papers Ljung and Box (1978), and McLeod and Li (1983) for further information.

Method 3 (The rank test) This test is very useful for finding linear trends. Denote by

$$
\Pi = \# \{(i, j): Y _ {i} > Y _ {j}, i > j, i = 2, \dots , n \}
$$

the random number of pairs $( i , j )$ satisfying the conditions $Y _ { i } > Y _ { j }$ and $i > j$ . There are $\textstyle { { \binom { n } { 2 } } = { \frac { 1 } { 2 } } n ( n - 1 ) }$ pairs $( i , j )$ such that $i > j$ . If $Y _ { 1 } , \dots , Y _ { n }$ are independent and identically distributed, then $P ( Y _ { i } > Y _ { j } ) = 1 / 2$ (assuming a continuous distribution). Now it follows that $\begin{array} { r } { \mu _ { \Pi } = E [ \Pi ] = \frac { 1 } { 4 } n ( n - 1 ) } \end{array}$ and, similarly, $\begin{array} { r } { \sigma _ { \Pi } ^ { 2 } = \mathrm { V a r } ( \Pi ) = \frac { 1 } { 7 2 } n ( n - 1 ) ( 2 n + 5 ) } \end{array}$ . Moreover, for large enough sample sizes $\pmb { n }$ , has an approximate normal distribution with mean $\pmb { \mu \pi }$ and variance $\pmb { \sigma _ { \Pi } ^ { 2 } }$ . Consequently, the hypothesis of independent, identically distributed data would be rejected at the level $\pmb { \alpha }$ if

$$
P = \frac {\left| \Pi - \mu_ {\Pi} \right|}{\sigma_ {\Pi}} > z _ {1 - \alpha / 2},
$$

where $z _ { 1 - \alpha / 2 }$ denotes the ${ \bf 1 } - { \pmb \alpha } / { \bf 2 }$ quantile of the standard normal distribution.

Method 4 (Tests for normality) If there is evidence that the data are generated by Gaussian random variables, one can create the qq plot to check for normality. It is based on a visual inspection of the data. To this end, denote by $Y _ { ( 1 ) } < \ldots < Y _ { ( n ) }$ the order statistics of the residuals $Y _ { 1 } , \dots , Y _ { n }$ which are normally distributed with expected value $\mu$ and variance $\pmb { \sigma } ^ { 2 }$ . It holds that

$$
E [ Y _ {(j)} ] = \mu + \sigma E [ X _ {(j)} ], \tag {1.5.1}
$$

where $X _ { ( 1 ) } < \ldots < X _ { ( n ) }$ are the order statistics of a standard normal distribution. The qq plot is defined as the graph of the pairs $( E [ X _ { ( 1 ) } ] , Y _ { ( 1 ) } ) , \dots , ( E [ X _ { ( n ) } ] , Y _ { ( n ) } )$ . According to display (1.5.1), the resulting graph will be approximately linear with the squared correlation $\scriptstyle { \pmb { R } } ^ { 2 }$ of the points being close to 1. The assumption of normality will thus be rejected if $\scriptstyle { \pmb R } ^ { 2 }$ is "too'' small. It is common to approximate $E [ X _ { ( j ) } ] \approx \Phi _ { j } = \Phi ^ { - 1 } ( ( j - . 5 ) / n )$ ( $\bar { \Phi }$ being the distribution function of the standard normal distribution). The previous statement is made precise by letting

$$
R ^ {2} = \frac {\left[ \sum_ {j = 1} ^ {n} (Y _ {(j)} - \bar {Y}) \Phi_ {j} \right] ^ {2}}{\sum_ {j = 1} ^ {n} (Y _ {(j)} - \bar {Y}) ^ {2} \sum_ {j = 1} ^ {n} \Phi_ {j} ^ {2}},
$$

where $\begin{array} { r } { \bar { Y } = \frac { 1 } { n } ( Y _ { 1 } + \ldots + Y _ { n } ) } \end{array}$ . The critical values for $\scriptstyle { \pmb { R } } ^ { 2 }$ are tabulated and can be found, for example in Shapiro and Francia (1972). The corresponding R function is qqnorm.

This page titled 1.5: Assessing the Residuals is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 1.6: Summary

In this chapter, the classical decomposition (1.1.1) of a time series into a drift component, a seasonal component and a sequence of residuals was introduced. Methods to estimate the drift and the seasonality were provided. Moreover, the class of stationary processes was identified as a reasonably broad class of random variables. Several ways were introduced to check whether or not the resulting residuals can be considered to be independent, identically distributed. In Chapter 3, the class of autoregressive moving average (ARMA) processes is discussed in depth, a parametric class of random variables that are at the center of linear time series analysis because they are able to capture a wide range of dependence structures and allow for a thorough mathematical treatment. Before, properties of the sample mean, sample ACVF and ACF are considered in the next chapter.

This page titled 1.6: Summary is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# CHAPTER OVERVIEW

# 2: The Estimation of Mean and Covariances

In this brief second chapter, some results concerning asymptotic properties of the sample mean and the sample ACVF are collected. Throughout, $( X _ { t } ; t \in \mathbb { Z } )$ denotes a weakly stationary stochastic process with mean $\pmb { \mu }$ and ACVF $\gamma .$ In Section 1.2 it was shown that such a process is completely characterized by these two quantities. The mean $\pmb { \mu }$ was estimated by the sample mean , and the ACVF $\gamma$ by the sample ACVF $\hat { \gamma }$ defined in (1.2.1). In the following, some properties of these estimators are discussed in more detail.

2.1: Estimation of the Mean   
2.2: Estimation of the Autocovariance Function

# 2.1: Estimation of the Mean

Assume that an appropriate guess for the unknown mean $\pmb { \mu }$ of some weakly stationary stochastic process $( X _ { t } ; t \in \mathbb { Z } )$ has to be found. The sample mean , easily computed as the average of $\pmb { n }$ observations ${ \pmb x } _ { 1 } , \ldots , { \pmb x } _ { n }$ of the process, has been identified as suitable in Section 1.2. To investigate its theoretical properties, one needs to analyze the random variable associated with it, that is,

$$
\bar {X} _ {n} = \frac {1}{n} (X _ {1} + \ldots + X _ {n}).
$$

Two facts can be quickly established.

· ${ \bar { X } } _ { n }$ is an unbiased estimator for $\pmb { \mu } ,$ , since

$$
E [ \bar {X} _ {n} ] = E \left[ \frac {1}{n} \sum_ {t = 1} ^ {n} X _ {t} \right] = \frac {1}{n} \sum_ {t = 1} ^ {n} E [ X _ {t} ] = \frac {1}{n} n \mu = \mu .
$$

This means that "on average'', the true but unknown $\pmb { \mu }$ is correctly estimated. Notice that there is no difference in the computations between the standard case of independent and identically distributed random variables and the more general weakly stationary process considered here.

If $\gamma ( n )  0$ as $\pmb { n }  \infty$ , then ${ \bar { X } } _ { n }$ is a consistent estimator for $\pmb { \mu }$ , since

$$
\begin{array}{l} \operatorname {V a r} (\bar {X} _ {n}) = \operatorname {C o v} \left(\frac {1}{n} \sum_ {s = 1} ^ {n} X _ {s}, \frac {1}{n} \sum_ {t = 1} ^ {n} X _ {t}\right) = \frac {1}{n ^ {2}} \sum_ {s = 1} ^ {n} \sum_ {t = 1} ^ {n} \operatorname {C o v} (X _ {s}, X _ {t}) \\ = \frac {1}{n ^ {2}} \sum_ {s - t = - n} ^ {n} (n - | s - t |) \gamma (s - t) = \frac {1}{n} \sum_ {h = - n} ^ {n} \left(1 - \frac {| h |}{n}\right) \gamma (h). \\ \end{array}
$$

Now, the quantity on the right-hand side converges to zero as $\pmb { n }  \infty$ because $\gamma ( n )  0$ as $\pmb { n }  \infty$ by assumption. The first equality sign in the latter equation array follows from the fact that $\operatorname { V a r } ( X ) = \operatorname { C o v } ( X , X )$ for any random variable $\pmb { X } _ { \mathrm { { i } } }$ , the second equality sign uses that the covariance function is linear in both arguments. For the third equality, one can use that $\operatorname { C o v } ( X _ { s } , X _ { t } ) = \gamma ( s - t )$ and that each $\gamma ( \pmb { \mathscr { s } } - \pmb { \mathscr { t } } )$ appears exactly $\pmb { n } - | \pmb { s } - \pmb { t } |$ times in the double summation. Finally, the right-hand side is obtained by replacing $\bullet - t$ with $\pmb { h }$ and pulling one $\pmb { n } ^ { - 1 }$ inside the summation.

In the standard case of independent and identically distributed random variables $n \mathrm { V a r } ( \bar { X } ) = \sigma ^ { 2 }$ . The condition $\gamma ( n )  0$ is automatically satisfied. However, in the general case of weakly stationary processes, it cannot be omitted.

More can be proved using an appropriate set of assumptions. The results are formulated as a theorem without giving the proofs.

# Theorem

Let $( X _ { t } ; t \in \mathbb { Z } )$ be a weakly stationary stochastic process with mean $\pmb { \mu }$ and ACVF $\gamma$ . Then, the following statements hold true as $\pmb { n }  \infty$ .

a. If $\scriptstyle \sum _ { h = - \infty } ^ { \infty } | \gamma ( h ) | < \infty$ , then

$$
n \operatorname {V a r} (\bar {X} _ {n}) \rightarrow \sum_ {h = - \infty} ^ {\infty} \gamma (h) = \tau^ {2};
$$

b. If the process is "close to Gaussianity'', then

$$
\sqrt {n} (\bar {X} _ {n} - \mu) \sim A N (0, \tau_ {n} ^ {2}), \qquad \tau_ {n} ^ {2} = \sum_ {h = - n} ^ {n} \left(1 - \frac {| h |}{n}\right) \gamma (h).
$$

Here, $\sim A N ( 0 , \tau _ { n } ^ { 2 } )$ stands for approximately normally distributed with mean zero and variance $\tau _ { n } ^ { 2 }$

Theorem can be utilized to construct confidence intervals for the unknown mean parameter $\pmb { \mu }$ . To do so, one must, however, estimate the unknown variance parameter $\tau _ { n }$ . For a large class of stochastic processes, it holds that $\tau _ { n } ^ { 2 }$ converges to $\tau ^ { 2 }$ as $\pmb { n }  \infty$ . Therefore, we can use $\tau ^ { 2 }$ as an approximation for $\tau _ { n } ^ { 2 }$ . Moreover, $\pmb { \tau ^ { 2 } }$ can be estimated by

$$
\hat {\tau} _ {n} ^ {2} = \sum_ {h = - \sqrt {n}} ^ {\sqrt {n}} \left(1 - \frac {| h |}{n}\right) \hat {\gamma} (h),
$$

where $\hat { \gamma } ( h )$ denotes the ACVF estimator defined in (1.2.1). An approximate $9 5 \%$ confidence interval for $\pmb { \mu }$ can now be constructed as

$$
\left(\bar {X} _ {n} - 1. 9 6 \frac {\hat {\tau} _ {n}}{\sqrt {n}}, \bar {X} _ {n} + 1. 9 6 \frac {\hat {\tau} _ {n}}{\sqrt {n}}\right).
$$

# Example : Autoregressive Processes

Let $( X _ { t } ; t \in \mathbb { Z } )$ be given by the equations

$$
X _ {t} - \mu = \phi \left(X _ {t - 1} - \mu\right) + Z _ {t}, \quad t \in \mathbb {Z}, \tag {2.1.1}
$$

where $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W } \mathbf { N } ( 0 , \sigma ^ { 2 } )$ and $| \phi | < 1$ . It will be shown in Chapter 3 that $( X _ { t } { : } t \in \mathbb { Z } )$ defines a weakly stationary process. Utilizing the stochastic difference Equations , both mean and autocovariances can be determined. It holds that $E [ X _ { t } ]$ $= \phi E [ X _ { t - 1 } ] + \mu ( 1 - \phi )$ . Since, by stationarity, $\pmb { \cal E } [ X _ { t - 1 } ]$ can be substituted with $E [ X _ { t } ]$ , it follows that

$$
E [ X _ {t} ] = \mu , \qquad t \in \mathbb {Z}.
$$

In the following we shall work with the process $( X _ { t } ^ { c } { : } t \in \mathbb { Z } )$ given by letting $X _ { t } ^ { c } = X _ { t } - \mu$ . Clearly, $E [ X _ { t } ^ { c } ] = 0$ . From the definition, it follows also that the covariances of $\left( X _ { t } ; t \in \mathbb { Z } \right)$ and $( X _ { t } ^ { c } { : } t \in \mathbb { Z } )$ coincide. First computing the second moment of $X _ { t } ^ { c }$ , gives

$$
E [ \{X _ {t} ^ {c} \} ^ {2} ] = E [ (\phi X _ {t - 1} ^ {c} + Z _ {t}) ^ {2} ] = \phi^ {2} E [ \{X _ {t - 1} ^ {c} \} ^ {2} ] + \sigma^ {2}
$$

and consequently, since $E [ \{ X _ { t - 1 } ^ { c } \} ^ { 2 } ] = E [ \{ X _ { t } ^ { c } \} ^ { 2 } ]$ by weak stationarity of $( X _ { t } ^ { c } { : } t \in \mathbb { Z } )$

$$
E [ \{X _ {t} ^ {c} \} ^ {2} ] = \frac {\sigma^ {2}}{1 - \phi^ {2}}, \qquad t \in \mathbb {Z}.
$$

It becomes apparent from the latter equation, why the condition $| \phi | < 1$ was needed in display (2.1.1). In the next step, the autocovariance function is computed. For $\pmb { h } > \mathbf { 0 }$ , it holds that

$$
\gamma (h) = E \left[ X _ {t + h} ^ {c} X _ {t} ^ {c} \right] = E \left[ \left(\phi X _ {t + h - 1} ^ {c} + Z _ {t + h}\right) X _ {t} ^ {c} \right] = \phi E \left[ X _ {t + h - 1} ^ {c} X _ {t} ^ {c} \right] = \phi \gamma (h - 1) = \phi^ {h} \gamma (0)
$$

after $\pmb { h }$ iterations. But since $\gamma ( 0 ) = E [ \{ X _ { t } ^ { c } \} ^ { 2 } ]$ , by symmetry of the ACVF, it follows that

$$
\gamma (h) = \frac {\sigma^ {2} \phi^ {| h |}}{1 - \phi^ {2}}, \qquad h \in \mathbb {Z}.
$$

After these theoretical considerations, a $9 5 \%$ (asymptotic) confidence interval for the mean parameter $\pmb { \mu }$ can be constructed. To check if Theorem 2.1.1 is applicable here, one needs to check if the autocovariances are absolutely summable:

$$
\begin{array}{l} \tau^ {2} = \sum_ {h = - \infty} ^ {\infty} \gamma (h) = \frac {\sigma^ {2}}{1 - \phi^ {2}} \left(1 + 2 \sum_ {h = 1} ^ {\infty} \phi^ {h}\right) = \frac {\sigma^ {2}}{1 - \phi^ {2}} \left(1 + \frac {2}{1 - \phi} - 2\right) \\ = \frac {\sigma^ {2}}{1 - \phi^ {2}} \frac {1}{1 - \phi} (1 + \phi) = \frac {\sigma^ {2}}{(1 - \phi) ^ {2}} <   \infty . \\ \end{array}
$$

Therefore, a $9 5 \%$ confidence interval for $\mu$ which is based on the observed values ${ \pmb x } _ { 1 } , \ldots , { \pmb x } _ { n }$ is given by

$$
\left(\bar {x} - 1. 9 6 \frac {\sigma}{\sqrt {n} (1 - \phi)}, \bar {x} + 1. 9 6 \frac {\sigma}{\sqrt {n} (1 - \phi)}\right).
$$

Therein, the parameters $\pmb { \sigma }$ and $\phi$ have to be replaced with appropriate estimators. These will be introduced in Chapter 3.

# 2.2: Estimation of the Autocovariance Function

This section deals with the estimation of the ACVF and ACF at lag . Recall from equation (1.2.1) that the estimator

$$
\hat {\gamma} (h) = \frac {1}{n} \sum_ {t = 1} ^ {n - | h |} \left(X _ {t + | h |} - \bar {X} _ {n}\right) \left(X _ {t} - \bar {X} _ {n}\right), \quad h = 0, \pm 1, \dots , \pm (n - 1),
$$

may be utilized as a proxy for the unknown $\gamma ( h )$ . As estimator for the ACF $\pmb { \rho } ( h )$ ,

$$
\hat {\rho} (h) = \frac {\hat {\gamma} (h)}{\hat {\gamma} (0)}, \quad h = 0, \pm 1, \dots , \pm (n - 1),
$$

was identified. Some of the theoretical properties of $\hat { \rho } ( h )$ are briefly collected in the following. They are not as obvious to derive as in the case of the sample mean, and all proofs are omitted. Note also that similar statements hold for $\hat { \gamma } ( h )$ as well.

The estimator $\hat { \rho } ( h )$ is generally biased, that is, $E [ \hat { \rho } ( h ) ] \neq \rho ( h )$ . It holds, however, under non-restrictive assumptions that

$$
E [ \hat {\rho} (h) ] \rightarrow \rho (h) \quad (n \rightarrow \infty).
$$

This property is called asymptotic unbiasedness.

The estimator $\hat { \rho } ( h )$ is consistent for $\pmb { \rho } ( h )$ under an appropriate set of assumptions, that is, $\operatorname { V a r } ( \hat { \rho } ( h ) - \rho ( h ) ) \to 0$ as $\pmb { n }  \infty$

It was already established in Section 1.5 how the sample ACF $\hat { \pmb \rho }$ can be used to test if residuals consist of white noise variables. For more general statistical inference, one needs to know the sampling distribution of $\hat { \pmb \rho }$ . Since the estimation of $\pmb { \rho } ( h )$ is based on only a few observations for $\pmb { h }$ close to the sample size $\pmb { n }$ , estimates tend to be unreliable. As a rule of thumb, given by Box and Jenkins (1976), $\pmb { n }$ should at least be 50 and $\pmb { h }$ less than or equal to $n / 4$ .

# Theorem

For $m \geq 1$ , let $\rho _ { m } = ( \rho ( 1 ) , \ldots , \rho ( m ) ) ^ { T }$ and $\hat { \rho } _ { m } = ( \hat { \rho } ( 1 ) , \dots , \hat { \rho } ( m ) ) ^ { T }$ , where denotes the transpose of a vector. Under a set of suitable assumptions, it holds that

$$
\sqrt {n} \left(\hat {\rho} _ {m} - \rho_ {m}\right) \sim A N (\mathbf {0}, \Sigma) \quad (n \rightarrow \infty),
$$

where $\sim A N ( 0 , \Sigma )$ stands for approximately normally distributed with mean vector and covariance matrix ${ \pmb { \Sigma } } = ( \sigma _ { i j } )$ given by Bartlett's formula

$$
\sigma_ {i j} = \sum_ {k = 1} ^ {\infty} \left[ \rho (k + i) + \rho (k - i) - 2 \rho (i) \rho (k) \right] \left[ \rho (k + j) + \rho (k - j) - 2 \rho (j) \rho (k) \right].
$$

The section is concluded with two examples. The first one recollects the results already known for independent, identically distributed random variables, the second deals with the autoregressive process of Example (2.2.1).

# Example

Let $( X _ { t } ; t \in \mathbb { Z } ) \sim \mathbb { I D } ( 0 , \sigma ^ { 2 } )$ . Then, $\pmb { \rho } ( \mathbf { 0 } ) = \mathbf { 1 }$ and $\pmb { \rho } ( h ) = \pmb 0$ for all $\pmb { h } \neq \mathbf { 0 }$ . The covariance matrix $\pmb { \Sigma }$ is therefore given by

$$
\sigma_ {i j} = 1 \quad \text {i f} i = j \qquad a n d \qquad \sigma_ {i j} = 0 \quad \text {i f} i \neq j.
$$

This means that $\pmb { \Sigma }$ is a diagonal matrix. In view of Theorem 2.2.1 it holds thus that the estimators $\hat { \rho } ( 1 ) , \dots , \hat { \rho } ( k )$ are approximately independent and identically distributed normal random variables with mean 0 and variance $1 / n$ . This was the basis for Methods 1 and 2 in Section 1.6 (see also Theorem 1.2.1).

# Example

Reconsider the autoregressive process $( X _ { t } ; t \in \mathbb { Z } )$ from Example 2.1.1 with $\pmb { \mu } = 0$ . Dividing $\gamma ( h )$ by $\gamma ( 0 )$ yields that

$$
\rho (h) = \phi^ {| h |}, \qquad h \in \mathbb {Z}.
$$

Now the diagonal entries of $\pmb { \Sigma }$ are computed as

$$
\begin{array}{l} \sigma_ {i i} = \sum_ {k = 1} ^ {\infty} [ \rho (k + i) + \rho (k - i) - 2 \rho (i) \rho (k) ] ^ {2} \\ = \sum_ {k = 1} ^ {i} \phi^ {2 i} (\phi^ {- k} - \phi^ {k}) ^ {2} + \sum_ {k = i + 1} ^ {\infty} \phi^ {2 k} (\phi^ {- i} - \phi^ {i}) ^ {2} \\ = (1 - \phi^ {2 i}) (1 + \phi^ {2}) (1 - \phi^ {2}) ^ {- 1} - 2 i \phi^ {2 i}. \\ \end{array}
$$

This page titled 2.2: Estimation of the Autocovariance Function is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# CHAPTER OVERVIEW

# 3: ARMA Processes

In this chapter autoregressive moving average processes are discussed. They play a crucial role in specifying time series models for applications. As the solutions of stochastic difference equations with constant coefficients and these processes possess a linear structure.

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes   
3.2: Causality and Invertibility   
3.3: The PACF of a Causal ARMA Process   
3.4: Forecasting   
3.5: Parameter Estimation   
3.6: Model Selection   
3.7: Summary

# 3.1: Introduction to Autoregressive Moving Average (ARMA) Processes

In this chapter autoregressive moving average processes are discussed. They play a crucial role in specifying time series models for applications. As the solutions of stochastic difference equations with constant coefficients and these processes possess a linear structure.

# Definition 3.1.1: ARMA processes

(a) A weakly stationary process $X _ { t } { : t \in \mathbb { Z } }$ is called an autoregressive moving average time series of order ${ \pmb p } , { \pmb q } .$ , abbreviated by $A R M A ( p , q )$ , if it satisfies the difference equations

$$
X _ {t} = \phi_ {1} X _ {t - 1} + \dots + \phi_ {p} X _ {t - p} + Z _ {t} + \theta_ {1} Z _ {t - 1} + \dots + \theta_ {q} Z _ {t - q}, \quad t \in \mathbb {Z}, \tag {3.1.1}
$$

where $\phi _ { 1 } , \ldots , \phi _ { p }$ and $\theta _ { 1 } , \ldots , \theta _ { q }$ are real constants, $\phi _ { p } \neq 0 \neq \theta _ { q } ,$ and $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W N } ( 0 , \sigma ^ { 2 } )$ .

(b) A weakly stationary stochastic process $\pmb { X } _ { t } ; t \in \mathbb { Z }$ is called an $A R M A ( p , q )$ time series with mean $\pmb { \mu }$ if the process $X _ { t } - \mu \colon t \in \mathbb { Z }$ satisfies the equation system.

A more concise representation of Equation can be obtained with the use of the backshift operator $\pmb { B } .$ . To this end, define the autoregressive polynomial and the moving average polynomial by

$$
\phi (z) = 1 - \phi_ {1} z - \phi_ {2} z ^ {2} - \ldots - \phi_ {p} z ^ {p}, \qquad z \in \mathbb {C},
$$

and

$$
\theta (z) = 1 + \theta_ {1} z + \theta_ {2} z ^ {2} + \ldots + \theta_ {q} z ^ {q}, \qquad z \in \mathbb {C},
$$

respectively, where denotes the set of complex numbers. Inserting the backshift operator into these polynomials, the equations in (3.1.1) become

$$
\phi (B) X _ {t} = \theta (B) Z _ {t}, \quad t \in \mathbb {Z}. \tag {3.1.2}
$$

![](images/aab041a4a3ab7ccf88d91bb64d8727ce6d145c0fb61032660891acceea4fa2a6.jpg)

![](images/1e04b4eb88522c4dfd18336dbfe1edc95ef7934ef56e4b130a9b0858ccb44fb4.jpg)

![](images/a1b6bba4ce561341ea4e20d6950a245e780e6855e32e9cd1543e8e4539fae20c.jpg)  
Figure 3.1: Realizations of three autoregressive moving average processes.

Example 3.1.1 Figure 3.1 displays realizations of three different autoregressive moving average time series based on independent, standard normally distributed $( Z _ { t } \colon t \in \mathbb { Z } )$ . The left panel is an ARMA(2,2) process with parameter specifications $\phi _ { 1 } = . 2$ , $\phi _ { 2 } = - . 3$ , $\pmb { \theta } _ { 1 } = - . 5$ and $\pmb { \theta _ { 2 } = . 3 }$ . The middle plot is obtained from an ARMA(1,4) process with parameters $\phi _ { 1 } = . 3$ , $\pmb { \theta _ { 1 } } = - . 2$ , , $\pmb \theta _ { 3 } = . 5$ , and $\theta _ { 4 } = . 2$ , while the right plot is from an ARMA(4,1) with parameters $\phi _ { 1 } = - . 2$ , $\phi _ { 2 } = - . 3 ,$ , $\phi _ { 3 } = . 5$ and $\phi _ { 4 } = . 2$ and $\pmb \theta _ { 1 } = . \pmb 6 .$ . The plots indicate that ARMA models can provide a flexible tool for modeling diverse residual sequences. It will turn out in the next section that all three realizations here come from (strictly) stationary processes. Similar time series plots can be produced in R using the commands

```txt
>arima22 =  
arima.sim(list(order=c(2,0,2), ar=c(.2,-.3), ma=c(-.5,.3)), n=100)  
>arima14 =  
arima.sim(list(order=c(1,0,4), ar=.3, ma=c(-.2,-.3,.5,.2)), n=100) 
```

>arima41 $=$ arima.sim(list(order $\tt { = } 0$ (4,0,1), ar=c(-.2,-.3,.5,.2), ma=.6), n=100)

Some special cases covered in the following two examples have particular relevance in time series analysis.

![](images/f1f4d6417a81403304506de022b5f6cf6917f1fdfeb27ce93dee3cc1fd55be0c.jpg)  
Figure 3.2: Realizations of three autoregressive processes.

Example 3.1.2 (AR Processes) If the moving average polynomial in (3.1.2) is equal to one, that is, if $\pmb \theta ( z ) \equiv \mathbf 1$ , then the resulting $( X _ { t } { : } t \in \mathbb { Z } )$ is referred to as autoregressive process of order ${ \pmb p } _ { : }$ , $A R ( { \pmb p } )$ . These time series interpret the value of the current variable $X _ { t }$ as a linear combination of $\pmb { p }$ previous variables $X _ { t - 1 } , \ldots , X _ { t - p }$ plus an additional distortion by the white noise $\scriptstyle { \pmb { Z } } _ { t }$ . Figure 3.1.2 displays two AR(1) processes with respective parameters $\phi _ { 1 } = - . 9$ (left) and $\phi _ { 1 } = . 8$ (middle) as well as an AR(2) process with parameters $\phi _ { 1 } = - . 5$ and $\phi _ { 2 } = . 3$ . The corresponding R commands are

>ar1neg $=$ arima.sim(list(order=c(1,0,0), ar=-.9), n=100) >ar1pos $=$ arima.sim(list(order=c(1,0,0), ar=.8), $\mathsf { n } { = } \mathsf { 1 } \Theta \Theta$ ) $> \mathsf { a r } 2 \ =$ arima.sim(list(order $\tt { = } 0$ (2,0,0), ar=c(-.5,.3)), n=100)

![](images/d3d589983913313eba88e441476fdbbb4ee33faf5b6533b2b7ea8efc98fbb222.jpg)  
Figure 3.3: Realizations of three moving average processes.

Example 3.1.3 (MA Processes) If the autoregressive polynomial in (3.1.2) is equal to one, that is, if $\phi ( z ) \equiv 1$ , then the resulting $( X _ { t } ; t \in \mathbb { Z } )$ is referred to as moving average process of order ${ \mathbfit { q } } , M A ( { \mathbfit { q } } ) \}$ . Here the present variable $X _ { t }$ is obtained as superposition of $\pmb q$ white noise terms $\begin{array} { r } { Z _ { t } , \ldots , Z _ { t - q } . } \end{array}$ Figure (3.1.3) shows two MA(1) processes with respective parameters $\pmb \theta _ { 1 } = . 5$ (left) and $\pmb \theta _ { 1 } = - . 8$ (middle). The right plot is observed from an MA(2) process with parameters $\pmb { \theta } _ { 1 } = - . 5$ and $\pmb { \theta _ { 2 } } = . 3$ . In R one may use

> ma1pos $=$ arima.sim(list(order=c(0,0,1), ma=.5), $\mathsf { n } { = } \mathsf { 1 } \Theta \Theta$ )   
$>$ ma1neg $=$ arima.sim(list(order=c(0,0,1), ma=-.8), $\mathsf { n } { = } \mathsf { 1 } \Theta \Theta$ )   
> ma2 = arima.sim(list(order=c(0,0,2), ma=c(-.5,.3)), n=100)

For the analysis upcoming in the next chapters, we now introduce moving average processes of infinite order $( q = \infty )$ . They are an important tool for determining stationary solutions to the difference equations (3.1.1).

# Definition 3.1.2 Linear processes

A stochastic process $( X _ { t } ; t \in \mathbb { Z } )$ is called linear process or $M A ( \infty )$ time series if there is a sequence $( \psi _ { j } ; j \in \mathbb { N } _ { 0 } )$ with $\textstyle \sum _ { j = 0 } ^ { \infty } \left| \psi _ { j } \right| < \infty$ such that

$$
X _ {t} = \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {t - j}, \quad t \in \mathbb {Z}, \tag {3.1.3}
$$

where $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \operatorname { W N } ( 0 , \sigma ^ { 2 } ) .$ .

Moving average time series of any order $\pmb q$ are special cases of linear processes. Just pick $\psi _ { j } = \pmb \theta _ { j }$ for $j = 1 , \dots , q$ and set $\psi _ { j } = 0$ if $\pmb { j }$ $> \pmb q$ . It is common to introduce the power series

$$
\psi (z) = \sum_ {j = 0} ^ {\infty} \psi_ {j} z ^ {j}, \qquad z \in \mathbb {C},
$$

to express a linear process in terms of the backshift operator. Display (3.1.3) can now be rewritten in the compact form

$$
X _ {t} = \psi (B) Z _ {t}, \qquad t \in \mathbb {Z}.
$$

With the definitions of this section at hand, properties of ARMA processes, such as stationarity and invertibility, are investigated in the next section. The current section is closed giving meaning to the notation $X _ { t } = \psi ( B ) Z _ { t }$ . Note that one is possibly dealing with an infinite sum of random variables. For completeness and later use, in the following example the mean and ACVF of a linear process are derived.

Example 3.1.4 Mean and ACVF of a linear process

Let $\left( X _ { t } ; t \in \mathbb { Z } \right)$ be a linear process according to Definition 3.1.2. Then, it holds that

$$
E [ X _ {t} ] = E \left[ \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {t - j} \right] = \sum_ {j = 0} ^ {\infty} \psi_ {j} E [ Z _ {t - j} ] = 0, \qquad t \in \mathbb {Z}.
$$

Next observe also that

$$
\begin{array}{l} \gamma (h) = \operatorname {C o v} \left(X _ {t + h}, X _ {t}\right) \\ = E \left[ \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {t + h - j} \sum_ {k = 0} ^ {\infty} \psi_ {k} Z _ {t - k} \right] \\ = \sigma^ {2} \sum_ {k = 0} ^ {\infty} \psi_ {k + h} \psi_ {k} <   \infty \\ \end{array}
$$

by assumption on the sequence $( \psi _ { j } ; j \in \mathbb { N } _ { 0 } )$ .

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)

# 3.2: Causality and Invertibility

While a moving average process of order $\pmb q$ will always be stationary without conditions on the coefficients $\theta _ { 1 } , . . . , \theta _ { q } ,$ some deeper thoughts are required in the case of $\operatorname { A R } ( { \pmb p } )$ and $\mathrm { A R M A } ( { \pmb { p } } , { \pmb q } )$ processes. For simplicity, we start by investigating the autoregressive process of order one, which is given by the equations $X _ { t } = \phi X _ { t - 1 } + Z _ { t }$ (writing $\phi = \phi _ { 1 } ^ { \phantom { } } ,$ ). Repeated iterations yield that

$$
X _ {t} = \phi X _ {t - 1} + Z _ {t} = \phi^ {2} X _ {t - 2} + Z _ {t} + \phi Z _ {t - 1} = \ldots = \phi^ {N} X _ {t - N} + \sum_ {j = 0} ^ {N - 1} \phi^ {j} Z _ {t - j}.
$$

Letting $N \to \infty$ , it could now be shown that, with probability one,

$$
X _ {t} = \sum_ {j = 0} ^ {\infty} \phi^ {j} Z _ {t - j} \tag {3.2.2}
$$

is the weakly stationary solution to the AR(1) equations, provided that $| \phi | < 1$ . These calculations would indicate moreover, that an autoregressive process of order one can be represented as linear process with coefficients $\psi _ { j } = \phi ^ { j }$ .

# Example : Mean and ACVF of an AR(1) process

Since an autoregressive process of order one has been identified as an example of a linear process, one can easily determine its expected value as

$$
E [ X _ {t} ] = \sum_ {j = 0} ^ {\infty} \phi^ {j} E [ Z _ {t - j} ] = 0, \qquad t \in \mathbb {Z}.
$$

For the ACVF, it is obtained that

$$
\begin{array}{l} \gamma (h) = \operatorname {C o v} \left(X _ {t + h}, X _ {t}\right) \\ = E \left[ \sum_ {j = 0} ^ {\infty} \phi^ {j} Z _ {t + h - j} \sum_ {k = 0} ^ {\infty} \phi^ {k} Z _ {t - k} \right] \\ = \sigma^ {2} \sum_ {k = 0} ^ {\infty} \phi^ {k + h} \phi^ {k} = \sigma^ {2} \phi^ {h} \sum_ {k = 0} ^ {\infty} \phi^ {2 k} = \frac {\sigma^ {2} \phi^ {h}}{1 - \phi^ {2}}, \\ \end{array}
$$

where $\pmb { h } \geq \mathbf { 0 }$ . This determines the ACVF for all $\pmb { h }$ using that $\gamma ( - h ) = \gamma ( h )$ . It is also immediate that the ACF satisfies $\rho ( h ) = \phi ^ { h }$ See also Example 3.1.1 for comparison.

# Example : Nonstationary AR(1) processes

In Example 1.2.3 we have introduced the random walk as a nonstationary time series. It can also be viewed as a nonstationary AR(1) process with parameter $\phi = 1$ . In general, autoregressive processes of order one with coefficients $| \phi | > 1$ are called {\it explosive}\/ for they do not admit a weakly stationary solution that could be expressed as a linear process. However, one may proceed as follows. Rewrite the defining equations of an AR(1) process as

$$
X _ {t} = - \phi^ {- 1} Z _ {t + 1} + \phi^ {- 1} X _ {t + 1}, \quad t \in \mathbb {Z}.
$$

Apply now the same iterations as before to arrive at

$$
X _ {t} = \phi^ {- N} X _ {t + N} - \sum_ {j = 1} ^ {N} \phi^ {- j} Z _ {t + j}, \qquad t \in \mathbb {Z}.
$$

Note that in the weakly stationary case, the present observation has been described in terms of past innovations. The representation in the last equation however contains only future observations with time lags larger than the present time . From a statistical point of view this does not make much sense, even though by identical arguments as above we may obtain

$$
X _ {t} = - \sum_ {j = 1} ^ {\infty} \phi^ {- j} Z _ {t + j}, \qquad t \in \mathbb {Z},
$$

as the weakly stationary solution in the explosive case.

The result of the previous example leads to the notion of causality which means that the process $( X _ { t } : t \in \mathbb { Z } )$ has a representation in terms of the white noise $( Z _ { s } : s \le t )$ and that is hence uncorrelated with the future as given by $( Z _ { s } : s > t )$ . We give the definition for the general ARMA case.

# Definition: Causality

An ARMA( ) process given by (3.1.1) is causal if there is a sequence $( \psi _ { j } : j \in \mathbb { N } _ { 0 } )$ such that $\textstyle \sum _ { j = 0 } ^ { \infty } \vert \psi _ { j } \vert < \infty$ and

$$
X _ {t} = \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {t - j}, \qquad t \in \mathbb {Z}.
$$

Causality means that an ARMA time series can be represented as a linear process. It was seen earlier in this section how an AR(1) process whose coefficient satisfies the condition $| \phi | < 1$ can be converted into a linear process. It was also shown that this is impossible if $\vert \phi \vert > 1$ . The conditions on the autoregressive parameter $\phi$ can be restated in terms of the corresponding autoregressive polynomial $\phi ( z ) = 1 - \phi z$ as follows. It holds that

$$
| \phi | <   1 \text {i f a n d o n l y i f} \phi (z) \neq 0 \text {f o r a l l} | z | \leq 1,
$$

$$
| \phi | > 1 \text {i f a n d o n l y i f} \phi (z) \neq 0 \text {f o r a l l} | z | \geq 1.
$$

It turns out that the characterization in terms of the zeroes of the autoregressive polynomials carries over from the AR(1) case to the general $\mathbf { A R M A } ( \pmb { p } , \pmb { q } )$ case. Moreover, the $\psi$ -weights of the resulting linear process have an easy representation in terms of the polynomials $\phi ( z )$ and $\pmb \theta ( z )$ . The result is summarized in the next theorem.

# Theorem 3.2.1

Let $( X _ { t } : t \in \mathbb { Z } )$ be an $A R M A ( \pmb { p } , \pmb { q } )$ process such that the polynomials $\phi ( z )$ and $\pmb \theta ( z )$ have no common zeroes. Then $( X _ { t } ; t \in \mathbb { Z } )$ is causal $i f$ and only if $\phi ( z ) \neq 0$ for all $z \in \mathbb { C }$ with $| z | \leq 1$ . The coefficients $( \psi _ { j } : j \in \mathbb { N } _ { 0 } )$ are determined by the power series expansion

$$
\psi (z) = \sum_ {j = 0} ^ {\infty} \psi_ {j} z ^ {j} = \frac {\theta (z)}{\phi (z)}, \quad | z | \leq 1.
$$

A concept closely related to causality is invertibility. This notion is motivated with the following example that studies properties of a moving average time series of order 1.

# Example

Let $( X _ { t } ; t \in \mathbb { N } )$ be an MA(1) process with parameter $\pmb { \theta } = \pmb { \theta } _ { 1 }$ . It is an easy exercise to compute the ACVF and the ACF as

$$
\gamma (h) = \left\{ \begin{array}{l l} (1 + \theta^ {2}) \sigma^ {2}, & h = 0, \\ \theta \sigma^ {2}, & h = 1 \\ 0 & h > 1, \end{array} \right. \qquad \rho (h) = \left\{ \begin{array}{l l} 1 & h = 0. \\ \theta (1 + \theta^ {2}) ^ {- 1}, & h = 1. \\ 0 & h > 1. \end{array} \right.
$$

These results lead to the conclusion that $\pmb { \rho } ( h )$ does not change if the parameter $\pmb \theta$ is replaced with $\pmb { \theta } ^ { - 1 }$ . Moreover, there exist pairs $( \theta , \sigma ^ { 2 } )$ that lead to the same ACVF, for example and $( \mathbf { 1 } / \mathbf { 5 } , \mathbf { 2 5 } )$ . Consequently, we arrive at the fact that the two MA(1) models

$$
X _ {t} = Z _ {t} + \frac {1}{5} Z _ {t - 1}, \quad t \in \mathbb {Z}, \quad (Z _ {t}; t \in \mathbb {Z}) \sim \text {i i d} \mathcal {N} (0, 2 5),
$$

and

$$
X _ {t} = \tilde {Z} _ {t} + 5 \tilde {Z} _ {t - 1}, \qquad t \in \mathbb {Z}, \qquad (\tilde {Z}: t \in \mathbb {Z}) \sim \mathrm {i i d} \mathcal {N} (0, 1),
$$

are indistinguishable because we only observe $X _ { t }$ but not the noise variables $\scriptstyle \mathbf { Z } _ { t }$ and $\tilde { z } _ { t }$ .

For convenience, the statistician will pick the model which satisfies the invertibility criterion which is to be defined next. It specifies that the noise sequence can be represented as a linear process in the observations.

# Definition: Invertibility

An ARMA( ) process given by (3.1.1) is invertible if there is a sequence $( \pi _ { j } { : } j \in \mathbb { N } _ { 0 } )$ such that $\textstyle \sum _ { j = 0 } ^ { \infty } \left| \pi _ { j } \right| < \infty$ and

$$
Z _ {t} = \sum_ {j = 0} ^ {\infty} \pi_ {j} X _ {t - j}, \qquad t \in \mathbb {Z}.
$$

# Theorem 3.2.2

Let $( X _ { t } : t \in \mathbb { Z } )$ be an $A R M A ( \pmb { p } , \pmb { q } )$ process such that the polynomials $\phi ( z )$ and $\pmb \theta ( z )$ have no common zeroes. Then $( X _ { t } ; t \in \mathbb { Z } )$ is invertible if and only if ${ \pmb \theta } ( { \pmb z } ) \neq { \bf 0 }$ for all $z \in \mathbb { C }$ with $| z | \leq 1$ . The coefficients $( \pi _ { j } ) _ { j \in \mathbb { N } _ { 0 } }$ are determined by the power series expansion

$$
\pi (z) = \sum_ {j = 0} ^ {\infty} \pi_ {j} z ^ {j} = \frac {\phi (z)}{\theta (z)}, \quad | z | \leq 1.
$$

From now on it is assumed that all ARMA sequences specified in the sequel are causal and invertible unless explicitly stated otherwise. The final example of this section highlights the usefulness of the established theory. It deals with parameter redundancy and the calculation of the causality and invertibility sequences $( \psi _ { j } { : } j \in \mathbb { N } _ { 0 } )$ and $( \pi _ { j } { : } j \in \mathbb { N } _ { 0 } )$ .

# Example : Parameter redundancy

Consider the ARMA equations

$$
X _ {t} = . 4 X _ {t - 1} +. 2 1 X _ {t - 2} + Z _ {t} +. 6 Z _ {t - 1} +. 0 9 Z _ {t - 2},
$$

which seem to generate an ARMA(2,2) sequence. However, the autoregressive and moving average polynomials have a common zero:

$$
\tilde {\phi} (z) = 1 - . 4 z - . 2 1 z ^ {2} = (1 -. 7 z) (1 +. 3 z),
$$

$$
\tilde {\theta} (z) = 1 +. 6 z +. 0 9 z ^ {2} = (1 +. 3 z) ^ {2}.
$$

Therefore, one can reset the ARMA equations to a sequence of order (1,1) and obtain

$$
X _ {t} = . 7 X _ {t - 1} + Z _ {t} +. 3 Z _ {t - 1}.
$$

Now, the corresponding polynomials have no common roots. Note that the roots of $\phi ( z ) = 1 - . 7 z$ and $\pmb \theta ( z ) = \mathbf 1 + . \mathbf 3 z$ are $\mathbf { 1 0 } / 7$ $> 1$ and $- 1 0 / 3 < - 1$ , respectively. Thus Theorems 3.2.1 and 3.2.2 imply that causal and invertible solutions exist. In the following, the corresponding coefficients in the expansions

$$
X _ {t} = \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {t - j} \qquad a n d \qquad Z _ {t} = \sum_ {j = 0} ^ {\infty} \pi_ {j} X _ {t - j}, \qquad t \in \mathbb {Z},
$$

are calculated. Starting with the causality sequence $( \psi _ { j } : j \in \mathbb { N } _ { 0 } )$ . Writing, for $| z | \leq 1$ ,

$$
\sum_ {j = 0} ^ {\infty} \psi_ {j} z ^ {j} = \psi (z) = \frac {\theta (z)}{\phi (z)} = \frac {1 + . 3 z}{1 - . 7 z} = (1 +. 3 z) \sum_ {j = 0} ^ {\infty} (. 7 z) ^ {j},
$$

it can be obtained from a comparison of coefficients that

$$
\psi_ {0} = 1 \qquad a n d \qquad \psi_ {j} = (. 7 + . 3) (. 7) ^ {j - 1} = (. 7) ^ {j - 1}, \qquad j \in \mathbb {N}.
$$

Similarly one computes the invertibility coefficients $( \pi _ { j } : j \in \mathbb { N } _ { 0 } )$ from the equation

$$
\sum_ {j = 0} ^ {\infty} \pi_ {j} z ^ {j} = \pi (z) = \frac {\phi (z)}{\theta (z)} = \frac {1 - . 7 z}{1 + . 3 z} = (1 - . 7 z) \sum_ {j = 0} ^ {\infty} (-. 3 z) ^ {j}
$$

$( | z | \leq 1 )$ as

$$
\pi_ {0} = 1 \quad a n d \quad \pi_ {j} = (- 1) ^ {j} (3 +. 7) (3) ^ {j - 1} = (- 1) ^ {j} (3) ^ {j - 1}.
$$

Together, the previous calculations yield to the explicit representations

$$
X _ {t} = Z _ {t} + \sum_ {j = 1} ^ {\infty} (. 7) ^ {j - 1} Z _ {t - j} \quad a n d \quad Z _ {t} = X _ {t} + \sum_ {j = 1} ^ {\infty} (- 1) ^ {j}. (3) ^ {j - 1} X _ {t - j}.
$$

In the remainder of this section, a general way is provided to determine the weights $( \psi _ { j } ; j \ge 1 )$ for a causal $\mathrm { A R M A } ( \pmb { p } , \pmb { q } )$ process given by $\phi ( B ) X _ { t } = \theta ( B ) Z _ { t }$ , where $\phi ( z ) \neq 0$ for all $z \in \mathbb { C }$ such that $| z | \leq 1$ . Since $\psi ( z ) = \theta ( z ) / \phi ( z )$ for these $\pmb { z } ,$ , the weight $\psi _ { j }$ can be computed by matching the corresponding coefficients in the equation $\psi ( z ) \phi ( z ) = \theta ( z )$ , that is,

$$
(\psi_ {0} + \psi_ {1} z + \psi_ {2} z ^ {2} + \dots) (1 - \phi_ {1} z - \dots - \phi_ {p} z ^ {p}) = 1 + \theta_ {1} z + \dots + \theta_ {q} z ^ {q}.
$$

Recursively solving for $\psi _ { 0 } , \psi _ { 1 } , \psi _ { 2 } , . . .$ gives

$$
\psi_ {0} = 1,
$$

$$
\psi_ {1} - \phi_ {1} \psi_ {0} = \theta_ {1},
$$

$$
\psi_ {2} - \phi_ {1} \psi_ {1} - \phi_ {2} \psi_ {0} = \theta_ {2},
$$

and so on as long as $j < \operatorname* { m a x } \{ p , q + 1 \}$ . The general solution can be stated as

$$
\psi_ {j} - \sum_ {k = 1} ^ {j} \phi_ {k} \psi_ {j - k} = \theta_ {j}, \quad 0 \leq j <   \max  \{p, q + 1 \}, \tag {3.2.1}
$$

$$
\psi_ {j} - \sum_ {k = 1} ^ {p} \phi_ {k} \psi_ {j - k} = 0, \quad j \geq \max  \{p, q + 1 \}, \tag {3.2.2}
$$

if we define $\phi _ { j } = 0$ if $j > p$ and $\pmb \theta _ { j } = \mathbf 0$ if $j > q$ . To obtain the coefficients $\psi _ { j }$ one therefore has to solve the homogeneous linear difference equation (3.2.2) subject to the initial conditions specified by (3.2.1). For more on this subject, see Section 3.6 of Brockwell and Davis (1991) and Section 3.3 of Shumway and Stoffer (2006).

# R calculations

In R, these computations can be performed using the command ARMAtoMA. For example, one can use the commands

$$
\begin{array}{l} > \text {A R M A t o M A} (\text {a r = . 7 , m a = . 3 , 2 5}) \\ > p l o t (A R M A t o M A (a r = . 7, m a = . 3, 2 5)) \\ \end{array}
$$

which will produce the output displayed in Figure 3.4. The plot shows nicely the exponential decay of the $\psi$ -weights which is typical for ARMA processes. The table shows row-wise the weights $\psi _ { 0 } , \ldots , \psi _ { 2 4 } .$ . This is enabled by the choice of 25 in the argument of the function ARMAtoMA.

<table><tr><td>1.0000000000</td><td>0.7000000000</td><td>0.4900000000</td><td>0.3430000000</td><td>0.2401000000</td></tr><tr><td>0.1680700000</td><td>0.1176490000</td><td>0.0823543000</td><td>0.0576480100</td><td>0.0403536070</td></tr><tr><td>0.0282475249</td><td>0.0197732674</td><td>0.0138412872</td><td>0.0096889010</td><td>0.0067822307</td></tr><tr><td>0.0047475615</td><td>0.0033232931</td><td>0.0023263051</td><td>0.0016284136</td><td>0.0011398895</td></tr><tr><td>0.0007979227</td><td>0.0005585459</td><td>0.0003909821</td><td>0.0002736875</td><td>0.0001915812</td></tr></table>

![](images/3f978959202d73376c6c06e7eefda180b0f77c04ea7406056384bb97ce9c7bee.jpg)  
Figure 3.4: The R output for the ARMA(1,1) process of Example 3.2.4

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)

This page titled 3.2: Causality and Invertibility is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 3.3: The PACF of a Causal ARMA Process

In this section, the partial autocorrelation function (PACF) is introduced to further assess the dependence structure of stationary processes in general and causal ARMA processes in particular. To start with, let us compute the ACVF of a moving average process of order

# Example : The ACVF of an MA( ) process

Let $( X _ { t } ; t \in \mathbb { Z } )$ be an $\mathrm { M A } ( { \pmb q } )$ process specified by the polynomial $\theta ( z ) = 1 + \theta _ { 1 } z + . . . + \theta _ { q } z ^ { q } ,$ . Then, letting $\pmb { \theta _ { 0 } = 1 }$ , it holds that

$$
E [ X _ {t} ] = \sum_ {j = 0} ^ {q} \theta_ {j} E [ Z _ {t - j} ] = 0.
$$

# Solution

To compute the ACVF, suppose that $h \geq 0$ and write

$$
\begin{array}{l} \gamma (h) = \operatorname {C o v} \left(X _ {t + h}, X _ {t}\right) = E \left[ X _ {t + h} X _ {t} \right] \\ = E \left[ \left(\sum_ {j = 0} ^ {q} \theta_ {j} Z _ {t + h - j}\right) \left(\sum_ {k = 0} ^ {q} \theta_ {k} Z _ {t - k}\right) \right] \\ = \sum_ {j = 0} ^ {q} \sum_ {k = 0} ^ {q} \theta_ {j} \theta_ {k} E [ Z _ {t + h - j} Z _ {t - k} ] \\ = \left\{ \begin{array}{l l} \sigma^ {2} \sum_ {k = 0} ^ {q - h} \theta_ {k + h} \theta_ {k}, & 0 \leq h \leq q. \\ 0, & h > q. \end{array} \right. \\ \end{array}
$$

The result here is a generalization of the MA(1) case, which was treated in Example 3.2.3. It is also a special case of the linear process in Example 3.1.4. The structure of the ACVF for MA processes indicates a possible strategy to determine in practice the unknown order $\pmb q$ : plot the the sample ACF and select as order $\pmb q$ the largest lag such that $\pmb { \rho } ( h )$ is significantly different from zero.

While the sample ACF can potentially reveal the true order of an MA process, the same is not true anymore in the case of AR processes. Even for the AR(1) time series it has been shown in Example 3.2.1 that its ACF $\rho ( h ) = \phi ^ { | h | }$ is nonzero for all lags. As further motivation, however, we discuss the following example.

# Example 3.3.2

Let $( X _ { t } ; t \in \mathbb { Z } )$ be a causal AR(1) process with parameter $| \phi | < 1$ . It holds that

$$
\gamma (2) = C o v \left(X _ {2}, X _ {0}\right) = C o v \left(\phi^ {2} X _ {0} + \phi Z _ {1} + Z _ {2}, X _ {0}\right) = \phi^ {2} \gamma (0) \neq 0.
$$

To break the linear dependence between $X _ { 0 }$ and $X _ { 2 }$ , subtract $\phi X _ { 1 }$ from both variables. Calculating the resulting covariance yields

$$
C o v \left(X _ {2} - \phi X _ {1}, X _ {0} - \phi X _ {1}\right) = C o v \left(Z _ {2}, X _ {0} - \phi X _ {1}\right) = 0,
$$

since, due to the causality of this AR(1) process, $X _ { 0 } - \phi X _ { 1 }$ is a function of ${ \cal Z } _ { 1 } , { \cal Z } _ { 0 } , { \cal Z } _ { - 1 } , \ldots$ and therefore uncorrelated with $X _ { 2 } - \phi X _ { 1 }$ $\mathbf { \mu } = \mathbf { Z _ { 2 } }$ .

The previous example motivates the following general definition.

# Definition 3.3.1 Partial autocorrelation function

Let $( X _ { t } ; t \in \mathbb { Z } )$ be a weakly stationary stochastic process with zero mean. Then, the sequence $( \phi _ { h h } : h \in \mathbb { N } )$ given by

$$
\phi_ {1 1} = \rho (1) = C o r r \left(X _ {1}, X _ {0}\right),
$$

$$
\phi_ {h h} = \operatorname {C o r r} \left(X _ {h} - X _ {h} ^ {h - 1}, X _ {0} - X _ {0} ^ {h - 1}\right), \quad h \geq 2,
$$

is called the partial autocorrelation function (PACF) of $( X _ { t } { : } t \in \mathbb { Z } )$

Therein,

$$
\begin{array}{l} X _ {h} ^ {h - 1} = \text {r e g r e s s i o n o f} X _ {h} \text {o n} \left(X _ {h - 1}, \dots , X _ {1}\right) \\ = \beta_ {1} X _ {h - 1} + \beta_ {2} X _ {h - 2} + \dots + \beta_ {h - 1} X _ {1} \\ \end{array}
$$

$$
\begin{array}{l} X _ {0} ^ {h - 1} = \text {r e g r e s s i o n} X _ {0} \text {o n} \left(X _ {1}, \dots , X _ {h - 1}\right) \\ = \beta_ {1} X _ {1} + \beta_ {2} X _ {2} + \dots + \beta_ {h - 1} X _ {h - 1}. \\ \end{array}
$$

Notice that there is no intercept coefficient $\beta _ { 0 }$ in the regression parameters, since it is assumed that $E [ X _ { t } ] = 0$ . The following example demonstrates how to calculate the regression parameters in the case of an AR(1) process.

![](images/dee2396416f6b8bacf54231a09a28b797ca82d58c70dc4bdb9d152cddd9166e1.jpg)

![](images/21c85b16c78ab02d28df19f7999901a5b202d2a52c02360bac32b4786b384609.jpg)

![](images/9142667a7c10a246770851143fa41c01825b7c88c97524986623b4a0f005c152.jpg)

![](images/b58e9d84b3c5e895cc977cd3b26f4251a6e1be8ad45b775ddede1466653d6702.jpg)

![](images/a5f98da577f89245e283877fadffc85c92344bf6ab3c769fdaf1a085fc6e2b9c.jpg)

![](images/b56aa7fb17e31c78924d63aff52ab493dee4ccef693e1a6d225677e15aafa2a4.jpg)  
Figure 3.5 The ACFs and PACFs of an AR(2) process (upper panel), and MA(3) process (middle panel) and and ARMA(1,1) process (lower panel).

# Example 3.3.3 PACF of an AR(1) process]

If $( X _ { t } { : } t \in \mathbb { Z } )$ is a causal AR(1) process, then $\phi _ { 1 1 } = \rho ( 1 ) = \phi$ . To calculate $\phi _ { 2 2 }$ , calculate first $X _ { 2 } ^ { 1 } = \beta X _ { 1 }$ , that is $\beta$ . This coefficient is determined by minimizing the mean-squared error between $X _ { 2 }$ and $\beta X _ { 1 }$ :

$$
E \left[ X _ {2} - \beta X _ {1} \right] ^ {2} = \gamma (0) - 2 \beta \gamma (1) + \beta^ {2} \gamma (0)
$$

which is minimized by $\beta = \rho ( 1 ) = \phi$ . (This follows easily by taking the derivative and setting it to zero.) Therefore $X _ { 2 } ^ { 1 } = \phi X _ { 1 }$ . Similarly, one computes $X _ { 0 } ^ { 1 } = \phi X _ { 1 }$ and it follows from Example 3.3.2 that $\phi _ { 2 2 } = 0$ . Indeed all lags $\pmb { h } \geq \pmb { 2 }$ of the PACF are zero.

More generally, consider briefly a causal $\operatorname { A R } ( { \pmb { p } } )$ process given by $\phi ( B ) X _ { t } = Z _ { t }$ with $\phi ( z ) = 1 - \phi _ { 1 } z - . . . - \phi _ { p } z ^ { p } .$

Then, for $\pmb { h } > \pmb { p }$ ,

$$
X _ {h} ^ {h - 1} = \sum_ {j = 1} ^ {p} \phi_ {j} X _ {h - j}
$$

and consequently

$$
\phi_ {h h} = \operatorname {C o r r} \left(X _ {h} - X _ {h} ^ {h - 1}, X _ {0} - X _ {0} ^ {h - 1}\right) = \operatorname {C o r r} \left(Z _ {h}, X _ {0} - X _ {0} ^ {h - 1}\right) = 0
$$

if $\hbar > p$ by causality (the same argument used in Example 3.3.2 applies here as well). Observe, however, that $\phi _ { h h }$ is not necessarily zero if $h \leq p .$ . The forgoing suggests that the sample version of the PACF can be utilized to identify the order of an autoregressive process from data: use as $\pmb { p }$ the largest lag $\pmb { h }$ such that $\phi _ { h h }$ is significantly different from zero.

On the other hand, for an invertible $\mathrm { M A } ( { \pmb q } )$ process, one can write $Z _ { t } = \pi ( B ) X _ { t }$ or, equivalently,

$$
X _ {t} = - \sum_ {j = 1} ^ {\infty} \pi_ {j} X _ {t - j} + Z _ {t}
$$

which shows that the PACF of an $\mathrm { M A } ( q )$ process will be nonzero for all lags, since for a ``perfect'' regression one would have to use all past variables $( X _ { s } ; s < t )$ instead of only the quantity $X _ { t } ^ { t - 1 }$ given in Definition 3.3.1.

In summary, the PACF reverses the behavior of the ACVF for autoregressive and moving average processes. While the latter have an ACVF that vanishes after lag $\pmb q$ and a PACF that is nonzero (though decaying) for all lags, AR processes have an ACVF that is nonzero (though decaying) for all lags but a PACF that vanishes after lag .

ACVF (ACF) and PACF hence provide useful tools in assessing the dependence of given ARMA processes. If the estimated ACVF (the estimated PACF) is essentially zero after some time lag, then the underlying time series can be conveniently modeled with an MA (AR) process---and no general ARMA sequence has to be fitted. These conclusions are summarized in Table 3.3.1

Table 3.1: The behavior of ACF and PACF for AR, MA, and ARMA processes.   

<table><tr><td></td><td>AR(p)</td><td>MA(q)</td><td>ARMA(p,q)</td></tr><tr><td>ACF</td><td>tails OFF</td><td>CUTS OFF after lag q</td><td>TAILS OFF</td></tr><tr><td>PACF</td><td>CUTS OFF after lag p</td><td>TAILS OFF</td><td>TAILS OFF</td></tr></table>

# Example 3.3.4

Figure 3.5 collects the ACFs and PACFs of three ARMA processes. The upper panel is taken from the AR(2) process with parameters $\phi _ { 1 } = 1 . 5$ and $\phi _ { 2 } = - . 7 5$ . It can be seen that the ACF tails off and displays cyclical behavior (note that the corresponding autoregressive polynomial has complex roots). The PACF, however, cuts off after lag 2. Thus, inspecting ACF and PACF, we would correctly specify the order of the AR process.

The middle panel shows the ACF and PACF of the MA(3) process given by the parameters $\pmb { \theta _ { 1 } = 1 . 5 }$ , $\theta _ { 2 } = - . 7 5$ and $\pmb { \theta _ { 3 } } = \pmb { 3 }$ . The plots confirm that $\pmb q = 3$ because the ACF cuts off after lag 3 and the PACF tails off.

Finally, the lower panel displays the ACF and PACF of the ARMA(1,1) process of Example 3.2.4. Here, the assessment is much harder. While the ACF tails off as predicted (see Table 3.1), the PACF basically cuts off after lag 4 or 5. This could lead to the wrong conclusion that the underlying process is actually an AR process of order 4 or 5. (The reason for this behavior lies in the fact that the dependence in this particular ARMA(1,1) process can be well approximated by that of an AR(4) or AR(5) time series.)

To reproduce the graphs in R, you can use the commands

$$
\begin{array}{l} > \operatorname {a r 2 . a c f} = \operatorname {A R M A a c f} (\operatorname {a r} = \operatorname {c} (1. 5, -. 7 5), \quad \operatorname {m a} = 0, 2 5) \\ > \operatorname {a r 2 . p a c f} = \operatorname {A R M A a c f} (\operatorname {a r} = \operatorname {c} (1. 5, -. 7 5), \operatorname {m a} = 0, 2 5, \operatorname {p a c f} = T) \\ \end{array}
$$

for the AR(2) process. The other two cases follow from straightforward adaptations of this code.

![](images/43ed394ec94d15c08614ede0b5fee2a659604b1e7cc97f5ad1ab88cf254b0c2c.jpg)

![](images/25de231c95ff9fbaf8ea6051a8f7a5ff6c84c8cbd0b93f87d2fb7c804073f1a0.jpg)

![](images/ba1ff1190dc95044f75f9b7afca7eb8861cc3a33f166878b476cf4935ae45b8e.jpg)  
Figure 3.6: The recruitment series of Example 3.3.5 (left), its sample ACF (middle) and sample PACF (right).

![](images/12218000b91121fbdbfacabe12d6a44d9c174b4576fd082d1e7298451ce5a021.jpg)  
Figure 3.7: Scatterplot matrix relating current recruitment to past recruitment for the lags $h = 1 , \ldots , 1 2$

# Example 3.3.5 Recruitment Series

The data considered in this example consists of 453 months of observed recruitment (number of new fish) in a certain part of the Pacific Ocean collected over the years 1950--1987. The corresponding time series plot is given in the left panel of Figure 3.6. The corresponding ACF and PACF displayed in the middle and right panel of the same figure recommend fitting an AR process of order $\pmb { p } = \pmb { 2 }$ to the recruitment data. Assuming that the data is in rec, the R code to reproduce Figure 3.6 is

```python
> rec = ts(rec, start=1950, frequency=12)  
> plot(rec, xlab="", ylab="")  
> acf(rec, lag=48)  
> pacf(rec, lag=48) 
```

This assertion is also consistent with the scatterplots that relate current recruitment to past recruitment at several time lags, namely $\pmb { h } = 1 , \dots , \pmb { 1 2 }$ . For lag 1 and 2, there seems to be a strong linear relationship, while this is not the case anymore for $h \geq 3$ . The corresponding R commands are

> lag.plot(rec, lags=12, layout $\tt { = } 0$ (3,4), diag=F)

Denote by $\pmb { X } _ { t }$ the recruitment at time . To estimate the AR(2) parameters, run a regression on the observed data triplets included in the set $( x _ { t } , x _ { t } - 1 , x _ { t } - 2 ) \colon j = 3 , \ldots , 4 5 3$ to fit a model of the form

$$
X _ {t} = \phi_ {0} + \phi_ {1} X _ {t} - 1 + \phi_ {2} X _ {t} - 2 + Z _ {t}, \quad t = 3, \dots , 4 5 3,
$$

where $( Z _ { t } ) \sim \mathbf { W } N ( 0 , \sigma ^ { 2 } )$ . This task can be performed in R as follows.

$>$ fit.rec $=$ ar.ols(rec, aic=F, order.max $^ { = 2 }$ , demean=F, intercept=T)

These estimates can be assessed with the command {\tt fit.rec} and the corresponding standard errors with . Here the parameter estimates $\pmb { \hat { \phi } _ { 0 } = 6 . 7 3 7 ( 1 . 1 1 1 ) }$ , $\hat { \phi } _ { 1 } = 1 . 3 5 4 1 ( . 0 4 2 )$ , $\hat { \phi } _ { 2 } = - . 4 6 3 2 ( . 0 4 1 2 )$ and $\hat { \pmb { \sigma } } ^ { 2 } = 8 9 . 7 2$ are obtained. The standard errors are given in parentheses.

# 3.4: Forecasting

Suppose that the variables $X _ { 1 } , \ldots , X _ { n }$ of a weakly stationary time series $( X _ { t } { : } t \in \mathbb { Z } )$ have been observed with the goal to predict or forecast the future values of $X _ { n + 1 } , X _ { n + 2 } , \dots$ The focus is here on so-called one-step best linear predictors (BLP). These are, by definition, linear combinations

$$
\hat {X} _ {n + 1} = \phi_ {n 0} + \phi_ {n 1} X _ {n} + \dots + \phi_ {n n} X _ {1} \tag {3.4.1}
$$

of the observed variables $X _ { 1 } , \ldots , X _ { n }$ that minimize the mean-squared error

$$
E \left[ \left\{X _ {n + 1} - g \left(X _ {1}, \dots , X _ {n}\right) \right\} ^ {2} \right]
$$

for functions $g$ of $X _ { 1 } , \ldots , X _ { n }$ . Straightforward generalizations yield definitions for the m-step best linear predictors $\hat { X } _ { n + m }$ of $X _ { n + m }$ for arbitrary $\pmb { m } \in \mathbb { N }$ in the same fashion. Using Hilbert space theory, one can prove the following theorem which will be the starting point for our considerations.

# Theorem : Best linear prediction (BLP)

Let $( X _ { t } ; t \in \mathbb { Z } )$ be a weakly stationary stochastic process of which $X _ { 1 } , \ldots , X _ { n }$ are observed. Then, the one-step BLP $\hat { X } _ { n + 1 }$ of $X _ { n + 1 }$ is determined by the equations

$$
E \left[ \left(X _ {n + 1} - \hat {X} _ {n + 1}\right) X _ {n + 1 - j} \right] = 0
$$

for all $j = 1 , \ldots , n + 1$ , where $X _ { 0 } = 1$ .

The equations specified in Theorem can be used to calculate the coefficients $\phi _ { n 0 } , \ldots , \phi _ { n n }$ in Equation . It suffices to focus on mean zero processes $( X _ { t } ; t \in \mathbb { Z } )$ and thus to set $\phi _ { n 0 } = 0$ as the following calculations show. Assume that $E [ X _ { t } ] = \mu$ for all $\pmb { t } \in \mathbb { Z }$ . Then, Theorem gives that $E [ \hat { X } _ { n + 1 } ] = E [ X _ { n + 1 } ] = \mu$ (using the equation with $j = n + 1$ . Consequently, it holds that

$$
\mu = E [ \hat {X} _ {n + 1} ] = E \left[ \phi_ {n 0} + \sum_ {\ell = 1} ^ {n} \phi_ {n \ell} X _ {n + 1 - \ell} \right] = \phi_ {n 0} + \sum_ {\ell = 1} ^ {n} \phi_ {n \ell} \mu .
$$

Using now that $\phi _ { n 0 } = \mu ( 1 - \phi _ { n 1 } - . . . - \phi _ { n n } )$ , Equation can be rewritten as

$$
\hat {Y} _ {n + 1} = \phi_ {n 1} Y _ {n} + \dots + \phi_ {n n} Y _ {1},
$$

where $\hat { Y } _ { n + 1 } = \hat { X } _ { n + 1 } - \mu$ has mean zero.

With the ACVF $\gamma$ of $( X _ { t } ; t \in \mathbb { Z } )$ , the equations in Theorem can be expressed as

$$
\sum_ {\ell = 1} ^ {n} \phi_ {n \ell} \gamma (j - \ell) = \gamma (j), \quad j = 1, \dots , n. \tag {3.4.2}
$$

Note that due to the convention $\phi _ { n 0 } = 0 ;$ , the last equation in Theorem (for which ${ j = n + 1 }$ is omitted. More conveniently, this is restated in matrix notation. To this end, let $\Gamma _ { n } = ( \gamma ( j - \ell ) ) _ { j , \ell = 1 , \dots , n }$ , $\phi _ { n } = ( \phi _ { n 1 } , \ldots , \phi _ { n n } ) ^ { T }$ and $\gamma _ { n } = ( \gamma ( 1 ) , \ldots , \gamma ( n ) ) ^ { T }$ , where denotes the transpose. With these notations, (3.4.2.) becomes

$$
\Gamma_ {n} \phi_ {n} = \gamma_ {n} \quad \Longleftrightarrow \quad \phi_ {n} = \Gamma_ {n} ^ {- 1} \gamma_ {n}, \tag {3.4.3}
$$

provided that $\Gamma _ { n }$ is nonsingular.

The determination of the coefficients $\phi _ { n \ell }$ has thus been reduced to solving a linear equation system and depends only on secondorder properties of $( X _ { t } ; t \in \mathbb { Z } )$ which are given by the ACVF $\gamma .$

Let $X _ { n } = ( X _ { n } , X _ { n - 1 } , \ldots , X _ { 1 } ) ^ { T }$ . Then, ${ \hat { X } } _ { n + 1 } = \phi _ { n } ^ { T } X _ { n }$ . To assess the quality of the prediction, one computes the mean-squared error with the help of Equation as follows:

$$
\begin{array}{l} P _ {n + 1} = E \left[ \left(X _ {n + 1} - \hat {X} _ {n + 1}\right) ^ {2} \right] \\ = E \left[ \left(X _ {n + 1} - \phi_ {n} ^ {T} X _ {n}\right) ^ {2} \right] \\ = E \left[ \left(X _ {n + 1} - \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} X _ {n}\right) ^ {2} \right] \\ = E \left[ X _ {n + 1} ^ {2} - 2 \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} X _ {n} X _ {n + 1} + \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} X _ {n} X _ {n} ^ {T} \Gamma_ {n} ^ {- 1} \gamma_ {n} \right] \\ = \gamma (0) - 2 \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} \gamma_ {n} + \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} \Gamma_ {n} \Gamma_ {n} ^ {- 1} \gamma_ {n} \\ = \gamma (0) - \gamma_ {n} ^ {T} \Gamma_ {n} ^ {- 1} \gamma_ {n}. \tag {3.4.4} \\ \end{array}
$$

As an initial example, we explain the prediction procedure for an autoregressive process of order 2.

# Example : Prediction of an AR(2) Process

Let $( X _ { t } ; t \in \mathbb { Z } )$ be the causal AR(2) process $X _ { t } = \phi _ { 1 } X _ { t - 1 } + \phi _ { 2 } X _ { t - 2 } + Z _ { t }$ . Suppose that only an observation of $\pmb { X _ { 1 } }$ is available to forecast the value of $X _ { 2 }$ . In this simplified case, the single prediction Equation is

$$
\phi_ {1 1} \gamma (0) = \gamma (1),
$$

so that $\phi _ { 1 1 } = \rho ( 1 )$ and $\hat { X } _ { 1 + 1 } = \rho ( 1 ) X _ { 1 }$ .

In the next step, assume that observed values of $\pmb { X _ { 1 } }$ and $X _ { 2 }$ are at hand to forecast the value of $X _ { 3 }$ . Then, one similarly obtains from (3.4.2.) that the predictor can be computed from

$$
\begin{array}{l} \hat {X} _ {2 + 1} = \phi_ {2 1} X _ {2} + \phi_ {2 2} X _ {1} = \phi_ {2} ^ {T} X _ {2} = (\Gamma_ {2} ^ {- 1} \gamma_ {2}) ^ {T} X _ {2} \\ = (\gamma (1), \gamma (2)) \left( \begin{array}{l l} \gamma (0) & \gamma (1) \\ \gamma (1) & \gamma (0) \end{array} \right) ^ {- 1} \left( \begin{array}{l} X _ {2} \\ X _ {1} \end{array} \right). \\ \end{array}
$$

However, applying the arguments leading to the definition of the PAC in Section 3.3.3., one finds that

$$
\begin{array}{l} E \left[ \left\{X _ {3} - \left(\phi_ {1} X _ {2} + \phi_ {2} X _ {1}\right) \right\} X _ {1} \right] = E \left[ Z _ {3} X _ {1} \right] = 0, \\ E \left[ \left\{X _ {3} - \left(\phi_ {1} X _ {2} + \phi_ {2} X _ {1}\right) \right\} X _ {2} \right] = E \left[ Z _ {3} X _ {2} \right] = 0. \\ \end{array}
$$

Hence, $\hat { X } _ { 2 + 1 } = \phi _ { 1 } X _ { 2 } + \phi _ { 2 } X _ { 1 }$ and even $\hat { X } _ { n + 1 } = \phi _ { 1 } X _ { n } + \phi _ { 2 } X _ { n - 1 }$ for all $\pmb { n } \geq \pmb { 2 } ,$ , exploiting the particular autoregressive structure. Since similar results can be proved for general causal $\operatorname { A R } ( p )$ processes, the one-step predictors have the form

$$
\hat {X} _ {n + 1} = \phi_ {1} X _ {n} + \dots + \phi_ {p} X _ {n - p + 1}
$$

whenever the number of observed variables $n$ is at least $p$ .

The major drawback of this approach is immediately apparent from the previous example: For larger sample sizes n, the prediction procedure requires the calculation of the inverse matrix $\boldsymbol { \Gamma } _ { n } ^ { - 1 }$ which is computationally expensive. In the remainder of this section, two recursive prediction methods are introduced that bypass the inversion altogether. They are known as Durbin-Levinson algorithm and innovations algorithm. Finally, predictors based on the infinite past are introduced which are often easily applicable for the class of causal and invertible ARMA processes.

# Method 1: The Durbin-Levinson algorithm

If $( X _ { t } ; t \in \mathbb { Z } )$ is a zero mean weakly stationary process with ACVF $\gamma$ such that $\gamma ( 0 ) > 0$ and $\gamma ( h )  0$ as $h  \infty$ , then the coefficients $\phi _ { n \ell }$ in (3.4.2.) and the mean squared errors $\scriptstyle { P _ { n } }$ in (3.4.4.) satisfy the recursions

$$
\phi_ {1 1} = \frac {\gamma (1)}{\gamma (0)}, \quad P _ {0} = \gamma (0),
$$

and, for $\pmb { n } \geq \pmb { 1 }$

$$
\phi_ {n n} = \frac {1}{P _ {n - 1}} \left(\gamma (n) - \sum_ {\ell = 1} ^ {n - 1} \phi_ {n - 1, \ell} \gamma (n - \ell)\right),
$$

$$
\left( \begin{array}{c} \phi_ {n 1} \\ \vdots \\ \phi_ {n, n - 1} \end{array} \right) = \left( \begin{array}{c} \phi_ {n - 1, 1} \\ \vdots \\ \phi_ {n - 1, n - 1} \end{array} \right) - \phi_ {n n} \left( \begin{array}{c} \phi_ {n - 1, n - 1} \\ \vdots \\ \phi_ {n - 1, 1} \end{array} \right)
$$

and

$$
P _ {n} = P _ {n - 1} \left(1 - \phi_ {n n} ^ {2}\right).
$$

It can be shown that under the assumptions made on the process $( X _ { t } { : } t \in \mathbb { Z } )$ , it holds indeed that $\phi _ { n n }$ is equal to the value of the PACF of $( X _ { t } ; t \in \mathbb { Z } )$ at lag n. The result is formulated as Corollary 5.2.1 in Brockwell and Davis (1991). This fact is highlighted in an example.

# The PACF of an AR(2) process

Let $\left( X _ { t } ; t \in \mathbb { Z } \right)$ be a causal AR(2) process. Then, $\rho ( 1 ) = \phi _ { 1 } / ( 1 - \phi _ { 2 } )$ and all other values can be computed recursively from

$$
\rho (h) - \phi_ {1} \rho (h - 1) - \phi_ {2} \rho (h - 2) = 0, \qquad h \geq 2.
$$

Note that the ACVF $\gamma$ satisfies a difference equation with the same coefficients, which is seen by multiplying the latter equation with $\gamma ( 0 )$ . Applying the Durbin-Levinson algorithm gives first that

$$
\phi_ {1 1} = \frac {\gamma (1)}{\gamma (0)} = \rho (1) \qquad \mathrm {a n d} \qquad P _ {1} = P _ {0} (1 - \phi_ {1 1} ^ {2}) = \gamma (0) (1 - \rho (1) ^ {2}).
$$

Ignoring the recursion for the error terms $\scriptstyle { P _ { n } }$ in the following, the next $\phi _ { n \ell }$ values are obtained a

$$
\phi_ {2 2} = \frac {1}{P _ {1}} \left[ \gamma (2) - \phi_ {1 1} \gamma (1) \right] = \frac {1}{1 - \rho (1) ^ {2}} \left[ \rho (2) - \rho (1) ^ {2} \right]
$$

$$
= \frac {\phi_ {1} ^ {2} (1 - \phi_ {2}) ^ {- 1} + \phi_ {2} - [ \phi_ {1} (1 - \phi_ {2}) ^ {- 1} ] ^ {2}}{1 - [ \phi_ {1} (1 - \phi_ {2}) ^ {- 1} ] ^ {2}} = \phi_ {2},
$$

$$
\phi_ {2 1} = \phi_ {1 1} - \phi_ {2 2} \phi_ {1 1} = \rho (1) (1 - \phi_ {2}) = \phi_ {1},
$$

$$
\phi_ {3 3} = \frac {1}{P _ {2}} \left[ \gamma (3) - \phi_ {2 1} \gamma (2) - \phi_ {2 2} \gamma (1) \right] = \frac {1}{P _ {2}} \left[ \gamma (3) - \phi_ {1} \gamma (2) - \phi_ {2} \gamma (2) \right] = 0.
$$

Now, referring to the remarks after Example 3.3.7., no further computations are necessary to determine the PACF because $\phi _ { n n }$ ${ \bf \mu } = { \bf 0 }$ for all $\pmb { n } > \pmb { p } = \pmb { 2 }$ .

# Method 2: The innovations algorithm

In contrast to the Durbin-Levinson algorithm, this method can also be applied to nonstationary processes. It should thus, in general, be preferred over Method 1. The innovations algorithm gets its name from the fact that one directly uses the form of the prediction equations in Theorem 3.4.1. which are stated in terms of the innovations $( X _ { t + 1 } - \hat { X } _ { t + 1 } ) _ { t \mathbb { \in } \mathbb { Z } }$ . Observe that the sequence consists of uncorrelated random variables.

The one-step predictors $\hat { X } _ { n + 1 }$ can be calculated from the recursions

$$
\hat {X} _ {0 + 1} = 0, \qquad P _ {1} = \gamma (0)
$$

and, for $\pmb { n } \geq \pmb { 1 }$

$$
\hat {X} _ {n + 1} = \sum_ {\ell = 1} ^ {n} \theta_ {n \ell} \left(X _ {n + 1 - \ell} - \hat {X} _ {n + 1 - \ell}\right)
$$

$$
P _ {n + 1} = \gamma (0) - \sum_ {\ell = 0} ^ {n - 1} \theta_ {n, n - \ell} ^ {2} P _ {\ell + 1},
$$

where the coefficients are obtained from the equations

$$
\theta_ {n, n - \ell} = \frac {1}{P _ {\ell + 1}} \left[ \gamma (n - \ell) - \sum_ {i = 0} ^ {\ell - 1} \theta_ {\ell , \ell - i} \theta_ {n, n - i} P _ {i + 1} \right], \qquad \ell = 0, 1, \ldots , n - 1.
$$

As example we show how the innovations algorithm is applied to a moving average time series of order 1.

# Example : Prediction of an MA(1) Process

Let $\left( X _ { t } ; t \in \mathbb { Z } \right)$ be the MA(1) process $X _ { t } = Z _ { t } + \theta Z _ { t - 1 }$ . Note that

$$
\gamma (0) = \left(1 + \theta^ {2}\right) \sigma^ {2}, \qquad \gamma (1) = \theta \sigma^ {2} \qquad \text {a n d} \qquad \gamma (h) = 0 \quad (h \geq 2).
$$

Using the innovations algorithm, one can compute the one-step predictor from the values

$$
\theta_ {n 1} = \frac {\theta \sigma^ {2}}{P _ {n}}, \qquad \theta_ {n \ell} = 0 \quad (\ell = 2, \ldots , n - 1),
$$

and

$$
P _ {1} = (1 + \theta^ {2}) \sigma^ {2},
$$

$$
P _ {n + 1} = \left(1 + \theta^ {2} - \theta \theta_ {n 1}\right) \sigma^ {2}
$$

as

$$
\hat {X} _ {n + 1} = \frac {\theta \sigma^ {2}}{P _ {n}} (X _ {n} - \hat {X} _ {n}).
$$

# Method 3: Prediction based on the infinite past

Suppose that a causal and invertible ARMA(p,q) process is analyzed. Assume further that (unrealistically) the complete history of the process can be stored and that thus all past variables $( X _ { t } { : } t \leq n )$ can be accessed. Define then

$$
\tilde {X} _ {n + m} = E \left[ X _ {n + m} \mid X _ {n}, X _ {n - 1}, \dots \right],
$$

as the $m$ -step ahead predictor based on the infinite past. It can be shown that, for large sample sizes n, the difference between the values of $\hat { X } _ { n + m }$ and ${ \tilde { X } } _ { n + m }$ vanishes at an exponential rate. Exploiting causality and invertibility of the ARMA process, one can transform the predictor ${ \tilde { X } } _ { n + m }$ so that it is in a computationally more feasible form. To do so, note that by causality

$$
\begin{array}{l} \tilde {X} _ {n + m} = E \left[ X _ {n + m} \mid X _ {n}, X _ {n - 1}, \dots \right] \\ = E \left[ \sum_ {j = 0} ^ {\infty} \psi_ {j} Z _ {n + m - j} \mid X _ {n}, X _ {n - 1}, \dots \right] \\ = \sum_ {j = m} ^ {\infty} \psi_ {j} Z _ {n + m - j} \tag {3.4.5} \\ \end{array}
$$

because $E [ Z _ { t } | X _ { n } , X _ { n - 1 } , \ldots ]$ equals zero if $t { > } n$ and equals $\mathrm { ~ Z ~ } _ { \mathrm { ~ t ~ } }$ if ${ \pmb t } \leq { \pmb n }$ (due to invertibility!). The representation in (3.4.5.) can be used to compute the mean squared prediction error $\tilde { P } _ { n + m }$ . It follows from causality that

$$
\tilde {P} _ {n + m} = E \left[ \left(X _ {n + m} - \tilde {X} _ {n + m}\right) ^ {2} \right] = E \left[ \left(\sum_ {j = 0} ^ {m - 1} \psi_ {j} Z _ {n + m - j}\right) ^ {2} \right] = \sigma^ {2} \sum_ {j = 0} ^ {m - 1} \psi_ {j} ^ {2}. \tag {3.4.6}
$$

On the other hand, Equation does not allow to directly calculate the forecasts because ${ \tilde { X } } _ { n + m }$ is given in terms of the noise variables $Z _ { n + m - j }$ . Instead invertibility will be utilized. Observe first that

$$
E [ X _ {n + m - j} | X _ {n}, X _ {n - 1}, \ldots ] = \left\{ \begin{array}{l l} \tilde {X} _ {n + m - j}, & j <   m. \\ X _ {n + m - j}, & j \geq m. \end{array} \right.
$$

By invertibility (the $\because 0 = "$ part follows again from causality),

$$
\begin{array}{l} 0 = E \left[ Z _ {n + m} \mid X _ {n}, X _ {n - 1}, \dots \right] (3.4.7) \\ = E \left[ \sum_ {j = 0} ^ {\infty} \pi_ {j} X _ {n + m - j} \mid X _ {n}, X _ {n - 1}, \dots \right] (3.4.8) \\ = \sum_ {j = 0} ^ {\infty} \pi_ {j} E \left[ X _ {n + m - j} \mid X _ {n}, X _ {n - 1}, \dots \right]. (3.4.9) \\ \end{array}
$$

Combining the previous two statements, yields

$$
\tilde {X} _ {n + m} = - \sum_ {j = 1} ^ {m - 1} \pi_ {j} \tilde {X} _ {n + m - j} - \sum_ {j = m} ^ {\infty} \pi_ {j} X _ {n + m - j}. \tag {3.4.10}
$$

The equations can now be solved recursively for $m = 1 , 2 , .$ Note, however, that for any $\pmb { m } \geq 1$ the sequence $( X _ { n + m + t }$ $- \tilde { X } _ { n + m + t } \colon t \in  { \mathbb { Z } } )$ does not consist of uncorrelated random variables. In fact, if $\pmb { h } \in \mathbb { N } _ { 0 }$ , it holds that

$$
\begin{array}{l} E \left[ \left(X _ {n + m} - \tilde {X} _ {n + m}\right) \left(X _ {n + m + h} - \tilde {X} _ {n + m + h}\right) \right] (3.4.11) \\ = E \left[ \sum_ {j = 0} ^ {m - 1} \psi_ {j} Z _ {n + m - j} \sum_ {i = 0} ^ {m + h - 1} \psi_ {i} Z _ {n + m + h - i} \right] (3.4.12) \\ = \sigma^ {2} \sum_ {j = 0} ^ {m - 1} \psi_ {j} \psi_ {j + h}. (3.4.13) \\ \end{array}
$$

Finally, for practical purposes the given forecast needs to be truncated. This is accomplished by setting

$$
\sum_ {j = n + m} ^ {\infty} \pi_ {j} X _ {n + m - j} = 0.
$$

The resulting equations (see Equation for comparison) yield recursively the truncated $m$ -step predictors $X _ { n + m } ^ { * }$

$$
X _ {n + m} ^ {*} = - \sum_ {j = 1} ^ {m - 1} \pi_ {j} X _ {n + m - j} ^ {*} - \sum_ {j = m} ^ {n + m - 1} \pi_ {j} X _ {n + m - j}. \tag {3.4.14}
$$

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

This page titled 3.4: Forecasting is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 3.5: Parameter Estimation

Let $( X _ { t } ; t \in \mathbb { Z } )$ be a causal and invertible ARMA(p,q)

process with known orders $p$ and $q$ , possibly with mean $\pmb { \mu }$ . This section is concerned with estimation procedures for the unknown parameter vector

$$
\beta = \left(\mu , \phi_ {1}, \dots , \phi_ {p}, \theta_ {1}, \dots , \theta_ {q}, \sigma^ {2}\right) ^ {T}. \tag {3.5.1}
$$

To simplify the estimation procedure, it is assumed that the data has already been adjusted by subtraction of the mean and the discussion is therefore restricted to zero mean ARMA models.

In the following, three estimation methods are introduced. The method of moments works best in case of pure AR processes, while it does not lead to optimal estimation procedures for general ARMA processes. For the latter, more efficient estimators are provided by the maximum likelihood and least squares methods which will be discussed subsequently.

Method 1 (Method of Moments) Since this method is only efficient in their case, the presentation here is restricted to $\operatorname { A R } ( p )$ processes

$$
X _ {t} = \phi_ {1} X _ {t - 1} + \ldots + \phi_ {p} X _ {t - p} + Z _ {t}, t \in \mathbb {Z},
$$

where $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W N } ( 0 , \sigma ^ { 2 } )$ . The parameter vector $\beta$ consequently reduces to $( \phi , \sigma ^ { 2 } ) ^ { T }$ with ${ \boldsymbol { \phi } } = ( \phi _ { 1 } , \dots , \phi _ { p } ) ^ { T }$ and can be estimated using the Yule-Walker equations

$$
\Gamma_ {p} \phi = \gamma_ {p} \quad \text {a n d} \sigma^ {2} = \gamma (0) - \phi^ {T} \gamma_ {p},
$$

where $\Gamma _ { p } = ( \gamma ( k - j ) ) _ { k , j = 1 , \dots , p }$ and $\gamma _ { \pmb { p } } = ( \gamma ( \pmb { 1 } ) , \dots , \gamma ( \pmb { p } ) ) ^ { T }$ . Observe that the equations are obtained by the same arguments applied to derive the Durbin-Levinson algorithm in the previous section. The method of moments suggests to replace every quantity in the Yule-Walker equations with their estimated counterparts, which yields the Yule-Walker estimators

$$
\widehat {\phi} = \hat {\Gamma} _ {p} ^ {- 1} \hat {\gamma} _ {p} = \hat {R} _ {p} ^ {- 1} \hat {\rho} _ {p} \tag {3.5.2}
$$

$$
\hat {\sigma} ^ {2} = \hat {\gamma} (0) - \hat {\gamma} _ {p} ^ {T} \hat {\Gamma} _ {p} ^ {- 1} \hat {\gamma} _ {p} = \hat {\gamma} (0) \left[ 1 - \hat {\rho} _ {p} ^ {T} \hat {R} _ {p} ^ {- 1} \hat {\rho} _ {p} \right]. \tag {3.5.3}
$$

Therein, $\begin{array} { r } { \hat { R } _ { p } = \hat { \gamma } ( 0 ) ^ { - 1 } \hat { \Gamma } _ { p } } \end{array}$ and $\hat { \rho } _ { p } = \hat { \gamma } ( 0 ) ^ { - 1 } \hat { \gamma } _ { p }$ with

$\hat { \gamma } ( h )$ defined as in (1.2.1). Using $\hat { \gamma } ( h )$ as estimator for the ACVF at lag , a dependence on the sample size $\pmb { n }$ is obtained in an implicit way. This dependence is suppressed in the notation used here. The following theorem contains the limit behavior of the Yule-Walker estimators as $n$ tends to infinity.

Theorem 3.5.1. If $( X _ { t } ; t \in \mathbb { Z } )$ is a causal $\operatorname { A R } ( p )$ process, then

$$
\sqrt {n} (\widehat {\phi} - \phi) \xrightarrow {\mathcal {D}} N (0, \sigma^ {2} \Gamma_ {p} ^ {- 1}) \qquad \mathrm {a n d} \qquad \hat {\sigma} ^ {2} \xrightarrow {P} \sigma^ {2}
$$

as $\pmb { n }  \infty$ , where $\to ^ { P }$ indicates convergence in probability.

A proof of this result is given in Section 8.10 of Brockwell and Davis (1991). Since equations (3.5.2) and (3.5.3) have the same structure as the corresponding equations (3.4.3) and (3.4.4), the Durbin-Levinson algorithm can be used to solve recursively for the estimators $\widehat { \phi } _ { h } = ( \widehat { \phi } _ { h 1 } , \ldots , \widehat { \phi } _ { h h } )$ . Moreover, since $\phi _ { h h }$ is equal to the value of the PACF of $( X _ { t } ; t \in \mathbb { Z } )$ at lag $h$ , the estimator $\widehat { \phi } _ { h h }$ can be used as its proxy. Since it is already known that, in the case of $\operatorname { A R } ( p )$ processes, $\phi _ { h h } = 0$ if $h { > } p$ , Theorem (3.5.1) implies immediately the following corollary.

Corollary 3.5.1 If $( X _ { t } ; t \in \mathbb { Z } )$ is a causal AR(p) process, then

$$
\sqrt {n} \widehat {\phi} _ {h h} \xrightarrow {\mathcal {D}} Z \quad (n \to \infty)
$$

for all $h { > } p$ , where Z stands for a standard normal random variable.

Example 3.5.1. (Yule-Walker estimates for AR(2) processes). Suppose that $\pmb { n } = \pmb { 1 } 4 4$ values of the autoregressive process $X _ { t }$ $= 1 . 5 X _ { t - 1 } - . 7 5 X _ { t - 2 } + Z _ { t }$ have been observed, where $( Z _ { t } \colon t \ \in \mathbb { Z } )$ is a sequence of independent standard normal variates. Assume

further that $\hat { \gamma } ( 0 ) = 8 . 4 3 4$ , $\hat { \rho } ( 1 ) = 0 . 8 3 4$ and $\hat { \rho } ( 2 ) = 0 . 4 7 6$ have been calculated from the data. The Yule-Walker estimators for the parameters are then given by

$$
\widehat {\phi} = \left( \begin{array}{c} \widehat {\phi_ {1}} \\ \widehat {\phi_ {2}} \end{array} \right) = \left( \begin{array}{c c} 1. 0 0 0 & 0. 8 3 4 \\ 0. 8 3 4 & 1. 0 0 0 \end{array} \right) ^ {- 1} \left( \begin{array}{c} 0. 8 3 4 \\ 0. 4 7 6 \end{array} \right) = \left( \begin{array}{c} 1. 4 3 9 \\ - 0. 7 2 5 \end{array} \right)
$$

and

$$
\hat {\sigma} ^ {2} = 8. 4 3 4 \left[ 1 - (0. 8 3 4, 0. 4 7 6) \left(1. 4 3 9 - 0. 7 2 5\right) \right] = 1. 2 1 5.
$$

To construct asymptotic confidence intervals using Theorem 3.5.1, the unknown limiting covariance matrix $\sigma ^ { 2 } \Gamma _ { p } ^ { - 1 }$ needs to be estimated. This can be done using the estimator

$$
\frac {\hat {\sigma} ^ {2} \hat {\Gamma} _ {p} ^ {- 1}}{n} = \frac {1}{1 4 4} \frac {1 . 2 1 5}{8 . 4 3 4} \left( \begin{array}{l l} 1. 0 0 0 & 0. 8 3 4 \\ 0. 8 3 4 & 1. 0 0 0 \end{array} \right) ^ {- 1} = \left( \begin{array}{c c} 0. 0 5 7 ^ {2} & - 0. 0 0 3 \\ - 0. 0 0 3 & 0. 0 5 7 ^ {2} \end{array} \right).
$$

Then, the ${ \bf 1 } - \alpha$ level confidence interval for the parameters $\phi _ { 1 }$ and $\phi _ { 2 }$ are computed as

$$
1. 4 3 9 \pm 0. 0 5 7 z _ {1 - \alpha / 2} \qquad \text {a n d} \qquad - 0. 7 2 5 \pm 0. 0 5 7 z _ {1 - \alpha / 2},
$$

respectively, where ${ z _ { 1 - \alpha / 2 } }$ is the corresponding normal quantile.

Example 3.5.2 (Recruitment Series).

Let us reconsider the recruitment series of Example 3.3.5. There, an AR(2) model was first established as appropriate for the data and the model parameters were then estimated using an ordinary least squares approach. Here, the coefficients will instead be estimated with the Yule-Walker procedure. The R command is

$$
> \operatorname {r e c. y w} = \operatorname {a r. y w} (\operatorname {r e c}, \text {o r d e r} = 2) \}
$$

The mean estimate can be obtained from rec.yw$x.mean as $\hat { \pmb { \mu } } = { \bf 6 2 . 2 6 }$ , while the autoregressive parameter estimates and their standard errors are accessed with the commands rec.yw$ar and sqrt(rec.yw$asy.var.coef as $\hat { \phi } _ { 1 } = 1 . 3 3 1 6 ( . 0 4 2 2 )$ and $\hat { \phi } _ { 2 }$ $\mathbf { = - 4 4 4 5 ( . 0 4 2 2 ) }$ . Finally, the variance estimate is obtained from rec.yw$var.pred as $\hat { \pmb { \sigma } } ^ { 2 } = \pmb { 9 4 . 7 9 9 1 }$ . All values are close to their counterparts in Example 3.3.5.

Example 3.5.3. Consider the invertible MA(1) process $X _ { t } = Z _ { t } + \theta Z _ { t - 1 }$ , where $| \pmb \theta | < 1$ . Using invertibility, each $\pmb { X } _ { t }$ has an infinite autoregressive representation

$$
X _ {t} = \sum_ {j = 1} ^ {\infty} (- \theta) ^ {j} X _ {t - j} + Z _ {t}
$$

that is nonlinear in the unknown parameter $\pmb \theta$ to be estimated. The method of moments is here based on solving

$$
\hat {\rho} (1) = \frac {\hat {\gamma} (1)}{\hat {\gamma} (0)} = \frac {\hat {\theta}}{1 + \hat {\theta} ^ {2}}.
$$

for $\hat { \pmb \theta } .$ . The foregoing quadratic equation has the two solutions

$$
\hat {\theta} = \frac {1 \pm \sqrt {1 - 4 \hat {\rho} (1) ^ {2}}}{2 \hat {\rho} (1)},
$$

of which we pick the invertible one. Note moreover, that $| \hat { \rho } ( 1 ) |$ is not necessarily less or equal to 1/2 which is required for the existence of real solutions. (The theoretical value $\vert \rho ( 1 ) \vert$ , however, is always less than 1/2 for any MA(1) process, as an easy computation shows). Hence, $\pmb \theta$ can not always be estimated from given data samples.

Method 2 (Maximum Likelihood Estimation) The innovations algorithm of the previous section applied to a causal ARMA(p,q) process $( X _ { t } ; t \in \mathbb { Z } )$ gives

$$
\hat {X} _ {i + 1} = \sum_ {j = 1} ^ {i} \theta_ {i j} (X _ {i + 1 - j} - \hat {X} _ {i + 1 - j}), \quad 1 \leq i <   \max  \{p, q \},
$$

$$
\hat {X} _ {i + 1} = \sum_ {j = 1} ^ {p} \phi_ {j} X _ {i + 1 - j} + \sum_ {j = 1} ^ {q} \theta_ {i j} (X _ {i + 1 - j} - \hat {X} _ {i + 1 - j}), \quad i \geq \max  \{p, q \},
$$

with prediction error

$$
P _ {i + 1} = \sigma^ {2} R _ {i + 1}.
$$

In the last expression, $\sigma ^ { 2 }$ has been factored out due to reasons that will become apparent from the form of the likelihood function to be discussed below. Recall that the sequence $( X _ { i + 1 } - \hat { X } _ { i + 1 } ; i \in \mathbb { Z } )$ consists of uncorrelated random variables if the parameters are known. Assuming normality for the errors, we moreover obtain even independence. This can be exploited to define the Gaussian maximum likelihood estimation(MLE) procedure. Throughout, it is assumed that $( X _ { t } ; t \in \mathbb { Z } )$ has zero mean $( \pmb { \mu } = \pmb { 0 } )$ . The parameters of interest are collected in the vectors $\beta = ( \phi , \theta , \sigma ^ { 2 } ) ^ { T }$ and $\beta ^ { \prime } = ( \phi , \pmb \theta ) ^ { T }$ , where ${ \boldsymbol { \phi } } = ( \phi _ { 1 } , \dots , \phi _ { p } ) ^ { T }$ and $\pmb { \theta } = ( \pmb { \theta _ { 1 } } , \dots , \pmb { \theta _ { q } } ) ^ { T }$ . Assume finally that we have observed the variables $X _ { 1 } , \ldots , X _ { n }$ . Then, the Gaussian likelihood function for the innovations is

$$
L (\beta) = \frac {1}{(2 \pi \sigma^ {2}) ^ {n / 2}} \left(\prod_ {i = 1} ^ {n} R _ {i} ^ {1 / 2}\right) \exp \left(- \frac {1}{2 \sigma^ {2}} \sum_ {j = 1} ^ {n} \frac {(X _ {j} - \hat {X} _ {j}) ^ {2}}{R _ {j}}\right). (3. 5. 4)
$$

Taking the partial derivative of $\ln L ( \beta )$ with respect to the variable $\pmb { \sigma } ^ { 2 }$ reveals that the MLE for $\pmb { \sigma } ^ { 2 }$ can be

calculated from

$$
\hat {\sigma} ^ {2} = \frac {S (\hat {\phi} , \hat {\theta})}{n}, \qquad S (\hat {\phi}, \hat {\theta}) = \sum_ {j = 1} ^ {n} \frac {(X _ {j} - \hat {X} _ {j}) ^ {2}}{R _ {j}}.
$$

Therein, $\hat { \phi }$ and $\hat { \pmb \theta }$ denote the MLEs of $\phi$ and $\pmb \theta$ obtained from minimizing the profile likelihood or reduced likelihood

$$
\ell (\phi , \theta) = \ln \left(\frac {S (\phi , \theta)}{n}\right) + \frac {1}{n} \sum_ {j = 1} ^ {n} \ln (R _ {j}).
$$

Observe that the profile likelihood $\ell ( \phi , \theta )$ can be computed using the innovations algorithm. The speed of these computations depends heavily on the quality of initial estimates. These are often provided by the non-optimal Yule-Walker procedure. For numerical methods, such as the Newton-Raphson and scoring algorithms, see Section 3.6 in Shumway and Stoffer (2006).

The limit distribution of the MLE procedure is given as the following theorem. Its proof can be found in Section 8.8 of Brockwell and Davis (1991).

Theorem 3.5.2. Let $( X _ { t } ; t \in \mathbb { Z } )$ be a causal and invertible ARMA(p,q) process defined with an iid sequence

$$
(Z _ {t}: t \in \mathbb {Z}) s a t i s f y i n g E [ Z _ {t} ] = 0 \text {a n d}
$$

$E [ Z _ { t } ^ { 2 } ] = \sigma ^ { 2 }$ . Consider the MLE ${ \hat { \beta } } ^ { \prime }$ of $\beta ^ { \prime }$ that is initialized with the moment estimators of

Method 1. Then,

$$
\sqrt {n} \left(\hat {\beta} ^ {\prime} - \beta^ {\prime}\right) \xrightarrow {\mathcal {D}} N \left(0, \sigma^ {2} \Gamma_ {p, q} ^ {- 1}\right) \quad (n \to \infty).
$$

The result is optimal. The covariance matrix $\Gamma _ { p , q }$ is in block form and can be evaluated in terms of covariances of various autoregressive processes.

Example 3.5.4 (Recruitment Series). The MLE estimation procedure for the recruitment series can be applied in R as follows:

$$
> \operatorname {r e c}. \mathrm {m l e} = \operatorname {a r}. \mathrm {m l e} (\operatorname {r e c}, \text {o r d e r} = 2)
$$

The mean estimate can be obtained from rec.mle$x.mean as $\hat { \pmb { \mu } } = { \bf 6 2 . 2 6 }$ , while the autoregressive parameter estimates and their standard errors are accessed with the commands rec.mle$ar and sqrt(rec.mle$asy.var.coef) as $\hat { \phi } _ { 1 } = 1 . 3 5 1 3 ( . 0 4 1 0 )$ and $\hat { \phi } _ { 2 } = - . 4 0 9 9 ( . 0 4 1 0 )$ . Finally, the variance estimate is obtained from rec.yw$var.pred as $\hat { \pmb { \sigma } } ^ { 2 } = 8 9 . 3 3 6 0$ . All values are very close to their counterparts in Example 3.3.5.

Method 3 (Least Squares Estimation) An alternative to the method of moments and the MLE is provided by the least squares estimation (LSE). For causal and invertible ARMA(p,q) processes, it is based on minimizing the weighted sum of squares

$$
S (\phi , \theta) = \sum_ {j = 1} ^ {n} \frac {\left(X _ {j} - \hat {X} _ {j}\right) ^ {2}}{R _ {j}}
$$

with respect to $\phi$ and , respectively. Assuming that $\tilde { \phi }$ and $\tilde { \pmb { \theta } }$ denote these LSEs, the LSE for $\pmb { \sigma } ^ { 2 }$ is computed as

$$
\tilde {\sigma} ^ {2} = \frac {S (\tilde {\phi} , \tilde {\theta})}{n - p - q}.
$$

The least squares procedure has the same asymptotics as the MLE.

Theorem 3.5.3. The result of Theorem 3.5.2. holds also if $\hat { \beta } ^ { \prime }$ is replaced with $\tilde { \beta } ^ { \prime }$

Example 3.5.5 (Recruitment Series). The least squares estimation has already been discussed in Example 3.3.5, including the R commands.

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

This page titled 3.5: Parameter Estimation is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 3.6: Model Selection

In this section, a rough guide for going about the data analysis will be provided. It consists of several parts, most of which have been discussed previously. The main focus is on the selection of $\pmb { p }$ and $\pmb q$ in the likely case that these parameters are unknown.

Step 1. Plot the data and check whether or not the variability remains reasonably stable throughout the observation period. If that is not the case, use preliminary transformations to stabilize the variance. One popular class is given by the Box-Cox transformations (Box and Cox, 1964)

$$
f _ {\lambda} (U _ {t}) = \left\{ \begin{array}{l l} \lambda^ {- 1} (U _ {t} ^ {\lambda} - 1), & U _ {t} \geq 0,   \lambda > 0. \\ \ln U _ {t} & U _ {t} > 0,   \lambda = 0. \end{array} \right.
$$

In practice $f _ { 0 }$ or $f _ { 1 / 2 }$ are often adequate choices. (Recall, for instance, the Australian wine sales data of Example 1.4.1.)

Step 2. Remove, if present, trend and seasonal components from the data. Chapter 1 introduced a number of tools to do so, based on

the classical decomposition of a time series

$$
Y _ {t} = m _ {t} + s _ {t} + X _ {t}
$$

into a trend, a seasonality and a residual component. Note that differencing works also without the specific representation in the last display. If the data appears stationary, move on to the next step. Else apply, for example, another set of difference operations.

Step 3. Suppose now that Steps 1 and 2 have provided us with observations that are well described by a stationary sequence $( X _ { t } ; t $ $\in \mathbb { Z } )$ . The goal is then to find the most appropriate $\operatorname { A R M A } ( p , q )$ model to describe the process. In the unlikely case that $\pmb { p }$ and $\pmb q$ can be assumed known, utilize the estimation procedures of Section 3.5 directly. Otherwise, choose them according to one of the following criteria.

(a) The standard criterion that is typically implemented in software packages is a modification of Akaike's information criterion, see Akaike (1969), which was given by Hurvich and Tsai (1989). In this paper it is suggested that the ARMA model parameters be chosen to minimize the objective function

$$
\mathrm {A I C} _ {C} (\phi , \theta , p, q) = - 2 \ln L (\phi , \theta , S (\phi , \theta) / n) + \frac {2 (p + q + 1) n}{n - p - q - 2}. \tag {3.6.1}
$$

Here, ${ \cal L } ( \phi , \theta , \sigma ^ { 2 } )$ denotes the Gaussian likelihood defined in (3.5.4) and $ { \boldsymbol { S } } ( \phi , \theta )$ is the weighted sum of squares in (3.5.5). It can be seen from the definition that the $\mathbf { A I C } _ { C }$ does not attempt to minimize the log-likelihood function directly. The introduction of the penalty term on the right-hand side of (3.6.1) reduces the risk of overfitting.

(b) For pure autoregressive processes, Akaike (1969) introduced criterion that is based on a minimization of the final prediction error. Here, the order $\pmb { p }$ is chosen as the minimizer of the objective function

$$
\mathrm {F P E} = \hat {\sigma} ^ {2} \frac {n + p}{n - p},
$$

where ${ \hat { \sigma } } ^ { 2 }$ denotes the MLE of the unknown noise variance $\pmb { \sigma } ^ { 2 }$ . For more on this topic and other procedures that help fit a model, we refer here to Section 9.3 of Brockwell and Davis (1991).

Step 4. The last step in the analysis is concerned with diagnostic checking by applying the goodness of fit tests of Section 1.5.

# 3.7: Summary

The class of autoregressive moving average processes has been introduced to model stationary stochastic processes. Theoretical properties such as causality and invertibility have been examined, which depend on the zeroes of the autoregressive and moving average polynomials, respectively.

It has been shown how the causal representation of an ARMA process can be utilized to compute its covariance function which contains all information about the dependence structure. Assuming known parameter values, several forecasting procedures have been discussed. The Durbin- Levinson algorithm works well for pure AR processes, while the innovations algorithm is particularly useful for pure MA processes. Predictions using an infinite past work well for causal and invertible ARMA processes. For practical purposes, however, a truncated version is more relevant.

Since the exact parameter values are in general unknown, several estimation procedures were introduced. The Yule-Walker procedure is only optimal in the AR case but provides useful initial estimates that can be used for the numerical derivation of maximum likelihood or least squares estimates.

Finally, a framework has been provided that may potentially be useful when facing the problem of analyzing a data set in practice.

This page titled 3.7: Summary is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# CHAPTER OVERVIEW

# 4: Spectral Analysis

This page is a draft and is under active development.

In this chapter, a general method is discussed to deal with the periodic components of a time series.

4.1: Introduction to Spectral Analysis   
4.2: The Spectral Density and the Periodogram   
4.3: Large Sample Properties   
4.4: Linear Filtering   
4.5: Summary

This page titled 4: Spectral Analysis is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 4.1: Introduction to Spectral Analysis

Many of the time series discussed in the previous chapters displayed strong periodic components: The sunspot numbers of Example 1.1.1, the number of trapped lynx of Example 1.1.2 and the Australian wine sales data of Example 1.4.1. Often, there is an obvious choice for the period $\pmb { d }$ of this cyclical part such as an annual pattern in the wine sales. Given $d ,$ one could then proceed by removing the seasonal effects as in Section 1.4. In the first two examples it is, however, somewhat harder to determine the precise value of . In this chapter, a general method is therefore discussed to deal with the periodic components of a time series. To complicate matters, it is usually the case that several cyclical patterns are simultaneously present in a time series. As an example recall the southern oscillation index (SOI) data which exhibits both an annual pattern and a so-called El Ni o pattern.

The sine and cosine functions are the prototypes of periodic functions. They are going to be utilized here to describe cyclical behavior in time series. Before doing so, a cycle is defined to be one complete period of a sine or cosine function over a time interval of length $\mathbf { 2 \pi }$ . Define also the frequency

$$
\omega = \frac {1}{d}
$$

as the number of cycles per observation, where $\pmb { d }$ denotes the period of a time series (that is, the number of observations in a cycle). For monthly observations with an annual period, $d = 1 2$ and hence $\omega = 1 / 1 2 = 0 . 0 8 3$ cycles per observation. Now reconsider the process

$$
X _ {t} = R \sin (2 \pi \omega t + \varphi)
$$

as introduced in Example 1.2.2, using the convention $\lambda = 2 \pi \omega$ . To include randomness in this process, choose the amplitude $\pmb { R }$ and the phase $\varphi$ to be random variables. An equivalent representation of this process is given by

$$
X _ {t} = A \cos (2 \pi \omega t) + B \sin (2 \pi \omega t),
$$

with $A = R \sin ( \varphi )$ and $B = R \cos ( \varphi )$ usually being independent standard normal variates. Then, $R ^ { 2 } = A ^ { 2 } + B ^ { 2 }$ is a $x$ -squared random variable with 2 degrees of freedom and $\varphi = \tan ^ { - 1 } ( B / A )$ is uniformly distributed on $( - \pi , \pi ]$ . Moreover, $\pmb { R }$ and $\varphi$ are independent. Choosing now the value of $\pmb { \omega }$ one particular periodicity can be described. To accommodate more than one, it seems natural to consider mixtures of these periodic series with multiple frequencies and amplitudes:

$$
X _ {t} = \sum_ {j = 1} ^ {m} \left[ A _ {j} \cos (2 \pi \omega_ {j} t) + B _ {j} \sin (2 \pi \omega_ {j} t) \right], \qquad t \in \mathbb {Z},
$$

where $A _ { 1 } , \ldots , A _ { m }$ and $\boldsymbol { B } _ { 1 } , \ldots , \boldsymbol { B } _ { m }$ are independent random variables with zero mean and variances $\sigma _ { 1 } ^ { 2 } , \ldots , \sigma _ { m } ^ { 2 } $ and $\omega _ { 1 } , \ldots , \omega _ { m }$ are distinct frequencies. It can be shown that $( X _ { t } ; t \in \mathbb { Z } )$ is a weakly stationary process with lag-h ACVF

$$
\gamma (h) = \sum_ {j = 1} ^ {m} \sigma_ {j} ^ {2} \cos (2 \pi \omega_ {j} h), \qquad h \in \mathbb {Z}.
$$

The latter result yields in particular that $\gamma ( 0 ) = \sigma _ { 1 } ^ { 2 } + \ldots + \sigma _ { m } ^ { 2 }$ . The variance of $\pmb { X } _ { t }$ is consequently the sum of the component variances.

Example 4.1.1. Let ${ \pmb m } = { \pmb 2 }$ and choose $A _ { 1 } = B _ { 1 } = 1$ , $A _ { 2 } = B _ { 2 } = 4$ to be constant as well as $\omega _ { 1 } = 1 / 1 2$ and $\omega _ { 2 } = 1 / 6$ . This means that

$$
X _ {t} = X _ {t} ^ {(1)} + X _ {t} ^ {(2)} = \left[ \cos (2 \pi t / 1 2) + \sin (2 \pi t / 1 2) \right] + \left[ 4 \cos (2 \pi t / 6) + 4 \sin (2 \pi t / 6) \right]
$$

is the sum of two periodic components of which one exhibits an annual cycle and the other a cycle of six months. For all processes involved, realizations of $\pmb { n } = 4 8$ observations (4 years of data) are displayed in Figure 4.1. Also shown is a fourth time series plot which contains the $\pmb { X } _ { t }$ distorted by standard normal independent noise, $\tilde { X } _ { t }$ . The corresponding R code is:

$$
\begin{array}{l} > t = 1: 4 8 \\ > x 1 = \cos (2 ^ {*} p i ^ {*} t / 1 2) + \sin (2 ^ {*} p i ^ {*} t / 1 2) \\ > x 2 = 4 ^ {*} \cos (2 ^ {*} p i ^ {*} t / 6) + 4 ^ {*} \sin (2 ^ {*} p i ^ {*} t / 6) \\ \end{array}
$$

$$
\begin{array}{l} > x = x 1 + x 2 \\ > t i l d e x = x + r n o r m (4 8) \\ \end{array}
$$

Note that the squared amplitude of $X _ { t } ^ { ( 1 ) }$ is $\mathbf { 1 ^ { 2 } + 1 ^ { 2 } = 2 }$ . The maximum and minimum values of $X _ { t } ^ { ( 1 ) }$ are therefore $\pm { \sqrt { 2 } }$ . Similarly, we obtain $\pm \sqrt { 3 2 }$ for the second component.

For a statistician it is now important to develop tools to recover the periodicities from the data. The branch of statistics concerned with this problem is called spectral analyis. The standard method in this area is based on the periodogram which is introduced now. Suppose for the moment that the frequency parameter $\omega _ { 1 } = 1 / 1 2$ in Example 4.1.1 is known. To obtain estimates of $\pmb { A } _ { 1 }$ and $\mathbf { \delta } _ { B _ { 1 } }$ , one could try to run a regression using the explanatory variables $Y _ { t , 1 } = \cos ( 2 \pi t / 1 2 )$ or $Y _ { t , 2 } = \sin ( 2 \pi t / 1 2 )$ to compute the least squares estimators

$$
\hat {A} _ {1} = \frac {\sum_ {t = 1} ^ {n} X _ {t} Y _ {t , 1}}{\sum_ {t = 1} ^ {n} Y _ {t , 1} ^ {2}} = \frac {2}{n} \sum_ {t = 1} ^ {n} X _ {t} \cos (2 \pi t / 1 2),
$$

$$
\hat {B} _ {1} = \frac {\sum_ {t = 1} ^ {n} X _ {t} Y _ {t , 2}}{\sum_ {t = 1} ^ {n} Y _ {t , 2} ^ {2}} = \frac {2}{n} \sum_ {t = 1} ^ {n} X _ {t} \sin (2 \pi t / 1 2).
$$

![](images/22d1625668e84d44a5cf482621e35cbc006f0477e06006a8ffce6385367ef786.jpg)

![](images/21bd5f807563ea4bd74c29280c558ce66022b7eb6bdb4e35eb8a00820da0b4b0.jpg)

![](images/6a05d7b223bc3b74bf04922452472ef04fda42359d75b5e6586a82988025c281.jpg)

![](images/81b1f088e5b838d36ca8e03fefb36de9a2726ae82bd5e06ad394a196d17d0e8b.jpg)  
Figure 4.1: Time series plots of $\mathrm { ( X _ { t } ^ { ( 1 ) } ) }$ , $\mathbf { ( X _ { t } ^ { \alpha ( 2 ) } ) }$ , $\left( \mathrm { X } _ { \mathrm { t } } \right)$ and $\tilde { X } _ { t }$

Since, in general, the frequencies involved will not be known to the statistician prior to the data analysis, the foregoing suggests to pick a number of potential \(\omega's, say $j / n$ for $j = 1 , \ldots , n / 2$ and to run a long regression of the form

$$
X _ {t} = \sum_ {j = 0} ^ {n / 2} \left[ A _ {j} \cos (2 \pi j t / n) + B _ {j} \sin (2 \pi j t / n) \right]. \tag {4.1.1}
$$

This leads to least squares estimates $\hat { A } _ { j }$ and $\hat { B } _ { j }$ of which the "significant'' ones should be selected. Note that the regression in 4.1.1 is a perfect one because there are as many unknowns as variables! Note also that

$$
P (j / n) = \hat {A} _ {j} ^ {2} + \hat {B} _ {j} ^ {2}
$$

is essentially (up to a normalization) an estimator for the correlation between the time series $X _ { t }$ and the corresponding sum of the periodic cosine and sine functions at frequency ${ \dot { \jmath } } / n$ . The collection of all $P ( j / n )$ , $j = 1 , \ldots , n / 2 ,$ , is called the scaled periodogram. It can be computed quickly via an algorithm known as the fast Fourier transform (FFT) which in turn is based on the discrete Fourier transform (DFT)

$$
d (j / n) = \frac {1}{\sqrt {n}} \sum_ {t = 1} ^ {n} X _ {t} \exp (- 2 \pi i j t / n).
$$

The frequencies ${ \dot { \ j } } / n$ are called the Fourier or fundamental frequencies. Since $\exp ( - i x ) = \cos ( x ) - i \sin ( x )$ and $| z | ^ { 2 } = z { \bar { z } } = ( a + i b ) ( a$ $- \left( i b \right) = a ^ { 2 } + b ^ { 2 }$ for any complex number $z = a + i b ,$ it follows that

$$
I (j / n) = | d (j / n) | ^ {2} = \frac {1}{n} \left(\sum_ {t = 1} ^ {n} X _ {t} \cos (2 \pi j t / n)\right) ^ {2} + \frac {1}{n} \left(\sum_ {t = 1} ^ {n} X _ {t} \sin (2 \pi j t / n)\right) ^ {2}.
$$

The quantity $\pmb { I } ( j / n )$ is referred to as the periodogram. It follows immediately that the periodogram and the scaled periodogram are related via the identity $4 I ( j / n ) = n P ( j / n )$ .

Example 4.1.2. Using the expressions and notations of Example 4.1.1, the periodogram and the scaled periodogram are computed in R as follows:

$\begin{array}{rl} & {\mathrm{>t = 1:48}}\\ & {\mathrm{>l = abs(fft(x) / sqrt(48))^{\wedge}2}}\\ & {\mathrm{>P = 4^{*}I / 48}}\\ & {\mathrm{>f = 0:24 / 48}}\\ & {\mathrm{>plot(f,P[1:25],type \(\equiv$ "1")}}\\ & {\mathrm{>abline(v = 1 / 12)}}\\ & {\mathrm{>abline(v = 1 / 6)}} \end{array}\)

The corresponding (scaled) periodogram for $( \tilde { X } _ { t } )$ can be obtained in a similar fashion. The scaled periodograms are shown in the left and middle panel of Figure 4.2. The right panel displays the scaled periodogram of another version of $( \tilde { X } _ { t } )$ in which the standard normal noise has been replaced with normal noise with variance 9. From these plots it can be seen that the six months periodicity is clearly visible in the graphs (see the dashed vertical lines at $\scriptstyle x = 1 / 6$ . The less pronounced annual cycle (vertical line at $x { = } 1 / 1 2$ is still visible in the first two scaled periodograms but is lost if the noise variance is increased as in the right plot. Note, however, that the y-scale is different for all three plots.

![](images/3e581ee404a5080fdb4984a2dff4f44f74467f9c5d5172038eb8b119174803ce.jpg)

![](images/5b5934ded000ae28c0066aff3ccceadcea7f7035eace4dc74f6eb134a1c7b88a.jpg)

![](images/0b437f80dec5e56739dc89a5ba704da37148380256a99889075ee7631af311cf.jpg)  
Figure 4.2: The scaled periodograms of $( X _ { t } ) , ( \tilde { X } _ { t } ^ { ( 1 ) } ) , ( \tilde { X } _ { t } ^ { ( 2 ) } )$

In the ideal situation that we observe the periodic component without additional contamination by noise, we can furthermore see why the periodogram may be useful in uncovering the variance decomposition from above. We have shown in the lines preceding Example 4.1.1 that the squared amplitudes of $X _ { t } ^ { ( 1 ) }$ and $X _ { t } ^ { ( 2 ) }$ are 2 and 32, respectively. These values are readily read from the scaled periodogram in the left panel of Figure 4.2. The contamination with noise alters these values.

In the next section, it is established that the time domain approach (based on properties of the ACVF, that is, regression on past values of the time series) and the frequency domain approach (using a periodic function approach via fundamental frequencies, that is, regression on sine and cosine functions) are equivalent. Some details are given on the spectral density (the population counterpart of the periodogram) and on properties of the periodogram itself.

# Contributors and Attributions

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

# 4.2: The Spectral Density and the Periodogram

The fundamental technical result which is at the core of spectral analysis states that any (weakly) stationary time series can be viewed (approximately) as a random superposition of sine and cosine functions varying at various frequencies. In other words, the regression in (4.1.1) is approximately true for all weakly stationary time series. In Chapters 1-3, it is shown how the characteristics of a stationary stochastic process can be described in terms of its ACVF $\gamma ( h )$ . The first goal in this section is to introduce the quantity corresponding to $\gamma ( h )$ in the frequency domain.

# Definition 4.2.1 (Spectral Density)

If the ACVF $\gamma ( h )$ of a stationary time series (X ) satisfies the conditiont t\in\mathbb{Z} \nonumber \]

$$
\sum_ {h = - \infty} ^ {\infty} | \gamma (h) | <   \infty ,
$$

then there exists a function $f$ defined on (-1/2,1/2] such that

$$
\gamma (h) = \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega h) f (\omega) d \omega , \qquad h \in \mathbb {Z},
$$

and

$$
f (\omega) = \sum_ {h = - \infty} ^ {\infty} \gamma (h) \exp (- 2 \pi i \omega h), \qquad \omega \in (- 1 / 2, 1 / 2 ].
$$

The function $f$ is called the spectral density of the process $\pmb { X } _ { t } \colon t \in \mathbb { Z }$ .

Definition 4.2.1 (which contains a theorem part as well) establishes that each weakly stationary process can be equivalently described in terms of its ACVF or its spectral density. It also provides the formulas to compute one from the other. Time series analysis can consequently be performed either in the time domain (using $\gamma ( h ) )$ or in the frequency domain (using f . Which approach is the more suitable one cannot be decided in a general fashion but has to be reevaluated for every application of interest.

In the following, several basic properties of the spectral density are collected and evaluated $f$ for several important examples. That the spectral density is analogous to a probability density function is established in the next proposition.

# Proposition 4.2.1

If $\mathrm { f } ( \omega )$ is the spectral density of a weakly stationary process $( X _ { t } ; t \in \mathbb { Z } )$ , then the following statements hold:

a. $\mathrm { f } ( \omega ) \geq 0$ for all $\omega$ . This follows from the positive definiteness of $\gamma ( h )$   
b. $\scriptstyle \mathrm { f } ( \omega ) = \mathrm { f } ( - \omega )$ and $\scriptstyle \mathrm { f } ( \omega + 1 ) = \mathrm { f } ( \omega )$   
c. The variance of $( X _ { t } ; t \in \mathbb { Z } )$ is given by

$$
\gamma (0) = \int_ {- 1 / 2} ^ {1 / 2} f (\omega) d \omega .
$$

Part (c) of the proposition states that the variance of a weakly stationary process is equal to the integrated spectral density over all frequencies. This property is revisited below, when a spectral analysis of variance (spectral ANOVA) will be discussed. In the following three examples are presented.

# Example 4.2.1 (White Noise)

If $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W N } ( 0 , \sigma ^ { 2 } )$ , then its ACVF is nonzero only for $h { = } 0$ , in which case $\gamma _ { Z } ( h ) = \sigma ^ { 2 }$ . Plugging this result into the defining equation in Definition4.2.1 yields that

$$
f _ {Z} (\omega) = \gamma_ {Z} (0) \exp (- 2 \pi i \omega 0) = \sigma^ {2}.
$$

The spectral density of a white noise sequence is therefore constant for all $\boldsymbol \omega \in ( - 1 / 2 , 1 / 2 ]$ , which means that every frequency contributes equally to the overall spectrum. This explains the term ``white'' noise (in analogy to ``white'' light).

# Example 4.2.2 (Moving Average)

Let $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W } \mathbf { N } ( 0 , \sigma ^ { 2 } )$ and define the time series $( X _ { t } { : } t \in \mathbb { Z } )$ by

$$
X _ {t} = \frac {1}{2} \left(Z _ {t} + Z _ {t - 1}\right), \qquad t \in \mathbb {Z}.
$$

It can be shown that

$$
\gamma_ {X} (h) = \frac {\sigma^ {2}}{4} \left(2 - | h |\right), \qquad h = 0, \pm 1
$$

![](images/35239ac5b6f6e502bb5210a37da8a466ebc5d5c129cf20d70a8c77e86fee9398.jpg)

![](images/ed5382dbf4110c2c0bb549a0410866e8ec290dac1f3300b6054fb8ae7a344742.jpg)

![](images/5a5a642737e5beca3e63869599b7a6bfb37562200bd2d0db10472c47bf7a68d7.jpg)  
Figure 4.3: Time series plot of white noise $( Z _ { t } \colon t \in \mathbb { Z } )$ (left), two-point moving average $( X _ { t } ; t \in \mathbb { Z } )$ (middle) and spectral density of $( X _ { t } ; t \in \mathbb { Z } )$ (right).

and that $\scriptstyle \gamma \_ X = 0$ otherwise. Therefore,

$$
\begin{array}{l} f _ {X} (\omega) = \sum_ {h = - 1} ^ {1} \gamma_ {X} (h) \exp (2 \pi i \omega h) \\ = \frac {\sigma^ {2}}{4} (\exp (- 2 \pi i \omega (- 1))) + 2 \exp (- 2 \pi i \omega 0) + \exp (- 2 \pi i \omega 1) \\ = \frac {\sigma^ {2}}{2} (1 + \cos (2 \pi \omega)) \\ \end{array}
$$

using that $\exp ( i x ) = \cos ( x ) + i \sin ( x )$ , $\cos ( x ) = \cos ( - x )$ and $\sin ( x ) = - \sin ( - x )$ . It can be seen from the two time series plots in Figure 4.3 that the application of the two-point moving average to the white noise sequence smoothes the sample path. This is due to an attenuation of the higher frequencies which is visible in the form of the spectral density in the right panel of Figure 4.3. All plots have been obtained using Gaussian white noise with ${ \pmb \sigma } ^ { 2 } = 1$ .

Example 4.2.3 (AR(2) Process).

Let $( X _ { t } ; t \in \mathbb { Z } )$ be an AR(2) process which can be written in the form

$$
Z _ {t} = X _ {t} - \phi_ {1} X _ {t - 1} - \phi_ {2} X _ {t - 2}, \quad t \in \mathbb {Z}
$$

In this representation, it can be seen that the ACVF $\gamma _ { z }$ of the white noise sequence can be obtained as

$$
\begin{array}{l} \gamma_ {Z} (h) = E \left[ \left(X _ {t} - \phi_ {1} X _ {t - 1} - \phi_ {2} X _ {t - 2}\right) \left(X _ {t + h} - \phi_ {1} X _ {t + h - 1} - \phi_ {2} X _ {t + h - 2}\right) \right] \\ = \left(1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}\right) \gamma_ {X} (h) + \left(\phi_ {1} \phi_ {2} - \phi_ {1}\right) \left[ \gamma_ {X} (h + 1) + \gamma_ {X} (h - 1) \right] \\ \end{array}
$$

$$
- \phi_ {2} [ \gamma_ {X} (h + 2) + \gamma_ {X} (h - 2) ]
$$

Now it is known from Definition 4.2.1 that

$$
\gamma_ {X} (h) = \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega h) f _ {X} (\omega) d \omega
$$

and

$$
\gamma_ {Z} (h) = \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega h) f _ {Z} (\omega) d \omega ,
$$

![](images/d263f5b743c3a084e21d3e7a300516f66694f6b24e12b08dd4e3d5dcfc9e6cae.jpg)

![](images/0123b8b6dd1476c0289f2220f4c55509fabe93b1127b3df80922ce837aab9b72.jpg)  
Figure 4.4: Time series plot and spectral density of the AR(2) process in Example 4.2.3.

where $\pmb { f } _ { \pmb { X } } ( \omega )$ and ${ f } _ { Z } ( \omega )$ denote the respective spectral densities. Consequently,

$$
\begin{array}{l} \gamma_ {Z} (h) = \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega h) f _ {Z} (\omega) d \omega \\ = \left(1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}\right) \gamma_ {X} (h) + \left(\phi_ {1} \phi_ {2} - \phi_ {1}\right) \left[ \gamma_ {X} (h + 1) + \gamma_ {X} (h - 1) \right] - \phi_ {2} \left[ \gamma_ {X} (h + 2) + \gamma_ {X} (h - 2) \right] \\ = \int_ {- 1 / 2} ^ {1 / 2} \left[ \left(1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}\right) + \left(\phi_ {1} \phi_ {2} - \phi_ {1}\right) \left(\exp (2 \pi i \omega) + \exp (- 2 \pi i \omega)\right) \right. \\ \left. - \phi_ {2} \left(\exp (4 \pi i \omega) + \exp (- 4 \pi i \omega)\right) \right] \exp (2 \pi i \omega h) f _ {X} (\omega) d \omega \\ = \int_ {- 1 / 2} ^ {1 / 2} \left[ (1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}) + 2 (\phi_ {1} \phi_ {2} - \phi_ {1}) \cos (2 \pi \omega) - 2 \phi_ {2} \cos (4 \pi \omega) \right] \exp (2 \pi i \omega h) f _ {X} (\omega) d \omega . \\ \end{array}
$$

The foregoing implies together with $f _ { Z } ( \omega ) = \sigma ^ { 2 }$ that

$$
\sigma^ {2} = \left[ \left(1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}\right) + 2 \left(\phi_ {1} \phi_ {2} - \phi_ {1}\right) \cos (2 \pi \omega) - 2 \phi_ {2} \cos (4 \pi \omega) \right] f _ {X} (\omega).
$$

Hence, the spectral density of an AR(2) process has the form

$$
f _ {X} (\omega) = \sigma^ {2} \big [ (1 + \phi_ {1} ^ {2} + \phi_ {2} ^ {2}) + 2 (\phi_ {1} \phi_ {2} - \phi_ {1}) \cos (2 \pi \omega) - 2 \phi_ {2} \cos (4 \pi \omega) \big ] ^ {- 1}.
$$

Figure 4.4 displays the time series plot of an AR(2) process with parameters $\phi _ { 1 } = 1 . 3 5$ , $\phi _ { 2 } = - . 4 1$ and $\sigma ^ { 2 } = 8 9 . 3 4 .$ . These values are very similar to the ones obtained for the recruitment series in Section 3.5. The same figure also shows the corresponding spectral density using the formula just derived.

With the contents of this Section, it has so far been established that the spectral density $\$ 10$ is a population quantity describing the impact of the various periodic components. Next, it is verified that the periodogram $\mathbb { S } \mathrm { I } ( \mathrm { \backslash 0 m e g a \_ j ) \mathbb { S } }$ introduced in Section is the sample counterpart of the spectral density.

# Proposition 4.2.2.

Let $\omega _ { j } = j / n$ denote the Fourier frequencies. If $I ( \omega _ { j } ) = | d ( \omega _ { j } ) | ^ { 2 }$ is the periodogram based on observations $X _ { 1 } , \ldots , X _ { n }$ of a weakly stationary process $( X _ { t } ; t \in \mathbb { Z } )$ , then

$$
I (\omega_ {j}) = \sum_ {h = - n + 1} ^ {n - 1} \hat {\gamma} _ {n} (h) \exp (- 2 \pi i \omega_ {j} h), \qquad j \neq 0.
$$

If $j = 0$ , then $I ( \omega _ { 0 } ) = I ( 0 ) = n \bar { X } _ { n } ^ { 2 } .$ .

Proof. Let first $j \neq 0 .$ Using that $\begin{array} { r } { \sum _ { t = 1 } ^ { n } \exp ( - 2 \pi i \omega _ { j } t ) = 0 , } \end{array}$ , it follows that

$$
\begin{array}{l} I (\omega_ {j}) = \frac {1}{n} \sum_ {t = 1} ^ {n} \sum_ {s = 1} ^ {n} (X _ {t} - \bar {X} _ {n}) (X _ {s} - \bar {X} _ {n}) \exp (- 2 \pi i \omega_ {j} (t - s)) \\ = \frac {1}{n} \sum_ {h = - n + 1} ^ {n - 1} \sum_ {t = 1} ^ {n - | h |} (X _ {t + | h |} - \bar {X} _ {n}) (X _ {t} - \bar {X} _ {n}) \exp (- 2 \pi i \omega_ {j} h) \\ = \sum_ {h = - n + 1} ^ {n - 1} \hat {\gamma} _ {n} (h) \exp (- 2 \pi i \omega_ {j} h), \\ \end{array}
$$

which proves the first claim of the proposition. If ${ \dot { \pmb { j } } } = { \bf 0 }$ , the relations $\cos ( 0 ) = 1$ and $\mathbf { s i n } ( \mathbf { 0 } ) = \mathbf { 0 }$ imply that $I ( 0 ) = n \bar { X } _ { n } ^ { 2 }$ . This completes the proof.

More can be said about the periodogram. In fact, one can interpret spectral analysis as a spectral analysis of variance (ANOVA). To see this, let first

$$
d _ {c} (\omega_ {j}) = \mathrm {R e} (d (\omega_ {j})) = \frac {1}{\sqrt {n}} \sum_ {t = 1} ^ {n} X _ {t} \cos (2 \pi \omega_ {j} t),
$$

$$
d _ {s} (\omega_ {j}) = \mathrm {I m} (d (\omega_ {j})) = \frac {1}{\sqrt {n}} \sum_ {t = 1} ^ {n} X _ {t} \sin (2 \pi \omega_ {j} t).
$$

Then, $I ( \omega _ { j } ) = d _ { c } ^ { 2 } ( \omega _ { j } ) + d _ { s } ^ { 2 } ( \omega _ { j } )$ . Let us now go back to the introductory example and study the process

$$
X _ {t} = A _ {0} + \sum_ {j = 1} ^ {m} \left[ A _ {j} \cos (2 \pi \omega_ {j} t) + B _ {j} \sin (2 \pi \omega_ {j} t) \right],
$$

where $m = ( n - 1 ) / 2$ and $\pmb { n }$ odd. Suppose $X _ { 1 } , \ldots , X _ { n }$ have been observed. Then, using regression techniques as before, it can be seen that $A _ { 0 } = \bar { X } _ { n }$ and

$$
A _ {j} = \frac {2}{n} \sum_ {t = 1} ^ {n} X _ {t} \cos (2 \pi \omega_ {j} t) = \frac {2}{\sqrt {n}} d _ {c} (\omega_ {j}),
$$

$$
B _ {j} = \frac {2}{n} \sum_ {t = 1} ^ {n} X _ {t} \sin (2 \pi \omega_ {j} t) = \frac {2}{\sqrt {n}} d _ {s} (\omega_ {j}).
$$

Therefore,

$$
\sum_ {t = 1} ^ {n} \left(X _ {t} - \bar {X} _ {n}\right) ^ {2} = 2 \sum_ {j = 1} ^ {m} \left[ d _ {c} ^ {2} (\omega_ {j}) + d _ {s} ^ {2} (\omega_ {j}) \right] = 2 \sum_ {j = 1} ^ {m} I (\omega_ {j})
$$

and the following ANOVA table is obtained. If the underlying stochastic process exhibits a strong periodic pattern at a certain frequency, then the periodogram will most likely pick these up.

<table><tr><td>Source</td><td>df</td><td>SS</td><td>MS</td></tr><tr><td>ω1</td><td>2</td><td>2I(ω1)</td><td>I(ω1)</td></tr><tr><td>ω2</td><td>2</td><td>2I(ω2)</td><td>I(ω2)</td></tr><tr><td>i</td><td>i</td><td>i</td><td>i</td></tr><tr><td>ωm</td><td>2</td><td>2I(ωm)</td><td>I(ωm)</td></tr><tr><td>Total</td><td>n-1</td><td>Σnt-1(Xt-Xm)2</td><td></td></tr></table>

# Example 4.2.4

Consider the $\pmb { n = 5 }$ data points $X _ { 1 } = 2$ , $X _ { 2 } = 4$ , $X _ { 3 } = 6$ , $X _ { 4 } = 4$ and $X _ { 5 } = 2$ , which display a cyclical but nonsinusoidal pattern. This suggests that $\omega = 1 / 5$ is significant and $\omega = 2 / 5$ is not. In R, the spectral ANOVA can be produced as follows.

$$
\begin{array}{l} > x = c (2, 4, 6, 4, 2), \quad t = 1: 5 \\ > \cos 1 = \cos (2 ^ {*} p i ^ {*} t ^ {*} 1 / 5) \\ > \sin 1 = \sin (2 ^ {*} p i ^ {*} t ^ {*} 1 / 5) \\ > \cos 2 = \cos (2 ^ {*} p i ^ {*} t ^ {*} 2 / 5) \\ > \sin 2 = \sin (2 ^ {*} p i ^ {*} t ^ {*} 2 / 5) \\ \end{array}
$$

This generates the data and the independent cosine and sine variables. Now run a regression and check the ANOVA output.

$$
\begin{array}{l} > \operatorname {r e g} = \operatorname {l m} (x \backslash - \{\} \cos 1 + \sin 1 + \cos 2 + \sin 2) \\ > \text {a n o v a} (\text {r e g}) \\ \end{array}
$$

This leads to the following output.

Response: x

Df Sum Sq Mean Sq F value Pr(>F)

cos1 1 7.1777 7.1777

cos2 1 0.0223 0.0223

sin1 1 3.7889 3.7889

sin2 1 0.2111 0.2111

Residuals 0 0.0000

According to previous reasoning (check the last table!), the periodogram at frequency $\omega _ { 1 } = 1 / 5$ is given as the sum of the and coefficients, that is, $I ( 1 / 5 ) = ( d _ { c } ( 1 / 5 ) + d _ { s } ( 1 / 5 ) ) / 2 = ( 7 . 1 7 7 7 + 3 . 7 8 8 9 ) / 2 = 5 . 4 8 3 3 .$ . Similarly, $I ( 2 / 5 ) = ( d _ { c } ( 2 / 5 ) + d _ { s } ( 2 / 5 ) ) / 2$ $= ( 0 . 0 2 2 3 + 0 . 2 1 1 1 ) / 2 = 0 . 1 1 6 7 .$

Note, however, that the mean squared error is computed differently in R. We can compare these values with the periodogram:

$$
> \operatorname {a b s} (\operatorname {f f t} (x)) ^ {\wedge} 2 / 5
$$

[1] 64.8000000 5.4832816 0.1167184 0.1167184 5.4832816

The first value here is $I ( 0 ) = n \bar { X } _ { n } ^ { 2 } = 5 * ( 1 8 / 5 ) ^ { 2 } = 6 4 . 8 .$ . The second and third value are $I ( 1 / 5 )$ and $I ( 2 / 5 )$ , respectively, while $I ( 3 / 5 )$ $= I ( 2 / 5 )$ and $I ( 4 / 5 ) = I ( 1 / 5 )$ complete the list.

In the next section, some large sample properties of the periodogram are discussed to get a better understanding of spectral analysis. \

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

This page titled 4.2: The Spectral Density and the Periodogram is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 4.3: Large Sample Properties

Let $( X _ { t } { : } t \in \mathbb { Z } )$ be a weakly stationary time series with mean $\pmb { \mu }$ , absolutely summable ACVF $\gamma ( h )$ and spectral density $\pmb { f } ( \omega )$ . Proceeding as in the proof of Proposition4.2.2., one obtains

$$
I \left(\omega_ {j}\right) = \frac {1}{n} \sum_ {h = - n + 1} ^ {n - 1} \sum_ {t = 1} ^ {n - | h |} \left(X _ {t + | h |} - \mu\right) \left(X _ {t} - \mu\right) \exp (- 2 \pi i \omega_ {j} h), \tag {4.3.1}
$$

provided $\omega _ { j } \neq 0$ . Using this representation, the limiting behavior of the periodogram can be established.

# Proposition 4.3.1

Let $I ( \cdot )$ be the periodogram based on observations $X _ { 1 } , \ldots , X _ { n }$ of a weakly stationary process $( X _ { t } ; t \in \mathbb { Z } )$ , then, for any $\omega \neq 0$ ,

$$
E [ I (\omega_ {j: n}) ] \rightarrow f (\omega) \quad (n \rightarrow \infty),
$$

$$
(n \to \infty),
$$

where $\omega _ { j : n } = j _ { n } / n$ with $( j _ { n } ) _ { n \in \mathbb { N } }$ chosen such that $\omega _ { j : n }  \omega$ as $\pmb { n }  \infty$ . If $\omega = 0$ , then

$$
E [ I (0) ] - n \mu^ {2} \rightarrow f (0) \quad (n \rightarrow \infty).
$$

Proof. There are two limits involved in the computations of the periodogram mean. First, take the limit as $\pmb { n }  \infty$ . This, however, requires secondly that for each $\pmb { n }$ we have to work with a different set of Fourier frequencies. To adjust for this, we have introduced the notation $\omega _ { j : n }$ . If $\omega _ { j } \neq 0$ is a Fourier frequency $\mathbf { \gamma } _ { \pmb { n } }$ fixed!), then

$$
E [ I (\omega_ {j}) ] = \sum_ {h = - n + 1} ^ {n - 1} \left(\frac {n - | h |}{n}\right) \gamma (h) \exp (- 2 \pi i \omega_ {j} h).
$$

Therefore $( n  \infty !$ ),

$$
E [ I (\omega_ {j: n}) ] \rightarrow \sum_ {h = - \infty} ^ {\infty} \gamma (h) \exp (- 2 \pi i \omega h) = f (\omega),
$$

thus proving the first claim. The second follows from $I ( 0 ) = n \bar { X } _ { n } ^ { 2 }$ (see Proposition 4.2.2.), so that $E [ I ( 0 ) ] - n \mu ^ { 2 } = n ( E [ \bar { X } _ { n } ^ { 2 } ] - \mu ^ { 2 } )$ $= n \mathrm { { V a r } } ( { \bar { X } } _ { n } ) \to f ( 0 )$ as $\pmb { n }  \infty$ as in Chapter 2. The proof is complete.

Proposition 4.3.1. shows that the periodogram $\scriptstyle { I ( \omega ) }$ is asymptotically unbiased for $\pmb { f } ( \omega )$ . It is, however, inconsistent. This is implied by the following proposition which is given without proof. It is not surprising considering that each value $I ( \omega _ { j } )$ is the sum of squares of only two random variables irrespective of the sample size.

# Proposition 4.3.2.

If $( X _ { t } ; t \in \mathbb { Z } )$ is a (causal or noncausal) weakly stationary time series such that

$$
X _ {t} = \sum_ {j = - \infty} ^ {\infty} \psi_ {j} Z _ {t - j}, \qquad t \in \mathbb {Z},
$$

![](images/414cac7cea0f8ba891183fdf16b25525a1e0ec1f768841269dc7b2c6e998a8f4.jpg)

with $\begin{array} { r } { \sum _ { j = - \infty } ^ { \infty } | \psi _ { j } | < \infty a n d ( Z _ { t } ) _ { t \in \mathbb { Z } } \sim \mathbb { W N } ( 0 , \sigma ^ { 2 } ) } \end{array}$ , then

$$
\left(\frac {2 I \left(\omega_ {1 : n}\right)}{f \left(\omega_ {1}\right)}, \dots , \frac {2 I \left(\omega_ {m : n}\right)}{f \left(\omega_ {m}\right)}\right) \xrightarrow {\mathcal {D}} \left(\xi_ {1}, \dots , \xi_ {m}\right),
$$

where $\omega _ { 1 } , \ldots , \omega _ { m }$ are $\textbf { ‰}$ distinct frequencies with $\omega _ { j : n }  \omega _ { j }$ and $f ( \omega _ { j } ) > 0$ . The variables $\xi _ { 1 } , \ldots , \xi _ { m }$ are independent, identical chisquared distributed with two degrees of freedom.

The result of this proposition can be used to construct confidence intervals for the value of the spectral density at frequency $\omega .$ . To this end, denote by $\chi _ { 2 } ^ { 2 } ( \alpha )$ the lower tail probability of the chi-squared variable $\xi _ { j } ,$ that is,

$$
P \left(\xi_ {j} \leq \chi_ {2} ^ {2} (\alpha)\right) = \alpha .
$$

Then, Proposition 4.3.2. implies that an approximate confidence interval with level ${ \bf 1 } - \alpha$ is given by

$$
\frac {2 I (\omega_ {j : n})}{\chi_ {2} ^ {2} (1 - \alpha / 2)} \leq f (\omega) \leq \frac {2 I (\omega_ {j : n})}{\chi_ {2} ^ {2} (\alpha / 2)}.
$$

Proposition 4.3.2. also suggests that confidence intervals can be derived simultaneously for several frequency components. Before confidence intervals are computed for the dominant frequency of the recruitment data return for a moment to the computation of the FFT which is the basis for the periodogram usage. To ensure a quick computation time, highly composite integers $\pmb { n } ^ { \prime }$ have to be used. To achieve this in general, the length of time series is adjusted by padding the original but detrended data by adding zeroes. In R, spectral analysis is performed with the function spec.pgram. To find out which $\$ 123,45$ is used for your particular data, type nextn(length(x)), assuming that your series is in x.

![](images/52568584935f175104ec53ec4248f1cf0b10f5954c1ad502eadc70ae2bdbdb04.jpg)  
Figure 4.6: Averaged periodogram of the recruitment data discussed in Example 4.3.1.

# Example 4.3.1.

Figure 4.5 displays the periodogram of the recruitment data which has been discussed in Example 3.3.5. It shows a strong annual frequency component at $\omega = 1 / 1 2$ as well as several spikes in the neighborhood of the El Ni o frequency $\omega = 1 / 4 8$ . Higher frequency components with $\omega > . 3$ are virtually absent. Even though an AR(2) model was fitted to this data in Chapter 3 to produce future values based on this fit, it is seen that the periodogram here does not validate this fit as the spectral density of an AR(2) process (as computed in Example 4.2.3.) is qualitatively different. In R, the following commands can be used (nextn(length(rec)) gives $\pmb { n } ^ { \prime } = 4 8 0$ here if the recruitment data is stored in rec as before).

```txt
>rec.pgram=spec.pgram(rec, taper=0, log="no")  
>abline(v=1/12, lty=2)  
>abline(v=1/48, lty=2) 
```

The function spec.pgram allows you to fine-tune the spectral analysis. For our purposes, we always use the specifications given above for the raw periodogram (taper allows you, for example, to exclusively look at a particular frequency band, log allows you to plot the log-periodogram and is the R standard).

To compute the confidence intervals for the two dominating frequencies and , you can use the following R code, noting that $1 / 1 2 = 4 0 / 4 8 0$ and $1 / 4 8 = 1 0 / 4 8 0$ .

```txt
>rec.pgram{\}spec[40]  
[1] 21332.94  
>rec.pgram{\}spec[10]  
[1] 14368.42 
```

```javascript
>u=qchisq(.025, 2); l=qchisq(.975, 2)
>2*rec.pgram${}spec[40]/1
>2*rec.pgram${}spec[40]/u
>2*rec.pgram${}spec[10]/1
~2*rec.pgram${}spec[10]/u 
```

Using the numerical values of this analysis, the following confidence intervals are obtained at the level $\pmb { \alpha } = . 1$ :

$f(1 / 12)\in (5783.041,842606.2)$ and $f(1 / 48)\in (3895.065,567522.5).$

These are much too wide and alternatives to the raw periodogram are needed. These are provided, for example, by a smoothing approach which uses an averaging procedure over a band of neighboring frequencies. This can be done as follows.

```txt
> k=kernel("daniell",4)  
> rec.ave=spec.pgram(rec, k, taper=0, log="no")  
> abline(v=1/12, lty=2)  
> abline(v=1/48, lty=2)  
> rec.ave$bandwidth  
[1] 0.005412659\medskip 
```

The resulting smoothed periodogram is shown in Figure 4.6. It is less noisy, as is expected from taking averages. More precisely, a two-sided Daniell filter with $\pmb { m } = 4$ was used here with $L = 2 m + 1$ neighboring frequencies

$\omega_{k} = \omega_{j} + \frac{k}{n},\qquad k = -m,\ldots ,m,$

to compute the periodogram at $\omega _ { j } = j / n$ . The resulting plot in Figure 4.6 shows, on the other hand, that the sharp annual peak has been flattened considerably. The bandwidth reported in R can be computed as $b = L / ( { \sqrt { 1 2 } } n )$ . To compute confidence intervals one has to adjust the previously derived formula. This is done by taking changing the degrees of freedom from 2 to $d f = 2 L n / n ^ { \prime }$ (if the zeroes where appended) and leads to

$\frac{df}{\chi_{df}^{2}(1 - \alpha / 2)}\sum_{k = -m}^{m}f(\omega_{j} + \frac{k}{n})\leq f(\omega)\leq \frac{df}{\chi_{df}^{2}(\alpha / 2)}\sum_{k = -m}^{m}f(\omega_{j} + \frac{k}{n})$

for $\omega \approx \omega _ { j }$ . For the recruitment data the following R code can be used:

```txt
>df=ceiling(rec.ave{\}df)  
>u=qchisq(.025,df), l~=~qchisq(.975,df)  
>df*rec.ave{\}spec[40]/1  
>df*rec.ave{\}spec[40]/u  
>df*rec.ave{\}spec[10]/1  
>df*rec.ave{\}spec[10]/u 
```

![](images/25a416a49bfd5c8257c6e9ba8f8b2fadd7f80c57b4dfdd98a4c211f840f210b1.jpg)  
Figure 4.7: The modified Daniell periodogram of the recruitment data discussed in Example 4.3.1.

to get the confidence intervals

$$
f (1 / 1 2) \in (1 4 8 2. 4 2 7, 5 9 1 6. 8 2 3) \quad \text {a n d} \quad f (1 / 4 8) \in (4 4 5 2. 5 8 3, 1 7 7 7 1. 6 4).
$$

The compromise between the noisy raw periodogram and further smoothing as described here (with $\pmb { L } = \pmb { 9 }$ ) reverses the magnitude of the $\mathbf { 1 } / \mathbf { 1 2 }$ annual frequency and the El Ni o component. This is due to the fact that the annual peak is a very sharp one, with neighboring frequencies being basically zero. For the component, there are is a whole band of neighboring frequency which also contribute the El Ni o phenomenon is irregular and does only on average appear every four years). Moreover, the annual cycle is now distributed over a whole range. One way around this issue is provided by the use of other kernels such as the modified Daniell kernel given in R as kernel("modified.daniell", c(3,3)). This leads to the spectral density in Figure 4.7.

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

Demo: I really love the way that Equation looks.

This page titled 4.3: Large Sample Properties is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 4.4: Linear Filtering

A linear filter uses specific coefficients $( \psi _ { s } ; s \in \mathbb { Z } )$ , called the impulse response function, to transform a weakly stationary input series $( X _ { t } { : } t \in \mathbb { Z } )$ into an output series $( Y _ { t } ; t \in \mathbb { Z } )$ via

$$
Y _ {t} = \sum_ {s = - \infty} ^ {\infty} \psi_ {s} X _ {t - s}, \qquad t \in \mathbb {Z},
$$

where $\scriptstyle \sum _ { s = - \infty } ^ { \infty } | \psi _ { s } | < \infty$ . Then, the frequency response function

$$
\Psi (\omega) = \sum_ {s = - \infty} ^ {\infty} \psi_ {s} \exp (- 2 \pi i \omega s)
$$

is well defined. Note that the two-point moving average of Example 4.2.2 and the differenced sequence $\nabla X _ { t }$ are examples of linear filters. On the other hand, any \/ causal ARMA process can be identified as a linear filter applied to a white noise sequence. Implicitly this concept was already used to compute the spectral densities in Exampels 4.2.2 and 4.2.3. To investigate this in further detail, let $\gamma _ { X } ( h )$ and $\gamma _ { Y } ( h )$ denote the ACVF of the input process $( X _ { t } { : } t \in \mathbb { Z } )$ and the output process $( Y _ { t } ; t \in \mathbb { Z } )$ , respectively, and denote by ${ f } _ { X } ( \omega )$ and ${ f } _ { Y } ( \omega )$ the corresponding spectral densities. The following is the main result in this section.

# Theorem 4.4.1.

Under the assumptions made in this section, it holds that $f _ { Y } ( \omega ) = | \Psi ( \omega ) | ^ { 2 } f _ { X } ( \omega )$ .

Proof. First note that

$$
\begin{array}{l} \gamma_ {Y} (h) = E \left[ \left(Y _ {t + h} - \mu_ {Y}\right) \left(Y _ {t} - \mu_ {Y}\right) \right] \\ = \sum_ {r = - \infty} ^ {\infty} \sum_ {s = - \infty} ^ {\infty} \psi_ {r} \psi_ {s} \gamma (h - r + s) \\ = \sum_ {r = - \infty} ^ {\infty} \sum_ {s = - \infty} ^ {\infty} \psi_ {r} \psi_ {s} \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega (h - r + s)) f _ {X} (\omega) d \omega \\ = \int_ {- 1 / 2} ^ {1 / 2} \left(\sum_ {r = - \infty} ^ {\infty} \psi_ {r} \exp (- 2 \pi i \omega r)\right) \left(\sum_ {s = - \infty} ^ {\infty} \psi_ {s} \exp (2 \pi i \omega s)\right) \exp (2 \pi i \omega h) f _ {X} (\omega) d \omega \\ = \int_ {- 1 / 2} ^ {1 / 2} \exp (2 \pi i \omega h) | \Psi (\omega) | ^ {2} f _ {X} (\omega) d \omega . \\ \end{array}
$$

Now identify $f _ { Y } ( \omega ) = | \Psi ( \omega ) | ^ { 2 } f _ { X } ( \omega )$ , which is the assertion of the theorem.

Theorem 4.4.1 suggests a way to compute the spectral density of a causal ARMA process. To this end, let $( Y _ { t } ; t \in \mathbb { Z } )$ be such a causal ARMA $( p , q )$ process satisfying $Y _ { t } = \psi ( B ) Z _ { t }$ , where $( Z _ { t } \colon t \in \mathbb { Z } ) \sim \mathbf { W N } ( 0 , \sigma ^ { 2 } )$ and

$$
\psi (z) = \frac {\theta (z)}{\phi (z)} = \sum_ {s = 0} ^ {\infty} \psi_ {s} z ^ {s}, \qquad | z | \leq 1.
$$

with $\pmb \theta ( z )$ and $\phi ( z )$ being the moving average and autoregressive polynomial, respectively. Note that the $\left( \psi _ { s } \colon s \in \mathbb { N } _ { 0 } \right)$ can be viewed as a special impulse response function.

# Corollary 4.4.1.

If $( Y _ { t } ; t \in \mathbb { Z } )$ be a causal ARMA $( p , q ) \backslash$ ) process. Then, its spectral density is given by

$$
f _ {Y} (\omega) = \sigma^ {2} \frac {\left| \theta \left(e ^ {- 2 \pi i \omega}\right) \right| ^ {2}}{\left| \phi \left(e ^ {- 2 \pi i \omega}\right) \right| ^ {2}}.
$$

Proof. Apply Theorem 4.4.1 with input sequence $( Z _ { t } ; t \in \mathbb { Z } )$ . Then $f _ { Z } ( \omega ) = \sigma ^ { 2 }$ , and moreover the frequency response function is

$$
\Psi (\omega) = \sum_ {s = 0} ^ {\infty} \psi_ {s} \exp (- 2 \pi i \omega s) = \psi (e ^ {- 2 \pi i \omega}) = \frac {\theta (e ^ {- 2 \pi i \omega})}{\phi (e ^ {- 2 \pi i \omega})}.
$$

Since $f _ { Y } ( \omega ) = | \Psi ( \omega ) | ^ { 2 } f _ { X } ( \omega )$ , the proof is complete.

Corollary 4.4.1 gives an easy approach to define parametric spectral density estimates for causal ARMA(p,q) processes by simply replacing the population quantities by appropriate sample counterparts. This gives the spectral density estimator

$$
\hat {f} (\omega) = \hat {\sigma} _ {n} ^ {2} \frac {| \hat {\theta} (e ^ {- 2 \pi i \omega}) | ^ {2}}{| \hat {\phi} (e ^ {- 2 \pi i \omega}) | ^ {2}}.
$$

Now any of the estimation techniques discussed in Section 3.5 may be applied when computing $\hat { f } ( \omega )$

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

This page titled 4.4: Linear Filtering is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# 4.5: Summary

In this chapter, the basic methods for frequency domain time series analysis were introduced. These are based on a regression of the given data on cosine and sine functions varying at the Fourier frequencies. On the population side, spectral densities were identified as the frequency domain counterparts of absolutely summable autocovariance functions. These are obtained from one another by the application of (inverse) Fourier transforms. On the sample side, the periodogram has been shown to be an estimator for the unknown spectral density. Since it is an inconsistent estimator, various techniques have been discussed to overcome this fact. Finally, linear filters were introduced which can, for example, be used to compute spectral densities of causal ARMA processes and to derive parametric spectral density estimators other than the periodogram.

# Contributers

Alexander Aue (Department of Statistics, University of California, Davis)   
Integrated by Brett Nakano (statistics, UC Davis)

This page titled 4.5: Summary is shared under a not declared license and was authored, remixed, and/or curated by Alexander Aue.

# Index

# A

# ARMA

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes

# ARMA Processes

3: ARMA Processes

# asymptotic unbiasedness

2.2: Estimation of the Autocovariance Function

# autocovariance function

2.2: Estimation of the Autocovariance Function

# autoregressive moving average time series

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes

# autoregressive polynomial

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes

# B

# BEST LINEAR PREDICTION

3.4: Forecasting

# C

causality

3.2: Causality and Invertibility

# F

# forecasting

3.4: Forecasting

# I

# Invertibility

3.2: Causality and Invertibility

# L

# linear filtering

4.4: Linear Filtering

# M

# method of moments

3.5: Parameter Estimation

# moving average polynomial

3.1: Introduction to Autoregressive Moving Average (ARMA) Processes

# P

# partial autocorrelation function

3.3: The PACF of a Causal ARMA Process

# periodogram

4.2: The Spectral Density and the Periodogram

# S

# spectral density

4.2: The Spectral Density and the Periodogram

# stochastic process

1.1: Introduction and Examples

# Glossary

Sample Word 1 | Sample Definition 1

# Detailed Licensing

Loading...

# Applied Time Series Analysis

# SS 2015

# Dr. Marcel Dettling

Institute for Data Analysis and Process Design

Zurich University of Applied Sciences

CH-8401 Winterthur

# Table of Contents

# 1 INTRODUCTION 1

1.1 PURPOSE 1   
1.2 EXAMPLES 2   
1.3 GOALS IN TIME SERIES ANALYSIS 8

# 2 MATHEMATICAL CONCEPTS 11

2.1 DEFINITION OF A TIME SERIES 11   
2.2 STATIONARITY 11   
2.3 TESTING STATIONARITY 13

# 3 TIME SERIES IN R 15

3.1 TIME SERIES CLASSES 15   
3.2 DATES AND TIMES IN R 17   
3.3 DATA IMPORT 21

# 4 DESCRIPTIVE ANALYSIS 23

4.1 VISUALIZATION 23   
4.2 TRANSFORMATIONS 26   
4.3 DECOMPOSITION 27   
4.4 AUTOCORRELATION 46   
4.5 PARTIAL AUTOCORRELATION 60

# 5 STATIONARY TIME SERIES MODELS 63

5.1 WHITE NOISE 63   
5.2 ESTIMATING THE CONDITIONAL MEAN 64   
5.3 AUTOREGRESSIVE MODELS 65   
5.4 MOVING AVERAGE MODELS 79   
5.5 ARMA(P,Q) MODELS 87

# 6 SARIMA AND GARCH MODELS 91

6.1 ARIMA MODELS 91   
6.2 SARIMA MODELS 94   
6.3 ARCH/GARCH MODELS 98

# 7 TIME SERIES REGRESSION 103

7.1 WHAT IS THE PROBLEM? 103   
7.2 FINDING CORRELATED ERRORS 107   
7.3 COCHRANE‐ORCUTT METHOD 114

7.4 GENERALIZED LEAST SQUARES 115  
7.5 MISSING PREDICTOR VARIABLES 121

8 FORECASTING 127

8.1 FORECASTING ARMA 128   
8.2 ARIMA/SARIMA 134   
8.3 EXPONENTIAL SMOOTHING 135  
8.4 FORECASTING DECOMPOSED SERIES 142

9 MULTIVARIATE TIME SERIES ANALYSIS 147

9.1 PRACTICAL EXAMPLE 147   
9.2 CROSS CORRELATION 151   
9.3 PREWHITENING 154   
9.4 TRANSFER FUNCTION MODELS 156

10 SPECTRAL ANALYSIS 161

10.1 DECOMPOSING IN THE FREQUENCY DOMAIN 161   
11 STATE SPACE MODELS 167

11.1 STATE SPACE FORMULATION 167   
11.2 AR PROCESSES WITH MEASUREMENT NOISE 168   
11.3 DYNAMIC LINEAR MODELS 171

# 1 Introduction

# 1.1 Purpose

Time series data, i.e. records which are measured sequentially over time, are extremely common. They arise in virtually every application field, such as e.g.:

Business

Sales figures, production numbers, customer frequencies, ...

 Economics

Stock prices, exchange rates, interest rates, ...

 Official Statistics

Census data, personal expenditures, road casualties, ...

 Natural Sciences

Population sizes, sunspot activity, chemical process data, ...

Environmetrics

Precipitation, temperature or pollution recordings, ...

In contrast to basic data analysis where the assumption of identically and independently distributed data is key, time series are serially correlated. The purpose of time series analysis is to visualize and understand these dependences in past data, and to exploit them for forecasting future values. While some simple descriptive techniques do often considerably enhance the understanding of the data, a full analysis usually involves modeling the stochastic mechanism that is assumed to be the generator of the observed time series.

![](images/447081b87aed2e001d9b274a33e74eb6d90adb0de374149a26edca9c9df5bc28.jpg)

Once a good model is found and fitted to data, the analyst can use that model to forecast future values and produce prediction intervals, or he can generate simulations, for example to guide planning decisions. Moreover, fitted models are used as a basis for statistical tests: they allow determining whether fluctuations in monthly sales provide evidence of some underlying change, or whether they are still within the range of usual random variation.

The dominant main features of many time series are trend and seasonal variation. These can either be modeled deterministically by mathematical functions of time, or are estimated using non-parametric smoothing approaches. Yet another key feature of most time series is that adjacent observations tend to be correlated, i.e. serially dependent. Much of the methodology in time series analysis is aimed at explaining this correlation using appropriate statistical models.

While the theory on mathematically oriented time series analysis is vast and may be studied without necessarily fitting any models to data, the focus of our course will be applied and directed towards data analysis. We study some basic properties of time series processes and models, but mostly focus on how to visualize and describe time series data, on how to fit models to data correctly, on how to generate forecasts, and on how to adequately draw conclusions from the output that was produced.

# 1.2 Examples

# 1.2.1 Air Passenger Bookings

The numbers of international passenger bookings (in thousands) per month on an airline (PanAm) in the United States were obtained from the Federal Aviation Administration for the period 1949-1960. The company used the data to predict future demand before ordering new aircraft and training aircrew. The data are available as a time series in R. Here, we here show how to access them, and how to first gain an impression.

$>$ data(AirPassengers)   
$>$ AirPassengers

<table><tr><td></td><td>Jan</td><td>Feb</td><td>Mar</td><td>Apr</td><td>May</td><td>Jun</td><td>Jul</td><td>Aug</td><td>Sep</td><td>Oct</td><td>Nov</td><td>Dec</td></tr><tr><td>1949</td><td>112</td><td>118</td><td>132</td><td>129</td><td>121</td><td>135</td><td>148</td><td>148</td><td>136</td><td>119</td><td>104</td><td>118</td></tr><tr><td>1950</td><td>115</td><td>126</td><td>141</td><td>135</td><td>125</td><td>149</td><td>170</td><td>170</td><td>158</td><td>133</td><td>114</td><td>140</td></tr><tr><td>1951</td><td>145</td><td>150</td><td>178</td><td>163</td><td>172</td><td>178</td><td>199</td><td>199</td><td>184</td><td>162</td><td>146</td><td>166</td></tr><tr><td>1952</td><td>171</td><td>180</td><td>193</td><td>181</td><td>183</td><td>218</td><td>230</td><td>242</td><td>209</td><td>191</td><td>172</td><td>194</td></tr><tr><td>1953</td><td>196</td><td>196</td><td>236</td><td>235</td><td>229</td><td>243</td><td>264</td><td>272</td><td>237</td><td>211</td><td>180</td><td>201</td></tr><tr><td>1954</td><td>204</td><td>188</td><td>235</td><td>227</td><td>234</td><td>264</td><td>302</td><td>293</td><td>259</td><td>229</td><td>203</td><td>229</td></tr><tr><td>1955</td><td>242</td><td>233</td><td>267</td><td>269</td><td>270</td><td>315</td><td>364</td><td>347</td><td>312</td><td>274</td><td>237</td><td>278</td></tr><tr><td>1956</td><td>284</td><td>277</td><td>317</td><td>313</td><td>318</td><td>374</td><td>413</td><td>405</td><td>355</td><td>306</td><td>271</td><td>306</td></tr><tr><td>1957</td><td>315</td><td>301</td><td>356</td><td>348</td><td>355</td><td>422</td><td>465</td><td>467</td><td>404</td><td>347</td><td>305</td><td>336</td></tr><tr><td>1958</td><td>340</td><td>318</td><td>362</td><td>348</td><td>363</td><td>435</td><td>491</td><td>505</td><td>404</td><td>359</td><td>310</td><td>337</td></tr><tr><td>1959</td><td>360</td><td>342</td><td>406</td><td>396</td><td>420</td><td>472</td><td>548</td><td>559</td><td>463</td><td>407</td><td>362</td><td>405</td></tr><tr><td>1960</td><td>417</td><td>391</td><td>419</td><td>461</td><td>472</td><td>535</td><td>622</td><td>606</td><td>508</td><td>461</td><td>390</td><td>432</td></tr></table>

Some further information about this dataset can be obtained by typing ?AirPassengers in R. The data are stored in an R-object of class ts, which is the specific class for time series data. However, for further details on how time series are handled in R, we refer to section 3.

One of the most important steps in time series analysis is to visualize the data, i.e. create a time series plot, where the air passenger bookings are plotted versus the time of booking. For a time series object, this can be done very simply in R, using the generic plot function:

> plot(AirPassengers, ylab $=$ "Pax", main ${ \bf \Phi } = { \bf \Phi }$ "Passenger Bookings")

The result is displayed on the next page. There are a number of features in the plot which are common to many time series. For example, it is apparent that the number of passengers travelling on the airline is increasing with time. In general, a systematic change in the mean level of a time series that does not appear to be periodic is known as a trend. The simplest model for a trend is a linear increase or decrease, an often adequate approximation. We will discuss how to estimate trends, and how to decompose time series into trend and other components in section 4.3.

The data also show a repeating pattern within each year, i.e. in summer, there are always more passengers than in winter. This is known as a seasonal effect, or seasonality. Please note that this term is applied more generally to any repeating pattern over a fixed period, such as for example restaurant bookings on different days of week.

![](images/7602bd2d73eee74aa505a12aa27b85c4a36b686a1382e03aadaeb80a53c17009.jpg)

We can naturally attribute the increasing trend of the series to causes such as rising prosperity, greater availability of aircraft, cheaper flights and increasing population. The seasonal variation coincides strongly with vacation periods. For this reason, we here consider both trend and seasonal variation as deterministic

components. As mentioned before, section 4.3 discusses visualization and estimation of these components, while in section 7, time series regression models will be specified to allow for underlying causes like these, and finally section 8 discusses exploiting these for predictive purposes.

# 1.2.2 Lynx Trappings

The next series which we consider here is the annual number of lynx trappings for the years 1821-1934 in the Mackenzie River District in Canada. We again load the data and visualize them using a time series plot:

> data(lynx)   
> plot(lynx, ylab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "# of Lynx Trapped", main ${ \bf \Phi } = { \bf \Phi }$ "Lynx Trappings")

The plot on the next page shows that the number of trapped lynx reaches high and low values every about 10 years, and some even larger figure every about 40 years. While biologists often approach such data with predator-prey-models, we here focus on the analysis of the time signal only. This suggests that the prominent periodicity is to be interpreted as random, but not deterministic.

![](images/a59b0e53d631bffe166030db6a99dd35f2aad3a649f5288e58cca3b465da995f.jpg)

This leads us to the heart of time series analysis: while understanding and modeling trend and seasonal variation is a very important aspect, much of the time series methodology is aimed at stationary series, i.e. data which do not show deterministic, but only random (cyclic) variation.

![](images/12f26c9114877a1a2c0921d580fbda79210e768e4e747a6412ce0f9f9ed21072.jpg)

![](images/c635896ba6190e623410ade602af62228b9c5e421d5cdc964afe883fa3a0983f.jpg)

![](images/c9002ab1880bfc97ac8a277c8866f20fa0c19a86205568b87614c4096fbfd153.jpg)

# 1.2.3 Luteinizing Hormone Measurements

One of the key features of the above lynx trappings series is that the observations apparently do not stem from independent and identically distributed (iid) random variables, but there is some serial correlation. If the previous value was high (or low, respectively), the next one is likely to be similar to the previous one. To explore, model and exploit such dependence lies at the root of time series analysis. We here show another series, where 48 luteinizing hormone levels were recorded from blood samples that were taken at 10 minute intervals from a human female. This hormone, also called lutropin, triggers ovulation.

```txt
> data(lh)  
> lh  
Time Series:  
Start = 1; End = 48; Frequency = 1  
[1] 2.4 2.4 2.4 2.2 2.1 1.5 2.3 2.3 2.5 2.0 1.9 1.7 2.2 1.8  
[15] 3.2 3.2 2.7 2.2 2.2 1.9 1.9 1.8 2.7 3.0 2.3 2.0 2.0 2.9  
[29] 2.9 2.7 2.7 2.3 2.6 2.4 1.8 1.7 1.5 1.4 2.1 3.3 3.5 3.5  
[43] 3.1 2.6 2.1 3.4 3.0 2.9 
```

Again, the data themselves are of course needed to perform analyses, but provide little overview. We can improve this by generating a time series plot:

```txt
> plot(lh, ylab="LH level", main="Luteinizing Hormone") 
```

![](images/b3181b1fa51b5654d02dc0ffb2a47c288539fb52fa5f3c8f3839ab83d48e968b.jpg)

For this series, given the way the measurements were made (i.e. 10 minute intervals), we can almost certainly exclude any deterministic seasonal pattern. But is there any stochastic cyclic behavior? This question is more difficult to answer. Normally, one resorts to the simpler question of analyzing the correlation of subsequent records, called autocorrelations. The autocorrelation for lag 1 can be visualized by producing a scatterplot of adjacent observations:

> plot(lh[1:47], lh[2:48], pch=20) > title("Scatterplot of LH Data with Lag 1")

![](images/121c7986d89181e25833c3d62a41011beb271c2c6c07006be281203e80fcbafc.jpg)  
Scatterplot of LH Data with Lag 1

Besides the (non-standard) observation that there seems to be an inhomogeneity, i.e. two distinct groups of data points, it is apparent that there is a positive correlation between successive measurements. This manifests itself with the clearly visible fact that if the previous observation was above or below the mean, the next one is more likely to be on the same side. We can even compute the value of the Pearson correlation coefficient:

> cor(lh[1:47], lh[2:48]) [1] 0.5807322

Its value of 0.58 is an estimate for the so-called autocorrelation coefficient at lag 1. As we will see in section 4.4, the idea of considering lagged scatterplots and computing Pearson correlation coefficients serves as a good proxy for a mathematically more sound method. We also note that despite the positive correlation of $+ 0 . 5 8$ , the series seems to always have the possibility of “reverting to the other side of the mean”, a property which is common to stationary series – an issue that will be discussed in section 2.2.

# 1.2.4 Swiss Market Index

The SMI is the blue chip index of the Swiss stock market. It summarizes the value of the shares of the 20 most important companies, and currently contains nearly $90 \%$ of the total market capitalization. It was introduced on July 1, 1988 at a basis level of 1500.00 points. Daily closing data for 1860 consecutive trading days from 1991-1998 are available in R. We observe a more than 4-fold increase during that period. As a side note, the value in February 2015 is around 8400 points, indicating a sidewards movement over the latest 15 years.

```txt
> data(EuStockMarkets)  
> EuStockMarkets  
Time Series:  
Start = c(1991, 130)  
End = c(1998, 169)  
Frequency = 260  
DAX SMI CAC FTSE  
1991.496 1628.75 1678.1 1772.8 2443.6  
1991.500 1613.63 1688.5 1750.5 2460.2  
1991.504 1606.51 1678.6 1718.0 2448.2  
1991.508 1621.04 1684.1 1708.1 2470.4  
1991.512 1618.16 1686.6 1723.1 2484.7  
1991.515 1610.61 1671.6 1714.3 2466.8 
```

As we can see, EuStockMarkets is a multiple time series object, which also contains data from the German DAX, the French CAC and UK’s FTSE. We will focus on the SMI and thus extract and plot the series:

```r
esm <- EuStockMarkets
tmp <- EuStockMarkets[,2]
smi <- ts(tmp, start=start(ism), freq=frequency(ism))
plot(smi, main="SMI Daily Closing Value") 
```

Because subsetting from a multiple time series object results in a vector, but not a time series object, we need to regenerate a latter one, sharing the arguments of the original. In the plot we clearly observe that the series has a trend, i.e. the mean is obviously non-constant over time. This is typical for all financial time series.

![](images/9718eb17f8b2b80e945374567b0f65be7f171104cefaef055c25872f5e50e65f.jpg)  
SMI Daily Closing Value

Such trends in financial time series are nearly impossible to predict, and difficult to characterize mathematically. We will not embark in this, but analyze the so-called log-returns, i.e. the day-to-day changes after a log-transformation of the series:

```txt
> lret.smi <- diff(log(smi))
> plot(lret.smi, main="SMI Log-Returns")
```

![](images/dc3e7794e316fccac83564538b3acbd9e2ba6aa5104ea9fa09ca142881eedab9.jpg)  
SMI Log-Returns

These log-returns are a close approximation to the relative change (percent values) with respect to the previous day. As can be seen above, they do not exhibit a trend anymore, but show some of the stylized facts that most log-returns of financial time series share. Using lagged scatterplots or the correlogram (to be discussed later in section 4.4), you can convince yourself that there is no serial correlation. Thus, there is no dependency which could be exploited to predict tomorrows return based on the one of today and/or previous days.

However, it is visible that large changes, i.e. log-returns with high absolute values, imply that future log-returns tend to be larger than normal, too. This feature is also known as volatility clustering, and financial service providers are trying their best to exploit this property to make profit. Again, you can convince yourself of the volatility clustering effect by taking the squared log-returns and analyzing their serial correlation, which is different from zero.

# 1.3 Goals in Time Series Analysis

A first impression of the purpose and goals in time series analysis could be gained from the previous examples. We conclude this introductory section by explicitly summarizing the most important goals.

# 1.3.1 Exploratory Analysis

Exploratory analysis for time series mainly involves visualization with time series plots, decomposition of the series into deterministic and stochastic parts, and studying the dependency structure in the data.

# 1.3.2 Modeling

The formulation of a stochastic model, as it is for example also done in regression, can and does often lead to a deeper understanding of the series. The formulation of a suitable model usually arises from a mixture between background knowledge in the applied field, and insight from exploratory analysis. Once a suitable model is found, a central issue remains, i.e. the estimation of the parameters, and subsequent model diagnostics and evaluation.

# 1.3.3 Forecasting

An often-heard motivation for time series analysis is the prediction of future observations in the series. This is an ambitious goal, because time series forecasting relies on extrapolation, and is generally based on the assumption that past and present characteristics of the series continue. It seems obvious that good forecasting results require a very good comprehension of a series’ properties, be it in a more descriptive sense, or in the sense of a fitted model.

# 1.3.4 Time Series Regression

Rather than just forecasting by extrapolation, we can try to understand the relation between a so-identified response time series, and one or more explanatory series. If all of these are observed at the same time, we can in principle employ the ordinary least squares (OLS) regression framework. However, the all-to-common assumption of (serially) uncorrelated errors in OLS is usually violated in a time series setup. We will illustrate how to properly deal with this situation, in order to generate correct confidence and prediction intervals.

# 1.3.5 Process Control

Many production or other processes are measured quantitatively for the purpose of optimal management and quality control. This usually results in time series data, to which a stochastic model is fit. This allows understanding the signal in the data, but also the noise: it becomes feasible to monitor which fluctuations in the production are normal, and which ones require intervention.

# 2 Mathematical Concepts

For performing anything else than very basic exploratory time series analysis, even from a much applied perspective, it is necessary to introduce the mathematical notion of what a time series is, and to study some basic probabilistic properties, namely the moments and the concept of stationarity.

# 2.1 Definition of a Time Series

As we have explained in section 1.2, observations that have been collected over fixed sampling intervals form a time series. Following a statistical approach, we consider such series as realizations of random variables. A sequence of random variables, defined at such fixed sampling intervals, is sometimes referred to as a discrete-time stochastic process, though the shorter names time series model or time series process are more popular and will mostly be used in this scriptum. It is very important to make the distinction between a time series, i.e. observed values, and a process, i.e. a probabilistic construct.

Definition: A time series process is a set of random variables $\left\{ X _ { t } , t \in T \right\}$ , where T is the set of times at which the process was, will or can be observed. We assume that each random variable $X _ { t }$ is distributed according some univariate distribution function $F _ { t }$ . Please note that for our entire course and hence scriptum, we exclusively consider time series processes with equidistant time intervals, as well as real-valued random variables $X _ { t }$ . This allows us to enumerate the set of times, so that we can write $T = \{ 1 , 2 , 3 , \ldots \}$ .

An observed time series, on the other hand, is seen as a realization of the random vector $X = ( X _ { 1 } , X _ { 2 } , . . . , X _ { n } )$ , and is denoted with small letters $x = ( x _ { 1 } , x _ { 2 } , . . . , x _ { n } )$ . It is important to note that in a multivariate sense, a time series is only one single realization of the $n$ -dimensional random variable $X$ , with its multivariate, $n$ -dimensional distribution function $F _ { 1 : n }$ . As we all know, we cannot do statistics with just a single observation. As a way out of this situation, we need to impose some conditions on the joint distribution function $F _ { 1 : n }$ .

# 2.2 Stationarity

The aforementioned condition on the joint distribution $F _ { 1 : n }$ will be formulated as the concept of stationarity. In colloquial language, stationarity means that the probabilistic character of the series must not change over time, i.e. that any section of the time series is “typical” for every other section with the same length. More mathematically, we require that for any indices $s , t$ and $k$ , the observations $x _ { t } , . . . , x _ { t + k }$ could have just as easily occurred at times $s , . . . , s + k$ . If that is not the case practically, then the series is hardly stationary.

Imposing even more mathematical rigor, we introduce the concept of strict stationarity. A time series is said to be strictly stationary if and only if the $( k + 1 )$ -dimensional joint distribution of $X _ { { t } } , . . . , X _ { { t } + k }$ coincides with the joint distribution of $X _ { s } , . . . , X _ { s + k }$ for any combination of indices t, $s$ and $k$ . For the special case of $k = 0$ and $t = s$ , this means that the univariate distributions $F _ { t }$ of all $X _ { t }$ are equal. For strictly stationary time series, we can thus leave off the index t on the distribution. As the next step, we will define the unconditional moments:

Expectation

Variance 2 

Covariance

In other words, strictly stationary series have constant (unconditional) expectation, constant (unconditional) variance , and the covariance, i.e. the dependency structure, depends only on the lag $h$ , which is the time difference between the two observations. However, the covariance terms are generally different from 0, and thus, the $X _ { t }$ are usually dependent. Moreover, the conditional expectation given the past of the series, $E [ X _ { t } | X _ { t - 1 } , X _ { t - 2 } , . . . ]$ is typically non-constant, denoted as $\mu _ { t }$ . In some (rarer, e.g. for financial time series) cases, even the conditional variance $V a r ( X _ { t } | X _ { t - 1 } , X _ { t - 2 } , \ldots )$ can be non-constant.

In practice however, except for simulation studies, we usually have no explicit knowledge of the latent time series process. Since strict stationarity is defined as a property of the process’ joint distributions (all of them), it is impossible to verify from an observed time series, i.e. a single data realization. We can, however, try to verify whether a time series process shows constant unconditional mean and variance, and whether the dependency only depends on the lag h. This much less rigorous property is known as weak stationarity.

In order to do well-founded statistical analyses with time series, weak stationarity is a necessary condition. It is obvious that if a series’ observations do not have common properties such as constant mean/variance and a stable dependency structure, it will be impossible to statistically learn from it. On the other hand, it can be shown that weak stationarity, along with the additional property of ergodicity (i.e. the mean of a time series realization converges to the expected value, independent of the starting point), is sufficient for most practical purposes such as model fitting, forecasting, etc.. We will, however, not further embark in this subject.

# Remarks:

From now on, when we speak of stationarity, we strictly mean weak stationarity. The motivation is that weak stationarity is sufficient for applied time series analysis, and strict stationarity is a practically useless concept.   
When we analyze time series data, we need to verify whether it might have arisen from a stationary process or not. Be careful with the wording: stationarity is always a property of the process, and never of the data.

Moreover, bear in mind that stationarity is a hypothesis, which needs to be evaluated for every series. We may be able to reject this hypothesis with quite some certainty if the data strongly speak against it. However, we can never prove stationarity with data. At best, it is plausible that a series originated from a stationary process.

Some obvious violations of stationarity are trends, non-constant variance, deterministic seasonal variation, as well as apparent breaks in the data, which are indicators for changing dependency structure.

# 2.3 Testing Stationarity

If, as explained above, stationarity is a hypothesis which is tested on data, students and users keep asking if there are any formal tests. The answer to this question is yes, and there are even quite a number of tests. This includes the Augmented Dickey-Fuller Test, the Phillips-Perron Test, the KPSS Test, which are all available in R’s tseries package. The urca package includes further tests such as the Elliott-Rothenberg-Stock, Schmidt-Phillips und Zivot-Andrews.

However, we will not discuss any of these tests here for a variety of reasons. First and foremost, they all focus on some very specific non-stationarity aspects, but do not test stationarity in a broad sense. While they may reasonably do their job in the narrow field they are aimed for, they have low power to detect general nonstationarity and in practice often fail to do so. Additionally, theory and formalism of these tests is quite complex, and thus beyond the scope of this course. In summary, these tests are to be seen as more of a pasttime for the mathematically interested, rather than a useful tool for the practitioner.

Thus, we here recommend assessing stationarity by visual inspection. The primary tool for this is the time series plot, but also the correlogram (see section 4.4) can be helpful as a second check. For long time series, it can also be useful to split up the series into several parts for checking whether mean, variance and dependency are similar over the blocks.

# 3 Time Series in R

# 3.1 Time Series Classes

In R, there are objects, which are organized in a large number of classes. These classes e.g. include vectors, data frames, model output, functions, and many more. Not surprisingly, there are also several classes for time series. We start by presenting ts, the basic class for regularly spaced time series. This class is comparably simple, as it can only represent time series with fixed interval records, and only uses numeric time stamps, i.e. (sophistically) enumerates the index set. However, it will be sufficient for most, if not all, of what we do in this course. Then, we also provide an outlook to more complicated concepts.

# 3.1.1 The ts Class

For defining a time series of class ts, we of course need to provide the data, but also the starting time as argument start, and the frequency of measurements as argument frequency. If no starting time is supplied, R uses its default value of 1, i.e. enumerates the times by the index set $1 , . . . , n$ , where $n$ is the length of the series. The frequency is the number of observations per unit of time, e.g. 1 for yearly, 4 for quarterly, or 12 for monthly recordings. Instead of the start, we could also provide the end of the series, and instead of the frequency, we could supply argument deltat, the fraction of the sampling period between successive observations. The following example will illustrate the concept.

Example: We here consider a simple and short series that holds the number of days per year with traffic holdups in front of the Gotthard road tunnel north entrance in Switzerland. The data are available from the Federal Roads Office.

<table><tr><td>2004</td><td>2005</td><td>2006</td><td>2007</td><td>2008</td><td>2009</td><td>2010</td><td>2011</td><td>2012</td><td>2013</td></tr><tr><td>88</td><td>76</td><td>112</td><td>109</td><td>91</td><td>98</td><td>139</td><td>150</td><td>168</td><td>149</td></tr></table>

The start of this series is in 2004. The time unit is years, and since we have just one record per year, the frequency of this series is 1. This tells us that while there may be a trend, there cannot be a seasonal effect, as the latter can only be present in periodic series, i.e. series with frequency $> 1$ . We now define a ts object in in R.

$>$ rawdat <- c(88, 76, 112, 109, 91, 98, 139, 150, 168, 149)

$>$ ts.dat <- ts(rawdat, start $= 2 0 0 4$ , freq $: = 1$ )

$>$ ts.dat

Time Series: Start = 2004, End = 2013

Frequency $\ c = \ 1$

[1] 88 76 112 109 91 98 139 150 168 149

There are a number of simple but useful functions that extract basic information from objects of class ts, see the following examples:

```matlab
> start(ts.dat)  
[1] 2004 1  
> end(ts.dat)  
[1] 2013 1  
> frequency(ts.dat)  
[1] 1  
> deltat(ts.dat)  
[1] 1 
```

Another possibility is to obtain the measurement times from a time series object. As class ts only enumerates the times, they are given as fractions. This can still be very useful for specialized plots, etc.

```txt
> time(ts.dat)  
Time Series:  
Start = 2004  
End = 2013  
Frequency = 1  
[1] 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 
```

The next basic, but for practical purposes very useful function is window(). It is aimed at selecting a subset from a time series. Of course, also regular Rsubsetting such as ts.dat[2:5] does work with the time series class. However, this results in a vector rather than a time series object, and is thus mostly of less use than the window() command.

```txt
> window(ts.dat, start=2006, end=2008)  
Time Series:  
Start = 2006  
End = 2008  
Frequency = 1  
[1] 112 109 91 
```

While we here presented the most important basic methods/functions for class ts, there is a wealth of further ones. This includes the plot() function, and many more, e.g. for estimating trends, seasonal effects and dependency structure, for fitting time series models and generating forecasts. We will present them in the forthcoming chapters of this scriptum.

To conclude the previous example, we will not do without showing the time series plot of the Gotthard road tunnel traffic holdup days, see next page. Because there are a limited number of observations, it is difficult to give statements regarding a possible trend and/or stochastic dependency.

```python
> plot(ts.dat, ylab="# of Days", main="Traffic Holdups")
```

![](images/eb2d6193b1b128839d25c88678d6d5ffbff5fc37794caf94a7ddcd630aaf87d1.jpg)

# 3.1.2 Other Classes

Besides the basic ts class, there are several more which offer a variety of additional options, but will rarely to never be required during our course. Most prominently, this includes the zoo package, which provides infrastructure for both regularly and irregularly spaced time series using arbitrary classes for the time stamps. It is designed to be as consistent as possible with the ts class. Coercion from and to zoo is also readily available.

Some further packages which contain classes and methods for time series include xts, its, tseries, fts, timeSeries and tis. Additional information on their content and philosophy can be found on CRAN.

# 3.2 Dates and Times in R

While for the ts class, the handling of times has been solved very simply and easily by enumerating, doing time series analysis in R may sometimes also require to explicitly working with date and time. There are several options for dealing with date and date/time data. The built-in as.Date() function handles dates that come without times. The contributed package chron handles dates and times, but does not control for different time zones, whereas the sophisticated but complex POSIXct and POSIXlt classes allow for dates and times with time zone control.

As a general rule for date/time data in R, we suggest to use the simplest technique possible. Thus, for date only data, as.Date() will mostly be the optimal choice. If handling dates and times, but without time-zone information, is required, the chron package is the choice. The POSIX classes are especially useful in the relatively rare cases when time-zone manipulation is important.

Apart for the POSIXlt class, dates/times are internally stored as the number of days or seconds from some reference date. These dates/times thus generally have a numeric mode. The POSIXlt class, on the other hand, stores date/time values as a list of components (hour, min, sec, mon, etc.), making it easy to extract these parts. Also the current date is accessible by typing Sys.Date() in the console, and returns an object of class Date.

# 3.2.1 The Date Class

As mentioned above, the easiest solution for specifying days in R is with the as.Date() function. Using the format argument, arbitrary date formats can be read. The default, however, is four-digit year, followed by month and then day, separated by dashes or slashes:

```txt
> as.Date("2012-02-14")
[1] "2012-02-14"
> as.Date("2012/02/07")
[1] "2012-02-07" 
```

If the dates come in non-standard appearance, we require defining their format using some codes. While the most important ones are shown below, we reference to the R help file of function strptime() for the full list.

```matlab
Code Value
%d Day of the month (decimal number)
%m Month (decimal number)
%b Month (character, abbreviated)
%B Month (character, full name)
%y Year (decimal, two digit)
%Y Year (decimal, four digit) 
```

The following examples illustrate the use of the format argument:

```txt
> as.Date("27.01.12", format=%d.%m.%y")
[1] "2012-01-27"
> as.Date("14. Februar, 2012", format=%d.%B, %Y")
[1] "2012-02-14" 
```

Internally, Date objects are stored as the number of days passed since the $1 ^ { \mathsf { s t } }$ of January in 1970. Earlier dates receive negative numbers. By using the as.numeric() function, we can easily find out how many days are past since the reference date. Also back-conversion from a number of past days to a date is straightforward:

```diff
> mydat <- as.Date("2012-02-14")
> ndays <- as.numeric(mydat)
> ndays
[1] 15384 
```

```txt
> tdays <- 10000  
> class(tdays) <- "Date"  
> tdays  
[1] "1997-05-19" 
```

A very useful feature is the possibility of extracting weekdays, months and quarters from Date objects, see the examples below. This information can be converted to factors. In this form, they serve for purposes such as visualization, decomposition, or time series regression.

```txt
> weekdays (mydat)  
[1] "Dienstag"  
> months (mydat)  
[1] "Februar"  
> quarters (mydat)  
[1] "Q1" 
```

Furthermore, some very useful summary statistics can be generated from Date objects: median, mean, min, max, range, ... are all available. We can even subtract two dates, which results in a difftime object, i.e. the time difference in days.

```txt
> dat <- as.Date(c("2000-01-01","2004-04-04","2007-08-09"))  
> dat  
[1] "2000-01-01" "2004-04-04" "2007-08-09"  
> min(dsat)  
[1] "2000-01-01"  
> max(dsat)  
[1] "2007-08-09"  
> mean(dsat)  
[1] "2003-12-15"  
> median(dsat)  
[1] "2004-04-04"  
> dat[3]-dat[1]  
Time difference of 2777 days 
```

Another option is generating time sequences. For example, to generate a vector of 12 dates, starting on August 3, 1985, with an interval of one single day between them, we simply type:

```html
> seq(as.Date("1985-08-03"), by="days", length=12)  
[1] "1985-08-03" "1985-08-04" "1985-08-05" "1985-08-06"  
[5] "1985-08-07" "1985-08-08" "1985-08-09" "1985-08-10"  
[9] "1985-08-11" "1985-08-12" "1985-08-13" "1985-08-14" 
```

The by argument proves to be very useful. We can supply various units of time, and even place an integer in front of it. This allows creating a sequence of dates separated by two weeks:

```txt
> seq(as.Date("1992-04-17"), by="2 weeks", length=12)  
[1] "1992-04-17" "1992-05-01" "1992-05-15" "1992-05-29"  
[5] "1992-06-12" "1992-06-26" "1992-07-10" "1992-07-24"  
[9] "1992-08-07" "1992-08-21" "1992-09-04" "1992-09-18" 
```

# 3.2.2 The chron Package

The chron() function converts dates and times to chron objects. The dates and times are provided separately to the chron() function, which may well require some inital pre-processing. For such parsing, R-functions such as substr() and strsplit() can be of great use. In the chron package, there is no support for time zones and daylight savings time, and chron objects are internally stored as fractional days since the reference date of January 1st, 1970. By using the function as.numeric(), these internal values can be accessed. The following example illustrates the use of chron:

```txt
> library(char)  
> dat <- c("2007-06-09 16:43:20", "2007-08-29 07:22:40", "2007-10-21 16:48:40", "2007-12-17 11:18:50")  
> dts <- substr(da, 1, 10)  
> tme <- substr(da, 12, 19)  
> fmt <- c("y-m-d","h:m:s")  
> cdt <- chron(dates=dsts, time=tme, format=fmt)  
> cdt  
[1] (07-06-09 16:43:20) (07-08-29 07:22:40)  
[3] (07-10-21 16:48:40) (07-12-17 11:18:50) 
```

As before, we can again use the entire palette of summary statistic functions. Of some special interest are time differences, which can now be obtained as either fraction of days, or in weeks, hours, minutes, seconds, etc.:

```txt
> cdt[2]-cdt[1]  
Time in days:  
[1] 80.61065  
> difftime(cdt[2], cdt[1], units="secs")  
Time difference of 6964760 secs 
```

# 3.2.3 POSIX Classes

The two classes POSIXct and POSIXlt implement date/time information, and in contrast to the chron package, also support time zones and daylight savings time. We recommend utilizing this functionality only when urgently needed, because the handling requires quite some care, and may on top of that be system dependent. Further details on the use of the POSIX classes can be found on CRAN.

As explained above, the POSIXct class also stores dates/times with respect to the internal reference, whereas the POSIXlt class stores them as a list of components (hour, min, sec, mon, etc.), making it easy to extract these parts.

# 3.3 Data Import

We can safely assume that most time series data are already present in electronic form; however, not necessarily in R. Thus, some knowledge on how to import data into R is required. It is be beyond the scope of this scriptum to present the uncounted options which exist for this task. Hence, we will restrict ourselves to providing a short overview and some useful hints.

The most common form for sharing time series data are certainly spreadsheets, or in particular, Microsoft Excel files. While library(ROBDC) offers functionality to directly import data from Excel files, we discourage its use. First of all, this only works on Windows systems. More importantly, it is usually simpler, quicker and more flexible to export comma- or tab-separated text files from Excel, and import them via the ubiquitous read.table() function, respectively the tailored version read.csv() (for comma separation) and read.delim() (for tab separation).

With packages ROBDC and RMySQL, R can also communicate with SQL databases, which is the method of choice for large scale problems. Furthermore, after loading library(foreign), it is also possible to read files from Stata, SPSS, Octave and SAS.

# 4 Descriptive Analysis

As always when working with data, i.e. “a pile of numbers”, it is important to gain an overview. In time series analysis, this encompasses several aspects:

 understanding the context of the problem and the data source   
 making suitable plots, looking for general structure and outliers   
 thinking about data transformations, e.g. to reduce skewness   
 judging stationarity and potentially achieve it by decomposition   
 for stationary series, the analysis of the autocorrelation function

We start by discussing time series plots, then discuss transformations, focus on the decomposition of time series into trend, seasonal effect and stationary random part and conclude by discussing methods for visualizing the dependency structure.

# 4.1 Visualization

# 4.1.1 Time Series Plot

The most important means of visualization is the time series plot, where the data are plotted versus time/index. There are several examples in section 1.2, where we also got acquainted with R’s generic plot() function. As a general rule, the data points are joined by lines in time series plots. This is despite the data are not continuous, as the plots are much easier to read in this form. The only exception where gaps are left is if there are missing values. Moreover, the reader expects that the axes are well-chosen, labeled and the measurement units are given.

Another issue is the correct aspect ratio for time series plots: if the time axis gets too much compressed, it can become difficult to recognize the behavior of a series. Thus, we recommend choosing the aspect ratio appropriately. However, there are no hard and simple rules on how to do this. As a rule of the thumb, use the “banking to 45 degrees” paradigm: increase and decrease in periodic series should not be displayed at angles much higher or lower than 45 degrees. For very long series, this can become difficult on either A4 paper or a computer screen. In this case, we recommend splitting up the series and display it in different frames. For illustration, we here show an example, the monthly unemployment rate in the US state of Maine, from January 1996 until August 2006. The data are available from a text file on the web. We can read it directly into R, define the data as an object of class ts and then do the time series plot:

$>$ www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"   
$>$ dat <- read.table(paste(www,"Maine.dat",sep="", header $\mathrel { \mathop : } \mathrm { = } \mathrm { T }$   
$>$ tsd <- ts(dat, start $= _ { \mathsf { C } }$ (1996,1), freq=12)   
$>$ plot(tsd, ylab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "(%)", main ${ \bf \Phi } = { \bf \Phi }$ "Unemployment in Maine")

![](images/38817f70d9c42c2f69063036c742710e00de3a58ec66aa991e8f6e35288768aa.jpg)  
Unemployment in Maine

Not surprisingly for monthly economic data, the series shows both a non-linear trend and a seasonal pattern that increases with the level of the series. Since unemployment rates are one of the main economic indicators used by politicians/decision makers, this series poses a worthwhile forecasting problem.

# 4.1.2 Multiple Time Series Plots

In applied problems, one is sometimes provided with multiple time series. Here, we illustrate some basics on import, definition and plotting. Our example exhibits the monthly supply of electricity (millions of kWh), beer (millions of liters) and chocolate-based production (tonnes) in Australia over the period from January 1958 to December 1990. These data are available from the Bureau of Australian Statistics and are, in pre-processed form, accessible as a text-file online.

$>$ www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"   
$>$ dat <- read.table(paste(www,"cbe.dat",sep $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "", header $\cdot = \mathrm { T }$ )   
$>$ tsd <- ts(dat, start=1958, freq $= 1 2$ )   
$>$ plot(tsd, main ${ \bf \Phi } = { \bf \Phi }$ "Chocolate, Beer & Electricity")

All three series show a distinct seasonal pattern, along with a trend. It is also instructive to know that the Australian population increased by a factor of 1.8 during the period where these three series were observed. As visible in the bit of code above, plotting multiple series into different panels is straightforward. As a general rule, using different frames for multiple series is the most recommended means of visualization. However, sometimes it can be more instructive to have them in the same frame. Of course, this requires that the series are either on the same scale, or have been indexed, resp. standardized to be so. Then, we can simply use plot(ind.tsd, plot.type $=$ "single"). When working with one single panel, we recommend to use different colors for the series, which is easily possible using a $\mathtt { C O 1 } { = } \mathtt { C }$ ("green3", "red3", "blue3") argument.

![](images/39f896efd39914c14b946124dfa80e9cdaca05f632f31af2a6397a403c128721.jpg)  
Chocolate, Beer & Electricity

## Indexing the series

tsd[,1] <- tsd[,1]/tsd[1,1]*100

tsd[,2] <- tsd[,2]/tsd[1,2]*100

tsd[,3] <- tsd[,3]/tsd[1,3]*100

## Plotting in one single frame

clr <- c("green3", "red3", "blue3")

plot(tsd, plot.type $=$ "single", ylab $=$ "Index", col=clr)

title("Indexed Chocolate, Beer & Electricity")

## Legend

ltxt <- names(dat)

legend("topleft", lty=1, col=clr, legend=ltxt)

![](images/4af204418b8732a163daa19261b882a8a683371a2b54ab5ea2581017e2254cee.jpg)  
Indexed Chocolate, Beer & Electricity

In the indexed single frame plot above, we can very well judge the relative development of the series over time. Due to different scaling, this was nearly impossible with the multiple frames on the previous page. We observe that electricity production increased around 8x during 1958 and 1990, whereas for chocolate the multiplier is around 4x, and for beer less than 2x. Also, the seasonal variation is most pronounced for chocolate, followed by electricity and then beer.

# 4.2 Transformations

Many popular time series models and most estimators (i.e. mean, variance, and correlation) are based and most efficient with Gaussian distribution and linear relations between the variables. However, data may exhibit different behavior. In such cases, we can often improve the fit by not using the original data $x _ { 1 } , . . . , x _ { n }$ , but a transformed version $g ( x _ { 1 } ) { , } . . . , g ( x _ { n } )$ . The most popular and practically relevant transformation is $g \left( \cdot \right) = \log ( \cdot )$ . It is indicated if either the variation in the series grows with increasing mean, or if the marginal distribution appears to be rightskewed. Both properties often appear in data that can take positive values only, such as the lynx trappings from section 1.2.2. It is easy to spot right-skewness by histograms and QQ-plots:

$>$ hist(lynx, col="lightblue")   
$>$ qqnorm(lynx, pch $_ { = 2 0 }$ ); qqline(lynx, col $=$ "blue")

![](images/da166e1868fe3b13ab2ccb13af0873b6373d8c3e510343d0a2b61f35c8162677.jpg)  
Histogram of lynx

![](images/e270b336c3eb850fefbfeff508c75708424fadd9701384dcc2aa240962b0485d.jpg)  
Normal Q-Q Plot

The lynx data show very strong right-skewness and hence, a log-transformation is recommended. Of course, it was not wrong to use the original scale for a time series plot, but when it comes to estimating autocorrelations or estimating models, it is clearly better to log-transform the data first. This is very easy in R:

> plot(log(lynx))   
$>$ title("Logged Lynx Trappings")

![](images/4fbb04cc49ea8b3d558b025d40ce909e228c2d7a4f4735dedcbf51cfc285e3f6.jpg)

The data now follow a more symmetrical pattern; the extreme upward spikes are all gone. We will use these transformed data to determine the autocorrelation and to generate forecasts. However, please be aware of the fact that backtransforming fitted or predicted (model) values to the original scale by just taking exp( ) usually leads to biased results, unless a correction factor is used. An indepth discussion of that issue is contained in chapter 8.

# 4.3 Decomposition

# 4.3.1 The Basics

We have learned in section 2.2 that stationarity is an important prerequisite for being able to statistically learn from time series data. However, many of the example series exhibit either trend and/or seasonal effect, and thus are nonstationary. In this section, we will learn how to deal with that. It is achieved by using decomposition models, the easiest of which is the simple additive one:

$$
X _ {t} = m _ {t} + s _ {t} + R _ {t},
$$

where $X _ { t }$ is the time series process at time t , $m _ { t }$ is the trend, $s _ { t }$ is the seasonal effect, and $R _ { t }$ is the remainder, i.e. a sequence of usually correlated random variables with mean zero. The goal is to find a decomposition such that $R _ { t }$ is a stationary time series. Such a model might be suitable for all the monthly-data series we got acquainted with so far: air passenger bookings, unemployment in Maine and Australian production. However, closer inspection of all these series exhibits that the seasonal effect and the random variation increase as the trend increases. In such cases, a multiplicative decomposition model is better:

$$
X _ {t} = m _ {t} \cdot s _ {t} \cdot R _ {t}
$$

Empirical experience says that taking logarithms is beneficial for such data. Also, some basic math shows that this brings us back to the additive case:

$$
\log \left(X _ {t}\right) = \log \left(m _ {t} \cdot s _ {t} \cdot R _ {t}\right) = \log \left(m _ {t}\right) + \log \left(s _ {t}\right) + \log \left(R _ {t}\right) = m _ {t} ^ {\prime} + s _ {t} ^ {\prime} + R _ {t} ^ {\prime}
$$

For illustration, we carry out the log-transformation on the air passenger bookings:

$$
> \text {p l o t} (\log (\text {A i r P a s s e n g e r s}), \text {y l a b} = ^ {\prime \prime} \log (\text {P a x}) ^ {\prime \prime}, \text {m a i n} = \dots)
$$

![](images/a1dd1eae91056761f2b5a9d3acd06e1b2ac7d075bf0ac0cc23dea52eaa7721f8.jpg)  
Logged Passenger Bookings

Indeed, seasonal effect and random variation now seem to be independent of the level of the series. Thus, the multiplicative model is much more appropriate than the additive one. However, a further snag is that the seasonal effect seems to alter over time rather than being constant. That issue will be addressed later.

# 4.3.2 Differencing

A simple approach for removing deterministic trends and/or seasonal effects from a time series is by taking differences. A practical interpretation of taking differences is that by doing so, the changes in the data will be monitored, but no longer the series itself. While this is conceptually simple and quick to implement, the main disadvantage is that it does not result in explicit estimates of the trend component $m _ { t }$ , the seasonal component $s _ { t }$ nor the remainder $R _ { t }$ .

We will first turn our attention to series with an additive trend, but without seasonal variation. By taking first-order differences with lag 1, and assuming a trend with little short-term changes, i.e. $m _ { t } \approx m _ { t - 1 }$ , we have:

$$
\begin{array}{l} X _ {t} = m _ {t} + R _ {t} \\ Y _ {t} = X _ {t} - X _ {t - 1} \approx R _ {t} - R _ {t - 1} \\ \end{array}
$$

In practice, this kind of differencing approach “mostly works”, i.e. manages to reduce presence of a trend in the series in a satisfactory manner. However, the trend is only fully removed if it is exactly linear, i.e. $m _ { t } = \alpha + \beta t$ . Then, we obtain:

$$
Y _ {t} = X _ {t} - X _ {t - 1} = \beta + R _ {t} - R _ {t - 1}
$$

Another somewhat disturbing property of the differencing approach is that strong, artificial new dependencies are created, meaning that the autocorrelation in $Y _ { { t } }$ is different from the one in $R _ { t }$ . For illustration, consider a stochastically independent remainder $R _ { t }$ : the differenced process $Y _ { t }$ has autocorrelation!

$$
\begin{array}{l} C o v (Y _ {t}, Y _ {t - 1}) \approx C o v (R _ {t} - R _ {t - 1}, R _ {t - 1} - R _ {t - 2}) \\ = - C o v (R _ {t - 1}, R _ {t - 1}) \\ \neq 0 \\ \end{array}
$$

We illustrate how differencing works by using a dataset that shows the traffic development on Swiss roads. The data are available from the federal road office (ASTRA) and show the indexed traffic amount from 1990-2010. We type in the values and plot the original series:

```txt
> SwissTraffic <- ts(c(100.0, 102.7, 104.2, 104.6, 106.7, 106.9, 107.6, 109.9, 112.0, 114.3, 117.4, 118.3, 120.9, 123.7, 124.1, 124.6, 125.6, 127.9, 127.4, 130.2, 131.3), start=1990, freq=1)  
> plot(SwissTraffic) 
```

![](images/76b337117c4c5d15dca9c0f6a157066c14f4cc1482916bcbd4fedf01338e520e.jpg)  
Swiss Traffic Index

There is a clear trend, which is close to linear, thus the simple approach should work well here. Taking first-order differences with lag 1 shows the yearly changes in the Swiss Traffic Index, which must now be a stationary series. In R, the job is done with function diff().

>diff(SwissTraffic)   
Time Series:   
Start $= 1991$ End $= 2010$ Frequency $= 1$ [1] 2.7 1.5 0.4 2.1 0.2 0.7 2.3 2.1 2.3 3.1   
[11] 0.9 2.6 2.8 0.4 0.5 1.0 2.3 -0.5 2.8 1.1

![](images/732d1aea7874b116f7802b109808c4b17a6ba0ba588319ff6f9848504be6e388.jpg)  
Differenced Swiss Traffic Index

Please note that the time series of differences is now 1 instance shorter than the original series. The reason is that for the first year, 1990, there is no difference to the previous year available. The differenced series now seems to have a constant mean, i.e. the trend was successfully removed.

# Log-Transformation and Differencing

On a sidenote, we consider a series that was log-transformed first, before firstorder differences with lag 1 were taken. An example is the SMI data that were shown in section 1.2.4. The result is the so-called log return, which is an approximation to the relative change, i.e. the percent in- or decrease with respect to the previous instance. In particular:

$$
Y _ {t} = \log (X _ {t}) - \log (X _ {t - 1}) = \log \left(\frac {X _ {t}}{X _ {t - 1}}\right) = \log \left(\frac {X _ {t} - X _ {t - 1}}{X _ {t - 1}} + 1\right) \approx \frac {X _ {t} - X _ {t - 1}}{X _ {t - 1}}
$$

The approximation of the log return to the relative change is very good for small changes, and becomes a little less precise with larger values. For example, if we have a $0 . 0 0 \%$ relative change, then $Y _ { t } = 0 . 0 0 \%$ , for $1 . 0 0 \%$ relative change we obtain $Y _ { t } = 0 . 9 9 5 \%$ and for $5 . 0 0 \%$ , $Y _ { t } = 4 . 8 8 \%$ . We conclude with summarizing that for any non-stationary series which is also due to a log-transformation, the transformation is always carried out first, and then followed by the differencing!

# The Backshift Operator

We here introduce the backshift operator $B$ because it allows for convenient notation. When the operator $B$ is applied to $X _ { t }$ it returns the instance at lag 1, i.e.

$$
B \left(X _ {t}\right) = X _ {t - 1}.
$$

Less mathematically, we can also say that applying $B$ means “go back one step”, or “increment the time series index $t$ by -1”. The operation of taking first-order differences at lag 1 as above can be written using the backshift operator:

$$
Y _ {t} = (1 - B) X _ {t} = X _ {t} - X _ {t - 1}
$$

However, the main aim of the backshift operator is to deal with more complicated forms of differencing, as will be explained below.

# Higher-Order Differencing

We have seen that taking first-order differences is able to remove linear trends from time series. What has differencing to offer for polynomial trends, i.e. quadratic or cubic ones? We here demonstrate that it is possible to take higher order differences to remove also these, for example, in the case of a quadratic trend.

$$
\begin{array}{l} X _ {t} = \alpha + \beta_ {1} t + \beta_ {2} t ^ {2} + R _ {t}, R _ {t} \text {s t a t i o n a r y} \\ Y _ {t} = (1 - B) ^ {2} X _ {t} \\ = \left(X _ {t} - X _ {t - 1}\right) - \left(X _ {t - 1} - X _ {t - 2}\right) \\ = R _ {t} - 2 R _ {t - 1} + R _ {t - 2} + 2 \beta_ {2} \\ \end{array}
$$

We see that the operator $\left( 1 - B \right) ^ { 2 }$ means that after taking “normal” differences, the resulting series is again differenced “normally”. This is a discretized variant of taking the second derivative, and thus it is not surprising that it manages to remove a quadratic trend from the data. As we can see, $Y _ { { t } }$ is an additive combination of the stationary $R _ { t }$ ’s terms, and thus itself stationary. Again, if $R _ { t }$ was an independent process, that would clearly not hold for $Y _ { { t } }$ , thus taking higher-order differences (strongly!) alters the dependency structure.

Moreover, the extension to cubic trends and even higher orders $d$ is straightforward. We just use the $( 1 - B ) ^ { d }$ operator applied to series $X _ { t }$ . In $\pmb { \mathrm { R } }$ , we can employ function diff(), but have to provide argument difference $\mathsf { \Omega } _ { \mathsf { 3 } } = \mathsf { d }$ for indicating the order of the difference $d$ .

# Removing Seasonal Effects by Differencing

For time series with monthly measurements, seasonal effects are very common. Using an appropriate form of differencing, it is possible to remove these, as well as potential trends. We take first-order differences with lag $p$ :

$$
Y _ {t} = (1 - B ^ {p}) X _ {t} = X _ {t} - X _ {t - p},
$$

Here, $p$ is the period of the seasonal effect, or in other words, the frequency of series, which is the number of measurements per time unit. The series $Y _ { { t } }$ then is made up of the changes compared to the previous period’s value, e.g. the previous year’s value. Also, from the definition, with the same argument as above, it is evident that not only the seasonal variation, but also a strictly linear trend will be removed.

Usually, trends are not exactly linear. We have seen that taking differences at lag 1 removes slowly evolving (non-linear) trends well due to $m _ { t } \approx m _ { t - 1 }$ . However, here the relevant quantities are $m _ { t }$ and $m _ { t - p }$ , and especially if the period $p$ is long, some trend will usually be remaining in the data. Then, further action is required.

# Example

We are illustrating seasonal differencing using the Mauna Loa atmospheric $C O _ { 2 }$ concentration data. This is a time series with monthly records from January 1959 to December 1997. It exhibits both a trend and a distinct seasonal pattern. We first load the data and do a time series plot:

> data(co2)   
> plot(co2, main ${ \bf \Phi } = { \bf \Phi }$ "Mauna Loa CO2 Concentrations")

Seasonal differencing is very conveniently available in R. We use function diff(), but have to set argument lag=.... For the Mauna Loa data with monthly measurements, the correct lag is 12. This results in the series shown on the next page. Because we are comparing every record with the one from the previous year, the resulting series is 12 observations shorter than the original one. It is pretty obvious that some trend is remaining and thus, the result from seasonal differencing cannot be considered as stationary. As the seasonal effect is gone, we could try to add some first-order differencing at lag 1.

![](images/7467d4eea9a815fda5fed1a1082938166b3eec5c1ad046f984dbdc1fadbc5f2a.jpg)  
Mauna Loa CO2 Concentrations

> sd.co2 <- diff(co2, lag=12)   
> plot(sd.co2, main ${ \bf \Phi } = { \bf \Phi }$ "Differenced Mauna Loa Data $\mathtt { p } = \mathtt { 1 } 2$ )")

![](images/dd0e8d44f8b6d7ed30ae3671794740e0509da2daf489deb46c27036ea6f402ee.jpg)  
Differenced Mauna Loa Data $( p = 1 2 )$

The second differencing step indeed managems to produce a stationary series, as can be seen below. The equation for the final series is:

$$
Z _ {t} = (1 - B) Y _ {t} = (1 - B) (1 - B ^ {1 2}) X _ {t}.
$$

The next step would be to analyze the autocorrelation of the series below and fit an $A R M A ( p , q )$ model. Due to the two differencing steps, such constructs are also named SARIMA models. They will be discussed in chapter 6.

![](images/b066c21e60e070ffdabf10d637790839318cf492063afe9c8d5156fc8e0a7702.jpg)  
Twice Differenced Mauna Loa Data $( 1 0 = 1 2 , 1 0 = 1 )$

We conclude this section by emphasizing that while differencing is quick and simple, and (correctly done) manages to remove any trend and/or seasonality, we do not obtain explicit estimates for trend $m _ { t }$ , seasonal effect $s _ { t }$ and remainder $R _ { t }$ which proves problematic in many applications.

# 4.3.3 Smoothing, Filtering

Our next goal is to define a decomposition procedure that yields explicit trend, seasonality and remainder estimates ˆm , $\hat { s } _ { t }$ and $\hat { R } _ { t }$ . In the absence of a seasonal effect, the trend of a time series can simply be obtained by applying an additive linear filter:

$$
\hat {m} _ {t} = \sum_ {i = - p} ^ {q} a _ {i} X _ {t + i}
$$

This definition is general, as it allows for arbitrary weights and asymmetric windows. The most popular implementation, however, relies on $p = q$ and $a _ { i } = 1 / \left( 2 p + 1 \right)$ , i.e. a running mean estimator with symmetric window and uniformly distributed weights. The window width is the smoothing parameter.

# Example: Trend Estimation with Running Mean

We here again consider the Swiss Traffic data that were already exhibited before. They show the indexed traffic development in Switzerland between 1990 and 2010. Linear filtering is available with function filter() in R. With the correct settings, this function becomes a running mean estimator.

> trend.est <- filter(SwissTraffic, filter $= _ { \mathsf { C } }$ (1,1,1)/3)

![](images/2207acdca0ba22d5688af57bcbc5b01ac5aa363bce431679a87bd22848a1aec6.jpg)  
Swiss Traffic Index with Running Mean

> trend.est

<table><tr><td colspan="7">Time Series: Start = 1990, End = 2010, Frequency = 1</td></tr><tr><td>[1]</td><td>NA</td><td>102.3000</td><td>103.8333</td><td>105.1667</td><td>106.0667</td><td>107.0667</td></tr><tr><td>[7]</td><td>108.1333</td><td>109.8333</td><td>112.0667</td><td>114.5667</td><td>116.6667</td><td>118.8667</td></tr><tr><td>[13]</td><td>120.9667</td><td>122.9000</td><td>124.1333</td><td>124.7667</td><td>126.0333</td><td>126.9667</td></tr><tr><td>[19]</td><td>128.5000</td><td>129.6333</td><td></td><td>NA</td><td></td><td></td></tr></table>

In our example, we chose the trend estimate to be the mean over three consecutive observations. This has the consequence that for both the first and the last instance of the time series, no trend estimate is available. Also, it is apparent that the Swiss Traffic series has a very strong trend signal, whereas the remaining stochastic term is comparably small in magnitude. We can now compare the estimated remainder term from the running mean trend estimation to the result from differencing:

![](images/63f7f3c2e411a1d7d4bcfae8671b1f28ae2d5befb20fc0c8507a4fe5f9a21dfd.jpg)  
Estimated Stochastic Remainder Term

The blue line is the remainder estimate from running mean approach, while the grey one resulted from differencing with lag 1. We observe that the latter has bigger variance; and, while there are some similarities between the two series, there are also some prominent differences – please note that while both seem stationary, they are different.

# Trend Estimation for Seasonal Data

We now turn our attention to time series that show both trend and seasonal effect. The goal is to specify a filtering approach that allows trend estimation for periodic data. We still base this on the running mean idea, but have to make sure that we average over a full period. For monthly data, the formula is:

$$
\hat {m} _ {t} = \frac {1}{1 2} \left(\frac {1}{2} X _ {t - 6} + X _ {t - 5} + \dots + X _ {t + 5} + \frac {1}{2} X _ {t + 6}\right), \text {f o r} t = 7, \dots , n - 6
$$

Be careful, as there is a slight snag if the frequency is even: if we estimate the trend for December, we use data from July to May, and then also add half of the value of the previous June, as well as half of the next June. This is required for having a window that is centered at the time we wish to estimate the trend. Using R’s function filter(), with appropriate choice of weights, we can compute the seasonal running mean. We illustrate this with the Mauna Loa $C O _ { 2 }$ data.

```r
> wghts <- c(.5, rep(1, 11), .5)/12  
> trend.est <- filter(co2, filter=wghts, sides=2)  
> plot(co2, main="Mauna Loa CO2 Concentrations")  
> lines(trend.est, col="red") 
```

We obtain a trend which fits well to the data. It is not a linear trend, rather it seems to be slightly progressively increasing, and it has a few kinks, too.

![](images/5b0e6af3cdd20730cb7494c223b619688cc3cff89baf4cf404d1adecd2d83715.jpg)  
Mauna Loa CO2 Concentrations

We finish this section about trend estimation using linear filters by stating that other smoothing approaches, e.g. running median estimation, the loess smoother and many more are valid choices for trend estimation, too.

# Estimation of the Seasonal Effect

For fully decomposing periodic series such as the Mauna Loa data, we also need to estimate the seasonal effect. This is done on the basis of the trend adjusted data: simple averages over all observations from the same seasonal entity are taken. The following formula shows the January effect estimation for the Mauna Loa data, a monthly series which starts in January and has 39 years of data.

$$
\hat {s} _ {J a n} = \hat {s} _ {1} = \hat {s} _ {1 3} = \dots = \frac {1}{3 9} \cdot \sum_ {j = 0} ^ {3 8} \left(x _ {1 2 j + 1} - \hat {m} _ {1 2 j + 1}\right)
$$

In R, a convenient way of estimating such seasonal effects is by generating a factor for the months, and then using the tapply() function. Please note that the seasonal running mean naturally generates NA values at the start and end of the series, which we need to remove in the seasonal averaging process.

```txt
> trend.adj <- co2-trend.est  
> month <- factor(rep(1:12,39))  
> seasn.est <- tapply(trend.adj, month, mean, na.rm=TRUE)  
> plot(seasn.est, type="h", xlab="Month")  
> title("Seasonal Effects for Mauna Loa Data")  
> abline(h=0, col="grey") 
```

![](images/072e45d87549af05c915cf020005b2bc6de8647f383babfdd072e73411196e06.jpg)  
Seasonal Effects for Mauna Loa Data

In the plot above, we observe that during a period, the highest values are usually observed in May, whereas the seasonal low is in October. The estimate for the remainder at time t is simply obtained by subtracting estimated trend and seasonality from the observed value.

$$
\hat {R} _ {t} = x _ {t} - \hat {m} _ {t} - \hat {s} _ {t}
$$

From the plot on the next page, it seems as if the estimated remainder still has some periodicity and thus it is questionable whether it is stationary. The periodicity is due to the fact that the seasonal effect is not constant but slowly evolving over time. In the beginning, we tend to overestimate it for most months, whereas in the end, we underestimate. We will address the issue on how to visualize evolving seasonality below in section 4.3.4 about STL-decomposition. A further option for dealing with non-constant seasonality is given by the exponential smoothing approach which is covered in chapter 8.3.

```txt
> rmain.est <- co2-trend.est-rep(seasn.est,39)  
> plot(rmain.est, main="Estimated Stochastic Remainder Term") 
```

![](images/78d38afb4024641e9bcfd7640bab62334b8bbecd3d46fa09bd058f98eb44734e.jpg)  
Estimated Stochastic Remainder Term

Moreover, we would like to emphasize that R offers the convenient decompose() function for running mean estimation and seasonal averaging.

> co2.dec <- decompose(co2)   
$>$ plot(co2.dec)

![](images/bb8c42995e28a449cc269e63214463fe8696c1b3f9bbede48a5aef7c0d796da4.jpg)  
Decomposition of additive time series

Please note that decompose() only works with periodic series where at least two full periods were observed; else it is not mathematically feasible to estimate trend and seasonality from a series. The decompose() function also offers the neat plotting method shown above that generates the four frames above with the series, and the estimated trend, seasonality and remainder. Except for the different visualization, the results are exactly the same as what we had produced with our do-it-yourself approach.

# 4.3.4 Seasonal-Trend Decomposition with LOESS

It is well known that the running mean is not the best smoother around. Thus, potential for improvement exists. While there is a dedicated R procedure for decomposing periodic series into trend, seasonal effect and remainder, we have to do some handwork in non-periodic cases.

# Trend Estimation with LOESS

We here consider again the Swiss Traffic dataset, for which the trend had already been estimated above. Our goal is to re-estimate the trend with LOESS, a smoothing procedure that is based on local, weighted regression. The aim of the weighting scheme is to reduce potentially disturbing influence of outliers. Applying the LOESS smoother with (the often optimal) default settings is straightforward:

>fit<-loess(SwissTraffic\~time(SwissTraffic)) $>$ trend<-predict(fit)

![](images/2690dd7ec52ab3ce535a3f6bb0e893478bcf1881e5dcbe3a5be1f72604e65edb.jpg)  
Swiss Traffic Index with Running Mean

We observe that the estimated trend, in contrast to the running mean result, is now smooth and allows for interpolation within the observed time. Also, the loess() algorithm returns trend estimates which extend to the boundaries of the dataset. In summary, we recommend to always perform trend estimation with LOESS.

# Using the stl() Procedure for Periodic Series

R’s stl() procedure offers a decomposition of a periodic time series into trend, seasonality and remainder. All estimates are based on the LOESS smoother. While the output is (nearly) equivalent to what we had obtained above with decompose(), we recommend to use this procedure only, because the results are more trustworthy. We do here without giving the full details on the procedure, but only state that it works iteratively. The commands are as follows:

> co2.stl <- stl(co2, s.window $=$ "periodic")   
$>$ plot(co2.stl, main $=$ "STL-Decomposition of CO2 Data")

![](images/24850e994dc3140f994408816399fad2fc1155b310901094385eb9de3dfc1d30.jpg)

The graphical output is similar to the one from decompose() The grey bars on the right hand side facilitate interpretation of the decomposition: they show the relative magnitude of the effects, i.e. cover the same span on the y-scale in all of the frames. The two principal arguments in function stl() are t.window and s.window: t.window controls the amount of smoothing for the trend, and has a default value which often yields good results. The value used can be inferred with:

> co2.stl$win[2]

t

The result is the number of lags used as a window for trend extraction in LOESS. Increasing it means the trend becomes smoother; lowering it makes the trend rougher, but more adapted to the data. The second argument, s.window, controls the smoothing for the seasonal effect. When set to “periodic” as above, the seasonality is obtained as a constant value from simple (monthly) averaging.

However, stl() offers better functionality. If s.window is set to a numeric value, the procedure can accommodate for evolving seasonality. The assumption behind is that the change in the seasonal effect happens slowly and smoothly. We visualize what is meant with the logged air passenger data. For quick illustration, we estimate the trend with a running mean filter; subtract it from the observed series and display all March and all August values of the trend adjusted series:

![](images/06818c1f47bcefba45c49e41123d85f96e1f2f82b0583a38ece5eefbdc53976f.jpg)  
Effect of March

![](images/158ad924fdbc24af02942f4878b00fc05d4a4c66383f626da7eb5889fb2783da.jpg)  
Effect of August

When assuming a non-changing seasonal effect, the standard procedure would be to take the mean of the data points in the above scatterplots and declare that as the seasonal effect for March and August, respectively. This is a rather crude way of data analysis, and can of course be improved. We achieve a better decomposition of the logged air passenger bookings by employing the stl() function and setting s.window ${ \tt r } = 1 3$ . The resulting output is displayed below.

```r
> fit.05 <- stl(lap, swindow= 5)
> fit.13 <- stl(lap, swindow=13)
> plot(fit.13, main="STL-Decomposition ...") 
```

Please note that there is no default value for the seasonal span, and the optimal choice is left to the user upon visual inspection. An excellent means for doing so is the monthplot() function which shows the seasonal effects that were estimated by stl().

```txt
> monthplot(fit.13, main="Monthplot, swindow=13")  
> monthplot(fit.05, main="Monthplot, swindow=5")
```

The output, which can be found on the next page shows an appropriate amount of smoothing in the left panel, with s.window ${ \tt = } 1 3$ . However on the right, with smaller span, i.e. s.window ${ = } 5$ , we observe overfitting – the seasonal effects do not evolve in a smooth way, and it means that this is not a good decomposition estimate.

![](images/975dc375dc1e5a0271729f0285d5fafbc45339df6eba3f0e777af8fdf398bf37.jpg)

![](images/d783423949a3b09c5675a948817421702331e436bb6d6a30738f232fc2a7454f.jpg)

![](images/117e02f73fedcf045738a7a4fc55ba3e051319568948b11c9a7a3817ced0bf5d.jpg)

# 4.3.5 Parametric Modeling

A powerful approach for decomposing time series is parametric modeling. It is based on the assumption of a functional form for the trend, usually a polynomial. For the seasonal effect, we can either use the dummy variable approach that amounts to averaging. Or, in some special cases, a sine/cosine seasonality may be appropriate. We illustrate the parametric modeling approach by two examples and use them for discussing some specifics.

We consider the Maine unemployment data from section 4.1.1. Our goal is to fit a polynomial trend, along with a seasonal effect that is obtained from averaging. We write down this model for a polynomial of grade 4.

$$
X _ {t} = \beta_ {0} + \beta_ {1} \cdot t + \beta_ {2} \cdot t ^ {2} + \beta_ {3} \cdot t ^ {3} + \beta_ {4} \cdot t ^ {4} + \alpha_ {i \langle t \rangle} + E _ {t},,
$$

where $t = 1 , . . . , 1 2 8$ and $i \langle t \rangle { \in } \{ 1 , . . . , 1 2 \}$ , i.e. $\alpha _ { i \langle t \rangle }$ is a factor variable encoding for the month the observation was made in, see the R code below. Two questions immediately pop up, namely what polynomial order is appropriate, and how this model can be fit.

As for the fitting, this will usually be done with the ordinary least squares (OLS) algorithm. This requires some prudence, because when working with time series, the remainder term $E _ { t }$ may not necessarily be stochastically independent. Thus, we might have some violated assumption for the OLS estimation. Since the estimated coefficients are still unbiased, OLS is a valid approach. However, be careful with the standard errors, as well as tests and confidence intervals derived from them, because they can be grossly misleading.

For the grade of the polynomial, we determine by eyeballing from the time series plot that the hypothesized trend in the unemployment series has at least 3 extrema. This means that a polynomial with grade below 4 will not result in a sensible trend estimate. Thus, we try orders 4, 5 and 6, and discuss how an appropriate choice can be made from residual analysis. However, we first focus on the R code for fitting such models. In the first step below, we lay the basics. From time series maine, we extract the times of observation, i.e. the predictor. As always when fitting polynomial regression models, it is crucial to center the xvalues to mitigate potential collinearity among the terms. Furthermore, we define a factor variable for modeling the seasonality.

>maine<- ts(mat,start=c(1996,1)，freq=12) $>$ tr <- as.numeric(time(main)) $>$ tc $<  -$ tr-mean(tr) $>$ mm<- rep(c("Jan","Feb","Mar","Apr","May","Jun", "Jul"，"Aug"，"Sep"，"Oct"，"Nov"，"Dec")) $>$ mm<- factor(rep(mm,11),levels $\equiv$ mm)[1:128]

We can then obtain an OLS-fit of the decomposition model with R’s lm() procedure, as shown below. The I() notation in the formula assures that the “^” are interpreted as arithmetical operators, i.e. powers of the predictor, rather than as formula operators. Thereafter, we can use the estimated coefficients for determining the trend estimate t.est.04. Because the seasonal factor uses the month of January as a reference, and thus generally has a mean different from zero, we need to shift the trend to make run through “the middle of the data”.

```txt
>fit04 <- lm(maine~tc+I(tc^2) + I(tc^3) + I(tc^4) + mm)  
>cf <- coef(fit04)  
> t.est.04 <- cf[1] + cf[2] * tc + cf[3] * tc^2 + cf[4] * tc^3 + cf[5] * tc^4  
> t04.adj <- t.est.04 - mean(t.est.04) + mean(maine) 
```

```txt
> plot(main, ylab="(%)", main="Unemployment in Maine")
> lines(tr, t.04(adj)
```

The time series plot below is enhanced with polynomial trend lines of order 4 (blue), 5 (red) and 6 (green). From this visualization, it is hard to decide which of the polynomials is most appropriate as a trend estimate. Because there are some boundary effects for orders 5 and 6, we might guess that their additional flexibility is not required. As we will see below, this is treacherous.

![](images/d06ce964a2b4fbe714921fe181e8e0563746bae5582c90b6187771480406de8b.jpg)  
Unemployment in Maine

A better way for judging the fit of a parametric model is by residual analysis. We plot the remainder term $\hat { E } _ { { t } }$ versus time and add a LOESS smoother. The following bit of code shows this for the grade 4 polynomial.

```txt
> re.est <- maine-fitted.fit04)  
> plot(re.est, ylab="", main="Residuals vs. Time, O(4)")  
> fit <- loess(re.est~tr)  
> lines(tr, fitted.fit), col="red")  
> abline(h=0, col="grey") 
```

We repeat the procedure for polynomial orders 5 and 6 and display all results on the next page. In the top plot, the remainder term still features a slight trend, owing to a too low polynomial grade. The middle panel looks better, but there is another clear improvement with order 6, which is the best choice for this series. It is also striking that the remainder is not an i.i.d. series, the serial correlation is clearly standing out. Its estimation and visualization will be discussed in the next section. We conclude this chapter on parametric modeling by issuing a warning: while the explicit form of the trend can be useful, it shall never be interpreted as causal for the evolvement of the series. Also, much care needs to be taken if forecasting is the goal. Extrapolating high-order polynomials beyond the range of observed times can yield very poor results. We will discuss some simple methods for trend extrapolation later in section 8 about forecasting.

![](images/3903e5ee3dcc5c2fafd8288aecf78d7ef6f9b99ab15f69a9ffdf660eadc25f09.jpg)  
Residuals vs. Time, O(4)

![](images/83764571318a02f31d463a81d4ee11ec1be2e4fe9fe6673261526df7ac3eacf3.jpg)  
Residuals vs. Time, O(5)

![](images/d74a32321104f1846083371ef782dfa3503d1170c6a45b9f2ae566ab44a35d3c.jpg)  
Residuals vs. Time, O(6)

# 4.4 Autocorrelation

An important feature of time series is their (potential) serial correlation. This section aims at analyzing and visualizing these correlations. We first display the autocorrelation between two random variables $X _ { t + k }$ and $X _ { t }$ , which is defined as:

$$
\operatorname {C o r} \left(X _ {t + k}, X _ {t}\right) = \frac {\operatorname {C o v} \left(X _ {t + k} , X _ {t}\right)}{\sqrt {\operatorname {V a r} \left(X _ {t + k}\right) \operatorname {V a r} \left(X _ {t}\right)}}
$$

This is a dimensionless measure for the linear association between the two random variables. Since for stationary series, we require the moments to be nonchanging over time, we can drop the index t for these, and write the autocorrelation as a function of the lag k :

$$
\rho (k) = \operatorname {C o r} \left(X _ {t + k}, X _ {t}\right)
$$

The goals in the forthcoming sections are estimating these autocorrelations from observed time series data, and to study the estimates’ properties. The latter will prove useful whenever we try to interpret sample autocorrelations in practice.

The example we consider in this chapter is the wave tank data. The values are wave heights in millimeters relative to still water level measured at the center of the tank. The sampling interval is 0.1 seconds and there are 396 observations. For better visualization, we here display the first 60 observations only:

$>$ www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"   
$>$ dat <- read.table(paste(www,"wave.dat",sep="", heade $\underline { { \boldsymbol { \mathbf { \Lambda } } } } = \mathbb { T }$ )   
$>$ wave <- ts(dat$waveht)   
$>$ plot(window(wave, 1, 60), ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-800,800), ylab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "Height")   
$>$ title("Wave Tank Data")

![](images/82ec8ac94ec431ea14129309c8ea17c5afd06d2de8e3669f12f41cf344642e4d.jpg)  
Wave Tank Data

These data show some pronounced cyclic behavior. This does not come as a surprise, as we all know from personal experience that waves do appear in cycles. The series shows some very clear serial dependence, because the current value is quite closely linked to the previous and following ones. But very clearly, it is also a stationary series.

# 4.4.1 Lagged Scatterplot

An appealing idea for analyzing the correlation among consecutive observations in the above series is to produce a scatterplot of $( x _ { t } , x _ { t + 1 } )$ for all $t = 1 , . . . , n - 1$ . There is a designated function lag.plot() in R. The result is as follows:

```txt
> lag.plot(wave, do-lines=FALSE, pch=20)  
> title("Lagged Scatterplot, k=1") 
```

![](images/346e06b5745cefa4679876c78523ef8aff3b5ad14f0dd6ee0023056387edef82.jpg)

The association seems linear and is positive. The Pearson correlation coefficient turns out to be 0.47, thus moderately strong. How to interpret this value from a practical viewpoint? Well, the square of the correlation coefficient, $0 . 4 7 ^ { 2 } = 0 . 2 2$ , is the percentage of variability explained by the linear association between $x _ { t }$ and its respective predecessor. Here in this case, $x _ { t - 1 }$ explains roughly $22 \%$ of the variability observed in $x _ { t }$ .

We can of course extend the very same idea to higher lags. We here analyze the lagged scatterplot correlations for lags $k = 2 , . . . 5$ , see below. When computed, the estimated Pearson correlations turn out to be -0.27, -0.50, -0.39 and -0.22, respectively. The formula for computing them is:

$$
\tilde {\rho} (k) = \frac {\sum_ {s = 1} ^ {n - k} (x _ {s + k} - \overline {{x}} _ {(k)}) (x _ {s} - \overline {{x}} _ {(1)})}{\sqrt {\sum_ {s = k + 1} ^ {n} (x _ {s} - \overline {{x}} _ {(k)}) ^ {2} \cdot \sum_ {t = 1} ^ {n - k} (x _ {t} - \overline {{x}} _ {(1)}) ^ {2}}} \mathrm {f o r} k = 1, \dots , n - 2,
$$

$$
\text {w h e r e} \overline {{x}} _ {(1)} = \frac {1}{n - k} \sum_ {i = 1} ^ {n - k} x _ {i} \text {a n d} \overline {{x}} _ {(k)} = \frac {1}{n - k} \sum_ {i = k + 1} ^ {n} x _ {i}
$$

It is important to notice that while there are $n - 1$ data pairs for computing $\tilde { \rho } ( 1 )$ , there are only $n - 2$ for $\tilde { \rho } ( 2 )$ , and then less and less, i.e. $n - k$ pairs for $\tilde { \rho } ( k )$ . Thus for the last autocorrelation coefficient which can be estimated, $\tilde { \rho } ( n - 2 )$ , there is only one single data pair which is left. Of course, they can always be interconnected by a straight line, and the correlation in this case is always $\pm 1$ . Of course, this is an estimation snag, rather than perfect linear association for the two random variables.

![](images/2911a500103832f4b5a109bf70cf407082122bcc35f6e0cb47e0acd2a8a255a5.jpg)

![](images/1b365a6ebd8750e27f6983143b1949a021950aa0708045ab99e5870b8cd19f7b.jpg)

![](images/f9ebb5d34afc2f1e196b05fb85e876ae6eb4b163ed64df04744a917336fae870.jpg)

![](images/9acd2fd1c892d7b7a24090b3af24b26d2170df6165d2254ab893ed815102c44a.jpg)

Intuitively, it is clear that because there are less and less data pairs at higher lags, the respective estimated correlations are less and less precise. Indeed, by digging deeper in mathematical statistics, one can prove that the variance of $\tilde { \rho } ( k )$ increases with $k$ . This is undesired, as it will lead to instable results and spurious effects. The remedy is discussed in the next section.

# 4.4.2 Plug-In Estimation

For mitigating the above mentioned problem with the lagged scatterplot method, autocorrelation estimation is commonly done using the so-called plug-in approach, using estimated autocovariances as the basis. The formula is as follows:

$$
\hat {\rho} (k) = \frac {\hat {\gamma} (k)}{\hat {\gamma} (0)}, \text {f o r} k = 1, \dots , n - 1,
$$

$$
\text {w h e r e} \hat {\gamma} (k) = \frac {1}{n} \sum_ {s = 1} ^ {n - k} \left(x _ {s + k} - \bar {x}\right) \left(x _ {s} - \bar {x}\right), \text {w i t h} \bar {x} = \frac {1}{n} \sum_ {t = 1} ^ {n} x _ {t}.
$$

Note that here, n is used as a denominator irrespective of the lag and thus the number of summands. This has the consequence that $\hat { \gamma } ( 0 )$ is not an unbiased estimator for $\gamma ( 0 ) = \sigma _ { X } ^ { 2 }$ ，but as explained above, there are good reasons to do so. When plugging in the above terms, the estimate for the $k$ th autocorrelation coefficient turns out to be:

$$
\hat {\rho} (k) = \frac {\sum_ {s = 1} ^ {n - k} \left(x _ {s + k} - \bar {x}\right) \left(x _ {s} - \bar {x}\right)}{\sum_ {t = 1} ^ {n} \left(x _ {t} - \bar {x}\right) ^ {2}}, \text {f o r} k = 1, \dots , n - 1.
$$

It is straightforward to compute these in R, function acf() does the job, and we below do so for the wave tank data. As for the moment, we are interested in the numerical results, we set argument plot $=$ FALSE. However, as we will see below, it is usually better to visualize the estimated autocorrelation coefficients graphically, as it will be explained below in section 4.4.3. Also note that R by default does not return all autocorrelations which are estimable in this series with 396 observations, but only the first 25.

> acf(wave, plot $=$ FALSE)

Autocorrelations of series ‘wave’, by lag

<table><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr><tr><td>1.000</td><td>0.470</td><td>-0.263</td><td>-0.499</td><td>-0.379</td><td>-0.215</td><td>-0.038</td><td>0.178</td></tr><tr><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td></tr><tr><td>0.269</td><td>0.130</td><td>-0.074</td><td>-0.079</td><td>0.029</td><td>0.070</td><td>0.063</td><td>-0.010</td></tr><tr><td>16</td><td>17</td><td>18</td><td>19</td><td>20</td><td>21</td><td>22</td><td>23</td></tr><tr><td>-0.102</td><td>-0.125</td><td>-0.109</td><td>-0.048</td><td>0.077</td><td>0.165</td><td>0.124</td><td>0.049</td></tr><tr><td>24</td><td>25</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>-0.005</td><td>-0.066</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

Next, we compare the autocorrelations from lagged scatterplot estimation vs. the ones from the plug-in approach. These are displayed on the next page. While for the first 50 lags, there is not much of a difference, the plug-in estimates are much more damped for higher lags. As claimed above, the lagged scatterplot estimate shows a value of 1 for lag 394, and some generally very erratic behavior in the few lags before.

We can “prove”, or rather, provide evidence that this is an estimation artifact only if we restrict the series to the first 60 observations and then repeat the estimation of autocorrelations. Again, for the highest few lags which are estimable, the lagged scatterplot approach shows erratic behavior – and this was not present at the same lags, when the series was still longer. We do not observe this kind of effect with the plug-in based autocorrelations, thus this is clearly the method of choice.

We finish this chapter by repeating that the bigger the lag, the fewer data pairs remain for estimating the autocorrelation coefficient. We discourage of the use of the lagged scatterplot approach. While the preferred plug-in approach is biased

due to the built-in damping mechanism, i.e. the estimates for high lags are shrunken towards zero; it can be shown that it has lower mean squared error. This is because it produces results with much less (random) variability. It can also be shown that the plug-in estimates are consistent, i.e. the bias disappears asymptotically.

![](images/f4ba445cdab9c5bffcdfa0aa3593dbac97ab381f79fc0caaa655dd2da8c720e3.jpg)  
ACF Estimation: Lagged Scatterplot vs. Plug-In

Nevertheless, all our findings still suggest that it is a good idea to consider only a first portion of the estimated autocorrelations. A rule of the thumb suggests that $1 0 \cdot \log _ { 1 0 } ( n )$ is a good threshold. For a series with 100 observations, the threshold becomes lag 20. A second rule operates with $n / 4$ as the maximum lag to which the autocorrelations are shown.

![](images/9fa4a58fe2efb21c2b1c5b5752f815cf830bb2bd5a3b8e20f1390623ffc39e41.jpg)  
ACF Estimation: Lagged Scatterplot vs. Plug-In

# 4.4.3 Correlogram

Now, we know how to estimate the autocorrelation function (ACF) for any lag $k$ . Here, we introduce the correlogram, the standard means of visualization for the ACF. We will then also study the properties of the ACF estimator. We employ R and obtain:

$$
> \operatorname {a c f} (\text {w a v e}, \text {y l i m} = \mathrm {c} (- 1, 1))
$$

![](images/9ebb1bff0fdd8d893266a7a0cb3216e1cbc2f43bf5a9c9ee0e11e2ff98331283.jpg)  
Correlogram of Wave Tank Data

It has become a widely accepted standard to use vertical spikes for displaying the estimated autocorrelations. Also note that the ACF starts with lag 0, at which it always takes the value 1. For better judgment, we also recommend setting the y - range to the interval [ 1,1]  . Apart from these technicalities, the ACF reflects the properties of the series. We also observe a cyclic behavior with a period of 8, as it is apparent in the time series plot of the original data. Moreover, the absolute value of the correlations attenuates with increasing lag. Next, we will discuss the interpretation of the correlogram.

# Confidence Bands

It is obvious that even for an iid series without any serial correlation, and thus $\rho ( k ) = 0$ for all $k$ ， the estimated autocorrelations ${ \hat { \rho } } ( k )$ will generally not be zero. Hopefully, they will be close, but the question is how close. An answer is indicated by the confidence bands, i.e. the blue dashed lines in the plot above.

These so-called confidence bands are obtained from an asymptotic result: for long iid time series it can be shown that the ${ \hat { \rho } } ( k )$ approximately follow a $N ( 0 , 1 / n )$ distribution. Thus, each $\rho ( k )$ lies within the interval of $\pm 1 . 9 6 / { \sqrt { n } }$ with a probability of approximately $9 5 \%$ . This leads us to the following statement that facilitates interpretation of the correlogram: “for any stationary time series, sample autocorrelation coefficients ${ \hat { \rho } } ( k )$ that fall within the confidence band $\pm 2 / { \sqrt { n } }$ are

considered to be different from 0 only by chance, while those outside the confidence band are considered to be truly different from 0 .”

On the other hand, the above statement means that even for iid series, we expect $5 \%$ of the estimated ACF coefficients to exceed the confidence bounds; these correspond to type 1 errors. Please note again that the indicated bounds are asymptotic and derived from iid series. The properties of serially dependent series are much harder to derive.

# Ljung-Box Test

The Ljung-Box approach tests the null hypothesis that a number of autocorrelation coefficients are simultaneously equal to zero. Or, more colloquially, it evaluates whether there is any significant autocorrelation in a series. The test statistic is:

$$
Q (h) = n \cdot (n + 2) \cdot \sum_ {k = 1} ^ {h} \frac {\hat {\rho} _ {k} ^ {2}}{n - k}
$$

Here, n is the length of the time series, $\hat { \rho } _ { k }$ are the sample autocorrelation coefficients at lag $k$ and $h$ is the lag up to which the test is performed. It is typical to use $h = 1$ , 3 , 5 , 10 or 20 . The test statistic asymptotically follows a $\chi ^ { 2 }$ distribution with $h$ degrees of freedom. As an example, we compute the test statistic and the respective p-value for the wave tank data with $h = 1 0$ .

```diff
> nn <- length(wave)
> qq <- nn*(nn+2)*sum((acf(wave) $acf[2:11]^2)/(nn-(1:10)))
> qq
[1] 344.0155
> 1-pchisq(qq, 10)
[1] 0 
```

We observe that $Q ( 1 0 ) = 3 4 4 . 0 1 5 5$ which is far in excess of what we would expect by chance on independent data.The critical value, i.e. the $9 5 \%$ -quantile of the $\chi _ { 1 0 } ^ { 2 }$ is at 18.3 and thus, the p-value is close to (but not exactly) zero. There is also a dedicated R function which can be used to perform Ljung-Box testing:

```txt
> Box.test(wave, lag=10, type="Ljung-Box") 
```

Box-Ljung test

data: wave

```txt
X-squared = 344.0155, df = 10, p-value < 2.2e-16 
```

The result is, of course, identical. Please be aware that the test is sometimes also referred to as Box-Ljung test. Also R is not very consistent in its nomenclature. However, the two are one and the same. Moreover, with a bit of experience the results of the Ljung-Box test can usually be guessed quite well from the correlogram by eyeballing.

# ACF of Non-Stationary Series

Estimation of the ACF from an observed time series assumes that the underlying process is stationary. Only then we can treat pairs of observations at lag $k$ as being probabilistically “equal” and compute sample covariance coefficients. Hence, while stationarity is at the root of ACF estimation, we can of course still apply the formulae given above to non-stationary series. The ACF then usually exhibits some typical patterns. This can serve as a second check for non-stationarity, i.e. helps to identify it, should it have gone unnoticed in the time series plot. We start by showing the correlogram for the SMI daily closing values from section 1.2.4. This series does not have seasonality, but a very clear trend.

> acf(smi, lag.max=100)

![](images/46c464fc5146d0024264bc62c22cba6b881f18f020b2e8f9c1bb0d176b67c3a9.jpg)  
Correlogram of SMI Daily Closing Values

We observe that the ACF decays very slowly. The reason is that if a time series features a trend, the observations at consecutive observations will usually be on the same side of the series’ global mean $\overline { { x } }$ . This is why that for small to moderate lags $k$ , most of the terms

$$
\left(x _ {s + k} - \bar {x}\right) \left(x _ {s} - \bar {x}\right)
$$

are positive. For this reason, the sample autocorrelation coefficient will be positive as well, and is most often also close to 1. Thus, a very slowly decaying ACF is an indicator for non-stationarity, i.e. a trend which was not removed before autocorrelations were estimated.

Next, we show an example of a series that has no trend, but a strongly recurring seasonal effect. We use R’s data(nottem), a time series containing monthly average air temperatures at Nottingham Castle in England from 1920-1939. Time series plot and correlogram are as follows:

![](images/7815059734cef40812154700216663cc8bd34b7a01aa75e1e875a3c0342bfb2a.jpg)  
Nottingham Monthly Average Temperature Data

![](images/516fc501dc54c7de0c80907bc82d1f284479a5aa4e19bc9e2288cd97363e7ad3.jpg)  
Correlogram of Nottingham Temperature Data

The ACF is cyclic, and owing to the recurring seasonality, the envelope again decays very slowly. Also note that for periodic series, R has periods rather than lags on the x-axis – often a matter of confusion. We conclude that a hardly, or very slowly decaying periodicity in the correlogram is an indication of a seasonal effect which was forgotten to be removed. Finally, we also show the correlogram for the logged air passenger bookings. This series exhibits both an increasing trend and a seasonal effect. The result is as follows:

```txt
> data(AirPassengers)  
> txt <- "Correlogram of Logged Air Passenger Bookings"  
> acf(log(AirPassengers), lag.max=48, main=txt) 
```

![](images/a37827cd18a1379b5bf275f1793100040334cee02b966815eb9eb7d211a76a45.jpg)  
Correlogram of Logged Air Passenger Bookings

Here, the two effects described above are interspersed. We have a (here dominating) slow decay in the general level of the ACF, plus some periodicity. Again, this is an indication for a non-stationary series. It needs to be decomposed, before the serial correlation in the stationary remainder term can be studied.

# The ACF and Outliers

If a time series has an outlier, it will appear twice in any lagged scatterplot, and will thus potentially have “double” negative influence on the ${ \hat { \rho } } ( k )$ . As an example, we consider variable temp from data frame beaver1, which can be found in R’s data(beavers). This is the body temperature of a female beaver, measured by telemetry in 10 minute intervals. We first visualize the data with a time series plot.

![](images/9726420a9068b04814a028528ce0f6cf70068a19d925513e6c5baa8b5ba8dbb9.jpg)  
Beaver Body Temperature Data

Observation 80 is a moderate, but distinct outlier. It is unclear to the author whether this actually is an error, or whether the reported value is correct. But because the purpose of this section is showing the potential influence of erroneous values, that is not important. Neither the Pearson correlation coefficient, nor the plug-in autocorrelation estimator is robust, thus the appearance of the correlogram can be altered quite strongly due to the presence of just one single outlier.

> plot(beaver[1:113], beaver[2:114], $\mathtt { p c h } { = } 2 0$ ,)   
$>$ title("Lagged Scatterplot for Beaver Temperature")

![](images/ccdaacf85795d25b77518ba6fee961bea1613c4a80b6e1070f94a3445b66ad8f.jpg)  
Lagged Scatterplot for Beaver Temperature

The two data points where the outlier is involved are highlighted. The Pearson correlation coefficients with and without these two observations are 0.86 and 0.91. Depending on the outliers severity, the difference can be much bigger. The next plot shows the entire correlogram for the beaver data, computed with (black) and without (red) the outlier. Also here, the difference may seem small and rather academic, but it could easily be severe if the outlier was just pronounced enough.

![](images/65753c1ed557c6c42ea595a04d16f3d3e6bd67f0d045dd5fb10f5e873ab87278.jpg)  
Correlogram of Beaver Temperature Data

The question is, how do we handle missing values in time series? In principle, we cannot just omit them without breaking the time structure. And breaking it means going away from our paradigm of equally spaced points in time. A popular choice is thus replacing the missing value. This can be done with various degrees of sophistication:

a) replacing the value with the global mean   
b) using a local mean, i.e. +/- 3 observations   
c) model based imputation by forecasting

The best strategy depends upon the case at hand. And in fact, there is a fourth alternative: while R’s acf() function by default does not allow for missing values, it still offers the option to proceed without imputation. If argument is set as na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, the covariances are computed from the complete cases, and the correlogram is shown as usual. However, having missed values in the series has the consequence that the estimates produced may well not be a valid (i.e. positive definite) autocorrelation sequence, and may contain missing values. From a practical viewpoint, these drawbacks can often be neglected, though.

# 4.4.4 Quality of ACF Estimates

In this section we will deal with the quality of the information that is contained in the correlogram. We will not do this from a very theoretical viewpoint, but rather focus on the practical aspects. We have already learned that the ACF estimates are generally biased, i.e. shrunken towards zero for higher lags. This means that it is better to cut off the correlogram at a certain lag. Furthermore, non-stationarities in the series can hamper the interpretation of the correlogram and we have also seen that outliers can have a quite strong impact. But there are even more aspects in ACF estimation that are problematic...

# The Compensation Issue

One can show that the sum of all autocorrelations which can be estimated from a time series realization, the sum over all ${ \hat { \rho } } ( k )$ for lags $k = 1 , . . . , n - 1$ , adds up to -1/2. Or, written as a formula:

$$
\sum_ {k = 1} ^ {n - 1} \hat {\rho} (k) = - \frac {1}{2}
$$

We omit the proof here. It is clear that the above condition will lead to quite severe artifacts, especially when a time series process has only positive correlations. We here show both the true, theoretical ACF of an $A R ( 1 )$ process with $\alpha _ { \mathrm { 1 } } = 0 . 7$ , which, as we will see in section 5, has $\rho ( k ) > 0$ for all $k$ , and the sample correlogram for a realization of that process with a length 200 observations.

![](images/0746c0abe3e5096f7c3c5a3e4a6c124481638cf06d0fb3ae738aea214994aed7.jpg)  
True ACF of an AR(1) Process with alpha=0.7

![](images/66051a060b7c28c7fcd698d91ec20ff330677807ce7123e1cdf19831eb59120f.jpg)  
Correlogram for a Realization from an AR(1) Process

The respective R-commands for producing these plots are as follows:

```r
## True ACF
true.acf <- ARMAacf(ar=0.7, lag.max=200)
plot(0:200, true.acf, type="h", xlab="Lag",ylim=c(-1,1))
title("True ACF of an AR(1) Process with alpha=0.7")
abline(h=0, col="grey") 
```

```r
## Simulation and Generating the ACF
set.seed(25)
ts.simul <- arima.sim(list(ar=0.7), 200)
acf(ts.simul, lag=200, main="Correlogram ...") 
```

What we observe is quite striking: only for the very first few lags, the sample ACF does match with its theoretical counterpart. As soon as we are beyond lag $k = 6$ , the sample ACF turns negative. This is an artifact, because the sum of the estimated autocorrelations coefficients needs to add up to -1/2. Some of these spurious, negative correlation estimates are so big that they even exceed the confidence bounds – an observation that has to be well kept in mind if one analyzes and tries to interpret the correlogram.

# Simulation Study

Last but not least, we will run a small simulation study that visualizes bias and variance in the sample autocorrelation coefficients. We will again base this on the simple AR(1) process with coefficient $\alpha _ { \mathrm { 1 } } = 0 . 7$ . For further discussion of the process’ properties, we refer to section 5. There, it will turn out that the $k ^ { t h }$ autocorrelation coefficient of such a process takes the value $( 0 . 7 ) ^ { k }$ , as visualized on the previous page.

For understanding the variability in $\hat { \rho } ( 1 )$ , ${ \hat { \rho } } ( 2 )$ , $\hat { \rho } ( 5 )$ and $\hat { \rho } ( 1 0 )$ , we simulate from the aforementioned $A R ( 1 )$ process. We generate series of length $n = 2 0$ , $n = 5 0$ , $n = 1 0 0$ and $n = 2 0 0$ . We then obtain the correlogram, record the estimated autocorrelation coefficients and repeat this process 1000 times. This serves as a basis for displaying the variability in $\hat { \rho } ( 1 )$ , ${ \hat { \rho } } ( 2 )$ , $\hat { \rho } ( 5 )$ and $\hat { \rho } ( 1 0 )$ with boxplots. They can be found below.

![](images/5bd3e731933ccdb8201d5e5b4d27630ea3dba96729733d137ca587694cfca657.jpg)  
Variation in ACF(1) estimation

![](images/f3e3f45ae63568cd5d7ccb30cc67c234a4d0ae7707a23a67f4e55e49a48ef9d1.jpg)  
Variation in ACF(2) estimation

![](images/70e97821eac858f4b1e4bf79903e16be53131d11eb5d5a6e9ac56c14b4556ccc.jpg)  
Variation in ACF(5) estimation

![](images/e6f505d9df24c8d5d0ae0235c996363bef6d8c9e0412fad6b9c84e35b7f69a08.jpg)  
Variation in ACF(10) estimation

We observe that for “short” series with less than 100 observations, estimating the ACF is difficult: the ${ \hat { \rho } } ( k )$ are strongly biased, and there is huge variability. Only for longer series, the consistency of the estimator “kicks in”, and yields estimates which are reasonably precise. For lag $k = 1 0$ , on the other hand, we observe less bias, but the variability in the estimate remains large, even for “long” series.

We conclude this situation by summarizing: by now, we have provided quite a bit of evidence that the correlogram can be tricky to interpret at best, sometimes even misleading, or plain wrong. However, it is the best means we have for understanding the dependency in a time series. And we will base many if not most of our decisions in the modeling process on the correlogram. However, please be aware of the bias and the estimation variability there is.

# 4.5 Partial Autocorrelation

For the above AR(1) process, with its strong positive correlation at lag 1, it is somehow “evident” that the autocorrelation for lags 2 and higher will be positive as well – just by propagation: if A is highly correlated to B, and B is highly correlated to C, then A is usually highly correlated to C as well. It would now be very instructive to understand the direct relation between A and C, i.e. exploring what dependency there is in excess to the one associated to B. In a time series context, this is exactly what the partial autocorrelations do. The mathematical definition is the one of a conditional correlation:

$$
\pi (k) = \operatorname {C o r} \left(X _ {t + k}, X _ {t} \mid X _ {t + 1} = x _ {t + 1}, \dots , X _ {t + k - 1} = x _ {t + k - 1}\right)
$$

In other words, we can also say that the partial autocorrelation is the association between $X _ { t }$ and $X _ { { t + k } }$ with the linear dependence of $X _ { t + 1 }$ through $X _ { { t + k - 1 } }$ removed. Another instructive analogy can be drawn to linear regression. The autocorrelation coefficient $\rho ( k )$ measures the simple dependence between $X _ { t }$ and $X _ { { t + k } }$ , whereas the partial autocorrelation $\pi ( k )$ measures the contribution to the multiple dependence, with the involvement of all intermediate instances $X _ { { t + 1 } } , . . . , X _ { { t + k - 1 } }$ as explanatory variables. There is a (theoretical) relation between the partial autocorrelations $\pi ( k )$ and the plain autocorrelations $\rho ( 1 ) , . . . , \rho ( k )$ , i.e. they can be derived from each other, e.g.:

$$
\pi (1) = \rho (1) \text {a n d} \pi (2) = (\rho (2) - \rho (1) ^ {2}) / (1 - \rho (1) ^ {2})
$$

The formula for higher lags $k$ exists, but get complicated rather quickly, so we do without displaying them. However, another absolutely central property of the partial autocorrelations $\pi ( p )$ is that the $k ^ { t h }$ coefficent of the $A R ( p )$ model, denoted as $\alpha _ { p }$ , is equal to $\pi ( p )$ . While there is an in depth discussion of $A R ( p )$ models in section 5, we here briefly sketch the idea, because it makes the above property seem rather logical. An autoregressive model of order $p$ , i.e. an $A R ( p )$ is:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + \ldots + \alpha_ {k} X _ {t - p} + E _ {t},
$$

where $E _ { t }$ is a sequence of iid random variables. Making the above statement concrete, this means that in an $A R ( 3 )$ process, we have $\pi ( 3 ) = \alpha _ { 3 }$ , but generally $\pi ( 2 ) \neq \alpha _ { 2 }$ and $\pi ( 1 ) \neq \alpha _ { 1 }$ . Moreover, we have $\pi ( k ) = 0$ for all $k > p$ . These properties are used in R for estimating partial autocorrelation coefficients. Estimates ${ \hat { \pi } } ( p )$ are generated by fitting autoregressive models of successively higher orders. The job is done with function pacf(): input/output are equal/similar to ACF estimation. In particular, the confidence bounds are also presented for the PACF. We conclude this section by showing the result for the wave tank data.

> pacf(wave, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1), main ${ \bf \Phi } = { \bf \Phi }$ "PACF of Wave Tank Data")

![](images/d95259a0c3d0e2842e5222743beaa9e3f2f507c4a7bb03df19fc23b99a9161b3.jpg)  
PACF of Wave Tank Data

We observe that $\hat { \pi } ( 1 ) \approx 0 . 5$ and $\hat { \pi } ( 2 ) \approx - 0 . 6$ . Some further PACF coefficients up to lag 10 seem significantly different from zero, but are smaller. From what we see here, we could try to describe the wave tank data with an AR(2) model. The next section will explain why.

# 5 Stationary Time Series Models

Rather than simply describing observed time series data, we now aim for fitting models. This will prove useful for a deeper understanding of the data, but is especially beneficial when forecasting is the main goal. We here focus on parametric models for stationary time series, namely the broad class of autoregressive moving average (ARMA) processes – these have shown great importance in modeling real-world data.

# 5.1 White Noise

As the most basic stochastic process, we introduce discrete White Noise. A time series $( W _ { 1 } , W _ { 2 } , . . . , W _ { n } )$ is called White Noise if the random variables $W _ { 1 } , W _ { 2 } , \ldots$ are independent and identically distributed with mean zero. This also implies that all random variables $W _ { t }$ have identical variance, and there are no autocorrelations and partial autocorrelations either: $\rho ( k ) = 0$ and $\pi ( k ) = 0$ for all lags $k$ . If in addition, the variables also follow a Gaussian distribution, i.e. $W _ { t } \sim N ( 0 , \sigma _ { w } ^ { 2 } )$ , the series is called Gaussian White Noise.

Before we show a realization of a White Noise process, we state that the term “White Noise” was coined in an article on heat radiation published in Nature in April 1922. There, it was used to refer to series time series that contained all frequencies in equal proportions, analogous to white light. It is possible to show that iid sequences of random variables do contain all frequencies in equal proportions, and hence, here we are.

![](images/4dadafccee797d909611cc0df95f93ae51eba9fd05b67c8dbd8422759e2f8c8f.jpg)  
Gaussian White Noise

In R, it is easy to generate Gaussian White Noise, we just type:

> ts(rnorm(200, mean ${ } = 0$ , $\mathtt { S C = 1 }$ ))

Well, by giving more thought on how computers work, i.e. by relying on deterministic algorithms, it may seem implausible that they can really generate independent data. We do not embark into these discussions here, but treat the result of rnorm() as being “good enough” for a realization of a White Noise process. Here, we show ACF and PACF of the above series. As expected, there are no (strongly) significant estimates.

![](images/c14548ec68b4a8b28711ade47c160904ff1f8add178ce1ddaf7797a2f88e4aad.jpg)  
ACF

![](images/4adad95e3cd0a6c321f5f40f1855616e355e490b4d6a3f74e5d4d417e4f270a1.jpg)  
PACF

White Noise series are important, because they usually arise as residual series when fitting time series models. The correlogram generally provides enough evidence for attributing a series as White Noise, provided the series is of reasonable length – our studies in section 4.4 suggests that 100 or 200 is such a value. Please also note that while there is not much structure in Gaussian White Noise, it still has a parameter. It is the variance $\sigma _ { { \scriptscriptstyle W } } ^ { 2 }$ .

# 5.2 Estimating the Conditional Mean

Before we present some time series models, it is important to build some understanding of what we are actually doing. All the $A R ( p )$ , $M A ( q )$ and $A R M A ( p , q )$ models that will be presented below are based on the assumption that the time series can be written as:

$$
X _ {t} = \mu_ {t} + E _ {t}.
$$

Hereby, $\mu _ { t }$ is the conditional mean of the series, i.e. $\mu _ { t } = E [ X _ { t } | X _ { t - 1 } , X _ { t - 2 } , \ldots ]$ and $E _ { t }$ is a disturbance term. For all models in section 5, the disturbance term is assumed to be a White Noise innovation.

It is very important to notice that while stationary series feature a constant marginal expectation $\mu$ , the conditional mean $\mu _ { t }$ is can be and often is nonconstant and time-dependent. Or in other words, there is some short-term memory in the series. The $A R M A ( p , q )$ processes that will be discussed here in this section are built on the following notion:

$$
\mu_ {t} = f (X _ {t - 1}, X _ {t - 2}, \dots , X _ {t - p}, E _ {t - 1}, E _ {t - 2}, \dots , E _ {t - q}).
$$

In words, the conditional mean is a function of past instances of the series as well as past innovations. We will see that usually, a selection of the involved terms is made, and that the function $f ( \cdot )$ is linear.

# 5.3 Autoregressive Models

# 5.3.1 Definition and Properties

The most natural formulation of a time series model is a linear regression approach on the past instances, i.e. a regression on the series itself. This coined the term autoregressive. In practice, such models prove to be very important; they are the most popular way of describing time series.

# Model and Terms

An autoregressive model of order $p$ , abbreviated as $A R ( p )$ , is based on a linear combination of past observations according to the following equation:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + \alpha_ {2} X _ {t - 2} + \ldots + \alpha_ {p} X _ {t - p} + E _ {t}.
$$

Hereby, the disturbance term $E _ { t }$ comes from a White Noise process, i.e. is iid. Moreover, we require that it is an innovation, i.e. that it is stochastically independent of $X _ { { t - 1 } } , X _ { { t - 2 } } , . . .$ . The term innovation is illustrative, because (under suitable conditions), it has the power to drive the series into a new direction, meaning that it is strong enough so that it can overplay the dependence of the series from its own past. An alternative notation for $A R ( p )$ models is possible with the backshift operator:

$$
(1 - \alpha_ {1} B - \alpha_ {2} B ^ {2} - \dots - \alpha_ {p} B ^ {p}) X _ {t} = E _ {t}, \text {o r s h o r t} \Phi (B) X _ {t} = E _ {t}
$$

Hereby, $\Phi ( B )$ is called the characteristic polynomial. It determines all the relevant properties of the process. The most important questions that we will deal with in this chapter are of course the choice of the order $p$ and the estimation of the coefficients $\alpha _ { 1 } , . . . , \alpha _ { p }$ . But first, a very important point:

$A R ( p )$ models must only be fitted to stationary time series. Any potential trends and/or seasonal effects need to be removed first. We will also make sure that the $A R ( p )$ processes are stationary.

When is an $A R ( p )$ stationary? Not always, but under some mild conditions. First of all, we study the unconditional expectation of an $A R ( p )$ process $X _ { t }$ which we assume to be stationary, hence $E [ X _ { t } ] = \mu$ for all $t$ . When we take expectations on both sides of the model equation, we have:

$$
\mu = E \left[ X _ {t} \right] = E \left[ \alpha_ {1} X _ {t - 1} + \dots + \alpha_ {p} X _ {t - p} + E _ {t} \right] = \left(\alpha_ {1} + \dots + \alpha_ {p}\right) \cdot \mu + 0, \text {h e n c e} \mu = 0.
$$

Thus, any stationary $A R ( p )$ process has a global mean of zero. But please be aware of the fact that the conditional mean is time dependent and generally different from zero.

$$
\mu_ {t} = E [ X _ {t} \mid X _ {t - 1}, \dots , X _ {t - p} ] = \alpha_ {1} x _ {t - 1} + \dots + \alpha_ {p} x _ {t - p}
$$

The question remains if $A R ( p )$ processes are practically useful, because most of the real-word time series have a global mean $\mu$ that is different from zero. However, that generally poses little difficulties if we add an additional parameter m to the model definition:

$$
Y _ {t} = m + X _ {t}
$$

In that case, $Y _ { _ t }$ is a shifted $A R ( p )$ process, i.e. it has all dependency properties from an $A R ( p )$ , but its mean is different from zero. In fact, all R methodology that exists for fitting $A R ( p )$ ’s assumes the process $Y _ { _ t }$ and thus estimates a global mean m unless this is explicitly excluded. In practice, if one colloquially speaks of an $A R ( p )$ , mostly one thinks of $Y _ { _ t }$ rather than $X _ { t }$ .

However, for the stationarity of an $A R ( p )$ , some further conditions on the model coefficients $\alpha _ { 1 } , . . . , \alpha _ { p }$ are required. The general derivation is quite complicated and will be omitted here. But for illustrative purpose, we assume a stationary $A R ( 1 )$ which has $V a r ( X _ { t } ) = \sigma _ { X } ^ { 2 }$ for all $t$ . If we determine the centralized second moment on both sides of the model equation, we obtain:

$$
\sigma_ {X} ^ {2} = \operatorname {V a r} \left(X _ {t}\right) = \operatorname {V a r} \left(\alpha_ {1} X _ {t - 1} + E _ {t}\right) = \alpha_ {1} ^ {2} \sigma_ {X} ^ {2} + \sigma_ {E} ^ {2}, \text {h e n c e} \sigma_ {X} ^ {2} = \frac {\sigma_ {E} ^ {2}}{1 - \alpha_ {1} ^ {2}}.
$$

From this we derive that an $A R ( 1 )$ can only be stationary if $\left| \alpha _ { 1 } \right| < 1$ . That limitation means that the dependence from the series’ past must not be too strong, so that the memory fades out. If $\left| \alpha _ { 1 } \right| > 1$ , the process diverges. The general condition for $A R ( p )$ models is (as mentioned above) more difficult to derive. We require that:

The (potentially complex) roots of the characteristic polynomial $\Phi ( B )$ must all exceed 1 in absolute value for an $A R ( p )$ process to be stationary.

In R, there is function polyroot() for finding a polynomials roots. If we want to verify whether an AR(3) with $\alpha _ { \mathrm { 1 } } = 0 . 4$ , $ \alpha _ { 2 } = - 0 . 2$ , $\mathcal { X } _ { 3 } = 0 . 3$ is stationary, we type:

$>$ abs(polyroot(c(1,0.4,-0.2,0.3))) [1] 1.776075 1.056710 1.776075

Thus, the $A R ( 3 )$ we specified is stationary. We will proceed by studying the dependency in $A R ( p )$ processes. For illustration, we first simulate from an $A R ( 1 )$ with $\alpha _ { \mathrm { 1 } } = 0 . 8$ . The model equation is:

$$
X _ {t} = 0. 8 \cdot X _ {t - 1} + E _ {t}
$$

So far, we had only required that $E _ { t }$ is a White Noise innovation, but not a distribution. We use the Gaussian in this example and set $x _ { 1 } = E _ { 1 }$ as the starting value.

```r
> set.seed(24)  
> E <- rnorm(200, 0, 1)  
> x <- numeric()  
> x[1] <- E[1]  
> for(i in 2:200) x[i] <- 0.8*x[i-1] + E[i]  
> plot(ts(x), main = "AR(1) with...") 
```

![](images/7d3f583333d19dc2f8a538bcb751c7a50820c5b53ac0ed0130dfbd86527c6be3.jpg)

We observe some cycles with exclusively positive and others with only negative values. That is not surprising: if the series takes a large value, then the next one is determined as 0.8 times that large value plus the innovation. Thus, it is more likely that the following value has the same sign as its predecessor. On the other hand, the innovation is powerful enough so that jumping to the other side of the global mean zero is always a possibility. Given that behavior, it is evident that the autocorrelation at lag 1 is positive. We can compute it explicitly from the model equation:

$$
C o r (X _ {t}, X _ {t - 1}) = C o r (\alpha_ {1} X _ {t - 1} + E _ {t}, X _ {t - 1}) = \alpha_ {1}
$$

Thus we have $\rho ( 1 ) = 0 . 8$ here, or in general $\rho ( 1 ) = \alpha _ { 1 }$ . The correlation for higher lags can be determined similarly by repeated plug-in of the model equation. It is:

$$
\rho (k) = \alpha_ {1} ^ {k}.
$$

Thus, for stationary $A R ( 1 )$ series, we have an exponential decay of the autocorrelation coefficients. Of course, it is also allowed to have a negative value for $\alpha _ { \mathrm { 1 } }$ , as long as $\left| \alpha _ { 1 } \right| < 1$ . A realization of length 200 with $ \alpha _ { 1 } = - 0 . 8$ is as follows:

![](images/296055d085b91560c9cee2dc0b940408ba9ce2cb966e7a1079a4d6081a73af1a.jpg)  
AR(1) with $\mathrm { a } _ { 1 } \mathrm { = } \mathrm { - } 0 . 8$

The series shows an alternating behavior: the next value is more likely to lie on the opposite side of the global mean zero, but there are exceptions when the innovation takes a large value. The autocorrelation still follows $\rho ( k ) = \alpha _ { 1 } ^ { k }$ . It is also alternating between positive and negative values with an envelope that is exponentially decaying.

We will now focus on appeareance and dependency of an $A R ( 3 )$ (with the coefficients from above). While we could still program the simulation code by ourselves, it is more convenient to use function arima.sim().

![](images/533cc880313354304dcdeac4cc8aa7f0b464fced0943330b57467cbe92d4fd34.jpg)  
AR(3) with $\mathrm { \Delta } \mathrm { a } _ { 1 } \mathrm { = } \mathrm { - } 0 . 4$ , $\mathrm { \alpha } \mathrm { a } _ { 2 } \mathrm { = } \mathrm { - } 0 . 2$ , $\mathrm { \Delta } \mathrm { a } _ { 3 } { = } 0 . 3$

What is now the (theoretical) correlation in this AR(3) ? We apply the standard trick of plugging-in the model equation. This yields:

$$
\begin{array}{l} \rho (k) = C o r \left(X _ {t + k}, X _ {t}\right) \\ = \operatorname {C o r} \left(\alpha_ {1} X _ {t + k - 1} + \dots + \alpha_ {p} X _ {t + k - p}, X _ {t}\right) \\ = \alpha_ {1} \rho (k - 1) + \dots + \alpha_ {p} \rho (k - p) \\ \end{array}
$$

with $\rho ( 0 ) = 1$ and $\rho ( - k ) = \rho ( k )$ . For $k = 1 , . . . , p$ this results in a $p \times p$ linear equation system called the Yule-Walker equations. It can be solved to obtain the autocorrelation coefficients which can finally be propagated for $k = p + 1 , p + 2 , \ldots$ . In R, there is function armaACF() that allows to determine the autocorrelation from autoregressive model coefficients.

$$
\begin{array}{l} > \text {a u t o c o r r} <   - \text {A R M A a c f} (\text {a r} = \text {c} (0. 4, - 0. 2, 0. 3), \text {l a g . m a x} = 2 0) \\ > \text {p l o t} (0: 2 0, \text {a u t o c o r r}, \text {t y p e} = ^ {\prime \prime} h ^ {\prime \prime}, x l a b = ^ {\prime \prime} L a g ^ {\prime \prime}) \\ \end{array}
$$

![](images/b915e675c099209d146273c7293d312af53dfb4550b6996bff3b2c62f8608822.jpg)  
Theoretical Autocorrelation for an AR(3)

We observe that the theoretical correlogram shows a more complex structure than what could be achieved with an $A R ( 1 )$ . Nevertheless, one can still find an exponentially decaying envelope for the magnitude of the autocorrelations. That is a property which is common to all $A R ( p )$ models.

From the above, we can conclude that the autocorrelations are generally non-zero for all lags, even though in the underlying model, $X _ { t }$ only depends on the $p$ previous values $X _ { { t - 1 } } , . . . , X _ { { t - p } }$ . In section 4.5 we learned that the partial autocorrelation at lag $k$ illustrates the dependence between $X _ { t }$ and $X _ { { t + k } }$ when the linear dependence on the intermittent terms was already taken into account. It is evident by definition that for any $A R ( p )$ process, we have $\pi ( k ) = 0$ for all $k > p$ . This can and will serve as a useful indicator for deciding on the model order $p$ if we are trying to identify the suitable model order when fitting real world data. In this section, we focus on the PACF for the above $A R ( 3 )$ .

> autocorr <- ARMAacf(ar=..., pacf $\underline { { \underline { { \mathbf { \Pi } } } } }$ TRUE, lag.max=20) > plot(0:20, autocorr, type $=$ "h", xlab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "Lag")

![](images/1004b88c16a926e0053d2a98f3625ff3c8517f2c87bdf2f901d4d2fb559c7664.jpg)  
Theoretical Partial Autocorrelation for an AR(3)

As claimed previously, we indeed observe $\rho ( 1 ) = \pi ( 1 ) = 0 . 3 4 3$ and $\pi ( 3 ) = \alpha _ { 3 } = 0 . 3$ . All partial autocorrelations from $\pi ( 4 )$ on are exactly zero.

# 5.3.2 Fitting

Fitting an $A R ( p )$ model to data involves three main steps. First, the model and its order need to be identified. Second, the model parameters need to be estimated and third, the quality of the fitted model needs to be verified by residual analysis.

# Model Identification

The model identification step first requires verifying that the data show properties which make it plausible that they were generated from an $A R ( p )$ process. In particular, the time series we are aiming to model needs to be stationary, show an ACF with approximately exponentially decaying envelope and a PACF with a recognizable cut-off at some lag $p$ smaller than about 5 10  . If any of these three properties is strongly violated, it is unlikely that an $A R ( p )$ will yield a satisfactory fit, and there might be models which are better suited for the problem at hand.

The choice of the model order $p$ then relies on the analysis of the sample PACF. Following the paradigm of parameter parsimony, we would first try the simplest model that seems plausible. This means choosing the smallest $p$ at which we suspect a cut-off, i.e. the smallest after which none, or only few and weakly significant partial autocorrelations follow. We illustrate the concept with the logged Lynx data that were already discussed in section 1.2.2. We need to generate both ACF and PACF, which can be found on the next page.

![](images/8437409f1f12f72c5dfb5181efae8f090c3b992d2db69aaf1da87c0df6411b28.jpg)  
ACF Logged Lynx Data

![](images/3db6fa3dd4f32bfa9ff7ca6c332fcaf967c0cae8f095126eedac8128d425a852.jpg)  
PACF of Logged Lynx Data

There is no reason to doubt the stationarity of the Lynx series. Moreover, the ACF shows a cyclic behavior that has an exponentially decaying envelope. Now does the PACF show a cut-off? That is a bit less clear, and several orders $p$ $( = 2 , 4 , 7 , 1 1 )$ come into question. However in summary, we conjecture that there are no strong objections against fitting an $A R ( p )$ . The choice of the order is debatable, but the parsimony paradigm tells us that we should try with the smallest candidate first, and that is $p = 2$ .

# Parameter Estimation

Observed time series are rarely centered and thus, it is usually inappropriate to fit a pure $A R ( p )$ process. In fact, all R routines for fitting autoregressive models by default assume the shifted process $Y _ { t } = m + X _ { t }$ . Hence, we have a regression-type equation with observations:

$$
(Y _ {t} - m) = \alpha_ {1} (Y _ {t - 1} - m) + \dots + \alpha_ {p} (Y _ {t - p} - m) + E _ {t} \text {f o r} t = p + 1, \dots , n.
$$

The goal here is to estimate the parameters $m , \mathcal { \alpha } _ { 1 } , . . . , \mathcal { \alpha } _ { p }$ such that the data are fitted well. There are several concepts that define well fitting. These include ordinary least squares estimation (OLS), Burg’s algorithm (Burg), the Yule-Walker approach (YW) and maximum likelihood estimation (MLE). Already at this point we note that while the four methods have fundamental individuality, they are asymptotically equivalent (under some mild assumptions) and yield results that mostly only differ slightly in practice. Still, it is worthwhile to study all the concepts.

# OLS

The OLS approach is based on the notion with the centering; the above equation defines a multiple linear regression problem without intercept. The goodness-of-fit criterion is $\left( x _ { t } - \hat { x } _ { t } \right) ^ { 2 }$ resp. $\left( y _ { t } - \hat { y } _ { t } \right) ^ { 2 }$ , the two quantities are equal. The first step with this approach is to center the data, which is based on subtracting the global mean:

Estimate $\hat { m } = \overline { { y } } = \sum _ { t = 1 } ^ { n } y _ { t }$ and then compute $x _ { t } = y _ { t } - { \hat { m } }$ for all $t = 1 , . . . , n$

On the $x _ { t }$ , an OLS (auto)regression without intercept is performed. Note that this regression is (technically) conditional on the first $p$ observations $x _ { 1 } , . . . , x _ { p }$ , which are only used as predictors, but not as response terms. In other words, the goodness-of-fit of the model is only evaluated for the last $n - p$ observations. The following code chunk implements the procedure for the logged lynx data:

```txt
> l1c <- log(lynx) - mean(log(lynx))
> resp <- l1c[3:114]
> pred1 <- l1c[2:113]
> pred2 <- l1c[1:112]
> fit.ols <- lm(response ~ -1 + pred1 + pred
> summary(fit.ols) 
```

```txt
Coefficients: Estimate Std. Error t value Pr(>|t|)  
pred1 1.38435 0.06359 21.77 <2e-16 ***  
pred2 -0.74793 0.06364 -11.75 <2e-16 ***  
--- 
```

```txt
Residual standard error: 0.528 on 110 degrees of freedom  
Multiple R-squared: 0.8341, Adjusted R-squared: 0.8311  
F-statistic: 276.5 on 2 and 110 DF, p-value: < 2.2e-16 
```

We can extract $\hat { m } = 6 . 6 8 6$ , $\hat { \alpha } _ { \scriptscriptstyle 1 } = 1 . 3 8 4$ , $\hat { \alpha } _ { 2 } = - 0 . 7 4 8$ and $\hat { \sigma } _ { { } _ { E } } = 0 . 5 2 8$ . But while this is an instructive way of estimating $A R ( p )$ models, it is a bit cumbersome and time consuming. Not surprisingly, there are procedures that are dedicated to fitting such models in R. We here display the use of function ar.ols(). To replicate the hand-produced result, we type:

```txt
> f.ar.ols <- ar.ols(log(lynx),aic=F, intercept=F, order=2)  
> f.ar.ols 
```

```txt
Coefficients: 1 2 1.3844 -0.7479 
```

```txt
Order selected 2 sigma^2 estimated as 0.2738 
```

Note that for producing the result, we need to avoid AIC-based model fitting with aic $\underline { { \underline { { \mathbf { \Pi } } } } } =$ FALSE. The shift m is automatically estimated, and thus we need to exclude an intercept term in the regression model using intercept $=$ FALSE. We observe that the estimated AR -coefficients $\hat { \alpha } _ { 1 } , \hat { \alpha } _ { 2 }$ take exactly the same values as with the hand-woven procedure above. The estimated shift $\hat { m }$ can be extracted via

```txt
> fit.ar.ols\\(x.mean [1] 6.685933 
```

and corresponds to the global mean of the series. Finally, the estimate for the innovation variance requires some prudence. The lm() summary output yields an

estimate of $\sigma _ { E }$ that was computed as $R S S / ( n - p )$ , whereas the value in the ar.ols() output is an estimate of $\sigma _ { E } ^ { 2 }$ that was computed as $R S S / n$ . The former is intended to be an unbiased estimate (though it should use the denominator $n - p - 1$ due to the estimation of the shift m ), and the latter is the MLE-estimator for the innovation variance. In practice, the numerical difference between the two is neglectable for any series that has reasonable length for fitting an AR model.

```txt
> sum(na.omit.fit.ar.ols$resid)^2)/112  
[1] 0.2737594 
```

# Burg’s Algorithm

While the OLS approach works, its downside is the asymmetry: the first $p$ terms are never evaluated as responses. That is cured by Burg’s Algorithm, an alternative approach for estimating $A R ( p )$ models. It is based on the notion that any $A R ( p )$ process is also an $A R ( p )$ if the time is run in reverse order. Under this property, minimizing the forward and backward 1-step squared prediction errors makes sense:

$$
\sum_ {t = p + 1} ^ {n} \left\{\left(X _ {t} - \sum_ {k = 1} ^ {p} \alpha_ {k} X _ {t - k}\right) ^ {2} + \left(X _ {t - p} - \sum_ {k = 1} ^ {p} \alpha_ {k} X _ {t - p + k}\right) ^ {2} \right\}
$$

In contrast to OLS, there is no explicit solution and numerical optimization is required. This is done with a recursive method called the Durbin-Levison algorithm. We do not explain its details here, but refer to the R implementation ar.burg().

> f.ar.burg <- ar.burg(log(lynx),aic $\equiv$ FALSE,order.max=2)  
> f.ar.burg

```txt
Call: ar.burg.default(x = log(lynx),aic = FALSE, order.max = 2) 
```

```txt
Coefficients: 1 2 1.3831 -0.7461 
```

```txt
Order selected 2 sigma^2 estimated as 0.2707 
```

> f.ar.burg\\(x.mean [1] 6.685933   
> sum(na.omit(f.ar.burg\\)resid)^2)/112 [1] 0.2737614

There are a few interesting points which require commenting. First and foremost, Burg’s algorithm also uses the arithmetic mean to estimate the global mean mˆ . The fitting procedure is then done on the centered observations $x _ { t }$ . On a side remark, note that assuming centered observations is possible. If argument demean ${ \bf \Phi } = { \bf \Phi }$ FALSE is set, the global mean is assumed to be zero and not estimated.

The two coefficients $\hat { \alpha } _ { 1 } , \hat { \alpha } _ { 2 }$ take some slightly different values than with OLS estimation. While often, the difference between the two methods is practically neglectable, it is nowadays generally accepted that the Burg solution is better for finite samples. Asymptotically, the two methods are equivalent. Finally, we observe that the ar.burg() output specifies $\hat { \sigma } _ { E } ^ { 2 } = 0 . 2 7 0 7$ . This is different from the MLE estimate of 0.27376 on the residuals. The explanation is that for Burg’s Algorithm, the innovation variance is estimated from the Durbin-Levinson updates; see the R help file for further reference.

# Yule-Walker Equations

A third option for estimating $A R ( p )$ models is to plugging-in the sample ACF into the Yule-Walker equations. In section 5.3.1 we had learned that there is a $p \times p$ linear equation system $\Big | \rho ( k ) = \alpha _ { 1 } \rho ( k - 1 ) + . . . + \alpha _ { { p } } \rho ( k - p ) \Big |$ for $k = 1 , . . . , p$ . Hence we can and will explicitly determine $\hat { \rho } ( 0 ) , . . . , \hat { \rho } ( k )$ and then solve the linear equation system for the coefficients $\alpha _ { 1 } , . . . , \alpha _ { { _ p } }$ . The procedure is implemented in R function ar.yw().

> f.ar.yw <- ar.yw(log(lynx),aic $\equiv$ FALSE,order.max=2)  
> f.ar.yw

```javascript
Call: ar.yw.default(x=log(lynx),aic=False, order.max=2) 
```

```txt
Coefficients: 1 2 1.3504 -0.7200 
```

```txt
Order selected 2 sigma^2 estimated as 0.3109 
```

Again, the two coefficients $\hat { \alpha } _ { 1 } , \hat { \alpha } _ { 2 }$ take some slightly different values than compared to the two methods before. Mostly this difference is practically neglectable and Yule-Walker is asymptotically equivalent to OLS and Burg. Nevertheless, for finite samples, the estimates from the Yule-Walker method are often worse in the sense that their (Gaussian) likelihood is lower. Thus, we recommend to prefer Burg’s algorithm. We conclude this section by noting that the Yule-Walker method also involves estimating the global mean m with the arithmetic mean as the first step. The innovation variance is estimated from the fitted coefficients and the autocovariance of the series and thus again takes a different value than before.

# Maximum-Likelihood Estimation (MLE)

The MLE is based on determining the model coefficients such that the likelihood given the data is maximized, i.e. the density function takes its maximal value under the present observations. This requires assuming a distribution for the $A R ( p )$ process, which comes quite naturally if one assumes that for the innovations, we have $E _ { t } \sim N ( 0 , \sigma _ { E } ^ { 2 } )$ , i.e. they are iid Gaussian random variables. With some theory (which we omit), one can then show that an $A R ( p )$ process $X _ { 1 } , . . . , X _ { n }$ is a random vector with a multivariate Gaussian distribution.

MLE then provides a simultaneous estimation of the shift $m$ , the innovation variance $\sigma _ { E } ^ { 2 }$ and the model coefficients $\alpha _ { 1 } , . . . , \alpha _ { p }$ . The criterion that is optimized can, in a simplified version, be written as:

$$
L (\alpha , m, \sigma_ {E} ^ {2}) \propto \exp \left(\sum_ {t = 1} ^ {n} \left(x _ {t} - \hat {x} _ {t}\right) ^ {2}\right)
$$

The details are quite complex and several constants are part of the equation, too. But we here note that the MLE derived from the Gaussian distribution is based on minimizing the sum of squared errors and thus equivalent to the OLS approach. Due to the simultaneous estimation of model parameters and innovation variance, a recursive algorithm is required. There is an implementation in R:

> f.ar.mle

Call: arima(x = log(lynx), order = c(2, 0, 0))

Coefficients:

ar1 ar2 intercept 1.3776 -0.7399 6.6863 s.e. 0.0614 0.0612 0.1349

sigma^2 = 0.2708: log likelihood $=$ -88.58, aic = 185.15

We observe estimates which are again slightly different from the ones computed previously. Again, those differences are mostly neglectable for practical data analysis. What is known from theory is that the MLE is (under mild assumptions) asymptotically normal with minimum variance among all asymptotically normal estimators. Note that the MLE based on Gaussian distribution still works reasonably well if that assumption is not met, as long as we do not have strongly skewed data (apply a transformation in that case) or extreme outliers.

# Practical Aspects

We presented four different methods for fitting $A R ( p )$ models. How to make a choice in practice? We explained that all methods are asymptotically equivalent and even on finite samples; the differences among them are little. Also, all methods are non-robust with respect to outliers and perform best on data which are approximately Gaussian. There is one practical aspect linked to the fitting routines that are available in R, though. Function arima() yields standard errors for m and $\alpha _ { 1 } , . . . , \alpha _ { p }$ . Approximate $9 5 \%$ confidence intervals can be obtained by taking the point estimate $+ / -$ twice the standard error. Hence, statements about the significance of the estimates can be made.

On the other hand, ar.ols(), ar.yw() und ar.burg() do not provide standard errors, but allow for convenient determination of the model order $p$ with the AIC statistic. While we still recommend investigating on the suitable order by analyzing ACF and PACF, the parsimonity paradigm and inspecting residual plots, using AIC as a second opinion is still recommended. It works as follows:

```txt
>fit.aic<- ar.burg(log(lynx))
>plot(0:fit.aic\$order.max, fit.aic\$aic) 
```

![](images/61c26dc67967f673d3404c8004bfb757245600c2226b4a772fb400a3427ac47b.jpg)  
AIC-Values for AR(p)-Models on the Logged Lynx Data

We observe that already $p = 2$ yields a good AIC value. Then there is little further improvement until $p = 1 1$ , and a just slightly lower value is found at $p = 1 2$ . Hence, we will evaluate $p = 2$ and $p = 1 1$ as two competing models with some further tools in the next section.

# 5.3.3 Residual Analysis

When comparing different models, a simple approach is to plot the original series along with the fitted model values. However, one has to keep in mind that this is an insample analysis, i.e. the bigger model has an advantage which does not necessarily persist once analyzes out-of-sample data. Please note that the residuals are estimates of the innovations $E _ { t }$ . Thus, a good model yields residuals that resemble a White Noise process. We require mean zero, constant variance and no autocorrelation. If these properties are not met, the model is not adequate.

$>$ fit.ar02 <- ar.burg(log(lynx), aic $\underline { { \underline { { \mathbf { \Pi } } } } } =$ FALSE, order.max $^ { = 2 }$ )   
$>$ fit.ar11 <- ar.burg(log(lynx), aic $\underline { { \underline { { \mathbf { \Pi } } } } } =$ FALSE, order.max=11)   
$>$ plot(log(lynx), main ${ \bf \Phi } = { \bf \Phi }$ "Logged Lynx Data with ...")   
$>$ lines(log(lynx)-fit.ar02$resid, col ${ . } =$ "red")  
$>$ lines(log(lynx)-fit.ar11$resid, col $=$ "blue")

The output is displayed on the next page. While some differences are visible, it is not easy to judge from the fitted values which of the two models is preferable. A better focus on the quality of the fit is obtained when the residuals and their dependance are inspected with time series plots as well as ACF/PACF correlograms. The graphical output is again displayed on the next page. We observe that the $A R ( 2 )$ residuals are not iid. Hence they do not form a White

Noise process and thus, we conclude that the $A R ( 1 1 )$ model yields a better description of the logged lynx data.

![](images/e6f535323998600122c059c0f3dc42bc7a2113d57a973fa63ced8d1c510b584f.jpg)  
Logged Lynx Data with AR(2) and AR(11)

> acf(fit.ar02$resid, na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, ylim $\scriptstyle = \mathbf { \mathbf { C } }$ (-1,1))   
> pacf(fit.ar02$resid, na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1))   
$>$ acf(fit.ar11$resid, na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1))   
$>$ pacf(fit.ar11$resid, na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1))

![](images/272d72004ce71cf1b6dacd28de8dd3e470e07f5ad9534cb3ac3d23153b28774f.jpg)  
ACF of AR(2)

![](images/a98c88ae13a412a68f914420d21a7c131113eecbf120c30ce8ad22b0826d9596.jpg)  
ACF of AR(11)

![](images/e23e38926c86f02a36b9fa2473f15fc28faa293f69a4ac85c22b608d544e1a95.jpg)  
PACF of AR(2)

![](images/7953c423cb8c11adb7bae48f00b4e662d911895a32b78fbbfefaca6b1597d19c.jpg)  
PACF of AR(11)

Because our estimation routines to some extent rely on the Gaussian distribution, it is always worthwhile to generate a Normal QQ-Plot for verifying this. Here, we obtain:

$>$ par(mfrow $= _ { \mathsf { C } }$ (1,2))  
$>$ qqnorm(as.numeric(fit.ar02$resid))  
$>$ qqline(as.numeric(fit.ar02$resid))  
$>$ qqnorm(as.numeric(fit.ar11$resid))   
$>$ qqline(as.numeric(fit.ar11$resid))

![](images/a9195fc64e2963a7d697ed3dbc0c8bcc19b31727973853967d0470540314949f.jpg)  
Normal QQ-Plot: AR(2)   
Theoretical Quantiles

![](images/9e8eb4423f1e6bc0df66e3a08b05c45f0576bac3ee17078a8d648ce54039e459.jpg)  
Normal QQ-Plot: AR(11)   
Theoretical Quantiles

Neither of the two plots (which are very similar) does indicate any problems. If the residuals’ distribution looks non-normal, a log-transformation might be worth a consideration, as it often improves the situation.

# Simulation from the Fitted Model

If there are competing models and none of the other criterions dictate which one to use, another option is to generate realizations from the fitted process using R’s function arima.sim(). It usually pays off to generate multiple realizations from each fitted model. By eyeballing, one then tries to judge which model yields data that resemble the true observations best. We here do the following:

$>$ ## Repeat these commands a number of times   
$>$ plot(arima.sim( $\mathtt { n } { = } 1 1 4$ , list(ar=fit.ar02$ar)))  
$>$ plot(arima.sim( $\mathtt { n } { = } 1 1 4$ , list(ar=fit.ar11$ar)))

A realization from the fitted $A R ( 1 1 )$ can be seen on the next side. In summary, the simulations from this bigger model look more realistic than the ones from the $A R ( 2 )$ . The clearest answer about the model which is preferable here comes from the ACF/PACF correlograms, though. We conclude this section about model fitting by saying that the logged lynx data are best modeled with the $A R ( 1 1 )$ .

![](images/0356dd520188c4218a4c5f6255b6952de9b2f49afca5832de14d9be32f79c0b4.jpg)

# 5.4 Moving Average Models

Here, we discuss moving average models. They are an extension of the White Noise process, i.e. $X _ { t }$ is as a linear combination of the current plus a few of the most recent innovation terms. As we will see, this leads to a time series process that is always stationary, but not iid. Furthermore, we will see that in many respects, moving average models are complementary to autoregressive models.

# 5.4.1 Definition and Properties

As we had mentioned above, a moving average process of order $q$ , or abbreviated, an $M A ( q )$ model for a series $X _ { t }$ is a linear combination of the current innovation term $E _ { t }$ , plus the $q$ most recent ones $E _ { { t - 1 } } , . . . , E _ { { t - q } }$ . The model equation is:

$$
X _ {t} = E _ {t} + \beta_ {1} \cdot E _ {t - 1} + \ldots + \beta_ {q} \cdot E _ {t - q}
$$

We require that $E _ { t }$ is an innovation, which means independent and identically distributed, and also independent of any $X _ { s }$ where $s < t$ . For simple notation, we can make use of the backshift operator and rewrite the model:

$$
X _ {t} = \left(1 + \beta_ {1} B + \dots + \beta_ {q} B ^ {q}\right) E _ {t} = \Theta (B) E _ {t}
$$

We call $\Theta ( B )$ the characteristic polynomial of the $M A ( q )$ process and obviously, it defines all properties of the series. As a remark, please note that a number of other textbooks define the $M A ( q )$ process with negative signs for the $\beta _ { j }$ . While this is mathematically equivalent, we prefer our notation with the $" + "$ signs, as it matches the way how things are implemented in R. We turn our sights towards the motivation for the moving average process.

# What is the rationale for the $M A ( q )$ process?

Firstly, they have been applied successfully in many applied fields, particularly in econometrics. Time series such as economic indicators are affected by a variety of random events such as strikes, government decision, referendums, shortages of key commodities, et cetera. Such events will not only have an immediate effect on the indicator, but may also affect its value (to a lesser extent) in several of the consecutive periods. Thus, it is plausible that moving average processes appear in practice. Moreover, some of their theoretical properties are in a nice way complementary to the ones of autoregressive processes. This will become clear if we study the moments and stationarity of the MA process.

# Moments and Dependence

A first, straightforward but very important result is that any $M A ( q )$ process $X _ { t }$ , as a linear combination of innovation terms, has zero mean and constant variance:

$$
E \left[ X _ {t} \right] = 0 \text {f o r a l l} t, \text {a n d} \operatorname {V a r} \left(X _ {t}\right) = \sigma_ {E} ^ {2} \cdot \left(1 + \sum_ {j = 1} ^ {q} \beta_ {j} ^ {2}\right) = \text {c o n s t}
$$

Please note that in practice, we can always enhance $M A ( q )$ ’s by adding a constant m that accounts for non-zero expectation of a time series, i.e. we can consider the shifted $M A ( q )$ process

$$
Y _ {t} = m + X _ {t}.
$$

Hence, the zero mean property does not affect the possible field of practical application. Now, if we could additionally show that the autocovariance in MA processes is independent of the time $t$ , we had already proven their stationarity. This is indeed the case. We start by considering a MA(1) with $X _ { t } = E _ { t } + \beta _ { 1 } { \cdot } E _ { t - 1 }$

$$
\gamma (1) = \operatorname {C o v} \left(X _ {t}, X _ {t - 1}\right) = \operatorname {C o v} \left(E _ {t} + \beta_ {1} E _ {t - 1}, E _ {t - 1} + \beta_ {1} E _ {t - 2}\right) = \beta_ {1} \sigma_ {E} ^ {2}.
$$

For any lag $k$ exceeding the order $q = 1$ , we use the same trick of plugging-in the model equation and directly obtain a perhaps somewhat surprising result:

$$
\gamma (k) = \operatorname {C o v} \left(X _ {t}, X _ {t - k}\right) = 0 \text {f o r a l l} k > q = 1.
$$

Thus, there is no more unconditional serial dependence in lags $> 1$ . For the autocorrelation of a MA(1) process, we have:

$$
\rho (1) = \frac {\gamma (1)}{\gamma (0)} = \frac {\beta_ {1}}{1 + \beta_ {1} ^ {2}} \text {a n d} \rho (k) = 0 \text {f o r a l l} k > q = 1.
$$

From this we conclude that $\rho ( 1 ) \leq 0 . 5$ , no matter what the choice for $\beta _ { 1 }$ is. Thus if in practice we observe a series where the first-order autocorrelation coefficient clearly exceeds this value, we have counterevidence to a MA(1) process.

Furthermore, we have shown that any MA(1) has zero mean, constant variance and an ACF that only depends on the lag $k$ , hence it is stationary. Note that the stationarity does (in contrast to AR processes) not depend on the choice of the parameter $\beta _ { 1 }$ . The stationarity property can be generalized to MA q( ) processes. Using some calculations and $\beta _ { 0 } = 1$ , we obtain:

$$
\rho (k) = \left\{ \begin{array}{l l} \sum_ {j = 0} ^ {q - k} \beta_ {j} \beta_ {j + k} / \sum_ {j = 0} ^ {q} \beta_ {j} ^ {2} & f o r \quad k = 1, \dots , q \\ 0 & f o r \quad k > q \end{array} \right.
$$

Hence, $\rho ( k )$ is independent of the time t for any $M A ( q )$ process, irrespective of the order $q$ . The main results which can be derived from this property is that $M A ( q )$ processes are always stationary, independent of $\beta _ { 1 } , . . . , \beta _ { q }$ . Moreover, we learn from the above that the autocorrelation is zero for all orders $k > q$ . And there obviously is a relation between the model parameters and the autocorrelation, although it gets quite complex for higher orders. While this formula may be employed for finding the true ACF of a given $M A ( q )$ , the most convenient way of doing this in practice remains with the R function ARMAacf().

# Example of a MA(1)

For illustration, we generate a realization consisting of 500 observations, from a MA(1) process with $\beta _ { \mathrm { 1 } } = 0 . 7$ , and display time series plot, along with both estimated and true ACF/PACF.

```r
> set.seed(21)  
> ts.ma1 <- arima.sim(list(ma=0.7), n=500)  
>  
> plot(ts.ma1, ylab="",ylim=c(-4,4))  
> title("Simulation from a MA(1) Process") 
```

![](images/3daa520def6c19e96583fb0b3870f87bb2bd3f27ae84ebc72b11f21401153a8d.jpg)  
Simulation from a MA(1) Process

> acf.true <- ARMAacf( $\mathtt { m a } { = } 0 . 7$ , lag.max=20)   
> pacf.true <- ARMAacf( $\mathtt { m a } { = } 0 . 7$ , pacf $\underline { { \underline { { \mathbf { \Pi } } } } }$ TRUE, lag.max=20)

![](images/feb89b3cd5d86da47a1a08ac596c0ca04635dadd5449b66526789a978d522b07.jpg)  
Estimated ACF

![](images/9d7fc1e29a3d8e432490b10f7facde4cd59bdd564854143d3546f5c689ab6eda.jpg)  
Estimated PACF

![](images/5d636e5383e63b976c0cc69bd156830ad7430d334a8500f073d505a28ae90258.jpg)  
True ACF

![](images/6cb76d4dc21007aadfdd7e6cb311a381b08cef5230bb6131c1a5be209ed2d9fa.jpg)  
True PACF

We observe that the estimates are pretty accurate: the ACF has a clear cut-off, whereas the PACF seems to feature some alternating behavior with an exponential decay in absolute value. This behavior is typical: the PACF of any $M A ( q )$ process shows an exponential decay, while the ACF has a cut-off. In this respect, $M A ( q )$ processes are in full contrast to the $A R ( p ) { \ ' } { \mathsf { s } }$ , i.e. the appearance of ACF and PACF is swapped.

# Invertibility

It is easy to show that the first autocorrelation coefficient $\rho ( 1 )$ of an MA(1) process can be written in standard form, or also as follows:

$$
\rho (1) = \frac {\beta_ {1}}{1 + \beta_ {1} ^ {2}} = \frac {1 / \beta_ {1}}{1 + (1 / \beta_ {1}) ^ {2}}
$$

Apparently, any MA(1) process with coefficient $\beta _ { 1 }$ has exactly the same ACF as the one with $1 / \beta _ { \mathrm { \iota } }$ . Thus, the two processes $X _ { t } = E _ { t } + 0 . 5 { \cdot } E _ { t - 1 }$ and $U _ { t } = E _ { t } + 2 \cdot E _ { t - 1 }$ have the same dependency structure. Or in other words, given some ACF, we cannot identify the generating MA process uniquely. This problem of ambiguity leads to the concept of invertibility. Now, if we express the processes $X _ { t }$ and $U _ { t }$ in terms of $X _ { { t - 1 } } , X _ { { t - 2 } } , . . .$ resp. $U _ { { t - 1 } } , U _ { { t - 2 } } , \dotsc$ , we find by successive substitution:

$$
\begin{array}{l} E _ {t} = X _ {t} - \beta_ {1} X _ {t - 1} + \beta_ {1} ^ {2} X _ {t - 2} - \dots \\ E _ {t} = U _ {t} - \left(1 / \beta_ {1}\right) U _ {t - 1} + \left(1 / \beta_ {1} ^ {2}\right) U _ {t - 2} - \dots \\ \end{array}
$$

Hence, if we rewrite the MA(1) as an $A R ( \infty )$ , only one of the processes will converge. That is the one where $\left| \beta _ { 1 } \right| < 1$ , and it will be called invertible. It is important to know that invertibility of MA processes is central when it comes to fitting them to data, because parameter estimation is based on rewriting them in the form of an $A R ( \infty )$ .

For higher-order $M A ( q )$ processes, the property of invertibility is equally central. If it is met, the series can be rewritten in form of an $A R ( \infty )$ and it is guaranteed that there is a unique MA process for any given ACF. Invertibilty of a $M A ( q )$ is met if the roots of the characteristic polynomial $\Theta ( B )$ all lie outside of the unit circle. As was explained earlier in chapter 5.3.1, we can verify this using the R function polyroot(). Please note that the estimation procedure described below will always result in coefficients $\hat { \beta } _ { 1 } , . . . , \hat { \beta } _ { q }$ that define an invertible $M A ( q )$ process.

# 5.4.2 Fitting

The process of fitting $M A ( q )$ models to data is more difficult than for $A R ( p )$ , as there are no (efficient) explicit estimators and numerical optimization is mandatory. Perhaps the simplest idea for estimating the parameters is to exploit the relation between the model parameters and the autocorrelation coefficients, i.e.:

$$
\rho (k) = \left\{ \begin{array}{l l} \sum_ {j = 0} ^ {q - k} \beta_ {j} \beta_ {j + k} / \sum_ {j = 0} ^ {q} \beta_ {j} ^ {2} & f o r \quad k = 1, \dots , q \\ 0 & f o r \quad k > q \end{array} \right.
$$

Hence in case of a MA(1) , we would determine $\hat { \beta } _ { 1 }$ by plugging-in $\hat { \rho } ( 1 )$ into the equation $\rho ( 1 ) = \beta _ { 1 } / ( 1 + \beta _ { 1 } ^ { 2 } )$ . This can be seen as an analogon to the Yule-Walker approach in AR modelling. Unfortunately, the plug-in idea yields an inefficient estimator and is not a viable option for practical work.

# Conditional Sum of Squares

Another appealing idea would be to use some (adapted) least squares procedure for determining the parameters. A fundamental requirement for doing so is that we can express the sum of squared residuals $\sum E _ { t } ^ { \mathrm { i } }$ in terms of the observations $X _ { 1 } , . . . , X _ { n }$ and the parameters $\beta _ { 1 } , . . . , \beta _ { q }$ only, and do not have to rely on the unobservable $E _ { 1 } , . . . , E _ { n }$ directly. This is (up to the choice of some initial values) possible for all invertible $M A ( q )$ processes. For simplicity, we restrict our illustration to the MA(1) case, where we can replace any innovation term $E _ { t }$ by:

$$
E _ {t} = X _ {t} - \beta_ {1} X _ {t - 1} + \beta_ {1} ^ {2} X _ {t - 2} + \ldots + (- \beta_ {1}) ^ {t - 1} X _ {1} + \beta_ {1} ^ {t} E _ {0}
$$

By doing so, we managed to express the innovation/residual at time t as a function of the model parameter $\beta _ { 1 }$ and a combination of the current and past observations of the series. What is also remaining is the (hypothetical) initial innovation term $E _ { 0 }$ . Conditional on the assumption $E _ { 0 } = 0$ , we can indeed rewrite the residuals sum of squares $\sum E _ { t } ^ { 2 }$ of any MA(1) using $X _ { 1 } , . . . , X _ { n }$ and $\beta _ { 1 }$ only. However, there is no closed form solution for the minimization of $\sum E _ { t } ^ { 2 }$ , since powers of the parameter $\beta _ { 1 }$ appear; but the problem can be tackled using numerical optimization. This approach is known as the Conditional Sum of Squares (CSS) method. It works similarly for higher orders $q$ , i.e. fundamentally relies on the invertibility of the $M A ( q )$ and assumes that $E _ { t } = 0$ for all $t = - \infty , . . . , 0$ . In R, the method is implemented in function arima() if argument method $\cdot ^ { = }$ "CSS" is set.

# Maximum-Likelihood Estimation

As can be seen from the R help file, the Conditional Sum of Squares method is only secondary to method $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "CSS-ML" in the R function arima(). This means that it is preferable to use CSS only to obtain a first estimate of the coefficients $\beta _ { 1 } , . . . , \beta _ { q }$ . They are then used as starting values for a Maximum-Likelihood estimation, which is based on the assumption of Gaussian innovations $E _ { t }$ . It is pretty obvious that $X _ { { t } } = E _ { { t } } + \beta _ { 1 } E _ { { t } - 1 } + . . . + \beta _ { q } E _ { { t } - q }$ , as a linear combination of normally distributed random variables, follows a Gaussian too. By taking the covariance terms into account, we obtain a multivariate Gaussian for the time series vector:

$$
X = \left(X _ {1},..., X _ {n}\right) \sim N (0, V), \text {r e s p .} Y = \left(Y _ {1},..., Y _ {n}\right) \sim N (m \cdot \underline {{1}}, V).
$$

MLE then relies on determining the parameters m (if a shifted $M A ( q )$ is estimated), $\beta _ { 1 } , . . . , \beta _ { q }$ and $\sigma _ { E } ^ { 2 }$ simultaneously by maximizing the probability density function of the above multivariate Gaussian with assuming the data $x _ { 1 } , . . . , x _ { n }$ as given quantities. This is a quite complex non-linear problem which needs to be solved numerically. A good implementation is found in R’s arima().

The benefit of MLE is that (under mild and in practice usually fulfilled conditions) certain optimality conditions are guaranteed. It is well known that the estimates are asymptotically normal with minimum variance among all asymptotically normal estimators. Additionally, it is pretty easy to derive standard errors for the estimates, which further facilitates their interpretation. And even though MLE is based on assuming Gaussian innovations, it still produces reasonable results if the deviations from that model are not too strong. Be especially wary in case of extremely skewed data or massive outliers. In such cases, applying a logtransformation before the modelling/estimation starts is a wise idea.

# 5.4.3 Example: Return of AT&T Bonds

As an example, we consider the daily changes in the return of an AT&T bond from April 1975 to December 1975, which makes for a total of 192 observations. The data are displayed along with their ACF and PACF on the next page.

![](images/9b04199bed43af726fdbea7de73a56c00646810be624a2543c0252bd1119eba5.jpg)  
Daily Changes in the Return of an AT&T Bond

![](images/d1f6c8492d56761ff4d7f68c3650690f71c8647781cf9b4384135d4f57a7dbe0.jpg)  
ACF

![](images/04d4d4080a48b4a51a7fa4ad76d2887640dfe0556dee24fb2f3d21a1253cbc25.jpg)  
PACF

The series seems to originate from a stationary process. There are no very clear cycles visible, hence it is hard to say anything about correlation and dependency, and it is impossible to identify the stochastic process behind the generation of these data from a time series plot alone. Using the ACF and PACF as a visual aid, we observe a pretty clear cut-off situation in the ACF at lag 1 which lets us assume that a MA(1) might be suitable. That opinion is undermined by the fact that the PACF drops off to small values quickly, i.e. we can attribute some exponential decay to it for lags 1 and 2.

Our next goal is now to fit the MA(1) to the data. As explained above, the simplest solution would be to determine ${ \hat { \rho } } ( 1 ) = - 0 . 2 6 6$ and derive $\hat { \beta } _ { 1 }$ from $\rho ( 1 ) = \beta _ { 1 } / ( 1 + \beta _ { 1 } ^ { 2 } )$ . This yields two solutions, namely $\hat { \beta } _ { 1 } = - 0 . 2 8 8 0 7$ and $\hat { \beta } _ { 1 } = - 3 . 4 7 1 3 2$ . Only one of these (the former) defines an invertible MA(1) , hence we would stick to that

solution. A better alternative is to use the CSS approach for parameter estimation. The code for doing so is as follows:

```python
> arima(diff(attbond), order=c(0,0,1), method="CSS")  
Call:  
arima(x = diff(attbond), order = c(0, 0, 1), method = "CSS")  
Coefficients:  
ma1 intercept  
-0.2877 -0.0246  
s.e. 0.0671 0.0426  
sigma^2 estimated as 0.6795: part log likelihood = -234.11 
```

Even more elegant and theoretically sound is the MLE. We can also perform this in R using function arima(). It yields a very similar but not identical result:

```python
> arima(diff(attbond), order=c(0,0,1))  
Call:  
arima(x = diff(attbond), order = c(0, 0, 1))  
Coefficients:  
    ma1 intercept
    -0.2865 -0.0247
s.e. 0.0671 0.0426  
sigma^2 = 0.6795: log likelihood = -234.16, aic = 474.31 
```

Please note that the application of the three estimation procedures here was just for illustrative purposes, and to show the (slight) differences that manifest themselves when different estimators are employed. In any practical work, you can easily restrict yourself to the application of the arima() procedure using the default fitting by method $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "CSS-ML".

For verifying the quality of the fit, a residual analysis is mandatory. The residuals of the MA(1) are estimates of the innovations $E _ { t }$ . The model can be seen as adequate if the residuals reflect the main properties of the innovations. Namely, they should be stationary and free of any dependency, as well as approximately Gaussian. We can verify this by producing a time series plot of the residuals, along with their ACF and PACF, and a Normal QQ-Plot. Sometimes, it is also instructive to plot the fitted values into the original data, or to simulate from the fitted process, since this further helps verifying that the fit is good.

```r
> par(mfrow=c(2,2))  
> fit <- arima(diff(attbond), order=c(0,0,1))  
> plot(resid.fit))  
> qqnorm(resid.fit)); qqline(resid.fit))  
> acf(resid.fit)); pacf(resid.fit)) 
```

![](images/9ff2efe2bb258d68cb61dfd6523d1d27eceeb1d41ab466aea1639f294d50b92a.jpg)

![](images/c02c246fdf4781ccdfe621bb49e2f081a3306990c67311e92feb734da9f0aaff.jpg)

![](images/906c97df14e1629eb33a21d86846ef11ccf88aed3dc24f8551022c70f0ed669d.jpg)

![](images/0991c126ba0e6ef8490c0bf97ff8b0ec19ad57cc2276e1788bab89aaa32f2b89.jpg)

There are no (partial) autocorrelations that exceed the confidence bounds, hence we can safely conjecture that the residuals are not correlated and hence, all the dependency signal has been captured by the MA(1) . When inspecting the time series of the residuals, it seems stationary. However, what catches the attention is the presence of three positive outliers and the fact that the residuals are generally long-tailed. We might try to overcome this problem by a log-transformation, but this is left to the reader.

# 5.5 ARMA(p,q) Models

Here, we discuss models that feature both dependency on previous observations $X _ { { t - 1 } } , X _ { { t - 2 } } , . . .$ as well as previous innovations terms $E _ { { \scriptscriptstyle t - 1 } } , E _ { { \scriptscriptstyle t - 2 } } , \ldots$ . Thus, they are a hybrid between $A R ( p )$ and $M A ( q )$ models, and aptly named $A R M A ( p , q )$ . Their importance lies in the fact that it is possible to model a far wider spectrum of dependency structures, and that they are parsimonious: often, an $A R M A ( p , q )$ requires (far) fewer parameters than pure AR or MA processes would.

# 5.5.1 Definition and Properties

The formal definition of an $A R M A ( p , q )$ process is as follows:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + \ldots + \alpha_ {p} X _ {t - p} + E _ {t} + \beta_ {1} E _ {t - 1} + \ldots + \beta_ {q} E _ {t - q}
$$

As before, we assume that $E _ { t }$ is causal and White Noise, i.e. an innovation with mean $E [ E _ { t } ] = 0$ and finite variance $V a r ( E _ { t } ) = \sigma _ { E } ^ { 2 }$ . It is much more convenient to use the characteristic polynomials $\Phi ( \cdot )$ for the AR part, and $\Theta ( \cdot )$ for the MA part, because this allows for a very compact notation:

$$
\Phi (B) X _ {t} = \Theta (B) E _ {t}.
$$

It is obvious that all relevant properties of an $A R M A ( p , q )$ process lie in the characteristic polynomials. If the roots of $\Phi ( \cdot )$ are outside of the unit circle, the process will be stationary and have mean zero. On the other hand, if the roots of $\Theta ( \cdot )$ are outside of the unit circle, the process is invertible. Both properties are important for practical application. If they are met, we can rewrite any $A R M A ( p , q )$ in the form of a $A R ( \infty )$ or an $M A ( \infty )$ . This explains why fitting an $A R M A ( p , q )$ can in practice often be replaced by fitting AR - or MA -models with high orders (although it is not a good idea to do so!). As has been argued above, any stationary $A R M A ( p , q )$ has mean zero, i.e. $E [ X _ { t } ] = 0$ . Thus, in practice we will often consider shifted ARMA -processes that are of the form:

$$
Y _ {t} = m + X _ {t}, \text {w h e r e} X _ {t} \text {i s a n A R M A} (p, q).
$$

In principle, it is straightforward to derive the ACF of an $A R M A ( p , q )$ , though algebraically a bit tedious. Given the applied focus of this scriptum, we do without and focus on the results and consequences instead. We illustrate the typical behavior of the ARMA autocorrelations on the basis of an example. Namely, we consider the ARMA(2,1) defined by:

$$
X _ {t} - 0. 8 X _ {t - 1} + 0. 4 X _ {t - 2} = E _ {t} + 0. 6 E _ {t - 1}
$$

On the next page, we exhibit the (theoretical) ACF and PACF. It is typical that neither the ACF nor the PACF cut-off strictly at a certain lag. Instead, they both show some infinite behavior, i.e. an exponential decay in the magnitude of the coefficients. However, superimposed on that is a sudden drop-off in both ACF and PACF. In our example, it is after lag 1 in the ACF, as induced by the moving average order $q = 1$ . In the PACF, the drop-off happens after lag 2, which is the logical consequence of the autoregressive order of $p = 2$ . The general behavior of the ACF and PACF is summarized in the table below.

<table><tr><td>Model</td><td>ACF</td><td>PACF</td></tr><tr><td>AR(p)</td><td>infinite / exp. decay</td><td>cut-off at lag p</td></tr><tr><td>MA(q)</td><td>cut-off at lag q</td><td>infinite / exp. decay</td></tr><tr><td>ARMA(p,q)</td><td>infinite / mix of decay &amp; cut-off</td><td>infinite / mix of decay &amp; cut-off</td></tr></table>

![](images/e95618beb0a23a03e825775ab7dc115d36183fe732e08f9529f68559c00a0476.jpg)

![](images/bfdf7da1e017660531bb6ca4122e4616279138967a2132a60363faaf69ebd44f.jpg)

It is important to know that with $A R M A ( p , q )$ processes, a wealth of autocorrelation structures can be generated. As to how visible the two cut-offs in ACF and PACF are, resp. whether the cut-off or the decay is dominating, depends on the model’s coefficients. There are ARMA’s where the AR part is dominating, there are others where the MA is stronger, and of course they can also be on an equal footing.

# 5.5.2 Fitting

The above properties of ACF and PACF can be exploited for choosing the type and order of a time series model. In particular, if neither the ACF nor the PACF shows a pronounced cut-off, where after some low lag (i.e. $p$ or $q < 1 0$ ) all the following correlations are non-significantly different from zero, then it is usually wise to choose an $A R M A ( p , q )$ . For determining the order $( p , q )$ , we search for the superimposed cut-off in the ACF (for $q$ ), respectively PACF (for $p$ ). The drop-off is not always easy to identify in practice. In “difficult” situations, it has also proven beneficial to support the choice of the right order with the AIC criterion. We could for example perform a grid search on all possible $A R M A ( p , q )$ models which do not use more than 5 parameters, i.e. $p + q < 5$ . This can readily be done in R by programming a for() loop.

It is very important to know that ARMA models are parsimonious, i.e. they usually do not require high orders $p$ and $q$ . In particular, they work well with far fewer parameters then pure AR or MA models would. Or in other words: often it is possible to fit high-order $A R ( p )$ ’s or MA q( ) ’s instead of a low-order $A R M A ( p , q )$ . That property does not come as a surprise: as we conjectured above, any stationary and invertible ARMA can be represented in the form of an $A R ( \infty )$ or an $M A ( \infty )$ . However, this is not a good idea in practice: estimating parameters “costs money”, i.e. will lead to less precise estimates. Thus, a low-order $A R M A ( p , q )$ is always to be preferred over a high-order $A R ( p )$ or $M A ( q )$ .

For estimating the coefficients, we are again confronted with the fact that there are no explicit estimators available. This is due to the MA component in the model which involves innovation terms that are unobservable. By rearranging terms in the model equation, we can again represent any $A R M A ( p , q )$ in a form where it only depends on the observed $X _ { t }$ , the coefficients $\alpha _ { 1 } , . . . , \alpha _ { { } _ { p } } ; \beta _ { 1 } , . . . , \beta _ { q }$ and some previous innovations $E _ { t }$ with $t < 1$ . If these latter terms are all set to zero, we can determine the optimal set of model coefficients by minimizing the sum of squared residuals (i.e. innovations) with a numerical method. This is the CSS approach that was already mentioned in 5.4.2 and is implemented in function arima() when method $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "CSS". By default however, these CSS estimates are only used as starting values for a MLE. If Gaussian innovations are assumed, then the joint distribution of any $A R M A ( p , q )$ process vector $\boldsymbol { X } = ( X _ { 1 } , . . . , X _ { n } )$ has a multivariate normal distribution.

$$
X = \left(X _ {1}, \dots , X _ {n}\right) \sim N (0, V), \text {r e s p .} Y = \left(Y _ {1}, \dots , Y _ {n}\right) \sim N (m \cdot \underline {{1}}, V).
$$

MLE then relies on determining the parameters m (if a shifted $A R M A ( p , q )$ is estimated), $\alpha _ { 1 } , . . . , \alpha _ { { } _ { p } } ; \beta _ { 1 } , . . . , \beta _ { q }$ and $\sigma _ { E } ^ { 2 }$ simultaneously by maximizing the probability density function of the above multivariate Gaussian with assuming the data $x _ { 1 } , . . . , x _ { n }$ as given quantities. This is a quite complex non-linear problem which needs to be solved numerically. A good implementation is found in R’s arima(). As was stated previously, the benefit of MLE is that (under mild and mostly met conditions) some optimality is guaranteed. In particular, the estimates are asymptotically normal with minimum variance among all asymptotically normal estimators. Another benefit is provided by the standard errors which allow for judging the precision of the estimates.

# 6 SARIMA and GARCH Models

As we have discovered previously, many time series are non-stationary due to deterministic trends and/or seasonal effects. While we have learned to remove these and then explain the remainder with some time series models, there are other models that can directly incorporate trend and seasonality. While they usually lack some transparency for the decomposition, their all-in-one approach allows for convenient forecasting, and also AIC-based decisions for choosing the right amount of trend and seasonality modeling become feasible.

Time series from financial or economic background often show serial correlation in the conditional variance, i.e. are conditionally heteroskedastic. This means that they exhibit periods of high and low volatility. Understanding the behavior of such series pays off, and the usual approach is to set up autoregressive models for the conditional variance. These are the famous ARCH models, which we will discuss along with their generalized variant, the GARCH class.

# 6.1 ARIMA Models

ARIMA models are aimed at describing series which exhibit a deterministic trend that can be removed by differencing; and where these differences can be described by an $A R M A ( p , q )$ model. Thus, the definition of an $A R I M A ( p , d , q )$ process arises naturally:

Definition: A series $X _ { t }$ follows an $A R I M A ( p , d , q )$ model if the $d$ th order difference of $X _ { t }$ is an $A R M A ( p , q )$ process. If we introduce

$$
Y _ {t} = (1 - B) ^ {d} X _ {t},
$$

where $B$ is the backshift operator, then we can write the ARIMA process using the characteristics polynomials, i.e. $\Theta ( \cdot )$ that accounts for the $A R$ , and $\Phi ( \cdot )$ that stands for the MA part.

$$
\Phi (B) Y _ {t} \quad = \Theta (B) E _ {t}
$$

$$
\Phi (B) (1 - B) ^ {d} X _ {t} = \Theta (B) E _ {t}
$$

Such series do appear in practice, as our example of the monthly prices for a barrel of crude oil (in $\mathsf { U S } \$ \Phi )$ ) from January 1986 to January 2006 shows. To stabilize the variance, we decide to log-transform the data, and model these.

$>$ library(TSA)   
$>$ data(oil.price)   
$>$ lop <- log(oil.price)   
$>$ plot(lop, ylab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "log(Price)")   
$>$ title("Logged Monthly Price for a Crude Oil Barrel")

![](images/26154aceab3b1bec6135cfdc85119b975acdb92c56617381b921975a3502ab4e.jpg)  
Logged Monthly Price for a Crude Oil Barrel

The series does not exhibit any apparent seasonality, but there is a clear trend, so that it is non-stationary. We try first-order (i.e. $d = 1$ ) differencing, and then check whether the result is stationary.

> dlop <- diff(lop)   
$>$ plot(dlop, ylab $\underline { { \underline { { \mathbf { \Pi } } } } } =$ "Differences")   
$>$ title("Differences of Logged Monthly Crude Oil Prices")

![](images/02e7fe411573f219cabb18ab39d326830b21e2a518d270c6bafcbf774a30c09d.jpg)  
Differences of Logged Monthly Crude Oil Prices

The trend was successfully removed by taking differences. ACF and PACF show that the result is serially correlated. There may be a drop-off in the ACF at lag 1, and in the PACF at either lag 1 or 2, suggesting an ARIMA(1,1,1) or an ARIMA(2,1,1) for the logged oil prices. However, the best performing model is somewhat surprisingly an ARIMA(1,1,2) , for which we show the results.

> par(mfrow $= _ { \mathsf { C } }$ (1,2))  
> acf(dlop, main ${ \bf \Phi } = { \bf \Phi }$ "ACF", ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1), lag.max=24)   
> pacf(dlop, main ${ \bf \Phi } = { \bf \Phi }$ "ACF", ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1), lag.max=24)

![](images/7fa2ce56272a6395af82caddab404a9cbb4bdc5502c8dd6d4dc5d44dc4684a36.jpg)  
ACF

![](images/243f1b3f66b6560d2eb50ff180a51ad2529bdff93aeee1dcf240b3b3282b6583.jpg)  
PACF

The fitting can be done with the arima() procedure that (by default) estimates the coefficients using Maximum Likelihood with starting values obtained from the Conditional Sum of Squares method. We can either let the procedure do the differencing:

> arima(lop, order $\Bumpeq _ { \mathsf { C } }$ (1,1,2))

Call:

arima( $\mathbf { \Phi } _ { \mathrm { ~ \bf ~ x ~ } } = \mathbf { \Phi } _ { \mathrm { ~ \bf ~ 1 0 p ~ } }$ , order = c(1, 1, 2))

Coefficients:

<table><tr><td></td><td>ar1</td><td>ma1</td><td>ma2</td></tr><tr><td></td><td>0.8429</td><td>-0.5730</td><td>-0.3104</td></tr><tr><td>s.e.</td><td>0.1548</td><td>0.1594</td><td>0.0675</td></tr></table>

sigma^2 = 0.006598: log likelihood $=$ 261.88, aic = -515.75

Or, we can use the differenced series dlop as input and fit an $A R M A ( 1 , 2 )$ . However, we need to tell R to not include an intercept – this is not necessary when the trend was removed by taking differences. The command is:

> arima(dlop, order $= _ { \mathsf { C } }$ (1,0,2), include.mean ${ \bf \Phi } = { \bf \Phi }$ FALSE)

The output from this is exactly the same as above. The next step is to perform residual analysis – if the model is appropriate, they must look like White Noise. This is (data not shown here) more or less the case. For decisions on the correct model order, also the AIC statistics can provide valuable information.

We finish this section by making some considerations on the model equation. We have:

$$
\begin{array}{l} Y _ {t} \quad = 0. 8 4 \cdot Y _ {t - 1} + E _ {t} - 0. 5 7 \cdot E _ {t - 1} - 0. 3 1 \cdot E _ {t - 2} \\ X _ {t} - X _ {t - 1} = 0. 8 4 \cdot \left(X _ {t - 1} - X _ {t - 2}\right) + E _ {t} - 0. 5 7 \cdot E _ {t - 1} - 0. 3 1 \cdot E _ {t - 2} \\ X _ {t} \quad = 1. 8 4 \cdot X _ {t - 1} - 0. 8 4 \cdot X _ {t - 2} + E _ {t} - 0. 5 7 \cdot E _ {t - 1} - 0. 3 1 \cdot E _ {t - 2} \\ \end{array}
$$

Thus, the ARIMA(1,1,2) can be rewritten as a non-stationary ARMA(2,2) . The nonstationarity is due to the roots of the AR characteristic polynomial, which are within the unit circle. Finally, we give some recipe for fitting ARIMA models:

1) Choose the appropriate order of differencing, usually $d = 1$ or (in rare cases) $d = 2$ , such that the result is a stationary series.   
2) Analyze ACF and PACF of the differenced series. If the stylized facts of an ARMA process are present, decide for the orders $p$ and $q$ .   
3) Fit the model using the arima() procedure. This can be done on the original series by setting $d$ accordingly, or on the differences, by setting $d = 0$ and argument include.mean $=$ FALSE.   
4) Analyze the residuals; these must look like White Noise. If several competing models are appropriate, use AIC to decide for the winner.

The fitted ARIMA model can then be used to generate forecasts including prediction intervals. This will, however, only be discussed in section 8.

# 6.2 SARIMA Models

After becoming acquainted with the ARIMA models, it is quite natural to ask for an extension to seasonal series; especially, because we learned that differencing at a lag equal to the period s does remove seasonal effects, too. Suppose we have a series $X _ { t }$ with monthly data. Then, series

$$
Y _ {t} = X _ {t} - X _ {t - 1 2} = (1 - B ^ {1 2}) X _ {t}
$$

has the seasonality removed. However, it is quite often the case that the result has not yet constant mean, and thus, some further differencing at lag 1 is required to achieve stationarity:

$$
Z _ {t} = Y _ {t} - Y _ {t - 1} = (1 - B) Y _ {t} = (1 - B) \left(1 - B ^ {1 2}\right) X _ {t} = X _ {t} - X _ {t - 1} - X _ {t - 1 2} + X _ {t - 1 3}
$$

We illustrate this using the Australian beer production series that we had already considered in section 4. It has monthly data that range from January 1958 to December 1990. Again, a log-transformation to stabilize the variance is indicated. On the next page, we display the original series $X _ { t }$ , the seasonally differenced series $Y _ { { t } }$ and finally the seasonal-trend differenced series $Z _ { t }$ .

> www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"   
> dat <- read.table(paste(www,"cbe.dat",sep="", heade $\mathtt { r } = \mathtt { T }$ )   
> beer <- ts(dat$beer, start=1958, freq=12)   
> d12.lbeer <- diff(log(beer), lag=12)   
> d.d12.lbeer <- diff(d12.lbeer)   
> plot(log(beer))   
> plot(d12.lbeer)   
> plot(d.d12.lbeer))

![](images/c0ece01a487a3a213bd4f0c3f946dbb59fe22a5058ffa5159ffe01e0f8749aae.jpg)  
Logged Australian Beer Production

![](images/97391e4aa8b69b0842884b6791a7667856f71d8c4f11839fe84e830cd8e3d3c3.jpg)  
Seasonally Differenced log(Beer) Series

![](images/f536c36baa050ee03474f032fc86c62aa818ae563b125532b3dd7e83847c4c7f.jpg)  
Additional Trend Removal Step

While the two series $X _ { t }$ and $Y _ { { t } }$ are non-stationary, the last one, $Z _ { t }$ may be, although it is a bit debatable whether the assumption of constant variation is violated or not. We proceed by analyzing ACF and PACF of series $Z _ { t }$ .

$>$ par(mfrow $= _ { \mathsf { C } }$ (1,2))  
$>$ acf(d.d12.lbeer, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1))   
$>$ pacf(d.d12.lbeer, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1), main $_ { . } =$ "PACF")

![](images/219557fec4c4303179cb53ef4b29582a233393cbe4658b047fab41a9f1b90946.jpg)  
ACF

![](images/6a645884a28294a241162c2c1ba9023f7baca0cc4701293b5634bd8aa81e1ef4.jpg)  
PACF

There is very clear evidence that series $Z _ { t }$ is serially dependent, and we could try an $A R M A ( p , q )$ to model this dependence. As for the choice of the order, this is not simple on the basis of the above correlograms. They suggest that high values for $p$ and $q$ are required, and model fitting with subsequent residual analysis and AIC inspection confirm this: $p = 1 4$ and $q = 1 1$ yield a good result.

It is (not so much in the above, but generally when analyzing data of this type) quite striking that the ACF and PACF coefficients have large values at multiples of the period s . This is very typical behavior for seasonally differenced series, in fact it originates from the evolution of resp. changes in the seasonality over the years. A simple model accounting for this is the so-called airline model:

$$
\begin{array}{l} Z _ {t} = (1 + \beta_ {1} B) \left(1 + \xi_ {1} B ^ {1 2}\right) E _ {t} \\ = \left(1 + \beta_ {1} B + \xi_ {1} B ^ {1 2} + \beta_ {1} \xi_ {1} B ^ {1 3}\right) E _ {t} \\ = E _ {t} + \beta_ {1} E _ {t - 1} + \xi_ {1} E _ {t - 1 2} + \beta_ {1} \xi_ {1} E _ {t - 1 3} \\ \end{array}
$$

This is a MA(13) model, where many of the coefficients are equal to 0. Because it was made up of an MA(1) with $B$ as an operator in the characteristic polynomial, and another one with $B ^ { s }$ as the operator, we call this a $S A R I M A ( 0 , 1 , 1 ) ( 0 , 1 , 1 ) ^ { 1 2 }$ . This idea can be generalized: we fit AR and MA parts with both $B$ and $B ^ { s }$ as operators in the characteristic polynomials, which again results in a high order ARMA model for $Z _ { t }$ .

Definition: A series $X _ { t }$ follows a $S A R I M A ( p , d , q ) ( P , D , Q ) ^ { s }$ process if the following equation holds:

$$
\Phi (B) \Phi_ {S} \left(B ^ {s}\right) Z _ {t} = \Theta (B) \Theta_ {S} \left(B ^ {s}\right) E _ {t},
$$

where series $Z _ { t }$ originated from $X _ { t }$ after appropriate seasonal and trend differencing, i.e. $Z _ { t } = ( 1 - B ) ^ { d } ( 1 - B ^ { s } ) ^ { D }$ .

Fortunately, it turns out that usually $d = D = 1$ is enough. As for the model orders $p , q , P , Q$ , the choice can be made on the basis of ACF and PACF, by searching for cut-offs. Mostly, these are far from evident, and thus, an often applied alternative is to consider all models with $p , q , P , Q \leq 2$ and doing an AIC-based grid search.

For our example, the 12 SARIMA(2,1,2)(2,1,2) has the lowest value and also shows satisfactory residuals, although it seems to perform slightly less well than the $S A R I M A ( 1 4 , 1 , 1 1 ) ( 0 , 1 , 0 ) ^ { 1 2 }$ . The R-command for the former is:

$>$ fit <- arima(log(beer), order $\Bumpeq { \bf c }$ (2,1,2), seasonal $= _ { \mathsf { C } }$ (2,1,2))

![](images/d7094d7f64f360c97357f4b41d2c87df81941c763d800be2046cd117b6ab7e71.jpg)  
Forecast of log(beer) with SARIMA(2,1,2)(2,1,2)

As it was mentioned in the introduction to this section, one of the main advantages of ARIMA and SARIMA models is that they allow for quick and convenient forecasting. While this will be discussed in depth later in section 8, we here provide a first example to show the potential.

From the logged beer production data, the last 2 years were omitted before the SARIMA model was fitted to the (shortened) series. On the basis of this model, a 2-year-forecast was computed, which is displayed by the red line in the plot above. The original data are shown as a solid (insample, 1958-1988) line, respectively as a dotted (out-of-sample, 1989-1990) line. We see that the forecast is reasonably accurate.

To facilitate the fitting of SARIMA models, we finish this chapter by providing some guidelines:

1) Perform seasonal differencing on the data. The lag $s$ is determined by the periodicity of the data, for the order, in most cases $D = 1$ is sufficient.   
2) Do a time series plot of the output of the above step. Decide whether it is stationary, or whether additional differencing at lag 1 is required to remove a potential trend. If not, then $d = 0$ , and proceed. If yes, $d = 1$ is enough for most series.   
3) From the output of step 2, i.e. series $Z _ { t }$ , generate ACF and PACF plots to study the dependency structure. Look for coefficients/cut-offs at low lags that indicate the direct, short-term dependency and determine orders $p$ and $q$ . Then, inspect coefficients/cut-offs at multiples of the period $s$ , which imply seasonal dependency and determine $P$ and $Q$ .   
4) Fit the model using procedure arima(). In contrast to ARIMA fitting, this is now exclusively done on the original series, with setting the two arguments order $\Bumpeq { \bf c }$ (p,d,q) and seasonal $= _ { \mathsf { C } }$ (P,D,Q) accordingly.   
5) Check the accuracy of the fitted model by residual analysis. These must look like White Noise. If thus far, there is ambiguity in the model order, AIC analysis can serve to come to a final decision.

Next, we turn our attention to series that have neither trend nor seasonality, but show serial dependence in the conditional variance.

# 6.3 ARCH/GARCH Models

In this chapter, we consider the SMI log-returns that were already presented in section 1.2.4. By closer inspection of the time series plot, we observe some longtailedness, and also, the series exhibits periods of increased variability, which is usually termed volatility in the (financial) literature. We had previously observed series with non-constant variation, such as the oil prices and beer production in the previous sections. Such series, where the variance increases with increasing level of the series, are called heteroskedastic, and can often be stabilized using a log-transformation.

However, that matter is different with the SMI log-returns: here, there are periods of increased volatility, and thus the conditional variance of the series is serially correlated, a phenomenon that is called conditional heteroskedasticity. This is not a violation of the stationarity assumption, but some special treatment for this type of series is required. Furthermore, the ACF of such series typically does not differ significantly from White Noise. Still, the data are not iid, which can be shown with the ACF of the squared observations. With the plots on the next page, we illustrate the presence of these stylized facts for the SMI log-returns:

![](images/d89110133d8b1d174dca46d39bba1b90bb9483c969652e9aa4065fb67a841601.jpg)

![](images/513ed73f9ace6c39ba8545ea00c0e4ef223ba5d1a0695b59f056ae596d3dc3d5.jpg)

![](images/b44eb70f99d663d1a5d7c829dbb6d1c4d7db9bbc580fc020101147479f20bbb6.jpg)

![](images/0e92094a8e21e2bdec2624f93c2483362caa76ca8bfebe61f20bad156ce30b85.jpg)

# 6.3.1 The ARCH and GARCH Models

In order to account for volatility, we require a model that reflects the dependency in the conditional variance. We operate under the assumption that:

$$
X _ {t} = \mu_ {t} + E _ {t},
$$

where the disturbance term $E _ { t }$ can be rewritten as $\sigma _ { t } W _ { t } \colon X _ { t } = \mu _ { t } + \sigma _ { t } W _ { t }$ . Here, W is a White Noise innovation and $\sigma _ { t } = V a r ( X _ { t } \mid X _ { t - 1 } , X _ { t - 2 } , \ldots )$ is the conditional variance that is assumed to be non-constant. Finally $\mu _ { t } = E [ X _ { t } | X _ { t - 1 } , X _ { t - 2 } , \ldots ]$ is the conditional expectation as before. It is perfectly allowed to have both dependence in the conditional mean and variance, and hence a mixture of ARMA and GARCH processes. However, for simplicity we assume throughout this section that both the conditional and the global mean are zero: $\mu = \mu _ { { } _ { t } } = 0$ and thus $X _ { t } = \sigma _ { t } W _ { t }$ .

The most simple and intuitive way of doing this is to use an autoregressive model for the variance process. Thus, a series $E _ { t }$ is first-order autoregressive conditional heteroskedastic, denoted as $A R C H ( 1 )$ , if:

$$
E _ {t} = W _ {t} \sqrt {\alpha_ {0} + \alpha_ {1} E _ {t - 1} ^ {2}}.
$$

Here, $W _ { t }$ is a White Noise process with mean zero and unit variance. The two parameters $\alpha _ { 0 } , \alpha _ { 1 }$ are the model coefficients. An ARCH (1) process shows volatility, as can easily be derived:

$$
\begin{array}{l} \operatorname {V a r} \left(E _ {t}\right) = E \left[ E _ {t} ^ {2} \right] \\ = E \left[ W _ {t} ^ {2} \right] E \left[ \alpha_ {0} + \alpha_ {1} E _ {t - 1} ^ {2} \right] \\ = E \left[ \alpha_ {0} + \alpha_ {1} E _ {t - 1} ^ {2} \right] \\ = \alpha_ {0} + \alpha_ {1} \cdot \operatorname {V a r} \left(E _ {t - 1}\right) \\ \end{array}
$$

Note that this derivation is based on $E [ W _ { t } ^ { 2 } ] = 1$ and $E [ E _ { t } ] = E [ W _ { t } ] = 0$ . As we had aimed for, the variance of an $A R C H ( 1 )$ process behaves just like an $A R ( 1 )$ model. Hence, the decay in the autocorrelations of the squared residuals should indicate whether an $A R C H ( 1 )$ is appropriate or not.

![](images/affbde1ed61fe9025fa63197afe98e4e34a6858d8d9b645e45aab6eaa8282d12.jpg)  
ACF of Squared Log-Returns

![](images/30bb6a302b491d0230e768101f6de8350db3b29217cddb6d505dd1b1731ad49f.jpg)  
PACF of Squared Log-Returns

In our case, the analysis of ACF and PACF of the squared log-returns suggests that the variance may be well described by an $A R ( 2 )$ process. This is not what we had discussed, but an extension exists. An $A R C H ( p )$ process is defined by:

$$
E _ {t} = W _ {t} \sqrt {\alpha_ {0} + \sum_ {i = 1} ^ {p} \alpha_ {p} E _ {t - i} ^ {2}}
$$

Fitting in R can be done using procedure garch(). This is a more flexible tool, which also allows for fitting GARCH processes, as discussed below. The command in our case is as follows:

$>$ fit <- garch(lret.smi, order = c(0,2), trace $=$ FALSE); fit Call: garch(x = lret.smi, order $=$ c(0, 2), trace $=$ FALSE) Coefficient(s):

a0 a1 a2 6.568e-05 1.309e-01 1.074e-01

For verifying appropriate fit of the $A R C H ( 2 )$ , we need to check the residuals of the fitted model. This includes inspecting ACF and PACF for both the “normal” and the squared residuals. We here do without showing plots, but the ARCH (2) is OK.

A nearby question is whether we can also use an $A R M A ( p , q )$ process for describing the dependence in the variance of the process. The answer is yes. This is what a $G A R C H ( p , q )$ model does. A series $E _ { t } = \dot { W } _ { t } \sqrt { H _ { t } }$ is $G A R C H ( p , q )$ if:

$$
H _ {t} = \alpha_ {0} + \sum_ {i = 1} ^ {q} \alpha_ {i} E _ {t - i} ^ {2} + \sum_ {j = 1} ^ {p} \beta_ {j} H _ {t - j}
$$

# 6.3.2 Use of GARCH Models

GARCH models are useless for the prediction of the level of a series, i.e. for the SMI log-returns, they do not provide any idea whether the stocks’ value will increase or decrease on the next day. However, they allow for a more precise understanding in the (up or down) changes that might be expected during the next day(s). This allows stockholders to adjust their position, so that they do not take any unduly risks.

# 7 Time Series Regression

# 7.1 What Is the Problem?

It is often the case that we aim for describing some time series $Y _ { _ t }$ with a linear combination of some explanatory series $x _ { t 1 } , . . . , x _ { t p }$ . As we will see below, the predictors can either be true covariates, or terms that are derived from time, as for example linear trends or seasonal effects. We employ the universally known linear model for linking the response series with the predictors:

$$
Y _ {t} = \beta_ {0} + \beta_ {1} x _ {t 1} + \dots + \beta_ {p} x _ {t p} + E _ {t}
$$

The regression coefficients $\beta _ { 1 } , . . . , \beta _ { p }$ are usually estimated with the least squares algorithm, for which an error term with zero expectation, constant variation and no correlation is assumed. However, if response and predictors are time series with autocorrelation, the last condition often turns out to be violated, though this is not always the case.

Now, if we are facing a (time series) regression problem with correlated errors, the estimates $\hat { \beta } _ { j }$ will remain being unbiased, but the least squares algorithm is no longer efficient. Or in other words: more precisely working estimators exist. Even more problematic are the standard errors of the regression coefficients $\hat { \beta } _ { j }$ : they are often grossly wrong in case of correlated errors. As they are routinely underestimated, inference on the predictors often yields spurious significance, i.e. one is prone to false conclusions from the analysis.

Thus, there is a need for more general linear regression procedures that can deal with serially correlated errors, and fortunately, they exist. We will here discuss the simple, iterative Cochrane-Orcutt procedure, and the Generalized Least Squares method, which marks a theoretically sound approach to regression with correlated errors. But first, we present some time series regression problems to illustrating what we are dealing with.

# Example 1: Global Temperature

In climate change studies time series with global temperature values are analyzed. The scale of measurement is anomalies, i.e. the difference between the monthly global mean temperature versus the overall mean between 1961 and 1990. The data can be obtained at http://www.cru.uea.ac.uk/cru/data. For illustrative purposes, we here restrict to a period from 1971 to 2005 which corresponds to a series of 420 records. For a time series plot, see the next page.

```r
> ## Time Series Plot
> my.temp <- window(global, c(1971, 1), c(2005, 12))
> plot(my.temp, ylab="anomaly")
> title("Global Temperature Anomalies") 
```

![](images/92d954de4fd1691f719c75d368807d9cb604453522b67667f28cc3abf92118a3.jpg)  
Global Temperature Anomalies

There is a clear trend which seems to be linear. Despite being monthly measured, the data show no evident seasonality. This is not overly surprising, since we are considering a global mean, i.e. the season should not make for a big difference. But on the other hand, because the landmass is not uniformly distributed over both halves of the globe, it could still be present. It is natural to try a season-trenddecomposition for this series. We will employ a parametric model featuring a linear trend plus a seasonal factor.

$$
Y _ {t} = \beta_ {0} + \beta_ {1} \cdot t + \beta_ {2} \cdot 1 _ {\left[ m o n t h = ^ {\prime \prime} F e b ^ {\prime \prime} \right]} + \dots + \beta_ {1 2} \cdot 1 _ {\left[ m o n t h = ^ {\prime \prime} D e c ^ {\prime \prime} \right]} + E _ {t},
$$

where t  1, , 420 and [ " "]1 month Feb $t = 1 , . . . , 4 2 0$ $1 _ { [ m o n t h = " F e b " ] }$ is a dummy variable that takes the value 1 if an observation is from month February, and zero else. Clearly, this is a time series regression model. The response $Y _ { { t } }$ is the global temperature anomalies, and even the predictors, i.e. the time and the dummies, can be seen as time series, even if simple ones.

As we have seen previously, the goal with such parametric decomposition models is to obtain a stationary remainder term $E _ { t }$ . But stationary does not necessarily mean White Noise, and in practice it often turns out that $E _ { t }$ shows some serial correlation. Thus, if the regression coefficients are obtained from the least squares algorithm, we apparently feature some violated assumption.

This violation can be problematic, even in an applied setting: a question of utter importance with the above series is whether trend and seasonal effect are significantly present. It would be nice to answer such questions using the inference approaches (tests and confidence intervals) that linear regression provides. However, for obtaining reliable inference results, we need to account for the correlation among the errors. We will show this below, after introducing some more examples and theory.

# Example 2: Air Pollution

In this second example, we consider a time series that is stationary, and where the regression aims at understanding the series, rather than decomposing it into some deterministic and random components. We examine the dependence of a photochemical pollutant (morning maximal value) on the two meteorological variables wind and temperature. The series, which constitute of 30 observations taken on consecutive days, come from the Los Angeles basin. They are not publicly available, but can be obtained from the lecturer upon request.

$>$ ## Importing the data   
$>$ tmp <- read.table("pollute.dat", header $=$ TRUE)   
$>$ dat <- ts.union(Oxidant $=$ ts(tmp$Oxidant), Wind $\underline { { \underline { { \mathbf { \Pi } } } } } =$ ts(tmp$Wind), Temp ${ } _ { 1 } = { } ^ { \prime }$ ts(tmp$Temp))   
> ## Visualizing the data   
$>$ plot(dat, main ${ \bf \Phi } = { \bf \Phi }$ "Air Pollution Data")

![](images/20e3c356de1f386c5d0a86d6aa296bea07d90a883ea696bc6f2cf3c2e6aba323.jpg)  
Air Pollution Data

There is no counterevidence to stationarity for all three series. What could be the goal here? Well, we aim for enhancing the understanding of how the pollution depends on the meteorology, i.e. what influence wind and temperature have on the oxidant values. We can naturally formulate the relation with a linear regression model:

$$
Y _ {t} = \beta_ {0} + \beta_ {1} x _ {t 1} + \beta_ {2} x _ {t 2} + E _ {t}.
$$

In this model, the response $Y _ { { t } }$ is the oxidant, and as predictors we have $x _ { t 1 }$ , wind, and $x _ { t 2 }$ , the temperature. For the index, we have $t = 1 , . . . , 3 0$ , and obviously, this is a time series regression model.

For gaining some more insight with these data, it is also instructive to visualize the data using a pairs plot, as shown on the next page. There, a strong, positive linear

association is recognizable between pollutant and the temperature. In contrast, there is a negative linear relation between pollutant and wind. Lastly, between the predictors wind and temperature, there is not much of a correlation. This data structure is not surprising because wind causes a stronger movement of the air and thus the pollutant is "better" distributed. Also, the wind causes some cooling.

![](images/202022fbba6eef2fd5753a4cdc458df80e3e3eddf6efecddf0353b7587480c46.jpg)

For achieving our practical goals with this dataset, we require precise and unbiased estimates of the regression coefficients $\beta _ { 1 }$ and $\beta _ { 2 }$ . Moreover, we might like to give some statements about the significance of the predictors, and thus, we require some sound standard errors for the estimates. However, also with these data, it is well conceivable that the error term $E _ { t }$ will be serially correlated. Thus again, we will require some procedure that can account for this.

# Time Series Regression Model

The two examples have shown that time series regression models do appear when decomposing series, but can also be important when we try to understand the relation between response and predictors with measurements that were taken sequentially. Generally, with the model

$$
Y _ {t} = \beta_ {0} + \beta_ {1} x _ {t 1} + \dots + \beta_ {p} x _ {t p} + E _ {t}
$$

we assume that the influence of the series $x _ { t 1 } , . . . , x _ { t p }$ on the response $Y _ { _ t }$ is simultaneous. Nevertheless, lagged variables are also allowed, i.e. we can also use terms such as $x _ { ( t - k ) ; j }$ with $k > 0$ as predictors. While this generalization can be easily built into our model, one quickly obtains models with many unknown parameters. Thus, when exploring the dependence of a response series to lags of some predictor series, there are better approaches than regression. In particular, this is the cross correlations and the transfer function model, which will be exhibited in later chapters of this scriptum.

In fact, there are not many restrictions for the time series regression model. As we have seen, it is perfectly valid to have non-stationary series as either the response or as predictors. However, it is crucial that there is no feedback from $Y _ { _ t }$ to the $x _ { t j }$ . Additionally, the error $E _ { t }$ must be independent of the explanatory variables, but it may exhibit serial correlation.

# 7.2 Finding Correlated Errors

When dealing with a time series regression problem, we first always assume uncorrelated errors and start out with an ordinary least squares regression. Based on its residuals, the assumption can be verified, and if necessary, action can be taken. For identifying correlation among the residuals, we analyze their time series plot, ACF and PACF.

# Example 1: Global Temperature

Our goal is the decomposition of the global temperature series into a linear trend plus some seasonal factor. First and foremost, we prepare the data:

```r
> num.temp <- as.numeric(my.temp)  
> num.time <- as.numeric(time(my.temp))  
> mn01 <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun")  
> mn02 <- c("Jul", "Aug", "Sep", "Oct", "Nov", "Dec")  
> month <- factor Cycling(my.temp), labels=c(mn01, mn02))  
> dat <- data.frame(temp=num.temp, time=num.time, month) 
```

The regression model is the estimated with R’s function lm(). The summary function returns estimates, standard errors plus the results from some hypothesis tests. It is important to notice that all of these results are in question should the errors turn out to be correlated.

```r
> fit.lm <- lm(temp ~ time + season, data=dat)  
> summary(fit.lm) 
```

```txt
Call:  
lm(formula = temp ~ time + season, data = dat) 
```

```txt
Residuals: Min 1Q Median 3Q Max -0.36554 -0.07972 -0.00235 0.07497 0.43348
```

```typescript
Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -3.603e+01 1.211e+00 -29.757 <2e-16 *** time 1.822e-02 6.089e-04 29.927 <2e-16 *** seasonFeb 6.539e-03 3.013e-02 0.217 0.8283 seasonMar -1.004e-02 3.013e-02 -0.333 0.7392 seasonApr -1.473e-02 3.013e-02 -0.489 0.6252 seasonMay -3.433e-02 3.013e-02 -1.139 0.2552 
```

<table><tr><td>seasonJun</td><td>-2.628e-02</td><td>3.013e-02</td><td>-0.872</td><td>0.3836</td></tr><tr><td>seasonJul</td><td>-2.663e-02</td><td>3.013e-02</td><td>-0.884</td><td>0.3774</td></tr><tr><td>seasonAug</td><td>-2.409e-02</td><td>3.013e-02</td><td>-0.799</td><td>0.4245</td></tr><tr><td>seasonSep</td><td>-3.883e-02</td><td>3.013e-02</td><td>-1.289</td><td>0.1982</td></tr><tr><td>seasonOct</td><td>-5.212e-02</td><td>3.013e-02</td><td>-1.730</td><td>0.0844</td></tr><tr><td>seasonNov</td><td>-6.633e-02</td><td>3.013e-02</td><td>-2.201</td><td>0.0283</td></tr><tr><td>seasonDec</td><td>-4.485e-02</td><td>3.013e-02</td><td>-1.488</td><td>0.1374</td></tr><tr><td>---</td><td></td><td></td><td></td><td></td></tr></table>

Residual standard error: 0.126 on 407 degrees of freedom Multiple R-squared: 0.6891, Adjusted R-squared: 0.68 F-statistic: 75.18 on 12 and 407 DF, p-value: < 2.2e-16

As the next step, we need to perform some residual diagnostics. The plot() function, applied to a regression fit, serves as a check for zero expectation, constant variation and normality of the errors, and can give hints on potentially problematic leverage points.

```txt
> par(mfrow=c(2,2))  
> plot(fit.lm, pch=20) 
```

![](images/4962c0c058ebfe503c6758085de2daa6cdb8ac60794897c6cd321321038c3024.jpg)

![](images/324e80ee7ed6525a48ab491f003881c2b4558781392b3347e9d9c701e56e7d64.jpg)

![](images/e50df072a1b91b430cb63692467e2a14a0ffc89b6e5e5c173a67145e92bd563c.jpg)

![](images/9680db4a6af4b83ca9e9d7ccd44f83c79e6ab52a779975c42ed4317d285e6c9e.jpg)

Except for some very slightly long tailed errors, which do not require any action, the residual plots look fine. What has not yet been verified is whether there is any serial correlation among the residuals. If we wish to see a time series plot, the following commands are useful:

> plot(dat$time, resid(fit.lm), type="l")

![](images/f214025708a509f29b410dc2c8ddf801581543d95072511306cfbfb4ac12171c.jpg)  
Residuals of the lm() Function

It is fairly obvious from the time series plot that the residuals are correlated. Our main tool for describing the dependency structure is the ACF and PACF plots, however. These are as follows:

$>$ par(mfrow $\scriptstyle \mathbf { \bar { \mathbf { \alpha } } } = \mathbf { \mathbf { \alpha } }$ (1,2))  
$>$ acf(resid(fit.lm), main ${ \bf \Phi } = { \bf \Phi }$ "ACF of Residuals")   
$>$ pacf(resid(fit.lm), main ${ \bf \Phi } = { \bf \Phi }$ "PACF of Residuals")

![](images/2eac8e629c6554586299247a17a05b5f39d1700b4eae45757d707330e57e2229.jpg)  
ACF of Residuals

![](images/f062020aa032779fbabe9856c2257ccb50f418558327a0c50b84c879ad80193e.jpg)  
PACF of Residuals

The ACF shows a rather slow exponential decay, whereas the PACF shows a clear cut-off at lag 2. With these stylized facts, it might well be that an AR(2)

model is a good description for the dependency among the residuals. We verify this:

>fit.ar2<-ar.burg(resid(fit.lm));fit.ar2   
Call:ar.burg.default $\mathbf{\Phi}(\mathbf{x} =$ resid(fit.lm))   
Coefficients: 1 2   
0.4945 0.3036   
Order selected 2 sigma^2 estimated as 0.00693

When using Burg’s algorithm for parameter estimation and doing model selection by AIC, order 2 also turns out to be optimal. For verifying an adequate fit, we visualize the residuals from the AR(2) model. These need to look like White Noise.

![](images/defdd9e4623a19476dde4ac88653a7db316a0eab00a65b5dcf1e3734356b0b95.jpg)  
Residuals of AR(2)

![](images/d6fbf0f7de28639ed99ce483f833d934cd22dc21d51f79d5d7f4387b72615071.jpg)  
ACF of AR(2) Residuals

![](images/94e01cad5360a094353cc57eb7f3fad4ca3eb97130472e167c9d42ea0360bd5c.jpg)  
ACF of AR(2) Residuals

There is no contradiction to the White Noise hypothesis for the residuals from the $A R ( 2 )$ model. Thus, we can summarize as follows: the regression model that was used for decomposing the global temperature series into a linear trend and a seasonal factor exhibit correlated errors that seem to originate from an AR(2) model. Theory tells us that the point estimates for the regression coefficients are still unbiased, but they are no longer efficient. Moreover, the standard errors for these coefficients can be grossly wrong. Thus, we need to be careful with the regression summary approach that was displayed above. And since our goal is inferring significance of trend and seasonality, we need to come up with some better suited method.

# Example 2: Air Pollution

Now, we are dealing with the air pollution data. Again, we begin our regression analysis using the standard assumption of uncorrelated errors. Thus, we start out by applying the lm() function and printing the summary().

```r
> fit.lm <- lm(Oxidant ~ Wind + Temp, data=dat)  
> summary(fit.lm) 
```

```txt
Call:  
lm(formula = Oxidant ~ Wind + Temp, data = dat) 
```

```txt
Residuals: Min 1Q Median 3Q Max -6.3939 -1.8608 0.5826 1.9461 4.9661 
```

```typescript
Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -5.20334 11.11810 -0.468 0.644 Wind -0.42706 0.08645 -4.940 3.58e-05 *** Temp 0.52035 0.10813 4.812 5.05e-05 *** 
```

```txt
Residual standard error: 2.95 on 27 degrees of freedom  
Multiple R-squared: 0.7773, Adjusted R-squared: 0.7608  
F-statistic: 47.12 on 2 and 27 DF, p-value: 1.563e-09 
```

We will do without showing the 4 standard diagnostic plots, and here only report that they do not show any model violations. Because we are performing a time series regression, we also need to check for potential serial correlation of the errors. As before, this is done on the basis of time series plot, ACF and PACF:

```txt
> plot(1:30, resid(fit.lm), type="l")
> title("Residuals of the lm() Function")
> par(mfrow=c(1,2))
> acf(resid(fit.lm),ylim=c(-1,1), main="ACF of Residuals")
> pacf(resid(fit.lm),ylim=c(-1,1), main="PACF of Residuals") 
```

![](images/36ff01a99fcb38f57886ea3cd30342abbaab0a3091a1508cabb997bcc49f23dd.jpg)  
Residuals of the lm() Function

![](images/8915ea58aab21d46fd50a4748ebf42db20e5ddd0970a7f0b82475a9beef49325.jpg)  
ACF of Residuals

![](images/4557e4027090f60d91a2266ddded3c152ba41868615ef003de41af25c1f0de71.jpg)  
PACF of Residuals

Also in this example, the time series of the residuals exhibits serial dependence. Because the ACF shows an exponential decay and the PACF cuts off at lag 1, we hypothesize that an $A R ( 1 )$ model is a good description. While the AIC criterion suggests an order of $p = 1 4$ , the residuals of an $A R ( 1 )$ show the behavior of White Noise. Additionally, using an $A R ( 1 4 )$ would be spending too many degrees of freedom for a series with only 30 observations.

Thus, we can summarize that also in our second example with the air pollution data, we feature a time series regression that has correlated errors. Again, we must not communicate the above regression summary and for sound inference, we require more sophisticated models.

# 7.2.1 Durbin-Watson Test

For the less proficient user, hypothesis tests always seem like an attractive alternative to visual inspection of graphical output. This is certainly also the case when the task is identifying a potential serial correlation in a regression analysis. Indeed, there is a formal test that addresses the issue, called the Durbin-Watson test. While we will here briefly go into it, we do not recommend it for practical application.The Durbin-Watson test tests the null hypothesis $H _ { 0 } : \rho ( 1 ) = 0$ against the alternative $H _ { \mathrm { \ell } _ { A } } : \rho ( 1 ) \neq 0$ . The test statistic $\hat { D }$ is calculated as follows

$$
\hat {D} = \frac {\sum_ {t = 2} ^ {n} (r _ {t} - r _ {t - 1}) ^ {2}}{\sum_ {t = 1} ^ {n} r _ {t} ^ {2}}
$$

where $\boldsymbol { r } _ { t } = \boldsymbol { y } _ { t } - \boldsymbol { \hat { y } } _ { t }$ is the residual from the regression model, observed at time $t$ . There is an approximate relationship between the test statistic $\hat { D }$ and the autocorrelation coefficient at lag 1:

$$
\hat {D} \approx 2 (1 - \hat {\rho} (1))
$$

The test statistic takes values between 0 if $r _ { t } = r _ { t - 1 }$ and 4 if $r _ { t } = r _ { t - 1 }$ . These extremes indicate perfect correlation of the residuals. Values around 2, on the other hand, are evidence for uncorrelated errors. The exact distribution of $\hat { D }$ is rather difficult to derive. However, we do not need to bother with this. The R package lmtest holds an implementation of the Durbin-Watson test with function dwtest(), where the p-value is either (for large sample size) determined by a normal approximation, or (for short series) by an iterative procedure.

# Example 1: Global Temperature

```txt
> dwtest fit.lm)  
data: fit.lm  
DW = 0.5785, p-value < 2.2e-16  
alt. hypothesis: true autocorrelation is greater than 0 
```

# Example 2: Air Pollution

```txt
> dwtest (fit.lm)  
data: fit.lm  
DW = 1.0619, p-value = 0.001675  
alt. hypothesis: true autocorrelation is greater than 0 
```

Thus, the null hypothesis is rejected in both examples and we come to the same conclusion (“errors are correlated”) as with our visual inspection. It is very important to note that this is not necessary: In cases where the errors follow an $A R ( p )$ process where $p > 1$ and $| \rho ( 1 ) |$ is small, the null hypothesis will not be rejected despite the fact that the errors are correlated.

# 7.3 Cochrane-Orcutt Method

The goal of this section is to solve the time series regression problem with errors that have an $A R ( 1 )$ structure. This simple case is illustrative and helps to build the comprehension for more complicated error dependencies. We consider the Air Pollution example, where we have:

$$
Y _ {t} = \beta_ {0} + \beta_ {1} x _ {t 1} + \beta_ {2} x _ {t 2} + E _ {t} \text {w i t h} E _ {t} = \alpha E _ {t - 1} + U _ {t}, \text {w h e r e} U _ {t} \sim N \left(0, \sigma_ {U} ^ {2}\right) i i d.
$$

The fundamental trick, on which in fact all time series regression methods are based will be presented here and now. We make the transformation:

$$
Y _ {t} ^ {\prime} = Y _ {t} - \alpha Y _ {t - 1}
$$

Next, we plug-in the model equation and rearrange the terms. Finally, we build on the fundamental property that $E _ { t } - \alpha E _ { t - 1 } = U _ { t }$ . The result is:

$$
\begin{array}{l} Y _ {t} ^ {\prime} = \beta_ {0} + \beta_ {1} x _ {t 1} + \beta_ {2} x _ {t 2} + E _ {t} - \alpha \left(\beta_ {0} + \beta_ {1} x _ {t - 1, 1} + \beta_ {2} x _ {t - 1, 2} + E _ {t - 1}\right) \\ = \beta_ {0} (1 - \alpha) + \beta_ {1} \left(x _ {t 1} - x _ {t - 1, 1}\right) + \beta_ {2} \left(x _ {t 2} - x _ {t - 1, 2}\right) + E _ {t} - \alpha E _ {t - 1} \\ = \beta_ {0} ^ {\prime} + \beta_ {1} x _ {t 1} ^ {\prime} + \beta_ {2} x _ {t 2} ^ {\prime} + U _ {t} \\ \end{array}
$$

Obviously, this is a time series regression problem where the error term $U _ { t }$ is iid. Also note that both the response and the predictors have undergone a transformation. The coefficients however, are identical in both the original and the modified regression equation. For implementing this approach in practice, we require knowledge about the $A R ( 1 )$ parameter $\alpha$ . Usually, it is not known previously. A simple idea to overcome this and solve the time series regression problem for the Air Pollution data is as follows:

1) Run OLS regression to obtain estimates $\hat { \beta } _ { 0 } , . . . , \hat { \beta } _ { p }$   
2) Estimate an $A R ( 1 )$ on the OLS residuals to obtain $\hat { \alpha }$   
3) Determine the prime variables $Y ^ { \prime } ; x ^ { \prime }$ and derive $\hat { \beta } _ { 0 } ^ { * } , \hat { \beta } _ { 1 } , . . . , \hat { \beta } _ { p }$ by OLS

This procedure is know as the Cochrane-Orcutt iterative method. Please note that the estimates $\hat { \beta } _ { 0 } ^ { \prime } , \hat { \beta } _ { 1 } , . . . , \hat { \beta } _ { p }$ and their standard errors from the OLS regression in step 3) are sound and valid. But while the Cochrane-Orcutt procedure has its historical importance and is very nice for illustration, it lacks of a direct R implementation, and, as an iterative procedure, also of mathematical closeness and quality. The obvious improvement is to solve the prime regression problem by simultaneous Maximum-Likelihood estimation of all parameters:

$$
\beta_ {0}, \dots \beta_ {p}; \alpha ; \sigma_ {U} ^ {2}
$$

This is possible and implemented in the R function gls(). Also, we need to be able to handle more complicated structure for the regression error $E _ { t }$ . For this, we resort to matrix notation, see the next section.

# 7.4 Generalized Least Squares

The ordinary least squares regression model assumes that $V a r ( E ) = \sigma ^ { 2 } I$ , i.e. the covariance matrix of the errors is diagonal with identical values on the diagonal itself. As we have seen in our examples above, this is not a good model for time series regression. There, we rather have $V a r ( E ) = \sigma ^ { 2 } \Sigma$ , where $\Sigma$ reports the correlation among the errors. Using a Cholesky decomposition, we can write $\Sigma = S S ^ { T }$ , where S is a triangular matrix. This allows us to rewrite the regression model in matrix notation as follows:

$$
\begin{array}{l} y = X \beta + E \\ S ^ {- 1} y = S ^ {- 1} X \beta + S ^ {- 1} E \\ y ^ {\prime} \quad = X ^ {\prime} \beta + E ^ {\prime} \\ \end{array}
$$

This transformation is successful, because in the prime model, we have uncorrelated errors again:

$$
V a r (E) = V a r (S ^ {- 1} E) = S ^ {- 1} V a r (E) S ^ {- T} = S ^ {- 1} \sigma^ {2} S S ^ {T} S ^ {- T} = \sigma^ {2} I
$$

With some algebra, it is easy to show that the estimated regression coefficients for the generalized least squares approach turn out to be:

$$
\hat {\boldsymbol {\beta}} = \left(X ^ {T} \Sigma^ {- 1} X\right) X ^ {T} \Sigma^ {- 1} y
$$

This is what is known as the generalized least squares estimator. Moreover, the covariance matrix of the coefficient vector is:

$$
V a r (\hat {\beta}) = \left(X ^ {T} \Sigma^ {- 1} X\right) ^ {- 1} \sigma^ {2}
$$

This covariance matrix then also contains standard errors in which the correlation of the errors has been accounted for, and with which sound inference is possible. However, while this all neatly lines up, we of course require knowledge about the error covariance matrix $\Sigma$ , which is generally unknown in practice. What we can do is estimate it from the data, for which two approaches exist.

# Cochrane-Orcutt Method

As we have seen above, this method is iterative: it starts with an ordinary least squares (OLS) regression, from which the residuals are determined. For these residuals, we can then fit an appropriate $A R M A ( p , q )$ model and with its estimated model coefficients $\alpha _ { 1 } , . . . , \alpha _ { p }$ and $\beta _ { 1 } ^ { M A ( q ) } , . . . , \beta _ { q } ^ { M A ( q ) }$ . On the basis of the estimated $A R ( M A )$ model coefficients, an estimate of the error covariance matrix $\Sigma$ can be derived. We denote it by $\hat { \Sigma }$ , and plug it into the formulae presented above. This yields adjusted regression coefficients and correct standard errors for these regression problems. As mentioned above, the iterative approach is secondary to a simultaneous MLE. Thus, we do without further performing Cochrane-Orcutt on our examples.

# The gls() Procedure

A better, yet more sophisticated approach is to estimate the regression coefficients and the ARMA parameters simultaneously. This can be done using the Maximum-Likelihood principle. Even under the assumption of Gaussian errors, this is a nonlinear and numerically difficult problem. However, for practical application, we do not need to worry. The R package nlme features the gls() procedure which tackles this problem. Thus, we focus on correct application of the R function.

# Example 1: Global Temperature

Every GLS regression analysis starts by fitting an OLS an analyzing the residuals, as we have done above. Remember that the only model violation we found were correlated residuals that were well described with an $A R ( 2 )$ model. Please note that for performing GLS, we need to provide a dependency structure for the errors. Here, this is the $A R ( 2 )$ model, in general, it is an appropriate $A R M A ( p , q )$ . The syntax and output is as follows:

```txt
> library(nlme)  
> corStruct <- corARMA(form~=time, p=2)  
> fit.gls <- gls(temp~time+season, data=dat, corr=corStruct)  
> fit.gls  
Generalized least squares fit by REML  
Model: temp ~ time + season  
Data: dat  
Log-restricted-likelihood: 366.3946 
```

```txt
Coefficients: (Intercept) time seasonFeb seasonMar -39.896981987 0.020175528 0.008313205 -0.006487876 seasonApr seasonMay seasonJun seasonJul -0.009403242 -0.027232895 -0.017405404 -0.015977913 seasonAug seasonSep seasonOct seasonNov -0.011664708 -0.024637218 -0.036152584 -0.048582236 seasonDec -0.025326174 
```

```txt
Correlation Structure: ARMA(2,0)  
Formula: ~time  
Parameter estimate(s):  
    Phi1 Phi2  
0.5539900 -0.1508046  
Degrees of freedom: 420 total; 407 residual  
Residual standard error: 0.09257678 
```

The result reports the regression and the AR coefficients. Using the summary() function, even more output with all the standard errors can be generated. We omit this here and instead focus on the necessary residual analysis for the GLS model. We can extract the residuals using the usual resid() command. Important: these

residuals must not look like White Noise, but as from an $A R M A ( p , q )$ with orders $p$ and $q$ as provided in the corStruct object – which in our case, is an $A R ( 2 )$ .

$>$ par(mfrow $\scriptstyle \mathbf { \bar { \mathbf { \alpha } } } = \mathbf { \mathbf { \alpha } }$ (1,2))  
$>$ acf(resid(fit.gls), main ${ \bf \Phi } = { \bf \Phi }$ "ACF of GLS-Residuals")   
$>$ pacf(resid(fit.gls), main ${ \bf \Phi } = { \bf \Phi }$ "PACF of GLS-Residuals")

![](images/b054e0a199038070e4e6a0dbf589226d8172baa95139b6845b3223248908782e.jpg)  
ACF of GLS-Residuals

![](images/5678287c5f71aec0a6174a6e6dea1309a75da4d60a758ce6a2c35ec710cdd91e.jpg)  
PACF of GLS-Residuals

The plots look similar to the ACF/PACF plots of the OLS residuals. This is often the case in practice, only for more complex situations, there can be a bigger discrepancy. And because we observe an exponential decay in the ACF, and a clear cut-off at lag 2 in the PACF, we conjecture that the GLS residuals meet the properties of the correlation structure we hypothesized, i.e. of an AR(2) model. Thus, we can now use the GLS fit for drawing inference. We first compare the OLS and GLS point estimate for the trend, along with its confidence interval:

```txt
> coef.fit.lm)[time"] time   
0.01822374   
> confint.fit.lm, "time") 2.5% 97.5%   
time 0.01702668 0.0194208   
> coef.fit.gls)[time"] time   
0.02017553   
> confint.fit.gls, "time") 2.5% 97.5%   
time 0.01562994 0.02472112 
```

We obtain a temperature increase of 0.0182 degrees per year with the OLS, and of 0.0202 with the GLS. While this may seem academic, the difference among the point estimates is around $10 \%$ , and theory tells us that the GLS result is more reliable. Moreover, the length of the confidence interval is 0.0024 with the OLS,

and 0.0091 and thus 3.5 times as large with the GLS. Thus, without accounting for the dependency among the errors, the precision of the trend estimate is by far overestimated. Nevertheless, also the confidence interval obtained from GLS regression does not contain the value 0, and thus, the null hypothesis on no global warming trend is rejected (with margin!).

Finally, we investigate the significance of the seasonal effect. Because this is a factor variable, i.e. a set of dummy variables, we cannot just produce a confidence interval. Instead, we have to rely on a significance test, i.e. a partial F-test. Again, we compare what is obtained from OLS and GLS:

```txt
> drop1(fit.lm, test="F")  
Single term deletions  
Model:  
temp ~ time + season  
Df Sum of Sq RSS AIC F value Pr(F)  
<none> 6.4654 -1727.0  
time 1 14.2274 20.6928 -1240.4 895.6210 <2e-16 ***  
season 11 0.1744 6.6398 -1737.8 0.9982 0.4472  
> anova(fit.gls)  
Denom. DF: 407  
numDF F-value p-value  
(Intercept) 1 78.40801 <.0001  
time 1 76.48005 <.0001  
season 11 0.64371 0.7912 
```

As for the trend, the result is identical with OLS and GLS. The seasonal effect is non-significant with p-values of 0.45 (OLS) and 0.79 (GLS). Again, the latter is the value we must believe in. We conclude that there is no seasonality in global warming – but there is a trend.

# Example 2: Air Pollution

For finishing the air pollution example, we also perform a GLS fit here. We identified an AR(1) as the correct dependency structure for the errors. Thus, we define it accordingly:

> dat <- cbind(da,t time=1:30)  
> corStruct <- corARMA(form $\equiv$ ~time, p=1)  
> model <- formula(Oxidant ~ Wind + Temp)  
> fit.gls <- gls(model, data $\equiv$ dat, correlation $\equiv$ corStruct)

The output then is as follows:

```txt
> fit.gls  
Generalized least squares fit by REML  
Model: model  
Data: dat  
Log-restricted-likelihood: -72.00127 
```

```txt
Coefficients: (Intercept) Wind Temp -3.7007024 -0.4074519 0.4901431   
Correlation Structure: AR(1) Formula: \~time Parameter estimate(s): Phi 0.5267549   
Degrees of freedom: 30 total; 27 residual Residual standard error: 3.066183 
```

Again, we have to check if the GLS residuals show the stylized facts of an $A R ( 1 )$

![](images/67373296d12ca1f5b2c80f08e723be91ed9b0a8897e4801445977668ffc1706b.jpg)

![](images/a45c081030e52b2f1473419cfe306fff8921be4c879ca696053c8cf06721acd6.jpg)

This is the case, and thus we can draw inference from the GLS results. The confidence intervals of the regression coefficients are:

```txt
> confint (fit.lm, c("Wind", "Temp")) 2.5 % 97.5 %  
Wind -0.6044311 -0.2496841  
Temp 0.2984794 0.7422260  
> confint (fit.gls, c("Wind", "Temp")) 2.5 % 97.5 %  
Wind -0.5447329 -0.2701709  
Temp 0.2420436 0.7382426 
```

Here the differences among point estimates and confidence intervals are not very pronounced. This has to do with the fact that the correlation among the errors is weaker than in the global temperature example. But we emphasize again that the GLS results are the one to be relied on and the magnitude of the difference between OLS and GLS can be tremendous.

# Simulation Study

We provide further evidence for the importance of the GLS approach by performing a simulation study in which the resulting coefficients and standard errors are compared to the ones obtained from OLS regression. We consider the following, relatively simple model:

$$
\begin{array}{l} x _ {t} = t / 5 0 \\ y _ {t} = x _ {t} + 2 \left(x _ {t}\right) ^ {2} + E _ {t} \\ \end{array}
$$

where $E _ { t }$ is from an $A R ( 1 )$ process with $\alpha _ { \mathrm { _ 1 } } = - 0 . 6 5$ . The innovations are Gaussian with $\sigma = 0 . 1$ . Regression coefficients and the true standard deviations of the estimators are known in this extraordinary situation. However, we generate 100 realizations with series length $n = 5 0$ , on each perform OLS and GLS regression and record both point estimate and standard error.

![](images/754a9e6621334fe01bfdbef02080eea6e5457dedf0b7e28a67ed1430f1e86551.jpg)  
Coefficient

![](images/d14bc447c080573c33d8bc98d4cf0b9cf667de20b5e54ee9839e81cdbf2c77c0.jpg)  
Standard Error

The simulation outcome is displayed by the boxplots in the figure above. While the point estimator for $\beta _ { 1 }$ in the left panel is unbiased for both OLS and GLS, we observe that the standard error for $\hat { \beta } _ { 1 }$ is very poor when the error correlation is not accounted for. We emphasize again that OLS regression with time series will inevitably lead to spuriously significant predictors and thus, false conclusions. Hence, it is absolutely key to inspect for possible autocorrelation in the regression residuals and apply the gls() procedure if necessary.

However, while gls() can cure the problem of autocorrelation in the error term, it does not solve the issue from the root. Sometimes, even this is possible. In the next subsection, we conclude the chapter about time series regression by showing how correlated errors can originate, and what practice has to offer for deeper understanding of the problem.

# 7.5 Missing Predictor Variables

The presence correlated errors is often due to missing predictors. For illustration, we consider a straightforward example of a ski selling company in the US. The quarterly sales $Y _ { { t } }$ are regressed on the personal disposable income (PDI) which is the one and only predictor $x _ { t }$ . We display the two time series in a scatterplot and enhance it with the OLS regression line.

```r
> ## Loading the data
> ski <- read.table("ski.dat", header=TRUE)
> names(ski) <- c("time", "sales", "pdi", "season")
>
>
## Scatterplot
> par(mfrow=c(1,1))
> plot(sales ~ pdi, data=ski, pch=20, main="Ski Sales")
>
>
## LS modeling and plotting the fit
> fit <- lm(sales ~ pdi, data=ski)
> abline(fit, col="red") 
```

![](images/d398dc91baed8e74c8e2e8b2ab2aa6df8e21723c0f29949b4ba924fd55870477.jpg)  
Ski Sales

The coefficient of determination is rather large, i.e. $R ^ { 2 } = 0 . 8 0 1$ and the linear fit seems adequate, i.e. a straight line seems to correctly describe the systematic relation between sales and PDI. However, the model diagnostic plots (see the next page) show some rather special behavior, i.e. there are hardly any “small” residuals (in absolute value). Or more precisely, the data points almost lie on two lines around the regression line, with almost no points near or on the line itself.

```txt
> ## Residual diagnostics  
> par(mfrow=c(2,2))  
> plot.fit, pch=20) 
```

![](images/c94ca55af091cfa4b228c5ca47302b020e5e0cb1064fb743e347090fcf054af1.jpg)

![](images/16872facbc70a66aa56b42946b04ab3561f60533f26a9e8d2c95152c44c0dd91.jpg)

![](images/d69dc9c0fefff78883de1beeb00b6b02e79ee0c7c98958a096f452b760cfe3f1.jpg)

![](images/cd2bcf813455713671744d1ebe48f86c0c0f8aaef5195221240b48155c90f2b8.jpg)

As the next step, we analyze the correlation of the residuals and perform a Durbin-Watson test. The result is as follows:

```txt
> dwtest (fit)  
data: fit  
DW = 1.9684, p-value = 0.3933  
alt. hypothesis: true autocorrelation is greater than 0 
```

![](images/93c9ad506b2bbc7d9413a3438bae11abb2fe3b4c1330f0ae7d0ac4c1a129a95c.jpg)  
ACF of OLS Residuals

![](images/b5cccc26e17d20f31d849e9c9ee3fec1620264d0dd468df4cfc6a22b46d272f6.jpg)  
PACF of OLS Residuals

While the Durbin-Watson test does not reject the null hypothesis, the residuals seem very strongly correlated. The ACF exhibits some decay that may still qualify as exponential, and the PACF has a clear cut-off at lag 2. Thus, an $A R ( 2 )$ model could be appropriate. And because it is an $A R ( 2 )$ where $\alpha _ { \mathrm { _ 1 } }$ and $\rho ( 1 )$ are very small, the Durbin-Watson test fails to detect the dependence in the residuals. The time series plot is as follows:

![](images/65cac2b4ec977e44df6ea4b151cad3b491605fcbd07022eddc513f05027abe6a.jpg)  
Time Series Plot of OLS Residuals

While we could now account for the error correlation with a GLS, it is always better to identify the reason behind the dependence. I admit this is suggestive here, but as mentioned in the introduction of this example, these are quarterly data and we might have forgotten to include the seasonality. It is not surprising that ski sales are much higher in fall and winter and thus, we introduce a factor variable which takes the value 0 in spring and summer, and 1 else.

![](images/3ae7a8efcddb9524233a647f43f29e6d85f3e2d0a21e7d3442289e0501ffc838.jpg)  
Ski Sales - Winter=1, Summer=0

Introducing the seasonal factor variable accounts to fitting two parallel regression lines for the winter and summer term. Eyeballing already lets us assume that the fit is good. This is confirmed when we visualize the diagnostic plots:

![](images/2b7611765b3e6bac0f7ea62421b89e03d10df3f7aec29838b63d3503b5d6fba1.jpg)

![](images/b930e4c8e57a0fe921b8aab4c41887639c4fe74fd6f2efda99abcfe500f4febf.jpg)

![](images/b68ace642444cddc9c2b60fe56ab5fc37d40bc5a17d424f0cabc39d7c2419d1b.jpg)

![](images/7ff9b9598a0498bcaa299ca198e8aa641bb0ed4ad7d4863629b9c1a9eab9339f.jpg)

The unwanted structure is now gone, as is the correlation among the errors:

![](images/95ea780d629538a7bd112f11c6e9a642dc4f1b2323aa20b28e374b0f95c1db1b.jpg)

![](images/3463a5066fa8ef869913b28b11ec497415a1a4b14f4d18439d7327052c1eb167.jpg)

Apparently, the addition of the season as an additional predictor has removed the dependence in the errors. Rather than using GLS, a sophisticated estimation procedure, we have found a simple model extension that describes the data well and is certainly easier to interpret (especially when it comes to prediction) than a model that is built on correlated errors.

We conclude by saying that using GLS for modeling dependent errors should only take place if care has been taken that no important and/or obvious predictors are missing in the model.

# 8 Forecasting

One of the principal goals with time series analysis is to produce predictions which show the future evolution of the data. This is what it is: an extrapolation in the time domain. And as we all know, extrapolation is always (at least slightly) problematic and can lead to false conclusions. Of course, this is no different with time series forecasting.

The saying is that the task we are faced with can be compared to driving a car by looking through the rear window mirror. While this may work well on a wide motorway that runs mostly straight and has a few gentle bends only, things get more complicated as soon as there are some sharp and unexpected bends in the road. Then, we would need to drive very slowly to stay on track. This all translates directly to time series analysis. For series where the signal is much stronger than the noise, accurate forecasting is possible. However, for noisy series, there is a great deal of uncertainty in the predictions, and they are at best reliable for a very short horizon.

From the above, one might conclude that the principal source of uncertainty is inherent in the process, i.e. comes from the innovations. However, in practice, this is usually different, and several other factors can threaten the reliability of any forecasting procedure. In particular:

We need to be certain that the data generating process does not change over time, i.e. continues in the future as it was observed in the past.   
When we choose/fit a model based on a realization of data, we have no guarantee that it is the correct, i.e. data-generating one.   
Even if we are so lucky to find the correct data-generating process (or in cases we know it), there is additional uncertainty arising from the estimation of the parameters.

Keeping these general warnings in mind, we will now present several approaches to time series forecasting. First, we deal with stationary processes and present, how AR, MA and ARMA processes can be predicted. These principles can be extended to the case of ARIMA and SARIMA models, such that forecasting series with either trend and/or seasonality is also possible.

As we had seen in section 4.3, the decomposition approach for non-stationary time series helps a great deal for visualization and modeling. Thus, we will present some heuristics about how to produce forecasts with series that were decomposed into trend, seasonal pattern and a stationary remainder. Last but not least, we present the method of exponential smoothing. This was constructed as a modelfree, intuitive weighting scheme that allows forecasting of time series. Due to its simplicity and the convenient implementation in the HoltWinters() procedure in R, it is very popular and often used in applied sciences.

# 8.1 Forecasting ARMA

We suppose that we are given a time series, for which an appropriate AR, MA or ARMA model was identified, the parameters were successfully estimated and where the residuals exhibited the required properties, i.e. looked like White Noise. Under these circumstances, forecasts may be readily computed. Given data up to time $n$ , the forecasts will involve either involve the past observations, and/or the residuals.

In mathematical statistics, many forecasting methods have been studied on a theoretical basis with the result that the minimum mean squared error forecast $\hat { X } _ { n + k , 1 : n }$ ,1:ˆX n k n  for $k$ steps ahead is given by the conditional expectation, i.e.:

$$
\hat {X} _ {n + k, 1 n} = E [ X _ {n + k} \mid X _ {1}, \dots , X _ {n} ]
$$

In evaluating this term, we use the fact that the best forecast of all future innovation terms $E _ { t } , t > n$ is simply zero. We will be more specific in the following subsections.

# 8.1.1 Forecasting AR(1)

For simplicity, we first consider a mean-zero, stationary $A R ( 1 )$ process with model equation:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + E _ {t},
$$

where $E _ { t }$ is the innovation, for which we do not need to assume a particular distribution. As we will see below, it is convenient to assume Gaussian $E _ { t }$ , because this allows for an easy derivation of a prediction interval. The conditional expectation at time $n + 1$ is given by:

$$
E [ X _ {n + 1} \mid X _ {1}, \dots , X _ {n} ] = \alpha_ {1} x _ {n}.
$$

Thus, we can forecast the next instance of a time series with the observed value of the previous one, in particular:

$$
\hat {X} _ {n + 1, 1: n} = \alpha_ {1} x _ {n}.
$$

For the $k$ -step forecast with $k > 1$ , we just need to repeatedly plug-in the model equation, and as use the fact that the conditional expectation of the innovations is zero:

$$
\begin{array}{l} \hat {X} _ {n + k, 1: n} = E \left[ X _ {n + k} \mid X _ {1}, \dots , X _ {n} \right] \\ = E \left[ \alpha_ {1} X _ {n + k - 1} + E _ {n + k} \mid X _ {1}, \dots , X _ {n} \right] \\ = \alpha_ {1} E \left[ X _ {n + k - 1} \mid X _ {1}, \dots , X _ {n} \right] \\ = \dots \\ = \alpha_ {1} ^ {k} x _ {n} \\ \end{array}
$$

For any stationary $A R ( 1 )$ process, the $k$ -step forecast beyond the end of a series depends on the last observation $x _ { n }$ only and goes to zero exponentially quickly. For practical implementation with real data, we would just plug-in the estimated model parameter $\hat { \alpha } _ { 1 }$ and can so produce a forecast for any desired horizon.

As always, a prediction is much more useful in practice if one knows how precise it is. Under the assumption of Gaussian innovations, a $9 5 \%$ prediction interval can be derived from the conditional variance $V a r ( X _ { n + k } \mid X _ { 1 } , . . . , X _ { n } )$ . For the special case of $k = 1$ we obtain:

$$
\alpha_ {1} x _ {n} \pm 1. 9 6 \cdot \sigma_ {E}.
$$

Again, for practical implementation, we need to plug-in $\hat { \alpha } _ { 1 }$ and $\hat { \sigma } _ { \scriptscriptstyle E }$ . For a $k$ -step prediction, the $9 5 \%$ prognosis interval is:

$$
\alpha_ {1} x _ {n} \pm 1. 9 6 \cdot \left(1 + \sum_ {j = 1} ^ {k - 1} \alpha_ {1} ^ {2 j}\right) \cdot \sigma_ {E}.
$$

For increasing prediction horizon $k$ , the conditional variance goes to $\sigma _ { E } ^ { 2 } / ( 1 - \alpha _ { 1 } ^ { 2 } )$ , which is the process variance $\sigma _ { X } ^ { 2 }$ . Thus, for the 1-step forecast, the uncertainty in the prediction is given by the innovation variance $\sigma _ { E }$ alone, while for increasing horizon $k$ the prognosis interval gets wider is finally determined by the process variance.

# Practical Example

We now turn our attention to a practical example, where we apply the R functions which implement the above theory. This is the Beaver data we had already discussed in section 4.4.3. An AR(1) model is appropriate, and for estimating the coefficients, we omit the last 14 observations from the data. These will be predicted, and the true values are needed for verifying the prediction.

![](images/e235a8387abb13195eceea9160fe59aa1747da1bc552ebf044216839ddfe4672.jpg)  
Beaver Data: 14-Step Prediction Based on AR(1)

The R commands for fitting the model on the training data and producing the 14- step prediction are as follows:

```r
> btrain <- window(beaver, 1, 100)  
> fit <- ar.burg(btrain, order=1)  
> forecast <- predict(fit, n.ahead=14) 
```

The forecast object is a list that has two components, pred and se, which contain the point predictions and the standard error, respectively. We now turn our attention to how the forecast is visualized:

```txt
> plot(beaver, lty=3)
> lines(btrain, lwd=2)
> lines(pred$pred, lwd=2, col="red")
> lines(pred$pred+pred$se*1.96, col="red")
> lines(pred$pred-pred$se*1.96, col="red") 
```

One more issue requires some attention here: for the Beaver data, a pure AR(1) process is not appropriate, because the global series mean is clearly different from zero. The way out is to de-mean the series, then fit the model and produce forecasts, and finally re-adding the global mean. R does all this automatically.

We conclude by summarizing what we observe in the example: the forecast is based on the last observed value $x _ { 1 0 0 } = 3 6 . 7 6$ , and from there approaches the global series mean $\hat { \mu } = 3 6 . 8 6$ exponentially quick. Because the estimated coefficient is $\hat { \alpha } _ { \mathrm { 1 } } = 0 . 8 7$ , and thus relatively close to one, the approach still takes some time.

# 8.1.2 Forecasting AR(p)

Forecasting from $A R ( p )$ processes works based on the same principles as explained above for the $A R ( 1 )$ , i.e. we use the conditional expected value. The algebra for writing the forecasting formulae is somewhat more laborious, but not more difficult. Thus, we do without displaying it here, and directly present the 1- step-forecast:

$$
\hat {X} _ {n + 1, 1: n} = \alpha_ {1} x _ {n} + \alpha_ {2} x _ {n - 1} + \dots + \alpha_ {p} x _ {n - p}
$$

The question is, what do we do for longer forecasting horizons? There, the forecast is again based on the linear combination of the $p$ past instances. For the ones with an index between 1 and $n$ , the observed value $x _ { t }$ is used. Else, if the index exceeds $n$ , we just plug-in the forecasted values $\hat { x } _ { t , \mathrm { l } : n }$ . Thus, the general formula is:

$$
\hat {X} _ {n + k, 1: n} = \alpha_ {1} \hat {X} _ {n + k - 1, 1: n} +... + \alpha_ {p} \hat {X} _ {n + k - p, 1: n},
$$

where $\hat { X } _ { t , 1 : n } = x _ { t }$ in all cases where $t \leq n$ , i.e. an observed value is available.

# Practical Example

We consider the lynx data for which we had identified an AR(11) as a suitable model. Again, we use the first 100 observations for fitting the model and lay aside the last 14, which are in turn used for verifying the result. Also, we do without showing the R code, because it is identical to the one from the previous example.

![](images/f1595f14ea181f67d2c110c0e8d4e40443322d5f887fdd5b47817cf713d66913.jpg)  
Logged Lynx Data: 14-Step Prediction Based on AR(11)

We observe that the forecast tracks the general behavior of the series well, though the level of the series is underestimated somewhat. This is, however, not due to an “error” of ours, it is just that the values were higher than the past observations suggested. We finish this section with some remarks:

Forecasting from an $A R ( p )$ only requires knowledge about the last $p$ instances of the series, plus the model parameters $\alpha _ { 1 } , . . . , \alpha _ { p }$ and the global series mean $\mu$ . Earlier values of the series are not required, the model thus has a Markov property of order $p$ .   
The prediction intervals only account for the uncertainty caused by the innovation variance, but not for the one caused by model misconception, and the plug-in of estimated parameters. Thus in practice, a true $9 5 \%$ interval would most likely be wider than shown above.

# 8.1.3 Forecasting MA(1)

We here consider an invertible MA(1) process, where the model equation is as follows:

$$
X _ {t} = E _ {t} + \beta_ {1} E _ {t - 1},
$$

where $E _ { t }$ is an innovation with expectation zero and constant variance.

As above, the forecast $\hat { X } _ { n + k , \ 1 : n }$ will again be based on the conditional expectation $E [ X _ { n + k } \mid X _ { 1 } , . . . , X _ { n } ]$ . We get to a solution if we plug-in the model equation. First, we assume that $k \geq 2$ , i.e. predict at least 2 time steps ahead.

$$
\begin{array}{l} \hat {X} _ {n + k, 1: n} = E \left[ X _ {n + k} \mid X _ {1}, \dots , X _ {n} \right] \\ = E \left[ E _ {n + k} + \beta_ {1} E _ {n + k - 1} \mid X _ {1},..., X _ {n} \right] \\ = E \left[ E _ {n + k} \mid X _ {1}, \dots , X _ {n} \right] + \beta_ {1} E \left[ E _ {n + k - 1} \mid X _ {1}, \dots , X _ {n} \right] \\ = 0 \\ \end{array}
$$

The best forecast MA(1) forecast for horizons 2 and up is thus zero. Remember that we require $E _ { t }$ being an innovation, and thus independent from previous instances $X _ { s }$ , $s < t$ of the time series process. Next, we address the 1-step forecast. This is more problematic, because the above derivation leads to:

$$
\begin{array}{l} \hat {X} _ {n + 1, 1: n} = \dots \\ = \beta_ {1} E [ E _ {n} \mid X _ {1}, \dots , X _ {n} ] \\ \neq \quad 0 (g e n e r a l l y) \\ \end{array}
$$

The 1-step forecast thus generally is different from zero. Moreover, the term $E [ E _ { n } | X _ { 1 } , . . . , X _ { n } ]$ is difficult to determine. Using some mathematical trickery, we can at least propose an approximate value. This trick is to move the point of reference into the infinite past, i.e. conditioning on all previous instances of the MA(1) process. We denote

$$
e _ {n} := E \left[ E _ {n} \mid X _ {- \infty} ^ {n} \right].
$$

By successive substitution, we then write the MA(1) as an $A R ( \infty )$ . This yields

$$
E _ {n} = \sum_ {j = 0} ^ {\infty} (- \beta_ {1}) ^ {j} X _ {n - j}.
$$

If we condition the expectation of $E _ { n }$ on the infinite past of the series $X _ { t }$ , we can plug-in the realizations $x _ { t }$ and obtain:

$$
E \left[ E _ {n} \mid X _ {- \infty} ^ {n} \right] = e _ {n} = \sum_ {j = 0} ^ {\infty} (- \beta_ {1}) ^ {j} x _ {n - j}.
$$

This is of course somewhat problematic for practical implementation, because we only have realizations for $x _ { 1 } , . . . , x _ { n }$ . However, because for invertible MA(1) processes, $\left| \beta _ { 1 } \right| < 1$ , the impact of early observations dies out exponentially quickly. Thus, we let $x _ { t } = 0$ for $t < 1$ , and thus also have that $e _ { t } = 0$ for $t < 1$ . Also, we plugin the estimated model parameter $\hat { \beta } _ { 1 }$ , and thus, the 1-step forecast for an MA(1) is:

$$
\hat {X} _ {n + 1, \mathrm {l}: n} = \sum_ {j = 0} ^ {n - 1} \hat {\beta} _ {1} (- \hat {\beta} _ {1}) ^ {j} x _ {n - j}
$$

This is a sum of all observed values, with exponentially decaying weights.

# 8.1.4 Forecasting MA(q)

When forecasting from $M A ( q )$ processes, we encounter the same difficulties as above. The prediction for horizons exceeding $q$ are all zero, but anything below contains terms for which the considerations in section 8.1.3 are again necessary. We do without displaying this, and proceed to giving the formulae for $A R M A ( p , q )$ forecasting, from which the ones for $M A ( q )$ can be learned.

# 8.1.5 Forecasting ARMA(p,q)

We are considering stationary and invertible ARMA p q ( , ) processes. The model equation for $X _ { n + 1 }$ then is:

$$
X _ {n + 1} = \alpha_ {1} X _ {n} + \ldots + \alpha_ {p} X _ {n + 1 - p} + E _ {n + 1} + \beta_ {1} E _ {n} + \ldots + \beta_ {q} E _ {n + 1 - q}
$$

As this model equation contains past innovations, we face the same problems as in section 8.1.3 when trying to derive the forecast for horizons $\leq q$ . These can be mitigated, if we again condition on the infinite past of the process.

$$
\begin{array}{l} \hat {X} _ {n + 1, \mathrm {l n}} = E \left[ X _ {n + 1} \mid X _ {- \infty} ^ {n} \right] \\ = \sum_ {i = 1} ^ {p} \alpha_ {i} E \left[ X _ {n + 1 - i} \mid X _ {- \infty} ^ {n} \right] + E \left[ E _ {n + 1} \mid X _ {- \infty} ^ {n} \right] + \sum_ {j = 1} ^ {q} \beta_ {j} E \left[ E _ {n + 1 - j} \mid X _ {- \infty} ^ {n} \right] \\ = \sum_ {i = 1} ^ {p} \alpha_ {i} x _ {n + 1 - i} + \sum_ {i = 1} ^ {q} \beta_ {j} E \left[ E _ {n + 1 - j} \mid X _ {- \infty} ^ {n} \right] \\ \end{array}
$$

If we are aiming for $k$ -step forecasting, we can use a recursive prediction scheme:

$$
\hat {X} _ {n + k, 1: n} = \sum_ {i = 1} ^ {p} \alpha_ {i} E [ X _ {n + k - i} | X _ {- \infty} ^ {n} ] + \sum_ {j = 1} ^ {q} \beta_ {j} E [ E _ {n + k - j} | X _ {- \infty} ^ {n} ],
$$

where for the AR - and MA -part the conditional expectations are:

$$
\begin{array}{l} E \left[ X _ {t} \mid X _ {- \infty} ^ {n} \right] = \left\{ \begin{array}{l l} x _ {t}, & i f t \leq n \\ \hat {X} _ {t, 1: n}, & i f t > n \end{array} \right. \\ E \left[ E _ {t} \mid X _ {- \infty} ^ {n} \right] = \left\{ \begin{array}{l} e _ {t}, i f t \leq n \\ 0, i f t > n \end{array} \right. \\ \end{array}
$$

The terms $e _ { t }$ are then determined as outlined above in section 8.1.3, and for the model parameters, we are plugging-in the estimates. This allows us to generate any forecast from an $A R M A ( p , q )$ model that we wish. The procedure is also known as Box-Jenkins procedure, after the two researchers who first introduced it.

Next, we illustrate this with a practical example, though in R, things are quite unspectacular. It is again the predict() procedure that is applied to a fit from arima(), the Box-Jenkins scheme that is employed runs in the background.

# Practical Example

We here consider the Douglas Fir data which show the width of the year rings over a period from 1107 to 1964. Because the data are non-stationary, we take differences and model these. An ARMA(1,1) seems appropriate. We put the last 64 observations aside so that we can verify our predictions. Then, the model is fitted and the Box-Jenkins predictions are obtained. The result, including a $9 5 \%$ prognosis interval, is shown below.

![](images/a3455bdca05a4a2499cded42e791cc3bad14f8169bf7ab6bc57aae759b965095.jpg)  
Differenced Douglas Fir Data: 64-Step Prediction Based on ARMA(1,1)

We observe that the forecast goes to zero exponentially quickly. However, it is in fact different from zero for all times. Moreover, all observations down to the very first one are used for obtaining the predictions. Again, the ARMA model combines the properties from pure AR and MA processes.

# 8.2 ARIMA/SARIMA

As we had explained in section 6, all $A R I M A ( p , d , q )$ and $S A R I M A ( p , d , q ) ( P , D , Q ) ^ { s }$ models can be written as non-stationary $A R M A ( p , q )$ processes. This notion opens the door as how forecasting for these series works – we just use that nonstationary representation and use the methods that were introduced before. Alternatively, we here give a sketch of what happens in an ARIMA forecast. We assume:

$$
X _ {t} \text {f o l l o w s a n A R I M A (1 , 1 , 1)} \text {, h e n c e} Z _ {t} = X _ {t} - X _ {t - 1} \text {i s a n A R M A (1 , 1)}
$$

Furthermore, we have data $Z _ { 1 } , . . . , Z _ { n }$ and were able to generate forecasts $\hat { Z } _ { n + 1 ; 1 ; n } , . . . , \hat { Z } _ { n + k ; 1 : n }$ 1 n. We are now seeking the $k$ -step forecast for the original process $X _ { t }$ . These are based on the notion of $\hat { X } _ { n + 1 ; 1 ; n } = \hat { Z } _ { n + 1 ; 1 ; n } + X _ { n }$ , hence:

$$
\begin{array}{l} \hat {X} _ {n + 1; \mathrm {l}: n} = \hat {Z} _ {n + 1; \mathrm {l}: n} + X _ {n} \\ \begin{array}{c} \hat {X} _ {n + 2; 1: n} = \hat {Z} _ {n + 2; 1: n} + \hat {X} _ {n + 1; 1: n} = X _ {n} + \hat {Z} _ {n + 1; 1: n} + \hat {Z} _ {n + 2; 1: n} \\ \vdots \end{array} \\ \hat {X} _ {n + k: 1: n} = X _ {n} + \hat {Z} _ {n + 1: 1: n} + \dots + \hat {Z} _ {n + k: 1: n} \\ \end{array}
$$

As we can see, the $k$ -step forecast for the original data is the cumulative sum of all forecasted terms of the differenced data.

# 8.3 Exponential Smoothing

# 8.3.1 Simple Exponential Smoothing

The objective in this section is to predict some future values $X _ { \mathfrak { n } + k }$ given an observed series $\{ X _ { 1 } , . . . , X _ { n } \}$ , and thus no different than before. We first assume that the data do not exhibit any deterministic trend or seasonality, or that these have been identified and removed. The (conditional) expected value of the process can change from one time step to the next, but we do not have any information about the direction of this change. A typical application is forecasting sales of a well-established product in a stable market. The model is:

$$
X _ {t} = \mu_ {t} + E _ {t},
$$

t tindependent random innovations with expectation zero and constant variance where $\mu _ { t }$ is the non-stationary mean of the process at time t, and $E _ { t }$ are $\sigma _ { E } ^ { 2 }$ We will here use the same notation as R does, and let $a _ { t }$ , called level of the series, be our estimate of $\mu _ { t }$ . By assuming that there is no deterministic trend, an intuitive estimate for the level at time $t$ is to take a weighted average of the current time series observation and the previous level:

$$
a _ {t} = \alpha x _ {t} + (1 - \alpha) a _ {t - 1}, \text {w i t h} 0 <   \alpha <   1.
$$

Apparently, the value of $\alpha$ determines the amount of smoothing: if it is near 1, there is little smoothing and the level $a _ { t }$ closely tracks the series $x _ { t }$ . This would be appropriate if the changes in the mean of the series are large compared to the innovation variance $\sigma _ { E } ^ { 2 }$ . At the other extreme, an $\alpha$ -value near 0 gives highly smoothed estimates of the current mean which take little account of the most recent observation. This would be the way to go for series with a large amount of noise compared to the signal size. A typical default value is $\alpha = 0 . 2$ , chosen in the light that for most series, the change in the mean between $t$ and $t - 1$ is smaller than $\sigma _ { E } ^ { 2 }$ . Alternatively, it is (with R) also possible to estimate $\alpha$ , see below.

Because we assume absence of deterministic trend and seasonality, the best forecast at time $n$ for the future level of the series, no matter what horizon we are aiming for, is given by the level estimate at time $n$ , i.e.

$$
\hat {X} _ {n + k, 1: n} = a _ {n}, \text {f o r a l l} k = 1, 2, \dots .
$$

We can rewrite the weighted average equation in two further ways, which yields insight into how exponential smoothing works. Firstly, we can write the level at time $t$ as the sum of $a _ { t - 1 }$ and the 1-step forecasting error and obtain the update formula:

$$
a _ {t} = \alpha (x _ {t} - a _ {t - 1}) + a _ {t - 1}
$$

Now, if we repeatedly apply back substitution, we obtain:

$$
a _ {t} = \alpha x _ {t} + \alpha (1 - \alpha) x _ {t - 1} + \alpha (1 - \alpha) ^ {2} x _ {t - 2} + \dots
$$

When written in this form, we see that the level $a _ { t }$ is a linear combination of the current and all past observations with more weight given to recent observations. The restriction $0 < \alpha < 1$ ensures that the weights $\alpha ( 1 - \alpha ) ^ { i }$ become smaller as i increases. In fact, they are exponentially decaying and form a geometric series. When the sum over these terms is taken to infinity, the result is 1. In practice, the infinite sum is not feasible, but can be avoided by specifying $a _ { 1 } = x _ { 1 }$ .

For any given smoothing parameter $\alpha$ , the update formula plus the choice of $a _ { 1 } = x _ { 1 }$ as a starting value can be used to determine the level $a _ { t }$ for all times $t = 2 , 3 , \ldots$ . The 1-step prediction errors $e _ { t }$ are given by:

$$
e _ {t} = x _ {t} - \hat {x} _ {t, 1: (t - 1)} = x _ {t} - a _ {t - 1}.
$$

By default, R obtains a value for the smoothing parameter $\alpha$ by minimizing the sum of squared 1-step prediction errors, called SS PE 1 :

$$
S S 1 P E = \sum_ {t = 2} ^ {n} e _ {t} ^ {2}.
$$

There is some mathematical theory that examines the quality of the SS PE 1 - minimizing $\alpha$ . Not surprisingly, this depends very much on the true, underlying process. However in practice, this value is reasonable and allows for good predictions.

# Practical Example

We here consider a time series that shows the number of complaint letters that were submitted to a motoring organization over the four years 1996-1999. At the beginning of year 2000, the organization wishes to estimate the current level of complaints and investigate whether there was any trend in the past. We import the data and do a time series plot:

```r
> www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"  
> dat <- read.table(paste(www, "motororg.dat", sep="", head=T)  
> cmp1 <- ts(da\$complaints, start=c(1996,1), freq=12)  
> plot(cmpl, ylab="", main="Complaints ...") 
```

![](images/6968fa762176d09b0d15ff1c6b8f07c362684e7d765228e98e7dff6093954fa2.jpg)  
Complaints to a Motorizing Organization

The series is rather short, and there is no clear evidence for a deterministic trend and/or seasonality. Thus, it seems sensible to use exponential smoothing here. The algorithm that was described above is implemented in R’s HoltWinters() procedure. Please note that HoltWinters() can do more than plain exponential smoothing, and thus we have to set arguments beta $_ { . } =$ FALSE and gamma $. =$ FALSE. If we do not specify a value for the smoothing parameter $\alpha$ with argument alpha, it will be estimated using the SS PE 1 criterion.

```txt
> fit <- HoltWinters(cmpl, beta=FALSE, gamma=FALSE); fit Holt-Winters exponential smoothing without trend and without seasonal component. 
```

```txt
Call: HoltWinters(x = cmp1, beta = FALSE, gamma = FALSE) 
```

```txt
Smoothing parameters:  
alpha: 0.1429622  
beta : FALSE  
gamma: FALSE 
```

```txt
Coefficients: [,1]  
a 17.70343  
> plot(fit) 
```

![](images/2d7458b9faa4b08bc344963b6b7100e7058f2cb2c4471e6be56049bd193d04eb.jpg)

The output shows that the level in December 1999, this is $a _ { 4 8 }$ , is estimated as 17.70. The optimal value for $\alpha$ according to the SS PE 1 criterion is 0.143, and the sum of squared prediction errors was 2502. Any other value for $\alpha$ will yield a worse result, thus we proceed and display the result visually.

# 8.3.2 The Holt-Winters Method

The simple exponential smoothing approach from above can be generalized for series which exhibit deterministic trend and/or seasonality. As we have seen in many examples, such series are the norm rather than the exception and thus, such a method comes in handy. It is based on these formulae:

$$
{ a _ { t } } { = } { \alpha ( x _ { t } - s _ { t - p } ) + ( 1 - \alpha ) ( a _ { t - 1 } + b _ { t - 1 } ) }
$$

$$
{b _ {t}} = {\beta (a _ {t} - a _ {t - 1}) + (1 - \beta) b _ {t - 1}}
$$

$$
s _ {t} = \gamma \left(x _ {t} - a _ {t}\right) + (1 - \gamma) s _ {t - p}
$$

In the above equations, $a _ { t }$ is again the level at time t , $b _ { t }$ is called the slope and $s _ { t }$ is the seasonal effect. There are now three smoothing parameters $\alpha , \beta , \gamma$ which are aimed at level, slope and season. The explanation of these equations is as follows:

The first updating equation for the level takes a weighted average of the most recent observation with the existing estimate of the previous’ period seasonal effect term subtracted, and the 1-step level forecast at $t - 1$ , which is given by level plus slope.   
The second updating equation takes a weighted average of the difference between the current and the previous level with the estimated slope at time $t - 1$ . Note that this can only be computed if $a _ { t }$ is available.

Finally, we obtain another estimate for the respective seasonal term by taking a weighted average of the difference between observation and level with the previous estimate of the seasonal term for the same unit, which was made at time $t - p$ .

If nothing else is known, the typical choice for the smoothing parameters is $\alpha = \beta = \gamma = 0 . 2$ .Moreover, starting values for the updating equations are required. Mostly, one chooses $a _ { 1 } = x _ { 1 }$ , the slope $b _ { 1 } = 0$ and the seasonal effects $s _ { 1 } , . . . , s _ { p }$ are either also set to zero or to the mean over the observations of a particular season. When applying the R function HoltWinters(), the starting values are obtained from the decompose() procedure, and it is possible to estimate the smoothing parameters through SS PE 1 minimization. The most interesting aspect are the predictions, though: the $k$ -step forecasting equation for $X _ { \mathfrak { n } + k }$ at time $n$ is:

$$
\hat {X} _ {n + k, 1: n} = a _ {n} + k b _ {n} + s _ {n + k - p},
$$

i.e. the current level with linear trend extrapolation plus the appropriate seasonal effect term. The following practical example nicely illustrates the method.

# Practical Example

![](images/e20d601113c6824b24263b999b854479bb6e2e584997c46852758601df4ca203.jpg)

We here discuss the series of monthly sales (in thousands of litres) of Australian white wine from January 1980 to July 1995. This series features a deterministic trend, the most striking feature is the sharp increase in the mid-80ies, followed by a reduction to a distinctly lower level again. The magnitude of both the seasonal effect and the errors seem to be increasing with the level of the series, and are thus multiplicative rather than additive. We will cure this by a log-transformation of the series, even though there exists a multiplicative formulation of the Holt-Winters algorithm, too.

```r
> www <- "http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/"  
> dat <- read.table(paste(www, "wine.dat", sep="", header=T)  
> aww <- ts(da $sweetw, start=c(1980,1), freq=12)  
> plot(aww, ylab="", main="Sales of Australian White Wine")  
> plot(log(aww), ylab="", main="Logged Sales ...") 
```

The transformation seems successful, thus we proceed to the Holt-Winters modeling. When we apply parameter estimation by SS PE 1 , this is straightforward. The fit contains the current estimates for level, trend and seasonality. Note that these are only valid for time $n$ , and not for the entire series. Anyhow, it is much better to visualize the sequence of $a _ { t } , b _ { t }$ and $\gamma _ { t }$ graphically. Moreover, plotting the fitted values along with the time series is informative, too.

![](images/8b6d69771ea6da11248e5fc11c79d79d2389c1a2ce698d84c45fcf352f81f713.jpg)  
Logged Sales of Australian White Wine

> fit

Holt-Winters exponential smoothing with trend and additive seasonal component.

Call:

```txt
HoltWinters(x = log(aww)) 
```

Smoothing parameters:

alpha: 0.4148028

beta : 0

gamma: 0.4741967

Coefficients:

```txt
a 5.62591329 s4 0.20894897 s9 -0.17107682  
b 0.01148402 s5 0.45515787 s10 -0.29304652  
s1 -0.01230437 s6 -0.37315236 s11 -0.26986816  
s2 0.01344762 s7 -0.09709593 s12 -0.01984965  
s3 0.06000025 s8 -0.25718994
```

The coefficient values (at time n ) are also the ones which are used for forecasting from that series with the formula given above. We produce a prediction up until the end of 1998, which is a 29-step forecast. The R commands are:

```txt
> plot.fit, xlim=c(1980, 1998))  
> lines(predict.fit, n.ahead=29), col="blue", lty=3) 
```

![](images/f7e51f657734dfbe60de7ee70fdae02730fdc330e006112e8a296610fbce9b8c.jpg)  
Holt-Winters filtering

It is also very instructive to plot how level, trend and seasonality evolved over time. This can be done very simply in R:

```txt
> plot(fit\\(fitted, main="Holt-Winters-Fit") 
```

![](images/099071986febff51c6dc7824b5e4d4cedd8f0ddd544dada401fcffbc1d4b31a0.jpg)  
Holt-Winters-Fit

Since we are usually more interested in the prediction on the original scale, i.e. in liters rather than log-liters of wine, we just re-exponentiate the values. Please note

that the result is an estimate of the median rather than the mean of the series. There are methods for correction, but the difference is usually only small.

```txt
> plot(aww, xlim=c(1980, 1998))
> lines(exp(fit\\(fitted[,1]), col="red")
> lines(exp(predict(fit, n.ahed=29)), col="blue", lty=3) 
```

![](images/4507d136b554f164d0820faca53ec967b91545d0969521703884f348308c277b.jpg)  
Holt-Winters-Forecast for the Original Series

Also, we note that the (insample) 1-step prediction error is equal to 50.04, which is quite a reduction when compared to the series’ standard deviation which is 121.4. Thus, the Holt-Winters fit has substantial explanatory power. Of course, it would now be interesting to test the accuracy of the predictions. We recommend that you, as an exercise, put aside the last 24 observations of the Australian white wine data, and run a forecasting evaluation where all the methods (SARIMA, decomposition approaches, Holt-Winters) compete against each other.

# 8.4 Forecasting Decomposed Series

Another approach for forecasting series with trend and/or seasonality is based on the descriptive decomposition. The paradigm is as follows:

Trend

We assume a smooth trend for which we recommend linear extrapolation.

Seasonal Effect

We extrapolate the seasonal effect according to the last observed period.

 Stationary Remainder

We fit an $A R M A ( p , q )$ and determine the forecast as discussed above.

We illustrate the procedure on the unemployment data from the state of Maine. We will work with the log-transformed data, for which an STL decomposition was performed. Because the extrapolation of the stationary remainder is as discussed

above, and the one of the seasonal effect is trivial, we focus on the trend extrapolation. We recommend the following procedure:

Fit a least squares regression line into the past trend values. The period on which the fit happens is chosen such that is has the same length as the forecasting horizon. In our particular example, where we want to forecast the upcoming two years of the series, these are the last 24 data points. Or in other words: for the trend forecast, we use the last observation as an anchor point and predict with the average slope from the last two years.

Please note that the so-produced trend forecast is a recommendation, but not necessarily the best solution. If some expert knowledge from the application field suggests another trend extrapolation, then it may well be used. It is however important, to clearly declare how the trend forecast was determined. The following code does the job, see next page for the result:

```r
## STL decomposition
> fit <- stl(log(tsd), swindow="periodic")
## KQ-Fit over the last 2 years
> plot.fit\$time_series[,2], xlim=c(1996, 2008+9/12))
> rect(2004+8/12, 1, 2006+7/12, 2, col="grey93", border=NA)
> rect(2006+7/12, 1, 2008+6/12, 2, col="grey83", border=NA)
> title("Trend Forecast by Linear Extrapolation")
> xx <- time.fit\$time_series[,2])[105:128]
> yy <- fit\$time_series[105:128,2]
> fit.regr <- lm(yy~xx)
> lines(xx, fitted.fit.regr), col="blue")
> lines(xx[1] + (23:46)/12, 1.494 + (0:23) / 12*coef.fit.regr)[2])
> lines.fit\$time_series[,2])
> box() 
```

![](images/111a258017ce990fe42e848b5fe6b6f269f2a5b27e0fc386d353c23a53a34b2e.jpg)  
Trend Forecast by Linear Extrapolation

Forecasting the seasonal effect is trivial, because we assume that it stays as it was last. Hence, we only need to take care of the stationary remainder. From the PACF, no particular order $p$ seems appealing for an AR model, see on the next page. As a way out, we choose to determine the suitable model using the AIC criterion, with which we find $p = 1 8$ .

Using the predict() command, we then produce a 24-step forecast for the stationary remainder. The final task is then to couple the forecasts for all three parts (trend, seasonal component and remainder) to produce a 2-year-forecast for the original series with the number of new vehicles on Swiss roads. Details are given in the R code which is provided on the next page.

```r
## Seasonal Component
12y <- window(saison, start=c(2009, 1), end=c(2010, 12))
sais.ex <- ts(12y, start=c(2011, 1), end=c(2012, 12), freq=12) 
```

![](images/b59bb6bfe41a34db6e3c0b3e66d9ca4de9be96562a10b2cb6ce570d23ddb9183.jpg)  
ACF vom stationären Restterm

![](images/6fed20a22f928b53828f2c10bb7b00f6e1708645ec898ca92186ecb386832c36.jpg)  
PACF vom stationären Restterm

## Stationary Remainder
rest <- fit\\(time_series[,3]
fit/rest <- ar.burg(rest)
rest.ex <- predict.fit, n.ahead=24) \\)pred

```htaccess
Adding the 3 Components  
series.ex <- trend.ex + saison.ex + rest.ex 
```

```r
## Displaying the Output
plot(series, xlim=c(2000, 2013))
lines(series.ex, col="red", lwd=2)
lines(c(2010.917, 2011), c(33773, 28590.20), col="red", lwd=2)
title("2-Jahres-Prognose Inverkehrssetzungen") 
```

![](images/365aeb8baccf86f67576b338b3c7cf45ff7d3ed4c76650394b4416557ffb6c80.jpg)  
2-Jahres-Prognose Inverkehrssetzungen

This procedure is a practical way for forecasting decomposed series. It is especially attractive if one wants to have a second thought on the predicted trend, and maybe correct it manually, based on deeper insight e.g. into the corporate plans about increasing or decreasing the market share, upcoming competitors, et cetera. On the downside, the procedure requires somewhat more effort for coming up with the forecasts, when compared to the SARIMA model and exponential smoothing. The choice of the right method however, depends on the use case.

# 9 Multivariate Time Series Analysis

While the header of this section says multivariate time series analysis, we will here restrict to two series series $X _ { 1 } = ( X _ { 1 , t } )$ and $X _ { 2 } = ( X _ { 2 , t } )$ , and thus bivariate time series analysis, because an extension to more than two series is essentially analogous. Please note that a prerequisite for all the theory in this section is that the series $X _ { 1 }$ and $X _ { 2 }$ are stationary.

Generally speaking, the goal of this section is to describe and understand the (inter)dependency between two series. We introduce the basic concepts of cross correlation and transfer function models, warn of arising difficulties in interpretation and show how these can be mitigated.

# 9.1 Practical Example

We will illustrate the theory on multivariate time series analysis with a practical example. The data were obtained in the context of the diploma thesis of Evelyn Zenklusen Mutter, a former WBL student who works for the Swiss Institute for Snow and Avalanche Research SLF. The topic is how the ground temperature in permafrost terrain depends on the ambient air temperature. The following section gives a few more details.

Ambient air temperatures influence ground temperatures with a certain temporal delay. Borehole temperatures measured at 0.5m depth in alpine permafrost terrain, as well as air temperatures measured at or nearby the boreholes will be used to model this dependency. The reaction of the ground on the air temperature is influenced by various factors such as ground surface cover, snow depth, water or ground ice content. To avoid complications induced by the insulating properties of the snow cover and by phase changes in the ground, only the snow-free summer period when the ground at 0.5m is thawed will be considered.

We here consider only one single borehole, it is located near the famous Hörnli hut at the base of Matterhorn near Zermatt/CH on 3295m above sea level. The air temperature was recorded on the nearby Platthorn at 3345m of elevation and 9.2km distance from the borehole. Data are available from beginning of July 2006 to the end of September 2006. After the middle of the observation period, there is a period of 23 days during which the ground was covered by snow, highlighted in grey color in the time series plots on the next page.

Because the snow insulates the ground, we do not expect the soil to follow the air temperature during that period. Hence, we set all values during that period equal to NA. The time series plots, and especially the indexed plot where both series are shown, clearly indicate that the soil reacts to the air temperature with a delay of a few days. We now aim for analyzing this relationship on a more quantitative basis, for which the methods of multivariate time series analysis will be employed.

![](images/8fc7aec4b5b440e9ff1e2b34f2fd6b4408f29fb96af31bf711acb3ef11bdd1a6.jpg)

![](images/e69f2dae51904fa53aa3f9e7fc5303148a6fa3c568791e785bfbc06d86e1f3ab.jpg)

![](images/e9710d8a0f8131a664bec438dd999b730df60f8fb2355ba20618abfac2cc35ab.jpg)

As we had stated above, multivariate time series analysis requires stationarity. Is this met with our series? The time series plot does not give a very clear answer. Science tells us that temperature has a seasonal pattern. Moreover, the correlogram of the two series is enlightening.

![](images/e54dfba4e07b371aed54a64dd09bf549285d23a150311c7b85131fc908cc0ea7.jpg)  
ACF of Air Temperature

![](images/c055eedb4baf6f5cae439d00440057159585aef2d64e566c72f8a9396e5354c2.jpg)  
ACF of Soil Temperature

The ACF exhibits a slow decay, especially for the soil temperature. Thus, we decide to perform lag 1 differencing before analyzing the series. This has another advantage: we are then exploring how changes in the air temperature are associated with changes in the soil temperature and if so, what the time delay is. These results are easier to interpret than a direct analysis of air and soil temperatures. Next, we display the differenced series with their ACF and PACF. The observations during the snow cover period are now omitted.

![](images/bb9d2a984e639ff6460eb28cd9e24d1c2c6eb54d660c7826970a6745f3d92524.jpg)  
Changes in the Air Temperature

![](images/38305189b57872f67fa095edff147060ad45358e4135ee2fb3c640e163e86d76.jpg)  
ACF

![](images/e15e17a30135da336d09183665719c198f34aa89c0ce612e519c43e04e1b3bdc.jpg)  
PACF

The differenced air temperature series seems stationary, but is clearly not iid. There seems to be some strong negative correlation at lag 4. This may indicate the properties of the meteorological weather patterns at that time of year in that part of Switzerland. We now perform the same analysis for the changes in the soil temperature.

![](images/0d8c8e7204ece648186d91f1d7dd6f5a2664e65a1939987b1f038bd9405c2bd5.jpg)  
Changes in the Soil Temperature

![](images/be3fa1b5a3ee61ce723d3cef89f115fd05b55a3f3db16e362f7f8f2643a404f4.jpg)  
ACF

![](images/db782108fef4cc780d0d97c0c0db014b25de66363c5e795048707be1e37ec7e1.jpg)  
PACF

In the course of our discussion of multivariate time series analysis, we will require some $A R M A ( p , q )$ models fitted to the changes in air and soil temperature. For the former series, model choice is not simple, as in both ACF and PACF, the coefficient at lag 4 sticks out. A grid search shows that an $A R ( 5 )$ model yields the best AIC value, and also, the residuals from this model do look as desired, i.e. it seems plausible that they are White Noise.

For the changes in the soil temperature, model identification is easier. ACF and PACF suggest either a MA(1) , an ARMA(2,1) or an AR(2) . From these three models, the MA(1) shows both the lowest AIC value as well as the “best looking” residuals. Furthermore, it is the parsimonious choice, and hence we got with it.

# 9.2 Cross Correlation

To begin with, we consider the (theoretical) cross covariance, the measure that describes the amount of linear dependence between the two time series processes. Firstly, we recall the definition of the within-series autocovariances, denoted by $\gamma _ { 1 1 } ( k )$ and $\gamma _ { 2 2 } ( k )$ :

$$
\gamma_ {1 1} (k) = \operatorname {C o v} \left(X _ {1, t + k}, X _ {1, t}\right), \gamma_ {2 2} (k) = \operatorname {C o v} \left(X _ {2, t + k}, X _ {2, t}\right)
$$

The cross covariances between the two processes $X _ { 1 }$ and $X _ { 2 }$ are given by:

$$
\gamma_ {1 2} (k) = \operatorname {C o v} \left(X _ {1, t + k}, X _ {2, t}\right), \gamma_ {2 1} (k) = \operatorname {C o v} \left(X _ {2, t + k}, X _ {1, t}\right)
$$

Note that owing to the stationarity of the two series, the cross covariances $\gamma _ { 1 2 } ( k )$ and $\gamma _ { 2 1 } ( k )$ both do not depend on the time t. Moreover, there is some obvious symmetry in the cross covariance:

$$
\gamma_ {1 2} (- k) = \operatorname {C o v} \left(X _ {1, t - k}, X _ {2, t}\right) = \operatorname {C o v} \left(X _ {1, t}, X _ {2, t + k}\right) = \gamma_ {2 1} (k)
$$

Thus, for practical purposes, it suffices to consider $\gamma _ { 1 2 } ( k )$ for positive and negative values of $k$ . Note that we will preferably work with correlations rather than covariances, because they are scale-free and thus easier to interpret. We can obtain the cross correlations by standardizing the cross covariances:

$$
\rho_ {1 2} (k) = \frac {\gamma_ {1 2} (k)}{\sqrt {\gamma_ {1 1} (0) \gamma_ {2 2} (0)}}, \rho_ {2 1} (k) = \frac {\gamma_ {2 1} (k)}{\sqrt {\gamma_ {1 1} (0) \gamma_ {2 2} (0)}}.
$$

Not surprisingly, we also have symmetry here, i.e. $\rho _ { 1 2 } ( - k ) = \rho _ { 2 1 } ( k )$ . Additionally, the cross correlations are limited to the interval between -1 and $+ 1$ , i.e. $| \rho _ { 1 2 } ( k ) | { \leq } 1$ . As for the interpretation, $\rho _ { 1 2 } ( k )$ measures the linear association between two values of $X _ { 1 }$ and $X _ { 2 }$ , if the value of the first time series is $k$ steps ahead. Concerning estimation of cross covariances and cross correlations, we apply the usual sample estimators:

$$
\hat {\gamma} _ {1 2} (k) = \frac {1}{n} \sum_ {t} \left(x _ {1, t + k} - \bar {x} _ {1}\right) \left(x _ {2, t} - \bar {x} _ {2}\right) \text {a n d} \hat {\gamma} _ {2 1} (k) = \frac {1}{n} \sum_ {t} \left(x _ {2, t + k} - \bar {x} _ {2}\right) \left(x _ {1, t} - \bar {x} _ {1}\right),
$$

where the summation index $t$ for $k \geq 0$ goes from 1 to $n - k$ and for $k < 0$ goes from $1 - k$ to $n$ . With $\overline { { x } } _ { 1 }$ and $\overline { { x } } _ { 2 }$ we denote the mean values of $x _ { 1 , t }$ and $x _ { 2 , t }$ , respectively. We define the estimation of the cross-correlations as

$$
\hat {\rho} _ {1 2} (k) = \frac {\hat {\gamma} _ {1 2} (k)}{\sqrt {\hat {\gamma} _ {1 1} (0) \hat {\gamma} _ {2 2} (0)}}, \hat {\rho} _ {2 1} (k) = \frac {\hat {\gamma} _ {2 1} (k)}{\sqrt {\hat {\gamma} _ {1 1} (0) \hat {\gamma} _ {2 2} (0)}}.
$$

The plot of $\hat { \rho } _ { 1 2 } ( k )$ against $k$ is called the cross-correlogram. Note that this must be viewed for both positive and negative $k$ . In R, we the job is done by the acf() function, applied to a multiple time series object.

> both <- ts.union(diff(air.na), diff(soil.na)) > acf(both, na.action ${ \bf \Phi } = { \bf \Phi }$ na.pass, ylim $\scriptscriptstyle \equiv _ { \mathrm { \scriptsize { C } } }$ (-1,1))

![](images/b128d42017bd9c732eb351e0fbcbb89b666863e450fb5c8f7e5e3ff3806069f1.jpg)  
air.changes

![](images/25d068a1381d788077e7c379062aa39dd434a2d6027862ca94c25c434c535e91.jpg)  
air.changes & soil.changes

![](images/a026e9ea086018f0cd5fa0831b078939cf65583174ae0df14a54cecee0f56f7b.jpg)  
soil.changes & air.changes

![](images/e31443fed3abc187581418beceb3f6e39af90494827b56afcbc7bc16ad4c7fd3.jpg)  
soil.changes

The top left panel shows the ACF of the differenced air temperature, the bottom right one holds the pure autocorrelations of the differenced soil temperature. The two off-diagonal plots contains estimates of the cross correlations: The top right panel has $\hat { \rho } _ { 1 2 } ( k )$ for positive values of $k$ , and thus shows how changes in the air temperature depend on changes in the soil temperature.

Note that we do not expect any significant correlation coefficients here, because the ground temperature has hardly any influence on the future air temperature at all. Conversely, the bottom left panel shows $\hat { \rho } _ { 1 2 } ( k )$ for negative values of $k$ , and thus how the changes in the soil temperature depend on changes in the air temperature. Here, we expect to see significant correlation.

# 9.2.1 Interpreting the Cross Correlogram

Interpreting the cross correlogram is tricky, because the within-series dependency results in a mixing of the correlations. It is very important to note that the confidence bounds shown in the above plots are usually wrong and can thus be strongly misleading. If not the additional steps to be discussed below are taken, interpreting the raw cross correlograms will lead to false conclusions.

The reason for these problems is that the variances and covariances of the $\hat { \rho } _ { 1 2 } ( k )$ are very complicated functions of $\rho _ { 1 1 } ( j ) , \rho _ { 2 2 } ( j )$ and $\rho _ { 1 2 } ( j ) , j \in \mathbb { Z }$ . For illustrative purposes, we will treat some special cases explicitly.

# Case 1: No correlation between the two series for large lags

In the case where the cross correlation $\rho _ { 1 2 } ( j ) = 0$ for $| j | \geq m$ , we have for $\mid k \mid \geq m$ :

$$
V a r \left(\hat {\rho} _ {1 2} (k)\right) \approx \frac {1}{n} \sum_ {j = - \infty} ^ {\infty} \left\{\rho_ {1 1} (j) \rho_ {2 2} (j) + \rho_ {1 2} (j + k) \rho_ {1 2} (j - k) \right\}.
$$

Thus, the variance of the estimated cross correlation coefficients goes to zero for $\$ 1$ \rightarrow \infty $\$ 9$ , but for a deeper understanding with finite sample size, we must know all true auto and cross-correlations, which is of course impossible in practice.

# Case 2: No correlation between the series for all lags

If the two processes $X _ { 1 }$ and $X _ { 2 }$ are independent, i.e. $\rho _ { 1 2 } ( j ) \equiv 0$ for all $j$ , then the variance of the cross correlation estimator simplifies to:

$$
\operatorname {V a r} \left(\hat {\rho} _ {1 2} (k)\right) \approx \frac {1}{n} \sum_ {j = - \infty} ^ {\infty} \rho_ {1 1} (j) \rho_ {2 2} (j).
$$

If, for example, $X _ { 1 }$ and $X _ { 2 }$ are two independent $A R ( 1 )$ processes with parameters $\alpha _ { \mathrm { _ 1 } }$ and $\alpha _ { 2 }$ , then $\rho _ { 1 1 } ( j ) = \alpha _ { 1 } ^ { | j | }$ , $\rho _ { 2 2 } ( j ) = \alpha _ { 2 } ^ { | j | }$ and $\rho _ { 1 2 } ( j ) \equiv 0$ . For the variance of $\hat { \rho } _ { 1 2 } ( k )$ we have, because the autocorrelations form a geometric series:

$$
V a r (\hat {\rho} _ {1 2} (k)) \approx \frac {1}{n} \sum_ {j = - \infty} ^ {\infty} (\alpha_ {1} \alpha_ {2}) ^ {| j |} = \frac {1}{n} \frac {1 + \alpha_ {1} \alpha_ {2}}{1 - \alpha_ {1} \alpha_ {2}}.
$$

For $\alpha _ { \mathrm { 1 } }  1$ and $\alpha _ { 2 }  1$ this expression goes to $\infty$ , i.e. the estimator $\hat { \rho } _ { 1 2 } ( k )$ can, for a finite time series, differ greatly from the true value 0 . We would like to illustrate this with two simulated $A R ( 1 )$ processes with $\mathcal { \alpha } _ { 1 } = \mathcal { \alpha } _ { 2 } = 0 . 9$ . According to theory all cross-correlations are 0. However, as we can see in the figure on the next page, the estimated cross correlations differ greatly from 0, even though the length of the estimated series is 200. In fact, $2 \sqrt { V a r ( \hat { \rho } _ { 1 2 } ( k ) ) } \approx 0 . 4 4$ , i.e. the $9 5 \%$ confidence interval is $\$ 1000.445$ . Thus even with an estimated cross-correlation of 0.4 the null hypothesis “true cross-correlation is equal to $0 ^ { \dprime }$ cannot be rejected.

# Case 3: No cross correlations for all lags and one series uncorrelated

Only now, in this special case, the variance of the cross correlation estimator is significantly simplified. In particular, if $X _ { 1 }$ is a White Noise process which is independent of $X _ { 2 }$ , we have, for large $n$ and small $k$ :

$$
\operatorname {V a r} \left(\hat {\rho} _ {1 2} (k)\right) \approx \frac {1}{n}.
$$

Thus, in this special case, the rule of thumb $\pm 2 / { \sqrt { n } }$ yields a valid approximation to a $9 5 \%$ confidence interval for the cross correlations and can help to decide whether they are significantly or just randomly different from zero.

![](images/f2ec7e9ad55bb7ebc1238d5b3dd3ffa7beb70e418bf85c2c160a19e4ff373d92.jpg)

![](images/7cee30a66564eab4123cf4b54da3565a7a7cff9ade33d4d537e9d2a657d037d6.jpg)

![](images/72c4cf0fea576ad4bd7be9d6373c2e42bd7f7237a68a8e4bf2ba2c2177c5e0cf.jpg)

![](images/c8a8ffe7a0a2c8ab9a2aae6992844cd0f2ce7b6177779428470dbbf44d6e380e.jpg)

In most practical examples, however, the data will be auto- and also cross correlated. Thus, the question arises whether it is at all possible to do something here. Fortunately, the answer is yes: with the method of prewhitening, described in the next chapter, we do obtain a theoretically sound and practically useful cross correlation analysis.

# 9.3 Prewhitening

The idea behind prewhitening is to transform one of the two series such that it is uncorrelated, i.e. a White Noise series, which also explains the name of the approach. Formally, we assume that the two stationary processes $X _ { 1 }$ and $X _ { 2 }$ can be transformed as follows:

$$
U _ {t} = \sum_ {i = 0} ^ {\infty} a _ {i} X _ {1, t - i}
$$

$$
V _ {t} = \sum_ {i = 0} ^ {\infty} b _ {i} X _ {2, t - i}
$$

Thus, we are after coefficients $a _ { i }$ and $b _ { i }$ such that an infinite linear combination of past terms leads to White Noise. We know from previous theory that such a representation exists for all stationary and invertible $A R M A ( p , q )$ processes, it is the $A R ( \infty )$ representation. For the cross-correlations between $U _ { t }$ and $V _ { t }$ and between $X _ { t }$ and $Y _ { { t } }$ , the following relation holds:

$$
\rho_ {U V} (k) = \sum_ {i = 0} ^ {\infty} \sum_ {j = 0} ^ {\infty} a _ {i} b _ {j} \rho_ {X _ {1} X _ {2}} (k + i - j)
$$

We conjecture that for two independent processes $X _ { 1 }$ and $X _ { 2 }$ , where all cross correlation coefficients $\rho _ { X _ { 1 } X _ { 2 } } ( k ) = 0$ , also all $\rho _ { U V } ( k ) = 0$ . Additionally, the converse is also true, i.e. it follows from ${ } ^ { * } U _ { t }$ and $V _ { t }$ uncorrelated” that the original processes $X _ { 1 }$ and $X _ { 2 }$ are uncorrelated, too. Since $U _ { t }$ and $V _ { t }$ are White Noise processes, we are in the above explained case 3, and thus the confidence bounds in the cross correlograms are valid. Hence, any cross correlation analysis on “real” time series starts with representing them in terms of $u _ { t }$ and $\nu _ { t }$ .

# Example: $A R ( 1 )$ Simulations

For our example with the two simulated $A R ( 1 )$ processes, we can estimate the AR model coefficients with the Burg method and plug them in for prewhitening the series. Note that this amounts considering the residuals from the two fitted models!

$$
u _ {t} = x _ {1, t} - \hat {\alpha} _ {1} x _ {1, t - 1}, \text {w h e r e} \hat {\alpha} _ {1} = 0. 8 8 9, \text {a n d}
$$

$$
v _ {t} = x _ {2, t} - \hat {\alpha} _ {2} x _ {2, t - 1}, \text {w h e r e} \hat {\alpha} _ {2} = 0. 9 1 7.
$$

![](images/24aee8f799632b9d4d058cf23c9c30fac3c6780c3a6573e2d52167a6941b6c96.jpg)

![](images/f35d063584225a93c9610b0529e5054033a9a6989b35a5257f53dbbb7bac1605.jpg)

![](images/2155f37e1beca84f789798da54479218fb1d07ce081361a10b1299980e9e7452.jpg)

![](images/e775c40dfd6297d566673946fb03f29ff88018a6ffec6428de7146162866e62f.jpg)

The figure on the previous page shows both the auto and cross correlations of the prewhitened series. We emphasize again that we here consider the residuals from the AR(1) models that were fitted to series $X _ { 1 }$ and $X _ { 2 }$ . We observe that, as we expect, there are no significant autocorrelations, and there is just one cross correlation coefficient that exceeds the $9 5 \%$ confidence bounds. We can attribute this to random variation.

The theory suggests, because $U _ { t }$ and $V _ { t }$ are uncorrelated, that also $X _ { 1 }$ and $X _ { 2 }$ do not show any linear dependence. Well, owing to how we set up the simulation, we know this for a fact, and take the result as evidence that the prewhitening approach works in practice.

# Example: Air and Soil Temperatures

For verifying whether there is any cross correlation between the changes in air and soil temperatures, we have to perform prewhitening also for the two differenced series. Previously, we had identified an $A R ( 5 )$ and a MA(1) model as. We can now just take their residuals and perform a cross correlation analysis:

```r
> fit.air <- arima(diff(air.na), order=c(5,0,0))  
> fit.soil <- arima(diff(soil.na), order=c(0,0,1))  
> u.air <- resid(fit.air); v.soil <- resid(fit.soil)  
> acf(ts.union(u.air, v.soil), na.action=na.pass) 
```

![](images/664e1311eaa2cd254faddd433713d5d3a910c069eaf75833d59d55d20169722d.jpg)

![](images/3047e7a7c53eab369a5f28ce1cdccbd029b259d4018358dc7e43abf95d4f8044.jpg)

![](images/9ace8adde27ee191f75bf7ff1d1bc93a37ff5efdf85d0715f4bb9b0a5f419ca6.jpg)

![](images/17e89d9cb484ec8147a50e97880599151abc7cdd9e55ee145c186e547beab318.jpg)

The bottom left panel shows some significant cross correlations. A change in the air temperature seems to induce a change in the ground with a lag of 1 or 2 days.

# 9.4 Transfer Function Models

In the previous section we had observed significant cross correlations between the prewhitened air and soil temperature changes. This means that the cross correlations between the original air and soil temperature changes will also be different from zero. However, due to the prewhitening, inferring the magnitude of the linear association is different. The aim of this section is to clarify this issue.

The transfer function models are a possible way to capture the dependency between two time series. We must assume that the first series influences the second, but the second does not influence the first. Furthermore, the influence occurs only at simultaneously or in the future, but not on past values. Both assumptions are met in our example. The transfer function model is:

$$
X _ {2, t} - \mu_ {2} = \sum_ {j = 0} ^ {\infty} \nu_ {j} \left(X _ {1, t - j} - \mu_ {1}\right) + E _ {t}
$$

We call $X _ { 1 }$ the input and correspondingly, $X _ { 2 }$ is named the output. For the error term $E _ { t }$ we require zero expectation and that they are independent from the input series, in particular:

$$
E \left[ E _ {t} \right] = 0 \text {a n d} C o v \left(E _ {t}, X _ {1, s}\right) = 0 \text {f o r a l l} t \text {a n d} s.
$$

However, the errors $E _ { t }$ are usually autocorrelated. Note that this model is very similar to the time series regression model. However, here we have infinitely many unknown coefficients $\nu _ { j }$ , i.e. we do not know (a priori) on which lags to regress the input for obtaining the output. For the following theory, we assume (w.l.o.g.) that $\mu _ { 1 } = \mu _ { 2 } = 0$ , i.e. the two series were adjusted for their means. In this case the cross covariances $\gamma _ { 2 1 } ( k )$ are given by:

$$
\gamma_ {2 1} (k) = C o v (X _ {2, t + k}, X _ {1, t}) = C o v (\sum_ {j = 0} ^ {\infty} \nu_ {j} X _ {1, t + k - j}, X _ {1, t}) = \sum_ {j = 0} ^ {\infty} \nu_ {j} \gamma_ {1 1} (k - j).
$$

In cases where the transfer function model has a finite number of coefficients $\nu _ { j }$ only, i.e. $\nu _ { _ j } = 0$ for $j > K$ , then the above formula turns into a linear system of $K + 1$ equations that we could theoretically solve for the unknowns $\nu _ { j } , j = 0 , . . . , K$ .

If we replaced the theoretical $\gamma _ { 1 1 }$ and $\gamma _ { 2 1 }$ by the empirical covariances $\hat { \gamma } _ { 1 1 }$ and $\hat { \gamma } _ { 2 1 }$ , this would yield, estimates $\hat { \nu } _ { j }$ . However, this method is statistically inefficient and the choice of $K$ proves to be difficult in practice. We again resort to some special case, for which the relation between cross covariance and transfer function model coefficients simplifies drastically.

# Special Case: Uncorrelated input series $X _ { 1 }$

In this case, $\gamma _ { 1 1 } ( k ) = 0$ for $k \neq 0$ and we have $\gamma _ { _ { 2 1 } } ( k ) = \nu _ { _ { k } } \gamma _ { _ { 1 1 } } ( 0 )$ . For the coefficients $\nu _ { \scriptscriptstyle k }$ this results in the simplified transfer function model:

$$
\nu_ {k} = \frac {\gamma_ {2 1} (k)}{\gamma_ {1 1} (0)} = \rho_ {2 1} \sqrt {\frac {\gamma_ {2 2} (0)}{\gamma_ {1 1} (0)}}, \text {f o r} k \geq 0.
$$

However, $X _ { 1 }$ generally is not a White Noise process. We can resort to prewhitening the input series. As we will show below, we can obtain an equivalent transfer function model with identical coefficients if a smart transformation is

applied to the output series. Namely, we have to filter the output with the model coefficients from the input series.

$$
X _ {1, t} = 0. 2 9 6 \cdot X _ {1, t - 1} - 0. 2 4 2 \cdot X _ {1, t - 2} - 0. 1 1 9 \cdot X _ {1, t - 3} - 0. 4 9 7 \cdot X _ {1, t - 4} + 0. 2 1 6 \cdot X _ {1, t - 5} + D _ {t},
$$

where $D _ { t }$ is the innovation, i.e. a White Noise process, for which we estimate the variance to be $\hat { \sigma } _ { D } ^ { 2 } = 2 . 3 9 2$ . We now solve this equation for $D _ { t }$ and get:

$$
\begin{array}{l} D _ {t} = X _ {1, t} - 0. 2 9 6 \cdot X _ {1, t - 1} + 0. 2 4 2 \cdot X _ {1, t - 2} + 0. 1 1 9 \cdot X _ {1, t - 3} + 0. 4 9 7 \cdot X _ {1, t - 4} - 0. 2 1 6 \cdot X _ {1, t - 5} \\ = (1 - 0. 2 9 6 B + 0. 2 4 2 B ^ {2} + 0. 1 1 9 B ^ {3} + 0. 4 9 7 B ^ {4} - 0. 2 1 6 B ^ {5}) X _ {1, t} \\ \end{array}
$$

We now apply this same transformation, i.e. the characteristic polynomial of the AR(5) also on the output series $X _ { 2 }$ and the transfer function model errors $E _ { t }$ :

$$
\begin{array}{l} Z _ {t} = \left(1 - 0. 2 9 6 B + 0. 2 4 2 B ^ {2} + 0. 1 1 9 B ^ {3} + 0. 4 9 7 B ^ {4} - 0. 2 1 6 B ^ {5}\right) X _ {2, t} \\ U _ {t} = (1 - 0. 2 9 6 B + 0. 2 4 2 B ^ {2} + 0. 1 1 9 B ^ {3} + 0. 4 9 7 B ^ {4} - 0. 2 1 6 B ^ {5}) E _ {t}. \\ \end{array}
$$

We can now equivalently write the transfer function model with the new processes $D _ { t } , Z _ { t }$ and $U _ { t }$ . It takes the form:

$$
Z _ {t} = \sum_ {j = 0} ^ {\infty} \nu_ {j} D _ {t - j} + U _ {t},
$$

where the coefficients $\nu _ { j }$ are identical than for the previous formulation of the model. The advantage of this latest formulation, however, is that the input series $D _ { t }$ is now White Noise, such that the above special case applies, and the transfer function model coefficients can be obtained by a straightforward computation from the cross correlations:

$$
\hat {v} _ {k} = \frac {\hat {\gamma} _ {2 1} (k)}{\hat {\sigma} _ {D} ^ {2}} = \frac {\hat {\sigma} _ {Z}}{\hat {\sigma} _ {D}} \hat {\rho} _ {2 1} (k), \text {w h e r e} k \geq 0.
$$

where $\hat { \gamma } _ { 2 1 }$ and $\hat { \rho } _ { { } _ { 2 1 } }$ denote the empirical cross covariances and cross correlations of $D _ { t }$ and $Z _ { t }$ . However, keep in mind that $Z _ { t }$ and $U _ { t }$ are generally correlated. Thus, the outlined method is not a statistically efficient estimator either. While efficient approaches exist, we will not discuss them in this course and scriptum. Furthermore, for practical application the outlined procedure usually yields reliable results. We conclude this section by showing the results for the permafrost example: the transfer function model coefficients in the example are based on the cross correlation between the $A R ( 5 )$ residuals of the air changes and the ground changes that had been filtered with these $A R ( 5 )$ coefficients.

```txt
> dd.air <- resid fit.air)  
> coefs <- coef (fit.air) [1:5])  
> zz.soil <- filter(diff(soil.na), c(1, -coefs, sides=1)  
> as.int <- ts.intersect(dd.air, zz.soil)  
> acf.val <- acf(as.int, na.action = na.pass) 
```

![](images/89a3d23cc7a312c5c6c99cc586525ea2543075c8d76a2de4c99bb7eb439c9f8b.jpg)

![](images/1e7eb6cbdfe50c728b250374afc0191c31da6d642561fa44825b0a5f9e08caee.jpg)

![](images/645e666b7648749da3d94c6f001ab8665c01a7da7494d8f6913c92a72057d76c.jpg)

![](images/71d0c83bf906808083625fd3562ff08e6e7ece7172d1c3a3fc169f4aae72d9f8.jpg)

Again, in all except for the bottom left panel, the correlation coefficients are mostly zero, respectively only insignificantly or by chance different from that value. This is different in the bottom left panel. Here, we have substantial cross correlation at lags 1 and 2. Also, these values are proportional to the transfer function model coefficients. We can extract these as follows:

```txt
> multip <- sd(zz.soil, na.rm=TRUE)/sd(dd.air, na.rm=TRUE)
> multip*acf.val$acf[,2,1] 
```

[1] 0.054305137 0.165729551 0.250648114 0.008416697   
[5] 0.036091971 0.042582917 -0.014780751 0.065008411   
[9] -0.002900099 -0.001487220 -0.062670672 0.073479065  
[13] -0.049352348 -0.060899602 -0.032943583 -0.025975790

Thus, the soil temperature in the permafrost boreholes reacts to air temperature changes with a delay of 1-2 days. An analysis of further boreholes has suggested that the delay depends on the type of terrain in which the measurements were made. Fastest response times are found for a very coarse-blocky rock glacier site, whereas slower response times are revealed for blocky scree slopes with smaller grain sizes.

# 10 Spectral Analysis

During this course, we have encountered several time series which show periodic behavior. Prominent examples include the number of shot lynx in the Mackenzie River district in Canada, as well as the wave tank data from section 4.4. In these series, the periodicity is not deterministic, but stochastic. An important goal is to understand the cycles at which highs and lows in the data appear.

In this chapter, we will introduce spectral analysis as a descriptive means for showing the character of, and the dependency structure within a time series. This will be based on interpreting the series as a superposition of cyclic components, namely as a linear combination of harmonic oscillations. We will introduce the periodogram, where the aim is to show which frequencies contribute most importantly to the variation in the series.

In spirit, such an analysis is related to the correlogram. In fact, one can show that the information in the correlogram and the periodogram are mathematically equivalent. However, the two approaches still provide different, complementary views on a series and it is thus often worthwhile to pursue both approaches. Finally, we here also mention that in some areas time series are preferably analyzed in the time domain, whereas in other applied fields, e.g. electrical engineering, geophysics and econometrics, the frequency approach predominates.

# 10.1 Decomposing in the Frequency Domain

We will here first introduce some background and theory on how to decompose time series into cyclic components and then lay the focus on the efficient estimation of these.

# 10.1.1 Harmonic Oscillations

The simplest and best known periodic functions are sine and cosine. It is thus appealing to use these as a basis for decomposing time series. A harmonic oscillation is of the form

$$
y (t) = a \cdot \cos (2 \pi \nu t - \phi).
$$

Here, we call $a$ the amplitude, $\nu$ is the frequency and $\phi$ is the phase. Apparently, the function $y ( t )$ is periodic, and the period is $T = 1 / \nu$ . It is common to write the above harmonic oscillation in a different form, i.e.:

$$
y (t) = \alpha \cdot \cos (2 \pi \nu t) + \beta \cdot \sin (2 \pi \nu t),
$$

where in fact $\alpha = a \cos ( \phi )$ and $\beta = a \sin ( \phi )$ . The advantage of this latter form is that if we want to fit a harmonic oscillation with fixed frequency to data, which means estimating amplitude and phase, we face a linear problem instead of a non-linear one, as it was the case in the previous formulation. The time can be either continuous or discrete. In the context of our analysis of discrete time series, only the latter will be relevant.

Now, if fitting a harmonic oscillation to discrete data, we face an identification problem: If frequency $\nu$ fits, then all higher frequencies such as $\nu + 1 , \nu + 2 , . .$ ..  will fit as well. This phenomenon is known as aliasing. The plot below shows harmonics where $a = 1$ and $\phi = 0$ . As frequencies, we choose both $\nu = 1 / 6$ and $\nu = 1 + 1 / 6$ .We observe that we cannot decide upon which of the two frequencies generated our discrete time observations. Naturally, the time resolution of our series determines which frequencies we can identify. Or more clearly: we take the point that our data do not allow to identify periodicities with frequency $\nu > 1 / 2$ , i.e. that harmonics which oscillate more than once between two observations.

# 10.1.2 Superposition of Harmonics

In a real-world stationary time series, it is rare to inexistent that only one single periodicity that can be attributed to a single frequency makes up for all the variation that is observed. Thus, for a decomposition of the series into a number of periodicities with different frequency, we choose the regression approach:

$$
X _ {t} = \alpha_ {0} + \sum_ {k = 1} ^ {m} \left(\alpha_ {k} \cos \left(2 \pi \nu_ {k} t\right) + \beta_ {k} \sin \left(2 \pi \nu_ {k} t\right)\right) + E _ {t},
$$

where $\alpha _ { k } ^ { } , \beta _ { k } ^ { }$ are interpreted as the unknown parameters, $E _ { t }$ is an iid error term with expectation zero and $\nu _ { 1 } , . . . , \nu _ { m }$ is a set of pre-defined frequencies. Under these assumptions, we can obtain estimates $\hat { \alpha } _ { k }$ , $\hat { \beta } _ { k }$ with the ordinary least squares algorithm. As for the frequencies, we choose multiples of $1 / n$ , i.e.

$$
\nu_ {k} = k / n, \text {f o r} k = 1, \dots , m \text {w i t h} m = \left\lfloor n / 2 \right\rfloor .
$$

These are called the Fourier frequencies. Using some mathematics, one can prove that the above regression problem has an orthogonal design. Thus, the estimated coefficients ˆ ,  $\hat { \beta } _ { k }$ are uncorrelated and (for $k > 0$ ) have variance $2 \sigma _ { E } ^ { 2 } / 2$ . Because we are also spending $n$ parameters for the $n$ observations, the frequency decomposition model fits perfectly, i.e. all residuals are zero. Another very important result is that the

$$
\text {s u m o f s q u a r e d r e s i d u a l s} \sum_ {i = 1} ^ {n} r _ {i} ^ {2} \text {i n c r e a s e s b y} \frac {n}{2} \left(\hat {\alpha} _ {k} ^ {2} + \hat {\beta} _ {k} ^ {2}\right)
$$

if the frequency $\nu _ { k }$ is omitted from the model. We can use this property to gauge the prominence of a particular frequency in the decomposition model, and exactly that is the aim with the periodogram which will be discussed below.

# 10.1.3 The Periodogram

The periodogram quantifies the presence of periodicities in a time series. It is based on half of the increase in sum of squared residuals in the decomposition model if a particular frequency is omitted. We can rewrite that directly as a function of the observations:

$$
\begin{array}{l} I _ {n} (\nu_ {k}) = \frac {n}{4} (\hat {\alpha} _ {k} ^ {2} + \hat {\beta} _ {k} ^ {2}) \\ = \frac {1}{n} \left(\sum_ {t = 1} ^ {n} x _ {t} \cos (2 \pi \nu_ {k} t)\right) ^ {2} + \frac {1}{n} \left(\sum_ {t = 1} ^ {n} x _ {t} \sin (2 \pi \nu_ {k} t)\right) ^ {2} \\ \end{array}
$$

The result is then plotted versus the frequency $\nu _ { \scriptscriptstyle k }$ , and this is known as the raw periodogram. In R, we can use the convenient function spec.pgram(). We illustrate its use with the lynx and the wave tank data:

> spec.pgram(log(lynx), log="no", type="h")   
$>$ spec.pgram(wave, log="no", type="h")

![](images/8a23d28a9550faa2863fcef496df6ef41d819fcfa04357f0123eba3305d4ed88.jpg)  
Time Series Plot of log(lynx)

![](images/b581a3a901fa75c9b9bcc1bd8e960f8e776e2da520a2f3a355d8401cf78c189e.jpg)  
Time Series Plot of Wave Tank Data

![](images/8c5f16e3b98031b10c31f4312883bbc5c08b9c9e40ee8af0727140418be8e745.jpg)  
Raw Periodogram of log(lynx)

![](images/f98079e27eed3cdcc1181ef3d992f995aac2c8ab5a6c5c39fc204edfdab077fe.jpg)  
Raw Periodogram of Wave Tank Data

The periodogram of the logged lynx data is easy to read: the most prominent frequencies in this series with 114 observations are the ones near 0.1, more exactly, these are $\nu _ { { } _ { 1 1 } } = 1 1 / 1 1 4 = 0 . 0 9 6$ and $\nu _ { _ { 1 2 } } = 1 2 / 1 1 4 = 0 . 1 0 5$ . The period of these frequencies is $1 / \nu _ { _ k }$ and thus, $1 1 4 / 1 1 = 1 0 . 3 6$ and $1 1 4 / 1 2 = 9 . 5 0 $ . This suggests that the series shows a peak at around every $1 0 ^ { \mathrm { t h } }$ observation which is clearly the case in practice. We can also say that the highs/lows appear between 11 and 12 times in the series. Also this can easily be verified in the time series plot.

Then, there is a secondary peak at $\nu _ { 3 } = 3 / 1 1 4$ . This must be a cyclic component that appears three times in our data, and the period is $1 1 4 / 3 = 3 8 $ . Thus, these are the 40-year-superhighs and -lows that we had identified already earlier.

For the wave tank data, we here consider the first 120 observations only. The periodogram is not as clean as for the logged lynx data, but we will try with an interpretation, too. The most prominent peaks are at $k = 1 2$ , 17 and 30 . Thus we have a superposition of cycles which last 4, 7 and 10 observations. The verification is left to you.

# 10.1.4 Leakage

While some basic inspections of the periodogram can and sometimes do already provide valuable insight, there are a few issues which need to be taken care of. The first one which is discussed here is the phenomenon called leakage. It appears if there is no Fourier frequency that corresponds to the true periodicity in the data. Usually, the periodogram then shows higher values in the vicinity of the true frequency. The following simulation example is enlightening:

$$
X _ {t} = \cos \left(\frac {2 \pi \cdot 1 3 \cdot t}{1 4 0}\right) + 0. 8 \cdot \cos \left(\frac {2 \pi \cdot 2 0 \cdot t}{1 4 0}\right), \text {f o r} t = 0, \dots , 1 3 9
$$

We have a series of 140 observations which is made up as the superposition of two harmonic oscillations with frequencies 13 /140 and 20 /140 . These correspond to periods of 7.00 and 10.77 , and both are Fourier frequencies. We display the time series plot, as well as the periodogram:

![](images/9f4eb5e2dd50ca82ca75d3cc8b9f36337bd876759db11f135aa5fa663d0b9fcd.jpg)

![](images/e9cc905ead496cdcdd82d79b02fa00753c18a501904a811d80c9fafd3e0bc1d9.jpg)

Now if we shorten this very same series by 16 data points so that 124 observations remain, the true frequencies 20 /140 and 13 /140 do no longer appear in the decomposition model, i.e. are not Fourier frequencies anymore. The periodogram now shows leakage:

![](images/b1e0c8554701ff9cc88afacc569d5206178cc55f61f0387c90410cd873ff3624.jpg)  
Raw Periodogram of Shortened Series

If not all of the true frequencies in the data generating model are Fourier frequencies, then, $\hat { \alpha } _ { k } , \hat { \beta } _ { k }$ $\hat { \beta } _ { k }$ from the decomposition model are only approximations to the true contribution of a particular frequency for the variation in the series.

# 11 State Space Models

State space modeling is a very flexible tool that from which one can benefit in almost all applied fields. It would certainly merit an own full course, exclusively focusing on its applied aspects. Due to restrictions in time, we here provide only a small overview on the potential and a few examples. While one can write most time series models in state space formulation, it is usually simpler to do without, and use their own genuine notation. The real benefits of state space models only come into play when one has to deal with observations that are blurred with additional measurement noise, or in situations, where some parameters are required to adapt over time.

We will here first introduce the general formulation of state space models, and then illustrate with a number of examples. The first two concern AR processes with additional observation noise, then there are two regressions with time-varying coefficients, and finally we consider a linear growth model. The conditional means and variances of the state vectors are usually estimated with the Kalman Filter. Because this is mathematically rather complex topic, and not in the primary focus of the applied user, this scriptum only provides the coarse rationale for it.

# 11.1 State Space Formulation

State space models are built on two equations. One is the state equation, and the other is the observation equation. We here introduce the general notation; their meaning will become clearer with the examples discussed below.

# State Equation

The state of the system at time t is represented by a column vector $X _ { t }$ , and it is a linear transformation of the state at time $t - 1$ , plus some random vector $W _ { t }$ (system noise) from a multivariate normal distribution. The linear transformation of the state at time $t - 1$ is defined with a matrix $G _ { t }$ , and the covariance matrix of the multivariate normal is denoted with $w _ { t }$ .

$$
X _ {t} = G _ {t} X _ {t - 1} + W _ {t}, \text {w h e r e} W _ {t} \sim N (0, w _ {t})
$$

# Observation Equation

The observation at time $t$ is denoted by a column vector $Y _ { { t } }$ that is a linear combination of the states, determined by a matrix $F _ { t }$ , and random variation (measurement noise) from a normal distribution with covariance matrix $\nu _ { t }$ .

$$
Y _ {t} = F _ {t} X _ {t} + V _ {t}, \text {w h e r e} V _ {t} \sim N (0, v _ {t})
$$

Note that in this general formulation, all matrices can be time varying, but in most of our examples, they will be constant. Also, the nomenclature is different depending on the source, but we here adopt the notation of R.

# 11.2 AR Processes with Measurement Noise

We are interested in a stochastic process $X _ { t }$ (which may be an AR process). Then, one usually makes measurements to obtain observations, i.e. acquires a realization of the process. So far, we operated under the assumption that the measurements were error-free, i.e. that there was no measurement noise and our data were exact. In many cases where the data are measured using physical devices, this is hardly realistic, and we may rather have realizations of some random variable

$$
Y _ {t} = X _ {t} + V _ {t}, \text {w h e r e} V _ {t} \sim N \left(0, \sigma_ {V} ^ {2}\right).
$$

Thus, the realizations of the process of interest, $X _ { t }$ are latent, i.e. hidden under some random noise. We will now discuss how this issue can be solved in practice.

# Example: AR(1)

As the simplest example of a state space model, we consider an $A R ( 1 )$ process which is superposed with some additional measurement noise. The state equation is as follows:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + W _ {t}.
$$

We assume that $W _ { t }$ is an iid innovation with Gaussian distribution, i.e. $W _ { t } \sim N ( 0 , \sigma _ { w } ^ { 2 } )$ . Also note that matrix $G _ { t }$ has dimension $1 \times 1$ , is time-constant and equal to $\alpha _ { \mathrm { _ 1 } }$ . If there is additional measurement noise, our observations can be perceived as realizations of the random variable $Y _ { { t } }$ :

$$
Y _ {t} = X _ {t} + V _ {t}, \text {w h e r e} V _ {t} \sim N \left(0, \sigma_ {V} ^ {2}\right).
$$

This is the observation equation, note that $F _ { t }$ is also time-constant and equal to the $1 \times 1$ identity matrix. We here assume that the errors $V _ { t }$ are iid, and also independent of $X _ { s }$ and $W _ { s }$ for all $t$ and $s$ . It is important to note that $W _ { t }$ is the process innovation that impacts future instances $X _ { { t + k } }$ . In contrast, $V _ { t }$ is pure measurement noise with no influence on the future of process $X _ { t }$ . For illustration, we consider a simulation example. We use $\alpha _ { \mathrm { 1 } } = 0 . 7$ , the innovation variance $\sigma _ { { \scriptscriptstyle W } } ^ { 2 }$ is 0.1 and the measurement error variance $\sigma _ { { } _ { V } } ^ { 2 }$ is 0.5. The length of the simulated series is 100 observations. On the next page, we show a number of plots. They include a time series plot with both series $X _ { t }$ and $Y _ { { t } }$ , and the individual plots of $X _ { t }$ with its ACF/PACF, and of $Y _ { _ t }$ with ACF/PACF. We clearly observe that the appearance of the two processes is very different. While $X _ { t }$ looks like an autoregressive process, and has ACF and PACF showing the stylized facts very prominently, $Y _ { _ t }$ almost appears to be White Noise. We here know that this is not

true. There is some dependency also in $Y _ { { t } }$ , but it is blurred by strong noise component, and it seems like a difficult task to recover the weak underlying signal.

![](images/66cd9a1d387225cbdf7e83a3f4667fd531506037b93c7b1fe9b649bab4b91cb6.jpg)  
AR(1) Simulation Example

We here emphasize that the state space formulation allowed to write a model comprised of a true signal plus additional noise. However, if we face an observed series of this type, we are not any further yet. We need some means to separate the two components. Kalman filtering, which is implemented in R package sspir, allows doing so: it recovers the (expected value of) the states $X _ { t }$ by some recursive algorithm. For details see below.

![](images/acae3d468cbc9480e95f1aba5a9bbf38770dbd3a8427640da31574984db2c990.jpg)  
Process X_t

![](images/28b608b3508fc827d3bf3233e381e49d1d8f092e86f6bf2366a19a565162fa38.jpg)  
ACF of Process X_t

![](images/bf9f05225de2cea4a7e5fe08aaa9a006af68ee8d947471630a2a461a321fd076.jpg)  
PACF of Process X_t

![](images/8047bbc09c6c939ac006473ab4fa2eed564469ae7184a73557cd53d07736dfe9.jpg)  
Observed Y_t

![](images/feb6cfe7441b42731e6fd59c7597a2afb7e84fab7f6346429f2c39b257a9e334.jpg)  
ACF of Observed Y_t

![](images/c632ddb1386438ca32bd6e78ad72c87d5e5d7a69fe18ea7e1179f372d742b8e0.jpg)  
PACF of Observed Y_t

```r
> # Load the package for Kalman filtering
> library(sspir)
>
> # State Space Formulation
>ssf <- SS(y = as.matrix(obs),
>
		Fmat = function (tt,x,phi) \{return (matrix(1))\},
>
		Gmat = function (tt,x,phi) \{return (matrix(0.7))\},
>
	_Vmat = function (tt,x,phi) \{return (matrix(0.5))\},
>
	_Wmat = function (tt,x,phi) \{return (matrix(0.1))\},
>
		m0 = matrix(0),
>
		C0 = matrix(0.1))
>
> # # Kalman Filtering
> fit <- kfilterssf)
> plot (fit$m, col="blue", lwd=2, ...) 
```

Kalman filtering in R requires to specifiy the state space model first. We need to supply argument y which stands for the observed time series data. They have to come in form of a matrix. Moreover, we have to specify the matrices $F _ { t } , G _ { t }$ , as well as the covariance structures $\nu _ { t } , w _ { t }$ . In our case, these are all simple $1 \times 1$ matrices. Finally, we have to provide $\mathtt { m 0 }$ , the starting value of the initial state, and C0, the variance of the initial state.

![](images/9de2c497a5c9a0e4d666d6abc8e043a7d7dbd65f9c97acde7f14a564dbcb12a7.jpg)  
AR(1) Simulation Example with Kalman Filter Output

We can then employ the Kalman filter to recover the original signal $X _ { t }$ . It was added as the blue line in the above plot. While it is not $100 \%$ accurate, it still does a very good job of filtering the noise out. However, note that with this simulation example, we have some advantage over the real-life situation. Here, we could specify the correct state space formulation. In practice, we might have problems to identify appropriate values for $G _ { t }$ (the true $A R ( 1 )$ parameter) and the variances in $\nu _ { t } , w _ { t }$ . On the other hand, in reality the precision of many measurement devices is more or less known, and thus some educated guess is possible.

# Example: AR(2)

Here, we demonstrate the formulation of a state space model for an AR(2) process that is superimposed with some measurement error. This example is important, because now, we need to use matrices in the state equation. It is as follows:

$$
\left( \begin{array}{c} X _ {t} \\ X _ {t - 1} \end{array} \right) = \left( \begin{array}{c c} \alpha_ {1} & \alpha_ {2} \\ 1 & 0 \end{array} \right) \left( \begin{array}{c} X _ {t - 1} \\ X _ {t - 2} \end{array} \right) + \left( \begin{array}{c} W _ {t} \\ 0 \end{array} \right)
$$

Apparently, this is a two-dimensional model. The observation equation is:

$$
Y _ {t} = (1 0) \cdot \left( \begin{array}{c} X _ {t} \\ X _ {t - 1} \end{array} \right) + V _ {t}
$$

Once the equations are set up, it is straightforward to derive the matrices:

$$
G _ {t} = G = \left( \begin{array}{c c} \alpha_ {1} & \alpha_ {2} \\ 1 & 0 \end{array} \right), H _ {t} = H = (1 0), w _ {t} = \left( \begin{array}{c c} \sigma_ {W} ^ {2} & 0 \\ 0 & 0 \end{array} \right), v _ {t} = \sigma_ {V} ^ {2}
$$

Similar to the example above, we could now simulate from an $A R ( 2 )$ process, add some artificial measurement noise and then try to uncover the signal using the Kalman filter. This is left as an exercise.

# 11.3 Dynamic Linear Models

A specific, but very useful application of state space models is to generalize linear regression such that the coefficients can vary over time. We consider a very simple example where the sales manager in a house building company uses the following model: the company’s house sales at time $t$ , denoted as $S _ { t }$ , depends on the general levels of sales in that area $L _ { \mathrm { \Lambda } }$ and the company’s pricing policy $P _ { t }$ .

$$
S _ {t} = L _ {t} + \beta_ {t} P _ {t} + V _ {t}
$$

This is a linear regression model with price as the predictor, and the general level as the intercept. The assumption is that their influence varies over time, but generally only in small increments. We can use the following notation:

$$
\begin{array}{l} L _ {t} = L _ {t - 1} + \Delta L _ {t} \\ \beta_ {t} = \beta_ {t - 1} + \Delta \beta_ {t} \\ \end{array}
$$

In this model, we assume that $\nu _ { t } , \Delta L _ { t }$ and $\Delta \beta _ { t }$ are random deviations with mean zero that are independent over time. While we assume independence of $\Delta L _ { t }$ and $\Delta \beta _ { t }$ , we could also allow for correlation among the two. The relative magnitudes of these perturbations are accounted for with the variances in the matrices $V _ { t }$ and $W _ { t }$ of the state space formulation. Note that if we set $W _ { t } = 0$ , then we are in the case

of plain OLS regression with constant parameters. Hence, we can also formulate any regression models in state space form. Here, we have:

$$
Y _ {t} = S _ {t}, X _ {t} = \left( \begin{array}{c} L _ {t} \\ \beta_ {t} \end{array} \right), W _ {t} = \left( \begin{array}{c} \Delta L _ {t} \\ \Delta \beta_ {t} \end{array} \right), F _ {t} = \left( \begin{array}{c} 1 \\ P _ {t} \end{array} \right), G = \left( \begin{array}{c c} 1 & 0 \\ 0 & 1 \end{array} \right)
$$

Because we do not have any data for this sales example, we again rely on a simulation. Evidently, this has the advantage that we can evaluate the Kalman filter output versus the truth. Thus, we let

$$
y _ {t} = a + b x _ {t} + z _ {t}
$$

$$
x _ {t} = 2 + t / 1 0
$$

We simulate 30 data points from $t = 1 , . . . , 3 0$ and assume errors which are standard normally distributed, i.e. $z _ { t } \sim N ( 0 , 1 )$ . The regression coefficients are $a = 4$ and $b = 2$ for $t = 1 , . . . , 1 5$ and $a = 5$ and $b = - 1$ for $t = 1 6 , . . . , 3 0$ . We will fit a straight line with time-varying coefficients, as this is the model that matches what we had found for the sales example above.

```r
> ## Simulation
> set.seed(1)
> x1 <- 1:30
> x1 <- x1/10+2
> aa <- c(rep(4,15), rep(5,15))
> bb <- c(rep(2,15), rep(-1,15))
> nn <- length(x1)
> y1 <- aa + bb * x1 + rnorm(nn)
> x0 <- rep(1, nn)
> xx <- cbind(x0, x1)
> x.mat <- matrix(xx, nrow=nn, ncol=2)
> y.mat <- matrix(y1, nrow=nn, ncol=1)
>
>
## State Space Formulation
>ssf <- SS(y=y.mat, x=x.mat,
>
		Fmat=function (tt, x, phi)
		return (matrix(c(x[tt, 1], x[tt, 2]), 2, 1)),
	"Gmat=function (tt, x, phi) return (diag(2)),"
	"Wmat=function (tt, x, phi) return (0.1*diag(2)),"
	"Vmat=function (tt, x, phi) return (matrix(1)),"
	"m0=matrix(c(5, 3), 1, 2),
	"C0=10*diag(2))"
>
>
## Kalman-Filtering
> fit <- kfilter(ssf)
> par(mfrow=c(1, 2))
> plot (fit\$m[,1], type="l", xlab="Time", ylab="")
> title("Kalman Filtered Intercept")
> plot (fit\$m[,2], type="l", xlab="Time", ylab="")
> title("Kalman Filtered Slope") 
```

![](images/8be932d27319adc3df4592abd3ddffadd1b3eea18e543d5b07b40ce90c796bc4.jpg)  
Kalman Filtered Intercept

![](images/31b33fbc45b6e034f65ee3072fd38aea580b16f4f2aa765fd2183b7437d028cb.jpg)  
Kalman Filtered Slope

The plots show the Kalman filter output for intercept and slope. The estimates pick up the true values very quickly, even after the change in the regime. It is worth noting that in this example, we had a very clear signal with relatively little noise, and we favored recovering the truth by specifying the state space formulation with the true error variances that are generally unknown in practice.

# Example: Batmobile

We here consider another regression problem where time-varying coefficients may be necessary. The description of the practical situation is as follows: In April 1979 the Albuquerque Police Department began a special enforcement program aimed at countering driving while intoxicated accidents. The program was composed of a squad of police officers, breath alcohol testing (BAT) devices, and a van named batmobile, which housed a BAT device and was used as a mobile station. The data were collected by the Division of Governmental Research of the University of New Mexico under a contract with the National Highway Traffic Safety Administration of the Department of Transportation to evaluate the batmobile program. Source: http://lib.stat.cmu.edu/DASL/Datafiles/batdat.html

The data comprise of quarterly figures of traffic accidents and the fuel consumption in the Albuquerque area as a proxy of the driven mileage. The first 29 quarters are the control period, and observations 30 to 52 were recorded during the experimental (batmobile) period. We would naturally assume a time series regression model for the number of accidents:

$$
A C C _ {t} = \beta_ {0} + \beta_ {1} \cdot F U E L _ {t} + \beta_ {2} \cdot 1 _ {Q _ {2} (t)} + \beta_ {3} \cdot 1 _ {Q _ {3} (t)} + \beta_ {4} \cdot 1 _ {Q _ {4} (t)} + E _ {t}
$$

The accidents depend on the mileage driven and there is a seasonal effect. In the above model the intercept $\beta _ { 0 }$ is assumed to be constant. In the light of the BAT program, we might well replace it by $\beta _ { 0 } = L _ { t }$ , i.e. some general level of accidents that is time-dependent. Let us first perform regression and check residuals.

```r
> ## Regression and Time Plot of Residuals
> fit <- lm(ACC ~ FUEL + season, data=regdat)
> plot(ts(resid.fit)), main="Time Plot of Residuals")
>
> ## Fitting a Loess Smoother to the Residuals
> times <- 1:52
> fit.loess <- loess(resid.fit) ~ times, span=0.65, degree=2)
> lines(times, fitted(fit.loess), col="red") 
```

The time series plot of the residuals shows very clear evidence that there is timely dependence. In contrast to what the regression model with constant coefficients suggests, the level of accidents seems to rise in the control period, then drops markedly after the BAT program was introduced. The conclusion is that our above regression model is not adequate and needs to be enhanced. However, just adding an indicator variable that codes for the times before and after the introduction of the BAT program will not solve the issue. It is evident that the level of the residuals is not constant before the program started, and it does not suddenly drop to a constant lower level thereafter.

![](images/5129e3eddf649247876f745b792d1ce9decb7e1af83655e6f716d686a8df6c20.jpg)  
Time Plot of Residuals

The alternative is to formulate a state space model and estimate it with the Kalman filter. We (conceptually) assume that all regression parameters are time dependent, and rewrite the model as:

$$
A C C _ {t} = L _ {t} + \beta_ {1 t} \cdot F U E L _ {t} + \beta_ {2 t} \cdot 1 _ {Q _ {2} (t)} + \beta_ {3 t} \cdot 1 _ {Q _ {3} (t)} + \beta_ {4 t} \cdot 1 _ {Q _ {4} (t)} + E _ {t}
$$

Our main interest lies in the estimation of the modified intercept term $L _ { \mathrm { \Lambda } _ { t } }$ , which we now call the level. We expect it to drop after the introduction of the BAT program, but let’s see if this materializes. The state vector $X _ { t }$ we are using contains the regression coefficients, and the state equation which describes their evolution over time is as follows:

$$
X _ {t} = G X _ {t - 1} + W _ {t}, \text {w h e r e} X _ {t} = \left( \begin{array}{c} L _ {t} \\ \beta_ {1 t} \\ \beta_ {2 t} \\ \beta_ {3 t} \\ \beta_ {4 t} \end{array} \right),   G = \left( \begin{array}{c c c c c} 1 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 & 1 \end{array} \right),   w _ {t} = \left( \begin{array}{c c c c c} 1 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 \end{array} \right).
$$

As we can see, we only allow for some small, random permutations in the level $L _ { \mathrm { \Lambda } _ { t } }$ , but not in the other regression coefficients. The observation equation then describes the regression problem, i.e.

$$
Y _ {t} = F _ {t} X _ {t} + V _ {t}, \text {w h e r e} Y _ {t} = A C C _ {t}, F _ {t} = \left(1, F u e l _ {t}, 1 _ {Q _ {2} (t)}, 1 _ {Q _ {3} (t)}, 1 _ {Q _ {4} (t)}\right), V _ {t} \sim N \left(0, \sigma_ {V} ^ {2}\right)
$$

The variance of the noise term $\sigma _ { V } ^ { 2 }$ is set to 600, which is the error variance in the canonical regression fit. Also the starting values for Kalman filtering, as well as the variances of these initial states are taken from there. Hence, the code for the state space formulation, as well as for Kalman filtering is as follows:

```r
> y.mat <- as.matrix(regdat$ACC)  
> x.mat <- model.matrix.fit)  
>ssf <- SS(y=y.mat, x=x.mat,  
+ Fmat=function(tt, x, phi) return(t(x[tt, , drop=FALSE])),  
+ Gmat=function(tt, x, phi) return(diag(5)),  
+ Wmat=function(tt, x, phi) return(diag(c(10, 0, 0, 0, 0))),  
+ Vmat=function(tt, x, phi) return matrix(600)),  
+ m0 = matrix(c(0, 5, 50, 50, 25), 1, 5),  
+ C0 = diag(c(900, 1, 100, 100, 100)))  
> fit kal <- kfilter(ssf) 
```

The filtered output is in object m in the output list. We can extract the estimates for the mean of the state vector at time t , which we display versus time.

![](images/bb6e2e16ad93ef096df54e7326c930c0288c5088436d43d4c69d2a040c7c6f66.jpg)

![](images/9bd8af3010b5018c6c95fa159db7b73ead65a4ff890d32e0c34753f6f21c530b.jpg)

Indeed, the level $L _ { \mathrm { \Lambda } _ { t } }$ shows a pronounced drop from $t = 3 5$ to $t = 4 5$ . Hence, the BAT program shows an effect, but there is some delay after the intervention and it takes some time until is has full effect. Finally, we track the estimates for the seasonal coefficients.

![](images/71791668151c675838abc5591d3e260b1c5dc65da927f87bb367d78206fc2699.jpg)

![](images/758901a697a634a97bc8fd7bd5077f714cd094220eb9e8bf25e73abdc8f77a6b.jpg)

![](images/336776b072807b231854aa1bf55963265d327083bff86a1795776da720168a7b.jpg)

The estimates for these coefficients slightly wiggle around over time. However, they do not seem to change systematically, as we had previously guessed.

# Analysis of Financial Time Series

Second Edition

![](images/21057663baa38214bdaa35fd91a0ac445d5aadcd024a4fcb233daff0b6027d24.jpg)

RueyS.Tsay

www.

WILEY SERIESINPROBABILITYAND STATISTICS

# Analysis of Financial Time Series Second Edition

RUEY S. TSAY

University of Chicago

Graduate School of Business

Analysis of Financial Time Series

WILEY SERIES IN PROBABILITY AND STATISTICS

Established by WALTER A. SHEWHART and SAMUEL S. WILKS

Editors: David J. Balding, Noel A. C. Cressie, Nicholas I. Fisher,

Iain M. Johnstone, J. B. Kadane, Geert Molenberghs, Louise M. Ryan,

David W. Scott, Adrian F. M. Smith, Jozef L. Teugels

Editors Emeriti: Vic Barnett, J. Stuart Hunter, David G. Kendall

A complete list of the titles in this series appears at the end of this volume.

# Analysis of Financial Time Series Second Edition

RUEY S. TSAY

University of Chicago

Graduate School of Business

Copyright $\circledcirc$ 2005 by John Wiley & Sons, Inc. All rights reserved.

Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada.

No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission.

Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Neither the publisher nor author shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages.

For general information on our other products and services or for technical support, please contact our Customer Care Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002.

Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic formats. For more information about Wiley products, visit our web site at www.wiley.com.

# Library of Congress Cataloging-in-Publication Data:

Tsay, Ruey S., 1951– Analysis of financial time series/Ruey S. Tsay.—2nd ed. p. cm. “Wiley-Interscience.” Includes bibliographical references and index. ISBN-13 978-0-471-69074-0 ISBN-10 0-471-69074-0 (cloth) 1. Time-series analysis. 2. Econometrics. 3. Risk management. I. Title. HA30.3T76 2005 332.0151955—dc22 2005047030

Printed in the United States of America.

To my parents and Teresa

# Contents

# Preface

xvii

# Preface to First Edition

xix

# 1. Financial Time Series and Their Characteristics

1

1.1 Asset Returns, 2   
1.2 Distributional Properties of Returns, 7

1.2.1 Review of Statistical Distributions and Their Moments, 7   
1.2.2 Distributions of Returns, 13   
1.2.3 Multivariate Returns, 16   
1.2.4 Likelihood Function of Returns, 17   
1.2.5 Empirical Properties of Returns, 17

1.3 Processes Considered, 20

Exercises, 22

References, 23

# 2. Linear Time Series Analysis and Its Applications

24

2.1 Stationarity, 25   
2.2 Correlation and Autocorrelation Function, 25   
2.3 White Noise and Linear Time Series, 31   
2.4 Simple Autoregressive Models, 32

2.4.1 Properties of AR Models, 33   
2.4.2 Identifying AR Models in Practice, 40   
2.4.3 Goodness of Fit, 46   
2.4.4 Forecasting, 47

2.5 Simple Moving-Average Models, 50

2.5.1 Properties of MA Models, 51   
2.5.2 Identifying MA Order, 52   
2.5.3 Estimation, 53   
2.5.4 Forecasting Using MA Models, 54

2.6 Simple ARMA Models, 56

2.6.1 Properties of ARMA(1,1) Models, 57   
2.6.2 General ARMA Models, 58   
2.6.3 Identifying ARMA Models, 59   
2.6.4 Forecasting Using an ARMA Model, 61   
2.6.5 Three Model Representations for an ARMA Model, 62

2.7 Unit-Root Nonstationarity, 64

2.7.1 Random Walk, 64   
2.7.2 Random Walk with Drift, 65   
2.7.3 Trend-Stationary Time Series, 67   
2.7.4 General Unit-Root Nonstationary Models, 67   
2.7.5 Unit-Root Test, 68

2.8 Seasonal Models, 72

2.8.1 Seasonal Differencing, 73   
2.8.2 Multiplicative Seasonal Models, 75

2.9 Regression Models with Time Series Errors, 80

2.10 Consistent Covariance Matrix Estimation, 86   
2.11 Long-Memory Models, 89

Appendix: Some SCA Commands, 91

Exercises, 93

References, 96

# 3. Conditional Heteroscedastic Models

3.1 Characteristics of Volatility, 98   
3.2 Structure of a Model, 99   
3.3 Model Building, 101

3.3.1 Testing for ARCH Effect, 101

3.4 The ARCH Model, 102

3.4.1 Properties of ARCH Models, 104   
3.4.2 Weaknesses of ARCH Models, 106   
3.4.3 Building an ARCH Model, 106   
3.4.4 Some Examples, 109

3.5 The GARCH Model, 113

3.5.1 An Illustrative Example, 116

3.5.2 Forecasting Evaluation, 121   
3.5.3 A Two-Pass Estimation Method, 121

3.6 The Integrated GARCH Model, 122   
3.7 The GARCH-M Model, 123   
3.8 The Exponential GARCH Model, 124

3.8.1 An Alternative Model Form, 125   
3.8.2 An Illustrative Example, 126   
3.8.3 Second Example, 126   
3.8.4 Forecasting Using an EGARCH Model, 128

3.9 The Threshold GARCH Model, 130   
3.10 The CHARMA Model, 131

3.10.1 Effects of Explanatory Variables, 133

3.11 Random Coefficient Autoregressive Models, 133   
3.12 The Stochastic Volatility Model, 134   
3.13 The Long-Memory Stochastic Volatility Model, 134   
3.14 Application, 136   
3.15 Alternative Approaches, 140

3.15.1 Use of High-Frequency Data, 140   
3.15.2 Use of Daily Open, High, Low, and Close Prices, 143

3.16 Kurtosis of GARCH Models, 145

Appendix: Some RATS Programs for Estimating Volatility Models, 147

Exercises, 148

References, 151

# 4. Nonlinear Models and Their Applications

154

4.1 Nonlinear Models, 156

4.1.1 Bilinear Model, 156   
4.1.2 Threshold Autoregressive (TAR) Model, 157   
4.1.3 Smooth Transition AR (STAR) Model, 163   
4.1.4 Markov Switching Model, 164   
4.1.5 Nonparametric Methods, 167   
4.1.6 Functional Coefficient AR Model, 175   
4.1.7 Nonlinear Additive AR Model, 176   
4.1.8 Nonlinear State-Space Model, 176   
4.1.9 Neural Networks, 177

4.2 Nonlinearity Tests, 183

4.2.1 Nonparametric Tests, 183   
4.2.2 Parametric Tests, 186   
4.2.3 Applications, 190

4.3 Modeling, 191   
4.4 Forecasting, 192

4.4.1 Parametric Bootstrap, 192   
4.4.2 Forecasting Evaluation, 192

4.5 Application, 194

Appendix A: Some RATS Programs for Nonlinear Volatility Models, 199

Appendix B: S-Plus Commands for Neural Network, 200

Exercises, 200

References, 202

# 5. High-Frequency Data Analysis and Market Microstructure

5.1 Nonsynchronous Trading, 207   
5.2 Bid–Ask Spread, 210   
5.3 Empirical Characteristics of Transactions Data, 212   
5.4 Models for Price Changes, 218

5.4.1 Ordered Probit Model, 218   
5.4.2 A Decomposition Model, 221

5.5 Duration Models, 225

5.5.1 The ACD Model, 227   
5.5.2 Simulation, 229   
5.5.3 Estimation, 232

5.6 Nonlinear Duration Models, 236   
5.7 Bivariate Models for Price Change and Duration, 237

Appendix A: Review of Some Probability Distributions, 242

Appendix B: Hazard Function, 245

Appendix C: Some RATS Programs for Duration Models, 246

Exercises, 248

References, 250

# 6. Continuous-Time Models and Their Applications

6.1 Options, 252   
6.2 Some Continuous-Time Stochastic Processes, 252

6.2.1 The Wiener Process, 253   
6.2.2 Generalized Wiener Processes, 255   
6.2.3 Ito Processes, 256

6.3 Ito’s Lemma, 256

6.3.1 Review of Differentiation, 256   
6.3.2 Stochastic Differentiation, 257

# 206

# 251

6.3.3 An Application, 258   
6.3.4 Estimation of $\mu$ and $\sigma$ , 259

6.4 Distributions of Stock Prices and Log Returns, 261   
6.5 Derivation of Black–Scholes Differential Equation, 262   
6.6 Black–Scholes Pricing Formulas, 264

6.6.1 Risk-Neutral World, 264   
6.6.2 Formulas, 264   
6.6.3 Lower Bounds of European Options, 267   
6.6.4 Discussion, 268

6.7 An Extension of Ito’s Lemma, 272

6.8 Stochastic Integral, 273   
6.9 Jump Diffusion Models, 274

6.9.1 Option Pricing Under Jump Diffusion, 279

6.10 Estimation of Continuous-Time Models, 282

Appendix A: Integration of Black–Scholes Formula, 282

Appendix B: Approximation to Standard Normal Probability, 284

Exercises, 284

References, 285

# 7. Extreme Values, Quantile Estimation, and Value at Risk

287

7.1 Value at Risk, 287   
7.2 RiskMetrics, 290

7.2.1 Discussion, 293   
7.2.2 Multiple Positions, 293

7.3 An Econometric Approach to VaR Calculation, 294

7.3.1 Multiple Periods, 296

7.4 Quantile Estimation, 298

7.4.1 Quantile and Order Statistics, 299   
7.4.2 Quantile Regression, 300

7.5 Extreme Value Theory, 301

7.5.1 Review of Extreme Value Theory, 301   
7.5.2 Empirical Estimation, 304   
7.5.3 Application to Stock Returns, 307

7.6 Extreme Value Approach to VaR, 311

7.6.1 Discussion, 314   
7.6.2 Multiperiod VaR, 316   
7.6.3 VaR for a Short Position, 316   
7.6.4 Return Level, 317

7.7 A New Approach Based on the Extreme Value Theory, 318

7.7.1 Statistical Theory, 318   
7.7.2 Mean Excess Function, 320   
7.7.3 A New Approach to Modeling Extreme Values, 322   
7.7.4 VaR Calculation Based on the New Approach, 324   
7.7.5 An Alternative Parameterization, 325   
7.7.6 Use of Explanatory Variables, 328   
7.7.7 Model Checking, 329   
7.7.8 An Illustration, 330

Exercises, 335

References, 337

# 8. Multivariate Time Series Analysis and Its Applications 339

8.1 Weak Stationarity and Cross-Correlation Matrices, 340

8.1.1 Cross-Correlation Matrices, 340   
8.1.2 Linear Dependence, 341   
8.1.3 Sample Cross-Correlation Matrices, 342   
8.1.4 Multivariate Portmanteau Tests, 346

8.2 Vector Autoregressive Models, 349

8.2.1 Reduced and Structural Forms, 349   
8.2.2 Stationarity Condition and Moments of a VAR(1) Model, 351   
8.2.3 Vector $\operatorname { A R } ( p )$ Models, 353   
8.2.4 Building a VAR(p) Model, 354   
8.2.5 Impulse Response Function, 362

8.3 Vector Moving-Average Models, 365

8.4 Vector ARMA Models, 371

8.4.1 Marginal Models of Components, 375

8.5 Unit-Root Nonstationarity and Cointegration, 376

8.5.1 An Error-Correction Form, 379

8.6 Cointegrated VAR Models, 380

8.6.1 Specification of the Deterministic Function, 382   
8.6.2 Maximum Likelihood Estimation, 383   
8.6.3 A Cointegration Test, 384   
8.6.4 Forecasting of Cointegrated VAR Models, 385   
8.6.5 An Example, 385

8.7 Threshold Cointegration and Arbitrage, 390

8.7.1 Multivariate Threshold Model, 391   
8.7.2 The Data, 392

8.7.3 Estimation, 393

Appendix A: Review of Vectors and Matrices, 395

Appendix B: Multivariate Normal Distributions, 399

Appendix C: Some SCA Commands, 400

Exercises, 401

References, 402

# 9. Principal Component Analysis and Factor Models

405

9.1 A Factor Model, 406   
9.2 Macroeconometric Factor Models, 407

9.2.1 A Single-Factor Model, 408   
9.2.2 Multifactor Models, 412

9.3 Fundamental Factor Models, 414

9.3.1 BARRA Factor Model, 414   
9.3.2 Fama–French Approach, 420

9.4 Principal Component Analysis, 421

9.4.1 Theory of PCA, 421   
9.4.2 Empirical PCA, 422

9.5 Statistical Factor Analysis, 426

9.5.1 Estimation, 428   
9.5.2 Factor Rotation, 429   
9.5.3 Applications, 430

9.6 Asymptotic Principal Component Analysis, 436

9.6.1 Selecting the Number of Factors, 437   
9.6.2 An Example, 437

Exercises, 440

References, 441

# 10. Multivariate Volatility Models and Their Applications

443

10.1 Exponentially Weighted Estimate, 444   
10.2 Some Multivariate GARCH Models, 447

10.2.1 Diagonal VEC Model, 447   
10.2.2 BEKK Model, 451

10.3 Reparameterization, 454

10.3.1 Use of Correlations, 454   
10.3.2 Cholesky Decomposition, 455

10.4 GARCH Models for Bivariate Returns, 459

10.4.1 Constant-Correlation Models, 459   
10.4.2 Time-Varying Correlation Models, 464

10.4.3 Some Recent Developments, 470

10.5 Higher Dimensional Volatility Models, 471   
10.6 Factor–Volatility Models, 477   
10.7 Application, 480   
10.8 Multivariate t Distribution, 482

Appendix: Some Remarks on Estimation, 483

Exercises, 488

References, 489

# 11. State-Space Models and Kalman Filter

11.1 Local Trend Model, 490

11.1.1 Statistical Inference, 493   
11.1.2 Kalman Filter, 495   
11.1.3 Properties of Forecast Error, 496   
11.1.4 State Smoothing, 498   
11.1.5 Missing Values, 501   
11.1.6 Effect of Initialization, 503   
11.1.7 Estimation, 504   
11.1.8 S-Plus Commands Used, 505

11.2 Linear State-Space Models, 508   
11.3 Model Transformation, 509

11.3.1 CAPM with Time-Varying Coefficients, 510   
11.3.2 ARMA Models, 512   
11.3.3 Linear Regression Model, 518   
11.3.4 Linear Regression Models with ARMA Errors, 519   
11.3.5 Scalar Unobserved Component Model, 521

11.4 Kalman Filter and Smoothing, 523

11.4.1 Kalman Filter, 523   
11.4.2 State Estimation Error and Forecast Error, 525   
11.4.3 State Smoothing, 526   
11.4.4 Disturbance Smoothing, 528

11.5 Missing Values, 531   
11.6 Forecasting, 532   
11.7 Application, 533

Exercises, 540

References, 541

# 12. Markov Chain Monte Carlo Methods with Applications 543

12.1 Markov Chain Simulation, 544   
12.2 Gibbs Sampling, 545   
12.3 Bayesian Inference, 547

12.3.1 Posterior Distributions, 547   
12.3.2 Conjugate Prior Distributions, 548

12.4 Alternative Algorithms, 551

12.4.1 Metropolis Algorithm, 551   
12.4.2 Metropolis–Hasting Algorithm, 552   
12.4.3 Griddy Gibbs, 552

12.5 Linear Regression with Time Series Errors, 553   
12.6 Missing Values and Outliers, 558

12.6.1 Missing Values, 559   
12.6.2 Outlier Detection, 561

12.7 Stochastic Volatility Models, 565

12.7.1 Estimation of Univariate Models, 566   
12.7.2 Multivariate Stochastic Volatility Models, 571

12.8 A New Approach to SV Estimation, 578   
12.9 Markov Switching Models, 588   
12.10 Forecasting, 594   
12.11 Other Applications, 597

Exercises, 597

References, 598

# Index 601

# Preface

The subject of financial time series analysis has attracted substantial attention in recent years, especially with the 2003 Nobel awards to Professors Robert Engle and Clive Granger. At the same time, the field of financial econometrics has undergone various new developments, especially in high-frequency finance, stochastic volatility, and software availability. There is a need to make the material more complete and accessible for advanced undergraduate and graduate students, practitioners, and researchers. The main goals in preparing this second edition have been to bring the book up to date both in new developments and empirical analysis, and to enlarge the core material of the book by including consistent covariance estimation under heteroscedasticity and serial correlation, alternative approaches to volatility modeling, financial factor models, state-space models, Kalman filtering, and estimation of stochastic diffusion models.

The book therefore has been extended to 10 chapters and substantially revised to include S-Plus commands and illustrations. Many empirical demonstrations and exercises are updated so that they include the most recent data.

The two new chapters are Chapter 9, Principal Component Analysis and Factor Models, and Chapter 11, State-Space Models and Kalman Filter. The factor models discussed include macroeconomic, fundamental, and statistical factor models. They are simple and powerful tools for analyzing high-dimensional financial data such as portfolio returns. Empirical examples are used to demonstrate the applications. The state-space model and Kalman filter are added to demonstrate their applicability in finance and ease in computation. They are used in Chapter 12 to estimate stochastic volatility models under the general Markov chain Monte Carlo (MCMC) framework. The estimation also uses the technique of forward filtering and backward sampling to gain computational efficiency.

A brief summary of the added material in the second edition is:

1. To update the data used throughout the book.   
2. To provide S-Plus commands and demonstrations.   
3. To consider unit-root tests and methods for consistent estimation of the covariance matrix in the presence of conditional heteroscedasticity and serial correlation in Chapter 2.

4. To describe alternative approaches to volatility modeling, including use of high-frequency transactions data and daily high and low prices of an asset in Chapter 3.   
5. To give more applications of nonlinear models and methods in Chapter 4.   
6. To introduce additional concepts and applications of value at risk in Chapter 7.   
7. To discuss cointegrated vector AR models in Chapter 8.   
8. To cover various multivariate volatility models in Chapter 10.   
9. To add an effective MCMC method for estimating stochastic volatility models in Chapter 12.

The revision benefits greatly from constructive comments of colleagues, friends, and many readers on the first edition. I am indebted to them all. In particular, I thank J. C. Artigas, Spencer Graves, Chung-Ming Kuan, Henry Lin, Daniel Pena, ˜ Jeff Russell, Michael Steele, George Tiao, Mark Wohar, Eric Zivot, and students of my MBA classes on financial time series for their comments and discussions, and Rosalyn Farkas, production editor, at John Wiley. I also thank my wife and children for their unconditional support and encouragement. Part of my research in financial econometrics is supported by the National Science Foundation, the High-Frequency Finance Project of the Institute of Economics, Academia Sinica, and the Graduate School of Business, University of Chicago.

Finally, the website for the book is:

gsbwww.uchicago.edu/fac/ruey.tsay/teaching/fts2.

Ruey S. Tsay

University of Chicago

Chicago, Illinois

# Preface for the First Edition

This book grew out of an MBA course in analysis of financial time series that I have been teaching at the University of Chicago since 1999. It also covers materials of Ph.D. courses in time series analysis that I taught over the years. It is an introductory book intended to provide a comprehensive and systematic account of financial econometric models and their application to modeling and prediction of financial time series data. The goals are to learn basic characteristics of financial data, understand the application of financial econometric models, and gain experience in analyzing financial time series.

The book will be useful as a text of time series analysis for MBA students with finance concentration or senior undergraduate and graduate students in business, economics, mathematics, and statistics who are interested in financial econometrics. The book is also a useful reference for researchers and practitioners in business, finance, and insurance facing value at risk calculation, volatility modeling, and analysis of serially correlated data.

The distinctive features of this book include the combination of recent developments in financial econometrics in the econometric and statistical literature. The developments discussed include the timely topics of value at risk (VaR), highfrequency data analysis, and Markov chain Monte Carlo (MCMC) methods. In particular, the book covers some recent results that are yet to appear in academic journals; see Chapter 6 on derivative pricing using jump diffusion with closedform formulas, Chapter 7 on value at risk calculation using extreme value theory based on a nonhomogeneous two-dimensional Poisson process, and Chapter 9 on multivariate volatility models with time-varying correlations. MCMC methods are introduced because they are powerful and widely applicable in financial econometrics. These methods will be used extensively in the future.

Another distinctive feature of this book is the emphasis on real examples and data analysis. Real financial data are used throughout the book to demonstrate applications of the models and methods discussed. The analysis is carried out by using several computer packages; the SCA (the Scientific Computing Associates)

for building linear time series models, the RATS (regression analysis for time series) for estimating volatility models, and the S-Plus for implementing neural networks and obtaining postscript plots. Some commands required to run these packages are given in appendixes of appropriate chapters. In particular, complicated RATS programs used to estimate multivariate volatility models are shown in Appendix A of Chapter 9. Some Fortran programs written by myself and others are used to price simple options, estimate extreme value models, calculate VaR, and carry out Bayesian analysis. Some data sets and programs are accessible from the World Wide Web at http://www.gsb.uchicago.edu/fac/ruey.tsay/teaching/fts.

The book begins with some basic characteristics of financial time series data in Chapter 1. The other chapters are divided into three parts. The first part, consisting of Chapters 2 to 7, focuses on analysis and application of univariate financial time series. The second part of the book covers Chapters 8 and 9 and is concerned with the return series of multiple assets. The final part of the book is Chapter 10, which introduces Bayesian inference in finance via MCMC methods.

A knowledge of basic statistical concepts is needed to fully understand the book. Throughout the chapters, I have provided a brief review of the necessary statistical concepts when they first appear. Even so, a prerequisite in statistics or business statistics that includes probability distributions and linear regression analysis is highly recommended. A knowledge of finance will be helpful in understanding the applications discussed throughout the book. However, readers with advanced background in econometrics and statistics can find interesting and challenging topics in many areas of the book.

An MBA course may consist of Chapters 2 and 3 as a core component, followed by some nonlinear methods (e.g., the neural network of Chapter 4 and the applications discussed in Chapters 5–7 and 10). Readers who are interested in Bayesian inference may start with the first five sections of Chapter 10.

Research in financial time series evolves rapidly and new results continue to appear regularly. Although I have attempted to provide broad coverage, there are many subjects that I do not cover or can only mention in passing.

I sincerely thank my teacher and dear friend, George C. Tiao, for his guidance, encouragement, and deep conviction regarding statistical applications over the years. I am grateful to Steve Quigley, Heather Haselkorn, Leslie Galen, Danielle LaCouriere, and Amy Hendrickson for making the publication of this book possible, to Richard Smith for sending me the estimation program of extreme value theory, to Bonnie K. Ray for helpful comments on several chapters, to Steve Kou for sending me his preprint on jump diffusion models, to Robert E. McCulloch for many years of collaboration on MCMC methods, to many students in my courses on analysis of financial time series for their feedback and inputs, and to Jeffrey Russell and Michael Zhang for insightful discussions concerning analysis of highfrequency financial data. To all these wonderful people I owe a deep sense of gratitude. I am also grateful for the support of the Graduate School of Business, University of Chicago and the National Science Foundation. Finally, my heartfelt thanks to my wife, Teresa, for her continuous support, encouragement, and

understanding; to Julie, Richard, and Vicki for bringing me joy and inspirations; and to my parents for their love and care.

Ruey S. Tsay

University of Chicago Chicago, Illinois

# Financial Time Series and Their Characteristics

Financial time series analysis is concerned with the theory and practice of asset valuation over time. It is a highly empirical discipline, but like other scientific fields theory forms the foundation for making inference. There is, however, a key feature that distinguishes financial time series analysis from other time series analysis. Both financial theory and its empirical time series contain an element of uncertainty. For example, there are various definitions of asset volatility, and for a stock return series, the volatility is not directly observable. As a result of the added uncertainty, statistical theory and methods play an important role in financial time series analysis.

The objective of this book is to provide some knowledge of financial time series, introduce some statistical tools useful for analyzing these series, and gain experience in financial applications of various econometric methods. We begin with the basic concepts of asset returns and a brief introduction to the processes to be discussed throughout the book. Chapter 2 reviews basic concepts of linear time series analysis such as stationarity and autocorrelation function, introduces simple linear models for handling serial dependence of the series, and discusses regression models with time series errors, seasonality, unit-root nonstationarity, and long-memory processes. The chapter also provides methods for consistent estimation of the covariance matrix in the presence of conditional heteroscedasticity and serial correlations. Chapter 3 focuses on modeling conditional heteroscedasticity (i.e., the conditional variance of an asset return). It discusses various econometric models developed recently to describe the evolution of volatility of an asset return over time. The chapter also discusses alternative methods to volatility modeling, including use of high-frequency transactions data and daily high and low prices of an asset. In Chapter 4, we address nonlinearity in financial time series, introduce test statistics that can discriminate nonlinear series from linear ones, and discuss several nonlinear models. The chapter also introduces nonparametric

estimation methods and neural networks and shows various applications of nonlinear models in finance. Chapter 5 is concerned with analysis of high-frequency financial data and its application to market microstructure. It shows that nonsynchronous trading and bid–ask bounce can introduce serial correlations in a stock return. It also studies the dynamic of time duration between trades and some econometric models for analyzing transactions data. In Chapter 6, we introduce continuous-time diffusion models and Ito’s lemma. Black–Scholes option pricing formulas are derived and a simple jump diffusion model is used to capture some characteristics commonly observed in options markets. Chapter 7 discusses extreme value theory, heavy-tailed distributions, and their application to financial risk management. In particular, it discusses various methods for calculating value at risk of a financial position. Chapter 8 focuses on multivariate time series analysis and simple multivariate models with emphasis on the lead–lag relationship between time series. The chapter also introduces cointegration, some cointegration tests, and threshold cointegration and applies the concept of cointegration to investigate arbitrage opportunity in financial markets. Chapter 9 discusses ways to simplify the dynamic structure of a multivariate series and methods to reduce the dimension. It introduces and demonstrates three types of factor model to analyze returns of multiple assets. In Chapter 10, we introduce multivariate volatility models, including those with time-varying correlations, and discuss methods that can be used to reparameterize a conditional covariance matrix to satisfy the positiveness constraint and reduce the complexity in volatility modeling. Chapter 11 introduces state-space models and the Kalman filter and discusses the relationship between state-space models and other econometric models discussed in the book. It also gives several examples of financial applications. Finally, in Chapter 12, we introduce some newly developed Markov chain Monte Carlo (MCMC) methods in the statistical literature and apply the methods to various financial research problems, such as the estimation of stochastic volatility and Markov switching models.

The book places great emphasis on application and empirical data analysis. Every chapter contains real examples and, on many occasions, empirical characteristics of financial time series are used to motivate the development of econometric models. Computer programs and commands used in data analysis are provided when needed. In some cases, the programs are given in an appendix. Many real data sets are also used in the exercises of each chapter.

# 1.1 ASSET RETURNS

Most financial studies involve returns, instead of prices, of assets. Campbell, Lo, and MacKinlay (1997) give two main reasons for using returns. First, for average investors, return of an asset is a complete and scale-free summary of the investment opportunity. Second, return series are easier to handle than price series because the former have more attractive statistical properties. There are, however, several definitions of an asset return.

Let $P _ { t }$ be the price of an asset at time index t. We discuss some definitions of returns that are used throughout the book. Assume for the moment that the asset pays no dividends.

# One-Period Simple Return

Holding the asset for one period from date $t - 1$ to date $t$ would result in a simple gross return

$$
1 + R _ {t} = \frac {P _ {t}}{P _ {t - 1}} \quad \text {o r} \quad P _ {t} = P _ {t - 1} \left(1 + R _ {t}\right). \tag {1.1}
$$

The corresponding one-period simple net return or simple return is

$$
R _ {t} = \frac {P _ {t}}{P _ {t - 1}} - 1 = \frac {P _ {t} - P _ {t - 1}}{P _ {t - 1}}. \tag {1.2}
$$

# Multiperiod Simple Return

Holding the asset for $k$ periods between dates $t - k$ and $t$ gives a $k$ -period simple gross return

$$
\begin{array}{l} 1 + R _ {t} [ k ] = \frac {P _ {t}}{P _ {t - k}} = \frac {P _ {t}}{P _ {t - 1}} \times \frac {P _ {t - 1}}{P _ {t - 2}} \times \dots \times \frac {P _ {t - k + 1}}{P _ {t - k}} \\ = \left(1 + R _ {t}\right) \left(1 + R _ {t - 1}\right) \dots \left(1 + R _ {t - k + 1}\right) \\ = \prod_ {j = 0} ^ {k - 1} (1 + R _ {t - j}). \\ \end{array}
$$

Thus, the $k$ -period simple gross return is just the product of the $k$ one-period simple gross returns involved. This is called a compound return. The $k$ -period simple net return is $R _ { t } [ k ] = ( P _ { t } - P _ { t - k } ) / P _ { t - k }$ .

In practice, the actual time interval is important in discussing and comparing returns (e.g., monthly return or annual return). If the time interval is not given, then it is implicitly assumed to be one year. If the asset was held for $k$ years, then the annualized (average) return is defined as

$$
\text {A n n u a l i z e d} \{R _ {t} [ k ] \} = \left[ \prod_ {j = 0} ^ {k - 1} \left(1 + R _ {t - j}\right) \right] ^ {1 / k} - 1.
$$

This is a geometric mean of the $k$ one-period simple gross returns involved and can be computed by

$$
\text {A n n u a l i z e d} \{R _ {t} [ k ] \} = \exp \left[ \frac {1}{k} \sum_ {j = 0} ^ {k - 1} \ln (1 + R _ {t - j}) \right] - 1,
$$

where $\exp ( x )$ denotes the exponential function and $\ln ( x )$ is the natural logarithm of the positive number $x$ . Because it is easier to compute arithmetic average than

geometric mean and the one-period returns tend to be small, one can use a first-order Taylor expansion to approximate the annualized return and obtain

$$
\text {A n n u a l i z e d} \{R _ {t} [ k ] \} \approx \frac {1}{k} \sum_ {j = 0} ^ {k - 1} R _ {t - j}. \tag {1.3}
$$

Accuracy of the approximation in Eq. (1.3) may not be sufficient in some applications, however.

# Continuous Compounding

Before introducing continuously compounded return, we discuss the effect of compounding. Assume that the interest rate of a bank deposit is $10 \%$ per annum and the initial deposit is $\$ 1.00$ . If the bank pays interest once a year, then the net value of the deposit becomes $\$ 1(1+0.1)=91.1$ one year later. If the bank pays interest semiannually, the 6-month interest rate is $1 0 \% / 2 = 5 \%$ and the net value is $\$ 1(1+0.1/2) ^ { 2 } =\ S 1 .1025$ after the first year. In general, if the bank pays interest m times a year, then the interest rate for each payment is $10 \% / m$ and the net value of the deposit becomes $\ S 1 ( 1 + 0 . 1 / m ) ^ { m }$ one year later. Table 1.1 gives the results for some commonly used time intervals on a deposit of $\$ 1.00$ with interest rate of $10 \%$ per annum. In particular, the net value approaches $\$ 1.1052$ , which is obtained by exp(0.1) and referred to as the result of continuous compounding. The effect of compounding is clearly seen.

In general, the net asset value $A$ of continuous compounding is

$$
A = C \exp (r \times n), \tag {1.4}
$$

where $r$ is the interest rate per annum, $C$ is the initial capital, and $n$ is the number of years. From Eq. (1.4), we have

$$
C = A \exp (- r \times n), \tag {1.5}
$$

which is referred to as the present value of an asset that is worth $A$ dollars $n$ years from now, assuming that the continuously compounded interest rate is $r$ per annum.

Table 1.1. Illustration of the Effects of Compoundinga   

<table><tr><td>Type</td><td>Number of Payments</td><td>Interest Rate per Period</td><td>Net Value</td></tr><tr><td>Annual</td><td>1</td><td>0.1</td><td>$1.10000</td></tr><tr><td>Semiannual</td><td>2</td><td>0.05</td><td>$1.10250</td></tr><tr><td>Quarterly</td><td>4</td><td>0.025</td><td>$1.10381</td></tr><tr><td>Monthly</td><td>12</td><td>0.0083</td><td>$1.10471</td></tr><tr><td>Weekly</td><td>52</td><td>0.1/52</td><td>$1.10506</td></tr><tr><td>Daily</td><td>365</td><td>0.1/365</td><td>$1.10516</td></tr><tr><td>Continuously</td><td>∞</td><td></td><td>$1.10517</td></tr></table>

a The time interval is 1 year and the interest rate is $10 \%$ per annum.

# Continuously Compounded Return

The natural logarithm of the simple gross return of an asset is called the continuously compounded return or log return:

$$
r _ {t} = \ln \left(1 + R _ {t}\right) = \ln \frac {P _ {t}}{P _ {t - 1}} = p _ {t} - p _ {t - 1}, \tag {1.6}
$$

where $p _ { t } = \ln ( P _ { t } )$ . Continuously compounded returns $r _ { t }$ enjoy some advantages over the simple net returns $R _ { t }$ . First, consider multiperiod returns. We have

$$
\begin{array}{l} r _ {t} [ k ] = \ln (1 + R _ {t} [ k ]) = \ln \left[ \left(1 + R _ {t}\right) \left(1 + R _ {t - 1}\right) \dots \left(1 + R _ {t - k + 1}\right) \right] \\ = \ln (1 + R _ {t}) + \ln (1 + R _ {t - 1}) + \dots + \ln (1 + R _ {t - k + 1}) \\ = r _ {t} + r _ {t - 1} + \dots + r _ {t - k + 1}. \\ \end{array}
$$

Thus, the continuously compounded multiperiod return is simply the sum of continuously compounded one-period returns involved. Second, statistical properties of log returns are more tractable.

# Portfolio Return

The simple net return of a portfolio consisting of $N$ assets is a weighted average of the simple net returns of the assets involved, where the weight on each asset is the percentage of the portfolio’s value invested in that asset. Let $p$ be a portfolio that places weight $w _ { i }$ on asset $i$ . Then the simple return of $p$ at time $t$ is $R _ { p , t } =$ $\textstyle \sum _ { i = 1 } ^ { N } w _ { i } R _ { i t }$ , where $R _ { i t }$ is the simple return of asset $i$ .

The continuously compounded returns of a portfolio, however, do not have the above convenient property. If the simple returns $R _ { i t }$ are all small in magnitude, then we have $\begin{array} { r } { r _ { p , t } \approx \dot { \sum _ { i = 1 } ^ { N } } w _ { i } r _ { i t } } \end{array}$ Ni 1 wirit , where rp,t is the continuously compounded return of $r _ { p , t }$ the portfolio at time t . This approximation is often used to study portfolio returns.

# Dividend Payment

If an asset pays dividends periodically, we must modify the definitions of asset returns. Let $D _ { t }$ be the dividend payment of an asset between dates $t - 1$ and $t$ and $P _ { t }$ be the price of the asset at the end of period t. Thus, dividend is not included in $P _ { t }$ . Then the simple net return and continuously compounded return at time $t$ become

$$
R _ {t} = \frac {P _ {t} + D _ {t}}{P _ {t - 1}} - 1, \qquad r _ {t} = \ln (P _ {t} + D _ {t}) - \ln (P _ {t - 1}).
$$

# Excess Return

Excess return of an asset at time $t$ is the difference between the asset’s return and the return on some reference asset. The reference asset is often taken to be riskless such as a short-term U.S. Treasury bill return. The simple excess return and log excess return of an asset are then defined as

$$
Z _ {t} = R _ {t} - R _ {0 t}, \quad z _ {t} = r _ {t} - r _ {0 t}, \tag {1.7}
$$

where $R _ { 0 t }$ and $r _ { 0 t }$ are the simple and log returns of the reference asset, respectively. In the finance literature, the excess return is thought of as the payoff on an arbitrage portfolio that goes long in an asset and short in the reference asset with no net initial investment.

Remark. A long financial position means owning the asset. A short position involves selling an asset one does not own. This is accomplished by borrowing the asset from an investor who has purchased it. At some subsequent date, the short seller is obligated to buy exactly the same number of shares borrowed to pay back the lender. Because the repayment requires equal shares rather than equal dollars, the short seller benefits from a decline in the price of the asset. If cash dividends are paid on the asset while a short position is maintained, these are paid to the buyer of the short sale. The short seller must also compensate the lender by matching the cash dividends from his own resources. In other words, the short seller is also obligated to pay cash dividends on the borrowed asset to the lender. 

# Summary of Relationship

The relationships between simple return $R _ { t }$ and continuously compounded (or log) return $r _ { t }$ are

$$
r _ {t} = \ln (1 + R _ {t}), \qquad R _ {t} = e ^ {r _ {t}} - 1.
$$

If the returns $R _ { t }$ and $r _ { t }$ are in percentages, then

$$
r _ {t} = 1 0 0 \ln \left(1 + \frac {R _ {t}}{1 0 0}\right), \quad R _ {t} = 1 0 0 (e ^ {r _ {t} / 1 0 0} - 1).
$$

Temporal aggregation of the returns produces

$$
1 + R _ {t} [ k ] = \left(1 + R _ {t}\right) \left(1 + R _ {t - 1}\right) \dots \left(1 + R _ {t - k + 1}\right),
$$

$$
r _ {t} [ k ] = r _ {t} + r _ {t - 1} + \dots + r _ {t - k + 1}.
$$

If the continuously compounded interest rate is $r$ per annum, then the relationship between present and future values of an asset is

$$
A = C \exp (r \times n), \quad C = A \exp (- r \times n).
$$

Example 1.1. If the monthly log return of an asset is $4 . 4 6 \%$ , then the corresponding monthly simple return is $1 0 0 [ \exp ( 4 . 4 6 / 1 0 0 ) - 1 ] = 4 . 5 6 \%$ . Also, if the monthly log returns of the asset within a quarter are $4 . 4 6 \%$ , $- 7 . 3 4 \%$ , and $1 0 . 7 7 \%$ , respectively, then the quarterly log return of the asset is $( 4 . 4 6 - 7 . 3 4 + 1 0 . 7 7 ) \% =$ $7 . 8 9 \%$ .

# 1.2 DISTRIBUTIONAL PROPERTIES OF RETURNS

To study asset returns, it is best to begin with their distributional properties. The objective here is to understand the behavior of the returns across assets and over time. Consider a collection of $N$ assets held for $T$ time periods, say, $t = 1 , \dots , T$ . For each asset $i$ , let $r _ { i t }$ be its log return at time t . The log returns under study are $\{ r _ { i t } ; i = 1 , \ldots , N ; t = 1 , \ldots , T \}$ . One can also consider the simple returns $\{ R _ { i t } ; i = 1 , \ldots , N ; t = 1 , \ldots , T \}$ and the log excess returns $\{ z _ { i t } ; i = 1 , \ldots , N$ ; $t = 1 , \dots , T \}$ .

# 1.2.1 Review of Statistical Distributions and Their Moments

We briefly review some basic properties of statistical distributions and the moment equations of a random variable. Let $R ^ { k }$ be the $k$ -dimensional Euclidean space. A point in $R ^ { k }$ is denoted by $\boldsymbol { x } \in { R } ^ { k }$ . Consider two random vectors $\pmb { X } = ( X _ { 1 } , \ldots , X _ { k } ) ^ { \prime }$ and $\pmb { Y } = ( Y _ { 1 } , \ldots , Y _ { q } ) ^ { \prime }$ . Let $P ( X \in A , Y \in B )$ be the probability that $X$ is in the subspace $A \subset R ^ { k }$ and $Y$ is in the subspace $B \subset R ^ { q }$ . For most of the cases considered in this book, both random vectors are assumed to be continuous.

# Joint Distribution

The function

$$
F _ {X, Y} (x, y; \theta) = P (X \leq x, Y \leq y; \theta),
$$

where $\boldsymbol { x } \in R ^ { p }$ , $\substack { \boldsymbol { y } } \in R ^ { q }$ , and the inequality “ $\because$ is a component-by-component operation, is a joint distribution function of $X$ and $Y$ with parameter $\pmb \theta$ . Behavior of $X$ and $Y$ is characterized by $F _ { X , Y } ( { \pmb x } , { \pmb y } ; { \pmb \theta } )$ . If the joint probability density function $f _ { x , y } ( x , y ; { \pmb \theta } )$ of $X$ and $Y$ exists, then

$$
F _ {X, Y} (\boldsymbol {x}, \boldsymbol {y}; \boldsymbol {\theta}) = \int_ {- \infty} ^ {\boldsymbol {x}} \int_ {- \infty} ^ {\boldsymbol {y}} f _ {x, y} (\boldsymbol {w}, z; \boldsymbol {\theta}) d z d \boldsymbol {w}.
$$

In this case, $X$ and $Y$ are continuous random vectors.

# Marginal Distribution

The marginal distribution of $X$ is given by

$$
F _ {X} (\boldsymbol {x}; \boldsymbol {\theta}) = F _ {X, Y} (\boldsymbol {x}, \infty , \dots , \infty ; \boldsymbol {\theta}).
$$

Thus, the marginal distribution of $X$ is obtained by integrating out Y . A similar definition applies to the marginal distribution of $Y$ .

If $k = 1$ , $X$ is a scalar random variable and the distribution function becomes

$$
F _ {X} (x) = P (X \leq x; \boldsymbol {\theta}),
$$

which is known as the cumulative distribution function (CDF) of $X$ . The CDF of a random variable is nondecreasing (i.e., $F _ { X } ( x _ { 1 } ) \leq F _ { X } ( x _ { 2 } )$ if $x _ { 1 } \leq x _ { 2 }$ ) and satisfies

$F _ { X } ( - \infty ) = 0$ and $F _ { X } ( \infty ) = 1$ . For a given probability $p$ , the smallest real number $x _ { p }$ such that $p \leq F _ { X } ( x _ { p } )$ is called the $p$ th quantile of the random variable $X$ . More specifically,

$$
x _ {p} = \inf  _ {x} \{x | p \leq F _ {X} (x) \}.
$$

We use the CDF to compute the $p$ value of a test statistic in the book.

# Conditional Distribution

The conditional distribution of $X$ given $Y \le y$ is given by

$$
F _ {X \mid Y \leq y} (\boldsymbol {x}; \boldsymbol {\theta}) = \frac {P (\boldsymbol {X} \leq \boldsymbol {x} , \boldsymbol {Y} \leq \boldsymbol {y} ; \boldsymbol {\theta})}{P (\boldsymbol {Y} \leq \boldsymbol {y} ; \boldsymbol {\theta})}.
$$

If the probability density functions involved exist, then the conditional density of $X$ given $Y = y$ is

$$
f _ {x \mid y} (\boldsymbol {x}; \boldsymbol {\theta}) = \frac {f _ {x , y} (\boldsymbol {x} , \boldsymbol {y} ; \boldsymbol {\theta})}{f _ {y} (\boldsymbol {y} ; \boldsymbol {\theta})}, \tag {1.8}
$$

where the marginal density function $f _ { y } ( { \pmb y } ; { \pmb \theta } )$ is obtained by

$$
f _ {y} (\boldsymbol {y}; \boldsymbol {\theta}) = \int_ {- \infty} ^ {\infty} f _ {x, y} (\boldsymbol {x}, \boldsymbol {y}; \boldsymbol {\theta}) d \boldsymbol {x}.
$$

From Eq. (1.8), the relation among joint, marginal, and conditional distributions is

$$
f _ {x, y} (\boldsymbol {x}, \boldsymbol {y}; \boldsymbol {\theta}) = f _ {x | y} (\boldsymbol {x}; \boldsymbol {\theta}) \times f _ {y} (\boldsymbol {y}; \boldsymbol {\theta}). \tag {1.9}
$$

This identity is used extensively in time series analysis (e.g., in maximum likelihood estimation). Finally, $X$ and $Y$ are independent random vectors if and only if $f _ { x | y } ( { \pmb x } ; { \pmb \theta } ) = f _ { x } ( { \pmb x } ; { \pmb \theta } )$ . In this case, $f _ { x , y } ( { \pmb x } , { \pmb y } ; { \pmb \theta } ) = f _ { x } ( { \pmb x } ; { \pmb \theta } ) f _ { y } ( { \pmb y } ; { \pmb \theta } )$ .

# Moments of a Random Variable

The th moment of a continuous random variable $X$ is defined as

$$
m _ {\ell} ^ {\prime} = E (X ^ {\ell}) = \int_ {- \infty} ^ {\infty} x ^ {\ell} f (x) d x,
$$

where $E$ stands for expectation and $f ( x )$ is the probability density function of $X$ . The first moment is called the mean or expectation of $X$ . It measures the central location of the distribution. We denote the mean of $X$ by $\mu _ { x }$ . The th central moment of $X$ is defined as

$$
m _ {\ell} = E [ (X - \mu_ {x}) ^ {\ell} ] = \int_ {- \infty} ^ {\infty} (x - \mu_ {x}) ^ {\ell} f (x) d x
$$

provided that the integral exists. The second central moment, denoted by $\sigma _ { x } ^ { 2 }$ , measures the variability of $X$ and is called the variance of $X$ . The positive square root, $\sigma _ { x }$ , of variance is the standard deviation of $X$ . The first two moments of a random variable uniquely determine a normal distribution. For other distributions, higher order moments are also of interest.

The third central moment measures the symmetry of $X$ with respect to its mean, whereas the fourth central moment measures the tail behavior of $X$ . In statistics, skewness and kurtosis, which are normalized third and fourth central moments of $X$ , are often used to summarize the extent of asymmetry and tail thickness. Specifically, the skewness and kurtosis of $X$ are defined as

$$
S (x) = E \left[ \frac {(X - \mu_ {x}) ^ {3}}{\sigma_ {x} ^ {3}} \right], \quad K (x) = E \left[ \frac {(X - \mu_ {x}) ^ {4}}{\sigma_ {x} ^ {4}} \right].
$$

The quantity $K ( x ) - 3$ is called the excess kurtosis because $K ( x ) = 3$ for a normal distribution. Thus, the excess kurtosis of a normal random variable is zero. A distribution with positive excess kurtosis is said to have heavy tails, implying that the distribution puts more mass on the tails of its support than a normal distribution does. In practice, this means that a random sample from such a distribution tends to contain more extreme values. Such a distribution is said to be leptokurtic. On the other hand, a distribution with negative excess kurtosis has short tails (e.g., a uniform distribution over a finite interval). Such a distribution is said to be platykurtic.

In application, skewness and kurtosis can be estimated by their sample counterparts. Let $\{ x _ { 1 } , \ldots , x _ { T } \}$ be a random sample of $X$ with $T$ observations. The sample mean is

$$
\hat {\mu} _ {x} = \frac {1}{T} \sum_ {t = 1} ^ {T} x _ {t}, \tag {1.10}
$$

the sample variance is

$$
\hat {\sigma} _ {x} ^ {2} = \frac {1}{T - 1} \sum_ {t = 1} ^ {T} \left(x _ {t} - \hat {\mu} _ {x}\right) ^ {2}, \tag {1.11}
$$

the sample skewness is

$$
\hat {S} (x) = \frac {1}{(T - 1) \hat {\sigma} _ {x} ^ {3}} \sum_ {t = 1} ^ {T} \left(x _ {t} - \hat {\mu} _ {x}\right) ^ {3}, \tag {1.12}
$$

and the sample kurtosis is

$$
\hat {K} (x) = \frac {1}{(T - 1) \hat {\sigma} _ {x} ^ {4}} \sum_ {t = 1} ^ {T} \left(x _ {t} - \hat {\mu} _ {x}\right) ^ {4}. \tag {1.13}
$$

Under the normality assumption, $\hat { \boldsymbol { S } } ( \boldsymbol { x } )$ and $\hat { K } ( x ) - 3$ are distributed asymptotically as normal with zero mean and variances $6 / T$ and $2 4 / T$ , respectively; see Snedecor

and Cochran (1980, p. 78). These asymptotic properties can be used to test the normality of asset returns. Given an asset return series $\{ r _ { 1 } , \hdots , r _ { T } \}$ , to test the skewness of the returns, we consider the null hypothesis $H _ { o } : S ( r ) = 0$ versus the alternative hypothesis $H _ { a } : S ( r ) \neq 0$ . The $t$ -ratio statistic of the sample skewness in Eq. (1.12) is

$$
t = \frac {\hat {S} (r)}{\sqrt {6 / T}}.
$$

The decision rule is as follows. Reject the null hypothesis at the $\alpha$ significance level, if $| t | > Z _ { \alpha / 2 }$ , where $Z _ { \alpha / 2 }$ is the upper $1 0 0 ( \alpha / 2 ) \mathrm { t h }$ quantile of the standard normal distribution. Alternatively, one can compute the $p$ -value of the test statistic $t$ and reject $H _ { o }$ if and only if the $p$ -value is less than $\alpha$ .

Similarly, one can test the excess kurtosis of the return series using the hypotheses $H _ { o } : K ( r ) - 3 = 0$ versus $H _ { a } : K ( r ) - 3 \neq 0$ . The test statistic is

$$
t = \frac {\hat {K} (r) - 3}{\sqrt {2 4 / T}},
$$

which is asymptotically a standard normal random variable. The decision rule is to reject $H _ { o }$ if and only if the $p$ -value of the test statistic is less than the significance level $\alpha$ . Jarque and Bera (1987) combine the two prior tests and use the test statistic

$$
J B = \frac {\hat {S} ^ {2} (r)}{6 / T} + \frac {(\hat {K} (r) - 3) ^ {2}}{2 4 / T},
$$

which is asymptotically distributed as a chi-squared random variable with 2 degrees of freedom, to test for the normality of $r _ { t }$ . One rejects $H _ { o }$ of normality if the $p$ -value of the $J B$ statistic is less than the significance level.

Example 1.2. Consider the daily simple returns of the IBM stock used in Table 1.2. The sample skewness and kurtosis of the returns are parts of the descriptive (or summary) statistics that can be obtained easily using various statistical software packages. Both SCA and S-Plus are used in the demonstration, where ‘d-ibmvwewsp6203.txt’ is the data file name. Note that in SCA the kurtosis denotes excess kurtosis. From the output, the excess kurtosis is high, indicating that the daily simple returns of IBM stock have heavy tails. To test the symmetry of return distribution, we use the test statistic

$$
t = \frac {0 . 0 7 7 5}{0 . 0 2 4} = 3. 2 3,
$$

which gives a $p$ -value of about 0.001, indicating that the daily simple returns of IBM stock are significantly skewed to the right at the $5 \%$ level.

Table 1.2. Descriptive Statistics for Daily and Monthly Simple and Log Returns of Selected Indexes and Stocksa   

<table><tr><td rowspan="2">Security</td><td rowspan="2">Start</td><td rowspan="2">Size</td><td colspan="3">Standard</td><td colspan="3">Excess</td></tr><tr><td>Mean</td><td>Deviation</td><td>Skewness</td><td>Kurtosis</td><td>Minimum</td><td>Maximum</td></tr><tr><td colspan="9">Daily Simple Returns (%)</td></tr><tr><td>SP</td><td>62/7/3</td><td>10446</td><td>0.033</td><td>0.945</td><td>-0.95</td><td>25.76</td><td>-20.47</td><td>9.10</td></tr><tr><td>VW</td><td>62/7/3</td><td>10446</td><td>0.045</td><td>0.794</td><td>-0.76</td><td>18.32</td><td>-17.14</td><td>8.66</td></tr><tr><td>EW</td><td>62/7/3</td><td>10446</td><td>0.085</td><td>0.726</td><td>-0.89</td><td>13.42</td><td>-10.39</td><td>6.95</td></tr><tr><td>IBM</td><td>62/7/3</td><td>10446</td><td>0.052</td><td>1.648</td><td>-0.08</td><td>10.21</td><td>-22.96</td><td>13.16</td></tr><tr><td>Intel</td><td>72/12/15</td><td>7828</td><td>0.131</td><td>2.998</td><td>-0.16</td><td>5.85</td><td>-29.57</td><td>26.38</td></tr><tr><td>3M</td><td>62/7/3</td><td>10446</td><td>0.054</td><td>1.465</td><td>-0.28</td><td>12.87</td><td>-25.98</td><td>11.54</td></tr><tr><td>Microsoft</td><td>86/3/14</td><td>4493</td><td>0.157</td><td>2.505</td><td>-0.25</td><td>8.75</td><td>-30.12</td><td>19.57</td></tr><tr><td>Citi-Group</td><td>86/10/30</td><td>4333</td><td>0.110</td><td>2.289</td><td>-0.10</td><td>6.79</td><td>-21.74</td><td>20.76</td></tr><tr><td colspan="9">Daily Log Returns (%)</td></tr><tr><td>SP</td><td>62/7/3</td><td>10446</td><td>0.029</td><td>0.951</td><td>-1.41</td><td>36.91</td><td>-22.90</td><td>8.71</td></tr><tr><td>VW</td><td>62/7/3</td><td>10446</td><td>0.041</td><td>0.895</td><td>-1.06</td><td>23.91</td><td>-18.80</td><td>8.31</td></tr><tr><td>EW</td><td>62/7/3</td><td>10446</td><td>0.082</td><td>0.728</td><td>-1.29</td><td>14.70</td><td>-10.97</td><td>6.72</td></tr><tr><td>IBM</td><td>62/7/3</td><td>10446</td><td>0.039</td><td>1.649</td><td>-0.25</td><td>12.60</td><td>-26.09</td><td>12.37</td></tr><tr><td>Intel</td><td>72/12/15</td><td>7828</td><td>0.086</td><td>3.013</td><td>-0.54</td><td>7.54</td><td>-35.06</td><td>23.41</td></tr><tr><td>3M</td><td>62/7/3</td><td>10446</td><td>0.044</td><td>1.469</td><td>-0.69</td><td>20.06</td><td>-30.08</td><td>10.92</td></tr><tr><td>Microsoft</td><td>86/3/14</td><td>4493</td><td>0.126</td><td>2.518</td><td>-0.73</td><td>13.23</td><td>-35.83</td><td>17.87</td></tr><tr><td>Citi-Group</td><td>86/10/30</td><td>4333</td><td>0.084</td><td>2.289</td><td>-0.21</td><td>7.47</td><td>-24.51</td><td>18.86</td></tr><tr><td colspan="9">Monthly Simple Returns (%)</td></tr><tr><td>SP</td><td>62/1</td><td>936</td><td>0.64</td><td>5.63</td><td>-0.35</td><td>9.26</td><td>-29.94</td><td>42.22</td></tr><tr><td>VW</td><td>26/1</td><td>936</td><td>0.95</td><td>5.49</td><td>-0.18</td><td>7.52</td><td>-28.98</td><td>38.27</td></tr><tr><td>EW</td><td>26/1</td><td>936</td><td>1.31</td><td>7.49</td><td>-1.54</td><td>14.46</td><td>-31.18</td><td>65.51</td></tr><tr><td>IBM</td><td>26/1</td><td>936</td><td>1.42</td><td>7.11</td><td>-0.27</td><td>2.15</td><td>-26.19</td><td>35.38</td></tr><tr><td>Intel</td><td>73/1</td><td>372</td><td>2.71</td><td>13.42</td><td>-0.26</td><td>2.43</td><td>-44.87</td><td>62.50</td></tr><tr><td>3M</td><td>46/2</td><td>695</td><td>1.37</td><td>6.53</td><td>-0.24</td><td>0.96</td><td>-27.83</td><td>25.80</td></tr><tr><td>Microsoft</td><td>86/4</td><td>213</td><td>3.37</td><td>11.95</td><td>-0.53</td><td>1.40</td><td>-34.35</td><td>51.55</td></tr><tr><td>Citi-Group</td><td>86/11</td><td>206</td><td>2.20</td><td>9.52</td><td>-0.18</td><td>0.87</td><td>-34.48</td><td>26.08</td></tr><tr><td colspan="9">Monthly Log Returns (%)</td></tr><tr><td>SP</td><td>26/1</td><td>936</td><td>0.48</td><td>5.62</td><td>-0.50</td><td>7.77</td><td>-35.58</td><td>35.22</td></tr><tr><td>VW</td><td>26/1</td><td>936</td><td>0.79</td><td>5.48</td><td>-0.54</td><td>6.72</td><td>-34.22</td><td>32.41</td></tr><tr><td>EW</td><td>26/1</td><td>936</td><td>1.04</td><td>7.21</td><td>-0.29</td><td>8.40</td><td>-37.37</td><td>50.38</td></tr><tr><td>IBM</td><td>26/1</td><td>936</td><td>1.16</td><td>7.02</td><td>-0.15</td><td>2.04</td><td>-30.37</td><td>30.29</td></tr><tr><td>Intel</td><td>73/1</td><td>372</td><td>1.80</td><td>13.37</td><td>-0.60</td><td>2.90</td><td>-59.54</td><td>48.55</td></tr><tr><td>3M</td><td>46/2</td><td>695</td><td>1.16</td><td>6.43</td><td>-0.06</td><td>1.25</td><td>-32.61</td><td>22.95</td></tr><tr><td>Microsoft</td><td>86/4</td><td>213</td><td>2.66</td><td>11.48</td><td>-0.01</td><td>1.19</td><td>-42.09</td><td>41.58</td></tr><tr><td>Citi-Group</td><td>86/11</td><td>206</td><td>1.73</td><td>9.55</td><td>-0.65</td><td>2.08</td><td>-42.28</td><td>23.18</td></tr></table>

aReturns are in percentages and the sample period ends on December 31, 2003. The statistics are defined in eqs. (1.10)–(1.13). VW, EW, and SP denote value-weighted, equal-weighted, and S&P composite index.

# SCA Demonstration

$\%$ denotes explanation.

input date, ibm, vw, ew, sp. file ’d-ibmvwewsp6203.txt’

% Load data into SCA and name the columns date,

% ibm, vw, ew, and sp.

ibm $\iota =$ ibm*100 % Compute percentage returns

desc ibm % Obtain descriptive statistics of ibm

VARIABLE NAME IS IBM

NUMBER OF OBSERVATIONS 10446

NUMBER OF MISSING VALUES 0

<table><tr><td></td><td>STATISTIC</td><td>STD. ERROR</td><td>STATISTIC/S.E.</td></tr><tr><td>MEAN</td><td>0.0523</td><td>0.0161</td><td>3.2457</td></tr><tr><td>VARIANCE</td><td>2.7163</td><td></td><td></td></tr><tr><td>STD DEVIATION</td><td>1.6481</td><td></td><td></td></tr><tr><td>C.V.</td><td>31.4900</td><td></td><td></td></tr><tr><td>SKEWNESS</td><td>0.0775</td><td>0.0240</td><td></td></tr><tr><td>KURTOSIS</td><td>10.2144</td><td>0.0479</td><td></td></tr><tr><td></td><td>QUARTILE</td><td></td><td></td></tr><tr><td>MINIMUM</td><td>-22.9630</td><td></td><td></td></tr><tr><td>1ST QUARTILE</td><td>-0.8380</td><td></td><td></td></tr><tr><td>MEDIAN</td><td>0.0000</td><td></td><td></td></tr><tr><td>3RD QUARTILE</td><td>0.8805</td><td></td><td></td></tr><tr><td>MAXIMUM</td><td>13.1640</td><td></td><td></td></tr><tr><td></td><td>RANGE</td><td></td><td></td></tr><tr><td>MAX - MIN</td><td>36.1270</td><td></td><td></td></tr><tr><td>Q3 - Q1</td><td>1.7185</td><td></td><td></td></tr></table>

# S-Plus Demonstration

$>$ is the prompt character and $\%$ marks explanation.

$>$ module(finmetrics) $\%$ Load the Finmetrics module.   
$>$ $\mathrm { _ { x = } }$ matrix(scan(file=’d-ibmvwewsp6203.txt’),5) % Load data   
$>$ ibm $_ { 1 = \times }$ [2,]*100 % compute percentage returns   
$>$ summaryStats(ibm) % obtain summary statistics

Sample Quantiles:

min 1Q median 3Q max -22.96 -0.838 0 0.8807 13.16

Sample Moments:

mean std skewness kurtosis

0.05234 1.648 0.0775 13.22

Number of Observations: 10446

# 1.2.2 Distributions of Returns

The most general model for the log returns $\{ r _ { i t } ; i = 1 , \ldots , N ; t = 1 , \ldots , T \}$ is its joint distribution function:

$$
F _ {r} \left(r _ {1 1}, \dots , r _ {N 1}; r _ {1 2}, \dots , r _ {N 2}; \dots ; r _ {1 T}, \dots , r _ {N T}; Y; \boldsymbol {\theta}\right), \tag {1.14}
$$

where $Y$ is a state vector consisting of variables that summarize the environment in which asset returns are determined and $\pmb \theta$ is a vector of parameters that uniquely determine the distribution function $F _ { r } ( . )$ . The probability distribution $F _ { r } ( . )$ governs the stochastic behavior of the returns $r _ { i t }$ and $Y$ . In many financial studies, the state vector $Y$ is treated as given and the main concern is the conditional distribution of $\{ r _ { i t } \}$ given Y . Empirical analysis of asset returns is then to estimate the unknown parameter $\pmb \theta$ and to draw statistical inference about the behavior of $\{ r _ { i t } \}$ given some past log returns.

The model in Eq. (1.14) is too general to be of practical value. However, it provides a general framework with respect to which an econometric model for asset returns $r _ { i t }$ can be put in a proper perspective.

Some financial theories such as the capital asset pricing model (CAPM) of Sharpe (1964) focus on the joint distribution of $N$ returns at a single time index t (i.e., the distribution of $\{ r _ { 1 t } , \hdots , r _ { N t } \} )$ . Other theories emphasize the dynamic structure of individual asset returns (i.e., the distribution of $\{ r _ { i 1 } , \ldots , r _ { i T } \}$ for a given asset i). In this book, we focus on both. In the univariate analysis of Chapters 2–7, our main concern is the joint distribution of $\{ r _ { i t } \} _ { t = 1 } ^ { T }$ for asset $i$ . To this end, it is useful to partition the joint distribution as

$$
\begin{array}{l} F \left(r _ {i 1}, \dots , r _ {i T}; \boldsymbol {\theta}\right) = F \left(r _ {i 1}\right) F \left(r _ {i 2} \mid r _ {1 t}\right) \dots F \left(r _ {i T} \mid r _ {i, T - 1}, \dots , r _ {i 1}\right) \\ = F \left(r _ {i 1}\right) \prod_ {t = 2} ^ {T} F \left(r _ {i t} \mid r _ {i, t - 1}, \dots , r _ {i 1}\right), \tag {1.15} \\ \end{array}
$$

where, for simplicity, the parameter $\pmb \theta$ is omitted. This partition highlights the temporal dependencies of the log return $r _ { i t }$ . The main issue then is the specification of the conditional distribution $F ( r _ { i t } | r _ { i , t - 1 } , . )$ , in particular, how the conditional distribution evolves over time. In finance, different distributional specifications lead to different theories. For instance, one version of the random-walk hypothesis is that the conditional distribution $F ( r _ { i t } | r _ { i , t - 1 } , \ldots , r _ { i 1 } )$ is equal to the marginal distribution $F ( r _ { i t } )$ . In this case, returns are temporally independent and, hence, not predictable.

It is customary to treat asset returns as continuous random variables, especially for index returns or stock returns calculated at a low frequency, and use their probability density functions. In this case, using the identity in Eq. (1.9), we can write the partition in Eq. (1.15) as

$$
f \left(r _ {i 1}, \dots , r _ {i T}; \boldsymbol {\theta}\right) = f \left(r _ {i 1}; \boldsymbol {\theta}\right) \prod_ {t = 2} ^ {T} f \left(r _ {i t} \mid r _ {i, t - 1}, \dots , r _ {i 1}, \boldsymbol {\theta}\right). \tag {1.16}
$$

For high-frequency asset returns, discreteness becomes an issue. For example, stock prices change in multiples of a tick size on the New York Stock Exchange (NYSE). The tick size was one-eighth of a dollar before July 1997 and was one-sixteenth of a dollar from July 1997 to January 2001. Therefore, the tick-by-tick return of an individual stock listed on the NYSE is not continuous. We discuss high-frequency stock price changes and time durations between price changes later in Chapter 5.

Remark. On August 28, 2000, the NYSE began a pilot program with seven stocks priced in decimals and the American Stock Exchange (AMEX) began a pilot program with six stocks and two options classes. The NYSE added 57 stocks and 94 stocks to the program on September 25 and December 4, 2000, respectively. All NYSE and AMEX stocks started trading in decimals on January 29, 2001. 

Equation (1.16) suggests that conditional distributions are more relevant than marginal distributions in studying asset returns. However, the marginal distributions may still be of some interest. In particular, it is easier to estimate marginal distributions than conditional distributions using past returns. In addition, in some cases, asset returns have weak empirical serial correlations, and, hence, their marginal distributions are close to their conditional distributions.

Several statistical distributions have been proposed in the literature for the marginal distributions of asset returns, including normal distribution, lognormal distribution, stable distribution, and scale-mixture of normal distributions. We briefly discuss these distributions.

# Normal Distribution

A traditional assumption made in financial study is that the simple returns $\{ R _ { i t } | t =$ $1 , \ldots , T \}$ are independently and identically distributed as normal with fixed mean and variance. This assumption makes statistical properties of asset returns tractable. But it encounters several difficulties. First, the lower bound of a simple return is $^ { - 1 }$ . Yet the normal distribution may assume any value in the real line and, hence, has no lower bound. Second, if $R _ { i t }$ is normally distributed, then the multiperiod simple return $R _ { i t } [ k ]$ is not normally distributed because it is a product of one-period returns. Third, the normality assumption is not supported by many empirical asset returns, which tend to have a positive excess kurtosis.

# Lognormal Distribution

Another commonly used assumption is that the log returns $r _ { t }$ of an asset are independent and identically distributed (iid) as normal with mean $\mu$ and variance $\sigma ^ { 2 }$ . The simple returns are then iid lognormal random variables with mean and variance given by

$$
E \left(R _ {t}\right) = \exp \left(\mu + \frac {\sigma^ {2}}{2}\right) - 1, \quad \operatorname {V a r} \left(R _ {t}\right) = \exp \left(2 \mu + \sigma^ {2}\right) [ \exp (\sigma^ {2}) - 1 ]. \tag {1.17}
$$

These two equations are useful in studying asset returns (e.g., in forecasting using models built for log returns). Alternatively, let $m _ { 1 }$ and $m _ { 2 }$ be the mean and variance of the simple return $R _ { t }$ , which is lognormally distributed. Then the mean and variance of the corresponding log return $r _ { t }$ are

$$
E (r _ {t}) = \ln \left(\frac {m _ {1} + 1}{\sqrt {1 + m _ {2} / (1 + m _ {1}) ^ {2}}}\right), \quad \operatorname {V a r} (r _ {t}) = \ln \left(1 + \frac {m _ {2}}{(1 + m _ {1}) ^ {2}}\right).
$$

Because the sum of a finite number of iid normal random variables is normal, $r _ { t } [ k ]$ is also normally distributed under the normal assumption for $\{ r _ { t } \}$ . In addition, there is no lower bound for $r _ { t }$ , and the lower bound for $R _ { t }$ is satisfied using $1 + R _ { t } = \exp ( r _ { t } )$ . However, the lognormal assumption is not consistent with all the properties of historical stock returns. In particular, many stock returns exhibit a positive excess kurtosis.

# Stable Distribution

The stable distributions are a natural generalization of normal in that they are stable under addition, which meets the need of continuously compounded returns $r _ { t }$ . Furthermore, stable distributions are capable of capturing excess kurtosis shown by historical stock returns. However, non-normal stable distributions do not have a finite variance, which is in conflict with most finance theories. In addition, statistical modeling using non-normal stable distributions is difficult. An example of nonnormal stable distributions is the Cauchy distribution, which is symmetric with respect to its median but has infinite variance.

# Scale Mixture of Normal Distributions

Recent studies of stock returns tend to use scale mixture or finite mixture of normal distributions. Under the assumption of scale mixture of normal distributions, the log return $r _ { t }$ is normally distributed with mean $\mu$ and variance $\sigma ^ { 2 }$ [i.e., $r _ { t } \sim N ( \mu , \sigma ^ { 2 } ) ]$ . However, $\sigma ^ { 2 }$ is a random variable that follows a positive distribution (e.g., $\sigma ^ { - 2 }$ follows a gamma distribution). An example of finite mixture of normal distributions is

$$
r _ {t} \sim (1 - X) N (\mu , \sigma_ {1} ^ {2}) + X N (\mu , \sigma_ {2} ^ {2}),
$$

where $X$ is a Bernoulli random variable such that $P ( X = 1 ) = \alpha$ and $P ( X = 0 ) =$ $1 - \alpha$ with $0 < \alpha < 1$ , $\sigma _ { 1 } ^ { 2 }$ is small, and $\sigma _ { 2 } ^ { 2 }$ is relatively large. For instance, with $\alpha = 0 . 0 5$ , the finite mixture says that $9 5 \%$ of the returns follow $N ( \mu , \sigma _ { 1 } ^ { 2 } )$ and $5 \%$ follow $N ( \mu , \sigma _ { 2 } ^ { 2 } )$ . The large value of $\sigma _ { 2 } ^ { 2 }$ enables the mixture to put more mass at the tails of its distribution. The low percentage of returns that are from $N ( \mu , \sigma _ { 2 } ^ { 2 } )$ says that the majority of the returns follow a simple normal distribution. Advantages of mixtures of normal include that they maintain the tractability of normal, have finite higher order moments, and can capture the excess kurtosis. Yet it is hard to estimate the mixture parameters (e.g., the $\alpha$ in the finite-mixture case).

![](images/a819ddc902ad6163659df3902fc3c47f304c3dc334a8468e00e7b2a95a2d3e2b.jpg)  
Figure 1.1. Comparison of finite mixture, stable, and standard normal density functions.

Figure 1.1 shows the probability density functions of a finite mixture of normal, Cauchy, and standard normal random variable. The finite mixture of normal is $( 1 - X ) N ( 0 , 1 ) + X \times N ( 0 , 1 6 )$ with $X$ being Bernoulli such that $P ( X = 1 ) =$ 0.05, and the density function of Cauchy is

$$
f (x) = \frac {1}{\pi \left(1 + x ^ {2}\right)}, \quad - \infty <   x <   \infty .
$$

It is seen that the Cauchy distribution has fatter tails than the finite mixture of normal, which, in turn, has fatter tails than the standard normal.

# 1.2.3 Multivariate Returns

Let ana $\pmb { r } _ { t } = ( r _ { 1 t } , \ldots , r _ { N t } ) ^ { \prime }$ be the log returns of  and 10 are concerned $N$ assets at time t . The multh the joint distribution of . $\{ r _ { t } \} _ { t = 1 } ^ { T }$ This joint distribution can be partitioned in the same way as that of Eq. (1.15). The analysis is then focused on the specification of the conditional distribution function $F ( \pmb { r } _ { t } | \pmb { r } _ { t - 1 } , \dots , \pmb { r } _ { 1 } , \pmb { \theta } )$ . In particular, how the conditional expectation and conditional covariance matrix of $r _ { t }$ evolve over time constitute the main subjects of Chapters 8 and 10.

The mean vector and covariance matrix of a random vector $\pmb { X } = ( X _ { 1 } , \ldots , X _ { p } )$ are defined as

$$
E (X) = \boldsymbol {\mu} _ {x} = [ E (X _ {1}), \dots , E (X _ {p}) ] ^ {\prime},
$$

$$
\operatorname {C o v} (X) = \boldsymbol {\Sigma} _ {x} = E \left[ \left(X - \boldsymbol {\mu} _ {x}\right) \left(X - \boldsymbol {\mu} _ {x}\right) ^ {\prime} \right],
$$

provided that the expectations involved exist. When the data $\{ \pmb { x } _ { 1 } , \hdots , \pmb { x } _ { T } \}$ of $X$ are available, the sample mean and covariance matrix are defined as

$$
\widehat {\boldsymbol {\mu}} _ {x} = \frac {1}{T} \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t}, \quad \widehat {\boldsymbol {\Sigma}} _ {x} = \frac {1}{T - 1} \sum_ {t = 1} ^ {T} (\boldsymbol {x} _ {t} - \widehat {\boldsymbol {\mu}} _ {x}) (\boldsymbol {x} _ {t} - \widehat {\boldsymbol {\mu}} _ {x}) ^ {\prime}.
$$

These sample statistics are consistent estimates of their theoretical counterparts provided that the covariance matrix of $X$ exists. In the finance literature, the multivariate normal distribution is often used for the log return $r _ { t }$ .

# 1.2.4 Likelihood Function of Returns

The partition of Eq. (1.15) can be used to obtain the likelihood function of the log returns $\{ r _ { 1 } , \ldots , r _ { T } \}$ of an asset, where for ease in notation the subscript $i$ is omitted from the log return. If the conditional distribution $f ( r _ { t } | r _ { t - 1 } , \dots , r _ { 1 } , \pmb \theta )$ is normal with mean $\mu _ { t }$ and variance $\sigma _ { t } ^ { 2 }$ , then $\pmb \theta$ consists of the parameters in $\mu _ { t }$ and $\sigma _ { t } ^ { 2 }$ and the likelihood function of the data is

$$
f \left(r _ {1}, \dots , r _ {T}; \boldsymbol {\theta}\right) = f \left(r _ {1}; \boldsymbol {\theta}\right) \prod_ {t = 2} ^ {T} \frac {1}{\sqrt {2 \pi} \sigma_ {t}} \exp \left(\frac {- \left(r _ {t} - \mu_ {t}\right) ^ {2}}{2 \sigma_ {t} ^ {2}}\right), \tag {1.18}
$$

where $f ( r _ { 1 } ; \pmb { \theta } )$ is the marginal density function of the first observation $r _ { 1 }$ . The value of $\pmb \theta$ that maximizes this likelihood function is the maximum likelihood estimate (MLE) of $\pmb \theta$ . Since the log function is monotone, the MLE can be obtained by maximizing the log likelihood function,

$$
\ln f (r _ {1}, \dots , r _ {T}; \boldsymbol {\theta}) = \ln f (r _ {1}; \boldsymbol {\theta}) - \frac {1}{2} \sum_ {t = 2} ^ {T} \left(\ln (2 \pi) + \ln (\sigma_ {t} ^ {2}) + \frac {(r _ {t} - \mu_ {t}) ^ {2}}{\sigma_ {t} ^ {2}}\right),
$$

which is easier to handle in practice. The log likelihood function of the data can be obtained in a similar manner if the conditional distribution $f ( r _ { t } | r _ { t - 1 } , \dots , r _ { 1 } ; \pmb \theta )$ is not normal.

# 1.2.5 Empirical Properties of Returns

The data used in this section are obtained from the Center for Research in Security Prices (CRSP) of the University of Chicago. Dividend payments, if any, are included in the returns. Figure 1.2 shows the time plots of monthly simple returns and log returns of International Business Machines (IBM) stock from January 1926 to December 2003. A time plot shows the data against the time index. The upper plot is for the simple returns. Figure 1.3 shows the same plots for the monthly returns of value-weighted market index. As expected, the plots show that the basic patterns of simple and log returns are similar.

![](images/82129a9ed2a7afcc1699fbc965f6ff38d2c08a802b8dbd238485712e07676745.jpg)

![](images/1c10278621d3af835126dd7fc7a4af4bc12098675b65ac85cde658bc70a73ddf.jpg)  
Figure 1.2. Time plots of monthly returns of IBM stock from January 1926 to December 2003. The upper panel is for simple returns, and the lower panel is for log returns.

![](images/52aa589b3f4e11c6307fc3354bceee6ff368bf7a015ff29195edd40fbfa8cdbe.jpg)

![](images/23846ccc5079934b6505278ec2469f8c23c3950c1eabc1f91814d22bd7ea7156.jpg)  
Figure 1.3. Time plots of monthly returns of the value-weighted index from January 1926 to December 2003. The upper panel is for simple returns, and the lower panel is for log returns.

Table 1.2 provides some descriptive statistics of simple and log returns for selected U.S. market indexes and individual stocks. The returns are for daily and monthly sample intervals and are in percentages. The data spans and sample sizes are also given in the table. From the table, we make the following observations. (a) Daily returns of the market indexes and individual stocks tend to have high excess kurtosis. For monthly series, the returns of market indexes have higher excess kurtosis than individual stocks. (b) The mean of a daily return series is close to zero, whereas that of a monthly return series is slightly larger. (c) Monthly returns have higher standard deviations than daily returns. (d) Among the daily returns, market indexes have smaller standard deviations than individual stocks. This is in agreement with common sense. (e) The skewness is not a serious problem for both daily and monthly returns. (f) The descriptive statistics show that the difference between simple and log returns is not substantial.

Figure 1.4 shows the empirical density functions of monthly simple and log returns of IBM stock. Also shown, by a dashed line, in each graph is the normal probability density function evaluated by using the sample mean and standard deviation of IBM returns given in Table 1.2. The plots indicate that the normality assumption is questionable for monthly IBM stock returns. The empirical density function has a higher peak around its mean, but fatter tails than that of the corresponding normal distribution. In other words, the empirical density function is taller and skinnier, but with a wider support than the corresponding normal density.

![](images/4fa00af2f5f7118aeb6ad53f13476d490482f71bccaf82924f31b24837d1cf40.jpg)

![](images/e0d2c917cbc61939f7e0cef2edd16d9a7ac4692e414b9fb65f53ece8d1780f6b.jpg)  
Figure 1.4. Comparison of empirical and normal densities for the monthly simple and log returns of IBM stock. The sample period is from January 1926 to December 2003. The left plot is for simple returns and the right plot for log returns. The normal density, shown by the dashed line, uses the sample mean and standard deviation given in Table 1.2.

# 1.3 PROCESSES CONSIDERED

Besides the return series, we also consider the volatility process and the behavior of extreme returns of an asset. The volatility process is concerned with the evolution of conditional variance of the return over time. This is a topic of interest because, as shown in Figures 1.2 and 1.3, the variabilities of returns vary over time and appear in clusters. In application, volatility plays an important role in pricing options and risk management. By extremes of a return series, we mean the large positive or negative returns. Table 1.2 shows that the minimum and maximum of a return series can be substantial. The negative extreme returns are important in risk management, whereas positive extreme returns are critical to holding a short position. We study properties and applications of extreme returns, such as the frequency of occurrence, the size of an extreme, and the impacts of economic variables on the extremes, in Chapter 7.

Other financial time series considered in the book include interest rates, exchange rates, bond yields, and quarterly earning per share of a company. Figure 1.5 shows the time plots of two U.S. monthly interest rates. They are the 10-year and 1-year Treasury constant maturity rates from April 1954 to March 2004. As expected, the two interest rates moved in unison, but the 1-year rates appear to be more volatile. Figure 1.6 shows the daily exchange rate between the U.S. dollar and

![](images/e26ee0bc80d2aae24938e05a895b20e33bad4ab6cd057f91e68225649f6b995c.jpg)

![](images/ef5cdaca469fa4bd69e3f71d552b030fcdaefe4b1528ac5ba5b7a6bd10a988bf.jpg)  
Figure 1.5. Time plots of monthly U.S. interest rates from April 1953 to March 2004: (a) the 10-year Treasury constant maturity rate and (b) the 1-year maturity rate.

![](images/077694770099a81f56872f7fa046b61580841e22b4c64984605363b9f76e84ad.jpg)

![](images/e2877c29e283076405805831040746b01209cb5834533d3997473dd54dfe4130.jpg)  
Figure 1.6. Time plot of daily exchange rate between U.S. dollar and Japanese yen from January 3, 2000 to March 26, 2004: (a) exchange rate and (b) changes in exchange rate.

the Japanese yen from January 2000 to March 2004. From the plot, the exchange rate encountered occasional big changes in the sampling period. Table 1.3 provides some descriptive statistics for selected U.S. financial time series. The monthly bond returns obtained from CRSP are Fama bond portfolio returns from January 1952 to December 2003. The interest rates are obtained from the Federal Reserve Bank of St. Louis. The weekly 3-month Treasury bill rate started on January 8, 1954, and the 6-month rate started on December 12, 1958. Both series ended on April 9, 2004. For the interest rate series, the sample means are proportional to the time to maturity, but the sample standard deviations are inversely proportional to the time to maturity. For the bond returns, the sample standard deviations are positively related to the time to maturity, whereas the sample means remain stable for all maturities. Most of the series considered have positive excess kurtosis.

With respect to the empirical characteristics of returns shown in Table 1.2, Chapters 2–4 focus on the first four moments of a return series and Chapter 7 on the behavior of minimum and maximum returns. Chapters 8 and 10 are concerned with moments of and the relationships between multiple asset returns, and Chapter 5 addresses properties of asset returns when the time interval is small. An introduction to mathematical finance is given in Chapter 6.

Table 1.3. Descriptive Statistics of Selected U.S. Financial Time Seriesa   

<table><tr><td>Maturity</td><td>Mean</td><td>Standard Deviation</td><td>Skewness</td><td>Excess Kurtosis</td><td>Minimum</td><td>Maximum</td></tr><tr><td colspan="7">Monthly Bond Returns: January 1952 to December 2003, T = 624</td></tr><tr><td>1–12 months</td><td>0.47</td><td>0.36</td><td>2.43</td><td>12.67</td><td>-0.40</td><td>3.52</td></tr><tr><td>24–36 months</td><td>0.53</td><td>0.99</td><td>1.40</td><td>12.93</td><td>-4.90</td><td>9.33</td></tr><tr><td>48–60 months</td><td>0.53</td><td>1.42</td><td>0.62</td><td>4.97</td><td>-5.78</td><td>10.06</td></tr><tr><td>61–120 months</td><td>0.55</td><td>1.71</td><td>0.63</td><td>4.86</td><td>-7.35</td><td>10.92</td></tr><tr><td colspan="7">Monthly Treasury Rates: April 1953 to March 2004, T = 612</td></tr><tr><td>1 year</td><td>5.80</td><td>3.01</td><td>0.96</td><td>1.27</td><td>-0.82</td><td>16.72</td></tr><tr><td>3 years</td><td>6.21</td><td>2.86</td><td>0.89</td><td>0.81</td><td>-1.47</td><td>16.22</td></tr><tr><td>5 years</td><td>6.41</td><td>2.79</td><td>0.88</td><td>0.67</td><td>-1.85</td><td>15.93</td></tr><tr><td>10 years</td><td>6.60</td><td>2.73</td><td>0.83</td><td>0.42</td><td>-2.29</td><td>15.32</td></tr><tr><td colspan="7">Weekly Treasury Bill Rates: End on February 16, 2001</td></tr><tr><td>3 months</td><td>5.51</td><td>2.76</td><td>1.14</td><td>1.88</td><td>-0.58</td><td>16.76</td></tr><tr><td>6 months</td><td>6.08</td><td>2.56</td><td>1.26</td><td>1.82</td><td>-2.35</td><td>15.76</td></tr></table>

aThe data are in percentages. The weekly 3-month Treasury bill rate started from January 8, 1954 and the 6-month rate started from December 12, 1958. Data sources are given in the text.

# EXERCISES

1.1. Consider the daily stock returns of American Express (axp), Caterpillar (cat), and Starbucks (sbux) from January 1994 to December 2003. The data are simple returns given in the file d-3stock.txt (date, axp, cat, sbux).

(a) Express the simple returns in percentages. Compute the sample mean, standard deviation, skewness, excess kurtosis, minimum, and maximum of the percentage simple returns.   
(b) Transform the simple returns to log returns.   
(c) Express the log returns in percentages. Compute the sample mean, standard deviation, skewness, excess kurtosis, minimum, and maximum of the percentage log returns.   
(d) Test the null hypothesis that the mean of the log returns of each stock is zero. (Perform three separate tests.) Use $5 \%$ significance level to draw your conclusion.

1.2. Answer the same questions as Exercise 1.1 but using monthly stock returns for IBM, CRSP value-weighted index (VW), CRSP equal-weighted index (EW), and S&P composite index from January 1975 to December 2003. The returns of the indexes include dividend distributions. Data file is m-ibm3dx7503.txt.

1.3. Consider the monthly stock returns of S&P composite index from January 1975 to December 2003 in Exercise 1.2. Answer the following questions:

(a) What is the average annual log return over the data span?   
(b) Assume that there were no transaction costs. If one invested $\$ 1.00$ on the S&P composite index at the beginning of 1975, what was the value of the investment at the end of 2003?

1.4. Consider the daily log returns of American Express stock from January 1994 to December 2003 as in Exercise 1.1. Use the $5 \%$ significance level to perform the following tests. (a) Test the null hypothesis that the skewness measure of the returns is zero. (b) Test the null hypothesis that the excess kurtosis of the returns is zero.   
1.5. Daily foreign exchange rates (spot rates) can be obtained from the Federal Reserve Bank in Chicago. The data are the noon buying rates in New York City certified by the Federal Reserve Bank of New York. Consider the exchange rates between the U.S. dollar and the Canadian dollar, euro, U.K. pound, and Japanese yen from January 2000 to March 2004. (a) Compute the daily log return of each exchange rate. (b) Compute the sample mean, standard deviation, skewness, excess kurtosis, minimum, and maximum of the log returns of each exchange rate. (c) Discuss the empirical characteristics of the log returns of exchange rates.

# REFERENCES

Campbell, J. Y., Lo, A. W., and MacKinlay, A. C. (1997). The Econometrics of Financial Markets. Princeton University Press, Princeton, NJ.   
Jarque, C. M. and Bera, A. K. (1987). A test of normality of observations and regression residuals. International Statistical Review 55: 163–172.   
Sharpe, W. (1964). Capital asset prices: A theory of market equilibrium under conditions of risk. Journal of Finance 19: 425–442.   
Snedecor, G. W. and Cochran, W. G. (1980). Statistical Methods, 7th edition. Iowa State University Press, Ames, IA.

# Linear Time Series Analysis and Its Applications

In this chapter, we discuss basic theories of linear time series analysis, introduce some simple econometric models useful for analyzing financial time series, and apply the models to asset returns. Discussions of the concepts are brief with emphasis on those relevant to financial applications. Understanding the simple time series models introduced here will go a long way to better appreciate the more sophisticated financial econometric models of the later chapters. There are many time series textbooks available. For basic concepts of linear time series analysis, see Box, Jenkins, and Reinsel (1994, Chapters 2 and 3) and Brockwell and Davis (1996, Chapters 1–3).

Treating an asset return (e.g., log return $r _ { t }$ of a stock) as a collection of random variables over time, we have a time series $\{ r _ { t } \}$ . Linear time series analysis provides a natural framework to study the dynamic structure of such a series. The theories of linear time series discussed include stationarity, dynamic dependence, autocorrelation function, modeling, and forecasting. The econometric models introduced include (a) simple autoregressive (AR) models, (b) simple moving-average (MA) models, (c) mixed autoregressive moving-average (ARMA) models, (d) seasonal models, (e) unit-root nonstationarity, (f) regression models with time series errors, and (g) fractionally differenced models for long-range dependence. For an asset return $r _ { t }$ , simple models attempt to capture the linear relationship between $r _ { t }$ and information available prior to time t . The information may contain the historical values of $r _ { t }$ and the random vector $Y$ in Eq. (1.14) that describes the economic environment under which the asset price is determined. As such, correlation plays an important role in understanding these models. In particular, correlations between the variable of interest and its past values become the focus of linear time series analysis. These correlations are referred to as serial correlations or autocorrelations. They are the basic tool for studying a stationary time series.

# 2.1 STATIONARITY

The foundation of time series analysis is stationarity. A time series $\{ r _ { t } \}$ is said to be strictly stationary if the joint distribution of $( r _ { t _ { 1 } } , \ldots , r _ { t _ { k } } )$ is identical to that of $( r _ { t _ { 1 } + t } , \ldots , r _ { t _ { k } + t } )$ for all $t$ , where $k$ is an arbitrary positive integer and $( t _ { 1 } , \ldots , t _ { k } )$ is a collection of $k$ positive integers. In other words, strict stationarity requires that the joint distribution of $( r _ { t _ { 1 } } , \ldots , r _ { t _ { k } } )$ is invariant under time shift. This is a very strong condition that is hard to verify empirically. A weaker version of stationarity is often assumed. A time series $\{ r _ { t } \}$ is weakly stationary if both the mean of $r _ { t }$ and the covariance between $r _ { t }$ and $r _ { t - \ell }$ are time-invariant, where $\ell$ is an arbitrary integer. More specifically, $\{ r _ { t } \}$ is weakly stationary if (a) $E ( r _ { t } ) = \mu$ , which is a constant, and (b) $\operatorname { C o v } ( r _ { t } , r _ { t - \ell } ) = \gamma _ { \ell }$ , which only depends on . In practice, suppose that we have observed $T$ data points $\{ r _ { t } | t = 1 , \ldots , T \}$ . The weak stationarity implies that the time plot of the data would show that the $T$ values fluctuate with constant variation around a fixed level. In applications, weak stationarity enables one to make inferences concerning future observations (e.g., prediction).

Implicitly, in the condition of weak stationarity, we assume that the first two moments of $r _ { t }$ are finite. From the definitions, if $r _ { t }$ is strictly stationary and its first two moments are finite, then $r _ { t }$ is also weakly stationary. The converse is not true in general. However, if the time series $r _ { t }$ is normally distributed, then weak stationarity is equivalent to strict stationarity. In this book, we are mainly concerned with weakly stationary series.

The covariance $\gamma _ { \ell } = \mathrm { C o v } ( r _ { t } , r _ { t - \ell } )$ is called the lag- autocovariance of $r _ { t }$ . It has two important properties: (a) $\gamma _ { 0 } = \mathrm { V a r } ( r _ { t } )$ and (b) $\gamma _ { - \ell } = \gamma _ { \ell }$ . The second property holds because $\mathrm { C o v } ( r _ { t } , r _ { t - ( - \ell ) } ) = \mathrm { C o v } ( r _ { t - ( - \ell ) } , r _ { t } ) = \mathrm { C o v } ( r _ { t + \ell } , r _ { t } ) =$ $\mathrm { C o v } ( r _ { t _ { 1 } } , r _ { t _ { 1 } - \ell } )$ , where $t _ { 1 } = t + \ell$ .

In the finance literature, it is common to assume that an asset return series is weakly stationary. This assumption can be checked empirically provided that a sufficient number of historical returns are available. For example, one can divide the data into subsamples and check the consistency of the results obtained across the subsamples.

# 2.2 CORRELATION AND AUTOCORRELATION FUNCTION

The correlation coefficient between two random variables $X$ and $Y$ is defined as

$$
\rho_ {x, y} = \frac {\operatorname {C o v} (X , Y)}{\sqrt {\operatorname {V a r} (X) \operatorname {V a r} (Y)}} = \frac {E [ (X - \mu_ {x}) (Y - \mu_ {y}) ]}{\sqrt {E (X - \mu_ {x}) ^ {2} E (Y - \mu_ {y}) ^ {2}}},
$$

where $\mu _ { x }$ and $\mu _ { y }$ are the mean of $X$ and $Y$ , respectively, and it is assumed that the variances exist. This coefficient measures the strength of linear dependence between $X$ and $Y$ , and it can be shown that $- 1 \le \rho _ { x , y } \le 1$ and $\rho _ { x , y } = \rho _ { y , x }$ . The two random variables are uncorrelated if $\rho _ { x , y } = 0$ . In addition, if both $X$ and $Y$ are normal random variables, then $\rho _ { x , y } = 0$ if and only if $X$ and $Y$ are independent. When the

sample $\{ ( x _ { t } , y _ { t } ) \} _ { t = 1 } ^ { T }$ is available, the correlation can be consistently estimated by its sample counterpart

$$
\hat {\rho} _ {x, y} = \frac {\sum_ {t = 1} ^ {T} (x _ {t} - \overline {{x}}) (y _ {t} - \overline {{y}})}{\sqrt {\sum_ {t = 1} ^ {T} (x _ {t} - \overline {{x}}) ^ {2} \sum_ {t = 1} ^ {T} (y _ {t} - \overline {{y}}) ^ {2}}},
$$

where $\textstyle { \overline { { x } } } = { \bigl ( } \sum _ { t = 1 } ^ { T } x _ { t } { \bigr ) } / T$ and $\textstyle { \overline { { y } } } = { \bigl ( } \sum _ { t = 1 } ^ { T } y _ { t } { \bigr ) } / T$ are the sample mean of $X$ and $Y$ respectively.

# Autocorrelation Function (ACF)

Consider a weakly stationary return series $r _ { t }$ . When the linear dependence between $r _ { t }$ and its past values $r _ { t - i }$ is of interest, the concept of correlation is generalized to autocorrelation. The correlation coefficient between $r _ { t }$ and $r _ { t - \ell }$ is called the lag- autocorrelation of $r _ { t }$ and is commonly denoted by $\rho _ { \ell }$ , which under the weak stationarity assumption is a function of $\ell$ only. Specifically, we define

$$
\rho_ {\ell} = \frac {\operatorname {C o v} \left(r _ {t} , r _ {t - \ell}\right)}{\sqrt {\operatorname {V a r} \left(r _ {t}\right) \operatorname {V a r} \left(r _ {t - \ell}\right)}} = \frac {\operatorname {C o v} \left(r _ {t} , r _ {t - \ell}\right)}{\operatorname {V a r} \left(r _ {t}\right)} = \frac {\gamma_ {\ell}}{\gamma_ {0}}, \tag {2.1}
$$

where the property $\operatorname { V a r } ( r _ { t } ) = \operatorname { V a r } ( r _ { t - \ell } )$ for a weakly stationary series is used. From the definition, we have $\rho _ { 0 } = 1$ , $\rho _ { \ell } = \rho _ { - \ell }$ , and $- 1 \leq \rho _ { \ell } \leq 1 .$ . In addition, a weakly stationary series $r _ { t }$ is not serially correlated if and only if $\rho _ { \ell } = 0$ for all $\ell > 0$ .

For a given sample of returns $\{ r _ { t } \} _ { t = 1 } ^ { T }$ , let $\overline { r }$ be the sample mean (i.e., $\overline { r } =$ $\textstyle { \big ( } \sum _ { t = 1 } ^ { T } r _ { t } { \big ) } / T$ = . Then the lag-1 sample autocorrelation of $r _ { t }$ is

$$
\hat {\rho} _ {1} = \frac {\sum_ {t = 2} ^ {T} (r _ {t} - \overline {{r}}) (r _ {t - 1} - \overline {{r}})}{\sum_ {t = 1} ^ {T} (r _ {t} - \overline {{r}}) ^ {2}}.
$$

Under some general conditions, $\hat { \rho } _ { 1 }$ is a consistent estimate of $\rho _ { 1 }$ . For example, if $\{ r _ { t } \}$ is an independent and identically distributed (iid) sequence and $E ( r _ { t } ^ { 2 } ) < \infty$ , then $\hat { \rho } _ { 1 }$ is asymptotically normal with mean zero and variance $1 / T$ ; see Brockwell and Davis (1991, Theorem 7.2.2). This result can be used in practice to test the null hypothesis $H _ { o } : \rho _ { 1 } = 0$ versus the alternative hypothesis $H _ { a } : \rho _ { 1 } \neq 0$ . The test statistic is the usual $t$ ratio, which is $\sqrt { T } \hat { \rho } _ { 1 }$ , and follows asymptotically the standard normal distribution. In general, the lag- sample autocorrelation of $r _ { t }$ is defined as

$$
\hat {\rho} _ {\ell} = \frac {\sum_ {t = \ell + 1} ^ {T} \left(r _ {t} - \bar {r}\right) \left(r _ {t - \ell} - \bar {r}\right)}{\sum_ {t = 1} ^ {T} \left(r _ {t} - \bar {r}\right) ^ {2}}, \quad 0 \leq \ell <   T - 1. \tag {2.2}
$$

If $\{ r _ { t } \}$ is an iid sequence satisfying $E ( r _ { t } ^ { 2 } ) < \infty$ , then $\hat { \rho } _ { \ell }$ is asymptotically normal with mean zero and variance $1 / T$ for any fixed positive integer . More generally, if $r _ { t }$ is a weakly stationary time series satisfying $\textstyle r _ { t } = \mu + \sum _ { i = 0 } ^ { q } \psi _ { i } a _ { t - i }$ , where $\psi _ { 0 } = 1 , q$ is a non-negative integer, and $\{ a _ { j } \}$ is a Gaussian white noise series, then $\hat { \rho } _ { \ell }$ is asymptotically normal with mean zero and variance $\textstyle { \big ( } 1 + 2 \sum _ { i = 1 } ^ { q } \rho _ { i } ^ { 2 } { \big ) } / T$

for $\ell > q$ . This is referred to as Bartlett’s formula in the time series literature; see Box, Jenkins, and Reinsel (1994). For more information about the asymptotic distribution of sample autocorrelations, see Fuller (1976, Chapter 6) and Brockwell and Davis (1991, Chapter 7).

# Testing Individual ACF

For a given positive integer $\ell$ , the previous result can be used to test $H _ { o } : \rho _ { \ell } = 0$ versus $H _ { a } : \rho _ { \ell } \neq 0$ . The test statistic is

$$
t \text {- r a t i o} = \frac {\hat {\rho} _ {\ell}}{\sqrt {(1 + 2 \sum_ {i = 1} ^ {\ell - 1} \hat {\rho} _ {i} ^ {2}) / T}}.
$$

If $\{ r _ { t } \}$ is a stationary Gaussian series satisfying $\rho _ { j } = 0$ for $j > \ell$ , the $t$ -ratio is asymptotically distributed as a standard normal random variable. Hence, the decision rule of the test is to reject $H _ { o }$ if $| t \mathrm { - r a t i o } | > Z _ { \alpha / 2 }$ , where $Z _ { \alpha / 2 }$ is the $1 0 0 ( 1 - \alpha / 2 ) \mathrm { t h }$ percentile of the standard normal distribution.

In finite samples, $\hat { \rho } _ { \ell }$ is a biased estimator of $\rho _ { \ell }$ . The bias is on the order of $1 / T$ , which can be substantial when the sample size $T$ is small. In most financial applications, $T$ is relatively large so that the bias is not serious.

# Portmanteau Test

Financial applications often require to test jointly that several autocorrelations of $r _ { t }$ are zero. Box and Pierce (1970) propose the Portmanteau statistic

$$
Q ^ {*} (m) = T \sum_ {\ell = 1} ^ {m} \hat {\rho} _ {\ell} ^ {2}
$$

as a test statistic for the null hypothesis $H _ { o } : \rho _ { 1 } = \cdot \cdot \cdot = \rho _ { m } = 0$ against the alternative hypothesis $H _ { a } : \rho _ { i } \neq 0$ for some $i \in \{ 1 , \ldots , m \}$ . Under the assumption that $\{ r _ { t } \}$ is an iid sequence with certain moment conditions, $Q ^ { * } ( m )$ is asymptotically a chi-squared random variable with $m$ degrees of freedom.

Ljung and Box (1978) modify the $Q ^ { * } ( m )$ statistic as below to increase the power of the test in finite samples:

$$
Q (m) = T (T + 2) \sum_ {\ell = 1} ^ {m} \frac {\hat {\rho} _ {\ell} ^ {2}}{T - \ell}. \tag {2.3}
$$

The decision rule is to reject $H _ { o }$ if $Q ( m ) > \chi _ { \alpha } ^ { 2 }$ , where $\chi _ { \alpha } ^ { 2 }$ denotes the $1 0 0 ( 1 - \alpha ) $ th percentile of a chi-squared distribution with m degrees of freedom. Most software packets will provide the $p$ -value of $Q ( m )$ . The decision rule is then to reject $H _ { o }$ if the $p$ -value is less than or equal to $\alpha$ , the significance level.

In practice, the selection of m may affect the performance of the $Q ( m )$ statistic. Several values of $m$ are often used. Simulation studies suggest that the choice of $m \approx \ln ( T )$ provides better power performance. This general rule needs modification

in analysis of seasonal time series for which autocorrelations with lags at multiples of the seasonality are more important.

The statistics $\hat { \rho } _ { 1 }$ , $\hat { \rho } _ { 2 }$ , . . . defined in Eq. (2.2) is called the sample autocorrelation function (ACF) of $r _ { t }$ . It plays an important role in linear time series analysis. As a matter of fact, a linear time series model can be characterized by its ACF, and linear time series modeling makes use of the sample ACF to capture the linear dynamic of the data. Figure 2.1 shows the sample autocorrelation functions of monthly simple and log returns of IBM stock from January 1926 to December 1997. The two sample ACFs are very close to each other, and they suggest that the serial correlations of monthly IBM stock returns are very small, if any. The sample ACFs are all within their two standard-error limits, indicating that they are not significantly different from zero at the $5 \%$ level. In addition, for the simple returns, the Ljung–Box statistics give $Q ( 5 ) = 5 . 4 $ and $Q ( 1 0 ) = 1 4 . 1 $ , which correspond to $p$ -values of 0.37 and 0.17, respectively, based on chi-squared distributions with 5 and 10 degrees of freedom. For the log returns, we have $Q ( 5 ) = 5 . 8 $ and $Q ( 1 0 ) = 1 3 . 7 $ with $p$ -values 0.33 and 0.19, respectively. The joint tests confirm that monthly IBM stock returns have no significant serial correlations. Figure 2.2 shows the same for the monthly returns of the value-weighted index from the Center for Research in Security Prices (CRSP), University of Chicago. There are some significant serial correlations at

![](images/72b1dabd0054a564715d8d0b371495082612fdc383115ab94cda4bc9cef3eb59.jpg)

![](images/9b022049c541378f2199a3d20d3db2f96d94732699a19de9f505b713025a6088.jpg)  
Figure 2.1. Sample autocorrelation functions of monthly (a) simple returns and (b) log returns of IBM stock from January 1926 to December 1997. In each plot, the two horizontal lines denote two standard-error limits of the sample ACF.

![](images/ee2d2a95e94325e4ad38365f3180fc868ce5f221e908d490c3c7a072b60322c2.jpg)  
(a) Simple returns

![](images/7f0a8aabb8294cb7dce2e52893e874f606e1bc1b73db5b9f797b96d635ddf214.jpg)  
(b) Log returns   
Figure 2.2. Sample autocorrelation functions of monthly (a) simple returns and (b) log returns of the value-weighted index of U.S. markets from January 1926 to December 1997. In each plot, the two horizontal lines denote two standard-error limits of the sample ACF.

the $5 \%$ level for both return series. The Ljung–Box statistics give $Q ( 5 ) = 2 7 . 8 $ and $Q ( 1 0 ) = 3 6 . 0 $ for the simple returns and $Q ( 5 ) = 2 6 . 9$ and $Q ( 1 0 ) = 3 2 . 7 $ for the log returns. The $p$ -values of these four test statistics are all less than 0.0003, suggesting that monthly returns of the value-weighted index are serially correlated. Thus, the monthly market index return seems to have stronger serial dependence than individual stock returns.

In the finance literature, a version of the capital asset pricing model (CAPM) theory is that the return $\{ r _ { t } \}$ of an asset is not predictable and should have no autocorrelations. Testing for zero autocorrelations has been used as a tool to check the efficient market assumption. However, the way by which stock prices are determined and index returns are calculated might introduce autocorrelations in the observed return series. This is particularly so in analysis of high-frequency financial data. We discuss some of these issues in Chapter 5.

# SCA Demonstration

Output edited and $\%$ denotes explanation.

acf ibm. maxl 10. % Compute 10 lags of ACF.

NAME OF THE SERIES . IBM  
TIME PERIOD ANALYZED 1 TO 864  
MEAN OF THE (DIFFERENCES) SERIES 0.0142  
STANDARD DEVIATION OF THE SERIES 0.0670  
T-VALUE OF MEAN (AGAINST ZERO) 6.2246  
AUTOCORRELATIONS % ACF(lag 1 to 10), Standard error, Q(m)  
1-10 .07 .01 -.02 -.01 -.01 -.01 -.00 .07 .05 .04  
ST.E. .03 .03 .03 .03 .03 .03 .03 .03 .03  
Q 4.8 4.9 5.4 5.4 5.4 5.5 5.5 10.2 12.6 14.1  
-- $= 1$ -cdfc(5.4,5) % Calculate p-value  
--  
print p % Print p-value  
.369

# S-Plus Demonstration

Output edited and $>$ denotes the prompt character.

```python
> ibm=scan(file='m-ibm2697.txt') % Load data
> autocorTest(IBM, lag=5) % Perform Q(5) test 
```

Test for Autocorrelation: Ljung-Box

```txt
Null Hypothesis: no autocorrelation 
```

Test Statistics:

```txt
Test Stat 5.4474 p.value 0.3638 
```

```txt
Dist. under Null: chi-square with 5 degrees of freedom  
Total Observ.: 864 
```

```txt
> ibm=log(IBM+1) % Convert into log returns  
> autocorTest(IBM, lag=5) 
```

Test Statistics:

```txt
Test Stat 5.7731 p.value 0.3289 
```

```txt
Dist. under Null: chi-square with 5 degrees of freedom 
```

# 2.3 WHITE NOISE AND LINEAR TIME SERIES

# White Noise

A time series $r _ { t }$ is called a white noise if $\{ r _ { t } \}$ is a sequence of independent and identically distributed random variables with finite mean and variance. In particular, if $r _ { t }$ is normally distributed with mean zero and variance $\sigma ^ { 2 }$ , the series is called a Gaussian white noise. For a white noise series, all the ACFs are zero. In practice, if all sample ACFs are close to zero, then the series is a white noise series. Based on Figures 2.1 and 2.2, the monthly returns of IBM stock are close to white noise, whereas those of the value-weighted index are not.

The behavior of sample autocorrelations of the value-weighted index returns indicates that for some asset returns it is necessary to model the serial dependence before further analysis can be made. In what follows, we discuss some simple time series models that are useful in modeling the dynamic structure of a time series. The concepts presented are also useful later in modeling volatility of asset returns.

# Linear Time Series

A time series $r _ { t }$ is said to be linear if it can be written as

$$
r _ {t} = \mu + \sum_ {i = 0} ^ {\infty} \psi_ {i} a _ {t - i}, \tag {2.4}
$$

where $\mu$ is the mean of $r _ { t }$ , $\psi _ { 0 } = 1$ , and $\{ a _ { t } \}$ is a sequence of independent and identically distributed random variables with mean zero and a well-defined distribution (i.e., $\{ a _ { t } \}$ is a white noise series). It will be seen later that $a _ { t }$ denotes the new information at time $t$ of the time series and is often referred to as the innovation or shock at time t. In this book, we are mainly concerned with the case where $a _ { t }$ is a continuous random variable. Not all financial time series are linear, however. We study nonlinearity and nonlinear models in Chapter 4.

For a linear time series in Eq. (2.4), the dynamic structure of $r _ { t }$ is governed by the coefficients $\psi _ { i }$ , which are called the $\psi$ -weights of $r _ { t }$ in the time series literature. If $r _ { t }$ is weakly stationary, we can obtain its mean and variance easily by using the independence of $\{ a _ { t } \}$ as

$$
E \left(r _ {t}\right) = \mu , \quad \operatorname {V a r} \left(r _ {t}\right) = \sigma_ {a} ^ {2} \sum_ {i = 0} ^ {\infty} \psi_ {i} ^ {2}, \tag {2.5}
$$

where $\sigma _ { a } ^ { 2 }$ is the variance of $a _ { t }$ . Because $\mathrm { V a r } ( r _ { t } ) < \infty$ , $\{ \psi _ { i } ^ { 2 } \}$ must be a convergent sequence, that is, ${ \psi } _ { i } ^ { 2 }  0$ and $i  \infty$ . Consequently, for a stationary series, impact of the remote shock $a _ { t - i }$ on the return $r _ { t }$ vanishes as $i$ increases.

The lag- autocovariance of $r _ { t }$ is

$$
\gamma_ {\ell} = \mathrm {C o v} (r _ {t}, r _ {t - \ell}) = E \left[ \left(\sum_ {i = 0} ^ {\infty} \psi_ {i} a _ {t - i}\right) \left(\sum_ {j = 0} ^ {\infty} \psi_ {j} a _ {t - \ell - j}\right) \right]
$$

$$
\begin{array}{l} = E \left(\sum_ {i, j = 0} ^ {\infty} \psi_ {i} \psi_ {j} a _ {t - i} a _ {t - \ell - j}\right) \\ = \sum_ {j = 0} ^ {\infty} \psi_ {j + \ell} \psi_ {j} E \left(a _ {t - \ell - j} ^ {2}\right) = \sigma_ {a} ^ {2} \sum_ {j = 0} ^ {\infty} \psi_ {j} \psi_ {j + \ell}. \tag {2.6} \\ \end{array}
$$

Consequently, the $\psi$ -weights are related to the autocorrelations of $r _ { t }$ as follows:

$$
\rho_ {\ell} = \frac {\gamma_ {\ell}}{\gamma_ {0}} = \frac {\sum_ {i = 0} ^ {\infty} \psi_ {i} \psi_ {i + \ell}}{1 + \sum_ {i = 1} ^ {\infty} \psi_ {i} ^ {2}}, \quad \ell \geq 0, \tag {2.7}
$$

where $\psi _ { 0 } = 1$ . Linear time series models are econometric and statistical models used to describe the pattern of the $\psi$ -weights of $r _ { t }$ . For a weakly stationary time series, ${ \psi } _ { i }  0$ as $i  \infty$ and, hence, $\rho _ { \ell }$ converges to zero as  increases. For asset returns, this means that, as expected, the linear dependence of current return $r _ { t }$ on the remote past return $r _ { t - \ell }$ diminishes for large $\ell$ .

# 2.4 SIMPLE AUTOREGRESSIVE MODELS

The fact that the monthly return $r _ { t }$ of CRSP value-weighted index has a statistically significant lag-1 autocorrelation indicates that the lagged return $r _ { t - 1 }$ might be useful in predicting $r _ { t }$ . A simple model that makes use of such predictive power is

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + a _ {t}, \tag {2.8}
$$

where $\{ a _ { t } \}$ is assumed to be a white noise series with mean zero and variance $\sigma _ { a } ^ { 2 }$ . This model is in the same form as the well-known simple linear regression model in which $r _ { t }$ is the dependent variable and $r _ { t - 1 }$ is the explanatory variable. In the time series literature, model (2.8) is referred to as an autoregressive (AR) model of order 1 or simply an AR(1) model. This simple model is also widely used in stochastic volatility modeling when $r _ { t }$ is replaced by its log volatility; see Chapters 3 and 12.

The AR(1) model in Eq. (2.8) has several properties similar to those of the simple linear regression model. However, there are some significant differences between the two models, which we discuss later. Here it suffices to note that an AR(1) model implies that, conditional on the past return $r _ { t - 1 }$ , we have

$$
E \left(r _ {t} \mid r _ {t - 1}\right) = \phi_ {0} + \phi_ {1} r _ {t - 1}, \quad \operatorname {V a r} \left(r _ {t} \mid r _ {t - 1}\right) = \operatorname {V a r} \left(a _ {t}\right) = \sigma_ {a} ^ {2}.
$$

That is, given the past return $r _ { t - 1 }$ , the current return is centered around $\phi _ { 0 } + \phi _ { 1 } r _ { t - 1 }$ with standard deviation $\sigma _ { a }$ . This is a Markov property such that conditional on $r _ { t - 1 }$ , the return $r _ { t }$ is not correlated with $r _ { t - i }$ for $i > 1$ . Obviously, there are situations in which $r _ { t - 1 }$ alone cannot determine the conditional expectation of $r _ { t }$ and a more

flexible model must be sought. A straightforward generalization of the AR(1) model is the $\operatorname { A R } ( p )$ model

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + \dots + \phi_ {p} r _ {t - p} + a _ {t}, \tag {2.9}
$$

where $p$ is a non-negative integer and $\{ a _ { t } \}$ is defined in Eq. (2.8). This model says that the past $p$ values $r _ { t - i }$ $( i = 1 , \ldots , p )$ jointly determine the conditional expectation of $r _ { t }$ given the past data. The $\operatorname { A R } ( p )$ model is in the same form as a multiple linear regression model with lagged values serving as the explanatory variables.

# 2.4.1 Properties of AR Models

For effective use of AR models, it pays to study their basic properties. We discuss properties of AR(1) and AR(2) models in detail and give the results for the general $\operatorname { A R } ( p )$ model.

# AR(1) Model

We begin with the sufficient and necessary condition for weak stationarity of the AR(1) model in Eq. (2.8). Assuming that the series is weakly stationary, we have $E ( r _ { t } ) = \mu$ , $\mathrm { V a r } ( r _ { t } ) = \gamma _ { 0 }$ , and $\mathrm { C o v } ( r _ { t } , r _ { t - j } ) = \gamma _ { j }$ , where $\mu$ and $\gamma _ { 0 }$ are constant and $\gamma _ { j }$ is a function of $j$ , not $t$ . We can easily obtain the mean, variance, and autocorrelations of the series as follows. Taking the expectation of Eq. (2.8) and because $E ( a _ { t } ) = 0$ , we obtain

$$
E \left(r _ {t}\right) = \phi_ {0} + \phi_ {1} E \left(r _ {t - 1}\right).
$$

Under the stationarity condition, $E ( r _ { t } ) = E ( r _ { t - 1 } ) = \mu$ and hence

$$
\mu = \phi_ {0} + \phi_ {1} \mu \quad \text {o r} \quad E (r _ {t}) = \mu = \frac {\phi_ {0}}{1 - \phi_ {1}}.
$$

This result has two implications for $r _ { t }$ . First, the mean of $r _ { t }$ exists if $\phi _ { 1 } \neq 1$ . Second, the mean of $r _ { t }$ is zero if and only if $\phi _ { 0 } = 0$ . Thus, for a stationary AR(1) process, the constant term $\phi _ { 0 }$ is related to the mean of $r _ { t }$ and $\phi _ { 0 } = 0$ implies that $E ( r _ { t } ) = 0$ .

Next, using $\phi _ { 0 } = ( 1 - \phi _ { 1 } ) \mu$ , the AR(1) model can be rewritten as

$$
r _ {t} - \mu = \phi_ {1} \left(r _ {t - 1} - \mu\right) + a _ {t}. \tag {2.10}
$$

By repeated substitutions, the prior equation implies that

$$
\begin{array}{l} r _ {t} - \mu = a _ {t} + \phi_ {1} a _ {t - 1} + \phi_ {1} ^ {2} a _ {t - 2} + \dots \\ = \sum_ {i = 0} ^ {\infty} \phi_ {1} ^ {i} a _ {t - i}. \tag {2.11} \\ \end{array}
$$

Thus, $r _ { t } - \mu$ is a linear function of $a _ { t - i }$ for $i \geq 0$ . Using this property and the independence of the series $\{ a _ { t } \}$ , we obtain $E [ ( r _ { t } - \mu ) a _ { t + 1 } ] = 0$ . By the stationarity assumption, we have $\operatorname { C o v } ( r _ { t - 1 } , a _ { t } ) = E [ ( r _ { t - 1 } - \mu ) a _ { t } ] = 0$ . This latter result can also be seen from the fact that $r _ { t - 1 }$ occurred before time $t$ and $a _ { t }$ does not depend on any past information. Taking the square, then the expectation of Eq. (2.10), we obtain

$$
\operatorname {V a r} \left(r _ {t}\right) = \phi_ {1} ^ {2} \operatorname {V a r} \left(r _ {t - 1}\right) + \sigma_ {a} ^ {2},
$$

where $\sigma _ { a } ^ { 2 }$ is the variance of $a _ { t }$ and we make use of the fact that the covariance between $r _ { t - 1 }$ and $a _ { t }$ is zero. Under the stationarity assumption, $\operatorname { V a r } ( r _ { t } ) = \operatorname { V a r } ( r _ { t - 1 } )$ , so that

$$
\operatorname {V a r} \left(r _ {t}\right) = \frac {\sigma_ {a} ^ {2}}{1 - \phi_ {1} ^ {2}}
$$

provided that $\phi _ { 1 } ^ { 2 } < 1$ . The requirement of $\phi _ { 1 } ^ { 2 } < 1$ results from the fact that the variance of a random variable is bounded and non-negative. Consequently, the weak stationarity of an AR(1) model implies that $- 1 < \phi _ { 1 } < 1$ . Yet if $- 1 < \phi _ { 1 } < 1$ , then by Eq. (2.11) and the independence of the $\{ a _ { t } \}$ series, we can show that the mean and variance of $r _ { t }$ are finite; see Eq. (2.5). In addition, by Eq. (2.6), all the autocovariances of $r _ { t }$ are finite. Therefore, the AR(1) model is weakly stationary. In summary, the necessary and sufficient condition for the AR(1) model in Eq. (2.8) to be weakly stationary is $| \phi _ { 1 } | < 1$ .

# Autocorrelation Function of an $A R ( I )$ Model

Multiplying Eq. (2.10) by $a _ { t }$ , using the independence between $a _ { t }$ and $r _ { t - 1 }$ , and taking expectation, we obtain

$$
E [ a _ {t} (r _ {t} - \mu) ] = E [ a _ {t} (r _ {t - 1} - \mu) ] + E (a _ {t} ^ {2}) = E (a _ {t} ^ {2}) = \sigma_ {a} ^ {2},
$$

where $\sigma _ { a } ^ { 2 }$ is the variance of $a _ { t }$ . Multiplying Eq. (2.10) by $( r _ { t - \ell } - \mu )$ , taking expectation, and using the prior result, we have

$$
\gamma_ {\ell} = \left\{ \begin{array}{l l} \phi_ {1} \gamma_ {1} + \sigma_ {a} ^ {2} & \text {i f} \ell = 0, \\ \phi_ {1} \gamma_ {\ell - 1} & \text {i f} \ell > 0, \end{array} \right.
$$

where we use $\gamma _ { \ell } = \gamma _ { - \ell }$ . Consequently, for a weakly stationary AR(1) model in Eq. (2.8), we have

$$
\operatorname {V a r} \left(r _ {t}\right) = \gamma_ {0} = \frac {\sigma^ {2}}{1 - \phi_ {1} ^ {2}}, \quad \text {a n d} \quad \gamma_ {\ell} = \phi_ {1} \gamma_ {\ell - 1}, \quad \text {f o r} \quad \ell > 0.
$$

From the latter equation, the ACF of $r _ { t }$ satisfies

$$
\rho_ {\ell} = \phi_ {1} \rho_ {\ell - 1}, \quad \text {f o r} \quad \ell \geq 0.
$$

![](images/4bb6139fe3aa8901e28018e66382b1e5342360c25ec422a90ea6fe0f220d39d3.jpg)

![](images/b870cfab69f948c1c7c77d923bb7367e79806121667f1decca715114e0dcc65a.jpg)  
Figure 2.3. The autocorrelation function of an AR(1) model: (a) for $\phi _ { 1 } = 0 . 8$ and (b) for $\phi _ { 1 } = - 0 . 8$ .

Because $\rho _ { 0 } = 1$ , we have $\rho _ { \ell } = \phi _ { 1 } ^ { \ell }$ . This result says that the ACF of a weakly stationary AR(1) series decays exponentially with rate $\phi _ { 1 }$ and starting value $\rho _ { 0 } = 1$ . For a positive $\phi _ { 1 }$ , the plot of ACF of an AR(1) model shows a nice exponential decay. For a negative $\phi _ { 1 }$ , the plot consists of two alternating exponential decays with rate $\phi _ { 1 } ^ { 2 }$ . Figure 2.3 shows the ACF of two AR(1) models with $\phi _ { 1 } = 0 . 8$ and $\phi _ { 1 } = - 0 . 8$ .

# AR(2) Model

An AR(2) model assumes the form

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + \phi_ {2} r _ {t - 2} + a _ {t}. \tag {2.12}
$$

Using the same technique as that of the AR(1) case, we obtain

$$
E (r _ {t}) = \mu = \frac {\phi_ {0}}{1 - \phi_ {1} - \phi_ {2}}
$$

provided that $\phi _ { 1 } + \phi _ { 2 } \neq 1$ . Using $\phi _ { 0 } = ( 1 - \phi _ { 1 } - \phi _ { 2 } ) \mu$ , we can rewrite the AR(2) model as

$$
\left(r _ {t} - \mu\right) = \phi_ {1} \left(r _ {t - 1} - \mu\right) + \phi_ {2} \left(r _ {t - 2} - \mu\right) + a _ {t}.
$$

Multiplying the prior equation by $( r _ { t - \ell } - \mu )$ , we have

$$
\begin{array}{l} \left(r _ {t - \ell} - \mu\right) \left(r _ {t} - \mu\right) = \phi_ {1} \left(r _ {t - \ell} - \mu\right) \left(r _ {t - 1} - \mu\right) \\ + \phi_ {2} \left(r _ {t - \ell} - \mu\right) \left(r _ {t - 2} - \mu\right) + \left(r _ {t - \ell} - \mu\right) a _ {t}. \\ \end{array}
$$

Taking expectation and using $E [ ( r _ { t - \ell } - \mu ) a _ { t } ] = 0$ for $\ell > 0$ , we obtain

$$
\gamma_ {\ell} = \phi_ {1} \gamma_ {\ell - 1} + \phi_ {2} \gamma_ {\ell - 2}, \quad \text {f o r} \quad \ell > 0.
$$

This result is referred to as the moment equation of a stationary AR(2) model. Dividing the above equation by $\gamma _ { 0 }$ , we have the property

$$
\rho_ {\ell} = \phi_ {1} \rho_ {\ell - 1} + \phi_ {2} \rho_ {\ell - 2}, \quad \text {f o r} \quad \ell > 0, \tag {2.13}
$$

for the ACF of $r _ { t }$ . In particular, the lag-1 ACF satisfies

$$
\rho_ {1} = \phi_ {1} \rho_ {0} + \phi_ {2} \rho_ {- 1} = \phi_ {1} + \phi_ {2} \rho_ {1}.
$$

Therefore, for a stationary AR(2) series $r _ { t }$ , we have $\rho _ { 0 } = 1$

$$
\begin{array}{l} \rho_ {1} = \frac {\phi_ {1}}{1 - \phi_ {2}}, \\ \rho_ {\ell} = \phi_ {1} \rho_ {\ell - 1} + \phi_ {2} \rho_ {\ell - 2}, \quad \ell \geq 2. \\ \end{array}
$$

The result of Eq. (2.13) says that the ACF of a stationary AR(2) series satisfies the second-order difference equation

$$
(1 - \phi_ {1} B - \phi_ {2} B ^ {2}) \rho_ {\ell} = 0,
$$

where $B$ is called the back-shift operator such that $B \rho _ { \ell } = \rho _ { \ell - 1 }$ . This difference equation determines the properties of the ACF of a stationary AR(2) time series. It also determines the behavior of the forecasts of $r _ { t }$ . In the time series literature, some people use the notation $L$ instead of $B$ for the back-shift operator. Here $L$ stands for lag operator. For instance, $L r _ { t } = r _ { t - 1 }$ and $L \psi _ { k } = \psi _ { k - 1 }$ .

Corresponding to the prior difference equation, there is a second-order polynomial equation

$$
1 - \phi_ {1} x - \phi_ {2} x ^ {2} = 0. \tag {2.14}
$$

Solutions of this equation are

$$
x = \frac {\phi_ {1} \pm \sqrt {\phi_ {1} ^ {2} + 4 \phi_ {2}}}{- 2 \phi_ {2}}.
$$

In the time series literature, inverses of the two solutions are referred to as the characteristic roots of the AR(2) model. Denote the two solutions by $\omega _ { 1 }$ and $\omega _ { 2 }$ . If both $\omega _ { i }$ are real valued, then the second-order difference equation of the model

can be factored as $( 1 - \omega _ { 1 } B ) ( 1 - \omega _ { 2 } B )$ and the AR(2) model can be regarded as an AR(1) model operating on top of another AR(1) model. The ACF of $r _ { t }$ is then a mixture of two exponential decays. If $\phi _ { 1 } ^ { 2 } + 4 \phi _ { 2 } < 0$ , then $\omega _ { 1 }$ and $\omega _ { 2 }$ are complex numbers (called a complex conjugate pair), and a plot of the ACF of $r _ { t }$ would show a picture of damping sine and cosine waves. In business and economic applications, complex characteristic roots are important. They give rise to the behavior of business cycles. It is then common for economic time series models to have complex-valued characteristic roots. For an AR(2) model in Eq. (2.12) with a pair of complex characteristic roots, the average length of the stochastic cycles is

$$
k = \frac {2 \pi}{\cos^ {- 1} [ \phi_ {1} / (2 \sqrt {- \phi_ {2}}) ]},
$$

where the cosine inverse is stated in radians. If one writes the complex solutions as $a \pm b i$ , where $i = \sqrt { - 1 }$ , then we have $\phi _ { 1 } = 2 a$ , $\phi _ { 2 } = - ( a ^ { 2 } + b ^ { 2 } )$ , and

$$
k = \frac {2 \pi}{\cos^ {- 1} (a / \sqrt {a ^ {2} + b ^ {2}})},
$$

where $\sqrt { a ^ { 2 } + b ^ { 2 } }$ is the absolute value of $a \pm b i$ .

Figure 2.4 shows the ACFs of four stationary AR(2) models. Part (b) is the ACF of the AR(2) model $( 1 - 0 . 6 B + 0 . 4 B ^ { 2 } ) r _ { t } = a _ { t }$ . Because $\phi _ { 1 } ^ { 2 } + 4 \phi _ { 2 } = 0 . 3 6 +$

![](images/43dd8c96d72a1d647f94644f6fd28a67b320368f6265968ec8ab5c3edb634b17.jpg)

![](images/8ef8cf9f79d30b9aff6737c7b53a69a83bdf61372209456fd72aa2edb03a755d.jpg)

![](images/e205368a5310f3c9e6e1b54e6c9cdeae586ac59f8632ecd95198f16cbac4c3b7.jpg)

![](images/779b49825561e9959b9aaa2c8bafef57b03ebbd32a7370cd25dc9cb22f33cc2b.jpg)  
Figure 2.4. The autocorrelation function of an AR(2) model: (a) $\phi _ { 1 } = 1 . 2$ and $\phi _ { 2 } = - 0 . 3 5$ , (b) $\phi _ { 1 } =$ 0.6 and $\phi _ { 2 } = - 0 . 4 $ , (c) $\phi _ { 1 } = 0 . 2$ and $\phi _ { 2 } = 0 . 3 5$ , and (d) $\phi _ { 1 } = - 0 . 2$ and $\phi _ { 2 } = 0 . 3 5$ .

$4 \times ( - 0 . 4 ) = - 1 . 2 4 < 0$ , this particular AR(2) model contains two complex characteristic roots, and hence its ACF exhibits damping sine and cosine waves. The other three AR(2) models have real-valued characteristic roots. Their ACFs decay exponentially.

Example 2.1. As an illustration, consider the quarterly growth rate of the U.S. real gross national product (GNP), seasonally adjusted, from the second quarter of 1947 to the first quarter of 1991. This series shown in Figure 2.5 is also used in Chapter 4 as an example of nonlinear economic time series. Here we simply employ an AR(3) model for the data. Denoting the growth rate by $r _ { t }$ , we can use the model building procedure of the next subsection to estimate the model. The fitted model is

$$
r _ {t} = 0. 0 0 4 7 + 0. 3 5 r _ {t - 1} + 0. 1 8 r _ {t - 2} - 0. 1 4 r _ {t - 3} + a _ {t}, \quad \hat {\sigma} _ {a} = 0. 0 0 9 8. \tag {2.15}
$$

Rewriting the model as

$$
r _ {t} - 0. 3 5 r _ {t - 1} - 0. 1 8 r _ {t - 2} + 0. 1 4 r _ {t - 3} = 0. 0 0 4 7 + a _ {t},
$$

we obtain a corresponding third-order difference equation

$$
(1 - 0. 3 5 B - 0. 1 8 B ^ {2} + 0. 1 4 B ^ {3}) = 0,
$$

![](images/4dca14f8be0e93f10cceb43f8cf33744c1ae7bc043940a80b7a591a314a333ae.jpg)  
Figure 2.5. Time plot of the growth rate of U.S. quarterly real GNP from 1947.II to 1991.I. The data are seasonally adjusted and in percentages.

which can be factored as

$$
(1 + 0. 5 2 B) (1 - 0. 8 7 B + 0. 2 7 B ^ {2}) = 0.
$$

The first factor $( 1 + 0 . 5 2 B )$ shows an exponentially decaying feature of the GNP growth rate. Focusing on the second-order factor $1 - 0 . 8 7 B - ( - 0 . 2 7 ) B ^ { 2 } = 0$ , we have $\phi _ { 1 } ^ { 2 } + 4 \phi _ { 2 } = 0 . 8 7 ^ { 2 } + 4 ( - 0 . 2 7 ) = - 0 . 3 2 3 1 < 0$ . Therefore, the second factor of the AR(3) model confirms the existence of stochastic business cycles in the quarterly growth rate of the U.S. real GNP. This is reasonable as the U.S. economy went through expansion and contraction periods. The average length of the stochastic cycles is approximately

$$
k = \frac {2 (3 . 1 4 1 5 9)}{\cos^ {- 1} [ \phi_ {1} / (2 \sqrt {- \phi_ {2}}) ]} = 1 0. 8 3 \mathrm {q u a r t e r s},
$$

which is about 3 years. If one uses a nonlinear model to separate the U.S. economy into “expansion” and “contraction” periods, the data show that the average duration of contraction periods is about three quarters and that of expansion periods is about 3 years; see the analysis in Chapter 4. The average duration of 10.83 quarters is a compromise between the two separate durations. The periodic feature obtained here is common among growth rates of national economies. For example, similar features can be found for many OECD countries.

# Stationarity

The stationarity condition of an AR(2) time series is that the absolute values of its two characteristic roots are less than one or, equivalently, its two characteristic roots are less than one in modulus. Under such a condition, the recursive equation in (2.13) ensures that the ACF of the model converges to zero as the lag  increases. This convergence property is a necessary condition for a stationary time series. In fact, the condition also applies to the AR(1) model where the polynomial equation is $1 - \phi _ { 1 } x = 0$ . The characteristic root is $w = 1 / x = \phi _ { 1 }$ , which must be less than 1 in modulus for $r _ { t }$ to be stationary. As shown before, $\rho _ { \ell } = \phi _ { 1 } ^ { \ell }$ for a stationary AR(1) model. The condition implies that $\rho _ { \ell } \to 0$ as $\ell \to \infty$ .

# $A R ( p )$ Model

The results of AR(1) and AR(2) models can readily be generalized to the general $\operatorname { A R } ( p )$ model in Eq. (2.9). The mean of a stationary series is

$$
E (r _ {t}) = \frac {\phi_ {0}}{1 - \phi_ {1} - \cdots - \phi_ {p}}
$$

provided that the denominator is not zero. The associated polynomial equation of the model is

$$
1 - \phi_ {1} x - \phi_ {2} x ^ {2} - \dots - \phi_ {p} x ^ {p} = 0,
$$

which is referred to as the characteristic equation of the model. If all the solutions of this equation are greater than one in modulus, then the series $r _ { t }$ is stationary. Again, inverses of the solutions are the characteristic roots of the model. Thus, stationarity requires that all characteristic roots are less than 1 in modulus. For a stationary $\operatorname { A R } ( p )$ series, the ACF satisfies the difference equation

$$
(1 - \phi_ {1} B - \phi_ {2} B ^ {2} - \dots - \phi_ {p} B ^ {p}) \rho_ {\ell} = 0, \quad \text {f o r} \quad \ell > 0.
$$

A plot of the ACF of a stationary $\operatorname { A R } ( p )$ model would then show a mixture of damping sine and cosine patterns and exponential decays depending on the nature of its characteristic roots.

# 2.4.2 Identifying AR Models in Practice

In application, the order $p$ of an AR time series is unknown and must be specified empirically. This is referred to as the order determination of AR models, and it has been extensively studied in the time series literature. Two general approaches are available for determining the value of $p$ . The first approach is to use the partial autocorrelation function, and the second approach uses some information criterion function.

# Partial Autocorrelation Function (PACF)

The PACF of a stationary time series is a function of its ACF and is a useful tool for determining the order $p$ of an AR model. A simple, yet effective way to introduce PACF is to consider the following AR models in consecutive orders:

$$
\begin{array}{l} r _ {t} = \phi_ {0, 1} + \phi_ {1, 1} r _ {t - 1} + e _ {1 t}, \\ r _ {t} = \phi_ {0, 2} + \phi_ {1, 2} r _ {t - 1} + \phi_ {2, 2} r _ {t - 2} + e _ {2 t}, \\ r _ {t} = \phi_ {0, 3} + \phi_ {1, 3} r _ {t - 1} + \phi_ {2, 3} r _ {t - 2} + \phi_ {3, 3} r _ {t - 3} + e _ {3 t}, \\ r _ {t} = \phi_ {0, 4} + \phi_ {1, 4} r _ {t - 1} + \phi_ {2, 4} r _ {t - 2} + \phi_ {3, 4} r _ {t - 3} + \phi_ {4, 4} r _ {t - 4} + e _ {4 t}, \\ \begin{array}{c c c} \vdots & \vdots \\ \vdots & \vdots \end{array} \\ \end{array}
$$

where $\phi _ { 0 , j } , \phi _ { i , j }$ , and $\{ \boldsymbol { e } _ { j t } \}$ are, respectively, the constant term, the coefficient of $r _ { t - i }$ , and the error term of an $\operatorname { A R } ( j )$ model. These models are in the form of a multiple linear regression and can be estimated by the least squares method. As a matter of fact, they are arranged in a sequential order that enables us to apply the idea of partial $F$ test in multiple linear regression analysis. The estimate $\bar { \hat { \phi } } _ { 1 , 1 }$ of the first equation is called the lag-1 sample PACF of $r _ { t }$ . The estimate $\hat { \phi } _ { 2 , 2 }$ of the second equation is the lag-2 sample PACF of $r _ { t }$ . The estimate $\hat { \phi } _ { 3 , 3 }$ of the third equation is the lag-3 sample PACF of $r _ { t }$ , and so on.

From the definition, the lag-2 PACF $\hat { \phi } _ { 2 , 2 }$ shows the added contribution of $r _ { t - 2 }$ to $r _ { t }$ over the AR(1) model $r _ { t } = \phi _ { 0 } + \phi _ { 1 } r _ { t - 1 } + e _ { 1 t }$ . The lag-3 PACF shows the added contribution of $r _ { t - 3 }$ to $r _ { t }$ over an AR(2) model, and so on. Therefore, for

Table 2.1. Sample Partial Autocorrelation Function and Akaike Information Criterion for the Monthly Simple Returns of CRSP Value-Weighted Index from January 1926 to December 1997   

<table><tr><td>p</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>PACF</td><td>0.11</td><td>-0.02</td><td>-0.12</td><td>0.04</td><td>0.07</td></tr><tr><td>AIC</td><td>-5.807</td><td>-5.805</td><td>-5.817</td><td>-5.816</td><td>-5.819</td></tr><tr><td>p</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>PACF</td><td>-0.06</td><td>0.02</td><td>0.06</td><td>0.06</td><td>-0.01</td></tr><tr><td>AIC</td><td>-5.821</td><td>-5.819</td><td>-5.820</td><td>-5.821</td><td>-5.818</td></tr></table>

an $\operatorname { A R } ( p )$ model, the lag- $p$ sample PACF should not be zero, but $\hat { \phi } _ { j , j }$ should be close to zero for all $j > p$ . We make use of this property to determine the order $p$ . For a stationary Gaussian $\operatorname { A R } ( p )$ model, it can be shown that the sample PACF has the following properties:

• $\hat { \phi } _ { p , p }$ converges to $\phi _ { p }$ as the sample size $T$ goes to infinity.   
• $\hat { \phi } _ { \ell , \ell }$ converges to zero for all $\ell > p$   
• The asymptotic variance of $\hat { \phi } _ { \ell , \ell }$ is $1 / T$ for $\ell > p$

These results say that, for an $\operatorname { A R } ( p )$ series, the sample PACF cuts off at lag $p$

As an example, consider the monthly simple returns of CRSP value-weighted index from January 1926 to December 1997. Table 2.1 gives the first 10 lags of a sample PACF of the series. With $T = 8 6 4$ , the asymptotic standard error of the sample PACF is approximately 0.03. Therefore, using the $5 \%$ significance level, we identify an AR(3) or AR(5) model for the data (i.e., $p = 3$ or 5).

As another example, Figure 2.6 shows the PACF of the GNP growth rate series of Example 2.1. The two dotted lines of the plot denote the approximate two standard-error limits $\pm ( 2 / \sqrt { 1 7 6 } )$ . The plot suggests an AR(3) model for the data because the first three lags of sample PACF appear to be large.

# Information Criteria

There are several information criteria available to determine the order $p$ of an AR process. All of them are likelihood based. For example, the well-known Akaike information criterion (AIC) (Akaike, 1973) is defined as

$$
\mathrm {A I C} = \frac {- 2}{T} \ln (\text {l i k e l i h o o d}) + \frac {2}{T} \times (\text {n u m b e r o f p a r a m e t e r s}), \tag {2.16}
$$

where the likelihood function is evaluated at the maximum likelihood estimates and $T$ is the sample size. For a Gaussian AR() model, AIC reduces to

$$
\operatorname {A I C} (\ell) = \ln \left(\tilde {\sigma} _ {\ell} ^ {2}\right) + \frac {2 \ell}{T},
$$

![](images/14c1f37a7c1d0d005679cddf452605e56da2173ecb0a5056e2ee0fd9cd26e031.jpg)  
Figure 2.6. Sample partial autocorrelation function of the U.S. quarterly real GNP growth rate from 1947.II to 1991.I. The dotted lines give an approximate pointwise $9 5 \%$ confidence interval.

where $\tilde { \sigma } _ { \ell } ^ { 2 }$ is the maximum likelihood estimate of $\sigma _ { a } ^ { 2 }$ , which is the variance of $a _ { t }$ , and $T$ is the sample size; see Eq. (1.18). The first term of the AIC in Eq. (2.16) measures the goodness of fit of the AR() model to the data whereas the second term is called the penalty function of the criterion because it penalizes a candidate model by the number of parameters used. Different penalty functions result in different information criteria.

Another commonly used criterion function is the (Schwarz) Bayesian information criterion (BIC). For a Gaussian AR() model, the criterion is

$$
\operatorname {B I C} (\ell) = \ln (\tilde {\sigma} _ {\ell} ^ {2}) + \frac {\ell \ln (T)}{T}.
$$

The penalty for each parameter used is 2 for AIC and $\ln ( T )$ for BIC. Thus, BIC tends to select a lower AR model when the sample size is moderate or large.

# Selection Rule

To use AIC to select an AR model in practice, one computes AIC() for $\ell =$ $0 , \ldots , P$ , where $P$ is a prespecified positive integer, and selects the order $k$ that has the minimum AIC value.

Table 2.1 also gives the AIC for $p = 1 , \ldots , 1 0 .$ The AIC values are close to each other with minimum $- 5 . 8 2 1$ occurring at $p = 6$ and 9, suggesting that an AR(6) model is preferred by the criterion. This example shows that different approaches for order determination may result in different choices of $p$ . There is no evidence to suggest that one approach outperforms the other in a real application. Substantive

information of the problem under study and simplicity are two factors that also play an important role in choosing an AR model for a given time series.

Again, consider the growth rate series of the U.S. quarterly real GNP of Example 2.1. The AIC obtained from the Finmetrics module of S-Plus also identifies an AR(3) model. Here the criterion value has been adjusted so that the minimum AIC is zero.

```html
> gnp=scan(file='q-gnp4791.txt')  
> ord=ar(gnp)  
> ord$aic  
[1] 27.569 2.608 1.590 0.000 0.273 2.203  
[7] 4.017 5.992 5.826 7.523 7.822 9.581  
[13] 7.398 8.943 10.912 12.895 14.298 16.279  
[19] 18.100 20.050 22.007 23.436 25.378  
> ord$order  
[1] 3 
```

# Parameter Estimation

For a specified $\operatorname { A R } ( p )$ model in Eq. (2.9), the conditional least squares method, which starts with the $( p + 1 ) \mathrm { t h }$ observation, is often used to estimate the parameters. Specifically, conditioning on the first $p$ observations, we have

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + \dots + \phi_ {p} r _ {t - p} + a _ {t}, \quad t = p + 1, \ldots , T,
$$

which is in the form of a multiple linear regression and can be estimated by the least squares method. Denote the estimate of $\phi _ { i }$ by $\hat { \phi } _ { i }$ . The fitted model is

$$
\hat {r} _ {t} = \hat {\phi} _ {0} + \hat {\phi} _ {1} r _ {t - 1} + \dots + \hat {\phi} _ {p} r _ {t - p}
$$

and the associated residual is

$$
\hat {a} _ {t} = r _ {t} - \hat {r} _ {t}.
$$

The series $\{ \hat { a } _ { t } \}$ is called the residual series, from which we obtain

$$
\hat {\sigma} _ {a} ^ {2} = \frac {\sum_ {t = p + 1} ^ {T} \hat {a} _ {t} ^ {2}}{T - 2 p - 1}.
$$

If the conditional likelihood method is used, the estimates of $\phi _ { i }$ remain unchanged, but the estimate of $\sigma _ { a } ^ { 2 }$ becomes $\tilde { \sigma } _ { a } ^ { 2 } = \hat { \sigma } _ { a } ^ { 2 } \times ( T - 2 p - 1 ) / ( T - p )$ . For illustration, consider an AR(3) model for the monthly simple returns of the value-weighted index in Table 2.1. The fitted model is

$$
r _ {t} = 0. 0 1 0 3 + 0. 1 0 4 r _ {t - 1} - 0. 0 1 0 r _ {t - 2} - 0. 1 2 0 r _ {t - 3} + \hat {a} _ {t}, \quad \hat {\sigma} _ {a} = 0. 0 5 4.
$$

The standard errors of the coefficients are 0.002, 0.034, 0.034, and 0.034, respectively. Except for the lag-2 coefficient, all parameters are statistically significant at the $1 \%$ level.

For this example, the AR coefficients of the fitted model are small, indicating that the serial dependence of the series is weak, even though it is statistically significant at the $1 \%$ level. The significance of $\hat { \phi } _ { 0 }$ of the entertained model implies that the expected mean return of the series is positive. In fact, $\hat { \mu } = 0 . 0 1 0 3 / ( 1 - 0 . 1 0 4 +$ $0 . 0 1 0 + 0 . 1 2 0 ) = 0 . 0 1$ , which is small, but has an important long-term implication. It implies that the long-term return of the index can be substantial. Using the multiperiod simple return defined in Chapter 1, the average annual simple gross return is $\begin{array} { r } { \big [ \prod _ { t = 1 } ^ { 8 6 4 } \mathsf { \bar { ( } 1 + } R _ { t } ) \big ] ^ { 1 2 / 8 6 4 } - 1 \approx 0 . 1 \mathsf { \bar { 0 } } 5 3 . } \end{array}$ . In other words, the monthly simple returns of the CRSP value-weighted index grew about $1 0 . 5 3 \%$ per annum from 1926 to 1997, supporting the common belief that equity market performs well in the long term. A $\$ 1$ investment at the beginning of 1926 would be worth about $\$ 1350$ at the end of 1997.

# Model Checking

A fitted model must be examined carefully to check for possible model inadequacy. If the model is adequate, then the residual series should behave as a white noise. The ACF and the Ljung–Box statistics in Eq. (2.3) of the residuals can be used to check the closeness of $\hat { a } _ { t }$ to a white noise. For an $\operatorname { A R } ( p )$ model, the Ljung–Box statistic $Q ( m )$ follows asymptotically a chi-squared distribution with $m - g$ degrees of freedom, where $g$ denotes the number of AR coefficients used in the model. The adjustment in the degrees of freedom is made based on the number of constraints added to the residuals $\hat { a } _ { t }$ from fitting an $\operatorname { A R } ( p )$ to an AR(0) model. If a fitted model is found to be inadequate, it must be refined. For instance, if some of the estimated AR coefficients are not significantly different from zero, then the model should be simplified by trying to remove those insignificant parameters. If residual ACF shows additional serial correlations, then the model should be extended to take care of the those correlations.

Consider the residual series of the fitted AR(3) model for the monthly valueweighted simple returns. We have $Q ( 1 2 ) = 1 6 . 9 $ with $p$ -value 0.050 based on its asymptotic chi-squared distribution with 9 degrees of freedom. Thus, the null hypothesis of no residual serial correlation in the first 12 lags is barely not rejected at the $5 \%$ level. However, since the lag-2 AR coefficient is not significant at the $5 \%$ level, one can refine the model as

$$
r _ {t} = 0. 0 1 0 2 + 0. 1 0 3 r _ {t - 1} - 0. 1 2 2 r _ {t - 3} + a _ {t}, \quad \hat {\sigma} _ {a} = 0. 0 5 4 2,
$$

where all the estimates are significant at the $5 \%$ level. The residual series gives $Q ( 1 2 ) = 1 7 . 2 $ with $p$ -value 0.070 (based on $\chi _ { 1 0 } ^ { 2 } ,$ ). The model is adequate in modeling the dynamic linear dependence of data.

# SCA Demonstration

Output edited.

input vw. file ’m-vw2697.txt’

tsm m1. model (1,2,3)vw=c+noise. % Model specification

```txt
-- estim m1. hold resi(r1). 
```

SUMMARY FOR UNIVARIATE TIME SERIES MODEL -- M1  
```txt
VARIABLE TYPE OF ORIGINAL DIFFERENCING  
VAR VARIABLE OR CENTERED  
VW RANDOM ORIGINAL NONE  
PAR. VAR. NUM./ FACTOR ORDER CONS- VALUE STD T  
LABEL NAME DENOM. TRAINE ERROR VALUE  
1 C CNST 1 0 NONE .0103 .0019 5.34  
2 VW AR 1 1 NONE .1041 .0338 3.08  
3 VW AR 1 2 NONE -.0103 .0340 -.30  
4 VW AR 1 3 NONE -.1204 .0338 -3.56  
EFFECTIVE NUMBER OF OBSERVATIONS . 861  
R-SQUARE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
RESIDUAL STANDARD ERROR. .. .. .. .. .. 0.541903E-01  
--  
acf r1. maxl 12.  
NAME OF THE SERIES .. .. .. .. .. .. R1  
TIME PERIOD ANALYZED .. .. .. .. 4 TO 864  
MEAN OF THE (DIFFERENCED) SERIES .. .. .. 0.0000  
STANDARD DEVIATION OF THE SERIES .. .. .. 0.0542  
T-VALUE OF MEAN (AGAINST ZERO) .. .. .. 0.0000 
```

AUTOCORRELATIONS   
```lua
1- 12 .01 .01 -.01 .03 .09 -.05 .01 .04 .08 -.00 -.03 .01  
ST.E. .03 .03 .03 .03 .03 .03 .03 .03 .03 .03 Q .0 .1 .2 1.0 7.4 9.3 9.3 10.6 15.8 15.8 16.8 16.9  
--  
p=1-cdfc(16.9,9) % Compute p value.  
--  
print p  
.050 
```

# S-Plus Demonstration

Output edited and $>$ is the prompt character.

```txt
> vw=scan(file='m-vw2697.txt')
> ar3=OLS(vw~ar(3))
> summary(ar3) 
```

Call: OLS(formula $=$ vw \~ ar(3))

```txt
Residuals: Min 1Q Median 3Q Max -0.2845 -0.0259 0.0025 0.0288 0.3705 
```

Coefficients: Value Std. Error t value $\Pr (>|t|)$ (Intercept) 0.0103 0.0019 5.3314 0.0000 lag1 0.1041 0.0339 3.0716 0.0022 lag2 -0.0103 0.0341 -0.3016 0.7630 lag3 -0.1204 0.0339 -3.5538 0.0004

```txt
Regression Diagnostics: R-Squared 0.0258 Adjusted R-Squared 0.0224 Durbin-Watson Stat 1.9890 
```

```javascript
> autocorTest(ar3\$residuals,lag=12) 
```

```txt
Test for Autocorrelation: Ljung-Box 
```

```txt
Null Hypothesis: no autocorrelation 
```

```txt
Test Statistics: 
```

```txt
Test Stat 16.9367 p.value 0.1520 % S-Plus uses 12 degrees of freedom. > 1-pchisq(16.9367,9) % Calculate p-value using 9 df. [1] 0.04971652 
```

# 2.4.3 Goodness of Fit

A commonly used statistic to measure goodness of fit of a stationary model is the R-square $( R ^ { 2 } )$ defined as

$$
R ^ {2} = 1 - \frac {\text {R e s i d u a l s u m o f s q u a r e s}}{\text {T o t a l s u m o f s q u a r e s}}.
$$

For a stationary $\operatorname { A R } ( p )$ time series model with $T$ observations $\{ r _ { t } | t = 1 , \ldots , T \}$ , the measure becomes

$$
R ^ {2} = 1 - \frac {\sum_ {t = p + 1} ^ {T} \hat {a} _ {t} ^ {2}}{\sum_ {t = p + 1} ^ {T} (r _ {t} - \overline {{r}}) ^ {2}},
$$

where $\begin{array} { r } { \overline { { r } } = \big ( \sum _ { t = p + 1 } ^ { T } r _ { t } \big ) / ( T - p ) } \end{array}$ . It is easy to show that $0 \leq R ^ { 2 } \leq 1$ . Typically, a larger $R ^ { 2 }$ indicates that the model provides a closer fit to the data. However, this is only true for a stationary time series. For the unit-root nonstationary series

discussed later in this chapter, $R ^ { 2 }$ of an AR(1) fit converges to one when the sample size increases to infinity, regardless of the true underlying model of $r _ { t }$ .

For a given data set, it is well-known that $R ^ { 2 }$ is a nondecreasing function of the number of parameters used. To overcome this weakness, an adjusted $R ^ { 2 }$ is proposed, which is defined as

$$
\begin{array}{l} \operatorname {A d j} - R ^ {2} = 1 - \frac {\text {V a r i a n c e o f r e s i d u a l s}}{\text {V a r i a n c e o f} r _ {t}} \\ = 1 - \frac {\hat {\sigma} _ {a} ^ {2}}{\hat {\sigma} _ {r} ^ {2}}, \\ \end{array}
$$

where $\hat { \sigma } _ { r } ^ { 2 }$ is the sample variance of $r _ { t }$ . This new measure takes into account the number of parameters used in the fitted model. However, it is no longer between 0 and 1.

# 2.4.4 Forecasting

Forecasting is an important application of time series analysis. For the $\operatorname { A R } ( p )$ model in Eq. (2.9), suppose that we are at the time index $h$ and interested in forecasting $r _ { h + \ell }$ , where $\ell \geq 1$ . The time index $h$ is called the forecast origin and the positive integer $\ell$ is the forecast horizon. Let $\hat { r } _ { h } ( \ell )$ be the forecast of $r _ { h + \ell }$ using the minimum squared error loss function and $F _ { h }$ be the collection of information available at the forecast origin $h$ . Then, the forecast $\hat { r } _ { k } ( \ell )$ is chosen such that

$$
E \left\{\left[ r _ {h + \ell} - \hat {r} _ {h} (\ell) \right] ^ {2} \mid F _ {h} \right\} \leq \min  _ {g} E \left[ \left(r _ {h + \ell} - g\right) ^ {2} \mid F _ {h} \right],
$$

where $g$ is a function of the information available at time $h$ (inclusive), that is, a function of $F _ { h }$ . We referred to $\hat { r } _ { h } ( \ell )$ as the $\ell$ -step ahead forecast of $r _ { t }$ at the forecast origin $h$ .

# 1-Step Ahead Forecast

From the $\operatorname { A R } ( p )$ model, we have

$$
r _ {h + 1} = \phi_ {0} + \phi_ {1} r _ {h} + \dots + \phi_ {p} r _ {h + 1 - p} + a _ {h + 1}.
$$

Under the minimum squared error loss function, the point forecast of $r _ { h + 1 }$ given $F _ { h } = \{ r _ { h } , r _ { h - 1 } , . . . \}$ is the conditional expectation

$$
\hat {r} _ {h} (1) = E \left(r _ {h + 1} \mid F _ {h}\right) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {h + 1 - i},
$$

and the associated forecast error is

$$
e _ {h} (1) = r _ {h + 1} - \hat {r} _ {h} (1) = a _ {h + 1}.
$$

Consequently, the variance of the 1-step ahead forecast error is $\mathrm { V a r } [ e _ { h } ( 1 ) ] =$ $\mathrm { V a r } ( a _ { h + 1 } ) = \sigma _ { a } ^ { 2 }$ . If $a _ { t }$ is normally distributed, then a $9 5 \%$ 1-step ahead interval forecast of $r _ { h + 1 }$ is $\hat { r } _ { h } ( 1 ) \pm 1 . 9 6 \times \sigma _ { a }$ . For the linear model in Eq. (2.4), $a _ { t + 1 }$ is also the 1-step ahead forecast error at the forecast origin t . In the econometric literature, $a _ { t + 1 }$ is referred to as the shock to the series at time $t + 1$ .

In practice, estimated parameters are often used to compute point and interval forecasts. This results in a conditional forecast because such a forecast does not take into consideration the uncertainty in the parameter estimates. In theory, one can consider parameter uncertainty in forecasting, but it is much more involved. When the sample size used in estimation is sufficiently large, then the conditional forecast is close to the unconditional one.

# 2-Step Ahead Forecast

Next, consider the forecast of $r _ { h + 2 }$ at the forecast origin $h$ . From the $\operatorname { A R } ( p )$ model, we have

$$
r _ {h + 2} = \phi_ {0} + \phi_ {1} r _ {h + 1} + \dots + \phi_ {p} r _ {h + 2 - p} + a _ {h + 2}.
$$

Taking conditional expectation, we have

$$
\hat {r} _ {h} (2) = E \left(r _ {h + 2} \mid F _ {h}\right) = \phi_ {0} + \phi_ {1} \hat {r} _ {h} (1) + \phi_ {2} r _ {h} + \dots + \phi_ {p} r _ {h + 2 - p}
$$

and the associated forecast error

$$
e _ {h} (2) = r _ {h + 2} - \hat {r} _ {h} (2) = \phi_ {1} [ r _ {h + 1} - \hat {r} _ {h} (1) ] + a _ {h + 2} = a _ {h + 2} + \phi_ {1} a _ {h + 1}.
$$

The variance of the forecast error is $\mathrm { V a r } [ e _ { h } ( 2 ) ] = ( 1 + \phi _ { 1 } ^ { 2 } ) \sigma _ { a } ^ { 2 }$ . Interval forecasts of $r _ { h + 2 }$ can be computed in the same way as those for $r _ { h + 1 }$ . It is interesting to see that $\mathrm { V a r } [ e _ { h } ( 2 ) ] \geq \mathrm { V a r } [ e _ { h } ( 1 ) ]$ , meaning that as the forecast horizon increases the uncertainty in forecast also increases. This is in agreement with common sense that we are more uncertain about $r _ { h + 2 }$ than $r _ { h + 1 }$ at the time index $h$ for a linear time series.

# Multistep Ahead Forecast

In general, we have

$$
r _ {h + \ell} = \phi_ {0} + \phi_ {1} r _ {h + \ell - 1} + \dots + \phi_ {p} r _ {h + \ell - p} + a _ {h + \ell}.
$$

The -step ahead forecast based on the minimum squared error loss function is the conditional expectation of $r _ { h + \ell }$ given $F _ { h }$ , which can be obtained as

$$
\hat {r} _ {h} (\ell) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} \hat {r} _ {h} (\ell - i),
$$

where it is understood that $\hat { r } _ { h } ( i ) = r _ { h + i }$ if $i \le 0$ . This forecast can be computed recursively using forecasts $\hat { r } _ { h } ( i )$ for $i = 1 , \ldots , \ell - 1$ . The -step ahead forecast

Table 2.2. Multistep Ahead Forecasts of an AR(3) Model for the Monthly Simple Returns of CRSP Value-Weighted Index with Forecast Origin of 858   

<table><tr><td>Step</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>Forecast</td><td>0.0088</td><td>0.0020</td><td>0.0050</td><td>0.0097</td><td>0.0109</td><td>0.0106</td></tr><tr><td>Standard error</td><td>0.0542</td><td>0.0546</td><td>0.0546</td><td>0.0550</td><td>0.0550</td><td>0.0550</td></tr><tr><td>Actual</td><td>0.0762</td><td>-0.0365</td><td>0.0580</td><td>-0.0341</td><td>0.0311</td><td>0.0183</td></tr></table>

error is $e _ { h } ( \ell ) = r _ { h + \ell } - \hat { r } _ { h } ( \ell )$ . It can be shown that for a stationary $\operatorname { A R } ( p )$ model, $\hat { r } _ { h } ( \ell )$ converges to $E ( r _ { t } )$ as $\ell \to \infty$ , meaning that for such a series long-term point forecast approaches its unconditional mean. This property is referred to as the mean reversion in the finance literature. For an AR(1) model, the speed of mean reversion is measured by the half-life defined as $k = \ln ( 0 . 5 / | \phi _ { 1 } | )$ . The variance of the forecast error then approaches the unconditional variance of $r _ { t }$ .

Table 2.2 contains the 1-step to 6-step ahead forecasts and the standard errors of the associated forecast errors at the forecast origin 858 for the monthly simple return of the value-weighted index using an AR(3) model that was reestimated using the first 858 observations. The actual returns are also given. Because of the weak serial dependence in the series, the forecasts and standard deviations of

![](images/257c92b6cbeb8b46c7a742d4b3490ce8a46b234cb4e093fb6257ee189440a7e9.jpg)  
Figure 2.7. Plot of 1-step to 6-step ahead out-of-sample forecasts for the monthly log returns of the CRSP value-weighted index. The forecast origin is $t = 8 5 8$ . The forecasts are denoted by $\bigcirc$ and the actual observations by black dots. The two dashed lines denote two standard-error limits of the forecasts.

forecast errors converge to the sample mean and standard deviation of the data quickly. For the first 858 observations, the sample mean and standard error are 0.0098 and 0.0550, respectively.

Figure 2.7 shows the 1-step to 6-step ahead out-of-sample forecasts and their two standard-error limits for the monthly log returns of value-weighted index. These forecasts are produced by the following AR(5) model:

$$
r _ {t} = 0. 0 0 7 5 + 0. 1 0 3 r _ {t - 1} + 0. 0 0 2 r _ {t - 2} - 0. 1 1 4 r _ {t - 3} + 0. 0 3 2 r _ {t - 4} + 0. 0 8 4 r _ {t - 5} + a _ {t},
$$

where $\hat { \sigma } _ { a } = 0 . 0 5 4$ , which was built based on the procedure discussed earlier. For this particular series, the forecasts are close to the actual values that are all within the $9 5 \%$ interval forecasts.

# 2.5 SIMPLE MOVING-AVERAGE MODELS

We now turn to another class of simple models that are also useful in modeling return series in finance. These models are called moving-average (MA) models. There are several ways to introduce MA models. One approach is to treat the model as a simple extension of white noise series. Another approach is to treat the model as an infinite-order AR model with some parameter constraints. We adopt the second approach. As shown in Chapter 5, the bid–ask bounce in stock trading may introduce an MA(1) structure in a return series.

There is no particular reason, but simplicity, to assume a priori that the order of an AR model is finite. We may entertain, at least in theory, an AR model with infinite order as

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + \phi_ {2} r _ {t - 2} + \dots + a _ {t}.
$$

However, such an AR model is not realistic because it has infinite many parameters. One way to make the model practical is to assume that the coefficients $\phi _ { i }$ satisfy some constraints so that they are determined by a finite number of parameters. A special case of this idea is

$$
r _ {t} = \phi_ {0} - \theta_ {1} r _ {t - 1} - \theta_ {1} ^ {2} r _ {t - 2} - \theta_ {1} ^ {3} r _ {t - 3} - \dots + a _ {t}, \tag {2.17}
$$

where the coefficients depend on a single parameter $\theta _ { 1 }$ via $\phi _ { i } = - \theta _ { 1 } ^ { i }$ for $i \geq 1$ . For the model in Eq. (2.17) to be stationary, $\theta _ { 1 }$ must be less than one in absolute value; otherwise, $\theta _ { 1 } ^ { i }$ and the series will explode. Because $| \theta _ { 1 } | < 1$ , we have $\theta _ { 1 } ^ { i }  0$ as $i  \infty$ . Thus, the contribution of $r _ { t - i }$ to $r _ { t }$ decays exponentially as $i$ increases. This is reasonable as the dependence of a stationary series $r _ { t }$ on its lagged value $r _ { t - i }$ , if any, should decay over time.

The model in Eq. (2.17) can be rewritten in a rather compact form. To see this, rewrite the model as

$$
r _ {t} + \theta_ {1} r _ {t - 1} + \theta_ {1} ^ {2} r _ {t - 2} + \dots = \phi_ {0} + a _ {t}. \tag {2.18}
$$

The model for $r _ { t - 1 }$ is then

$$
r _ {t - 1} + \theta_ {1} r _ {t - 2} + \theta_ {1} ^ {2} r _ {t - 3} + \dots = \phi_ {0} + a _ {t - 1}. \tag {2.19}
$$

Multiplying Eq. (2.19) by $\theta _ { 1 }$ and subtracting the result from Eq. (2.18), we obtain

$$
r _ {t} = \phi_ {0} (1 - \theta_ {1}) + a _ {t} - \theta_ {1} a _ {t - 1},
$$

which says that, except for the constant term, $r _ { t }$ is a weighted average of shocks $a _ { t }$ and $a _ { t - 1 }$ . Therefore, the model is called an MA model of order 1 or MA(1) model for short. The general form of an MA(1) model is

$$
r _ {t} = c _ {0} + a _ {t} - \theta_ {1} a _ {t - 1}, \quad \text {o r} \quad r _ {t} = c _ {0} + (1 - \theta_ {1} B) a _ {t}, \tag {2.20}
$$

where $c _ { 0 }$ is a constant and $\{ a _ { t } \}$ is a white noise series. Similarly, an MA(2) model is in the form

$$
r _ {t} = c _ {0} + a _ {t} - \theta_ {1} a _ {t - 1} - \theta_ {2} a _ {t - 2}, \tag {2.21}
$$

and an $\mathrm { M A } ( q )$ model is

$$
r _ {t} = c _ {0} + a _ {t} - \theta_ {1} a _ {t - 1} - \dots - \theta_ {q} a _ {t - q}, \tag {2.22}
$$

or $r _ { t } = c _ { 0 } + ( 1 - \theta _ { 1 } B - \cdot \cdot \cdot - \theta _ { q } B ^ { q } ) a _ { t }$ , where $q > 0$ .

# 2.5.1 Properties of MA Models

Again, we focus on the simple MA(1) and MA(2) models. The results of $\mathrm { M A } ( q )$ models can easily be obtained by the same techniques.

# Stationarity

MA models are always weakly stationary because they are finite linear combinations of a white noise sequence for which the first two moments are time-invariant. For example, consider the MA(1) model in Eq. (2.20). Taking expectation of the model, we have

$$
E \left(r _ {t}\right) = c _ {0},
$$

which is time-invariant. Taking the variance of Eq. (2.20), we have

$$
\operatorname {V a r} \left(r _ {t}\right) = \sigma_ {a} ^ {2} + \theta_ {1} ^ {2} \sigma_ {a} ^ {2} = \left(1 + \theta_ {1} ^ {2}\right) \sigma_ {a} ^ {2},
$$

where we use the fact that $a _ { t }$ and $a _ { t - 1 }$ are uncorrelated. Again, $\mathrm { V a r } ( r _ { t } )$ is timeinvariant. The prior discussion applies to general $\mathrm { M A } ( q )$ models, and we obtain two general properties. First, the constant term of an MA model is the mean of the series (i.e., $E ( r _ { t } ) = c _ { 0 }$ ). Second, the variance of an $\mathrm { M A } ( q )$ model is

$$
\operatorname {V a r} \left(r _ {t}\right) = \left(1 + \theta_ {1} ^ {2} + \theta_ {2} ^ {2} + \dots + \theta_ {q} ^ {2}\right) \sigma_ {a} ^ {2}.
$$

# Autocorrelation Function

Assume for simplicity that $c _ { 0 } = 0$ for an MA(1) model. Multiplying the model by $r _ { t - \ell }$ , we have

$$
r _ {t - \ell} r _ {t} = r _ {t - \ell} a _ {t} - \theta_ {1} r _ {t - \ell} a _ {t - 1}.
$$

Taking expectation, we obtain

$$
\gamma_ {1} = - \theta_ {1} \sigma_ {a} ^ {2}, \quad \text {a n d} \quad \gamma_ {\ell} = 0, \quad \text {f o r} \quad \ell > 1.
$$

Using the prior result and the fact that $\mathrm { V a r } ( r _ { t } ) = ( 1 + \theta _ { 1 } ^ { 2 } ) \sigma _ { a } ^ { 2 }$ , we have

$$
\rho_ {0} = 1, \quad \rho_ {1} = \frac {- \theta_ {1}}{1 + \theta_ {1} ^ {2}}, \quad \rho_ {\ell} = 0, \quad \text {f o r} \quad \ell > 1.
$$

Thus, for an MA(1) model, the lag-1 ACF is not zero, but all higher order ACFs are zero. In other words, the ACF of an MA(1) model cuts off at lag 1. For the MA(2) model in Eq. (2.21), the autocorrelation coefficients are

$$
\rho_ {1} = \frac {- \theta_ {1} + \theta_ {1} \theta_ {2}}{1 + \theta_ {1} ^ {2} + \theta_ {2} ^ {2}}, \quad \rho_ {2} = \frac {- \theta_ {2}}{1 + \theta_ {1} ^ {2} + \theta_ {2} ^ {2}}, \quad \rho_ {\ell} = 0, \quad \text {f o r} \quad \ell > 2.
$$

Here the ACF cuts off at lag 2. This property generalizes to other MA models. For an $\mathrm { M A } ( q )$ model, the lag- $q$ ACF is not zero, but $\rho _ { \ell } = 0$ for $\ell > q$ . Consequently, an $\mathrm { M A } ( q )$ series is only linearly related to its first $q$ lagged values and hence is a “finite-memory” model.

# Invertibility

Rewriting a zero-mean MA(1) model as $a _ { t } = r _ { t } + \theta _ { 1 } a _ { t - 1 }$ , one can use repeated substitutions to obtain

$$
a _ {t} = r _ {t} + \theta_ {1} r _ {t - 1} + \theta_ {1} ^ {2} r _ {t - 2} + \theta_ {1} ^ {3} r _ {t - 3} + \dots .
$$

This equation expresses the current shock $a _ { t }$ as a linear combination of the present and past returns. Intuitively, $\theta _ { 1 } ^ { j }$ should go to zero as $j$ increases because the remote return $r _ { t - j }$ should have very little impact on the current shock, if any. Consequently, for an MA(1) model to be plausible, we require $| \theta _ { 1 } | < 1$ . Such an MA(1) model is said to be invertible. If $| \theta _ { 1 } | = 1$ , then the MA(1) model is noninvertible. See Section 2.6.5 for further discussion on invertibility.

# 2.5.2 Identifying MA Order

The ACF is useful in identifying the order of an MA model. For a time series $r _ { t }$ with ACF $\rho _ { \ell }$ , if $\rho _ { q } \neq 0$ , but $\rho _ { \ell } = 0$ for $\ell > q$ , then $r _ { t }$ follows an $\mathrm { M A } ( q )$ model.

Figure 2.8 shows the time plot of monthly simple returns of the CRSP equalweighted index from January 1926 to December 2003 and the sample ACF of the series. The two dashed lines shown on the ACF plot denote the two standard-error limits. It is seen that the series has significant ACF at lags 1, 3, and 9. There are

![](images/2fd18156915f195a1f7f51970583d0d07bc2c6847b801a73998eb389cebb19a4.jpg)  
(a) Monthly simple returns

![](images/ee31499a4bf711c180e3b94038bab411ab896cd6234bbea7bac4e2fbf80fced1.jpg)  
(b) Sample ACF   
Figure 2.8. Time plot and sample autocorrelation function of the monthly simple returns of the CRSP equal-weighted index from January 1926 to December 2003.

some marginally significant ACFs at higher lags, but we do not consider them here. Based on the sample ACF, the following MA(9) model

$$
r _ {t} = c _ {0} + a _ {t} - \theta_ {1} a _ {t - 1} - \theta_ {3} a _ {t - 3} - \theta_ {9} a _ {t - 9}
$$

is identified for the series. Note that, unlike the sample PACF, the sample ACF provides information on the nonzero MA lags of the model.

# 2.5.3 Estimation

Maximum likelihood estimation is commonly used to estimate MA models. There are two approaches for evaluating the likelihood function of an MA model. The first approach assumes that the initial shocks (i.e., $a _ { t }$ for $t \leq 0$ ) are zero. As such, the shocks needed in likelihood function calculation are obtained recursively from the model, starting with $a _ { 1 } = r _ { 1 } - c _ { 0 }$ and $a _ { 2 } = r _ { 2 } - c _ { 0 } + \theta _ { 1 } a _ { 1 }$ . This approach is referred to as the conditional likelihood method and the resulting estimates are the conditional maximum likelihood estimates. The second approach treats the initial shocks $a _ { t } , t \leq 0$ , as additional parameters of the model and estimates them jointly with other parameters. This approach is referred to as the exact likelihood method. The exact likelihood estimates are preferred over the conditional ones, especially

when the MA model is close to being noninvertible. The exact method, however, requires more intensive computation. If the sample size is large, then the two types of maximum likelihood estimates are close to each other. For details of conditional and exact likelihood estimates of MA models, readers are referred to Box, Jenkins, and Reinsel (1994) or Chapter 8.

For illustration, consider the monthly simple return series of the CRSP equalweighted index and the specified MA(9) model. The conditional maximum likelihood method produces the fitted model

$$
r _ {t} = 0. 0 1 3 + a _ {t} + 0. 1 8 1 a _ {t - 1} - 0. 1 2 1 a _ {t - 3} + 0. 1 2 2 a _ {t - 9}, \quad \hat {\sigma} _ {a} = 0. 0 7 2 4, \tag {2.23}
$$

where standard errors of the coefficient estimates are 0.003, 0.032, 0.032, and 0.032, respectively. The Ljung–Box statistics of the residuals give $Q ( 1 2 ) = 1 5 . 0 $ with $p$ -value 0.091, which is based on an asymptotic chi-squared distribution with 9 degrees of freedom. The model appears to be adequate in modeling the linear dynamic dependence of the data. The exact maximum likelihood method produces the fitted model

$$
r _ {t} = 0. 0 1 3 + a _ {t} + 0. 1 8 3 a _ {t - 1} - 0. 1 2 0 a _ {t - 3} + 0. 1 2 3 a _ {t - 9}, \quad \hat {\sigma} _ {a} = 0. 0 7 2 4, \tag {2.24}
$$

where standard errors of the estimates are 0.003, 0.032, 0.032, and 0.032, respectively. The Ljung–Box statistics of the residuals give $Q ( 1 2 ) = 1 5 . 2 $ with $p$ -value 0.086. This fitted model is also adequate. Comparing models (2.23) and (2.24), we see that, for this particular instance, the difference between the conditional and exact likelihood methods is negligible.

# 2.5.4 Forecasting Using MA Models

Forecasts of an MA model can easily be obtained. Because the model has finite memory, its point forecasts go to the mean of the series quickly. To see this, assume that the forecast origin is $h$ and let $F _ { h }$ denote the information available at time $h$ . For the 1-step ahead forecast of an MA(1) process, the model says

$$
r _ {h + 1} = c _ {0} + a _ {h + 1} - \theta_ {1} a _ {h}.
$$

Taking the conditional expectation, we have

$$
\hat {r} _ {h} (1) = E (r _ {h + 1} | F _ {h}) = c _ {0} - \theta_ {1} a _ {h},
$$

$$
e _ {h} (1) = r _ {h + 1} - \hat {r} _ {h} (1) = a _ {h + 1}.
$$

The variance of the 1-step ahead forecast error is $\mathrm { V a r } [ e _ { h } ( 1 ) ] = \sigma _ { a } ^ { 2 }$ . In practice, the quantity $a _ { h }$ can be obtained in several ways. For instance, assume that $a _ { 0 } = 0$ , then $a _ { 1 } = r _ { 1 } - c _ { 0 }$ , and we can compute $a _ { t }$ for $2 \leq t \leq h$ recursively by using $a _ { t } =$ $r _ { t } - c _ { 0 } + \theta _ { 1 } a _ { t - 1 }$ . Alternatively, it can be computed by using the AR representation of the MA(1) model; see Section 2.6.5.

For the 2-step ahead forecast, from the equation

$$
r _ {h + 2} = c _ {0} + a _ {h + 2} - \theta_ {1} a _ {h + 1},
$$

we have

$$
\hat {r} _ {h} (2) = E (r _ {h + 2} | F _ {h}) = c _ {0},
$$

$$
e _ {h} (2) = r _ {h + 2} - \hat {r} _ {h} (2) = a _ {h + 2} - \theta_ {1} a _ {h + 1}.
$$

The variance of the forecast error is $\mathrm { V a r } [ e _ { h } ( 2 ) ] = ( 1 + \theta _ { 1 } ^ { 2 } ) \sigma _ { a } ^ { 2 }$ , which is the variance of the model and is greater than or equal to that of the 1-step ahead forecast error. The prior result shows that for an MA(1) model the 2-step ahead forecast of the series is simply the unconditional mean of the model. This is true for any forecast origin $h$ . More generally, $\hat { r } _ { h } ( \ell ) = c _ { 0 }$ for $\ell \geq 2$ . In summary, for an MA(1) model, the 1-step ahead point forecast at the forecast origin $h$ is $c _ { 0 } - \theta _ { 1 } a _ { h }$ and the multistep ahead forecasts are $c _ { 0 }$ , which is the unconditional mean of the model. If we plot the forecasts $\hat { r } _ { h } ( \ell )$ versus $\ell$ , we see that the forecasts form a horizontal line after one step. Thus, for MA(1) models, mean-reverting only takes 1 time period.

Similarly, for an MA(2) model, we have

$$
r _ {h + \ell} = c _ {0} + a _ {h + \ell} - \theta_ {1} a _ {h + \ell - 1} - \theta_ {2} a _ {h + \ell - 2},
$$

from which we obtain

$$
\hat {r} _ {h} (1) = c _ {0} - \theta_ {1} a _ {h} - \theta_ {2} a _ {h - 1},
$$

$$
\hat {r} _ {h} (2) = c _ {0} - \theta_ {2} a _ {h},
$$

$$
\hat {r} _ {h} (\ell) = c _ {0}, \quad \text {f o r} \quad \ell > 2.
$$

Thus, the multistep ahead forecasts of an MA(2) model go to the mean of the series after two steps. The variances of forecast errors go to the variance of the series after two steps. In general, for an MA(q) model, multistep ahead forecasts go to the mean after the first $q$ steps.

Table 2.3 gives some forecasts of the MA(9) model in Eq. (2.23) for the monthly simple returns of the equal-weighted index at the forecast origin $h = 9 2 6$ (February 2003). The sample mean and standard error of the first 926 observations of the series are 0.0126 and 0.0751, respectively. As expected, the table shows that (a) the 10-step ahead forecast is the sample mean, and (b) the standard deviations of the forecast errors converge to the standard deviation of the series as the forecast horizon increases.

# Summary

A brief summary of AR and MA models is in order. We have discussed the following properties:

• For MA models, the ACF is useful in specifying the order because the ACF cuts off at lag $q$ for an $\mathrm { M A } ( q )$ series.

Table 2.3. Forecast Performance of a MA(9) Model for the Monthly Simple Returns of the CRSP Equal-Weighted Indexa   

<table><tr><td>Step</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>Forecast</td><td>0.0140</td><td>-0.0050</td><td>0.0158</td><td>-0.0008</td><td>0.0171</td></tr><tr><td>Standard error</td><td>0.0726</td><td>0.0737</td><td>0.0737</td><td>0.0743</td><td>0.0743</td></tr><tr><td>Actual</td><td>0.0097</td><td>0.0983</td><td>0.1330</td><td>0.0496</td><td>0.0617</td></tr><tr><td>Step</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>Forecast</td><td>0.0257</td><td>0.0009</td><td>0.0149</td><td>0.0099</td><td>0.0126</td></tr><tr><td>Standard error</td><td>0.0743</td><td>0.0743</td><td>0.0743</td><td>0.0743</td><td>0.0748</td></tr><tr><td>Actual</td><td>0.0475</td><td>0.0252</td><td>0.0810</td><td>0.0381</td><td>0.0391</td></tr></table>

a The forecast origin is February 2003 with $h = 9 2 6$ . The model is estimated by the conditional maximum likelihood method.

• For AR models, the PACF is useful in order determination because the PACF cuts off at lag $p$ for an $\operatorname { A R } ( p )$ process.   
• An MA series is always stationary, but for an AR series to be stationary, all of its characteristic roots must be less than 1 in modulus.   
• For a stationary series, the multistep ahead forecasts converge to the mean of the series and the variances of forecast errors converge to the variance of the series.

# 2.6 SIMPLE ARMA MODELS

In some applications, the AR or MA models discussed in the previous sections become cumbersome because one may need a high-order model with many parameters to adequately describe the dynamic structure of the data. To overcome this difficulty, the autoregressive moving-average (ARMA) models are introduced; see Box, Jenkins, and Reinsel (1994). Basically, an ARMA model combines the ideas of AR and MA models into a compact form so that the number of parameters used is kept small. For the return series in finance, the chance of using ARMA models is low. However, the concept of ARMA models is highly relevant in volatility modeling. As a matter of fact, the generalized autoregressive conditional heteroscedastic (GARCH) model can be regarded as an ARMA model, albeit nonstandard, for the $a _ { t } ^ { 2 }$ series; see Chapter 3 for details. In this section, we study the simplest ARMA(1,1) model.

A time series $r _ { t }$ follows an ARMA(1,1) model if it satisfies

$$
r _ {t} - \phi_ {1} r _ {t - 1} = \phi_ {0} + a _ {t} - \theta_ {1} a _ {t - 1}, \tag {2.25}
$$

where $\{ a _ { t } \}$ is a white noise series. The left-hand side of Eq. (2.25) is the AR component of the model and the right-hand side gives the MA component. The constant term is $\phi _ { 0 }$ . For this model to be meaningful, we need $\phi _ { 1 } \neq \theta _ { 1 }$ ; otherwise,

there is a cancellation in the equation and the process reduces to a white noise series.

# 2.6.1 Properties of ARMA(1,1) Models

Properties of ARMA(1,1) models are generalizations of those of AR(1) models with some minor modifications to handle the impact of the MA(1) component. We start with the stationarity condition. Taking expectation of Eq. (2.25), we have

$$
E \left(r _ {t}\right) - \phi_ {1} E \left(r _ {t - 1}\right) = \phi_ {0} + E \left(a _ {t}\right) - \theta_ {1} E \left(a _ {t - 1}\right).
$$

Because $E ( a _ { i } ) = 0$ for all $i$ , the mean of $r _ { t }$ is

$$
E (r _ {t}) = \mu = \frac {\phi_ {0}}{1 - \phi_ {1}}
$$

provided that the series is weakly stationary. This result is exactly the same as that of the AR(1) model in Eq. (2.8).

Next, assuming for simplicity that $\phi _ { 0 } = 0$ , we consider the autocovariance function of $r _ { t }$ . First, multiplying the model by $a _ { t }$ and taking expectation, we have

$$
E \left(r _ {t} a _ {t}\right) = E \left(a _ {t} ^ {2}\right) - \theta_ {1} E \left(a _ {t} a _ {t - 1}\right) = E \left(a _ {t} ^ {2}\right) = \sigma_ {a} ^ {2}. \tag {2.26}
$$

Rewriting the model as

$$
r _ {t} = \phi_ {1} r _ {t - 1} + a _ {t} - \theta_ {1} a _ {t - 1}
$$

and taking the variance of the prior equation, we have

$$
\operatorname {V a r} \left(r _ {t}\right) = \phi_ {1} ^ {2} \operatorname {V a r} \left(r _ {t - 1}\right) + \sigma_ {a} ^ {2} + \theta_ {1} ^ {2} \sigma_ {a} ^ {2} - 2 \phi_ {1} \theta_ {1} E \left(r _ {t - 1} a _ {t - 1}\right).
$$

Here we make use of the fact that $r _ { t - 1 }$ and $a _ { t }$ are uncorrelated. Using Eq. (2.26), we obtain

$$
\operatorname {V a r} \left(r _ {t}\right) - \phi_ {1} ^ {2} \operatorname {V a r} \left(r _ {t - 1}\right) = \left(1 - 2 \phi_ {1} \theta_ {1} + \theta_ {1} ^ {2}\right) \sigma_ {a} ^ {2}.
$$

Therefore, if the series $r _ { t }$ is weakly stationary, then $\operatorname { V a r } ( r _ { t } ) = \operatorname { V a r } ( r _ { t - 1 } )$ and we have

$$
\mathrm {V a r} (r _ {t}) = \frac {(1 - 2 \phi_ {1} \theta_ {1} + \theta_ {1} ^ {2}) \sigma_ {a} ^ {2}}{1 - \phi_ {1} ^ {2}}.
$$

Because the variance is positive, we need $\phi _ { 1 } ^ { 2 } < 1$ (i.e., $| \phi _ { 1 } | < 1 \AA ,$ ). Again, this is precisely the same stationarity condition as that of the AR(1) model.

To obtain the autocovariance function of $r _ { t }$ , we assume $\phi _ { 0 } = 0$ and multiply the model in Eq. (2.25) by $r _ { t - \ell }$ to obtain

$$
r _ {t} r _ {t - \ell} - \phi_ {1} r _ {t - 1} r _ {t - \ell} = a _ {t} r _ {t - \ell} - \theta_ {1} a _ {t - 1} r _ {t - \ell}.
$$

For $\ell = 1$ , taking expectation and using Eq. (2.26) for $t - 1$ , we have

$$
\gamma_ {1} - \phi_ {1} \gamma_ {0} = - \theta_ {1} \sigma_ {a} ^ {2},
$$

where $\gamma _ { \ell } = \mathrm { C o v } ( r _ { t } , r _ { t - \ell } )$ . This result is different from that of the AR(1) case for which $\gamma _ { 1 } - \phi _ { 1 } \gamma _ { 0 } = 0$ . However, for $\ell = 2$ and taking expectation, we have

$$
\gamma_ {2} - \phi_ {1} \gamma_ {1} = 0,
$$

which is identical to that of the AR(1) case. In fact, the same technique yields

$$
\gamma_ {\ell} - \phi_ {1} \gamma_ {\ell - 1} = 0, \quad \text {f o r} \quad \ell > 1. \tag {2.27}
$$

In terms of the ACF, the previous results show that for a stationary ARMA(1,1) model

$$
\rho_ {1} = \phi_ {1} - \frac {\theta_ {1} \sigma_ {a} ^ {2}}{\gamma_ {0}}, \quad \rho_ {\ell} = \phi_ {1} \rho_ {\ell - 1}, \quad \text {f o r} \quad \ell > 1.
$$

Thus, the ACF of an ARMA(1,1) model behaves very much like that of an AR(1) model except that the exponential decay starts with lag 2. Consequently, the ACF of an ARMA(1,1) model does not cut off at any finite lag.

Turning to the PACF, one can show that the PACF of an ARMA(1,1) model does not cut off at any finite lag either. It behaves very much like that of an MA(1) model except that the exponential decay starts with lag 2 instead of lag 1.

In summary, the stationarity condition of an ARMA(1,1) model is the same as that of an AR(1) model, and the ACF of an ARMA(1,1) exhibits a pattern similar to that of an AR(1) model except that the pattern starts at lag 2.

# 2.6.2 General ARMA Models

A general ARMA $( p , q )$ model is in the form

$$
r _ {t} = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {t - i} + a _ {t} - \sum_ {i = 1} ^ {q} \theta_ {i} a _ {t - i},
$$

where $\{ a _ { t } \}$ is a white noise series and $p$ and $q$ are non-negative integers. The AR and MA models are special cases of the $\mathbf { A R M A } ( p , q )$ model. Using the back-shift operator, the model can be written as

$$
(1 - \phi_ {1} B - \dots - \phi_ {p} B ^ {p}) r _ {t} = \phi_ {0} + (1 - \theta_ {1} B - \dots - \theta_ {q} B ^ {q}) a _ {t}. \tag {2.28}
$$

The polynomial $1 - \phi _ { 1 } B - \cdot \cdot \cdot - \phi _ { p } B ^ { p }$ is the AR polynomial of the model. Similarly, $1 - \theta _ { 1 } B - \cdot \cdot \cdot - \theta _ { q } B ^ { q }$ is the MA polynomial. We require that there are no common factors between the AR and MA polynomials; otherwise the order $( p , q )$ of the model can be reduced. Like a pure AR model, the AR polynomial

introduces the characteristic equation of an ARMA model. If all of the solutions of the characteristic equation are less than 1 in absolute value, then the ARMA model is weakly stationary. In this case, the unconditional mean of the model is $E ( r _ { t } ) = \phi _ { 0 } / ( 1 - \phi _ { 1 } - \cdot \cdot \cdot - \phi _ { p } )$ .

# 2.6.3 Identifying ARMA Models

The ACF and PACF are not informative in determining the order of an ARMA model. Tsay and Tiao (1984) propose a new approach that uses the extended autocorrelation function (EACF) to specify the order of an ARMA process. The basic idea of EACF is relatively simple. If we can obtain a consistent estimate of the AR component of an ARMA model, then we can derive the MA component. From the derived MA series, we can use the ACF to identify the order of the MA component.

Derivation of the EACF is relatively involved; see Tsay and Tiao (1984) for details. Yet the function is easy to use. The output of the EACF is a two-way table, where the rows correspond to AR order $p$ and the columns to MA order $q$ . The theoretical version of the EACF for an ARMA(1,1) model is given in Table 2.4. The key feature of the table is that it contains a triangle of O’s with the upper left vertex located at the order (1,1). This is the characteristic we use to identify the order of an ARMA process. In general, for an $\mathbf { A R M A } ( p , q )$ model, the triangle of O’s will have its upper left vertex at the $( p , q )$ position.

For illustration, consider the monthly log stock returns of the 3M Company from February 1946 to December 1997. There are 623 observations. The return series and its sample ACF are shown in Figure 2.9. The ACF indicates that there are no significant serial correlations in the data at the $5 \%$ level. Table 2.5 shows the sample EACF and a corresponding simplified table for the series. The simplified table is constructed by using the following notation:

1. X denotes that the absolute value of the corresponding EACF is greater than or equal to $2 / \sqrt { T }$ , which is twice the asymptotic standard error of the EACF.   
2. O denotes that the corresponding EACF is less than $2 / \sqrt { T }$ in modulus.

Table 2.4. Theoretical EACF Table for an ARMA(1,1) Modela   

<table><tr><td rowspan="2">AR</td><td colspan="8">MA</td></tr><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr><tr><td>0</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td></tr><tr><td>1</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>2</td><td>*</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>3</td><td>*</td><td>*</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>4</td><td>*</td><td>*</td><td>*</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>5</td><td>*</td><td>*</td><td>*</td><td>*</td><td>X</td><td>O</td><td>O</td><td>O</td></tr></table>

a X denotes nonzero, O denotes zero, and * denotes either zero or nonzero. This latter category does not play any role in identifying the order (1,1).

![](images/ecd0a5f9ef10e4151172d7bea86d539638363396b30e45098723f2d0e2ceb0d9.jpg)

![](images/8bd84e4fcce9277b625766338c5ab1192ae531378f5e7ac0f863ac623143a9b8.jpg)  
Figure 2.9. Time plot and sample autocorrelation function of the monthly log stock returns of 3M Company from February 1946 to December 1997.

Table 2.5. Sample Extended Autocorrelation Function and a Simplified Table for the Monthly Log Returns of 3M Stock from February 1946 to December 1997   

<table><tr><td colspan="13">Sample Extended Autocorrelation Function
MA Order: q</td></tr><tr><td>p</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td></tr><tr><td>0</td><td>-0.05</td><td>-0.04</td><td>-0.07</td><td>-0.01</td><td>0.02</td><td>0.06</td><td>-0.00</td><td>0.02</td><td>-0.01</td><td>-0.06</td><td>0.03</td><td>0.09</td></tr><tr><td>1</td><td>-0.49</td><td>0.01</td><td>-0.06</td><td>-0.03</td><td>-0.00</td><td>0.06</td><td>0.01</td><td>0.01</td><td>-0.01</td><td>-0.05</td><td>0.02</td><td>0.08</td></tr><tr><td>2</td><td>-0.45</td><td>-0.18</td><td>-0.05</td><td>0.01</td><td>-0.02</td><td>0.06</td><td>0.03</td><td>0.02</td><td>-0.01</td><td>-0.00</td><td>0.01</td><td>0.05</td></tr><tr><td>3</td><td>-0.18</td><td>0.15</td><td>0.40</td><td>-0.01</td><td>-0.01</td><td>0.05</td><td>-0.00</td><td>0.03</td><td>-0.03</td><td>-0.00</td><td>0.00</td><td>0.02</td></tr><tr><td>4</td><td>0.42</td><td>0.04</td><td>0.39</td><td>-0.08</td><td>-0.01</td><td>0.01</td><td>-0.01</td><td>0.04</td><td>0.02</td><td>0.02</td><td>-0.00</td><td>0.01</td></tr><tr><td>5</td><td>-0.13</td><td>0.24</td><td>0.41</td><td>0.07</td><td>0.23</td><td>0.01</td><td>0.01</td><td>0.05</td><td>-0.03</td><td>0.02</td><td>-0.01</td><td>0.00</td></tr><tr><td>6</td><td>-0.07</td><td>-0.37</td><td>0.06</td><td>0.31</td><td>0.20</td><td>-0.09</td><td>0.01</td><td>0.06</td><td>-0.03</td><td>0.02</td><td>-0.01</td><td>0.00</td></tr></table>

Simplified EACF Table   
MA Order: q   

<table><tr><td>p</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>0</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>X</td><td>O</td></tr><tr><td>1</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>2</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>3</td><td>X</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>4</td><td>X</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>5</td><td>X</td><td>X</td><td>X</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>6</td><td>O</td><td>X</td><td>O</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr></table>

The simplified table clearly exhibits a triangular pattern of O’s with its upper left vertex at the order $( p , q ) = ( 0 , 0 )$ . The only exception is a single X in the first row, which corresponds to a sample EACF of 0.09 that is only slightly greater than $2 / { \sqrt { 6 2 3 } } = 0 . { \dot { 0 } } 8 .$ . Therefore, the EACF suggests that the monthly log returns of 3M stock follow an ARMA(0,0) model (i.e., a white noise series). This is in agreement with the result suggested by the sample ACF in Figure 2.9.

The information criteria discussed earlier can also be used to select ARMA models. Typically, for some prespecified positive integers $P$ and $Q$ , one computes AIC (or BIC) for $\mathbf { A R M A } ( p , q )$ models, where $0 \le p \le P$ and $0 \leq q \leq Q$ , and selects the model that gives the minimum AIC (or BIC). This approach requires maximum likelihood estimation of many models and in some cases may encounter the difficulty of overfitting in estimation.

Once an $\mathbf { A R M A } ( p , q )$ model is specified, its parameters can be estimated by either the conditional or exact likelihood method. In addition, the Ljung–Box statistics of the residuals can be used to check the adequacy of a fitted model. If the model is correctly specified, then $Q ( m )$ follows asymptotically a chi-squared distribution with $m - g$ degrees of freedom, where $g$ denotes the number of parameters used in the model.

# 2.6.4 Forecasting Using an ARMA Model

Like the behavior of the ACF, forecasts of an $\mathbf { A R M A } ( p , q )$ model have characteristics similar to those of an $\operatorname { A R } ( p )$ model after adjusting for the impacts of the MA component on the lower horizon forecasts. Denote the forecast origin by $h$ and the available information by $F _ { h }$ . The 1-step ahead forecast of $r _ { h + 1 }$ can easily be obtained from the model as

$$
\hat {r} _ {h} (1) = E \left(r _ {h + 1} \mid F _ {h}\right) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {h + 1 - i} - \sum_ {i = 1} ^ {q} \theta_ {i} a _ {h + 1 - i},
$$

and the associated forecast error is $e _ { h } ( 1 ) = r _ { h + 1 } - \hat { r } _ { h } ( 1 ) = a _ { h + 1 }$ . The variance of 1-step ahead forecast error is $\mathrm { V a r } [ e _ { h } ( 1 ) ] = \sigma _ { a } ^ { 2 }$ . For the $\ell$ -step ahead forecast, we have

$$
\hat {r} _ {h} (\ell) = E (r _ {h + \ell} | F _ {h}) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} \hat {r} _ {h} (\ell - i) - \sum_ {i = 1} ^ {q} \theta_ {i} a _ {h} (\ell - i),
$$

where it is understood that $\hat { r } _ { h } ( \ell - i ) = r _ { h + \ell - i }$ if $\ell - i \leq 0$ and $a _ { h } ( \ell - i ) = 0$ if $\ell - i > 0$ and $a _ { h } ( \ell - i ) = a _ { h + \ell - i }$ if $\ell - i \leq 0$ . Thus, the multistep ahead forecasts of an ARMA model can be computed recursively. The associated forecast error is

$$
e _ {h} (\ell) = r _ {h + \ell} - \hat {r} _ {h} (\ell),
$$

which can be computed easily via a formula to be given below in Eq. (2.34).

# 2.6.5 Three Model Representations for an ARMA Model

In this subsection, we briefly discuss three model representations for a stationary $\mathbf { A R M A } ( p , q )$ model. The three representations serve three different purposes. Knowing these representations can lead to a better understanding of the model. The first representation is the $\mathbf { A R M A } ( p , q )$ model in Eq. (2.28). This representation is compact and useful in parameter estimation. It is also useful in computing recursively multistep ahead forecasts of $r _ { t }$ ; see the discussion of the last subsection.

For the other two representations, we use long division of two polynomials. Given two polynomials $\begin{array} { r } { \phi ( B ) = 1 - \sum _ { i = 1 } ^ { p } \phi _ { i } B ^ { i } } \end{array}$ and $\begin{array} { r } { \theta ( B ) = 1 - \sum _ { i = 1 } ^ { q } \theta _ { i } B ^ { i } } \end{array}$ , we can obtain, by long division, that

$$
\frac {\theta (B)}{\phi (B)} = 1 + \psi_ {1} B + \psi_ {2} B ^ {2} + \dots \equiv \psi (B) \tag {2.29}
$$

and

$$
\frac {\phi (B)}{\theta (B)} = 1 - \pi_ {1} B - \pi_ {2} B ^ {2} - \dots \equiv \pi (B). \tag {2.30}
$$

For instance, if $\phi ( B ) = 1 - \phi _ { 1 } B$ and $\theta ( B ) = 1 - \theta _ { 1 } B$ , then

$$
\psi (B) = \frac {1 - \theta_ {1} B}{1 - \phi_ {1} B} = 1 + (\phi_ {1} - \theta_ {1}) B + \phi_ {1} (\phi_ {1} - \theta_ {1}) B ^ {2} + \phi_ {1} ^ {2} (\phi_ {1} - \theta_ {1}) B ^ {3} + \dots ,
$$

$$
\pi (B) = \frac {1 - \phi_ {1} B}{1 - \theta_ {1} B} = 1 - (\phi_ {1} - \theta_ {1}) B - \theta_ {1} (\phi_ {1} - \theta_ {1}) B ^ {2} - \theta_ {1} ^ {2} (\phi_ {1} - \theta_ {1}) B ^ {3} - \dots .
$$

From the definition, $\psi ( B ) \pi ( B ) = 1$ . Making use of the fact that $B c = c$ for any constant (because the value of a constant is time-invariant), we have

$$
\frac {\phi_ {0}}{\theta (1)} = \frac {\phi_ {0}}{1 - \theta_ {1} - \cdots - \theta_ {q}} \quad \mathrm {a n d} \quad \frac {\phi_ {0}}{\phi (1)} = \frac {\phi_ {0}}{1 - \phi_ {1} - \cdots - \phi_ {p}}.
$$

# AR Representation

Using the result of long division in Eq. (2.30), the $\mathbf { A R M A } ( p , q )$ model can be written as

$$
r _ {t} = \frac {\phi_ {0}}{1 - \theta_ {1} - \cdots - \theta_ {q}} + \pi_ {1} r _ {t - 1} + \pi_ {2} r _ {t - 2} + \pi_ {3} r _ {t - 3} + \dots + a _ {t}. \tag {2.31}
$$

This representation shows the dependence of the current return $r _ { t }$ on the past returns $r _ { t - i }$ , where $i > 0$ . The coefficients $\{ \pi _ { i } \}$ are referred to as the $\pi$ -weights of an ARMA model. To show that the contribution of the lagged value $r _ { t - i }$ to $r _ { t }$ is diminishing as $i$ increases, the $\pi _ { i }$ coefficient should decay to zero as $i$ increases. An $\mathbf { A R M A } ( p , q )$ model that has this property is said to be invertible. For a pure AR model, $\theta ( B ) = 1$ so that $\pi ( B ) = \phi ( B )$ , which is a finite-degree polynomial. Thus, $\pi _ { i } = 0$ for $i > p$ , and the model is invertible. For other ARMA models, a sufficient

condition for invertibility is that all the zeros of the polynomial $\theta ( B )$ are greater than unity in modulus. For example, consider the MA(1) model $r _ { t } = ( 1 - \theta _ { 1 } B ) a _ { t }$ The zero of the first-order polynomial $1 - \theta _ { 1 } B$ is $B = 1 / \theta _ { 1 }$ . Therefore, an MA(1) model is invertible if $| 1 / \theta _ { 1 } | > 1$ . This is equivalent to $| \theta _ { 1 } | < 1$ .

From the AR representation in Eq. (2.31), an invertible $\mathbf { A R M A } ( p , q )$ series $r _ { t }$ is a linear combination of the current shock $a _ { t }$ and a weighted average of the past values. The weights decay exponentially for more remote past values.

# MA Representation

Again, using the result of long division in Eq. (2.29), an $\mathbf { A R M A } ( p , q )$ model can also be written as

$$
r _ {t} = \mu + a _ {t} + \psi_ {1} a _ {t - 1} + \psi_ {2} a _ {t - 2} + \dots = \mu + \psi (B) a _ {t}, \tag {2.32}
$$

where $\mu = E ( r _ { t } ) = \phi _ { 0 } / ( 1 - \phi _ { 1 } - \cdot \cdot \cdot - \phi _ { p } )$ . This representation shows explicitly the impact of the past shock $a _ { t - i }$ $\begin{array} { r } { \vec { \imath } > 0 } \end{array}$ ) on the current return $r _ { t }$ . The coefficients $\{ \psi _ { i } \}$ are referred to as the impulse response function of the ARMA model. For a weakly stationary series, the $\psi _ { i }$ coefficients decay exponentially as $i$ increases. This is understandable as the effect of shock $a _ { t - i }$ on the return $r _ { t }$ should diminish over time. Thus, for a stationary ARMA model, the shock $a _ { t - i }$ does not have a permanent impact on the series. If $\phi _ { 0 } \neq 0$ , then the MA representation has a constant term, which is the mean of $r _ { t }$ (i.e., $\phi _ { 0 } / ( 1 - \phi _ { 1 } - \cdot \cdot \cdot - \phi _ { p } ) ;$ ).

The MA representation in Eq. (2.32) is also useful in computing the variance of a forecast error. At the forecast origin $h$ , we have the shocks $a _ { h } , a _ { h - 1 } , \ldots$ Therefore, the -step ahead point forecast is

$$
\hat {r} _ {h} (\ell) = \mu + \psi_ {\ell} a _ {h} + \psi_ {\ell + 1} a _ {h - 1} + \dots , \tag {2.33}
$$

and the associated forecast error is

$$
e _ {h} (\ell) = a _ {h + \ell} + \psi_ {1} a _ {h + \ell - 1} + \dots + \psi_ {\ell - 1} a _ {h + 1}.
$$

Consequently, the variance of -step ahead forecast error is

$$
\operatorname {V a r} \left[ e _ {h} (\ell) \right] = \left(1 + \psi_ {1} ^ {2} + \dots + \psi_ {\ell - 1} ^ {2}\right) \sigma_ {a} ^ {2}, \tag {2.34}
$$

which, as expected, is a nondecreasing function of the forecast horizon $\ell$ .

Finally, the MA representation in Eq. (2.32) provides a simple proof of mean reversion of a stationary time series. The stationarity implies that $\psi _ { i }$ approaches zero as $i  \infty$ . Therefore, by Eq. (2.33), we have $\hat { r } _ { h } ( \ell ) \to \mu$ as $\ell \to \infty$ . Because $\hat { r } _ { h } ( \ell )$ is the conditional expectation of $r _ { h + \ell }$ at the forecast origin $h$ , the result says that in the long-term the return series is expected to approach its mean, that is, the series is mean-reverting. Furthermore, using the MA representation in Eq. (2.32), we have $\begin{array} { r } { \mathrm { V a r } ( r _ { t } ) = \big ( 1 + \sum _ { i = 1 } ^ { \infty } \psi _ { i } ^ { 2 } \big ) \sigma _ { a } ^ { 2 } } \end{array}$ . Consequently, by Eq. (2.34), we have $\operatorname { V a r } [ e _ { h } ( \ell ) ] \to \operatorname { V a r } ( r _ { t } )$ as $\ell \to \infty$ . The speed by which $\hat { r } _ { h } ( \ell )$ approaches $\mu$ determines the speed of mean-reverting.

# 2.7 UNIT-ROOT NONSTATIONARITY

So far we have focused on return series that are stationary. In some studies, interest rates, foreign exchange rates, or the price series of an asset are of interest. These series tend to be nonstationary. For a price series, the nonstationarity is mainly due to the fact that there is no fixed level for the price. In the time series literature, such a nonstationary series is called unit-root nonstationary time series. The best known example of unit-root nonstationary time series is the random-walk model.

# 2.7.1 Random Walk

A time series $\{ p _ { t } \}$ is a random walk if it satisfies

$$
p _ {t} = p _ {t - 1} + a _ {t}, \tag {2.35}
$$

where $p _ { 0 }$ is a real number denoting the starting value of the process and $\{ a _ { t } \}$ is a white noise series. If $p _ { t }$ is the log price of a particular stock at date $t$ , then $p _ { 0 }$ could be the log price of the stock at its initial public offering (i.e., the logged IPO price). If $a _ { t }$ has a symmetric distribution around zero, then conditional on $p _ { t - 1 }$ , $p _ { t }$ has a 50–50 chance to go up or down, implying that $p _ { t }$ would go up or down at random. If we treat the random-walk model as a special AR(1) model, then the coefficient of $p _ { t - 1 }$ is unity, which does not satisfy the weak stationarity condition of an AR(1) model. A random-walk series is, therefore, not weakly stationary, and we call it a unit-root nonstationary time series.

The random-walk model has widely been considered as a statistical model for the movement of logged stock prices. Under such a model, the stock price is not predictable or mean-reverting. To see this, the 1-step ahead forecast of model (2.35) at the forecast origin $h$ is

$$
\hat {p} _ {h} (1) = E \left(p _ {h + 1} \mid p _ {h}, p _ {h - 1}, \dots\right) = p _ {h},
$$

which is the log price of the stock at the forecast origin. Such a forecast has no practical value. The 2-step ahead forecast is

$$
\begin{array}{l} \hat {p} _ {h} (2) = E \left(p _ {h + 2} \mid p _ {h}, p _ {h - 1}, \dots\right) = E \left(p _ {h + 1} + a _ {h + 2} \mid p _ {h}, p _ {h - 1}, \dots\right) \\ = E \left(p _ {h + 1} \mid p _ {h}, p _ {h - 1}, \dots\right) = \hat {p} _ {h} (1) = p _ {h}, \\ \end{array}
$$

which again is the log price at the forecast origin. In fact, for any forecast horizon $\ell > 0$ , we have

$$
\hat {p} _ {h} (\ell) = p _ {h}.
$$

Thus, for all forecast horizons, point forecasts of a random-walk model are simply the value of the series at the forecast origin. Therefore, the process is not meanreverting.

The MA representation of the random-walk model in Eq. (2.35) is

$$
p _ {t} = a _ {t} + a _ {t - 1} + a _ {t - 2} + \dots .
$$

This representation has several important practical implications. First, the $\ell$ -step ahead forecast error is

$$
e _ {h} (\ell) = a _ {h + \ell} + \dots + a _ {h + 1},
$$

so that $\operatorname { V a r } [ e _ { h } ( \ell ) ] = \ell \sigma _ { a } ^ { 2 }$ , which diverges to infinity as $\ell \to \infty$ . The length of an interval forecast of $p _ { h + \ell }$ will approach infinity as the forecast horizon increases. This result says that the usefulness of point forecast $\hat { p } _ { h } ( \ell )$ diminishes as $\ell$ increases, which again implies that the model is not predictable. Second, the unconditional variance of $p _ { t }$ is unbounded because $\operatorname { V a r } [ e _ { h } ( \ell ) ]$ approaches infinity as  increases. Theoretically, this means that $p _ { t }$ can assume any real value for a sufficiently large t . For the log price $p _ { t }$ of an individual stock, this is plausible. Yet for market indexes, negative log price is very rare if it happens at all. In this sense, the adequacy of a random-walk model for market indexes is questionable. Third, from the representation, $\psi _ { i } = 1$ for all i. Thus, the impact of any past shock $a _ { t - i }$ on $p _ { t }$ does not decay over time. Consequently, the series has a strong memory as it remembers all of the past shocks. In economics, the shocks are said to have a permanent effect on the series. The strong memory of a unit-root time series can be seen from the sample ACF of the observed series. The sample ACFs are all approaching 1 as the sample size increases.

# 2.7.2 Random Walk with Drift

As shown by empirical examples considered so far, the log return series of a market index tends to have a small and positive mean. This implies that the model for the log price is

$$
p _ {t} = \mu + p _ {t - 1} + a _ {t}, \tag {2.36}
$$

where $\mu = E ( p _ { t } - p _ { t - 1 } )$ and $\{ a _ { t } \}$ is a white noise series. The constant term $\mu$ of model (2.36) is very important in financial study. It represents the time trend of the log price $p _ { t }$ and is often referred to as the drift of the model. To see this, assume that the initial log price is $p _ { 0 }$ . Then we have

$$
p _ {1} = \mu + p _ {0} + a _ {1},
$$

$$
p _ {2} = \mu + p _ {1} + a _ {2} = 2 \mu + p _ {0} + a _ {2} + a _ {1},
$$

$$
\begin{array}{c c} \vdots & \vdots \\ \vdots & \vdots \end{array}
$$

$$
p _ {t} = t \mu + p _ {0} + a _ {t} + a _ {t - 1} + \dots + a _ {1}.
$$

The last equation shows that the log price consists of a time trend $t \mu$ and a pure random-walk process $\textstyle \sum _ { i = 1 } ^ { t } a _ { i }$ . Because $\textstyle \operatorname { V a r } \bigl ( \sum _ { i = 1 } ^ { t } a _ { i } \bigr ) = t \sigma _ { a } ^ { 2 }$ , where $\sigma _ { a } ^ { 2 }$ is the variance of $a _ { t }$ , the conditional standard deviation of $p _ { t }$ is $\sqrt { t } \sigma _ { a }$ , which grows at a slower rate than the conditional expectation of $p _ { t }$ . Therefore, if we graph $p _ { t }$ against the time index $t$ , we have a time trend with slope $\mu$ . A positive slope $\mu$ implies that the log price eventually goes to infinity. In contrast, a negative $\mu$ implies that

the log price would converge to $- \infty$ as $t$ increases. Based on the above discussion, it is then not surprising to see that the log return series of the CRSP value- and equal-weighted indexes have a small, but statistically significant, positive mean.

To illustrate the effect of the drift parameter on the price series, we consider the monthly log stock returns of the 3M Company from February 1946 to December 1997. As shown by the sample EACF in Table 2.5, the series has no significant serial correlation. The series thus follows the simple model

$$
r _ {t} = 0. 0 1 1 5 + a _ {t}, \quad \hat {\sigma} _ {a} = 0. 0 6 3 9, \tag {2.37}
$$

where 0.0115 is the sample mean of $r _ { t }$ and has a standard error 0.0026. The mean of the monthly log returns of 3M stock is, therefore, significantly different from zero at the $1 \%$ level. We use the log return series to construct two log price series, namely,

$$
p _ {t} = \sum_ {i = 1} ^ {t} r _ {i} \quad \text {a n d} \quad p _ {t} ^ {*} = \sum_ {i = 1} ^ {t} a _ {i},
$$

where $a _ { i }$ is the mean-corrected log return in Eq. (2.37) (i.e., $a _ { t } = r _ { t } - 0 . 0 1 1 5 )$ . The $p _ { t }$ is the log price of 3M stock, assuming that the initial log price is zero (i.e., the log price of January 1946 was zero). The $p _ { t } ^ { * }$ is the corresponding log price if the mean of log returns was zero. Figure 2.10 shows the time plots of $p _ { t }$ and $p _ { t } ^ { * }$

![](images/a910500ee83f6a0a225767d068f65fe745e592b37345424036ed782dbe4765ad.jpg)  
Figure 2.10. Time plots of log prices for 3M stock from February 1946 to December 1997, assuming that the log price of January 1946 was zero. The dashed line is for log price without time trend. The straight line is $y _ { t } = 0 . 0 1 1 5 \times t$ .

as well as a straight line $y _ { t } = 0 . 0 1 1 5 \times t$ . From the plots, the importance of the constant 0.0115 in Eq. (2.37) is evident. In addition, as expected, the slope of the upward trend of $p _ { t }$ is about 0.0115.

Finally, it is important to understand the meaning of a constant term in a time series model. First, for an $\mathrm { M A } ( q )$ model in Eq. (2.22), the constant term is simply the mean of the series. Second, for a stationary $\operatorname { A R } ( p )$ model in Eq. (2.9) or $\mathbf { A R M A } ( p , q )$ model in Eq. (2.28), the constant term is related to the mean via $\mu = \phi _ { 0 } / ( 1 - \phi _ { 1 } - \cdot \cdot \cdot - \phi _ { p } )$ . Third, for a random walk with drift, the constant term becomes the time slope. These different interpretations for the constant term in a time series model clearly highlight the difference between dynamic and usual linear regression models.

Another important difference between dynamic and regression models is shown by an AR(1) model and a simple linear regression model,

$$
r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + a _ {t} \quad \text {a n d} \quad y _ {t} = \beta_ {0} + \beta_ {1} x _ {t} + a _ {t}.
$$

For the AR(1) model to be meaningful, the coefficient $\phi _ { 1 }$ must satisfy $| \phi _ { 1 } | \leq 1$ However, the coefficient $\beta _ { 1 }$ can assume any fixed real number.

# 2.7.3 Trend-Stationary Time Series

A closely related model that exhibits linear trend is the trend-stationary time series model,

$$
p _ {t} = \beta_ {0} + \beta_ {1} t + r _ {t},
$$

where $r _ { t }$ is a stationary time series, for example, a stationary $\operatorname { A R } ( p )$ series. Here $p _ { t }$ grows linearly in time with rate $\beta _ { 1 }$ and hence can exhibit behavior similar to that of a random-walk model with drift. However, there is a major difference between the two models. To see this, suppose that $p _ { 0 }$ is fixed. The random-walk model with drift assumes the mean $E ( p _ { t } ) = p _ { 0 } + \mu t$ and variance $\mathrm { V a r } ( p _ { t } ) = t \sigma _ { a } ^ { 2 }$ , both of which are time dependent. On the other hand, the trend-stationary model assumes the mean $E ( p _ { t } ) = \beta _ { 0 } + \beta _ { 1 } t$ , which depends on time, and variance $\mathrm { V a r } ( p _ { t } ) = \mathrm { V a r } ( r _ { t } )$ , which is finite and time-invariant. The trend-stationary series can be transformed into a stationary one by removing the time trend via a simple linear regression analysis. For analysis of trend-stationary time series, see Section 2.9.

# 2.7.4 General Unit-Root Nonstationary Models

Consider an ARMA model. If one extends the model by allowing the AR polynomial to have 1 as a characteristic root, then the model becomes the well-known autoregressive integrated moving-average (ARIMA) model. An ARIMA model is said to be unit-root nonstationary because its AR polynomial has a unit root. Like a random-walk model, an ARIMA model has strong memory because the $\psi _ { i }$ coefficients in its MA representation do not decay over time to zero, implying that the past shock $a _ { t - i }$ of the model has a permanent effect on the series. A conventional approach for handling unit-root nonstationarity is to use differencing.

# Differencing

A time series $y _ { t }$ is said to be an $\mathrm { A R I M A } ( p , 1 , q )$ process if the change series $c _ { t } =$ $y _ { t } - y _ { t - 1 } = ( 1 - B ) y _ { t }$ follows a stationary and invertible $\mathbf { A R M A } ( p , q )$ model. In finance, price series are commonly believed to be nonstationary, but the log return series, $r _ { t } = \ln ( p _ { t } ) - \ln ( p _ { t - 1 } )$ , is stationary. In this case, the log price series is unit-root nonstationary and hence can be treated as an ARIMA process. The idea of transforming a nonstationary series into a stationary one by considering its change series is called differencing in the time series literature. More formally, $c _ { t } = y _ { t } - y _ { t - 1 }$ is referred to as the first differenced series of $y _ { t }$ . In some scientific fields, a time series $y _ { t }$ may contain multiple unit roots and needs to be differenced multiple times to become stationary. For example, if both $y _ { t }$ and its first differenced series $c _ { t } = y _ { t } - y _ { t - 1 }$ are unit-root nonstationary, but $s _ { t } = c _ { t } - c _ { t - 1 } = y _ { t } - 2 y _ { t - 1 } +$ $y _ { t - 2 }$ is weakly stationary, then $y _ { t }$ has double unit roots, and $s _ { t }$ is the second differenced series of $y _ { t }$ . In addition, if $s _ { t }$ follows an $\mathbf { A R M A } ( p , q )$ model, then $y _ { t }$ is an $\mathrm { A R I M A } ( p , 2 , q )$ process. For such a time series, if $s _ { t }$ has a nonzero mean, then $y _ { t }$ has a quadratic time function and the quadratic time coefficient is related to the mean of $s _ { t }$ . The seasonally adjusted series of U.S. quarterly gross domestic product implicit price deflator might have double unit roots. However, the mean of the second differenced series is not significantly different from zero (see Exercises at end of chapter). Box, Jenkins, and Reinsel (1994) discuss many properties of general ARIMA models.

# 2.7.5 Unit-Root Test

To test whether the log price $p _ { t }$ of an asset follows a random walk or a random walk with drift, we employ the models

$$
p _ {t} = \phi_ {1} p _ {t - 1} + e _ {t}, \tag {2.38}
$$

$$
p _ {t} = \phi_ {0} + \phi_ {1} p _ {t - 1} + e _ {t}, \tag {2.39}
$$

where $e _ { t }$ denotes the error term, and consider the null hypothesis $H _ { o } : \phi _ { 1 } = 1$ versus the alternative hypothesis $H _ { a } : \phi _ { 1 } < 1$ . This is the well-known unit-root testing problem; see Dickey and Fuller (1979). A convenient test statistic is the $t$ -ratio of the least squares (LS) estimate of $\phi _ { 1 }$ . For Eq. (2.38), the LS method gives

$$
\hat {\phi} _ {1} = \frac {\sum_ {t = 1} ^ {T} p _ {t - 1} p _ {t}}{\sum_ {t = 1} ^ {T} p _ {t - 1} ^ {2}}, \quad \hat {\sigma} _ {e} ^ {2} = \frac {\sum_ {t = 1} ^ {T} (p _ {t} - \hat {\phi} _ {1} p _ {t - 1}) ^ {2}}{T - 1},
$$

where $p _ { 0 } = 0$ and $T$ is the sample size. The $t$ -ratio is

$$
\mathrm {D F} \equiv t \text {- r a t i o} = \frac {\hat {\phi} _ {1} - 1}{\operatorname {s t d} (\hat {\phi} _ {1})} = \frac {\sum_ {t = 1} ^ {T} p _ {t - 1} e _ {t}}{\hat {\sigma} _ {e} \sqrt {\sum_ {t = 1} ^ {T} p _ {t - 1} ^ {2}}},
$$

which is commonly referred to as the Dickey–Fuller test. If $\{ e _ { t } \}$ is a white noise series with finite moments of order slightly greater than 2, then the DF-statistic

converges to a function of the standard Brownian motion as $T \to \infty$ ; see Chan and Wei (1988) and Phillips (1987) for more information. If $\phi _ { 0 }$ is zero but Eq. (2.39) is employed anyway, then the resulting $t$ -ratio for testing $\phi _ { 1 } = 1$ will converge to another nonstandard asymptotic distribution. In either case, simulation is used to obtain critical values of the test statistics; see Fuller (1976, Chapter 8) for selected critical values. Yet if $\phi _ { 0 } \neq 0$ and Eq. (2.39) is used, then the $t$ -ratio for testing $\phi _ { 1 } = 1$ is asymptotically normal. However, large sample sizes are needed for the asymptotic normal distribution to hold. Standard Brownian motion is introduced in Chapter 6.

For many economic time series, ARIMA $( p , d , q )$ models might be more appropriate than the simple model in Eq. (2.39). In the econometric literature, $\operatorname { A R } ( p )$ models are often used. Denote the series by $x _ { t }$ . To verify the existence of a unit root in an $\operatorname { A R } ( p )$ process, one may perform the test $H _ { o } : \beta = 1$ versus $H _ { a } : \beta < 1$ using the regression

$$
x _ {t} = c _ {t} + \beta x _ {t - 1} + \sum_ {i = 1} ^ {p - 1} \phi_ {i} \Delta x _ {t - i} + e _ {t}, \tag {2.40}
$$

where $c _ { t }$ is a deterministic function of the time index $t$ and $\Delta x _ { j } = x _ { j } - x _ { j - 1 }$ is the differenced series of $x _ { t }$ . In practice, $c _ { t }$ can be zero or a constant or $c _ { t } = \omega _ { 0 } + \omega _ { 1 } t$ . The $t$ -ratio of $\hat { \beta } - 1$ ,

$$
\mathrm {A D F - t e s t} = \frac {\hat {\beta} - 1}{\operatorname {s t d} (\hat {\beta})},
$$

where $\hat { \beta }$ denotes the least squares estimate of $\beta$ , is the well-known augmented Dickey–Fuller unit-root test. Note that because of the first differencing, Eq. (2.40) is equivalent to an $\operatorname { A R } ( p )$ model with deterministic function $c _ { t }$ . Equation (2.40) can also be rewritten as

$$
\Delta x _ {t} = c _ {t} + \beta_ {c} x _ {t - 1} + \sum_ {i = 1} ^ {p - 1} \phi_ {i} \Delta x _ {t - i} + e _ {t},
$$

where $\beta _ { c } = \beta - 1$ . One can then test the equivalent hypothesis $H _ { o } : \beta _ { c } = 0$ versus $H _ { a } : \beta _ { c } < 0$ .

Example 2.2. Consider the log series of U.S. quarterly gross domestic product (GDP) from 1947.I to 2003.IV. The series exhibits an upward trend, showing the growth of the U.S. economy, and has high sample serial correlations; see the left panel of Figure 2.11. The first differenced series, representing the growth rate of U.S. GDP and also shown in Figure 2.11, seems to vary around a fixed mean level, even though the variability appears to be smaller in recent years. To confirm the observed phenomenon, we apply the augmented Dickey–Fuller unit-root test to the log series. Based on the sample PACF of the differenced series shown in

![](images/de4e52011191a5a1f4f67e53446a3062831079401ade31f42bb65de1df8148f3.jpg)

![](images/55a91a6c5629e03206cadec3f4de8cbed2a0981097d348d6472f1acf352a953b.jpg)

![](images/6dd72c1f8fce24d72b52570ebc8b85a22bdbfa205422f5c0fdb53796f4101dbf.jpg)

![](images/6b207551aaa68a0dd2e376a0335324b7f06caef1996143496389306bc6ffeab5.jpg)  
Figure 2.11. Log series of U.S. quarterly GDP from 1947.I to 2003.IV: (a) time plot of the logged GDP series, (b) sample ACF of the log GDP data, (c) time plot of the first differenced series, and (d) sample PACF of the differenced series.

Figure 2.11, we choose $p = 1 0$ . Other values of $p$ are also used, but they do not alter the conclusion of the test. With $p = 1 0$ , the ADF-test statistic is $- 1 . 1 3 1$ with $p$ -value 0.7038, indicating that the unit-root hypothesis cannot be rejected. From the S-Plus output below, $\hat { \beta } = 1 + \hat { \beta } _ { c } = 1 - 0 . 0 \dot { 0 } 0 6 = 0 . 9 9 9 4$ .

# S-Plus Demonstration

Output edited.

>adft $\equiv$ unitroot(gdp,trend $= ^{\prime}$ c',method $= ^{\prime}$ adf'，lags $= 10$ >summary(adft)

Test for Unit Root: Augmented DF Test

```txt
Null Hypothesis: there is a unit root Type of Test: t test Test Statistic: -1.131 P-value: 0.7038 
```

Coefficients: Value Std. Error t value $\Pr (|t|)$ lag1 -0.0006 0.0006 -1.1306 0.2595 lag2 0.3797 0.0679 5.5946 0.0000

<table><tr><td>...</td><td></td><td></td><td></td><td></td></tr><tr><td>lag10</td><td>0.1798</td><td>0.0656</td><td>2.7405</td><td>0.0067</td></tr><tr><td>constant</td><td>0.0123</td><td>0.0048</td><td>2.5654</td><td>0.0110</td></tr></table>

Regression Diagnostics:

R-Squared 0.2831 Adjusted R-Squared 0.2485

Residual standard error: 0.009498 on 214 degrees of freedom

As another example, consider the daily log series of the S&P 500 index from January 1990 to December 2003 for 3532 observations. The series is shown in Figure 2.12. Testing for a unit root in the index is relevant if one wishes to verify empirically that the index follows a random walk with drift. To this end, we use $c _ { t } =$ $\omega _ { 0 } + \omega _ { 1 } t$ in applying the augmented Dickey–Fuller test. Furthermore, we choose $p = 1 4$ because AIC selects an AR(13) model for the first differenced series. The resulting test statistic is $- 0 . 9 6 4 8$ with $p$ -value 0.9469. Thus, the unit-root hypothesis cannot be rejected at any reasonable significance level. But the parameter estimates for the deterministic terms are not significantly different from zero at the usual $5 \%$ level. In summary, for the time period considered, the log series of the index contains a unit root, but there is no strong evidence of any time trend.

![](images/4028422636ea423039651a05ed27a2e0eee308605d0b0c72218777b310c8c896.jpg)  
Figure 2.12. Time plot of the logarithm of daily S&P 500 index from January 2, 1990 to December 31, 2003.

# S-Plus Demonstration

Output edited.

```python
>adft=unitroot(sp,method='idf',trend='ct',lags=14)  
>summary(adft) 
```

Test for Unit Root: Augmented DF Test

```txt
Null Hypothesis: there is a unit root Type of Test: t test Test Statistic: -0.9648 P-value: 0.9469 
```

```txt
Coefficients: Value Std. Error t value Pr(>|t|) lag1 -0.0008 0.0008 -0.9648 0.3347 ... lag14 0.0319 0.0169 1.8894 0.0589 constant 0.0056 0.0054 1.0316 0.3023 time 0.0000 0.0000 0.4871 0.6262 
```

```txt
Regression Diagnostics: R-Squared 0.0107 Adjusted R-Squared 0.0065 
```

Residual standard error: 0.01049 on 3514 degrees of freedom

# 2.8 SEASONAL MODELS

Some financial time series such as quarterly earning per share of a company exhibits certain cyclical or periodic behavior. Such a time series is called a seasonal time series. Figure 2.13a shows the time plot of quarterly earning per share of Johnson and Johnson from the first quarter of 1960 to the last quarter of 1980. The data obtained from Shumway and Stoffer (2000) possess some special characteristics. In particular, the earning grew exponentially during the sample period and had a strong seasonality. Furthermore, the variability of earning increased over time. The cyclical pattern repeats itself every year so that the periodicity of the series is 4. If monthly data are considered (e.g., monthly sales of Wal-Mart stores), then the periodicity is 12. Seasonal time series models are also useful in pricing weatherrelated derivatives and energy futures, because most environmental time series exhibit strong seasonal behavior.

Analysis of seasonal time series has a long history. In some applications, seasonality is of secondary importance and is removed from the data, resulting in a seasonally adjusted time series that is then used to make inference. The procedure to remove seasonality from a time series is referred to as seasonal adjustment. Most economic data published by the U.S. government are seasonally adjusted (e.g., the

growth rate of gross domestic product and the unemployment rate). In other applications such as forecasting, seasonality is as important as other characteristics of the data and must be handled accordingly. Because forecasting is a major objective of financial time series analysis, we focus on the latter approach and discuss some econometric models that are useful in modeling seasonal time series.

# 2.8.1 Seasonal Differencing

Figure 2.13b shows the time plot of log earning per share of Johnson and Johnson. We took the log transformation for two reasons. First, it is used to handle the exponential growth of the series. Indeed, the new plot confirms that the growth is linear on the log scale. Second, the transformation is used to stabilize the variability of the series. The increasing pattern in variability of Figure 2.13a disappears in the new plot. Log transformation is commonly used in analysis of financial and economic time series. In this particular instance, all earnings are positive so that no adjustment is needed before taking the transformation. In some cases, one may need to add a positive constant to every data point before taking the transformation.

Denote the log earning by $x _ { t }$ . The upper left panel of Figure 2.14 shows the sample ACF of $x _ { t }$ , which indicates that the quarterly log earning per share has strong serial correlations. A conventional method to handle such strong serial correlations

![](images/1af325eebd520cab595e1afd59b159faa5cc1b23b00537eb0da3f32c682c4994.jpg)  
(a) Earning per share

![](images/e9ebb6498d613aeb86aaee651ac046dc9ea51bd738c37d0b2496e4b36486fef4.jpg)  
(b) Log earning per share   
Figure 2.13. Time plots of quarterly earning per share of Johnson and Johnson from 1960 to 1980: (a) observed earning and (b) log earning.

![](images/3c2afa5bff8777e8bbd9103a58f7cb457a7644caf4cabafc348e937ef1759bc2.jpg)

![](images/9813f7c3d9e4a738322c627616017211349d60ebed99d4eab668cd03fbd028ac.jpg)

![](images/24b1b360fb3bf72c179d026586e55a541e0e1f9cd495ef643354e952f6ee091b.jpg)

![](images/38d1169ce64aa6a7ea725fa540b8c38fa814f3337783d3ba50053648e97503d4.jpg)  
Figure 2.14. Sample ACF of the log series of quarterly earning per share of Johnson and Johnson from 1960 to 1980, where $x _ { t }$ is the log earning, dx is the first differenced series, ds is the seasonally differenced series, and dx ds denotes series with regular and seasonal differencing.

is to consider the first differenced series of $x _ { t }$ (i.e., $\Delta x _ { t } = x _ { t } - x _ { t - 1 } = ( 1 - B ) x _ { t } )$ . The lower left plot of Figure 2.14 gives the sample ACF of $\Delta x _ { t }$ . The ACF is strong when the lag is a multiple of periodicity 4. This is a well-documented behavior of a sample ACF of a seasonal time series. Following the procedure of Box, Jenkins, and Reinsel (1994, Chapter 9), we take another difference of the data, that is,

$$
\Delta_ {4} \left(\Delta x _ {t}\right) = \left(1 - B ^ {4}\right) \Delta x _ {t} = \Delta x _ {t} - \Delta x _ {t - 4} = x _ {t} - x _ {t - 1} - x _ {t - 4} + x _ {t - 5}.
$$

The operation $\Delta _ { 4 } = ( 1 - B ^ { 4 } )$ is called a seasonal differencing. In general, for a seasonal time series $y _ { t }$ with periodicity $s$ , seasonal differencing means

$$
\Delta_ {s} y _ {t} = y _ {t} - y _ {t - s} = (1 - B ^ {s}) y _ {t}.
$$

The conventional difference $\Delta y _ { t } = y _ { t } - y _ { t - 1 } = ( 1 - B ) y _ { t }$ is referred to as the regular differencing. The lower right plot of Figure 2.14 shows the sample ACF of $\Delta _ { 4 } \Delta x _ { t }$ , which has a significant negative ACF at lag 1 and a marginal negative correlation at lag 4. For completeness, Figure 2.14 also gives the sample ACF of the seasonally differenced series $\Delta _ { 4 } x _ { t }$ .

# 2.8.2 Multiplicative Seasonal Models

The behavior of the sample ACF of $( 1 - B ^ { 4 } ) ( 1 - B ) x _ { t }$ in Figure 2.14 is common among seasonal time series. It led to the development of the following special seasonal time series model:

$$
(1 - B ^ {s}) (1 - B) x _ {t} = (1 - \theta B) (1 - \Theta B ^ {s}) a _ {t}, \tag {2.41}
$$

where $s$ is the periodicity of the series, $a _ { t }$ is a white noise series, $| \theta | < 1$ , and $| \Theta | < 1$ . This model is referred to as the airline model in the literature; see Box, Jenkins, and Reinsel (1994, Chapter 9). It has been found to be widely applicable in modeling seasonal time series. The AR part of the model simply consists of the regular and seasonal differences, whereas the MA part involves two parameters. Focusing on the MA part (i.e., on the model),

$$
w _ {t} = (1 - \theta B) \left(1 - \Theta B ^ {s}\right) a _ {t} = a _ {t} - \theta a _ {t - 1} - \Theta a _ {t - s} + \theta \Theta a _ {t - s - 1},
$$

where $w _ { t } = ( 1 - B ^ { s } ) ( 1 - B ) x _ { t }$ and $s > 1$ . It is easy to obtain that $E ( w _ { t } ) = 0$ and

$$
\begin{array}{l} \operatorname {V a r} \left(w _ {t}\right) = \left(1 + \theta^ {2}\right) \left(1 + \Theta^ {2}\right) \sigma_ {a} ^ {2}, \\ \operatorname {C o v} \left(w _ {t}, w _ {t - 1}\right) = - \theta \left(1 + \Theta^ {2}\right) \sigma_ {a} ^ {2}, \\ \operatorname {C o v} \left(w _ {t}, w _ {t - s + 1}\right) = \theta \Theta \sigma_ {a} ^ {2}, \\ \operatorname {C o v} \left(w _ {t}, w _ {t - s}\right) = - \Theta \left(1 + \theta^ {2}\right) \sigma_ {a} ^ {2}, \\ \operatorname {C o v} \left(w _ {t}, w _ {t - s - 1}\right) = \theta \Theta \sigma_ {a} ^ {2}, \\ \operatorname {C o v} \left(w _ {t}, w _ {t - \ell}\right) = 0, \quad \text {f o r} \quad \ell \neq 0, 1, s - 1, s, s + 1. \\ \end{array}
$$

Consequently, the ACF of the $w _ { t }$ series is given by

$$
\rho_ {1} = \frac {- \theta}{1 + \theta^ {2}}, \quad \rho_ {s} = \frac {- \Theta}{1 + \Theta^ {2}}, \quad \rho_ {s - 1} = \rho_ {s + 1} = \rho_ {1} \rho_ {s} = \frac {\theta \Theta}{(1 + \theta^ {2}) (1 + \Theta^ {2})},
$$

and $\rho _ { \ell } = 0$ for $\ell > 0$ and $\ell \neq 1 , s - 1 , s , s + 1$ . For example, if $w _ { t }$ is a quarterly time series, then $s = 4$ and for $\ell > 0$ , the ACF $\rho _ { \ell }$ is nonzero at lags 1, 3, 4, and 5 only.

It is interesting to compare the prior ACF with those of the MA(1) model $y _ { t } = ( 1 - \theta B ) a _ { t }$ and the $\mathbf { M A } ( s )$ model $z _ { t } = ( 1 - \Theta B ^ { s } ) a _ { t }$ . The ACFs of $y _ { t }$ and $z _ { t }$ series are

$$
\begin{array}{l} \rho_ {1} (y) = \frac {- \theta}{1 + \theta^ {2}}, \quad \text {a n d} \quad \rho_ {\ell} (y) = 0, \quad \ell > 1, \\ \rho_ {s} (z) = \frac {- \Theta}{1 + \Theta^ {2}}, \quad \text {a n d} \quad \rho_ {\ell} (z) = 0, \quad \ell > 0, \neq s. \\ \end{array}
$$

We see that (a) $\rho _ { 1 } = \rho _ { 1 } ( y )$ , (b) $\rho _ { s } = \rho _ { s } ( z )$ , and (c) $\rho _ { s - 1 } = \rho _ { s + 1 } = \rho _ { 1 } ( y ) \times \rho _ { s } ( z )$ . Therefore, the ACF of $w _ { t }$ at lags $( s - 1 )$ and $( s + 1 )$ can be regarded as the

interaction between lag-1 and lag-s serial dependence, and the model of $w _ { t }$ is called a multiplicative seasonal MA model. In practice, a multiplicative seasonal model says that the dynamics of the regular and seasonal components of the series are approximately orthogonal.

The model

$$
w _ {t} = \left(1 - \theta B - \Theta B ^ {s}\right) a _ {t}, \tag {2.42}
$$

where $| \theta | < 1$ and $| \Theta | < 1$ , is a nonmultiplicative seasonal MA model. It is easy to see that for the model in Eq. (2.42), $\rho _ { s + 1 } = 0$ . A multiplicative model is more parsimonious than the corresponding nonmultiplicative model because both models use the same number of parameters, but the multiplicative model has more nonzero ACFs.

Example 2.3. In this example we apply the airline model to the log series of quarterly earning per share of Johnson and Johnson from 1960 to 1980. Based on the exact likelihood method, the fitted model is

$$
(1 - B) (1 - B ^ {4}) x _ {t} = (1 - 0. 6 7 8 B) (1 - 0. 3 1 4 B ^ {4}) a _ {t}, \quad \hat {\sigma} _ {a} = 0. 0 8 9,
$$

where standard errors of the two MA parameters are 0.080 and 0.101, respectively. The Ljung–Box statistics of the residuals show $Q ( 1 2 ) = 1 0 . 0 $ with $p$ -value 0.44. The model appears to be adequate.

To illustrate the forecasting performance of the prior seasonal model, we reestimate the model using the first 76 observations and reserve the last eight data points for forecasting evaluation. We compute 1-step to 8-step ahead forecasts and their standard errors of the fitted model at the forecast origin $h = 7 6$ . An antilog transformation is taken to obtain forecasts of earning per share using the relationship between normal and log-normal distributions given in Chapter 1. Figure 2.15 shows the forecast performance of the model, where the observed data are shown by the solid line, point forecasts are shown by dots, and the dashed lines show $9 5 \%$ interval forecasts. The forecasts show a strong seasonal pattern and are close to the observed data. Finally, for an alternative approach to modeling the quarterly earning data, see Section 11.7.

When the seasonal pattern of a time series is stable over time (e.g., close to a deterministic function), dummy variables may be used to handle the seasonality. This approach is taken by some analysts. However, deterministic seasonality is a special case of the multiplicative seasonal model discussed before. Specifically, if $\Theta = 1$ , then model (2.41) contains a deterministic seasonal component. Consequently, the same forecasts are obtained by using either dummy variables or a multiplicative seasonal model when the seasonal pattern is deterministic. Yet use of dummy variables can lead to inferior forecasts if the seasonal pattern is not deterministic. In practice, we recommend that the exact likelihood method should be used to estimate a multiplicative seasonal model, especially when the sample

![](images/b5bacb3e818c4b9cf6dac8fb338ab7d8a9b5cf99b05c569eb7f57e37f4ae336a.jpg)  
Figure 2.15. Out-of-sample point and interval forecasts for the quarterly earning of Johnson and Johnson. The forecast origin is the fourth quarter of 1978. In the plot, the solid line shows the actual observations, dots represent point forecasts, and dashed lines show $9 5 \%$ interval forecasts.

size is small or when there is the possibility of having a deterministic seasonal component.

Example 2.4. To demonstrate deterministic seasonal behavior, consider the monthly simple returns of the CRSP Decile 1 index from January 1960 to December 2003 for 528 observations. The series is shown in Figure 2.16a, and the time plot does not show any clear pattern of seasonality. However, the sample ACF of the return series shown in Figure 2.16b contains significant lags at 12, 24, and 36 as well as lag 1. If seasonal ARMA models are entertained, a model in the form

$$
(1 - \phi_ {1} B) (1 - \phi_ {1 2} B ^ {1 2}) R _ {t} = c + (1 - \theta_ {1 2} B ^ {1 2}) a _ {t}
$$

is identified, where $R _ { t }$ denotes the monthly simple return. Using the conditional likelihood method, the fitted model is

$$
(1 - 0. 2 5 B) (1 - 0. 9 9 B ^ {1 2}) R _ {t} = 0. 0 0 0 4 + (1 - 0. 9 2 B ^ {1 2}) a _ {t}, \quad \tilde {\sigma} _ {a} = 0. 0 7 1.
$$

The MA coefficient is close to unity, indicating that the fitted model is close to being noninvertible. If the exact likelihood method is used, we have

$$
(1 - 0. 2 6 4 B) (1 - 0. 9 9 6 B ^ {1 2}) R _ {t} = 0. 0 0 0 2 + (1 - 0. 9 9 9 B ^ {1 2}) a _ {t}, \quad \tilde {\sigma} _ {a} = 0. 0 6 7.
$$

![](images/728428e7bf1cf95f60853a7daee0b7604c86e0e1fbab30c6eb6115b1f8517998.jpg)

![](images/1378c4560deea990b994117afd6cc5eb1e1cbc498383df9230d9f54631db1e3b.jpg)

![](images/20ebed6834021d3b89132d2a127e27f60fd4ba2d440b023ce60708a73e8b80b4.jpg)

![](images/9a941ec84b67d0e96c1273af9d78035fc69030cbc98bda221704270e04ec4833.jpg)  
Figure 2.16. Monthly simple returns of CRSP Decile 1 index from January 1960 to December 2003: (a) time plot of the simple returns, (b) sample ACF of the simple returns, (c) time plot of the simple returns after adjusting for January effect, and (d) sample ACF of the adjusted simple returns.

The cancellation between seasonal AR and MA factors is clearly seen. This highlights the usefulness of using the exact likelihood method, and the estimation result suggests that the seasonal behavior might be deterministic. To further confirm this assertion, we define the dummy variable for January, that is,

$$
\operatorname {J a n} _ {t} = \left\{ \begin{array}{l l} 1 & \text {i f t i s J a n u a r y ,} \\ 0 & \text {o t h e r w i s e ,} \end{array} \right.
$$

and employ the simple liner regression

$$
R _ {t} = \beta_ {0} + \beta_ {1} \mathrm {J a n} _ {t} + e _ {t}.
$$

The right panel of Figure 2.16 shows the time plot and sample ACF of the residual series of the prior simple linear regression. From the sample ACF, there are no significant serial correlations at any multiples of 12, suggesting that the seasonal pattern has been successfully removed by the January dummy variable. Consequently, the seasonal behavior in the monthly simple return of Decile 1 is due to the January effect.

# SCA Demonstration

Output edited.

tsm m1. model (1)(12)dec1=c1+(12)noise.

estim m1. hold resi(r1)

SUMMARY FOR UNIVARIATE TIME SERIES MODEL -- M1

VAR TYPE OF ORIGINAL DIFFERENCING VARIABLE OR CENTERED

DEC1 RANDOM ORIGINAL NONE

<table><tr><td colspan="9">PAR. VAR. NUM. / FACTOR ORDER CONS- VALUE STD T LABEL NAME</td></tr><tr><td>1</td><td>C1</td><td>CNST</td><td>1</td><td>0</td><td>NONE</td><td>.0004</td><td>.0003</td><td>1.11</td></tr><tr><td>2</td><td>DEC1</td><td>MA</td><td>1</td><td>12</td><td>NONE</td><td>.9213</td><td>.0205</td><td>44.90</td></tr><tr><td>3</td><td>DEC1</td><td>AR</td><td>1</td><td>1</td><td>NONE</td><td>.2496</td><td>.0419</td><td>5.95</td></tr><tr><td>4</td><td>DEC1</td><td>AR</td><td>2</td><td>12</td><td>NONE</td><td>.9943</td><td>.0094</td><td>105.71</td></tr></table>

EFFECTIVE NUMBER OF OBSERVATIONS . 515

R-SQUARE 0.207

RESIDUAL STANDARD ERROR. . . . . . . 0.705662E-01

estim m1. method exact. hold resi(r1)

SUMMARY FOR UNIVARIATE TIME SERIES MODEL -- M1

VAR. TYPE OF ORIGINAL DIFFERENCING VAR. OR CENTERED

DEC1 RANDOM ORIGINAL NONE

<table><tr><td>PAR.</td><td>VARI.</td><td>NUM./</td><td>FACTOR</td><td>ORDER</td><td>CONS-</td><td>VALUE</td><td>STD</td><td>T</td></tr><tr><td>LABEL</td><td>NAME</td><td>DENOM.</td><td></td><td></td><td>TRAIN</td><td></td><td>ERROR</td><td>VALUE</td></tr></table>

1 C1 CNST 1 0 NONE .0002 .0002 .67

2 DEC1 MA 1 12 NONE .9989 .0156 63.99

3 DEC1 AR 1 1 NONE .2638 .0424 6.23

4 DEC1 AR 2 12 NONE .9963 .0058 170.55

EFFECTIVE NUMBER OF OBSERVATIONS . 515

R-SQUARE 0.283

RESIDUAL STANDARD ERROR. . . . . . . 0.670734E-01

# 2.9 REGRESSION MODELS WITH TIME SERIES ERRORS

In many applications, the relationship between two time series is of major interest. The market model in finance is an example that relates the return of an individual stock to the return of a market index. The term structure of interest rates is another example in which the time evolution of the relationship between interest rates with different maturities is investigated. These examples lead to the consideration of a linear regression in the form

$$
r _ {1 t} = \alpha + \beta r _ {2 t} + e _ {t}, \tag {2.43}
$$

where $r _ { 1 t }$ and $r _ { 2 t }$ are two time series and $e _ { t }$ denotes the error term. The least squares (LS) method is often used to estimate model (2.43). If $\{ e _ { t } \}$ is a white noise series, then the LS method produces consistent estimates. In practice, however, it is common to see that the error term $e _ { t }$ is serially correlated. In this case, we have a regression model with time series errors, and the LS estimates of $\alpha$ and $\beta$ may not be consistent.

A regression model with time series errors is widely applicable in economics and finance, but it is one of the most commonly misused econometric models because the serial dependence in $e _ { t }$ is often overlooked. It pays to study the model carefully.

We introduce the model by considering the relationship between two U.S. weekly interest rate series:

• $r _ { 1 t }$ , the 1-year Treasury constant maturity rate.   
• $r _ { 3 t }$ , the 3-year Treasury constant maturity rate.

Both series have 1967 observations from January 4, 1962 to September 10, 1999 and are measured in percentages. The series are obtained from the Federal Reserve Bank of St. Louis. Strictly speaking, we should model the two interest series jointly using multivariate time series analysis in Chapter 8. However, for simplicity, we focus here on regression-type analysis and ignore the issue of simultaneity.

Figure 2.17 shows the time plots of the two interest rates with the solid line denoting the 1-year rate and the dashed line the 3-year rate. Figure 2.18a plots $r _ { 1 t }$ versus $r _ { 3 t }$ , indicating that, as expected, the two interest rates are highly correlated. A naive way to describe the relationship between the two interest rates is to use the simple model $r _ { 3 t } = \alpha + \beta r _ { 1 t } + e _ { t }$ . This results in a fitted model

$$
r _ {3 t} = 0. 9 1 1 + 0. 9 2 4 r _ {1 t} + e _ {t}, \quad \hat {\sigma} _ {e} = 0. 5 3 8, \tag {2.44}
$$

with $R ^ { 2 } = 9 5 . 8 \%$ , where the standard errors of the two coefficients are 0.032 and 0.004, respectively. Model (2.44) confirms the high correlation between the two interest rates. However, the model is seriously inadequate as shown by Figure 2.19, which gives the time plot and ACF of its residuals. In particular, the sample ACF of the residuals is highly significant and decays slowly, showing the pattern of

![](images/6c7f80aa854d0f3087e7ec2961b01c333713a501af207f24c89187002814fb25.jpg)  
Figure 2.17. Time plots of U.S. weekly interest rates (in percentages) from January 4, 1962 to September 10, 1999. The solid line is the Treasury 1-year constant maturity rate and the dashed line the Treasury 3-year constant maturity rate.

![](images/f25dc60f9dcd531d9a4ea3a8fc7e25f2d227a796b1ab45d7b82d725556ad7b36.jpg)  
Figure 2.18. Scatterplots of U.S. weekly interest rates from January 5, 1962 to September 10, 1999: (a) 3-year rate versus 1-year rate and (b) changes in 3-year rate versus changes in 1-year rate.

![](images/50f3b7090f84f660cc4d87fa826a1ae287260f56612dd7182a29a2e643256d3a.jpg)

![](images/ba00174125c9400019da24a08a1ade449d0307e98d55c620800260aec8ab0020.jpg)  
Figure 2.19. Residual series of linear regression (2.44) for two U.S. weekly interest rates: (a) time plot and (b) sample ACF.

a unit-root nonstationary time series. The behavior of the residuals suggests that marked differences exist between the two interest rates. Using modern econometric terminology, if one assumes that the two interest rate series are unit-root nonstationary, then the behavior of the residuals of Eq. (2.44) indicates that the two interest rates are not cointegrated; see Chapter 8 for discussion of cointegration. In other words, the data fail to support the hypothesis that there exists a long-term equilibrium between the two interest rates. In some sense, this is not surprising because the pattern of “inverted yield curve” did occur during the data span. By inverted yield curve, we mean the situation under which interest rates are inversely related to their time to maturities.

The unit-root behavior of both interest rates and the residuals of Eq. (2.44) leads to consideration of the change series of interest rates. Let

1. $c _ { 1 t } = r _ { 1 t } - r _ { 1 , t - 1 } = ( 1 - B ) r _ { 1 t }$ for $t \geq 2$ : changes in the 1-year interest rate;   
2. $c _ { 3 t } = r _ { 3 t } - r _ { 3 , t - 1 } = ( 1 - B ) r _ { 3 t }$ for $t \geq 2$ : changes in the 3-year interest rate;

and consider the linear regression $c _ { 3 t } = \alpha + \beta c _ { 1 t } + e _ { t }$ . Figure 2.20 shows time plots of the two change series, whereas Figure 2.18b provides a scatterplot between them. The change series remain highly correlated with a fitted linear regression model given by

$$
c _ {3 t} = 0. 0 0 0 2 + 0. 7 8 1 1 c _ {1 t} + e _ {t}, \quad \hat {\sigma} _ {e} = 0. 0 6 8 2, \tag {2.45}
$$

![](images/cadfa297e141d824a32335f8b6fd7c8b02ebf6561c0486b8439911e66ed1f1ce.jpg)  
(a) Change in 1-year rate

![](images/8628538161260e9aa0f8994b7d8f7af14757943d0f09a7b6a38117687a2d9dcf.jpg)  
(b) Change in 3-year rate   
Figure 2.20. Time plots of the change series of U.S. weekly interest rates from January 12, 1962 to September 10, 1999: (a) changes in the Treasury 1-year constant maturity rate and (b) changes in the Treasury 3-year constant maturity rate.

with $R ^ { 2 } = 8 4 . 8 \%$ . The standard errors of the two coefficients are 0.0015 and 0.0075, respectively. This model further confirms the strong linear dependence between interest rates. Figure 2.21 shows the time plot and sample ACF of the residuals of Eq. (2.45). Once again, the ACF shows some significant serial correlation in the residuals, but the magnitude of the correlation is much smaller. This weak serial dependence in the residuals can be modeled by using the simple time series models discussed in the previous sections, and we have a linear regression with time series errors.

The main objective of this section is to discuss a simple approach for building a linear regression model with time series errors. The approach is straightforward. We employ a simple time series model discussed in this chapter for the residual series and estimate the whole model jointly. For illustration, consider the simple linear regression in Eq. (2.45). Because residuals of the model are serially correlated, we shall identify a simple ARMA model for the residuals. From the sample ACF of the residuals shown in Figure 2.21, we specify an MA(1) model for the residuals and modify the linear regression model to

$$
c _ {3 t} = \alpha + \beta c _ {1 t} + e _ {t}, \quad e _ {t} = a _ {t} - \theta_ {1} a _ {t - 1}, \tag {2.46}
$$

![](images/a039038139f20600414102931496b0be0e84a94d48371dc6191e4a551191c96e.jpg)

![](images/673fc09349396c5d8ea65e3b15deec3bbb581ecd2f08cd649cf9d7048d7b2a7a.jpg)  
Figure 2.21. Residual series of the linear regression (2.45) for two change series of U.S. weekly interest rates: (a) time plot and (b) sample ACF.

where $\{ a _ { t } \}$ is assumed to be a white noise series. In other words, we simply use an MA(1) model, without the constant term, to capture the serial dependence in the error term of Eq. (2.45). The resulting model is a simple example of linear regression with time series errors. In practice, more elaborated time series models can be added to a linear regression equation to form a general regression model with time series errors.

Estimating a regression model with time series errors was not easy before the advent of modern computers. Special methods such as the Cochrane–Orcutt estimator have been proposed to handle the serial dependence in the residuals; see Greene (2000, p. 546). By now, the estimation is as easy as that of other time series models. If the time series model used is stationary and invertible, then one can estimate the model jointly via the maximum likelihood method. This is the approach we take by using the SCA package. S-Plus demonstration is given later. For the U.S. weekly interest rate data, the fitted version of model (2.46) is

$$
c _ {3 t} = 0. 0 0 0 2 + 0. 7 8 2 4 c _ {1 t} + e _ {t}, \quad e _ {t} = a _ {t} + 0. 2 1 1 5 a _ {t - 1}, \quad \hat {\sigma} _ {a} = 0. 0 6 6 8, \tag {2.47}
$$

with $R ^ { 2 } = 8 5 . 4 \%$ . The standard errors of the parameters are 0.0018, 0.0077, and 0.0221, respectively. The model no longer has a significant lag-1 residual ACF, even though some minor residual serial correlations remain at lags 4 and 6. The

incremental improvement of adding additional MA parameters at lags 4 and 6 to the residual equation is small and the result is not reported here.

Comparing the models in Eqs. (2.44), (2.45), and (2.47), we make the following observations. First, the high $R ^ { 2 }$ and coefficient 0.924 of model (2.44) are misleading because the residuals of the model show strong serial correlations. Second, for the change series, $R ^ { 2 }$ and the coefficient of $c _ { 1 t }$ of models (2.45) and (2.47) are close. In this particular instance, adding the MA(1) model to the change series only provides a marginal improvement. This is not surprising because the estimated MA coefficient is small numerically, even though it is statistically highly significant. Third, the analysis demonstrates that it is important to check residual serial dependence in linear regression analysis.

Because the constant term of Eq. (2.47) is insignificant, the model shows that the two weekly interest rate series are related as

$$
r _ {3 t} = r _ {3, t - 1} + 0. 7 8 2 \left(r _ {1 t} - r _ {1, t - 1}\right) + a _ {t} + 0. 2 1 2 a _ {t - 1}.
$$

The interest rates are concurrently and serially correlated.

# Summary

We outline a general procedure for analyzing linear regression models with time series errors:

1. Fit the linear regression model and check serial correlations of the residuals.   
2. If the residual series is unit-root nonstationary, take the first difference of both the dependent and explanatory variables. Go to step 1. If the residual series appears to be stationary, identify an ARMA model for the residuals and modify the linear regression model accordingly.   
3. Perform a joint estimation via the maximum likelihood method and check the fitted model for further improvement.

To check the serial correlations of residuals, we recommend that the Ljung–Box statistics be used instead of the Durbin–Watson (DW) statistic because the latter only considers the lag-1 serial correlation. There are cases in which residual serial dependence appears at higher order lags. This is particularly so when the time series involved exhibits some seasonal behavior.

Remark. For a residual series $e _ { t }$ with $T$ observations, the Durbin–Watson statistic is

$$
\mathrm {D W} = \frac {\sum_ {t = 2} ^ {T} \left(e _ {t} - e _ {t - 1}\right) ^ {2}}{\sum_ {t = 1} ^ {T} e _ {t} ^ {2}}.
$$

Straightforward calculation shows that DW $\approx 2 ( 1 - \hat { \rho } _ { 1 } )$ , where $\hat { \rho } _ { 1 }$ is the lag-1 ACF of $\left\{ \boldsymbol { e } _ { t } \right\}$ .

In S-Plus, regression models with time series errors can be analyzed by the command OLS (ordinary least squares) if the residuals assume an AR model. Also, to identify a lagged variable, the command is tslag, for example, $\mathrm { ~ y ~ } = \mathrm { ~ t s 1 a g ~ ( \vec { r } , \vec { \tau } ^ { 1 } ) ~ }$ $=$ . For the interest rate series, the relevant commands are given below, where $\%$ denotes explanation of the command. 

```matlab
>da=matrix.scan(file='w-gs1n36299.txt'),3) %load data  
> r1t=da[1,]  
> r3t=da[2,]  
> fit=OLS(r3t~r1t) % fit the first regression  
> summary.fit)  
> c3t=diff(r3t) % take difference  
> c1t=diff(r1t)  
> fit1=OLS(c3t~c1t) % fit second regression  
> summary.fit1)  
> fit2=OLS(c3t~c1t+tslag(c3t,1)+tslag(c1t,1), na.rm=T)  
> summary.fit2) 
```

See the output in the next section for more information.

# 2.10 CONSISTENT COVARIANCE MATRIX ESTIMATION

Consider again the regression model in Eq. (2.43). There may exist situations in which the error term $e _ { t }$ has serial correlations and/or conditional heteroscedasticity, but the main objective of the analysis is to make inference concerning the regression coefficients $\alpha$ and $\beta$ . See Chapter 3 for discussion of conditional heteroscedasticity. In situations under which the ordinary least squares estimates of the coefficients remain consistent, methods are available to provide consistent estimate of the covariance matrix of the coefficients. Two such methods are widely used. The first method is called heteroscedasticity consistent (HC) estimator; see Eicker (1967) and White (1980). The second method is called heteroscedasticity and autocorrelation consistent (HAC) estimator; see Newey and West (1987).

For ease in discussion, we shall rewrite the regression model as

$$
y _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + e _ {t}, \quad t = 1, \dots , T, \tag {2.48}
$$

where $y _ { t }$ is the dependent variable, $\pmb { x } _ { t } = ( x _ { 1 t } , \ldots , x _ { k t } ) ^ { \prime }$ is a $k$ -dimensional vector of explanatory variables including constant, and $\pmb { \beta } = ( \beta _ { 1 } , \ldots , \beta _ { k } ) ^ { \prime }$ is the parameter vector. Here $ { \boldsymbol { c } } ^ { \prime }$ denotes the transpose of the vector $c$ . The LS estimate of $\beta$ and the associated covariance matrix are

$$
\hat {\boldsymbol {\beta}} = \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1} \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} y _ {t}, \quad \operatorname {C o v} (\hat {\boldsymbol {\beta}}) = \sigma_ {e} ^ {2} \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1},
$$

where $\sigma _ { e } ^ { 2 }$ is the variance of $e _ { t }$ and is estimated by the variance of the residuals of the regression. In the presence of serial correlations or conditional heteroscedasticity, the prior covariance matrix estimator is inconsistent, often resulting in inflating the $t$ -ratios of $\hat { \boldsymbol { \beta } }$ .

The estimator of White (1980) is

$$
\operatorname {C o v} (\hat {\boldsymbol {\beta}}) _ {\mathrm {H C}} = \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1} \left[ \frac {T}{T - k} \sum_ {t = 1} ^ {T} \hat {e} _ {t} ^ {2} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1}, \tag {2.49}
$$

where $\hat { e } _ { t } = y _ { t } - x _ { t } ^ { \prime } \hat { \beta }$ is the residual at time $t$ . The estimator of Newey and West (1987) is

$$
\operatorname {C o v} (\hat {\boldsymbol {\beta}}) _ {\mathrm {H A C}} = \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1} \hat {C} _ {\mathrm {H A C}} \left[ \sum_ {t = 1} ^ {T} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} \right] ^ {- 1}, \tag {2.50}
$$

where

$$
\hat {\boldsymbol {C}} _ {\mathrm {H A C}} = \sum_ {t = 1} ^ {T} \hat {e} _ {t} ^ {2} \boldsymbol {x} _ {t} \boldsymbol {x} _ {t} ^ {\prime} + \sum_ {j = 1} ^ {\ell} w _ {j} \sum_ {t = j + 1} ^ {T} (\boldsymbol {x} _ {t} \hat {e} _ {t} \hat {e} _ {t - j} \boldsymbol {x} _ {t - j} ^ {\prime} + \boldsymbol {x} _ {t - j} \hat {e} _ {t - j} \hat {e} _ {t} \boldsymbol {x} _ {t} ^ {\prime}),
$$

where $\ell$ is a truncation parameter and $w _ { j }$ is a weight function such as the Bartlett weight function defined by

$$
w _ {j} = 1 - \frac {j}{\ell + 1}.
$$

Other weight functions can also be used. Newey and West suggest choosing  to be the integer part of $4 ( T / 1 0 0 ) ^ { 2 / 9 }$ . This estimator essentially uses a nonparametric method to estimate the covariance matrix of $\left\{ \sum _ { t = 1 } ^ { T } \hat { e } _ { t } \pmb { x } _ { t } \right\}$ .

For illustration, we employ the first differenced interest rate series in Eq. (2.45). The $t$ -ratio of the coefficient of $c _ { 1 t }$ is 104.63 if both serial correlation and heteroscedasticity in residuals are ignored; it becomes 46.73 when the HC estimator is used, and it reduces to 40.08 when the HAC estimator is used. The S-Plus demonstration below also uses a regression that includes lagged values $_ { c _ { 1 , t - 1 } }$ and $c _ { 3 , t - 1 }$ as regressors to take care of serial correlations in the residuals.

# S-Plus Demonstration

$\%$ denotes explanation.

> $\mathrm { \ x = }$ matrix(scan(file=’w-gs1n36299.txt’),3) % Load data   
> gs1=x[1,] $\%$ 1-year interest rate   
> gs3=x[2,] % 3-year interest rate   
> dgs3=diff(gs3)   
> dgs1=diff(gs1)

>reg.fit $\equiv$ OLS(dgs3~dgs1）%Fitasimplelinearregression >summary(reg.fit)

Call: OLS(formula $=$ dgs3\~dgs1)

```txt
Residuals: Min 1Q Median 3Q Max -0.3806 -0.0334 -0.0005 0.0344 0.4742
```

Coefficients: Value Std. Error t value $\Pr (|t|)$ (Intercept) 0.0002 0.0015 0.1609 0.8722 dgs1 0.7811 0.0075 104.6283 0.0000

```txt
Regression Diagnostics: 
```

```txt
R-Squared 0.8479  
Adjusted R-Squared 0.8478  
Durbin-Watson Stat 1.6158 
```

```python
> summary(reg.fit, correction="white") % Use HC estimator 
```

Coefficients: Value Std. Error t value $\Pr (|t|)$ (Intercept) 0.0002 0.0015 0.1609 0.8722 dgs1 0.7811 0.0167 46.7260 0.0000

```txt
> summary(reg.fit, correction="nw") % Use HAC estimator 
```

Coefficients: Value Std. Error t value $\Pr (|t|)$ (Intercept) 0.0002 0.0017 0.1436 0.8858 dgs1 0.7811 0.0195 40.0841 0.0000

$\%$ Below, fit a regression model with time series error  
> reg.ts=OLS(dgs3~dgs1+tslag(dgs3,1)+tslag(dgs1,1),na:r=m=T)  
> summary(reg.ts)

```txt
Call: OLS(formula = dgs3~dgs1+tslag(dgs3,1) + tslag(dgs1,1), na.rm = T) 
```

```txt
Residuals: Min 1Q Median 3Q Max -0.3652 -0.0329 -0.0005 0.0333 0.4506
```

Coefficients: Value Std. Error t value $\mathsf{Pr}(|t|)$ (Intercept) 0.0002 0.0015 0.1426 0.8866

<table><tr><td>dgs1</td><td>0.7851</td><td>0.0078</td><td>100.4694</td><td>0.0000</td></tr><tr><td>tslug(dgs3, 1)</td><td>0.1920</td><td>0.0221</td><td>8.6685</td><td>0.0000</td></tr><tr><td>tslug(dgs1, 1)</td><td>-0.1634</td><td>0.0190</td><td>-8.6219</td><td>0.0000</td></tr></table>

Regression Diagnostics:

R-Squared 0.8537

Adjusted R-Squared 0.8535

Durbin-Watson Stat 1.9740

# 2.11 LONG-MEMORY MODELS

We have discussed that for a stationary time series the ACF decays exponentially to zero as lag increases. Yet for a unit-root nonstationary time series, it can be shown that the sample ACF converges to 1 for all fixed lags as the sample size increases; see Chan and Wei (1988) and Tiao and Tsay (1983). There exist some time series whose ACF decays slowly to zero at a polynomial rate as the lag increases. These processes are referred to as long-memory time series. One such example is the fractionally differenced process defined by

$$
(1 - B) ^ {d} x _ {t} = a _ {t}, \quad - 0. 5 <   d <   0. 5, \tag {2.51}
$$

where $\{ a _ { t } \}$ is a white noise series. Properties of model (2.51) have been widely studied in the literature (e.g., Hosking, 1981). We summarize some of these properties below.

1. If $d < 0 . 5$ , then $x _ { t }$ is a weakly stationary process and has the infinite MA representation

$$
\begin{array}{l} x _ {t} = a _ {t} + \sum_ {i = 1} ^ {\infty} \psi_ {i} a _ {t - i}, \quad \text {w i t h} \quad \psi_ {k} = \frac {d (1 + d) \cdots (k - 1 + d)}{k !} \\ = \frac {(k + d - 1) !}{k ! (d - 1) !}. \\ \end{array}
$$

2. If $d > - 0 . 5$ , then $x _ { t }$ is invertible and has the infinite AR representation

$$
\begin{array}{l} x _ {t} = \sum_ {i = 1} ^ {\infty} \pi_ {i} x _ {t - i} + a _ {t}, \quad \text {w i t h} \quad \pi_ {k} = \frac {- d (1 - d) \cdots (k - 1 - d)}{k !} \\ = \frac {(k - d - 1) !}{k ! (- d - 1) !}. \\ \end{array}
$$

3. For $- 0 . 5 < d < 0 . 5$ , the ACF of $x _ { t }$ is

$$
\rho_ {k} = \frac {d (1 + d) \cdots (k - 1 + d)}{(1 - d) (2 - d) \cdots (k - d)}, \quad k = 1, 2, \dots .
$$

In particular, $\rho _ { 1 } = d / ( 1 - d )$ and

$$
\rho_ {k} \approx \frac {(- d) !}{(d - 1) !} k ^ {2 d - 1}, \quad \text {a s} \quad k \to \infty .
$$

4. For $- 0 . 5 < d < 0 . 5$ , the PACF of $x _ { t }$ is $\phi _ { k , k } = { d } / { ( k - d ) }$ for $k = 1 , 2 , \ldots$   
5. For $- 0 . 5 < d < 0 . 5$ , the spectral density function $f ( \omega )$ of $x _ { t }$ , which is the Fourier transform of the ACF of $x _ { t }$ , satisfies

$$
f (\omega) \sim \omega^ {- 2 d}, \quad \text {a s} \quad \omega \rightarrow 0, \tag {2.52}
$$

where $\omega \in [ 0 , 2 \pi ]$ denotes the frequency.

Of particular interest here is the behavior of the ACF of $x _ { t }$ when $d < 0 . 5$ . The property says that $\rho _ { k } \sim k ^ { 2 d - 1 }$ , which decays at a polynomial, instead of exponential, rate. For this reason, such an $x _ { t }$ process is called a long-memory time series. A special characteristic of the spectral density function in Eq. (2.52) is that the spectrum diverges to infinity as $\omega  0$ . However, the spectral density function of a stationary ARMA process is bounded for all $\omega \in [ 0 , 2 \pi ]$ .

![](images/7aa17fbaa699eeaf2ac57e75029d3884589aaa89cf28eeedc96d3602b6b79dfd.jpg)  
(a) ACF of the absolute returns of value-weighted index

![](images/d4f699afc9b9b9ce2bd317f5e9a0b7dc1107dc7b69e33b265300aa2d13cacfa0.jpg)  
(b) ACF of the absolute returns of equal-weighted index   
Figure 2.22. Sample autocorrelation function of the absolute series of daily simple returns for the CRSP value- and equal-weighted indexes: (a) the value-weighted index return and (b) the equal-weighted index return. The sample period is from July 3, 1962 to December 31, 1997.

Earlier we used the binomial theorem for noninteger powers

$$
(1 - B) ^ {d} = \sum_ {k = 0} ^ {\infty} (- 1) ^ {k} \left( \begin{array}{c} d \\ k \end{array} \right) B ^ {k}, \quad \left( \begin{array}{c} d \\ k \end{array} \right) = \frac {d (d - 1) \cdots (d - k + 1)}{k !}.
$$

If the fractionally differenced series $( 1 - B ) ^ { d } x _ { t }$ follows an $\mathbf { A R M A } ( p , q )$ model, then $x _ { t }$ is called an $\mathrm { A R F I M A } ( p , d , q )$ process, which is a generalized ARIMA model by allowing for noninteger $d$ .

In practice, if the sample ACF of a time series is not large in magnitude, but decays slowly, then the series may have long memory. As an illustration, Figure 2.22 shows the sample ACFs of the absolute series of daily simple returns for the CRSP value- and equal-weighted indexes from July 3, 1962 to December 31, 1997. The ACFs are relatively small in magnitude but decay very slowly; they appear to be significant at the $5 \%$ level even after 300 lags. For more information about the behavior of sample ACFs of absolute return series, see Ding, Granger, and Engle (1993). For the pure fractionally differenced model in Eq. (2.51), one can estimate $d$ using either a maximum likelihood method or a regression method with logged periodogram at the lower frequencies. Finally, long-memory models have attracted some attention in the finance literature in part because of the work on fractional Brownian motion in the continuous-time models.

# APPENDIX: SOME SCA COMMANDS

# Commands Used in Section 2.4

The data file is ‘m-vw.txt’ and comments start with ‘–’. These comments explain the function of each command.

```txt
-- load data into SCA and denote the series by vw.  
input vw. file 'm-vw.txt'  
-- compute 10 lags of PACF.  
pacf vw. maxl 10.  
-- compute AIC for AR(1) to AR(10).  
miden vw. no ccm. arfits 1 to 10.  
-- specify an AR(3) model and denote the model by m1.  
tsm m1. model (1,2,3) vw=c0+noise.  
-- estimate the model and store the residuals in r1.  
estim m1. hold resi(r1)  
-- compute ACF of the residuals, including Q statistics.  
acf r1.  
-- refine the model to an AR(5).  
tsm m1. model (1,2,3,4,5) vw=c0+noise.  
-- estimate the model and store the residuals in r1.  
estim m1. hold resi(r1)  
-- compute ACF of the residuals.  
acf r1. maxl 10. 
```

```txt
-- compute p-value of the Q(5) statistic.  
p=1.0-cdfc(11.2,5)  
-- print p-value.  
print p  
-- re-estimate the model using the first 858 observations.  
estim m1. span 1,858.  
-- compute 1-step to 6-step ahead forecasts at origin 858.  
ufore m1. orig 858. nofs 6.  
-- quit SCA.  
stop 
```

# Commands Used in Section 2.9

The 1-year maturity interest rates are in the file ‘wgs1yr.txt’ and the 3-year rates are in the file ‘wgs3yr.txt’.

```lua
-- load data into SCA, denote the data by rate1 and rate3.  
input date, rate1. file 'wgs1yr.txt'  
--  
input date, rate3. file 'wgs3yr.txt'  
-- specify a simple linear regression model.  
tsm m1. model rate3 = b0 + (b1) rate1 + noise.  
-- estimate the specified model and store residual in r1.  
estim m1. hold resi(r1).  
-- compute 10 lags of residual acf.  
acf r1. maxl 10.  
--difference the series & denote the new ones by c1t and c diff old rate1, rate3. new c1t, c3t. compress.  
--specify a linear regression model for the differenced data m2. model c3t = h0 + (h1) c1t + noise.  
-- estimation  
estim m2. hold resi(r2).  
-- compute residual acf.  
acf r2. maxl 10.  
--specify a regression model with time series errors.  
tsm m3. model c3t = g0 + (g1) c1t + (1) noise.  
-- estimate the model using the exact likelihood method.  
estim m3. method exact. hold resi(r3).  
-- compute residual acf.  
acf r3. maxl 10.  
-- refine the model to include more MA lags.  
tsm m4. model c3t = g0 + (g1) c1t + (1, 4, 6) noise.  
-- estimation  
estim m4. method exact. hold resi(r4).  
-- compute residual acf.  
acf r4. maxl 10.  
-- exit SCA  
stop 
```

# EXERCISES

If not specifically specified, use $5 \%$ significance level to draw conclusions in the exercises.

2.1. Suppose that the simple return of a monthly bond index follows the MA(1) model

$$
R _ {t} = a _ {t} + 0. 2 a _ {t - 1}, \quad \sigma_ {a} = 0. 0 2 5.
$$

Assume that $a _ { 1 0 0 } = 0 . 0 1$ . Compute the 1-step and 2-step ahead forecasts of the return at the forecast origin $t = 1 0 0$ . What are the standard deviations of the associated forecast errors? Also compute the lag-1 and lag-2 autocorrelations of the return series.

2.2. Suppose that the daily log return of a security follows the model

$$
r _ {t} = 0. 0 1 + 0. 2 r _ {t - 2} + a _ {t},
$$

where $\{ a _ { t } \}$ is a Gaussian white noise series with mean zero and variance 0.02. What are the mean and variance of the return series $r _ { t } ?$ Compute the lag-1 and lag-2 autocorrelations of $r _ { t }$ . Assume that $r _ { 1 0 0 } = - 0 . 0 1$ , and $r _ { 9 9 } = 0 . 0 2$ Compute the 1-step and 2-step ahead forecasts of the return series at the forecast origin $t = 1 0 0$ . What are the associated standard deviations of the forecast errors?

2.3. Consider the monthly U.S. unemployment rate from January 1951 to February 2004 in the file m-unemhelp.txt. The data are seasonally adjusted and obtained from the Federal Reserve Bank in St. Louis. Build a time series model for the series and use the model to forecast the unemployment rate for March, April, and May of 2004. In addition, compute the average period of business cycles if they exist. (Note that more than one model fit the data well. You only need an adequate model.)

2.4. Consider the monthly simple returns of the Decile 1, Decile 5, and Decile 10 of NYSE/AMEX/NASDAQ based on market capitalization. The data span is from January 1960 to December 2003, and the data are obtained from CRSP.

(a) For each return series, test the null hypothesis that the first 12 lags of autocorrelations are zero at the $5 \%$ level. Draw your conclusion.   
(b) Build an AR and an MA model for the series of Decile 5.   
(c) Use the AR and MA models built to produce 1-step to 3-step ahead forecasts of the series.

2.5. Consider the daily simple returns of IBM stock from 1962 to 2002 in the file d-ibmvwew6202.txt. Compute the first 100 lags of the ACF of the absolute daily simple returns of IBM stock. Is there evidence of long-range dependence? Why?

2.6. Consider the demand for electricity of a manufacturing sector in the United States. The data are logged, denote the demand of a fixed day of each month, and are in power6.txt. Build a time series model for the series and use the fitted model to produce 1-step to 24-step ahead forecasts.

2.7. Consider the daily simple return of CRSP equal-weighted index, including distributions, from January 1980 to December 1999 in file d-ew8099.txt (date, ew). Indicator variables for Mondays, Tuesdays, Wednesdays, and Thursdays are in the first four columns of wkdays8099.txt. Use a regression model to study the effects of trading days on the index return. What is the fitted model? Are the weekday effects significant in the returns at the $5 \%$ level? Use the HAC estimator of the covariance matrix to obtain the $t$ -ratio of regression estimates. Does it change the conclusion of weekday effect? Are there serial correlations in the regression residuals? If yes, build a regression model with time series error to study weekday effects.

2.8. As demonstrated by the prior exercise, daily returns of equal-weighted index have some weekday effects. How about daily returns of S&P composite index? To answer this question, consider the daily returns of S&P composite index from January 3, 2000 to December 31, 2003. The data are in the file d-dell3dx0003.txt, which has 12 columns. The first four columns are daily simple returns of Dell, vw, ew, and sp. Columns 5–9 are indicators for Monday to Friday, respectively. Columns 10–12 are year, month, and day. There are 1004 data points. Perform all tests using the $5 \%$ significance level, and answer the following questions:

(a) Is there a Friday effect on the daily simple returns of S&P composite index? You may employ a simple linear regression model to answer this question. Estimate the model and test the hypothesis that there is no Friday effect. Draw your conclusion.   
(b) Check the residual serial correlations using $Q ( 1 2 )$ statistic. Are there any significant serial correlations in the residuals?

2.9. Now consider similar questions of the previous exercise for individual stock returns. We use the daily simple returns of Dell stock in this exercise.

(a) Is there a Friday effect on the daily simple returns of Dell stock? Estimate your model and test the hypothesis that there is no Friday effect. Draw your conclusion.   
(b) Are there serial correlations in the residuals? Use $Q ( 1 2 )$ to perform the test. Draw your conclusion.   
(c) Refine the above model by using the technique of a regression model with time series errors. In there a significant Friday effect based on the refined model?

2.10. Consider the monthly yields of Moody’s AAA &BAA seasoned bonds from January 1919 to March 2004. The data are obtained from the Federal Reserve Bank in St. Louis. Monthly yields are averages of daily yields. Obtain the summary statistics (sample mean, standard deviation, skewness, excess kurtosis, minimum, and maximum) of the two yield series. Are the bond yields skewed? Do they have heavy tails? Answer the questions using $5 \%$ significance level.   
2.11. Consider the monthly AAA bond yields of the prior exercise. Build a time series model for the series.   
2.12. Again, consider the two bond yield series, that is, AAA and BAA. What is the relationship between the two series? To answer this question, build a time series model using yields of AAA bond as the dependent variable and yields of BAA bond as independent variable.   
2.13. Consider the monthly log returns of CRSP equal-weighted index from January 1962 to December 1999 for 456 observations. You may obtain the data from CRSP directly or from the file m-ew6299.txt on the Web.

(a) Build an AR model for the series and check the fitted model.   
(b) Build an MA model for the series and check the fitted model.   
(c) Compute 1-step and 2-step ahead forecasts of the AR and MA models built in the previous two questions.   
(d) Compare the fitted AR and MA models.

2.14. This problem is concerned with the dynamic relationship between the spot and futures prices of the S&P 500 index. The data file sp5may.dat has three columns: log(futures price), log(spot price), and cost-of-carry $( \times 1 0 0 )$ . The data were obtained from the Chicago Mercantile Exchange for the S&P 500 stock index in May 1993 and its June futures contract. The time interval is 1 minute (intraday). Several authors used the data to study index futures arbitrage. Here we focus on the first two columns. Let $f _ { t }$ and $s _ { t }$ be the log prices of futures and spot, respectively. Consider $y _ { t } = f _ { t } - f _ { t - 1 }$ and $x _ { t } = s _ { t } - s _ { t - 1 }$ . Build a regression model with time series errors between $\{ y _ { t } \}$ and $\{ x _ { t } \}$ , with $y _ { t }$ being the dependent variable.

2.15. The quarterly gross domestic product implicit price deflator is often used as a measure of inflation. The file q-gdpdef.dat contains the data for the United States from the first quarter of 1947 to the first quarter of 2004. Data format is year, month, and deflator. The data are seasonally adjusted and equal to 100 for year 2000. Build an ARIMA model for the series and check the validity of the fitted model. The data are obtained from the Federal Reserve Bank of St. Louis.

# REFERENCES

Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. In B.N. Petrov and F. Csaki (eds.), 2nd International Symposium on Information Theory, pp. 267–281. Akademia Kiado, Budapest.   
Box, G. E. P., Jenkins, G. M., and Reinsel, G. C. (1994). Time Series Analysis: Forecasting and Control, 3rd edition. Prentice Hall, Englewood Cliffs, NJ.   
Box, G. E. P. and Pierce, D. (1970). Distribution of residual autocorrelations in autoregressive-integrated moving average time series models. Journal of the American Statistical Association 65: 1509–1526.   
Brockwell, P. J. and Davis, R. A. (1991). Time Series: Theory and Methods, 2nd edition. Springer-Verlag, New York.   
Brockwell, P. J. and Davis, R. A. (1996). Introduction to Time Series and Forecasting. Springer, New York.   
Chan, N. H. and Wei, C. Z. (1988). Limiting distributions of least squares estimates of unstable autoregressive processes. Annals of Statistics 16: 367–401.   
Dickey, D. A. and Fuller, W. A. (1979). Distribution of the estimates for autoregressive time series with a unit root. Journal of the American Statistical Association, 74: 427–431.   
Ding, Z., Granger, C. W. J., and Engle, R. F. (1993). A long memory property of stock returns and a new model. Journal of Empirical Finance 1: 83–106.   
Eicker, F. (1967). Limit theorems for regression with unequal and dependent Errors. In L. LeCam and J. Neyman (eds.), Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability. University of California Press, Berkeley.   
Fuller, W. A. (1976). Introduction to Statistical Time Series. Wiley, New York.   
Greene, W. H. (2000). Econometric Analysis, 4th edition. Prentice-Hall, Upper Saddle River, NJ.   
Hosking, J. R. M. (1981). Fractional differencing. Biometrika 68: 165–176.   
Ljung, G. and Box, G. E. P. (1978). On a measure of lack of fit in time series models. Biometrika 66: 67–72.   
Newey, W. and West, K. (1987). A simple positive semidefinite, heteroscedasticity and autocorrelation consistent covariance matrix. Econometrica 55: 863–898.   
Phillips, P. C. B. (1987). Time series regression with a unit root. Econometrica 55: 277–301.   
Shumway, R. H. and Stoffer, D. S. (2000). Time Series Analysis and Its Applications. Springer-Velag, New York.   
Tiao, G. C. and Tsay, R. S. (1983). Consistency properties of least squares estimates of autoregressive parameters in ARMA models. Annals of Statistics 11: 856–871.   
Tsay, R. S. and Tiao, G. C. (1984). Consistent estimates of autoregressive parameters and extended sample autocorrelation function for stationary and nonstationary ARMA models. Journal of the American Statistical Association 79: 84–96.   
White, H. (1980). A heteroscedasticity consistent covariance matrix estimator and a direct test for heteroscedasticity. Econometrica 48: 827–838.

# Conditional Heteroscedastic Models

The objective of this chapter is to study some statistical methods and econometric models available in the literature for modeling the volatility of an asset return. The models are referred to as conditional heteroscedastic models.

Volatility is an important factor in options trading. Here volatility means the conditional standard deviation of the underlying asset return. Consider, for example, the price of a European call option, which is a contract giving its holder the right, but not the obligation, to buy a fixed number of shares of a specified common stock at a fixed price on a given date. The fixed price is called the strike price and is commonly denoted by $K$ . The given date is called the expiration date. The important time span here is the time to expiration, and we denote it by . The well-known Black–Scholes option pricing formula states that the price of such a call option is

$$
c _ {t} = P _ {t} \Phi (x) - K r ^ {- \ell} \Phi \left(x - \sigma_ {t} \sqrt {\ell}\right), \quad \text {a n d} \quad x = \frac {\ln \left(P _ {t} / K r ^ {- \ell}\right)}{\sigma_ {t} \sqrt {\ell}} + \frac {1}{2} \sigma_ {t} \sqrt {\ell}, \tag {3.1}
$$

where $P _ { t }$ is the current price of the underlying stock, $r$ is the risk-free interest rate, $\sigma _ { t }$ is the conditional standard deviation of the log return of the specified stock, and $\Phi ( x )$ is the cumulative distribution function of the standard normal random variable evaluated at $x$ . A derivation of the formula is given later in Chapter 6. The formula has several nice interpretations, but it suffices to say here that the conditional standard deviation $\sigma _ { t }$ of the log return of the underlying stock plays an important role. This volatility evolves over time and is the main topic of the chapter. If the option holder can exercise her right any time on or before the expiration date, then the option is called an American call option.

Volatility has many other financial applications. As discussed in Chapter 7, volatility modeling provides a simple approach to calculating value at risk of a financial position in risk management. It also plays an important role in asset allocation under the mean-variance framework. Furthermore, modeling the volatility of a time series can improve the efficiency in parameter estimation and the accuracy

in interval forecast. Finally, the volatility index of a market has recently become a financial instrument. The VIX volatility index compiled by the Chicago Board of Option Exchange (CBOE) started to trade in futures on March 26, 2004.

The univariate volatility models discussed in this chapter include the autoregressive conditional heteroscedastic (ARCH) model of Engle (1982), the generalized ARCH (GARCH) model of Bollerslev (1986), the exponential GARCH (EGARCH) model of Nelson (1991), the conditional heteroscedastic autoregressive movingaverage (CHARMA) model of Tsay (1987), the random coefficient autoregressive (RCA) model of Nicholls and Quinn (1982), and the stochastic volatility (SV) models of Melino and Turnbull (1990), Taylor (1994), Harvey, Ruiz, and Shephard (1994), and Jacquier, Polson, and Rossi (1994). We also discuss advantages and weaknesses of each volatility model and show some applications of the models. Multivariate volatility models, including those with time-varying correlations, are discussed in Chapter 10. The chapter also discusses some alternative approaches to volatility modeling in Section 3.15, including use of daily high and low prices of an asset.

# 3.1 CHARACTERISTICS OF VOLATILITY

A special feature of stock volatility is that it is not directly observable. For example, consider the daily log returns of IBM stock. The daily volatility is not directly observable from the return data because there is only one observation in a trading day. If intraday data of the stock, such as 10-minute returns, are available, then one can estimate the daily volatility. See Section 3.15. The accuracy of such an estimate deserves a careful study, however. For example, stock volatility consists of intraday volatility and overnight volatility with the latter denoting variation between trading days. The high-frequency intraday returns contain only very limited information about the overnight volatility. The unobservability of volatility makes it difficult to evaluate the forecasting performance of conditional heteroscedastic models. We discuss this issue later.

In options markets, if one accepts the idea that the prices are governed by an econometric model such as the Blac–Scholes formula, then one can use the price to obtain the “implied” volatility. Yet this approach is often criticized for using a specific model, which is based on some assumptions that might not hold in practice. For instance, from the observed prices of a European call option, one can use the Black–Scholes formula in Eq. (3.1) to deduce the conditional standard deviation $\sigma _ { t }$ . The resulting value of $\sigma _ { t }$ is called the implied volatility of the underlying stock. However, this implied volatility is derived under the assumption that the price of the underlying asset follows a geometric Brownian motion. It might be different from the actual volatility. Experience shows that implied volatility of an asset return tends to be larger than that obtained by using a GARCH type of volatility model. This might be due to the risk premium for volatility or to the way daily returns are calculated. The VIX of CBOE is an implied volatility.

Although volatility is not directly observable, it has some characteristics that are commonly seen in asset returns. First, there exist volatility clusters (i.e., volatility

may be high for certain time periods and low for other periods). Second, volatility evolves over time in a continuous manner—that is, volatility jumps are rare. Third, volatility does not diverge to infinity—that is, volatility varies within some fixed range. Statistically speaking, this means that volatility is often stationary. Fourth, volatility seems to react differently to a big price increase or a big price drop, referred to as the leverage effect. These properties play an important role in the development of volatility models. Some volatility models were proposed specifically to correct the weaknesses of the existing ones for their inability to capture the characteristics mentioned earlier. For example, the EGARCH model was developed to capture the asymmetry in volatility induced by big “positive” and “negative” asset returns.

# 3.2 STRUCTURE OF A MODEL

Let $r _ { t }$ be the log return of an asset at time index t. The basic idea behind volatility study is that the series $\{ r _ { t } \}$ is either serially uncorrelated or with minor lower order serial correlations, but it is a dependent series. For illustration, Figure 3.1 shows the ACF and PACF of some functions of the monthly log stock returns

![](images/d86970c0e818c87af7d1abb61788cce9d1efe51a4d902094fe7c3157ec5d4eed.jpg)

![](images/ef64a2ba3ec55d4e109e59a14c32a697ea3f04c529aea7d7c5b8c4f5dc573092.jpg)

![](images/2c127a8b5cbc6f81a063971083bea4872400d1a31e124366c01951e52ecfb401.jpg)

![](images/b399fe2285edd1112724ddb7e53fc4b90b7ee4a9d4e74a4d148be0e69fddb503.jpg)  
Figure 3.1. Sample ACF and PACF of various functions of monthly log stock returns of Intel Corporation from January 1973 to December 2003: (a) ACF of the log returns, (b) ACF of the squared returns, (c) ACF of the absolute returns, and (d) PACF of the squared returns.

of Intel Corporation from January 1973 to December 2003. Figure 3.1a shows the sample ACF of the return, which suggests no significant serial correlations except for a minor one at lag 7. Figure 3.1c shows the sample ACF of the absolute log returns (i.e., $| r _ { t } | )$ , whereas Figure 3.1b shows the sample ACF of the squared returns $r _ { t } ^ { 2 }$ . These two plots clearly suggest that the monthly returns are not serially independent. Combining the three plots, it seems that the returns are indeed serially uncorrelated, but dependent. Volatility models attempt to capture such dependence in the return series.

To put the volatility models in proper perspective, it is informative to consider the conditional mean and variance of $r _ { t }$ given $F _ { t - 1 }$ ; that is,

$$
\mu_ {t} = E \left(r _ {t} \mid F _ {t - 1}\right), \quad \sigma_ {t} ^ {2} = \operatorname {V a r} \left(r _ {t} \mid F _ {t - 1}\right) = E \left[ \left(r _ {t} - \mu_ {t}\right) ^ {2} \mid F _ {t - 1} \right], \tag {3.2}
$$

where $F _ { t - 1 }$ denotes the information set available at time $t - 1$ . Typically, $F _ { t - 1 }$ consists of all linear functions of the past returns. As shown by the empirical examples of Chapter 2 and Figure 3.1, serial dependence of a stock return series $r _ { t }$ is weak if it exists at all. Therefore, the equation for $\mu _ { t }$ in (3.2) should be simple, and we assume that $r _ { t }$ follows a simple time series model such as a stationary $\mathbf { A R M A } ( p , q )$ model with some explanatory variables. In other words, we entertain the model

$$
r _ {t} = \mu_ {t} + a _ {t}, \quad \mu_ {t} = \phi_ {0} + \sum_ {i = 1} ^ {k} \beta_ {i} x _ {i t} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {t - i} - \sum_ {i = 1} ^ {q} \theta_ {i} a _ {t - i}, \tag {3.3}
$$

for $r _ { t }$ , where $k$ , $p$ , and $q$ are non-negative integers, and $x _ { i t }$ are explanatory variables.

Model (3.3) illustrates a possible financial application of the linear time series models of Chapter 2. The order $( p , q )$ of an ARMA model may depend on the frequency of the return series. For example, daily returns of a market index often show some minor serial correlations, but monthly returns of the index may not contain any significant serial correlation. The explanatory variables $x _ { t }$ in Eq. (3.3) are flexible. For example, a dummy variable can be used for the Mondays to study the effect of weekend on daily stock returns. In the capital asset pricing model (CAPM), the mean equation of $r _ { t }$ can be written as $r _ { t } = \phi _ { 0 } + \beta r _ { m , t } + a _ { t }$ , where $r _ { m , t }$ denotes the market return.

Combining Eqs. (3.2) and (3.3), we have

$$
\sigma_ {t} ^ {2} = \operatorname {V a r} \left(r _ {t} \mid F _ {t - 1}\right) = \operatorname {V a r} \left(a _ {t} \mid F _ {t - 1}\right). \tag {3.4}
$$

The conditional heteroscedastic models of this chapter are concerned with the evolution of $\sigma _ { t } ^ { 2 }$ . The manner under which $\sigma _ { t } ^ { 2 }$ evolves over time distinguishes one volatility model from another.

Conditional heteroscedastic models can be classified into two general categories. Those in the first category use an exact function to govern the evolution of $\sigma _ { t } ^ { 2 }$ , whereas those in the second category use a stochastic equation to describe $\sigma _ { t } ^ { 2 }$ . The GARCH model belongs to the first category whereas the stochastic volatility model is in the second category.

Throughout the book, $a _ { t }$ is referred to as the shock or innovation of an asset return at time $t$ and $\sigma _ { t }$ is the positive square root of $\sigma _ { t } ^ { 2 }$ . The model for $\mu _ { t }$ in Eq. (3.3) is referred to as the mean equation for $r _ { t }$ and the model for $\sigma _ { t } ^ { 2 }$ is the volatility equation for $r _ { t }$ . Therefore, modeling conditional heteroscedasticity amounts to augmenting a dynamic equation, which governs the time evolution of the conditional variance of the asset return, to a time series model.

# 3.3 MODEL BUILDING

Building a volatility model for an asset return series consists of four steps:

1. Specify a mean equation by testing for serial dependence in the data and, if necessary, building an econometric model (e.g., an ARMA model) for the return series to remove any linear dependence.   
2. Use the residuals of the mean equation to test for ARCH effects.   
3. Specify a volatility model if ARCH effects are statistically significant and perform a joint estimation of the mean and volatility equations.   
4. Check the fitted model carefully and refine it if necessary.

For most asset return series, the serial correlations are weak, if any. Thus, building a mean equation amounts to removing the sample mean from the data if the sample mean is significantly different from zero. For some daily return series, a simple AR model might be needed. In some cases, the mean equation may employ some explanatory variables such as an indicator variable for weekend or January effects.

In what follows, we use S-Plus in empirical illustrations. Other software packages (e.g., Eviews, SCA, R, and RATS) can also be used.

# 3.3.1 Testing for ARCH Effect

For ease in notation, let $a _ { t } = r _ { t } - \mu _ { t }$ be the residuals of the mean equation. The squared series $a _ { t } ^ { 2 }$ is then used to check for conditional heteroscedasticity, which is also known as the ARCH effects. Two tests are available. The first test is to apply the usual Ljung–Box statistics $Q ( m )$ to the $\{ a _ { t } ^ { 2 } \}$ series; see McLeod and Li (1983). The null hypothesis is that the first $m$ lags of ACF of the $a _ { t } ^ { 2 }$ series are zero. The second test for conditional heteroscedasticity is the Lagrange multiplier test of Engle (1982). This test is equivalent to the usual $F$ statistic for testing $\alpha _ { i } = 0$ $( i = 1 , \ldots , m )$ in the linear regression

$$
a _ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \dots + \alpha_ {m} a _ {t - m} ^ {2} + e _ {t}, \quad t = m + 1, \ldots , T,
$$

where $e _ { t }$ denotes the error term, m is a prespecified positive integer, and $T$ is the sample size. Specifically, the null hypothesis is $H _ { o } \colon \alpha _ { 1 } = \cdot \cdot \cdot = \alpha _ { m } = 0$ . Let $\begin{array} { r } { S S R _ { 0 } = \mathbf { \bar { \rho } } { \bf \bar { \rho } } _ { t = m + 1 } ( a _ { t } ^ { \bar { 2 } } - \overline { { \omega } } ) ^ { 2 } } \end{array}$ , where $\begin{array} { r } { \overline { { \omega } } = ( \bar { 1 / T } T ) \sum _ { t = 1 } ^ { T } a _ { t } ^ { 2 } } \end{array}$ is the sample mean of $a _ { t } ^ { 2 }$ ,

and $\begin{array} { r } { S S R _ { 1 } = \sum _ { t = m + 1 } ^ { T } \hat { e } _ { t } ^ { 2 } } \end{array}$ , where $\hat { \boldsymbol { e } } _ { t }$ is the least squares residual of the prior linear

$$
F = \frac {\left(S S R _ {0} - S S R _ {1}\right) / m}{S S R _ {1} / (T - 2 m - 1)},
$$

which is asymptotically distributed as a chi-squared distribution with m degrees of freedom under the null hypothesis. The decision rule is to reject the null hypothesis if $F > \chi _ { m } ^ { 2 } ( \alpha )$ , where $\chi _ { m } ^ { 2 } ( \alpha )$ is the upper $1 0 0 ( 1 - \alpha ) \mathfrak { t }$ h percentile of $\chi _ { m } ^ { 2 }$ , or the $p$ -value of $F$ is less than $\alpha$ .

To demonstrate, we consider the monthly log stock returns of Intel Corporation from 1973 to 2003; see Example 3.1 below. The series does not have significant serial correlations so that it can be directly used to test for the ARCH effect. Indeed, the $Q ( m )$ statistics of the return series give $Q ( 1 2 ) = 1 8 . 5 7$ with $p$ -value 0.10, confirming no serial correlations in the data. On the other hand, the Lagrange multiplier test shows strong ARCH effects with test statistic $F \approx 4 3 . 5$ , the $p$ -value of which is close to zero.

# S-Plus Demonstration

Denote the return series by intc. Note that the command archTest applies directly to the $a _ { t }$ series, not to $a _ { t } ^ { 2 }$ .

```txt
> autocorTest(intc,lag=12)  
Test for Autocorrelation: Ljung-Box  
Null Hypothesis: no autocorrelation 
```

```txt
Test Statistics: Test Stat 18.5664 p.value 0.0995 
```

```txt
Dist. under Null: chi-square with 12 degrees of freedom  
Total Observ.: 372 
```

```txt
> archTest(intc, lag=12)  
Test for ARCH Effects: LM Test  
Null Hypothesis: no ARCH effects 
```

```txt
Test Statistics: Test Stat 43.5041 p.value 0.0000 
```

```txt
Dist. under Null: chi-square with 12 degrees of freedom 
```

# 3.4 THE ARCH MODEL

The first model that provides a systematic framework for volatility modeling is the ARCH model of Engle (1982). The basic idea of ARCH models is that (a) the shock $a _ { t }$ of an asset return is serially uncorrelated, but dependent, and (b) the

dependence of $a _ { t }$ can be described by a simple quadratic function of its lagged values. Specifically, an $\mathrm { A R C H } ( m )$ model assumes that

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \dots + \alpha_ {m} a _ {t - m} ^ {2}, \tag {3.5}
$$

where $\{ \epsilon _ { t } \}$ is a sequence of independent and identically distributed (iid) random variables with mean zero and variance 1, $\alpha _ { 0 } > 0$ , and $\alpha _ { i } \geq 0$ for $i > 0$ . The coefficients $\alpha _ { i }$ must satisfy some regularity conditions to ensure that the unconditional variance of $a _ { t }$ is finite. In practice, $\epsilon _ { t }$ is often assumed to follow the standard normal or a standardized Student- $\cdot t$ distribution or a generalized error distribution.

From the structure of the model, it is seen that large past squared shocks $\{ a _ { t - i } ^ { 2 } \} _ { i = 1 } ^ { m }$ imply a large conditional variance $\sigma _ { t } ^ { 2 }$ for the innovation $a _ { t }$ . Consequently, $a _ { t }$ tends to assume a large value (in modulus). This means that, under the ARCH framework, large shocks tend to be followed by another large shock. Here I use the word tend because a large variance does not necessarily produce a large realization. It only says that the probability of obtaining a large variate is greater than that of a smaller variance. This feature is similar to the volatility clusterings observed in asset returns.

The ARCH effect also occurs in other financial time series. Figure 3.2 shows the time plots of (a) the percentage changes in Deutsche mark/U.S. dollar exchange rate measured in 10-minute intervals from June 5, 1989 to June 19, 1989 for 2488

![](images/5bf2d8d3753462d7365547734399584e7416e8582d7132f6e19c4eaecb27bd21.jpg)

![](images/d367c445e76c479ca152367a24c53b197ec657ad26e8cd408657697171bd4b9b.jpg)  
(b) Squared series   
Figure 3.2. (a) Time plot of 10-minute returns of the exchange rate between Deutsche mark and U.S. dollar and (b) the squared returns.

![](images/49051b86b3d1bcdc68f2d1fff9b67a8efda8d1343b101491e54e4e7a2334b6b6.jpg)

![](images/a0d1ac2f4adbb9f9d6d5d76b8aa79270360f2372b3d7bd11a9acdc54b1ccf7d7.jpg)  
Figure 3.3. (a) Sample autocorrelation function of the return series of mark/dollar exchange rate and (b) sample partial autocorrelation function of the squared returns.

observations, and (b) the squared series of the percentage changes. Big percentage changes occurred occasionally, but there were certain stable periods. Figure 3.3a shows the sample ACF of the percentage change series. Clearly, the series has no serial correlation. Figure 3.3b shows the sample PACF of the squared series of percentage change. It is seen that there are some big spikes in the PACF. Such spikes suggest that the percentage changes are not serially independent and have some ARCH effects.

Remark. Some authors use $h _ { t }$ to denote the conditional variance in Eq. (3.5). In this case, the shock becomes $a _ { t } = \sqrt { h _ { t } } \epsilon _ { t }$ . 

# 3.4.1 Properties of ARCH Models

To understand the ARCH models, it pays to carefully study the ARCH(1) model

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2},
$$

where $\alpha _ { 0 } > 0$ and $\alpha _ { 1 } \geq 0$ . First, the unconditional mean of $a _ { t }$ remains zero because

$$
E \left(a _ {t}\right) = E \left[ E \left(a _ {t} \mid F _ {t - 1}\right) \right] = E \left[ \sigma_ {t} E \left(\epsilon_ {t}\right) \right] = 0.
$$

Second, the unconditional variance of $a _ { t }$ can be obtained as

$$
\begin{array}{l} \operatorname {V a r} \left(a _ {t}\right) = E \left(a _ {t} ^ {2}\right) = E \left[ E \left(a _ {t} ^ {2} \mid F _ {t - 1}\right) \right] \\ = E \left(\alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2}\right) = \alpha_ {0} + \alpha_ {1} E \left(a _ {t - 1} ^ {2}\right). \\ \end{array}
$$

Because $a _ { t }$ is a stationary process with $E ( a _ { t } ) = 0$ , $\mathrm { V a r } ( a _ { t } ) = \mathrm { V a r } ( a _ { t - 1 } ) = E ( a _ { t - 1 } ^ { 2 } )$ . Therefore, we have $\mathrm { V a r } ( a _ { t } ) = \alpha _ { 0 } + \alpha _ { 1 } \mathrm { V a r } ( a _ { t } )$ and $\mathrm { V a r } ( a _ { t } ) = \alpha _ { 0 } / ( 1 - \alpha _ { 1 } )$ −. Since the variance of $a _ { t }$ must be positive, we require $0 \leq \alpha _ { 1 } < 1$ . Third, in some applications, we need higher order moments of $a _ { t }$ to exist and, hence, $\alpha _ { 1 }$ must also satisfy some additional constraints. For instance, to study its tail behavior, we require that the fourth moment of $a _ { t }$ is finite. Under the normality assumption of $\epsilon _ { t }$ in Eq. (3.5), we have

$$
E \left(a _ {t} ^ {4} \mid F _ {t - 1}\right) = 3 \left[ E \left(a _ {t} ^ {2} \mid F _ {t - 1}\right) \right] ^ {2} = 3 \left(\alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2}\right) ^ {2}.
$$

Therefore,

$$
E \left(a _ {t} ^ {4}\right) = E \left[ E \left(a _ {t} ^ {4} \mid F _ {t - 1}\right) \right] = 3 E \left(\alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2}\right) ^ {2} = 3 E \left(\alpha_ {0} ^ {2} + 2 \alpha_ {0} \alpha_ {1} a _ {t - 1} ^ {2} + \alpha_ {1} ^ {2} a _ {t - 1} ^ {4}\right).
$$

If $a _ { t }$ is fourth-order stationary with $m _ { 4 } = E ( a _ { t } ^ { 4 } )$ , then we have

$$
\begin{array}{l} m _ {4} = 3 \left[ \alpha_ {0} ^ {2} + 2 \alpha_ {0} \alpha_ {1} \operatorname {V a r} \left(a _ {t}\right) + \alpha_ {1} ^ {2} m _ {4} \right] \\ = 3 \alpha_ {0} ^ {2} \left(1 + 2 \frac {\alpha_ {1}}{1 - \alpha_ {1}}\right) + 3 \alpha_ {1} ^ {2} m _ {4}. \\ \end{array}
$$

Consequently,

$$
m _ {4} = \frac {3 \alpha_ {0} ^ {2} (1 + \alpha_ {1})}{(1 - \alpha_ {1}) (1 - 3 \alpha_ {1} ^ {2})}.
$$

This result has two important implications: (a) since the fourth moment of $a _ { t }$ is positive, we see that $\alpha _ { 1 }$ must also satisfy the condition $1 - 3 \alpha _ { 1 } ^ { 2 } > 0$ ; that is, $\begin{array} { r } { 0 \leq \alpha _ { 1 } ^ { 2 } < \frac { 1 } { 3 } } \end{array}$ ; and (b) the unconditional kurtosis of $a _ { t }$ is

$$
\frac {E (a _ {t} ^ {4})}{[ \mathrm {V a r} (a _ {t}) ] ^ {2}} = 3 \frac {\alpha_ {0} ^ {2} (1 + \alpha_ {1})}{(1 - \alpha_ {1}) (1 - 3 \alpha_ {1} ^ {2})} \times \frac {(1 - \alpha_ {1}) ^ {2}}{\alpha_ {0} ^ {2}} = 3 \frac {1 - \alpha_ {1} ^ {2}}{1 - 3 \alpha_ {1} ^ {2}} > 3.
$$

Thus, the excess kurtosis of $a _ { t }$ is positive and the tail distribution of $a _ { t }$ is heavier than that of a normal distribution. In other words, the shock $a _ { t }$ of a conditional Gaussian ARCH(1) model is more likely than a Gaussian white noise series to produce “outliers.” This is in agreement with the empirical finding that “outliers” appear more often in asset returns than that implied by an iid sequence of normal random variates.

These properties continue to hold for general ARCH models, but the formulas become more complicated for higher order ARCH models. The condition $\alpha _ { i } \geq 0$ in Eq. (3.5) can be relaxed. It is a condition to ensure that the conditional variance $\sigma _ { t } ^ { 2 }$

is positive for all $t$ . In fact, a natural way to achieve positiveness of the conditional variance is to rewrite an $\mathrm { A R C H } ( m )$ model as

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + A _ {m, t - 1} ^ {\prime} \Omega A _ {m, t - 1}, \tag {3.6}
$$

where $A _ { m , t - 1 } = ( a _ { t - 1 } , \ldots , a _ { t - m } ) ^ { \prime }$ and $\Omega$ is an $m \times m$ non-negative definite matrix. The $\operatorname { A R C H } ( m )$ model in Eq. (3.5) requires $\Omega$ to be diagonal. Thus, Engle’s model uses a parsimonious approach to approximate a quadratic function. A simple way to achieve Eq. (3.6) is to employ a random-coefficient model for $a _ { t }$ ; see the CHARMA and RCA models discussed later.

# 3.4.2 Weaknesses of ARCH Models

The advantages of ARCH models include properties discussed in the previous subsection. The model also has some weaknesses:

1. The model assumes that positive and negative shocks have the same effects on volatility because it depends on the square of the previous shocks. In practice, it is well known that price of a financial asset responds differently to positive and negative shocks.   
2. The ARCH model is rather restrictive. For instance, $\alpha _ { 1 } ^ { 2 }$ of an ARCH(1) model must be in the interval [0, $\textstyle { \frac { 1 } { 3 } } ]$ if the series has a finite fourth moment. The constraint becomes complicated for higher order ARCH models. In practice, it limits the ability of ARCH models with Gaussian innovations to capture excess kurtosis.   
3. The ARCH model does not provide any new insight for understanding the source of variations of a financial time series. It merely provides a mechanical way to describe the behavior of the conditional variance. It gives no indication about what causes such behavior to occur.   
4. ARCH models are likely to overpredict the volatility because they respond slowly to large isolated shocks to the return series.

# 3.4.3 Building an ARCH Model

Among volatility models, specifying an ARCH model is relatively easy. Details are given below.

# Order Determination

If an ARCH effect is found to be significant, one can use the PACF of $a _ { t } ^ { 2 }$ to determine the ARCH order. Using PACF of $a _ { t } ^ { 2 }$ to select the ARCH order can be justified as follows. From the model in Eq. (3.5), we have

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \dots + \alpha_ {m} a _ {t - m} ^ {2}.
$$

For a given sample, $a _ { t } ^ { 2 }$ is an unbiased estimate of $\sigma _ { t } ^ { 2 }$ . Therefore, we expect that $a _ { t } ^ { 2 }$ is linearly related to $a _ { t - 1 } ^ { 2 } , \ldots , a _ { t - m } ^ { 2 }$ in a manner similar to that of an autoregressive

model of order m. Note that a single $a _ { t } ^ { 2 }$ is generally not an efficient estimate of $\sigma _ { t } ^ { 2 }$ , but it can serve as an approximation that could be informative in specifying the order $m$ .

Alternatively, define $\eta _ { t } = a _ { t } ^ { 2 } - \sigma _ { t } ^ { 2 }$ . It can be shown that $\{ \eta _ { t } \}$ is an un-correlated series with mean 0. The ARCH model then becomes

$$
a _ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \dots + \alpha_ {m} a _ {t - m} ^ {2} + \eta_ {t},
$$

which is in the form of an $\operatorname { A R } ( m )$ model for $a _ { t } ^ { 2 }$ , except that $\{ \eta _ { t } \}$ is not an iid series. From Chapter 2, PACF of $a _ { t } ^ { 2 }$ is a useful tool to determine the order m. Because $\{ \eta _ { t } \}$ are not identically distributed, the least squares estimates of the prior model are consistent, but not efficient. The PACF of $a _ { t } ^ { 2 }$ may not be effective when the sample size is small.

# Estimation

Three likelihood functions are commonly used in ARCH estimation. Under the normality assumption, the likelihood function of an ARCH(m) model is

$$
\begin{array}{l} f \left(a _ {1}, \dots , a _ {T} \mid \alpha\right) = f \left(a _ {T} \mid F _ {T - 1}\right) f \left(a _ {T - 1} \mid F _ {T - 2}\right) \dots f \left(a _ {m + 1} \mid F _ {m}\right) f \left(a _ {1}, \dots , a _ {m} \mid \alpha\right) \\ = \prod_ {t = m + 1} ^ {T} \frac {1}{\sqrt {2 \pi \sigma_ {t} ^ {2}}} \exp \left(- \frac {a _ {t} ^ {2}}{2 \sigma_ {t} ^ {2}}\right) \times f (a _ {1}, \dots , a _ {m} | \boldsymbol {\alpha}), \\ \end{array}
$$

where ${ \pmb { \alpha } } = ( \alpha _ { 0 } , \alpha _ { 1 } , \dots , \alpha _ { m } ) ^ { \prime }$ and $f ( a _ { 1 } , \ldots , a _ { m } | \pmb { \alpha } )$ is the joint probability density function of $a _ { 1 } , \ldots , a _ { m } .$ $a _ { m }$ . Since the exact form of $f ( a _ { 1 } , \ldots , a _ { m } | \pmb { \alpha } )$ is complicated, it is commonly dropped from the prior likelihood function, especially when the sample size is sufficiently large. This results in using the conditional likelihood function

$$
f (a _ {m + 1}, \dots , a _ {T} | \boldsymbol {\alpha}, a _ {1}, \dots , a _ {m}) = \prod_ {t = m + 1} ^ {T} \frac {1}{\sqrt {2 \pi \sigma_ {t} ^ {2}}} \exp \left(- \frac {a _ {t} ^ {2}}{2 \sigma_ {t} ^ {2}}\right),
$$

where $\sigma _ { t } ^ { 2 }$ can be evaluated recursively. We refer to estimates obtained by maximizing the prior likelihood function as the conditional maximum likelihood estimates (MLEs) under normality.

Maximizing the conditional likelihood function is equivalent to maximizing its logarithm, which is easier to handle. The conditional log likelihood function is

$$
\ell (a _ {m + 1}, \dots , a _ {T} | \boldsymbol {\alpha}, a _ {1}, \dots , a _ {m}) = \sum_ {t = m + 1} ^ {T} \left(- \frac {1}{2} \ln (2 \pi) - \frac {1}{2} \ln (\sigma_ {t} ^ {2}) - \frac {1}{2} \frac {a _ {t} ^ {2}}{\sigma_ {t} ^ {2}}\right).
$$

Since the first term $\ln ( 2 \pi )$ does not involve any parameters, the log likelihood function becomes

$$
\ell (a _ {m + 1}, \ldots , a _ {T} | \boldsymbol {\alpha}, a _ {1}, \ldots , a _ {m}) = - \sum_ {t = m + 1} ^ {T} \left(\frac {1}{2} \ln (\sigma_ {t} ^ {2}) + \frac {1}{2} \frac {a _ {t} ^ {2}}{\sigma_ {t} ^ {2}}\right),
$$

where $\sigma _ { t } ^ { 2 } = \alpha _ { 0 } + \alpha _ { 1 } a _ { t - 1 } ^ { 2 } + \cdot \cdot \cdot + \alpha _ { m } a _ { t - m } ^ { 2 }$ can be evaluated recursively.

In some applications, it is more appropriate to assume that $\epsilon _ { t }$ follows a heavytailed distribution such as a standardized Student-t distribution. Let $x _ { v }$ be a Student-$t$ distribution with $v$ degrees of freedom. Then $\mathrm { V a r } ( x _ { v } ) = v / ( v - 2 )$ for $v > 2$ , and we use $\epsilon _ { t } = x _ { v } / \sqrt { v / ( v - 2 ) }$ . The probability density function of $\epsilon _ { t }$ is

$$
f \left(\epsilon_ {t} | v\right) = \frac {\Gamma \left((v + 1) / 2\right)}{\Gamma (v / 2) \sqrt {(v - 2) \pi}} \left(1 + \frac {\epsilon_ {t} ^ {2}}{v - 2}\right) ^ {- (v + 1) / 2}, \quad v > 2, \tag {3.7}
$$

where $\Gamma ( x )$ is the usual gamma function (i.e., $\begin{array} { r } { \Gamma ( x ) = \int _ { 0 } ^ { \infty } y ^ { x - 1 } e ^ { - y } d y ) } \end{array}$ . Using $a _ { t } = \sigma _ { t } \epsilon _ { t }$ , we obtain the conditional likelihood function of $a _ { t }$ as

$$
f (a _ {m + 1}, \ldots , a _ {T} | \boldsymbol {\alpha}, A _ {m}) = \prod_ {t = m + 1} ^ {T} \frac {\Gamma ((v + 1) / 2)}{\Gamma (v / 2) \sqrt {(v - 2) \pi}} \frac {1}{\sigma_ {t}} \left(1 + \frac {a _ {t} ^ {2}}{(v - 2) \sigma_ {t} ^ {2}}\right) ^ {- (v + 1) / 2},
$$

where $v > 2$ and $A _ { m } = ( a _ { 1 } , a _ { 2 } , \ldots , a _ { m } )$ . We refer to the estimates that maximize the prior likelihood function as the conditional MLEs under $t$ -distribution. The degrees of freedom of the $t$ -distribution can be specified a priori or estimated jointly with other parameters. A value between 3 and 6 is often used if it is prespecified.

If the degrees of freedom $v$ of the Student- $\mathbf { \nabla } \cdot \mathbf { \boldsymbol { t } }$ distribution is prespecified, then the conditional log likelihood function is

$$
\ell \left(a _ {m + 1}, \dots , a _ {T} \mid \boldsymbol {\alpha}, A _ {m}\right) = - \sum_ {t = m + 1} ^ {T} \left[ \frac {v + 1}{2} \ln \left(1 + \frac {a _ {t} ^ {2}}{(v - 2) \sigma_ {t} ^ {2}}\right) + \frac {1}{2} \ln \left(\sigma_ {t} ^ {2}\right) \right]. \tag {3.8}
$$

If one wishes to estimate $v$ jointly with other parameters, then the log likelihood function becomes

$$
\begin{array}{l} \ell \left(a _ {m + 1}, \dots , a _ {T} \mid \alpha , v, A _ {m}\right) \\ = (T - m) \left[ \ln (\Gamma ((v + 1) / 2)) - \ln (\Gamma (v / 2)) - 0. 5 \ln ((v - 2) \pi) \right] \\ + \ell \left(a _ {m + 1}, \dots , a _ {T} \mid \alpha , A _ {m}\right), \\ \end{array}
$$

where the second term is given in Eq. (3.8).

Finally, $\epsilon _ { t }$ may assume a generalized error distribution (GED) with probability density function

$$
f (x) = \frac {v \exp \left(- \frac {1}{2} | x / \lambda | ^ {v}\right)}{\lambda 2 ^ {(1 + 1 / v)} \Gamma (1 / v)}, \quad - \infty <   x <   \infty , \quad 0 <   v \leq \infty , \tag {3.9}
$$

where $\Gamma ( . )$ is the gamma function and

$$
\lambda = [ 2 ^ {(- 2 / v)} \Gamma (1 / v) / \Gamma (3 / v) ] ^ {1 / 2}.
$$

This distribution reduces to a Gaussian distribution if $v = 2$ and it has heavy tails when $v < 2$ . The conditional log likelihood function $\ell ( a _ { m + 1 } , \ldots , a _ { T } | \pmb { \alpha } , \pmb { A } _ { m } )$ can easily be obtained.

# Model Checking

For a properly specified ARCH model, the standardized residuals

$$
\tilde {a} _ {t} = \frac {a _ {t}}{\sigma_ {t}}
$$

form a sequence of iid random variables. Therefore, one can check the adequacy of a fitted ARCH model by examining the series $\{ \tilde { a } _ { t } \}$ . In particular, the Ljung–Box statistics of $\tilde { a } _ { t }$ can be used to check the adequacy of the mean equation and that of $\tilde { a } _ { t } ^ { 2 }$ can be used to test the validity of the volatility equation. The skewness, kurtosis, and quantile-to-quantile plot (i.e., QQ-plot) of $\{ \tilde { a } _ { t } \}$ can be used to check the validity of the distribution assumption. Many residual plots are available in S-Plus for model checking.

# Forecasting

Forecasts of the ARCH model in Eq. (3.5) can be obtained recursively as those of an AR model. Coahead forecast of er an ARCH(m) model. At the forecast origin is $h$ , the 1-step $\sigma _ { h + 1 } ^ { 2 }$

$$
\sigma_ {h} ^ {2} (1) = \alpha_ {0} + \alpha_ {1} a _ {h} ^ {2} + \dots + \alpha_ {m} a _ {h + 1 - m} ^ {2}.
$$

The 2-step ahead forecast is

$$
\sigma_ {h} ^ {2} (2) = \alpha_ {0} + \alpha_ {1} \sigma_ {h} ^ {2} (1) + \alpha_ {2} a _ {h} ^ {2} + \dots + \alpha_ {m} a _ {h + 2 - m} ^ {2},
$$

and the $\ell$ -step ahead forecast for $\sigma _ { h + \ell } ^ { 2 }$

$$
\sigma_ {h} ^ {2} (\ell) = \alpha_ {0} + \sum_ {i = 1} ^ {m} \alpha_ {i} \sigma_ {h} ^ {2} (\ell - i), \tag {3.10}
$$

where $\sigma _ { h } ^ { 2 } ( \ell - i ) = a _ { h + \ell - i } ^ { 2 }$ if $\ell - i \leq 0$ .

# 3.4.4 Some Examples

In this subsection, we illustrate ARCH modeling by considering two examples.

Example 3.1. We first apply the modeling procedure to build a simple ARCH model for the monthly log returns of Intel stock. The sample ACF and PACF of the squared returns in Figure 3.1 clearly show the existence of conditional heteroscedasticity. This is confirmed by the ARCH effect test shown in Section 3.3.1, and we proceed to identify the order of an ARCH model. The sample PACF in Figure 3.1d indicates that an ARCH(3) model might be appropriate. Consequently, we specify the model

$$
r _ {t} = \mu + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \alpha_ {2} a _ {t - 2} ^ {2} + \alpha_ {3} a _ {t - 3} ^ {2}
$$

for the monthly log returns of Intel stock. Assuming that $\epsilon _ { t }$ are iid standard normal, we obtain the fitted model

$$
r _ {t} = 0. 0 1 7 1 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 1 2 0 + 0. 1 7 8 7 a _ {t - 1} ^ {2} + 0. 0 7 7 2 a _ {t - 2} ^ {2} + 0. 0 5 7 2 a _ {t - 3} ^ {2},
$$

where the standard errors of the parameters are 0.0066, 0.0011, 0.0803, 0.0506, and 0.0769, respectively; see the output below. While the estimates meet the general requirement of an ARCH(3) model, the estimates of $\alpha _ { 2 }$ and $\alpha _ { 3 }$ appear to be statistically nonsignificant at the $5 \%$ level. Therefore, the model can be simplified.

# S-Plus Demonstration

Output edited and $\%$ marks explanation.

```txt
> arch3.fit=garch(intc~1,~garch(3,0))  
> summary(arch3.fit)  
Call:  
garch(formula.mean = intc ~ 1, formula.var = ~ garch(3, 0)) 
```

Estimated Coefficients:   
```txt
Mean Equation: intc ~ 1  
Conditional Variance Equation: ~ garch(3, 0)  
Conditional Distribution: gaussian 
```

Value Std.Error t value $\mathsf{Pr}(|t|)$ C 0.01713 0.006626 2.5860 0.005047 % one-sided A 0.01199 0.001107 10.8325 0.000000 % p-value ARCH(1) 0.17874 0.080294 2.2260 0.013309 ARCH(2) 0.07720 0.050552 1.5271 0.063800 ARCH(3) 0.05722 0.076928 0.7438 0.228747

```matlab
> arch1=garch(intc~1,~garch(1,0)) % A simplified model  
> summary(arch1)  
Call:  
    garch(formula.mean = intc ~ 1, formula.var = ~ garch(1,0)) 
```

```txt
Mean Equation: intc ~ 1  
Conditional Variance Equation: ~ garch(1, 0)  
Conditional Distribution: gaussian 
```

Estimated Coefficients:   
Value Std.Error t value $\mathsf{Pr}(|t|)$ C 0.01741 0.006231 2.794 2.737e-03 A 0.01258 0.001246 10.091 0.000e+00 ARCH(1) 0.35258 0.088515 3.983 4.094e-05

```txt
> stdresi=arch1\$residuals/arch1\$sigma.t % Standardized
> autocorTest(stdresi,lag=10) % residuals 
```

Null Hypothesis: no autocorrelation

Test Statistics:

Test Stat 13.7820 p.value 0.1832

Dist. under Null: chi-square with 10 degrees of freedom

> archTest(stdresi,lag ${ \ o } = \beth 0$ ) % ARCH test for residuals

Null Hypothesis: no ARCH effects

Test Statistics:

Test Stat 11.3793 p.value 0.3287

Dist. under Null: chi-square with 10 degrees of freedom

> arch1$asymp.sd % Obtain unconditional variance

[1] 0.1393796

> plot(arch1) % Obtain various plots, including the

% fitted volatility series.

Dropping the two nonsignificant parameters, we obtain the model

$$
r _ {t} = 0. 0 1 7 4 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 1 2 6 + 0. 3 5 2 6 a _ {t - 1} ^ {2}, \tag {3.11}
$$

where the standard errors of the parameters are 0.0062, 0.0012, and 0.0885, respectively. All the estimates are highly significant. Figure 3.4 shows the standardized residuals $\{ \tilde { a } _ { t } \}$ and the sample ACF of some functions of $\{ \tilde { a } _ { t } \}$ . The Ljung–Box statistics of standardized residuals give $Q ( 1 0 ) = 1 3 . 7 8 $ with $p$ -value 0.18 and those of $\{ \tilde { a } _ { t } ^ { 2 } \}$ give $Q ( 1 0 ) = 1 1 . 3 8 $ with $p$ -value 0.33. See the output. Consequently, the ARCH(1) model in Eq. (3.11) is adequate for describing the conditional heteroscedasticity of the data at the $5 \%$ significance level.

The ARCH(1) model in Eq. (3.11) has some interesting properties. First, the expected monthly log return for Intel stock is about $1 . 7 4 \%$ , which is remarkable, especially since the sample includes the period after the Internet bubble. Second, $\begin{array} { r } { \hat { \alpha } _ { 1 } ^ { 2 } = 0 . 3 5 3 ^ { 2 } < \frac { 1 } { 3 } } \end{array}$ so that the unconditional fourth moment of the monthly log return of Intel stock exists. Third, the unconditional standard deviation of $r _ { t }$ is $\sqrt { 0 . 0 1 2 6 / ( 1 - 0 . 3 5 2 ) } = 0 . 1 3 9 4$ . Finally, the ARCH(1) model can be used to predict the monthly volatility of Intel stock returns.

# t Innovation

For comparison, we also fit an ARCH(1) model with Student-t innovations to the series. The resulting model is

$$
r _ {t} = 0. 0 2 2 1 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 1 3 4 + 0. 2 4 9 2 a _ {t - 1} ^ {2}, \tag {3.12}
$$

where standard errors of the parameters are 0.0060, 0.0020, and 0.1156, respectively. The estimated degrees of freedom is 6.16 with standard error 1.65. All the estimates are significant at the $5 \%$ level, but the $t$ -ratio of $\hat { \alpha } _ { 1 }$ is only 2.16. The unconditional standard deviation of $a _ { t }$ is $\sqrt { 0 . 0 1 3 4 / ( 1 - 0 . 2 4 9 2 ) } = 0 . 1 3 3 6$ , which

![](images/3d31592e794a580f4fc799775b346fd61cda98c944afcb313e885786ddf2a14a.jpg)

![](images/1b6febf39cdabbb48596952de4f69e7a269572ad5fc66d0548656b828636bc48.jpg)

![](images/5600be2e05be0324e958bd05e910bb7077d718e516f78a3752e99068d001e04e.jpg)

![](images/84b022e43bb0aa87bd7b06fc0f8db38ffb6ec30734bdadcaeff343dfaa40ebaa.jpg)  
Figure 3.4. Model checking statistics of the Gaussian ARCH(1) model in Eq. (3.11) for the monthly log returns of Intel stock from January 1973 to December 2003: parts (a), (b), and (c) show the sample ACF of the standardized residuals, their squared series, and absolute series, respectively; part (d) is the time plot of standardized residuals.

is close to that obtained under normality. The Ljung–Box statistics of the standardized residuals give $Q ( 1 2 ) = 1 6 . 1 $ with $p$ -value 0.19, confirming that the mean equation is adequate. However, the Ljung–Box statistics for the squared standardized residuals show $Q ( 1 2 ) = 2 9 . 9 1 $ with $p$ -value 0.0029. The volatility equation is inadequate at the $5 \%$ level. Further analysis shows that the Lagrange multiplier test gives $Q ( 1 0 ) = 1 3 . 0 7 $ with $p$ -value 0.22. The inadequacy in the volatility equation is due to some higher order serial dependence in the squared standardized residuals.

Comparing models (3.11) and (3.12), we see that (a) using a heavy-tailed distribution for $\epsilon _ { t }$ reduces the ARCH effect, and (b) the difference between the two models is small for this particular instance. Finally, a more appropriate conditional heteroscedastic model for this data set is a GARCH(1,1) model, which is discussed in the next section.

# S-Plus Demonstration

With $t$ innovations.

```python
> arch1t=garch(intc~1,~garch(1,0),cond.dist='t')  
> summary/arch1t)  
Call:  
garch(formula.mean = intc ~ 1, formula.var = ~ garch(1, 0), cond.dist = "t") 
```

```txt
Mean Equation: intc ~ 1  
Conditional Variance Equation: ~ garch(1, 0)  
Conditional Distribution: t  
with estimated parameter 6.159751 and standard error 1.647094  
Estimated Coefficients: 
```

Value Std.Error t value $\mathsf{Pr}(|t|)$ C0.02213 0.006010 3.681 1.333e-04 A0.01338 0.001965 6.809 2.001e-11 ARCH(1) 0.24916 0.115574 2.156 1.587e-02   
AIC(4）=-477.9073，BIC(4）=-462.2317   
Ljung-Box test for standardized residuals: Statistic P-value Chi^2-d.f. 16.1 0.1868 12   
Ljung-Box test for squared standardized residuals: Statistic P-value Chi^2-d.f. 29.91 0.002882 12

Remark. In S-Plus, the command garch allows for several conditional distributions. They are specified by cond.dist $= \therefore t ^ { \prime } ,$ or ‘‘ged’’. The default is Gaussian. 

Example 3.2. Consider the percentage changes of the exchange rate between mark and dollar in 10-minute intervals. The data are shown in Figure 3.2a. As shown in Figure 3.3a, the series has no serial correlations. However, the sample PACF of the squared series $a _ { t } ^ { 2 }$ shows some big spikes, especially at lags 1 and 3. There are some large PACF at higher lags, but the lower order lags tend to be more important. Following the procedure discussed in the previous subsection, we specify an ARCH(3) model for the series. Using the conditional Gaussian likelihood function, we obtain the fitted model $r _ { t } = 0 . 0 0 1 8 + \sigma _ { t } \epsilon _ { t }$ and

$$
\sigma_ {t} ^ {2} = 0. 2 2 \times 1 0 ^ {- 2} + 0. 3 2 2 a _ {t - 1} ^ {2} + 0. 0 7 4 a _ {t - 2} ^ {2} + 0. 0 9 3 a _ {t - 3} ^ {2},
$$

where all the estimates in the volatility equation are statistically significant at the $5 \%$ significance level. The standard errors of the volatility parameters are $0 . 4 7 \times$ $1 0 ^ { - 6 }$ , 0.017, 0.016, and 0.014, respectively. Model checking, using the standardized residual $\tilde { a } _ { t }$ , indicates that the model is adequate.

# 3.5 THE GARCH MODEL

Although the ARCH model is simple, it often requires many parameters to adequately describe the volatility process of an asset return. For instance, consider the

monthly excess returns of the S&P 500 index of Example 3.3 below. An ARCH(9) model is needed for the volatility process. Some alternative models must be sought. Bollerslev (1986) proposes a useful extension known as the generalized ARCH (GARCH) model. For a log return series $r _ { t }$ , let $a _ { t } = r _ { t } - \mu _ { t }$ be the innovation at time $t$ . Then $a _ { t }$ follows a ${ \mathrm { G A R C H } } ( m , s )$ model if

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \sum_ {i = 1} ^ {m} \alpha_ {i} a _ {t - i} ^ {2} + \sum_ {j = 1} ^ {s} \beta_ {j} \sigma_ {t - j} ^ {2}, \tag {3.13}
$$

where again $\{ \epsilon _ { t } \}$ is a sequence of iid random variables with mean 0 and variance 1.0, $\alpha _ { 0 } > 0$ , $\alpha _ { i } \geq 0$ , $\beta _ { j } \geq 0$ , and $\begin{array} { r } { \sum _ { i = 1 } ^ { \operatorname* { m a x } ( m , s ) } ( \alpha _ { i } + \beta _ { i } ) < 1 } \end{array}$ -max(m,s)i (αi + βi ) < 1. Here it is understood that $\alpha _ { i } = 0$ for $i > m$ and $\beta _ { j } = 0$ for $j > s$ . The latter constraint on $\alpha _ { i } + \beta _ { i }$ implies that the unconditional variance of $a _ { t }$ is finite, whereas its conditional variance $\sigma _ { t } ^ { 2 }$ evolves over time. As before, $\epsilon _ { t }$ is often assumed to be a standard normal or standardized Student- $\cdot t$ distribution or generalized error distribution. Equation (3.13) reduces to a pure $\mathrm { A R C H } ( m )$ model if $s = 0$ . The $\alpha _ { i }$ and $\beta _ { j }$ are referred to as ARCH and GARCH parameters, respectively.

To understand properties of GARCH models, it is informative to use the following representation. Let $\eta _ { t } = a _ { t } ^ { 2 } - \sigma _ { t } ^ { 2 }$ so that $\sigma _ { t } ^ { 2 } = a _ { t } ^ { 2 } - \eta _ { t }$ . By plugging $\sigma _ { t - i } ^ { 2 } =$ $a _ { t - i } ^ { 2 } - \eta _ { t - i }$ $( i = 0 , \ldots , s )$ ) into Eq. (3.13), we can rewrite the GARCH model as

$$
a _ {t} ^ {2} = \alpha_ {0} + \sum_ {i = 1} ^ {\max  (m, s)} \left(\alpha_ {i} + \beta_ {i}\right) a _ {t - i} ^ {2} + \eta_ {t} - \sum_ {j = 1} ^ {s} \beta_ {j} \eta_ {t - j}. \tag {3.14}
$$

It is easy to check that $\{ \eta _ { t } \}$ is a martingale difference series (i.e., $E ( \eta _ { t } ) = 0$ and $\mathrm { c o v } ( \eta _ { t } , \eta _ { t - j } ) = 0$ for $j \geq 1 $ ). However, $\{ \eta _ { t } \}$ in general is not an iid sequence. Equation (3.14) is an ARMA form for the squared series $a _ { t } ^ { 2 }$ . Thus, a GARCH model can be regarded as an application of the ARMA idea to the squared series $a _ { t } ^ { 2 }$ . Using the unconditional mean of an ARMA model, we have

$$
E (a _ {t} ^ {2}) = \frac {\alpha_ {0}}{1 - \sum_ {i = 1} ^ {\max (m , s)} (\alpha_ {i} + \beta_ {i})}
$$

provided that the denominator of the prior fraction is positive.

The strengths and weaknesses of GARCH models can easily be seen by focusing on the simplest GARCH(1,1) model with

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2}, \quad 0 \leq \alpha_ {1}, \beta_ {1} \leq 1, (\alpha_ {1} + \beta_ {1}) <   1. \tag {3.15}
$$

First, a large $a _ { t - 1 } ^ { 2 }$ or $\sigma _ { t - 1 } ^ { 2 }$ gives rise to a large $\sigma _ { t } ^ { 2 }$ . This means that a large $a _ { t - 1 } ^ { 2 }$ tends to be followed by another large $a _ { t } ^ { 2 }$ , generating, again, the well-known behavior of volatility clustering in financial time series. Second, it can be shown that if $1 - 2 \alpha _ { 1 } ^ { 2 } - \stackrel { \cdot } { ( } \alpha _ { 1 } + \beta _ { 1 } ) ^ { 2 } > 0$ , then

$$
\frac {E (a _ {t} ^ {4})}{[ E (a _ {t} ^ {2}) ] ^ {2}} = \frac {3 [ 1 - (\alpha_ {1} + \beta_ {1}) ^ {2} ]}{1 - (\alpha_ {1} + \beta_ {1}) ^ {2} - 2 \alpha_ {1} ^ {2}} > 3.
$$

Consequently, similar to ARCH models, the tail distribution of a GARCH(1,1) process is heavier than that of a normal distribution. Third, the model provides a simple parametric function that can be used to describe the volatility evolution.

Forecasts of a GARCH model can be obtained using methods similar to those of an ARMA model. Consider the GARCH(1,1) model in Eq. (3.15) and assume that the forecast origin is $h$ . For 1-step ahead forecast, we have

$$
\sigma_ {h + 1} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {h} ^ {2} + \beta_ {1} \sigma_ {h} ^ {2},
$$

where $a _ { h }$ and $\sigma _ { h } ^ { 2 }$ are known at the time index $h$ . Therefore, the 1-step ahead forecast is

$$
\sigma_ {h} ^ {2} (1) = \alpha_ {0} + \alpha_ {1} a _ {h} ^ {2} + \beta_ {1} \sigma_ {h} ^ {2}.
$$

For multistep ahead forecasts, we use $a _ { t } ^ { 2 } = \sigma _ { t } ^ { 2 } \epsilon _ { t } ^ { 2 }$ and rewrite the volatility equation in Eq. (3.15) as

$$
\sigma_ {t + 1} ^ {2} = \alpha_ {0} + (\alpha_ {1} + \beta_ {1}) \sigma_ {t} ^ {2} + \alpha_ {1} \sigma_ {t} ^ {2} (\epsilon_ {t} ^ {2} - 1).
$$

When $t = h + 1$ , the equation becomes

$$
\sigma_ {h + 2} ^ {2} = \alpha_ {0} + (\alpha_ {1} + \beta_ {1}) \sigma_ {h + 1} ^ {2} + \alpha_ {1} \sigma_ {h + 1} ^ {2} (\epsilon_ {h + 1} ^ {2} - 1).
$$

Since $E ( \epsilon _ { h + 1 } ^ { 2 } - 1 | F _ { h } ) = 0$ , the 2-step ahead volatility forecast at the forecast origin $h$ + satisfies the equation

$$
\sigma_ {h} ^ {2} (2) = \alpha_ {0} + (\alpha_ {1} + \beta_ {1}) \sigma_ {h} ^ {2} (1).
$$

In general, we have

$$
\sigma_ {h} ^ {2} (\ell) = \alpha_ {0} + \left(\alpha_ {1} + \beta_ {1}\right) \sigma_ {h} ^ {2} (\ell - 1), \quad \ell > 1. \tag {3.16}
$$

This result is exactly the same as that of an ARMA(1,1) model with AR polynomial $1 - ( \alpha _ { 1 } + \beta _ { 1 } ) B$ . By repeated substitutions in Eq. (3.16), we obtain that the $\ell$ -step ahead forecast can be written as

$$
\sigma_ {h} ^ {2} (\ell) = \frac {\alpha_ {0} [ 1 - (\alpha_ {1} + \beta_ {1}) ^ {\ell - 1} ]}{1 - \alpha_ {1} - \beta_ {1}} + (\alpha_ {1} + \beta_ {1}) ^ {\ell - 1} \sigma_ {h} ^ {2} (1).
$$

Therefore,

$$
\sigma_ {h} ^ {2} (\ell) \rightarrow \frac {\alpha_ {0}}{1 - \alpha_ {1} - \beta_ {1}}, \quad \text {a s} \quad \ell \rightarrow \infty
$$

provided that $\alpha _ { 1 } + \beta _ { 1 } < 1$ . Consequently, the multistep ahead volatility forecasts of a GARCH(1,1) model converge to the unconditional variance of $a _ { t }$ as the forecast horizon increases to infinity provided that $\mathrm { V a r } ( a _ { t } )$ exists.

The literature on GARCH models is enormous; see Bollerslev, Chou, and Kroner (1992), Bollerslev, Engle, and Nelson (1994), and the references therein. The model encounters the same weaknesses as the ARCH model. For instance, it responds equally to positive and negative shocks. In addition, recent empirical studies of high-frequency financial time series indicate that the tail behavior of GARCH models remains too short even with standardized Student-t innovations. For further information about kurtosis of GARCH models, see Section 3.16.

# 3.5.1 An Illustrative Example

The modeling procedure of ARCH models can also be used to build a GARCH model. However, specifying the order of a GARCH model is not easy. Only lower order GARCH models are used in most applications, say, GARCH(1,1), GARCH(2,1), and GARCH(1,2) models. The conditional maximum likelihood method continues to apply provided that the starting values of the volatility $\{ \sigma _ { t } ^ { 2 } \}$ are assumed to be known. Consider, for instance, a GARCH(1,1) model. If $\sigma _ { 1 } ^ { 2 }$ is treated as fixed, then $\sigma _ { t } ^ { 2 }$ can be computed recursively for a GARCH(1,1) model. In some applications, the sample variance of $a _ { t }$ serves as a good starting value of $\sigma _ { 1 } ^ { 2 }$ . The fitted model can be checked by using the standardized residual $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ and its squared process.

Example 3.3. In this example, we consider the monthly excess returns of the S&P 500 index starting from 1926 for 792 observations. The series is shown in Figure 3.5. Denote the excess return series by $r _ { t }$ . Figure 3.6 shows the sample ACF of $r _ { t }$ and the sample PACF of $r _ { t } ^ { 2 }$ . The $r _ { t }$ series has some serial correlations at lags 1 and 3, but the key feature is that the PACF of $r _ { t } ^ { 2 }$ shows strong linear dependence. If an MA(3) model is entertained, we obtain

$$
r _ {t} = 0. 0 0 6 2 + a _ {t} + 0. 0 9 4 4 a _ {t - 1} - 0. 1 4 0 7 a _ {t - 3}, \quad \hat {\sigma} _ {a} = 0. 0 5 7 6
$$

for the series, where all of the coefficients are significant at the $5 \%$ level. However, for simplicity, we use instead an AR(3) model

$$
r _ {t} = \phi_ {1} r _ {t - 1} + \phi_ {2} r _ {t - 2} + \phi_ {3} r _ {t - 3} + \beta_ {0} + a _ {t}.
$$

The fitted AR(3) model, under the normality assumption, is

$$
r _ {t} = 0. 0 8 8 r _ {t - 1} - 0. 0 2 3 r _ {t - 2} - 0. 1 2 3 r _ {t - 3} + 0. 0 0 6 6 + a _ {t}, \quad \hat {\sigma} _ {a} ^ {2} = 0. 0 0 3 3 3. \tag {3.17}
$$

For the GARCH effects, we use the GARCH(1,1) model

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \beta_ {1} \sigma_ {t - 1} ^ {2} + \alpha_ {1} a _ {t - 1} ^ {2}.
$$

A joint estimation of the AR(3)–GARCH(1,1) model gives

$$
\begin{array}{l} r _ {t} = 0. 0 0 7 8 + 0. 0 3 2 r _ {t - 1} - 0. 0 2 9 r _ {t - 2} - 0. 0 0 8 r _ {t - 3} + a _ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 0 0 0 8 4 + 0. 1 2 1 3 a _ {t - 1} ^ {2} + 0. 8 5 2 3 \sigma_ {t - 1} ^ {2}. \\ \end{array}
$$

![](images/825eb1c39a0f567fe1be8c926ed9ce33124a4acf20e737584377dab98b0c16e4.jpg)  
Figure 3.5. Time series plot of the monthly excess returns of the S&P 500 index.

![](images/36fb82c1beb330c2178186cd58efe2d0666d8e2af5b89584beb62b8f5cb0ed24.jpg)

![](images/766f8e6b87e9f131595119d95d4b8e1113d8efd967fe24e6eae914c42136dabd.jpg)  
Figure 3.6. (a) Sample ACF of the monthly excess returns of the S&P 500 index and (b) sample PACF of the squared monthly excess returns.

From the volatility equation, the implied unconditional variance of $a _ { t }$ is

$$
\frac {0 . 0 0 0 0 8 4}{1 - 0 . 8 5 2 3 - 0 . 1 2 1 3} = 0. 0 0 3 1 7,
$$

which is close to that of Eq. (3.17). However, $t$ -ratios of the parameters in the mean equation suggest that all three AR coefficients are insignificant at the $5 \%$ level. Therefore, we refine the model by dropping all AR parameters. The refined model is

$$
r _ {t} = 0. 0 0 7 6 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 0 0 8 6 + 0. 1 2 1 6 a _ {t - 1} ^ {2} + 0. 8 5 1 1 \sigma_ {t - 1} ^ {2}. \tag {3.18}
$$

The standard error of the constant in the mean equation is 0.0015, whereas those of the parameters in the volatility equation are 0.000024, 0.0197, and 0.0190, respectively. The unconditional variance of $a _ { t }$ is $0 . 0 0 0 0 8 6 / ( 1 - 0 . 8 5 1 1 - 0 . 1 2 1 6 ) =$ 0.00314. This is a simple stationary GARCH(1,1) model. Figure 3.7 shows the estimated volatility process, $\sigma _ { t }$ , and the standardized shocks $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ for the GARCH(1,1) model in Eq. (3.18). The $\tilde { a } _ { t }$ series appears to be a white noise process. Figure 3.8 provides the sample ACF of the standardized residuals $\tilde { a } _ { t }$ and

![](images/568f5f12c07ef71136b30a60083f9b24909b206a5f0a1182a40ba195ed07702c.jpg)  
(a) Estimated volatility process

![](images/a9328c30b5b40cf2cdfc2627fd769dde0cfcd354221fe62a93e1d5aefa690d9f.jpg)  
(b) Standardized residuals   
Figure 3.7. (a) Time series plot of estimated volatility $\left( \sigma _ { t } \right)$ for the monthly excess returns of the S&P 500 index and (b) the standardized shocks of the monthly excess returns of the S&P 500 index. Both plots are based on the GARCH(1,1) model in Eq. (3.18).

![](images/838879bf386d3914446048143d6a0f5bb3da95b401390dc4107b2d88788fd441.jpg)

![](images/93620889f8499fb18e9c74edebb63704ca80fd591b5efda98759445aef20b944.jpg)  
Figure 3.8. Model checking of the GARCH(1,1) model in Eq. (3.18) for monthly excess returns of the S&P 500 index: (a) sample ACF of standardized residuals and (b) sample ACF of the squared standardized residuals.

the squared process $\tilde { a } _ { t } ^ { 2 }$ . These ACFs fail to suggest any significant serial correlations or conditional heteroscedasticity in the standardized residual series. More specifically, we have $Q ( 1 2 ) = 1 1 . 9 9 ( 0 . 4 5 )$ and $Q ( 2 4 ) = 2 8 . 5 2 ( 0 . 2 4 )$ for $\tilde { a } _ { t }$ , and $Q ( 1 2 ) = 1 3 . 1 1 ( 0 . 3 6 )$ and $Q ( 2 4 ) = 2 6 . 4 5 ( 0 . 3 3 )$ for $\tilde { a } _ { t } ^ { 2 }$ , where the number in parentheses is the $p$ -value of the test statistic. Thus, the model appears to be adequate in describing the linear dependence in the return and volatility series. Note that the fitted model shows $\hat { \alpha } _ { 1 } + \hat { \beta } _ { 1 } = 0 . 9 7 7 2$ , which is close to 1. This phenomenon is commonly observed in practice and it leads to imposing the constraint $\alpha _ { 1 } + \beta _ { 1 } = 1$ in a GARCH(1,1) model, resulting in an integrated GARCH (or IGARCH) model; see Section 3.6.

Finally, to forecast the volatility of monthly excess returns of the S&P 500 index, we can use the volatility equation in Eq. (3.18). For instance, at the forecast origin $h$ , we have $\sigma _ { h + 1 } ^ { 2 } = 0 . 0 0 0 0 8 6 + 0 . 1 2 1 6 a _ { h } ^ { 2 } + 0 . 8 5 1 1 \sigma _ { h } ^ { 2 }$ . The 1-step ahead forecast is then

$$
\sigma_ {h} ^ {2} (1) = 0. 0 0 0 0 8 6 + 0. 1 2 1 6 a _ {h} ^ {2} + 0. 8 5 1 1 \sigma_ {h} ^ {2},
$$

where $a _ { h }$ is the residual of the mean equation at time $h$ and $\sigma _ { h }$ is obtained from the volatility equation. The starting value $\sigma _ { 0 } ^ { 2 }$ is fixed at either zero or the unconditional variance of $a _ { t }$ . For multistep ahead forecasts, we use the recursive formula in Eq. (3.16). Table 3.1 shows some mean and volatility forecasts for the monthly

Table 3.1. Volatility Forecasts for the Monthly Excess Returns of the S&P 500 Indexa   

<table><tr><td>Horizon</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>∞</td></tr><tr><td>Return</td><td>0.0076</td><td>0.0076</td><td>0.0076</td><td>0.0076</td><td>0.0076</td><td>0.0076</td></tr><tr><td>Volatility</td><td>0.0536</td><td>0.0537</td><td>0.0537</td><td>0.0538</td><td>0.0538</td><td>0.0560</td></tr></table>

a The forecast origin is $h = 7 9 2$ , which corresponds to December 1991. Here volatility denotes conditional standard deviation.

excess return of the S&P 500 index with forecast origin $h = 7 9 2$ based on the GARCH(1,1) model in Eq. (3.18).

# Some S-Plus Commands Used in Example 3.3

```matlab
> fit=garch(sp~ar(3),~garch(1,1))  
> summary.fit)  
> fit=garch(sp~1,~garch(1,1))  
> summary.fit)  
> names.fit)  
[1] "residuals" "sigma.t" "df.residual" "coef" "model"  
[6] "cond.dist" "likelihood" "opt.index" "cov"  
[10] "prediction" "call" "asymp.sd" "series"  
> % Next, compute the standardized residuals  
> stdresi=fit\$residuals/fit\$sigma.t  
> autocorTest(stdresi,lag=24)  
> autocorTest(stdresi^2,lag=24)  
> predict.fit,5) % Compute predictions 
```

Note that in the prior commands the volatility series $\sigma _ { t }$ is stored in fit$sigma.t and the residual series of the returns in fit$residuals.

# t Innovation

Assuming that $\epsilon _ { t }$ follows a standardized Student-t distribution with 5 degrees of freedom, we reestimate the GARCH(1,1) model and obtain

$$
r _ {t} = 0. 0 0 8 5 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 0 1 2 + 0. 1 1 2 1 a _ {t - 1} ^ {2} + 0. 8 4 3 2 \sigma_ {t - 1} ^ {2}, \tag {3.19}
$$

where the standard errors of the parameters are 0.0015, $0 . 5 1 \times 1 0 ^ { - 4 }$ , 0.0296, and 0.0371, respectively. This model is essentially an IGARCH(1,1) model as $\hat { \alpha } _ { 1 } + \hat { \beta } _ { 1 } \approx 0 . 9 5$ , which is close to 1. The Ljung–Box statistics of the standardized residuals give $Q ( 1 0 ) = 1 1 . 3 8$ with $p$ -value 0.33 and those of the $\{ \tilde { a } _ { t } ^ { 2 } \}$ series give $Q ( 1 0 ) = 1 0 . 4 8 $ with $p$ -value 0.40. Thus, the fitted GARCH(1,1) model with Student-t distribution is adequate.

# S-Plus Commands Used

```txt
> fit1 = garch(sp~1, ~garch(1, 1), cond.dist='t', cond.par=5,
+ cond.est=F)
> summary(fit1)
> stresi=fit1\$residuals/fit1\$sigma.t
> autocorTest(stresi, lag=10)
> autocorTest(stresi^2, lag=10) 
```

# Estimation of Degrees of Freedom

If we further extend the GARCH(1,1) model by estimating the degrees of freedom of the Student-t distribution used, we obtain the model

$$
r _ {t} = 0. 0 0 8 5 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 0 1 2 + 0. 1 1 2 1 a _ {t - 1} ^ {2} + 0. 8 4 3 2 \sigma_ {t - 1} ^ {2}, \tag {3.20}
$$

where the estimated degrees of freedom is 7.02. Standard errors of the estimates in Eq. (3.20) are close to those in Eq. (3.19). The standard error of the estimated degrees of freedom is 1.78. Consequently, we cannot reject the hypothesis of using a standardized Student-t distribution with 5 degrees of freedom at the $5 \%$ significance level.

# S-Plus Commands Used

$$
\begin{array}{l} > f i t 2 = \operatorname {g a r c h} (\mathrm {s p} \sim 1, \sim \operatorname {g a r c h} (1, 1), \operatorname {c o n d . d i s t} = ^ {\prime} \mathrm {t} ^ {\prime}) \\ > \text {s u m m a r y} (\text {f i t 2}) \\ \end{array}
$$

# 3.5.2 Forecasting Evaluation

Since the volatility of an asset return is not directly observable, comparing the forecasting performance of different volatility models is a challenge to data analysts. In the literature, some researchers use out-of-sample forecasts and compare the volatility forecasts $\sigma _ { h } ^ { 2 } ( \ell )$ with the shock $a _ { h + \ell } ^ { 2 }$ in the forecasting sample to assess the forecasting performance of a volatility model. This approach often finds a low correlation coefficient between $a _ { h + \ell } ^ { 2 }$ and $\sigma _ { h } ^ { 2 } ( \ell )$ , that is, low $R ^ { 2 }$ . However, such a finding is not surprising because $a _ { h + \ell } ^ { 2 }$ alone is not an adequate measure of the volatility at timpoint of view, $h + \ell$ ahead forecasts. From a statis a consistent estimate of $E ( a _ { h + 1 } ^ { 2 } | F _ { h } ) = \sigma _ { h + 1 } ^ { 2 }$ $a _ { h + 1 } ^ { 2 }$ $\sigma _ { h + 1 } ^ { 2 }$ +  + But it is not an accurate estimate of σ 2h 1 $\sigma _ { h + 1 } ^ { 2 }$ variable with a known mean value cannot provide an accurate estimate of its variance. Consequently, such an approach to evaluate forecasting performance of volatility models is strictly speaking not proper. For more information concerning forecasting evaluation of GARCH models, readers are referred to Andersen and Bollerslev (1998).

# 3.5.3 A Two-Pass Estimation Method

Based on Eq. (3.14), a two-pass estimation method can be used to estimate GARCH models. First, ignoring any ARCH effects, one estimates the mean equation of a return series using the methods discussed in Chapter 2 (e.g., maximum likelihood method). Denote the residual series by $a _ { t }$ . Second, treating $\{ a _ { t } ^ { 2 } \}$ as an observed time series, one applies the maximum likelihood method to estimate parameters of Eq. (3.14). Denote the AR and MA coefficient estimates by $\hat { \phi } _ { i }$ and $\widehat { \theta } _ { i }$ . The GARCH estimates are obtained as $\hat { \beta } _ { i } = \hat { \theta } _ { i }$ and $\hat { \alpha } _ { i } = \hat { \phi } _ { i } - \hat { \theta } _ { i }$ . Obviously, such estimates are approximations to the true parameters and their statistical properties have not been rigorously investigated. However, limited experience shows that this simple approach often provides good approximations, especially when the sample size

is moderate or large. For instance, consider the monthly excess return series of the S&P 500 index of Example 3.3. Using the conditional MLE method in SCA, we obtain the model

$$
r _ {t} = 0. 0 0 6 1 + a _ {t}, \quad a _ {t} ^ {2} = 0. 0 0 0 1 4 + 0. 9 5 8 3 a _ {t - 1} ^ {2} + \eta_ {t} - 0. 8 4 5 6 \eta_ {t - 1},
$$

where all estimates are significantly different from zero at the $5 \%$ level. From the estimates, we have $\hat { \beta } _ { 1 } ^ { \phantom { - } } = 0 . 8 4 5 \bar { 6 }$ and $\hat { \alpha } _ { 1 } = 0 . 9 5 8 3 - 0 . 8 4 5 6 = 0 . 1 1 2 7$ . These approximate estimates are very close to those in Eq. (3.18) or (3.20). Furthermore, the fitted volatility series of the two-pass method is very close to that of Figure 3.7a.

# 3.6 THE INTEGRATED GARCH MODEL

If the AR polynomial of the GARCH representation in Eq. (3.14) has a unit root, then we have an IGARCH model. Thus, IGARCH models are unit-root GARCH models. Similar to ARIMA models, a key feature of IGARCH models is that the impact of past squared shocks $\eta _ { t - i } = a _ { t - i } ^ { 2 } - \sigma _ { t - i } ^ { 2 }$ for $i > 0$ on $a _ { t } ^ { 2 }$ is persistent.

An IGARCH(1,1) model can be written as

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \beta_ {1} \sigma_ {t - 1} ^ {2} + (1 - \beta_ {1}) a _ {t - 1} ^ {2},
$$

where $\left\{ \epsilon _ { t } \right\}$ is defined as before and $1 > \beta _ { 1 } > 0$ . For the monthly excess returns of the S&P 500 index, an estimated IGARCH(1,1) model is

$$
\begin{array}{l} r _ {t} = 0. 0 0 6 7 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 0 0 1 1 9 + 0. 8 0 5 9 \sigma_ {t - 1} ^ {2} + 0. 1 9 4 1 a _ {t - 1} ^ {2}, \\ \end{array}
$$

where the standard errors of the estimates in the volatility equation are 0.0017, 0.000013, and 0.0144, respectively. The parameter estimates are close to those of the GARCH(1,1) model shown before, but there is a major difference between the two models. The unconditional variance of $a _ { t }$ , hence that of $r _ { t }$ , is not defined under the above IGARCH(1,1) model. This seems hard to justify for an excess return series. From a theoretical point of view, the IGARCH phenomenon might be caused by occasional level shifts in volatility. The actual cause of persistence in volatility deserves a careful investigation.

When $\alpha _ { 1 } + \beta _ { 1 } = 1$ , repeated substitutions in Eq. (3.16) give

$$
\sigma_ {h} ^ {2} (\ell) = \sigma_ {h} ^ {2} (1) + (\ell - 1) \alpha_ {0}, \quad \ell \geq 1, \tag {3.21}
$$

where $h$ is the forecast origin. Consequently, the effect of $\sigma _ { h } ^ { 2 } ( 1 )$ on future volatilities is also persistent, and the volatility forecasts form a straight line with slope $\alpha _ { 0 }$ . Nelson (1990) studies some probability properties of the volatility process $\sigma _ { t } ^ { 2 }$ under an IGARCH model. The process $\sigma _ { t } ^ { 2 }$ is a martingale for which some nice results are available in the literature. Under certain conditions, the volatility process is strictly stationary, but not weakly stationary because it does not have the first two moments.

The case of $\alpha _ { 0 } = 0$ is of particular interest in studying the IGARCH(1,1) model. In this case, the volatility forecasts are simply $\sigma _ { h } ^ { 2 } ( 1 )$ for all forecast horizons; see Eq. (3.21). This special IGARCH(1,1) model is the volatility model used in RiskMetrics, which is an approach for calculating value at risk; see Chapter 7. The model is also an exponential smoothing model for the $\{ a _ { t } ^ { 2 } \}$ series. To see this, rewrite the model as

$$
\begin{array}{l} \sigma_ {t} ^ {2} = \left(1 - \beta_ {1}\right) a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2} \\ = (1 - \beta_ {1}) a _ {t - 1} ^ {2} + \beta_ {1} [ (1 - \beta) a _ {t - 2} ^ {2} + \beta_ {1} \sigma_ {t - 2} ^ {2} ] \\ = (1 - \beta_ {1}) a _ {t - 1} ^ {2} + (1 - \beta_ {1}) \beta_ {1} a _ {t - 2} ^ {2} + \beta_ {1} ^ {2} \sigma_ {t - 2} ^ {2} \\ \end{array}
$$

By repeated substitutions, we have

$$
\sigma_ {t} ^ {2} = (1 - \beta_ {1}) \left(a _ {t - 1} ^ {2} + \beta_ {1} a _ {t - 2} ^ {2} + \beta_ {1} ^ {2} a _ {t - 3} ^ {3} + \dots\right),
$$

which is the well-known exponential smoothing formation with $\beta _ { 1 }$ being the discounting factor. Exponential smoothing methods can thus be used to estimate such an IGARCH(1,1) model.

# 3.7 THE GARCH-M MODEL

In finance, the return of a security may depend on its volatility. To model such a phenomenon, one may consider the GARCH-M model, where “M” stands for GARCH in the mean. A simple GARCH(1,1)-M model can be written as

$$
\begin{array}{l} r _ {t} = \mu + c \sigma_ {t} ^ {2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2}, \tag {3.22} \\ \end{array}
$$

where $\mu$ and $c$ are constants. The parameter $c$ is called the risk premium parameter. A positive $c$ indicates that the return is positively related to its volatility. Other specifications of risk premium have also been used in the literature, including $r _ { t } = \mu + c \sigma _ { t } + a _ { t }$ and $r _ { t } = \mu + c \ln ( \sigma _ { t } ^ { 2 } ) + a _ { t }$ .

The formulation of the GARCH-M model in Eq. (3.22) implies that there are serial correlations in the return series $r _ { t }$ . These serial correlations are introduced by those in the volatility process $\{ \sigma _ { t } ^ { 2 } \}$ . The existence of risk premium is, therefore, another reason that some historical stock returns have serial correlations.

For illustration, we consider a GARCH(1,1)-M model with Gaussian innovations for the monthly excess returns of the S&P 500 index from January 1926 to December 1991. The fitted model is

$$
r _ {t} = 0. 0 0 5 5 + 1. 0 9 \sigma_ {t} ^ {2} + a _ {t}, \quad \sigma_ {t} ^ {2} = 8. 7 6 \times 1 0 ^ {- 5} + 0. 1 2 3 a _ {t - 1} ^ {2} + 0. 8 4 9 \sigma_ {t - 1} ^ {2},
$$

where the standard errors for the two parameters in the mean equation are 0.0023 and 0.818, respectively, and those for the parameters in the volatility equation are $2 . 5 1 \times 1 0 ^ { - 5 }$ , 0.0205, and 0.0196, respectively. The estimated risk premium for the index return is positive but is not statistically significant at the $5 \%$ level. Here the result is obtained using S-Plus. Other forms of GARCH-M specification in S-Plus are given in Table 3.2. The idea of risk premium applies to other GARCH models.

Table 3.2. GARCH-M Models Allowed in S-Plusa   

<table><tr><td>g(σt)</td><td>Command</td></tr><tr><td>σt2</td><td>var.in.mean</td></tr><tr><td>σt</td><td>sd.in.mean</td></tr><tr><td>ln(σt2)</td><td>logvar.in.mean</td></tr></table>

aThe mean equation is $r _ { t } = \mu + c g ( \sigma _ { t } ) + a _ { t }$ .

# S-Plus Demonstration

$>$ sp.fit $=$ garch(sp~1+var.in.mean,~garch(1,1))  
$>$ summary(sp.fit)

# 3.8 THE EXPONENTIAL GARCH MODEL

To overcome some weaknesses of the GARCH model in handling financial time series, Nelson (1991) proposes the exponential GARCH (EGARCH) model. In particular, to allow for asymmetric effects between positive and negative asset returns, he considers the weighted innovation

$$
g \left(\epsilon_ {t}\right) = \theta \epsilon_ {t} + \gamma \left[ \left| \epsilon_ {t} \right| - E \left(\left| \epsilon_ {t} \right|\right) \right], \tag {3.23}
$$

where $\theta$ and $\gamma$ are real constants. Both $\epsilon _ { t }$ and $| \epsilon _ { t } | - E ( | \epsilon _ { t } | )$ are zero-mean iid sequences with continuous distributions. Therefore, $E [ g ( \epsilon _ { t } ) ] = 0$ . The asymmetry of $g ( \epsilon _ { t } )$ can easily be seen by rewriting it as

$$
g (\epsilon_ {t}) = \left\{ \begin{array}{l l} (\theta + \gamma) \epsilon_ {t} - \gamma E (| \epsilon_ {t} |) & \text {i f} \epsilon_ {t} \geq 0, \\ (\theta - \gamma) \epsilon_ {t} - \gamma E (| \epsilon_ {t} |) & \text {i f} \epsilon_ {t} <   0. \end{array} \right.
$$

Remark. For the standard Gaussian random variable $\epsilon _ { t }$ , $E ( | \epsilon _ { t } | ) = \sqrt { 2 / \pi }$ . For the standardized Student-t distribution in Eq. (3.7), we have

$$
E (| \epsilon_ {t} |) = \frac {2 \sqrt {v - 2} \Gamma ((v + 1) / 2)}{(v - 1) \Gamma (v / 2) \sqrt {\pi}}.
$$

An EGARCH(m, s) model can be written as

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \ln \left(\sigma_ {t} ^ {2}\right) = \alpha_ {0} + \frac {1 + \beta_ {1} B + \cdots + \beta_ {s - 1} B ^ {s - 1}}{1 - \alpha_ {1} B - \cdots - \alpha_ {m} B ^ {m}} g \left(\epsilon_ {t - 1}\right), \tag {3.24}
$$

where $\alpha _ { 0 }$ is a constant, $B$ is the back-shift (or lag) operator such that $B g ( \epsilon _ { t } ) =$ $g ( \epsilon _ { t - 1 } )$ , and $1 + \beta _ { 1 } B + \cdot \cdot \cdot + \beta _ { s - 1 } B ^ { s - 1 }$ and $1 - \alpha _ { 1 } B - \cdot \cdot \cdot - \alpha _ { m } B ^ { m }$ are polynomials with zeros outside the unit circle and have no common factors. By outside the unit circle, we mean that absolute values of the zeros are greater than 1. Again, Eq. (3.24) uses the usual ARMA parameterization to describe the evolution of the conditional variance of $a _ { t }$ . Based on this representation, some properties of the EGARCH model can be obtained in a similar manner as those of the GARCH

model. For instance, the unconditional mean of $\ln ( \sigma _ { t } ^ { 2 } )$ is $\alpha _ { 0 }$ . However, the model differs from the GARCH model in several ways. First, it uses logged conditional variance to relax the positiveness constraint of model coefficients. Second, the use of $g ( \epsilon _ { t } )$ enables the model to respond asymmetrically to positive and negative lagged values of $a _ { t }$ . Some additional properties of the EGARCH model can be found in Nelson (1991).

To better understand the EGARCH model, let us consider the simple model with order (1,1):

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad (1 - \alpha B) \ln \left(\sigma_ {t} ^ {2}\right) = (1 - \alpha) \alpha_ {0} + g \left(\epsilon_ {t - 1}\right), \tag {3.25}
$$

where the $\epsilon _ { t }$ are iid standard normal and the subscript of $\alpha _ { 1 }$ is omitted. In this case, $E ( | \epsilon _ { t } | ) = \sqrt { 2 / \pi }$ and the model for $\ln ( \sigma _ { t } ^ { 2 } )$ becomes

$$
(1 - \alpha B) \ln \left(\sigma_ {t} ^ {2}\right) = \left\{ \begin{array}{l l} \alpha_ {*} + (\gamma + \theta) \epsilon_ {t - 1} & \text {i f} \epsilon_ {t - 1} \geq 0, \\ \alpha_ {*} + (\gamma - \theta) (- \epsilon_ {t - 1}) & \text {i f} \epsilon_ {t - 1} <   0, \end{array} \right. \tag {3.26}
$$

where $\alpha _ { * } = ( 1 - \alpha ) \alpha _ { 0 } - \sqrt { 2 / \pi } \gamma$ . This is a nonlinear function similar to that of the threshold autoregressive (TAR) model of Tong (1978, 1990). It suffices to say that for this simple EGARCH model the conditional variance evolves in a nonlinear manner depending on the sign of $a _ { t - 1 }$ . Specifically, we have

$$
\sigma_ {t} ^ {2} = \sigma_ {t - 1} ^ {2 \alpha} \exp (\alpha_ {*}) \left\{ \begin{array}{l l} \exp \left((\gamma + \theta) \frac {a _ {t - 1}}{\sigma_ {t - 1}}\right) & \text {i f} a _ {t - 1} \geq 0, \\ \exp \left((\gamma - \theta) \frac {| a _ {t - 1} |}{\sigma_ {t - 1}}\right) & \text {i f} a _ {t - 1} <   0. \end{array} \right.
$$

The coefficients $( \gamma + \theta )$ and $( \gamma - \theta )$ show the asymmetry in response to positive and negative $a _ { t - 1 }$ . The model is, therefore, nonlinear if $\theta \neq 0$ . Since negative shocks tend to have larger impacts, we expect $\theta$ to be negative. For higher order EGARCH models, the nonlinearity becomes much more complicated. Cao and Tsay (1992) use nonlinear models, including EGARCH models, to obtain multistep ahead volatility forecasts. We discuss nonlinearity in financial time series in Chapter 4.

# 3.8.1 An Alternative Model Form

An alternative form for the EGARCH(m, s) model is

$$
\ln \left(\sigma_ {t} ^ {2}\right) = \alpha_ {0} + \sum_ {i = 1} ^ {s} \alpha_ {i} \frac {\left| a _ {t - i} \right| + \gamma_ {i} a _ {t - i}}{\sigma_ {t - i}} + \sum_ {j = 1} ^ {m} \beta_ {j} \ln \left(\sigma_ {t - j} ^ {2}\right). \tag {3.27}
$$

Here a positive $a _ { t - i }$ contributes $\alpha _ { i } ( 1 + \gamma _ { i } ) | \epsilon _ { t - i } |$ to the log volatility, whereas a negative $a _ { t - i }$ gives $\alpha _ { i } ( 1 - \gamma _ { i } ) | \epsilon _ { t - i } |$ , where $\epsilon _ { t - i } = a _ { t - i } / \sigma _ { t - i } .$ . The $\gamma _ { i }$ parameter thus signifies the leverage effect of $a _ { t - i }$ . Again, we expect $\gamma _ { i }$ to be negative in real applications. This is the model form used in S-Plus.

# 3.8.2 An Illustrative Example

Nelson (1991) applies an EGARCH model to the daily excess returns of the valueweighted market index from the Center for Research in Security Prices from July 1962 to December 1987. The excess returns are obtained by removing monthly Treasury bill returns from the value-weighted index returns, assuming that the Treasury bill return was constant for each calendar day within a given month. There are 6408 observations. Denote the excess return by $r _ { t }$ . The model used is as follows:

$$
\begin{array}{l} r _ {t} = \phi_ {0} + \phi_ {1} r _ {t - 1} + c \sigma_ {t} ^ {2} + a _ {t}, \\ \ln \left(\sigma_ {t} ^ {2}\right) = \alpha_ {0} + \ln \left(1 + w N _ {t}\right) + \frac {1 + \beta B}{1 - \alpha_ {1} B - \alpha_ {2} B ^ {2}} g \left(\epsilon_ {t - 1}\right), \tag {3.28} \\ \end{array}
$$

where $\sigma _ { t } ^ { 2 }$ is the conditional variance of $a _ { t }$ given $F _ { t - 1 }$ , $N _ { t }$ is the number of nontrading days between trading days $t - 1$ and $t$ , $\alpha _ { 0 }$ and $w$ are real parameters, $g ( \epsilon _ { t } )$ is defined in Eq. (3.23), and $\epsilon _ { t }$ follows a generalized error distribution in Eq. (3.9). Similar to a GARCH-M model, the parameter $c$ in Eq. (3.28) is the risk premium parameter. Table 3.3 gives the parameter estimates and their standard errors of the model. The mean equation of model (3.28) has two features that are of interest. First, it uses an AR(1) model to take care of possible serial correlation in the excess returns. Second, it uses the volatility $\sigma _ { t } ^ { 2 }$ as a regressor to account for risk premium. The estimated risk premium is negative, but statistically insignificant.

# 3.8.3 Second Example

As another illustration, we consider the monthly log returns of IBM stock from January 1926 to December 1997 for 864 observations. An AR(1)–EGARCH(1,1) model is entertained and the fitted model is

$$
r _ {t} = 0. 0 1 0 5 + 0. 0 9 2 r _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \tag {3.29}
$$

$$
\ln \left(\sigma_ {t} ^ {2}\right) = - 5. 4 9 6 + \frac {g \left(\epsilon_ {t - 1}\right)}{1 - 0 . 8 5 6 B}, \tag {3.30}
$$

$$
g (\epsilon_ {t - 1}) = - 0. 0 7 9 5 \epsilon_ {t - 1} + 0. 2 6 4 7 \left[ | \epsilon_ {t - 1} | - \sqrt {2 / \pi} \right],
$$

Table 3.3. Estimated AR(1)–EGARCH(2,2) Model for the Daily Excess Returns of the Value-Weighted CRSP Market Index: July 1962 to December 1987   

<table><tr><td>Parameter</td><td>α0</td><td>w</td><td>γ</td><td>α1</td><td>α2</td><td>β</td></tr><tr><td>Estimate</td><td>-10.06</td><td>0.183</td><td>0.156</td><td>1.929</td><td>-0.929</td><td>-0.978</td></tr><tr><td>Error</td><td>0.346</td><td>0.028</td><td>0.013</td><td>0.015</td><td>0.015</td><td>0.006</td></tr><tr><td>Parameter</td><td>θ</td><td>φ0</td><td>φ1</td><td>c</td><td>v</td><td></td></tr><tr><td>Estimate</td><td>-0.118</td><td>3.5·10-4</td><td>0.205</td><td>-3.361</td><td>1.576</td><td></td></tr><tr><td>Error</td><td>0.009</td><td>9.9·10-5</td><td>0.012</td><td>2.026</td><td>0.032</td><td></td></tr></table>

where $\left\{ \epsilon _ { t } \right\}$ is a sequence of independent standard Gaussian random variates. All parameter estimates are statistically significant at the $5 \%$ level. For model checking, the Ljung–Box statistics give $Q ( 1 0 ) = 6 . 3 1 ( 0 . 7 1 )$ and $Q ( 2 0 ) = 2 1 . 4 ( 0 . 3 2 )$ for the standardized residual process $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ and $Q ( 1 0 ) = 4 . 1 3 ( 0 . 9 0 )$ and $Q ( 2 0 ) = 1 5 . 9 3 ( 0 . 6 6 )$ for the squared process $\tilde { a } _ { t } ^ { 2 }$ , where again the number in parentheses denotes $p$ -value. Therefore, there is no serial correlation or conditional heteroscedasticity in the standardized residuals of the fitted model. The prior AR(1)–EGARCH(1,1) model is adequate.

From the estimated volatility equation in (3.30) and using $\sqrt { 2 / \pi } \approx 0 . 7 9 7 9$ , we obtain the volatility equation as

$$
\ln (\sigma_ {t} ^ {2}) = - 1. 0 0 1 + 0. 8 5 6 \ln (\sigma_ {t - 1} ^ {2}) + \left\{ \begin{array}{c l} 0. 1 8 5 2 \epsilon_ {t - 1} & \text {i f} \epsilon_ {t - 1} \geq 0, \\ - 0. 3 4 4 2 \epsilon_ {t - 1} & \text {i f} \epsilon_ {t - 1} <   0. \end{array} \right.
$$

Taking antilog transformation, we have

$$
\sigma_ {t} ^ {2} = \sigma_ {t - 1} ^ {2 \times 0. 8 5 6} e ^ {- 1. 0 0 1} \times \left\{ \begin{array}{l l} e ^ {0. 1 8 5 2 \epsilon_ {t - 1}} & \text {i f} \epsilon_ {t - 1} \geq 0, \\ e ^ {- 0. 3 4 4 2 \epsilon_ {t - 1}} & \text {i f} \epsilon_ {t - 1} <   0. \end{array} \right.
$$

This equation highlights the asymmetric responses in volatility to the past positive and negative shocks under an EGARCH model. For example, for a standardized shock with magnitude 2 (i.e., two standard deviations), we have

$$
\frac {\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = - 2\right)}{\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = 2\right)} = \frac {\exp \left[ - 0 . 3 4 4 2 \times (- 2) \right]}{\exp \left(0 . 1 8 5 2 \times 2\right)} = e ^ {0. 3 1 8} = 1. 3 7 4.
$$

Therefore, the impact of a negative shock of size two standard deviations is about $3 7 . 4 \%$ higher than that of a positive shock of the same size. This example clearly demonstrates the asymmetric feature of EGARCH models. In general, the bigger the shock, the larger the difference in volatility impact.

Finally, we extend the sample period to include the log returns from 1998 to 2003 so that there are 936 observations and use S-Plus to fit an EGARCH(1,1) model. The results are given below.

# S-Plus Demonstration

Output edited.

```javascript
> ibm.egarch=garch(ibmln~1,~egarch(1,1),leverage=T, + cond.dist='ged') 
```

```txt
> summary.ibm.egriculture 
```

```txt
Call: 
```

```txt
garch(formula.mean = ibmln \~ 1, formula.var = ~ egarch(1,1), leverage = T, cond.dist = "ged") 
```

Mean Equation: ibmln ~ 1

Conditional Variance Equation: ~ egarch(1, 1) Conditional Distribution: ged with estimated parameter 1.5003 and standard error 0.09912

Estimated Coefficients:   
Value Std.Error t value $\mathsf{Pr}(|t|)$ C 0.01181 0.002012 5.870 3.033e-09 A -0.55680 0.171602 -3.245 6.088e-04 ARCH(1) 0.22025 0.052824 4.169 1.669e-05 GARCH(1) 0.92910 0.026743 34.742 0.000e+00 LEV(1) -0.26400 0.126096 -2.094 1.828e-02

Ljung-Box test for standardized residuals:   
```txt
Statistic P-value Chi^2-d.f. 17.87 0.1195 12 
```

Ljung-Box test for squared standardized residuals:   
```txt
Statistic P-value Chi^2-d.f. 6.723 0.8754 12 
```

The fitted GARCH(1,1) model is

$$
\begin{array}{l} r _ {t} = 0. 0 1 1 8 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \ln \left(\sigma_ {t} ^ {2}\right) = - 0. 5 5 7 + 0. 2 2 0 \frac {\left| a _ {t - 1} \right| - 0 . 2 6 4 a _ {t - 1}}{\sigma_ {t - 1}} + 0. 9 2 9 \ln \left(\sigma_ {t - 1} ^ {2}\right), \tag {3.31} \\ \end{array}
$$

where $\epsilon _ { t }$ follows a GED distribution with parameter 1.5. This model is adequate based on the Ljung–Box statistics of the standardized residual series and its squared process. As expected, the output shows that the estimated leverage effect is negative and is statistically significant at the $5 \%$ level with $t$ -ratio $- 2 . 0 9 4$ .

# 3.8.4 Forecasting Using an EGARCH Model

We use the EGARCH(1,1) model to illustrate multistep ahead forecasts of EGARCH models, assuming that the model parameters are known and the innovations are standard Gaussian. For such a model, we have

$$
\ln \left(\sigma_ {t} ^ {2}\right) = (1 - \alpha_ {1}) \alpha_ {0} + \alpha_ {1} \ln \left(\sigma_ {t - 1} ^ {2}\right) + g \left(\epsilon_ {t - 1}\right),
$$

$$
g \left(\epsilon_ {t - 1}\right) = \theta \epsilon_ {t - 1} + \gamma \left(\left| \epsilon_ {t - 1} \right| - \sqrt {2 / \pi}\right).
$$

Taking exponentials, the model becomes

$$
\begin{array}{l} \sigma_ {t} ^ {2} = \sigma_ {t - 1} ^ {2 \alpha_ {1}} \exp [ (1 - \alpha_ {1}) \alpha_ {0} ] \underbrace {\exp [ g (\epsilon_ {t - 1}) ]}, \tag {3.32} \\ g \left(\epsilon_ {t - 1}\right) = \theta \epsilon_ {t - 1} + \gamma \left(\left| \epsilon_ {t - 1} \right| - \sqrt {2 / \pi}\right). \\ \end{array}
$$

Let $h$ be the forecast origin. For the 1-step ahead forecast, we have

$$
\sigma_ {h + 1} ^ {2} = \sigma_ {h} ^ {2 \alpha_ {1}} \exp [ (1 - \alpha_ {1}) \alpha_ {0} ] \exp [ g (\epsilon_ {h}) ],
$$

where all of the quantities on the right-hand side are known. Thus, the 1-step ahead volatility forecast at the forecast origin $h$ is simply $\hat { \sigma } _ { h } ^ { 2 } ( 1 ) = \sigma _ { h + 1 } ^ { 2 }$ given earlier. For the 2-step ahead forecast, Eq. (3.32) gives

$$
\sigma_ {h + 2} ^ {2} = \sigma_ {h + 1} ^ {2 \alpha_ {1}} \exp [ (1 - \alpha_ {1}) \alpha_ {0} ] \exp [ g (\epsilon_ {h + 1}) ].
$$

Taking conditional expectation at time $h$ , we have

$$
\hat {\sigma} _ {h} ^ {2} (2) = \hat {\sigma} _ {h} ^ {2 \alpha_ {1}} (1) \exp [ (1 - \alpha_ {1}) \alpha_ {0} ] E _ {h} \left\{\exp \left[ g \left(\epsilon_ {h + 1}\right) \right] \right\},
$$

where $E _ { h }$ denotes a conditional expectation taken at the time origin $h$ . The prior expectation can be obtained as follows:

$$
\begin{array}{l} E \{\exp [ g (\epsilon) ] \} = \int_ {- \infty} ^ {\infty} \exp [ \theta \epsilon + \gamma (| \epsilon | - \sqrt {2 / \pi}) ] f (\epsilon) d \epsilon \\ = \exp (- \gamma \sqrt {2 / \pi}) \left[ \int_ {0} ^ {\infty} e ^ {(\theta + \gamma) \epsilon} \frac {1}{\sqrt {2 \pi}} e ^ {- \epsilon^ {2} / 2} d \epsilon \right. \\ \left. + \int_ {- \infty} ^ {0} e ^ {(\theta - \gamma) \epsilon} \frac {1}{\sqrt {2 \pi}} e ^ {- \epsilon^ {2} / 2} d \epsilon \right] \\ = \exp \left(- \gamma \sqrt {2 / \pi}\right) \left[ e ^ {(\theta + \gamma) ^ {2} / 2} \Phi (\theta + \gamma) + e ^ {(\theta - \gamma) ^ {2} / 2} \Phi (\gamma - \theta) \right], \\ \end{array}
$$

where $f ( \epsilon )$ and $\Phi ( x )$ are the probability density function and CDF of the standard normal distribution, respectively. Consequently, the 2-step ahead volatility forecast is

$$
\begin{array}{l} \hat {\sigma} _ {h} ^ {2} (2) = \hat {\sigma} _ {h} ^ {2 \alpha_ {1}} (1) \exp \left[ (1 - \alpha_ {1}) \alpha_ {0} - \gamma \sqrt {2 / \pi} \right] \\ \times \left\{\exp \left[ (\theta + \gamma) ^ {2} / 2 \right] \Phi (\theta + \gamma) + \exp \left[ (\theta - \gamma) ^ {2} / 2 \right] \Phi (\gamma - \theta) \right\}. \\ \end{array}
$$

Repeating the previous procedure, we obtain a recursive formula for a $j$ -step ahead forecast:

$$
\begin{array}{l} \hat {\sigma} _ {h} ^ {2} (j) = \hat {\sigma} _ {h} ^ {2 \alpha_ {1}} (j - 1) \exp (\omega) \\ \times \left\{\exp \left[ (\theta + \gamma) ^ {2} / 2 \right] \Phi (\theta + \gamma) + \exp \left[ (\theta - \gamma) ^ {2} / 2 \right] \Phi (\gamma - \theta) \right\}, \\ \end{array}
$$

where $\omega = ( 1 - \alpha _ { 1 } ) \alpha _ { 0 } - \gamma \sqrt { 2 / \pi }$ . The values of $\Phi ( \theta + \gamma )$ and $\Phi ( \theta - \gamma )$ can be obtained from most statistical packages. Alternatively, accurate approximations to these values can be obtained by using the method in Appendix B of Chapter 6.

For illustration, consider the AR(1)–EGARCH(1,1) model of the previous subsection for the monthly log returns of IBM stock, ending December 1997. Using the fitted EGARCH(1,1) model, we can compute the volatility forecasts for the series. At the forecast origin $t = 8 6 4$ , the forecasts are $\hat { \sigma } _ { 8 6 4 } ^ { 2 } ( 1 ) = 6 . 0 5 \times 1 0 ^ { - 3 }$ , $\hat { \sigma } _ { 8 6 4 } ^ { 2 } ( 2 ) =$ $5 . 8 2 \times 1 0 ^ { - 3 }$ , $\hat { \sigma } _ { 8 6 4 } ^ { 2 } ( 3 ) = 5 . 6 3 \times 1 0 ^ { - 3 }$ , and $\hat { \sigma } _ { 8 6 4 } ^ { 2 } ( 1 0 ) = 4 . 9 4 \times 1 0 ^ { - 3 }$ . These forecasts converge gradually to the sample variance $4 . 3 7 \times 1 0 ^ { - 3 }$ of the shock process $a _ { t }$ of Eq. (3.29).

# 3.9 THE THRESHOLD GARCH MODEL

Another volatility model commonly used to handle leverage effects is the threshold GARCH (or TGARCH) model; see Glosten, Jagannathan, and Runkle (1993) and Zakoian (1994). A TGARCH(m, s) model assumes the form

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \sum_ {i = 1} ^ {s} \left(\alpha_ {i} + \gamma_ {i} N _ {t - i}\right) a _ {t - i} ^ {2} + \sum_ {j = 1} ^ {m} \beta_ {j} \sigma_ {t - j} ^ {2}, \tag {3.33}
$$

where $N _ { t - i }$ is an indicator for negative $a _ { t - i }$ , that is,

$$
N _ {t - i} = \left\{ \begin{array}{l l} 1 \text {i f} a _ {t - i} <   0, \\ 0 \text {i f} a _ {t - i} \geq 0, \end{array} \right.
$$

and $\alpha _ { i } , \gamma _ { i }$ , and $\beta _ { j }$ are non-negative parameters satisfying conditions similar to those of GARCH models. From the model, it is seen that a positive $a _ { t - i }$ contributes $\alpha _ { i } a _ { t - i } ^ { 2 }$ to $\sigma _ { t } ^ { 2 }$ , whereas a negative $a _ { t - i }$ has a larger impact $( \alpha _ { i } + \gamma _ { i } ) a _ { t - i } ^ { 2 }$ with $\gamma _ { i } > 0$ . The model uses zero as its threshold to separate the impacts of past shocks. Other threshold values can also be used; see Chapter 4 for the general concept of threshold models. Model (3.33) is also called the GJR model because Glosten et al. (1993) proposed essentially the same model.

For illustration, consider the monthly log returns of IBM stock from 1926 to 2003. The fitted TGARCH(1,1) model with conditional GED innovations is

$$
\begin{array}{l} r _ {t} = 0. 0 1 2 1 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 3. 4 5 \times 1 0 ^ {- 4} + (0. 0 6 5 8 + 0. 0 8 4 3 N _ {t - 1}) a _ {t - 1} ^ {2} + 0. 8 1 8 2 \sigma_ {t - 1} ^ {2}, \tag {3.34} \\ \end{array}
$$

where the estimated parameter of the GED is 1.51 with standard error 0.099. The standard error of the parameter for the mean equation is 0.002 and the standard errors of the parameters in the volatility equation are $1 . 2 6 \times ^ { - 4 }$ , 0.0314, 0.0395, and 0.049, respectively. To check the fitted model, we have $Q ( 1 2 ) = 1 8 . 3 4 ( 0 . 1 0 6 )$ for the standardized residual $\tilde { a } _ { t }$ and $Q ( 1 2 ) = 5 . 3 6 ( 0 . 9 5 )$ for $\tilde { a } _ { t } ^ { 2 }$ . The model is adequate in modeling the first two conditional moments of the log return series. Based on the fitted model, the leverage effect is significant at the $5 \%$ level.

# S-Plus Commands Used

$>$ ibm.tgarch $=$ garch(ibmln~1,~tgarch(1,1),leverage $= \mathbf { T }$ ,   
$^ +$ cond.dist=’ged’)   
$>$ summary(ibm.tgarch)  
$>$ plot(ibm.tgarch)

It is interesting to compare the two models in Eqs. (3.31) and (3.34) for the monthly log returns of IBM stock. Assume that $a _ { t - 1 } = \pm 2 \sigma _ { t - 1 }$ so that $\epsilon _ { t - 1 } = \pm 2$ The EGARCH(1,1) model gives

$$
\frac {\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = - 2\right)}{\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = 2\right)} = e ^ {0. 2 2 \times 2 \times 0. 6 3 2} \approx 1. 2 6 4.
$$

On the other hand, ignoring the constant term 0.000345, the TGARCH(1,1) model gives

$$
\frac {\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = - 2\right)}{\sigma_ {t} ^ {2} \left(\epsilon_ {t - 1} = 2\right)} \approx \frac {[ (0 . 0 6 5 8 + 0 . 0 8 4 3) 4 + 0 . 8 1 8 2 ] \sigma_ {t - 1} ^ {2}}{(0 . 0 6 5 8 \times 4 + 0 . 8 1 8 2) \sigma_ {t - 1} ^ {2}} = 1. 3 1 2.
$$

The two models provide similar leverage effects.

# 3.10 THE CHARMA MODEL

Many other econometric models have been proposed in the literature to describe the evolution of the conditional variance $\sigma _ { t } ^ { 2 }$ in Eq. (3.2). We mention the conditional heteroscedastic ARMA (CHARMA) model that uses random coefficients to produce conditional heteroscedasticity; see Tsay (1987). The CHARMA model is not the same as the ARCH model, but the two models have similar second-order conditional properties. A CHARMA model is defined as

$$
r _ {t} = \mu_ {t} + a _ {t}, \quad a _ {t} = \delta_ {1 t} a _ {t - 1} + \delta_ {2 t} a _ {t - 2} + \dots + \delta_ {m t} a _ {t - m} + \eta_ {t}, \tag {3.35}
$$

where $\{ \eta _ { t } \}$ is a Gaussian white noise series with mean zero and variance $\sigma _ { \eta } ^ { 2 }$ $\{ \delta _ { t } \} = \{ ( \delta _ { 1 t } , \dots , \delta _ { m t } ) ^ { \prime } \}$ is a sequence of iid random vectors with mean zero and non-negative definite covariance matrix $\pmb { \Omega }$ , and $\{ \delta _ { t } \}$ is independent of $\{ \eta _ { t } \}$ . In this section, we use some basic properties of vector and matrix operations to simplify the presentation. Readers may consult Appendix A of Chapter 8 for a brief review of these properties. For $m > 0$ , the model can be written as

$$
a _ {t} = \boldsymbol {a} _ {t - 1} ^ {\prime} \boldsymbol {\delta} _ {t} + \eta_ {t},
$$

where $\pmb { a } _ { t - 1 } = ( a _ { t - 1 } , \ldots , a _ { t - m } ) ^ { \prime }$ is a vector of lagged values of $a _ { t }$ and is available at time $t - 1$ . The conditional variance of $a _ { t }$ of the CHARMA model in Eq. (3.35) is then

$$
\begin{array}{l} \sigma_ {t} ^ {2} = \sigma_ {\eta} ^ {2} + \boldsymbol {a} _ {t - 1} ^ {\prime} \operatorname {C o v} (\delta_ {t}) \boldsymbol {a} _ {t - 1} \\ = \sigma_ {\eta} ^ {2} + \left(a _ {t - 1}, \dots , a _ {t - m}\right) \boldsymbol {\Omega} \left(a _ {t - 1}, \dots , a _ {t - m}\right) ^ {\prime}. \tag {3.36} \\ \end{array}
$$

Denote the $( i , j )$ th element of $\pmb { \Omega }$ by $\omega _ { i j }$ . Because the matrix is symmetric, we have $\omega _ { i j } = \omega _ { j i }$ . If $m = 1$ , then Eq. (3.36) reduces to $\sigma _ { t } ^ { 2 } = \sigma _ { \eta } ^ { 2 } + \omega _ { 1 1 } \overline { { a _ { t - 1 } ^ { 2 } } }$ , which is an ARCH(1) model. If $m = 2$ , then Eq. (3.36) reduces to

$$
\sigma_ {t} ^ {2} = \sigma_ {\eta} ^ {2} + \omega_ {1 1} a _ {t - 1} ^ {2} + 2 \omega_ {1 2} a _ {t - 1} a _ {t - 2} + \omega_ {2 2} a _ {t - 2} ^ {2},
$$

which differs from an ARCH(2) model by the cross-product term $a _ { t - 1 } a _ { t - 2 }$ . In general, the conditional variance of a CHARMA(m) model is equivalent to that of an $\mathrm { A R C H } ( m )$ model if $\pmb { \Omega }$ is a diagonal matrix. Because $\pmb { \Omega }$ is a covariance matrix, which is non-negative definite, and $\sigma _ { \eta } ^ { 2 }$ is a variance, which is positive, we have $\sigma _ { t } ^ { 2 } \ge \sigma _ { \eta } ^ { 2 } > 0$ for all t . In other words, the positiveness of $\sigma _ { t } ^ { 2 }$ is automatically satisfied under a CHARMA model.

An obvious difference between ARCH and CHARMA models is that the latter use cross-products of the lagged values of $a _ { t }$ in the volatility equation. The crossproduct terms might be useful in some applications. For example, in modeling an asset return series, cross-product terms denote interactions between previous returns. It is conceivable that stock volatility may depend on such interactions. However, the number of cross-product terms increases rapidly with the order m, and some constraints are needed to keep the model simple. A possible constraint is to use a small number of cross-product terms in a CHARMA model. Another difference between the two models is that higher order properties of CHARMA models are harder to obtain than those of ARCH models because it is in general harder to handle multiple random variables.

For illustration, we employ the CHARMA model

$$
r _ {t} = \phi_ {0} + a _ {t}, \qquad a _ {t} = \delta_ {1 t} a _ {t - 1} + \delta_ {2 t} a _ {t - 2} + \eta_ {t}
$$

for the monthly excess returns of the S&P 500 index used before in GARCH modeling. The fitted model is

$$
r _ {t} = 0. 0 0 6 3 5 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 1 7 9 + (a _ {t - 1}, a _ {t - 2}) \widehat {\Omega} (a _ {t - 1}, a _ {t - 2}) ^ {\prime},
$$

where

$$
\widehat {\boldsymbol {\Omega}} = \left[ \begin{array}{c c} 0. 1 4 1 7 (0. 0 3 3 3) & - 0. 0 5 9 4 (0. 0 3 6 5) \\ - 0. 0 5 9 4 (0. 0 3 6 5) & 0. 3 0 8 1 (0. 0 3 4 0) \end{array} \right],
$$

where the numbers in parentheses are standard errors. The cross-product term of $\widehat { \pmb { \Omega } }$ has a $t$ -ratio of $- 1 . 6 3$ , which is marginally significant at the $10 \%$ level. If we refine the model to

$$
r _ {t} = \phi_ {0} + a _ {t}, \qquad a _ {t} = \delta_ {1 t} a _ {t - 1} + \delta_ {2 t} a _ {t - 2} + \delta_ {3 t} a _ {t - 3} + \eta_ {t},
$$

but assume that $\delta _ { 3 t }$ is uncorrelated with $( \delta _ { 1 t } , \delta _ { 2 t } )$ , then we obtain the fitted model

$$
r _ {t} = 0. 0 0 6 8 + a _ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 1 3 6 + (a _ {t - 1}, a _ {t - 2}, a _ {t - 3}) \widehat {\Omega} (a _ {t - 1}, a _ {t - 2}, a _ {t - 3}) ^ {\prime},
$$

where the elements of $\widehat { \pmb { \Omega } }$ and their standard errors, shown in parentheses, are

$$
\widehat {\boldsymbol {\Omega}} = \left[ \begin{array}{c c c} 0. 1 2 1 2 (0. 0 3 5 5) & - 0. 0 6 2 2 (0. 0 2 8 3) & 0 \\ - 0. 0 6 2 2 (0. 0 2 8 3) & 0. 1 9 1 3 (0. 0 2 5 4) & 0 \\ 0 & 0 & 0. 2 9 8 8 (0. 0 4 2 0) \end{array} \right].
$$

All of the estimates are now statistically significant at the $5 \%$ level. From the model, $a _ { t } = r _ { t } - 0 . 0 0 6 8$ is the deviation of the monthly excess return from its average. The fitted CHARMA model shows that there is some interaction effect between the first two lagged deviations. Indeed, the volatility equation can be written approximately as

$$
\sigma_ {t} ^ {2} = 0. 0 0 1 3 6 + 0. 1 2 a _ {t - 1} ^ {2} - 0. 1 2 a _ {t - 1} a _ {t - 2} + 0. 1 9 a _ {t - 2} ^ {2} + 0. 3 0 a _ {t - 3} ^ {2}.
$$

The conditional variance is slightly larger when $a _ { t - 1 } a _ { t - 2 }$ is negative.

# 3.10.1 Effects of Explanatory Variables

The CHARMA model can easily be generalized so that the volatility of $r _ { t }$ may depend on some explanatory variables. Let $\{ x _ { i t } \} _ { i = 1 } ^ { m }$ be $m$ explanatory variables available at time t. Consider the model

$$
r _ {t} = \mu_ {t} + a _ {t}, \quad a _ {t} = \sum_ {i = 1} ^ {m} \delta_ {i t} x _ {i, t - 1} + \eta_ {t}, \tag {3.37}
$$

where $\pmb { \delta } _ { t } = ( \delta _ { 1 t } , \ldots , \delta _ { m t } ) ^ { \prime }$ and $\eta _ { t }$ are random vector and variable defined in Eq. (3.35). Then the conditional variance of $a _ { t }$ is

$$
\sigma_ {t} ^ {2} = \sigma_ {\eta} ^ {2} + (x _ {1, t - 1}, \dots , x _ {m, t - 1}) \boldsymbol {\Omega} (x _ {1, t - 1}, \dots , x _ {m, t - 1}) ^ {\prime}.
$$

In application, the explanatory variables may include some lagged values of $a _ { t }$

# 3.11 RANDOM COEFFICIENT AUTOREGRESSIVE MODELS

In the literature, the random coefficient autoregressive (RCA) model is introduced to account for variability among different subjects under study, similar to the panel data analysis in econometrics and the hierarchical model in statistics. We classify the RCA model as a conditional heteroscedastic model, but historically it is used to obtain a better description of the conditional mean equation of the process by allowing for the parameters to evolve over time. A time series $r _ { t }$ is said to follow an $\operatorname { R C A } ( p )$ model if it satisfies

$$
r _ {t} = \phi_ {0} + \sum_ {i = 1} ^ {p} \left(\phi_ {i} + \delta_ {i t}\right) r _ {t - i} + a _ {t}, \tag {3.38}
$$

where $p$ is a positive integer, $\{ \delta _ { t } \} = \{ ( \delta _ { 1 t } , \hdots , \delta _ { p t } ) ^ { \prime } \}$ is a sequence of independent random vectors with mean zero and covariance matrix ${ \pmb \Omega } _ { \delta }$ , and $\{ \delta _ { t } \}$ is independent of $\{ a _ { t } \}$ ; see Nicholls and Quinn (1982) for further discussions of the model. The conditional mean and variance of the RCA model in Eq. (3.38) are

$$
\begin{array}{l} \mu_ {t} = E (r _ {t} | F _ {t - 1}) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {t - i}, \\ \sigma_ {t} ^ {2} = \sigma_ {a} ^ {2} + (r _ {t - 1}, \dots , r _ {t - p}) \boldsymbol {\Omega} _ {\delta} (r _ {t - 1}, \dots , r _ {t - p}) ^ {\prime}, \\ \end{array}
$$

which is in the same form as that of a CHARMA model. However, there is a subtle difference between RCA and CHARMA models. For the RCA model, the volatility is a quadratic function of the observed lagged values $r _ { t - i }$ . Yet the volatility is a quadratic function of the lagged innovations $a _ { t - i }$ in a CHARMA model.

# 3.12 THE STOCHASTIC VOLATILITY MODEL

An alternative approach to describe the volatility evolution of a financial time series is to introduce an innovation to the conditional variance equation of $a _ { t }$ ; see Melino and Turnbull (1990), Taylor (1994), Harvey, Ruiz, and Shephard (1994), and Jacquier, Polson, and Rossi (1994). The resulting model is referred to as a stochastic volatility (SV) model. Similar to EGARCH models, to ensure positiveness of the conditional variance, SV models use $\ln ( \sigma _ { t } ^ { 2 } )$ instead of $\sigma _ { t } ^ { 2 }$ . A SV model is defined as

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad (1 - \alpha_ {1} B - \dots - \alpha_ {m} B ^ {m}) \ln \left(\sigma_ {t} ^ {2}\right) = \alpha_ {0} + v _ {t}, \tag {3.39}
$$

where the $\epsilon _ { t }$ are iid $N ( 0 , 1 )$ , the $v _ { t }$ are iid $N ( 0 , \sigma _ { v } ^ { 2 } )$ , $\left\{ \epsilon _ { t } \right\}$ and $\{ v _ { t } \}$ are independent, $\alpha _ { 0 }$ is a constant, and all zeros of the polynomial $\begin{array} { r } { 1 - \sum _ { i = 1 } ^ { m } \alpha _ { i } B ^ { i } } \end{array}$ }are greater than 1 in modulus. Adding the innovation $v _ { t }$ substantially increases the flexibility of the model in describing the evolution of $\sigma _ { t } ^ { 2 }$ , but it also increases the difficulty in parameter estimation. To estimate a SV model, we need a quasi-likelihood method via Kalman filtering or a Monte Carlo method. Jacquier, Polson, and Rossi (1994) provide some comparison of estimation results between quasi-likelihood and Markov chain Monte Carlo (MCMC) methods. The difficulty in estimating a SV model is understandable because for each shock $a _ { t }$ the model uses two innovations $\epsilon _ { t }$ and $v _ { t }$ . We discuss a MCMC method to estimate SV models in Chapter 12. For more discussions on stochastic volatility models, see Taylor (1994).

The appendixes of Jacquier, Polson, and Rossi (1994) provide some properties of the SV model when $m = 1$ . For instance, with $m = 1$ , we have

$$
\ln (\sigma_ {t} ^ {2}) \sim N \left(\frac {\alpha_ {0}}{1 - \alpha_ {1}}, \frac {\sigma_ {v} ^ {2}}{1 - \alpha_ {1} ^ {2}}\right) \equiv N (\mu_ {h}, \sigma_ {h} ^ {2}),
$$

and $E ( a _ { t } ^ { 2 } ) = \exp ( \mu _ { h } + \sigma _ { h } ^ { 2 } / 2 )$ , $E ( a _ { t } ^ { 4 } ) = 3 \exp ( 2 \mu _ { h } ^ { 2 } + 2 \sigma _ { h } ^ { 2 } )$ , and $\mathrm { c o r r } ( a _ { t } ^ { 2 } , a _ { t - i } ^ { 2 } ) =$ $[ \exp ( \sigma _ { h } ^ { 2 } \alpha _ { 1 } ^ { i } ) - 1 ] / [ 3 \exp ( \sigma _ { h } ^ { 2 } ) - 1 ]$ . Limited experience shows that SV models often provided improvements in model fitting, but their contributions to out-of-sample volatility forecasts received mixed results.

# 3.13 THE LONG-MEMORY STOCHASTIC VOLATILITY MODEL

More recently, the SV model is further extended to allow for long memory in volatility, using the idea of fractional difference. As stated in Chapter 2, a time series is a long-memory process if its autocorrelation function decays at a hyperbolic, instead

![](images/6f6626710e1ba839df89ad58682985a2db8761fb6ffb1baa2da15b3723bee0c5.jpg)

![](images/2fa8c0e8c1662a95d03265414d716ef38fa39ff43c5aaa4f262567b3a0091e0d.jpg)  
Figure 3.9. The sample ACF of daily absolute log returns for (a) the S&P 500 index and (b) IBM stock for the period from July 3, 1962 to December 31, 2003. The two horizontal lines denote the asymptotic $5 \%$ limits.

of an exponential, rate as the lag increases. The extension to long-memory models in volatility study is motivated by the fact that the autocorrelation function of the squared or absolute-valued series of an asset return often decays slowly, even though the return series has no serial correlation; see Ding, Granger, and Engle (1993). Figure 3.9 shows the sample ACF of the daily absolute returns for IBM stock and the S&P 500 index from July 3, 1962 to December 31, 2003. These sample ACFs are positive with moderate magnitude, but decay slowly.

A simple long-memory stochastic volatility (LMSV) model can be written as

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} = \sigma \exp \left(u _ {t} / 2\right), \quad (1 - B) ^ {d} u _ {t} = \eta_ {t}, \tag {3.40}
$$

where $\sigma > 0$ , the $\epsilon _ { t }$ are iid $N ( 0 , 1 )$ , the $\eta _ { t }$ are iid $N ( 0 , \sigma _ { \eta } ^ { 2 } )$ and independent of $\epsilon _ { t }$ , and $0 < d < 0 . 5$ . The feature of long memory stems from the fractional difference $( 1 - B ) ^ { d }$ , which implies that the ACF of $u _ { t }$ decays slowly at a hyperbolic, instead of an exponential, rate as the lag increases. For model (3.40), we have

$$
\begin{array}{l} \ln \left(a _ {t} ^ {2}\right) = \ln \left(\sigma^ {2}\right) + u _ {t} + \ln \left(\epsilon_ {t} ^ {2}\right) \\ = \left[ \ln \left(\sigma^ {2}\right) + E \left(\ln \epsilon_ {t} ^ {2}\right) \right] + u _ {t} + \left[ \ln \left(\epsilon_ {t} ^ {2}\right) - E \left(\ln \epsilon_ {t} ^ {2}\right) \right] \\ \equiv \mu + u _ {t} + e _ {t}. \\ \end{array}
$$

Thus, the $\ln ( a _ { t } ^ { 2 } )$ series is a Gaussian long-memory signal plus a non-Gaussian white noise; see Breidt, Crato, and de Lima (1998). Estimation of the long-memory stochastic volatility model is complicated, but the fractional difference parameter $d$ can be estimated by using either a quasi-maximum likelihood method or a regression method. Using the log series of squared daily returns for companies in the S&P 500 index, Bollerslev and Jubinski (1999) and Ray and Tsay (2000) found that the median estimate of $d$ is about 0.38. For applications, Ray and Tsay (2000) studied common long-memory components in daily stock volatilities of groups of companies classified by various characteristics. They found that companies in the same industrial or business sector tend to have more common long-memory components (e.g., big U.S. national banks and financial institutions).

# 3.14 APPLICATION

In this section, we apply the volatility models discussed in this chapter to investigate some problems of practical importance. The data used are the monthly log returns of IBM stock and the S&P 500 index from January 1926 to December 1999. There are 888 observations, and the returns are in percentages and include dividends. Figure 3.10 shows the time plots of the two return series. Note that the result of this section was obtained by the RATS program.

Example 3.4. The questions we address here are whether the daily volatility of a stock is lower in the summer and, if so, by how much. Affirmative answers to these two questions have practical implications in stock option pricing. We use the monthly log returns of IBM stock shown in Figure 3.10a as an illustrative example.

Denote the monthly log return series by $r _ { t }$ . If Gaussian GARCH models are entertained, we obtain the GARCH(1,1) model

$$
\begin{array}{l} r _ {t} = 1. 2 3 + 0. 0 9 9 r _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 3. 2 0 6 + 0. 1 0 3 a _ {t - 1} ^ {2} + 0. 8 2 5 \sigma_ {t - 1} ^ {2}, \tag {3.41} \\ \end{array}
$$

for the series. The standard errors of the two parameters in the mean equation are 0.222 and 0.037, respectively, whereas those of the parameters in the volatility equation are 0.947, 0.021, and 0.037, respectively. Using the standardized residuals $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ , we obtain $Q ( 1 0 ) = 7 . 8 2 ( 0 . 5 5 3 )$ and $Q ( 2 0 ) = 2 1 . 2 2 ( 0 . 3 2 5 )$ , where $p$ -value is in parentheses. Therefore, there are no serial correlations in the residuals of the mean equation. The Ljung–Box statistics of the $\tilde { a } _ { t } ^ { 2 }$ series show $Q ( 1 0 ) =$ 2.89(0.98) and $Q ( 2 0 ) = 7 . 2 6 ( 0 . 9 9 )$ , indicating that the standardized residuals have no conditional heteroscedasticity. The fitted model seems adequate. This model serves as a starting point for further study.

To study the summer effect on stock volatility of an asset, we define an indicator variable

$$
u _ {t} = \left\{ \begin{array}{l l} 1 & \text {i f t i s J u n e , J u l y , o r A u g u s t} \\ 0 & \text {o t h e r w i s e} \end{array} \right. \tag {3.42}
$$

![](images/00b2b4bff166677670af275bccc3b7dec4e4ad27dab76f3749a5b617ade5fe9f.jpg)

![](images/59cd533572c8b76a355852dd9523f95827010ae164c67d0b38bc04b662112f96.jpg)  
Figure 3.10. Time plots of monthly log returns for (a) IBM stock and (b) the S&P 500 index. The sample period is from January 1926 to December 1999. The returns are in percentages and include dividends.

and modify the volatility equation to

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2} + u _ {t} (\alpha_ {0 0} + \alpha_ {1 0} a _ {t - 1} ^ {2} + \beta_ {1 0} \sigma_ {t - 1} ^ {2}).
$$

This equation uses two GARCH(1,1) models to describe the volatility of a stock return; one model for the summer months and the other for the remaining months. For the monthly log returns of IBM stock, estimation results show that the estimates of $\alpha _ { 1 0 }$ and $\beta _ { 1 0 }$ are statistically nonsignificant at the $10 \%$ level. Therefore, we refine the equation and obtain the model

$$
\begin{array}{l} r _ {t} = 1. 2 1 + 0. 0 9 9 r _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 4. 5 3 9 + 0. 1 1 3 a _ {t - 1} ^ {2} + 0. 8 1 6 \sigma_ {t - 1} ^ {2} - 5. 1 5 4 u _ {t}. \tag {3.43} \\ \end{array}
$$

The standard errors of the parameters in the mean equation are 0.218 and 0.037, respectively, and those of the parameters in the volatility equation are 1.071, 0.022, 0.037, and 1.900, respectively. The Ljung–Box statistics for the standardized residuals $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ show $Q ( 1 0 ) = 7 . 6 6 ( 0 . 5 6 9 )$ and $Q ( 2 0 ) = 2 1 . 6 4 ( 0 . 3 0 2 )$ . Therefore, there are no serial correlations in the standardized residuals. The Ljung–Box statistics for $\tilde { a } _ { t } ^ { 2 }$ give $Q ( 1 0 ) = 3 . 3 8 ( 0 . 9 7 )$ and $Q ( 2 0 ) = 6 . 8 2 ( 0 . 9 9 )$ , indicating no

conditional heteroscedasticity in the standardized residuals, either. The refined model seems adequate.

Comparing the volatility models in Eqs. (3.41) and (3.43), we obtain the following conclusions. First, because the coefficient $- 5 . 5 1 4$ is significantly different from zero with $p$ -value 0.0067, the summer effect on stock volatility is statistically significant at the $1 \%$ level. Furthermore, the negative sign of the estimate confirms that the volatility of IBM monthly log stock returns is indeed lower during the summer. Second, rewrite the volatility model in Eq. (3.43) as

$$
\sigma_ {t} ^ {2} = \left\{ \begin{array}{c l} - 0. 6 1 5 + 0. 1 1 3 a _ {t - 1} ^ {2} + 0. 8 1 6 \sigma_ {t - 1} ^ {2} & \text {i f t i s J u n e , J u l y , o r A u g u s t}, \\ 4. 5 3 9 + 0. 1 1 3 a _ {t - 1} ^ {2} + 0. 8 1 6 \sigma_ {t - 1} ^ {2}, & \text {o t h e r w i s e}. \end{array} \right.
$$

The negative constant term $- 0 . 6 1 5 = 4 . 5 3 9 - 5 . 5 1 4$ is counterintuitive. However, since the standard errors of 4.539 and 5.514 are relatively large, the estimated difference $- 0 . 6 1 5$ might not be significantly different from zero. To verify the assertion, we refit the model by imposing the constraint that the constant term of the volatility equation is zero for the summer months. This can easily be done by using the equation

$$
\sigma_ {t} ^ {2} = \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2} + \gamma (1 - u _ {t}).
$$

The fitted model is

$$
\begin{array}{l} r _ {t} = 1. 2 1 + 0. 0 9 9 r _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \tag {3.44} \\ \sigma_ {t} ^ {2} = 0. 1 1 4 a _ {t - 1} ^ {2} + 0. 8 1 1 \sigma_ {t - 1} ^ {2} + 4. 5 5 2 (1 - u _ {t}). \\ \end{array}
$$

The standard errors of the parameters in the mean equation are 0.219 and 0.038, respectively, and those of the parameters in the volatility equation are 0.022, 0.034, and 1.094, respectively. The Ljung–Box statistics of the standardized residuals show $Q ( 1 0 ) = 7 . 6 8 $ and $Q ( 2 0 ) = 2 1 . 6 7 $ and those of the $\tilde { a } _ { t } ^ { 2 }$ series give $Q ( 1 0 ) =$ 3.17 and $Q ( 2 0 ) = 6 . 8 5$ . These test statistics are close to what we had before and are not significant at the $5 \%$ level.

The volatility Eq. (3.44) can readily be used to assess the summer effect on the IBM stock volatility. For illustration, based on the model in Eq. (3.44), the medians of $a _ { t } ^ { 2 }$ and $\sigma _ { t } ^ { 2 }$ are 29.4 and 75.1, respectively, for the IBM monthly log returns in 1999. Using these values, we have $\sigma _ { t } ^ { 2 } = 0 . 1 1 4 \times 2 9 . 4 + 0 . 8 1 1 \times 7 5 . 1 = 6 4 . 3$ for the summer months and $\sigma _ { t } ^ { 2 } = 6 8 . 8$ for the other months. The ratio of the two volatilities is $6 4 . 3 / 6 8 . 8 \approx 9 3 \%$ . Thus, there is a $7 \%$ reduction in the volatility of the monthly log return of IBM stock in the summer months.

Example 3.5. The S&P 500 index is widely used in the derivative markets. As such, modeling its volatility is a subject of intensive study. The question we ask in this example is whether the past returns of individual components of the index contribute to the modeling of the S&P 500 index volatility in the presence of its own returns. A thorough investigation on this topic is beyond the scope of

this chapter, but we use the past returns of IBM stock as explanatory variables to address the question.

The data used are shown in Figure 3.10. Denote by $r _ { t }$ the monthly log return series of the S&P 500 index. Using the $r _ { t }$ series and Gaussian GARCH models, we obtain the following special GARCH(2,1) model:

$$
r _ {t} = 0. 6 0 9 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = 0. 7 1 7 + 0. 1 4 7 a _ {t - 2} ^ {2} + 0. 8 3 9 \sigma_ {t - 1} ^ {2}. \tag {3.45}
$$

The standard error of the constant term in the mean equation is 0.138 and those of the parameters in the volatility equation are 0.214, 0.021, and 0.017, respectively. Based on the standardized residuals $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ , we have $Q ( 1 0 ) = 1 1 . 5 1 ( 0 . 3 2 )$ and $Q ( 2 0 ) = 2 3 . 7 1 ( 0 . 2 6 )$ , where the number in parentheses denotes $p$ -value. For the $\tilde { a } _ { t } ^ { 2 }$ series, we have $Q ( 1 0 ) = 9 . 4 2 ( 0 . 4 9 )$ and $Q ( 2 0 ) = 1 3 . 0 1 ( 0 . 8 8 )$ . Therefore, the model seems adequate at the $5 \%$ significance level.

Next, we evaluate the contributions, if any, of using the past returns of IBM stock, which is a component of the S&P 500 index, in modeling the index volatility. As a simple illustration, we modify the volatility equation as

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {2} a _ {t - 2} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2} + \gamma (x _ {t - 1} - 1. 2 4) ^ {2},
$$

where $x _ { t }$ is the monthly log return of IBM stock and 1.24 is the sample mean of $x _ { t }$ . The fitted model for $r _ { t }$ becomes

$$
\begin{array}{l} r _ {t} = 0. 6 1 6 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 1. 0 6 9 + 0. 1 4 8 a _ {t - 2} ^ {2} + 0. 8 3 4 \sigma_ {t - 1} ^ {2} - 0. 0 0 7 (x _ {t - 1} - 1. 2 4) ^ {2}. \tag {3.46} \\ \end{array}
$$

The standard error of the parameter in the mean equation is 0.139 and the standard errors of the parameters in the volatility equation are 0.271, 0.020, 0.018, and 0.002, respectively. For model checking, we have $Q ( 1 0 ) = 1 1 . 3 9 ( 0 . 3 3 )$ and $Q ( 2 0 ) =$ 23.63(0.26) for the standardized residuals $\tilde { a } _ { t } = a _ { t } / \sigma _ { t }$ and $Q ( 1 0 ) = 9 . 3 5 ( 0 . 5 0 )$ and $Q ( 2 0 ) = 1 3 . 5 1 ( 0 . 8 5 )$ for the $\tilde { a } _ { t } ^ { 2 }$ series. Therefore, the model is adequate.

Since the $p$ -value for testing $\gamma = 0$ is 0.0039, the contribution of the lag-1 IBM stock return to the S&P 500 index volatility is statistically significant at the $1 \%$ level. The negative sign is understandable because it implies that using the lag-1 past return of IBM stock reduces the volatility of the S&P 500 index return. Table 3.4 gives the fitted volatility of the S&P 500 index from July to December

Table 3.4. Fitted Volatilities for the Monthly Log Returns of the S&P 500 Index from July to December 1999 Using Models with and Without the Past Log Return of IBM Stock   

<table><tr><td>Month</td><td>7/99</td><td>8/99</td><td>9/99</td><td>10/99</td><td>11/99</td><td>12/99</td></tr><tr><td>Model (3.45)</td><td>26.30</td><td>26.01</td><td>24.73</td><td>21.69</td><td>20.71</td><td>22.46</td></tr><tr><td>Model (3.46)</td><td>23.32</td><td>23.13</td><td>22.46</td><td>20.00</td><td>19.45</td><td>18.27</td></tr></table>

of 1999 using models (3.45) and (3.46). From the table, the past value of IBM log stock return indeed contributes to the modeling of the S&P 500 index volatility.

# 3.15 ALTERNATIVE APPROACHES

In this section, we discuss two alternative methods to volatility modeling.

# 3.15.1 Use of High-Frequency Data

French, Schwert, and Stambaugh (1987) consider an alternative approach for volatility estimation that uses high-frequency data to calculate volatility of low-frequency returns. In recent years, this approach has attracted substantial interest due to the availability of high-frequency financial data; see Andersen, Bollerslev, Diebold, and Labys (2001a, b).

Suppose that we are interested in the monthly volatility of an asset for which daily returns are available. Let $r _ { t } ^ { m }$ be the monthly log return of the asset at month t. Assume that there are $n$ trading days in month $t$ and the daily log returns of the asset in the month are $\{ r _ { t , i } \} _ { i = 1 } ^ { n }$ . Using properties of log returns, we have

$$
r _ {t} ^ {m} = \sum_ {i = 1} ^ {n} r _ {t, i}.
$$

Assuming that the conditional variance and covariance exist, we have

$$
\operatorname {V a r} \left(r _ {t} ^ {m} \mid F _ {t - 1}\right) = \sum_ {i = 1} ^ {n} \operatorname {V a r} \left(r _ {t, i} \mid F _ {t - 1}\right) + 2 \sum_ {i <   j} \operatorname {C o v} \left[ \left(r _ {t, i}, r _ {t, j}\right) \mid F _ {t - 1} \right], \tag {3.47}
$$

where $F _ { t - 1 }$ denotes the information available at month $t - 1$ (inclusive). The prior equation can be simplified if additional assumptions are made. For example, if we assume that $\{ r _ { t , i } \}$ is a white noise series, then

$$
\operatorname {V a r} \left(r _ {t} ^ {m} \mid F _ {t - 1}\right) = n \operatorname {V a r} \left(r _ {t, 1}\right),
$$

where $\mathrm { V a r } ( r _ { t , 1 } )$ can be estimated from the daily returns $\{ r _ { t , i } \} _ { i = 1 } ^ { n }$ by

$$
\hat {\sigma} ^ {2} = \frac {\sum_ {i = 1} ^ {n} (r _ {t , i} - \overline {{r}} _ {t}) ^ {n}}{n - 1},
$$

where $\overline { { r } } _ { t }$ is the sample mean of the daily log returns in month $t$ (i.e., $\overline { { r } } _ { t } =$ $\textstyle \big ( \sum _ { i = 1 } ^ { n } r _ { t , i } \big ) / n \big )$ . The estimated monthly volatility is then

$$
\hat {\sigma} _ {m} ^ {2} = \frac {n}{n - 1} \sum_ {i = 1} ^ {n} \left(r _ {t, i} - \bar {r} _ {t}\right) ^ {2}. \tag {3.48}
$$

If $\{ r _ { t , i } \}$ follows an MA(1) model, then

$$
\operatorname {V a r} \left(r _ {t} ^ {m} \mid F _ {t - 1}\right) = n \operatorname {V a r} \left(r _ {t, 1}\right) + 2 (n - 1) \operatorname {C o v} \left(r _ {t, 1}, r _ {t, 2}\right),
$$

which can be estimated by

$$
\hat {\sigma} _ {m} ^ {2} = \frac {n}{n - 1} \sum_ {i = 1} ^ {n} \left(r _ {t, i} - \bar {r} _ {t}\right) ^ {2} + 2 \sum_ {i = 1} ^ {n - 1} \left(r _ {t, i} - \bar {r} _ {t}\right) \left(r _ {t, i + 1} - \bar {r} _ {t}\right). \tag {3.49}
$$

The previous approach for volatility estimation is simple, but it encounters several difficulties in practice. First, the model for daily returns $\{ r _ { t , i } \}$ is unknown. This complicates the estimation of covariances in Eq. (3.47). Second, there are roughly 21 trading days in a month, resulting in a small sample size. The accuracy of the estimates of variance and covariance in Eq. (3.47) might be questionable. The accuracy depends on the dynamic structure of $\{ r _ { t , i } \}$ and their distribution. If the daily log returns have high excess kurtosis and serial correlations, then the sample estimates $\hat { \sigma } _ { m } ^ { 2 }$ in Eqs. (3.48) and (3.49) may not even be consistent; see Bai, Russell, and Tiao (2004). Further research is needed to make this approach valuable.

Example 3.6. Consider the monthly volatility of the log returns of the S&P 500 index from January 1980 to December 1999. We calculate the volatility by three methods. In the first method, we use daily log returns and Eq. (3.48) (i.e., assuming that the daily log returns form a white noise series). The second method also uses daily returns but assumes an MA(1) model (i.e., using Eq. (3.49)). The third method applies a GARCH(1,1) model to the monthly returns from January 1962 to December 1999. We use a longer data span to obtain a more accurate estimate of the monthly volatility. The GARCH(1,1) model used is

$$
r _ {t} ^ {m} = 0. 6 5 8 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = 3. 3 4 9 + 0. 0 8 6 a _ {t - 1} ^ {2} + 0. 7 3 5 \sigma_ {t - 1} ^ {2},
$$

where $\epsilon _ { t }$ is a standard Gaussian white noise series. Figure 3.11 shows the time plots of the estimated monthly volatility. Clearly the estimated volatilities based on daily returns are much higher than those based on monthly returns and a GARCH(1,1) model. In particular, the estimated volatility for October 1987 was about 680 when daily returns are used. The plots shown were truncated to have the same scale.

$\begin{array} { r } { \hat { \sigma } _ { m } ^ { 2 } \approx \sum _ { i = 1 } ^ { n } r _ { t , i } ^ { 2 } } \end{array}$ In Eq. (3.48), if we further assume that the sample mean . In this case, the cumulative sum of squares of daily log returns $\overline { { r } } _ { t }$ is zero, then we have in a month is used as an estimate of monthly volatility. This concept has been generalized to estimate daily volatility of an asset by using intradaily log returns. Let $r _ { t }$ be the daily log return of an asset. Suppose that there are $n$ equally spaced intradaily log returns available such that $\textstyle r _ { t } = \sum _ { i = 1 } ^ { n } r _ { t , i } .$ . The quantity

$$
\mathrm {R V} _ {t} = \sum_ {i = 1} ^ {n} r _ {t, i} ^ {2},
$$

is called the realized volatility of $r _ { t }$ ; see Andersen et al. (2001a, b). Mathematically, realized volatility is a quadratic variation of $r _ { t }$ and it assumes that $\{ r _ { t , i } \} _ { i = 1 } ^ { n }$ forms an iid sequence with mean zero and finite variance. Limited experience indicates that $\ln ( \mathrm { R V } _ { t } )$ often follows approximately a Gaussian ARIMA(0,1,q) model, which

![](images/f8ae55d5c6e9081bf1a028984492f154a1cc66a3be0cdaa6bcb97fadfc6b2053.jpg)

![](images/42a9068b39b1cf7d87180050e700d26dcd17a2454ab47c62c287da37ce140263.jpg)

![](images/42fd952ffbcd5b80451eb0a9bb80cb2a1e63fcf1356ecc5457adfe9faccd4650.jpg)  
Figure 3.11. Time plots of estimated monthly volatility for the log returns of the S&P 500 index from January 1980 to December 1999: (a) assumes that the daily log returns form a white noise series, (b) assumes that the daily log returns follow an MA(1) model, and (c) uses monthly returns from January 1962 to December 1999 and a GARCH(1,1) model.

can be used to produce forecasts. See demonstration in Section 11.1 for further information.

Advantages of realized volatility include simplicity and making use of intradaily returns. Intuitively, one would like to use as much information as possible by choosing a large n. However, when the time interval between $r _ { t , i }$ is small, the returns are subject to the effects of market microstructure, for example, bid–ask bounce, which often result in a biased estimate of the volatility. The problem of choosing an optimal time interval for constructing realized volatility has attracted much research lately. For heavily traded assets in the United States, a time interval of 3–15 minutes is often used. Another problem of using realized volatility for stock returns is that the overnight return, which is the return from the closing price of day $t - 1$ to the opening price of $t$ , tends to be substantial. Ignoring overnight

returns can seriously underestimate the volatility. On the other hand, our limited experience shows that overnight returns appear to be small for index returns or foreign exchange returns.

In a series of recent articles, Barndorff-Nielsen and Shephard (2004) have used high-frequency returns to study bi-power variations of an asset return and developed some methods to detect jumps in volatility.

# 3.15.2 Use of Daily Open, High, Low, and Close Prices

For many assets, daily opening, high, low, and closing prices are available. Parkinson (1980), Garman and Klass (1980), Rogers and Satchell (1991), and Yang and Zhang (2000) showed that one can use such information to improve volatility estimation. Figure 3.12 shows a time plot of price versus time for the tth trading day, assuming that time is continuous. For an asset, define the following variables:

• $C _ { t } =$ the closing price of the t th trading day.   
• $O _ { t } =$ the opening price of the tth trading day.   
• $f =$ fraction of the day (in interval [0,1]) that trading is closed.   
• $H _ { t } =$ the highest price of the t th trading period.   
• $L _ { t } =$ the lowest price of the $t$ th trading period.   
• $F _ { t - 1 } =$ public information available at time $t - 1$ .

The conventional variance (or volatility) is $\sigma _ { t } ^ { 2 } = E [ ( C _ { t } - C _ { t - 1 } ) ^ { 2 } | F _ { t - 1 } ]$ . Garman and Klass (1980) considered several estimates of $\sigma _ { t } ^ { 2 }$ assuming that the price follows

![](images/8d89bf2fd81247bc6b077a1e5e208cb8c4b621a82d81f381694e64a004ecbb06.jpg)  
Figure 3.12. Time plot of price over time: scale for price is arbitrary.

a simple diffusion model without drift; see Chapter 6 for more information about stochastic diffusion models. The estimators considered include:

• σˆ 20,t = (Ct − Ct −1)2 .   
  
σˆ 2,t   
2 0.17 (Ot − Ct−1)2   
$\approx 0 . 5 ( H _ { t } - L _ { t } ) ^ { 2 } -$   
2 0.12 (Ot − Ct−1)2

A more precise, but complicated, estimator $\hat { \sigma } _ { 4 , t } ^ { 2 }$ was also considered. However, it is close to $\hat { \sigma } _ { 5 , t } ^ { 2 }$ . Defining the efficiency factor of a volatility estimator as

$$
\operatorname {E f f} \left(\hat {\sigma} _ {i, t} ^ {2}\right) = \frac {\operatorname {V a r} \left(\hat {\sigma} _ {0 , t} ^ {2}\right)}{\operatorname {V a r} \left(\hat {\sigma} _ {i , t} ^ {2}\right)},
$$

Garman and Klass (1980) found that $\mathrm { E f f } ( \hat { \sigma } _ { i , t } ^ { 2 } )$ is approximately 2, 5.2, 6.2, 7.4, and 8.4 for $i = 1 , 2 , 3 , 5 $ and 6, respectively, for the simple diffusion model entertained. Note that $\hat { \sigma } _ { 2 , t } ^ { 2 }$ was derived by Parkinson (1980) with $f = 0$ .

Define the following:

• $o _ { t } = \ln ( O _ { t } ) - \ln ( C _ { t - 1 } )$ , the normalized open.   
• $u _ { t } = \ln ( H _ { t } ) - \ln ( O _ { t } )$ , the normalized high.   
• $d _ { t } = \ln ( L _ { t } ) - \ln ( O _ { t } )$ , the normalized low.   
• $c _ { t } = \ln ( C _ { t } ) - \ln ( O _ { t } )$ , the normalized close.

Suppose that there are $n$ days of data available and the volatility is constant over the period. Yang and Zhang (2000) recommend the estimate

$$
\hat {\sigma} _ {y z} ^ {2} = \hat {\sigma} _ {o} ^ {2} + k \hat {\sigma} _ {c} ^ {2} + (1 - k) \hat {\sigma} _ {r s} ^ {2}
$$

as a robust estimator of the volatility, where

$$
\begin{array}{l} \hat {\sigma} _ {o} ^ {2} = \frac {1}{n - 1} \sum_ {t = 1} ^ {n} (o _ {t} - \overline {{o}}) ^ {2} \quad \text {w i t h} \quad \overline {{o}} = \frac {1}{n} \sum_ {t = 1} ^ {n} o _ {t}, \\ \hat {\sigma} _ {c} ^ {2} = \frac {1}{n - 1} \sum_ {t = 1} ^ {n} (c _ {t} - \overline {{c}}) ^ {2} \quad \text {w i t h} \quad \overline {{c}} = \frac {1}{n} \sum_ {t = 1} ^ {n} c _ {t}, \\ \hat {\sigma} _ {r s} ^ {2} = \frac {1}{n} \sum_ {t = 1} ^ {n} \left[ u _ {t} \left(u _ {t} - c _ {t}\right) + d _ {t} \left(d _ {t} - c _ {t}\right) \right], \\ k = \frac {0 . 3 4}{1 . 3 4 + (n + 1) / (n - 1)}. \\ \end{array}
$$

The estimate $\hat { \sigma } _ { r s } ^ { 2 }$ was proposed by Rogers and Satchell (1991), and the quantity $k$ is chosen to minimize the variance of the estimator of $\hat { \sigma } _ { y z } ^ { 2 }$ , which is a linear combination of three estimates.

The quantity $H _ { t } - L _ { t }$ is called the range of the price in the tth day. This estimator has led to the use of range-based volatility estimates; see, for instance, Alizadeh, Brandt, and Diebold (2002). In practice, stock prices are only observed at discrete time points. As such, the observed daily high is likely lower than $H _ { t }$ and the observed daily low is likely higher than $L _ { t }$ . Consequently, the observed daily price range tends to underestimate the actual range and, hence, may lead to underestimation of volatility. This bias in volatility estimation depends on the trading frequency and tick size of the stocks. For intensively traded stocks, the bias should be negligible. For other stocks, further study is needed to better understand the performance of range-based volatility estimation.

# 3.16 KURTOSIS OF GARCH MODELS

Uncertainty in volatility estimation is an important issue, but it is often overlooked. To assess the variability of an estimated volatility, one must consider the kurtosis of a volatility model. In this section, we derive the excess kurtosis of a GARCH(1,1) model. The same idea applies to other GARCH models, however. The model considered is

$$
a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2},
$$

where $\alpha _ { 0 } > 0$ , $\alpha _ { 1 } \geq 0$ , $\beta _ { 1 } \geq 0$ , $\alpha _ { 1 } + \beta _ { 1 } < 1$ , and $\left\{ \epsilon _ { t } \right\}$ is an iid sequence satisfying

$$
E (\epsilon_ {t}) = 0, \quad \operatorname {V a r} (\epsilon_ {t}) = 1, \quad E (\epsilon_ {t} ^ {4}) = K _ {\epsilon} + 3,
$$

where $K _ { \epsilon }$ is the excess kurtosis of the innovation $\epsilon _ { t }$ . Based on the assumption, we have the following:

• $\mathrm { V a r } ( a _ { t } ) = E ( \sigma _ { t } ^ { 2 } ) = \alpha _ { 0 } / [ 1 - ( \alpha _ { 1 } + \beta _ { 1 } ) ] .$   
• $E ( a _ { t } ^ { 4 } ) = ( K _ { \epsilon } + 3 ) E ( \sigma _ { t } ^ { 4 } )$ provided that $E ( \sigma _ { t } ^ { 4 } )$ exists.

Taking the square of the volatility model, we have

$$
\sigma_ {t} ^ {4} = \alpha_ {0} ^ {2} + \alpha_ {1} ^ {2} a _ {t - 1} ^ {4} + \beta_ {1} ^ {2} \sigma_ {t - 1} ^ {4} + 2 \alpha_ {0} \alpha_ {1} a _ {t - 1} ^ {2} + 2 \alpha_ {0} \beta_ {1} \sigma_ {t - 1} ^ {2} + 2 \alpha_ {1} \beta_ {1} \sigma_ {t - 1} ^ {2} a _ {t - 1} ^ {2}.
$$

Taking expectation of the equation and using the two properties mentioned earlier, we obtain

$$
E (\sigma_ {t} ^ {4}) = \frac {\alpha_ {0} ^ {2} (1 + \alpha_ {1} + \beta_ {1})}{[ 1 - (\alpha_ {1} + \beta_ {1}) ] [ 1 - \alpha_ {1} ^ {2} (K _ {\epsilon} + 2) - (\alpha_ {1} + \beta_ {1}) ^ {2} ]},
$$

provided that $1 > \alpha _ { 1 } + \beta _ { 1 } \geq 0$ and $1 - \alpha _ { 1 } ^ { 2 } ( K _ { \epsilon } + 2 ) - ( \alpha _ { 1 } + \beta _ { 1 } ) ^ { 2 } > 0 \mathrm { , }$ . The excess kurtosis of $a _ { t }$ , if it exists, is then

$$
\begin{array}{l} K _ {a} = \frac {E (a _ {t} ^ {4})}{[ E (a _ {t} ^ {2}) ] ^ {2}} - 3 \\ = \frac {(K _ {\epsilon} + 3) [ 1 - (\alpha_ {1} + \beta_ {1}) ^ {2} ]}{1 - 2 \alpha_ {1} ^ {2} - (\alpha_ {1} + \beta_ {1}) ^ {2} - K _ {\epsilon} \alpha_ {1} ^ {2}} - 3. \\ \end{array}
$$

This excess kurtosis can be written in an informative expression. First, consider the case that $\epsilon _ { t }$ is normally distributed. In this case, $K _ { \epsilon } = 0$ , and some algebra shows that

$$
K _ {a} ^ {(g)} = \frac {6 \alpha_ {1} ^ {2}}{1 - 2 \alpha_ {1} ^ {2} - (\alpha_ {1} + \beta_ {1}) ^ {2}},
$$

where the superscript $( g )$ is used to denote Gaussian distribution. This result has two important implications: (a) the kurtosis of $a _ { t }$ exists if $1 - 2 \alpha _ { 1 } ^ { 2 } - ( \alpha _ { 1 } + \beta _ { 1 } ) ^ { 2 } > 0$ , and (b) if $\alpha _ { 1 } = 0$ , then $K _ { a } ^ { ( g ) } = 0$ , meaning that the corresponding GARCH(1,1) model does not have heavy tails.

Second, consider the case that $\epsilon _ { t }$ is not Gaussian. Using the prior result, we have

$$
\begin{array}{l} K _ {a} = \frac {K _ {\epsilon} - K _ {\epsilon} (\alpha_ {1} + \beta_ {1}) + 6 \alpha_ {1} ^ {2} + 3 K _ {\epsilon} \alpha_ {1} ^ {2}}{1 - 2 \alpha_ {1} ^ {2} - (\alpha_ {1} + \beta_ {1}) ^ {2} - K _ {\epsilon} \alpha_ {1} ^ {2}} \\ = \frac {K _ {\epsilon} [ 1 - 2 \alpha_ {1} ^ {2} - (\alpha_ {1} + \beta_ {1}) ^ {2} ] + 6 \alpha_ {1} ^ {2} + 5 K _ {\epsilon} \alpha_ {1} ^ {2}}{1 - 2 \alpha_ {1} ^ {2} - (\alpha_ {1} + \beta_ {1}) ^ {2} - K _ {\epsilon} \alpha_ {1} ^ {2}} \\ = \frac {K _ {\epsilon} + K _ {a} ^ {(g)} + \frac {5}{6} K _ {\epsilon} K _ {a} ^ {(g)}}{1 - \frac {1}{6} K _ {\epsilon} K _ {a} ^ {(g)}}. \\ \end{array}
$$

This result was obtained originally by George C. Tiao; see Bai, Russell, and Tiao (2003). It holds for all GARCH models provided that the kurtosis exists. For instance, if $\beta _ { 1 } = 0$ , then the model reduces to an ARCH(1) model. In this case, it is easy to verify that $K _ { a } ^ { ( g ) } = 6 \alpha _ { 1 } ^ { 2 } / ( 1 - 3 \alpha _ { 1 } ^ { 2 } )$ provided that $1 > 3 \alpha _ { 1 } ^ { 2 }$ and the excess kurtosis of $a _ { t }$ is

$$
\begin{array}{l} K _ {a} = \frac {\left(K _ {\epsilon} + 3\right) \left(1 - \alpha_ {1} ^ {2}\right)}{1 - \left(K _ {\epsilon} + 3\right) \alpha_ {1} ^ {2}} - 3 = \frac {K _ {\epsilon} + 2 K _ {\epsilon} \alpha_ {1} ^ {2} + 6 \alpha_ {1} ^ {2}}{1 - 3 \alpha_ {1} ^ {2} - K _ {\epsilon} \alpha_ {1} ^ {2}} \\ = \frac {K _ {\epsilon} (1 - 3 \alpha_ {1} ^ {2}) + 6 \alpha_ {1} ^ {2} + 5 K _ {\epsilon} \alpha_ {1} ^ {2}}{1 - 3 \alpha_ {1} ^ {2} - K _ {\epsilon} \alpha_ {1} ^ {2}} \\ = \frac {K _ {\epsilon} + K _ {a} ^ {(g)} + \frac {5}{6} K _ {\epsilon} K _ {a} ^ {(g)}}{1 - \frac {1}{6} K _ {\epsilon} K _ {a} ^ {(g)}}. \\ \end{array}
$$

The prior result shows that for a GARCH(1,1) model the coefficient $\alpha _ { 1 }$ plays a critical role in determining the tail behavior of $a _ { t }$ . If $\alpha _ { 1 } = 0$ , then $K _ { a } ^ { ( g ) } = 0$ and

$K _ { a } = K _ { \epsilon }$ . In this case, the tail behavior of $a _ { t }$ is similar to that of the standardized noise $\epsilon _ { t }$ . Yet if $\alpha _ { 1 } > 0$ , then $K _ { a } ^ { ( g ) } > 0$ and the $a _ { t }$ process has heavy tails.

For a (standardized) Student-t distribution with $v$ degrees of freedom, we have $E ( \epsilon _ { t } ^ { 4 } ) = 6 / ( v - 4 ) + 3$ if $v > 4$ . Therefore, the excess kurtosis of $\epsilon _ { t }$ is $K _ { \epsilon } =$ $6 / ( v - 4 )$ for $v > 4$ . This is part of the reason that we used $t _ { 5 }$ in the chapter when the degrees of freedom of a $t$ -distribution are prespecified. The excess kurtosis of $a _ { t }$ becomes $K _ { a } = [ 6 + ( v + 1 ) K _ { a } ^ { ( g ) } ] / [ v - 4 - \stackrel { \textstyle ^ { - } } { K _ { a } ^ { ( \bar { g } ) } } ]$ provided that $1 - 2 \alpha _ { 1 } ^ { 2 } ( v -$ $1 ) / ( v - 4 ) - ( \alpha _ { 1 } + \beta _ { 1 } ) ^ { 2 } > 0$ .

# APPENDIX: SOME RATS PROGRAMS FOR ESTIMATING VOLATILITY MODELS

The data file used in the illustration is sp500.txt, which contains the monthly excess returns of the S&P 500 index with 792 observations. Comments in a RATS program start with *.

A Gaussian GARCH(1,1) Model with a Constant Mean Equation   
```txt
all 0 792:1  
open data sp500.txt  
data(org=obs) / rt  
*** initialize the conditional variance function  
set h = 0.0  
*** specify the parameters of the model  
nonlin mu a0 a1 b1  
*** specify the mean equation  
frml at = rt(t)-mu  
*** specify the volatility equation  
frml gvar = a0+a1*at(t-1)**2+b1*h(t-1)  
*** specify the log likelihood function  
frml garchln = -0.5*log(h(t)=gvar(t))-0.5*at(t)**2/h(t)  
*** sample period used in estimation  
smpl 2 792  
*** initial estimates  
compute a0 = 0.01, a1 = 0.1, b1 = 0.5, mu = 0.1  
maximize(method=bhhh, recursive, iterations=150) garchln  
set fv = gvar(t)  
set resid = at(t)/sqrt(fv(t))  
set residsq = resid(t)*resid(t)  
*** Checking standardized residuals  
cor(qstats,number=20, span=10) resid  
*** Checking squared standardized residuals  
cor(qstats,number=20, span=10) residsq 
```

A GARCH(1,1) Model with Student-t Innovation   
```txt
all 0 792:1  
open data sp500.txt  
data(org=obs) / rt  
set h = 0.0 
```

```txt
nonlin mu a0 a1 b1 v  
frml at = rt(t) -mu  
frml gvar = a0 + a1 * at(t-1) ** 2 + b1 * h(t-1)  
frml tt = at(t) ** 2 / (h(t) = gvar(t))  
frml tln = %LNGAMMA((v+1)/2.) - %LNGAMMA(v/2.) - 0.5 * log(v-2.)  
frml gln = tln - ((v+1)/2.) * log(1.0 + tt(t) / (v-2.0)) - 0.5 * log(h(t))  
smp1 2792  
compute a0 = 0.01, a1 = 0.1, b1 = 0.5, mu = 0.1, v = 10  
maximize(method=bhhh, recursive, iterations=150) gln  
set fv = gvar(t)  
set resid = at(t) / sqrt(fv(t))  
set residsq = resid(t) * resid(t)  
cor(qstats, number=20, span=10) resid  
cor(qstats, number=20, span=10) residsq 
```

An AR(1)–EGARCH(1,1) Model for Monthly Log Returns of IBM Stock   
```lisp
all 0 864:1  
open data m-ibm.txt  
data(org=obs) / rt  
set h = 0.0  
nonlin c0 p1 th ga a0 a1  
frml at = rt(t) -c0-p1*rt(t-1)  
frml epsi = at(t) / (sqrt(exp(h(t))))  
frml g = th*epsi(t) + ga*(abs(epsi(t)) - sqrt(2./%PI))  
frml gvar = a1*h(t-1) + (1-a1)*a0+g(t-1)  
frml garchln = -0.5*(h(t)=gvar(t)) - 0.5*epsi(t)**2  
smpl 3 864  
compute c0 = 0.01, p1 = 0.01, th = 0.1, ga = 0.1  
compute a0 = 0.01, a1 = 0.5  
maximize(method=bhhh, recursive, iterations=150) garchln  
set fv = gvar(t)  
set resid = epsi(t)  
set residsq = resid(t)*resid(t)  
cor(qstats, number=20, span=10) resid  
cor(qstats, number=20, span=10) residsq 
```

# EXERCISES

3.1. Derive multistep ahead forecasts for a GARCH(1,2) model at the forecast origin $h$ .   
3.2. Derive multistep ahead forecasts for a GARCH(2,1) model at the forecast origin $h$ .   
3.3. Suppose that $r _ { 1 } , \ldots , r _ { n }$ are observations of a return series that follows the AR(1)–GARCH(1,1) model

$$
r _ {t} = \mu + \phi_ {1} r _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2},
$$

where $\epsilon _ { t }$ is a standard Gaussian white noise series. Derive the conditional log likelihood function of the data.

3.4. In the previous equation, assume that $\epsilon _ { t }$ follows a standardized Student-t distribution with v degrees of freedom. Derive the conditional log likelihood function of the data.   
3.5. Consider the monthly simple returns of Intel stock from 1973 to 2003 in m-intc7303.txt. Transform the returns into log returns. Build a GARCH model for the transformed series and compute 1-step to 5-step ahead volatility forecasts at the forecast origin December 2003.   
3.6. The file $\mathtt { m - m r k 4 6 0 3 }$ .txt contains monthly simple returns of Merck stock from June 1946 to December 2003. The file has two columns denoting date and simple return. Transform the simple returns to log returns.

(a) Is there any evidence of serial correlations in the log returns? Use autocorrelations and $5 \%$ significance level to answer the question. If yes, remove the serial correlations.   
(b) Is there any evidence of ARCH effects in the log returns? Use the residual series if there is serial correlation in part (a). Use Ljung – Box statistics for the squared returns (or residuals) with 6 and 12 lags of autocorrelation and $5 \%$ significance level to answer the question.   
(c) Identify an ARCH model for the data and fit the identified model. Write down the fitted model.

3.7. The file m-3m4603.txt contains two columns. They are date and the monthly simple return for 3M stock. Transform the returns to log returns.

(a) Is there any evidence of ARCH effects in the log returns? Use Ljung–Box statistics with 6 and 12 lags of autocorrelations and $5 \%$ significance level to answer the question.   
(b) Use the PACF of the squared returns to identify an ARCH model. What is the fitted model?   
(c) There are 695 data points. Refit the model using the first 690 observations and use the fitted model to predict the volatilities for $t$ from 691 to 695 (the forecast origin is 690).   
(d) Build an ARCH-M model for the log return series of 3M stock. Test the hypothesis that the risk premium is zero at the $5 \%$ significance level. Draw your conclusion.   
(e) Build an EGARCH model for the log return series of 3M stock using the first 690 observations. Use the fitted model to compute 1-step to 5-step ahead volatility forecasts at the forecast origin $h = 6 9 0$ .

3.8. The file m-gmsp5003.txt contains the dates and monthly simple returns of General Motors stock and the S&P 500 index from 1950 to 2003.

(a) Build a GARCH model with Gaussian innovations for the log returns of GM stock. Check the model and write down the fitted model.

(b) Build a GARCH-M model with Gaussian innovations for the log returns of GM stock. What is the fitted model?

(c) Build a GARCH model with Student-t distribution for the log returns of GM stock, including estimation of the degrees of freedom. Write down the fitted model. Let $v$ be the degrees of freedom of the Student-t distribution. Test the hypothesis $H _ { o } \colon v = 6$ versus $H _ { a } \colon v \neq 6$ , using the $5 \%$ significance level.

(d) Build an EGARCH model for the log returns of GM stock. What is the fitted model?

(e) Obtain 1-step to 6-step ahead volatility forecasts for all the models obtained. Compare the forecasts.

3.9. Consider the monthly log returns of GM stock in m-gmsp5003.txt. Build an adequate TGARCH model for the series. Write down the fitted model and test for the significance of the leverage effect. Obtain 1-step to 6-step ahead volatility forecasts.

3.10. Again, consider the returns in m-gmsp5003.txt.

(a) Build a Gaussian GARCH model for the monthly log returns of the S&P 500 index. Check the model carefully.

(b) Is there a summer effect on the volatility of the index return? Use the GARCH model built in part (a) to answer this question.

(c) Are lagged returns of GM stock useful in modeling the index volatility? Again, use the GARCH model of part (a) as a baseline model for comparison.

3.11. The file d-gmsp9303.txt contains the daily simple returns of GM stock and the S&P composite index from 1993 to 2003. It has three columns denoting date, GM return, and SP return.

(a) Compute the daily log returns of GM stock. Is there any evidence of ARCH effects in the log returns? You may use 10 lags of the squared returns and $5 \%$ significance level to perform the test.

(b) Compute the PACF of the squared log returns (10 lags).

(c) Specify a GARCH model for the GM log return using a normal distribution for the innovations. Perform model checking and write down the fitted model.

(d) Find an adequate GARCH model for the series but using the generalized error distribution for the innovations. Write down the fitted model.

3.12. Consider the daily simple returns of the S&P composite index in the file d-gmsp9303.txt.

(a) Is there any ARCH effect in the simple return series? Use 10 lags of the squared returns and $5 \%$ significance level to perform the test.   
(b) Build an adequate GARCH model for the simple return series.   
(c) Compute 1-step to 4-step ahead forecasts of the simple return and its volatility based on the fitted model.

3.13. Again, consider the daily simple returns of GM stock in the file d-gmsp9303.txt.

(a) Find an adequate GARCH-M model for the series. Write down the fitted model.   
(b) Find an adequate EGARCH model for the series. Is the “leverage” effect significant at the $5 \%$ level?

3.14. Revisit the file d-gmsp9303.txt. However, we shall investigate the value of using market volatility in modeling volatility of individual stocks. Convert the two simple return series into percentage log return series.

(a) Build an AR(5)–GARCH(1,1) model with generalized error distribution for the log S&P returns. The AR(5) contains only lags 3 and 5. Denote the fitted volatility series by “spvol.”   
(b) Estimate a GARCH(1,1) model with spvol as an exogenous variable to the log GM return series. Check the adequacy of the model, and write down the fitted model. In S-Plus, the command is

$$
f i t = \operatorname {g a r c h} (\mathrm {g m} \sim 1, \sim \operatorname {g a r c h} (1, 1) + \operatorname {s p v o l}, \operatorname {c o n d . d i s t} = ^ {\prime} \operatorname {g e d} ^ {\prime})
$$

(c) Discuss the implication of the fitted model.

3.15. Again, consider the percentage daily log returns of GM stock and the S&P 500 index from 1993 to 2003 as before, but we shall investigate whether the volatility of GM stock has any contribution in modeling the S&P 500 index volatility. Follow the steps below to perform the analysis.

(a) Fit a GARCH(1,1) model with generalized error distribution to the percentage log returns of GM stock. Denote the fitted volatility by gmvol. Build an adequate GARCH model plus gmvol as the exogenous variable for the log S&P return series. Write down the fitted model.   
(b) Is the volatility of GM stock returns helpful in modeling the volatility of the S&P index returns? Why?

# REFERENCES

Alizadeh, S., Brandt, M., and Diebold, F. X. (2002). Range-based estimation of stochastic volatility models. Journal of Finance 57: 1047–1092.

Andersen, T. G. and Bollerslev, T. (1998). Answering the skeptics: Yes, standard volatility models do provide accurate forecasts. International Economic Review 39: 885–905.

Andersen, T. G., Bollerslev, T., Diebold, F. X., and Labys, P. (2001a). The distribution of realized exchange rate volatility. Journal of the American Statistical Association 96: 42–55.   
Andersen, T. G., Bollerslev, T., Diebold, F. X., and Labys, P. (2001b). The distribution of realized stock return volatility. Journal of Financial Economics 61: 43–76.   
Bai, X., Russell, J. R., and Tiao, G. C. (2003). Kurtosis of GARCH and stochastic volatility models with non-normal innovations. Journal of Econometrics 114: 349–360.   
Bai, X., Russell, J. R., and Tiao, G. C. (2004). Effects of non-normality and dependence on the precision of variance estimates using high-frequency financial data. Revised working paper, Graduate School of Business, University of Chicago.   
Barndorff-Nielsen, O. E. and Shephard, N. (2004). Power and bi-power variations with stochastic volatility and jumps (with discussion). Journal of Financial Econometrics 2: 1–48.   
Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics 31: 307–327.   
Bollerslev, T. (1990). Modeling the coherence in short-run nominal exchange rates: a multivariate generalized ARCH approach. Review of Economics and Statistics 72: 498–505.   
Bollerslev, T., Chou, R. Y., and Kroner, K. F. (1992). ARCH modeling in finance. Journal of Econometrics 52: 5–59.   
Bollerslev, T., Engle, R. F., and Nelson, D. B. (1994). ARCH model. In R. F. Engle and D. C. McFadden (eds.), Handbook of Econometrics IV, pp. 2959–3038. Elsevier Science, Amsterdam.   
Bollerslev, T. and Jubinski, D. (1999). Equality trading volume and volatility: latent information arrivals and common long-run dependencies. Journal of Business & Economic Statistics 17: 9–21.   
Breidt, F. J., Crato, N., and de Lima, P. (1998). On the detection and estimation of long memory in stochastic volatility. Journal of Econometrics 83: 325–348.   
Cao, C. and Tsay, R. S. (1992). Nonlinear time series analysis of stock volatilities. Journal of Applied Econometrics 7: s165–s185.   
Ding, Z., Granger, C. W. J., and Engle, R. F. (1993). A long memory property of stock returns and a new model. Journal of Empirical Finance 1: 83–106.   
Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflations. Econometrica 50: 987–1007.   
French, K. R., Schwert, G. W., and Stambaugh, R. F. (1987). Expected stock returns and volatility. Journal of Financial Economics 19: 3–29.   
Garman, M. B. and Klass, M. J. (1980). On the estimation of security price volatilities from historical data. Journal of Business 53: 67–78.   
Glosten, L. R., Jagannathan, R., and Runkle, D. E. (1993). On the relation between the expected value and the volatility of nominal excess return on stocks. Journal of Finance 48: 1779–1801.   
Harvey, A. C., Ruiz, E., and Shephard, N. (1994). Multivariate stochastic variance models. Review of Economic Studies 61: 247–264.   
Jacquier, E., Polson, N. G., and Rossi, P. (1994). Bayesian analysis of stochastic volatility models (with discussion). Journal of Business & Economic Statistics 12: 371–417.   
McLeod, A. I. and Li, W. K. (1983). Diagnostic checking ARMA time series models using squared-residual autocorrelations. Journal of Time Series Analysis 4: 269–273.

Melino, A. and Turnbull, S. M. (1990). Pricing foreign currency options with stochastic volatility. Journal of Econometrics 45: 239–265.   
Nelson, D. B. (1990). Stationarity and persistence in the GARCH(1,1) model. Econometric Theory 6: 318–334.   
Nelson, D. B. (1991). Conditional heteroskedasticity in asset returns: A new approach. Econometrica 59: 347–370.   
Nicholls, D. F. and Quinn, B. G. (1982). Random Coefficient Autoregressive Models: An Introduction, Lecture Notes in Statistics, 11. Springer-Verlag, New York.   
Parkinson, M. (1980). The extreme value method for estimating the variance of the rate of return. Journal of Business 53: 61–65.   
Ray, B. K. and Tsay, R. S. (2000). Long-range dependence in daily stock volatilities. Journal of Business & Economic Statistics 18: 254–262.   
Rogers, L. C. G. and Satchell, S. E. (1991). Estimating variance from high, low and closing prices. Annals of Applied Probability 1: 504–512.   
Taylor, S. J. (1994). Modeling stochastic volatility: A review and comparative study. Mathematical Finance 4: 183–204.   
Tong, H. (1978). On a threshold model. In C. H. Chen (ed.), Pattern Recognition and Signal Processing. Sijhoff & Noordhoff, Amsterdam.   
Tong, H. (1990). Non-Linear Time Series: A Dynamical System Approach. Oxford University Press, Oxford, UK.   
Tsay, R. S. (1987). Conditional heteroscedastic time series models. Journal of the American Statistical Association 82: 590–604.   
Yang, D. and Zhang, Q. (2000). Drift-independent volatility estimation based on high, low, open, and close prices. Journal of Business 73: 477–491.   
Zakoian, J. M. (1994). Threshold heteroscedastic models. Journal of Economic Dynamics and Control 18: 931–955.

# Nonlinear Models and Their Applications

This chapter focuses on nonlinearity in financial data and nonlinear econometric models useful in analysis of financial time series. Consider a univariate time series $x _ { t }$ , which, for simplicity, is observed at equally spaced time points. We denote the observations by $\{ x _ { t } | t = 1 , \ldots , T \}$ , where $T$ is the sample size. As stated in Chapter 2, a purely stochastic time series $x _ { t }$ is said to be linear if it can be written as

$$
x _ {t} = \mu + \sum_ {i = 0} ^ {\infty} \psi_ {i} a _ {t - i}, \tag {4.1}
$$

where $\mu$ is a constant, $\psi _ { i }$ are real numbers with $\psi _ { 0 } = 1$ , and $\{ a _ { t } \}$ is a sequence of independent and identically distributed (iid) random variables with a well-defined distribution function. We assume that the distribution of $a _ { t }$ is continuous and $E ( a _ { t } ) = 0$ . In many cases, we further assume that $\mathrm { V a r } ( a _ { t } ) = \sigma _ { a } ^ { 2 }$ or, even stronger, that $a _ { t }$ =is Gaussian. If $\sigma _ { a } ^ { 2 } \sum _ { i = 1 } ^ { \infty } \psi _ { i } ^ { 2 } < \infty$ , then $x _ { t }$ = ais weakly stationary (i.e., the first two moments of $x _ { t }$ are time-invariant). The ARMA process of Chapter 2 is linear because it has an MA representation in Eq. (4.1). Any stochastic process that does not satisfy the condition of Eq. (4.1) is said to be nonlinear. The prior definition of nonlinearity is for purely stochastic time series. One may extend the definition by allowing the mean of $x _ { t }$ to be a linear function of some exogenous variables, including the time index and some periodic functions. But such a mean function can be handled easily by the methods discussed in Chapter 2, and we do not discuss it here. Mathematically, a purely stochastic time series model for $x _ { t }$ is a function of an iid sequence consisting of the current and past shocks—that is,

$$
x _ {t} = f \left(a _ {t}, a _ {t - 1}, \dots\right). \tag {4.2}
$$

The linear model in Eq. (4.1) says that $f ( . )$ is a linear function of its arguments. Any nonlinearity in $f ( . )$ results in a nonlinear model. The general nonlinear model in Eq. (4.2) is not directly applicable because it contains too many parameters.

To put nonlinear models available in the literature in a proper perspective, we write the model of $x _ { t }$ in terms of its conditional moments. Let $F _ { t - 1 }$ be the $\sigma$ -field generated by available information at time $t - 1$ (inclusive). Typically, $F _ { t - 1 }$ denotes the collection of linear combinations of elements in $\{ x _ { t - 1 } , x _ { t - 2 } , . . . \}$ and $\{ a _ { t - 1 } , a _ { t - 2 } , . . . \}$ . The conditional mean and variance of $x _ { t }$ given $F _ { t - 1 }$ are

$$
\mu_ {t} = E \left(x _ {t} \mid F _ {t - 1}\right) \equiv g \left(F _ {t - 1}\right), \quad \sigma_ {t} ^ {2} = \operatorname {V a r} \left(x _ {t} \mid F _ {t - 1}\right) \equiv h \left(F _ {t - 1}\right), \tag {4.3}
$$

where $g ( . )$ and $h ( . )$ are well-defined functions with $h ( . ) > 0$ . Thus, we restrict the model to

$$
x _ {t} = g (F _ {t - 1}) + \sqrt {h (F _ {t - 1})} \epsilon_ {t},
$$

where $\epsilon _ { t } = a _ { t } / \sigma _ { t }$ is a standardized shock (or innovation). For the linear series $x _ { t }$ in Eq. (4.1), $g ( . )$ is a linear function of elements of $F _ { t - 1 }$ and $h ( . ) = \sigma _ { a } ^ { 2 }$ . The development of nonlinear models involves making extensions of the two equations in Eq. (4.3). If $g ( . )$ is nonlinear, $x _ { t }$ is said to be nonlinear in mean. If $h ( . )$ is timevariant, then $x _ { t }$ is nonlinear in variance. The conditional heteroscedastic models of Chapter 3 are nonlinear in variance because their conditional variances $\sigma _ { t } ^ { 2 }$ evolve over time. In fact, except for the GARCH-M models, in which $\mu _ { t }$ depends on $\sigma _ { t } ^ { 2 }$ and hence also evolves over time, all of the volatility models of Chapter 3 focus on modifications or extensions of the conditional variance equation in Eq. (4.3). Based on the well-known Wold decomposition, a weakly stationary and purely stochastic time series can be expressed as a linear function of uncorrelated shocks. For stationary volatility series, these shocks are uncorrelated, but dependent. The models discussed in this chapter represent another extension to nonlinearity derived from modifying the conditional mean equation in Eq. (4.3).

Many nonlinear time series models have been proposed in the statistical literature, such as the bilinear models of Granger and Andersen (1978), the threshold autoregressive (TAR) model of Tong (1978), the state-dependent model of Priestley (1980), and the Markov switching model of Hamilton (1989). The basic idea underlying these nonlinear models is to let the conditional mean $\mu _ { t }$ evolve over time according to some simple parametric nonlinear function. Recently, a number of nonlinear models have been proposed by making use of advances in computing facilities and computational methods. Examples of such extensions include the nonlinear state-space modeling of Carlin, Polson, and Stoffer (1992), the functionalcoefficient autoregressive model of Chen and Tsay (1993a), the nonlinear additive autoregressive model of Chen and Tsay (1993b), and the multivariate adaptive regression spline of Lewis and Stevens (1991). The basic idea of these extensions is either using simulation methods to describe the evolution of the conditional distribution of $x _ { t }$ or using data-driven methods to explore the nonlinear characteristics of a series. Finally, nonparametric and semiparametric methods such as kernel regression and artificial neural networks have also been applied to explore the nonlinearity in a time series. We discuss some nonlinear models in Section 4.3 that are applicable to financial time series. The discussion includes some nonparametric and semiparametric methods.

Apart from the development of various nonlinear models, there is substantial interest in studying test statistics that can discriminate linear series from nonlinear ones. Both parametric and nonparametric tests are available. Most parametric tests employ either the Lagrange multiplier or likelihood ratio statistics. Nonparametric tests depend on either higher order spectra of $x _ { t }$ or the concept of dimension correlation developed for chaotic time series. We review some nonlinearity tests in Section 4.2. Sections 4.3 and 4.4 discuss modeling and forecasting of nonlinear models. Finally, an application of nonlinear models is given in Section 4.5.

# 4.1 NONLINEAR MODELS

Most nonlinear models developed in the statistical literature focus on the conditional mean equation in Eq. (4.3); see Priestley (1988) and Tong (1990) for summaries of nonlinear models. Our goal here is to introduce some nonlinear models that are applicable to financial time series.

# 4.1.1 Bilinear Model

The linear model in Eq. (4.1) is simply the first-order Taylor series expansion of the $f ( . )$ function in Eq. (4.2). As such, a natural extension to nonlinearity is to employ the second-order terms in the expansion to improve the approximation. This is the basic idea of bilinear models, which can be defined as

$$
x _ {t} = c + \sum_ {i = 1} ^ {p} \phi_ {i} x _ {t - i} - \sum_ {j = 1} ^ {q} \theta_ {j} a _ {t - j} + \sum_ {i = 1} ^ {m} \sum_ {j = 1} ^ {s} \beta_ {i j} x _ {t - i} a _ {t - j} + a _ {t}, \tag {4.4}
$$

where $p , q , m$ , and $s$ are non-negative integers. This model was introduced by Granger and Andersen (1978) and has been widely investigated. Subba Rao and Gabr (1984) discuss some properties and applications of the model, and Liu and Brockwell (1988) study general bilinear models. Properties of bilinear models such as stationarity conditions are often derived by (a) putting the model in a statespace form (see Chapter 11) and (b) using the state transition equation to express the state as a product of past innovations and random coefficient vectors. A special generalization of the bilinear model in Eq. (4.4) has conditional heteroscedasticity. For example, consider the model

$$
x _ {t} = \mu + \sum_ {i = 1} ^ {s} \beta_ {i} a _ {t - i} a _ {t} + a _ {t}, \tag {4.5}
$$

where $\{ a _ { t } \}$ is a white noise series. The first two conditional moments of $x _ { t }$ are

$$
E (x _ {t} | F _ {t - 1}) = \mu , \quad \operatorname {V a r} (x _ {t} | F _ {t - 1}) = \left(1 + \sum_ {i = 1} ^ {s} \beta_ {i} a _ {t - i}\right) ^ {2} \sigma_ {a} ^ {2},
$$

which are similar to that of the RCA or CHARMA model of Chapter 3.

Example 4.1. Consider the monthly simple returns of the CRSP equal-weighted index from January 1926 to December 1997 for 864 observations. Denote the series by $R _ { t }$ . The sample PACF of $R _ { t }$ shows significant partial autocorrelations at lags 1 and 3, whereas that of $R _ { t } ^ { 2 }$ suggests that the conditional heteroscedasticity might depend on the past three innovations. Therefore, we employ the special bilinear model

$$
R _ {t} = \mu + \phi_ {1} R _ {t - 1} + \phi_ {3} R _ {t - 3} + \left(1 + \beta_ {1} a _ {t - 1} + \beta_ {2} a _ {t - 2} + \beta_ {3} a _ {t - 3}\right) a _ {t}
$$

for the series. Assuming that the conditional distribution of $a _ { t }$ is normal, we use the conditional maximum likelihood method and obtain the fitted model

$$
\begin{array}{l} R _ {t} = 0. 0 1 4 + 0. 1 6 0 R _ {t - 1} - 0. 1 0 4 R _ {t - 3} \\ + (1 + 0. 3 3 7 a _ {t - 1} - 0. 0 2 2 a _ {t - 2} - 0. 6 0 1 a _ {t - 3}) a _ {t}, \tag {4.6} \\ \end{array}
$$

where $\hat { \sigma } _ { a } ^ { 2 } = 0 . 0 0 5 2$ and the standard errors of the parameters are, in the order of appearance, 0.003, 0.026, 0.018, 0.083, 0.084, and 0.079. The only insignificant estimate is the coefficient of $a _ { t - 2 }$ . Define

$$
\hat {a} _ {t} = \frac {R _ {t} - 0 . 0 1 4 - 0 . 1 6 0 R _ {t - 1} + 0 . 0 1 4 R _ {t - 3}}{1 + 0 . 3 3 7 \hat {a} _ {t - 1} - 0 . 0 2 2 \hat {a} _ {t - 2} - 0 . 6 0 1 \hat {a} _ {t - 3}},
$$

where $\hat { a } _ { t } = 0$ for $t \leq 3$ as the residual series of the model. The sample ACF of $\hat { a } _ { t }$ shows no significant serial correlations, but the series is not independent because the squared series $\hat { a } _ { t } ^ { 2 }$ has significant serial correlations. The validity of model (4.6) deserves further investigation. For comparison, we also consider an ARCH(3) model for the series and obtain

$$
\begin{array}{l} R _ {t} = 0. 0 1 3 + 0. 2 2 2 R _ {t - 1} - 0. 1 4 0 R _ {t - 3} + a _ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 0 2 + 0. 1 6 8 a _ {t - 1} ^ {2} + 0. 0 0 0 0 1 a _ {t - 2} ^ {2} + 0. 2 7 4 a _ {t - 3} ^ {2}, \tag {4.7} \\ \end{array}
$$

where all estimates but the coefficient of $a _ { t - 2 } ^ { 2 }$ are highly significant. The standard-−ized residual series and its squared series show no serial correlations, indicating that the ARCH(3) model is adequate for the data. Models (4.6) and (4.7) appear to be similar, but the latter seems to fit the data better.

# 4.1.2 Threshold Autoregressive (TAR) Model

This model is motivated by several nonlinear characteristics commonly observed in practice such as asymmetry in declining and rising patterns of a process. It uses piecewise linear models to obtain a better approximation of the conditional mean equation. However, in contrast to the traditional piecewise linear model that allows for model changes to occur in the “time” space, the TAR model uses threshold space to improve linear approximation. Let us start with a simple 2-regime AR(1) model

$$
x _ {t} = \left\{ \begin{array}{c l} - 1. 5 x _ {t - 1} + a _ {t} & \text {i f} x _ {t - 1} <   0, \\ 0. 5 x _ {t - 1} + a _ {t} & \text {i f} x _ {t - 1} \geq 0, \end{array} \right. \tag {4.8}
$$

![](images/21b096da0e9b1b9f3c357df07ba9998b7463f4e526375226a37f188fe0aa5045.jpg)  
Figure 4.1. Time plot of a simulated 2-regime TAR(1) series.

where the $a _ { t }$ are iid $N ( 0 , 1 )$ . Here the threshold variable is $x _ { t - 1 }$ so that the delay is 1, and the threshold is 0. Figure 4.1 shows the time plot of a simulated series of $x _ { t }$ with 200 observations. A horizontal line of zero is added to the plot, which illustrates several characteristics of TAR models. First, despite the coefficient $- 1 . 5$ in the first regime, the process $x _ { t }$ is geometrically ergodic and stationary. In fact, the necessary and sufficient condition for model (4.8) to be geometrically ergodic is $\phi _ { 1 } ^ { ( 1 ) } < 1$ , $\phi _ { 1 } ^ { ( \bar { 2 } ) } < 1$ , and $\phi _ { 1 } ^ { ( 1 ) } \phi _ { 1 } ^ { ( 2 ) } < 1$ , where $\phi _ { 1 } ^ { ( i ) }$ is the AR coefficient of regime $i$ ; see Petruccelli and Woolford (1984) and Chen and Tsay (1991). Ergodicity is an important concept in time series analysis. For example, the statistical theory showing that the sample mean $\textstyle { \overline { { x } } } = { \bigl ( } \sum _ { t = 1 } ^ { T } x _ { t } { \bigr ) } / T$ of $x _ { t }$ converges to the mean of $x _ { t }$ is referred to as the ergodic theorem, which can be regarded as the counterpart of the central limit theory for the iid case. Second, the series exhibits an asymmetric increasing and decreasing pattern. If $x _ { t - 1 }$ is negative, then $x _ { t }$ tends to switch to a positive value due to the negative and explosive coefficient $- 1 . 5$ . Yet when $x _ { t - 1 }$ is positive, it tends to take multiple time indexes for $x _ { t }$ to reduce to a negative value. Consequently, the time plot of $x _ { t }$ shows that regime 2 has more observations than regime 1, and the series contains large upward jumps when it becomes negative. The series is therefore not time-reversible. Third, the model contains no constant terms, but $E ( x _ { t } )$ is not zero. The sample mean of the particular realization is 0.61 with a standard deviation of 0.07. In general, $E ( x _ { t } )$ is a weighted average of the conditional means of the two regimes, which are nonzero. The weight for each regime is simply the probability that $x _ { t }$ is in that regime under its stationary

distribution. It is also clear from the discussion that, for a TAR model to have zero mean, nonzero constant terms in some of the regimes are needed. This is very different from a stationary linear model for which a nonzero constant implies that the mean of $x _ { t }$ is not zero.

A time series $x _ { t }$ is said to follow a $k$ -regime self-exciting TAR (SETAR) model with threshold variable $x _ { t - d }$ if it satisfies

$$
x _ {t} = \phi_ {0} ^ {(j)} + \phi_ {1} ^ {(j)} x _ {t - 1} - \dots - \phi_ {p} ^ {(j)} x _ {t - p} + a _ {t} ^ {(j)}, \quad \text {i f} \quad \gamma_ {j - 1} \leq x _ {t - d} <   \gamma_ {j}, \tag {4.9}
$$

where $k$ and $d$ are positive integers, $j = 1 , \ldots , k , \gamma _ { i }$ are real numbers such that $- \infty = \gamma _ { 0 } < \gamma _ { 1 } < \cdot \cdot \cdot < \gamma _ { k - 1 } < \gamma _ { k } = \infty$ , the superscript $( j )$ is used to signify the regime, and $\{ a _ { t } ^ { ( j ) } \}$ are iid sequences with mean 0 and variance $\sigma _ { j } ^ { 2 }$ and are mutually independent for different $j$ . The parameter $d$ is referred to as the delay parameter and $\gamma _ { j }$ are the thresholds. Here it is understood that the AR models are different for different regimes; otherwise, the number of regimes can be reduced. Equation (4.9) says that a SETAR model is a piecewise linear AR model in the threshold space. It is similar in spirit to the usual piecewise linear models in regression analysis, where model changes occur in the order in which observations are taken. The SETAR model is nonlinear provided that $k > 1$ .

Properties of general SETAR models are hard to obtain, but some of them can be found in Tong (1990), Chan (1993), Chan and Tsay (1998), and the references therein. In recent years, there is increasing interest in TAR models and their applications; see, for instance, Hansen (1997), Tsay (1998), and Montgomery et al. (1998). Tsay (1989) proposed a testing and modeling procedure for univariate SETAR models. The model in Eq. (4.9) can be generalized by using a threshold variable $z _ { t }$ that is measurable with respect to $F _ { t - 1 }$ (i.e., a function of elements of $F _ { t - 1 }$ ). The main requirements are that $z _ { t }$ is stationary with a continuous distribution function over a compact subset of the real line and that $z _ { t - d }$ is known at time $t$ . Such a generalized model is referred to as an open-loop TAR model.

Example 4.2. To demonstrate the application of TAR models, consider the U.S. monthly civilian unemployment rate, seasonally adjusted and measured in percentage, from January 1948 to March 2004 for 675 observations. The data are obtained from the Bureau of Labor Statistics, Department of Labor, and are shown in Figure 4.2. The plot shows two main characteristics of the data. First, there appears to be a slow, but upward trend in the overall unemployment rate. Second, the unemployment rate tends to increase rapidly and decrease slowly. Thus, the series is not time-reversible and may not be unit-root stationary, either.

Because the sample autocorrelation function decays slowly, we employ the first differenced series $y _ { t } = ( 1 - B ) u _ { t }$ in the analysis, where $u _ { t }$ is the monthly unemployment rate. Using univariate ARIMA models, we obtain the model

$$
(1 - 1. 1 8 B + 0. 3 3 B ^ {2}) (1 - 0. 5 1 B ^ {1 2}) y _ {t} = (1 - 1. 1 7 B + 0. 4 8 B ^ {2}) (1 - 0. 8 2 B ^ {1 2}) a _ {t}, \tag {4.10}
$$

![](images/34dc77cb2c7a3915b4675906bd5a3fb798e7a4246d0f757121b99d10e6c12e84.jpg)  
Figure 4.2. Time plot of monthly U.S. civilian unemployment rate, seasonally adjusted, from January 1948 to March 2004.

where $\hat { \sigma } _ { a } = 0 . 1 9 0$ and all estimates are statistically significant at the $5 \%$ level with minimum $t$ -ratio of $- 2 . 0 1$ for the AR(2) coefficient. The residuals of model (4.10) give $Q ( 1 2 ) = 9 . 9 $ and $Q ( 2 4 ) = 2 2 . 4 $ , indicating that the fitted model adequately describes the serial dependence of the data. Note that the seasonal AR and MA coefficients are highly significant with standard error 0.05 and 0.045, respectively, even though the data were seasonally adjusted. The adequacy of seasonal adjustment deserves further study.

To model nonlinearity in the data, we employ TAR models and obtain the model

$$
y _ {t} = \left\{ \begin{array}{l l} 0. 0 6 9 y _ {t - 2} + 0. 1 5 3 y _ {t - 3} + 0. 1 0 6 y _ {t - 4} - 0. 1 8 1 y _ {t - 1 2} + a _ {1 t} & \text {i f} y _ {t - 1} \leq 0. 1, \\ 0. 4 0 1 y _ {t - 2} + 0. 2 0 8 y _ {t - 3} - 0. 1 3 9 y _ {t - 1 2} + a _ {2 t} & \text {i f} y _ {t - 1} > 0. 1, \end{array} \right. \tag {4.11}
$$

where the standard errors of $a _ { i t }$ are 0.183 and 0.223, respectively, the standard errors of the AR parameters in regime 1 are 0.048, 0.044, 0.043, and 0.038 whereas those of the AR parameters in regime 2 are 0.057, 0.060, and 0.079, respectively. The number of data points in regimes 1 and 2 are 422 and 240, respectively. The residuals of model (4.11) also fail to show any significant serial correlation. Based on the fitted TAR model, the dynamic dependence in the data appears to be stronger when the change in monthly unemployment rate is greater than $0 . 1 \%$ . This is understandable because a substantial increase in the unemployment rate is indicative of weakening in the U.S. economy, and policy makers might be more inclined to

take action to help the economy, which in turn may affect the dynamics of the unemployment rate series. Consequently, model (4.11) is capable of describing the time-varying dynamics of the U.S. unemployment rate.

The MA representation of model (4.10) is

$$
\psi (B) \approx 1 + 0. 0 1 B + 0. 1 5 B ^ {2} + 0. 1 8 B ^ {3} + 0. 1 6 B ^ {4} + \dots .
$$

It is then not surprising to see that no $y _ { t - 1 }$ term appears in model (4.11).

As mentioned in Chapter 3, threshold models can be used in finance to handle the asymmetric responses in volatility between positive and negative returns. The models can also be used to study arbitrage tradings in index futures and cash prices; see Chapter 8 on multivariate time series analysis. Here we focus on volatility modeling and introduce an alternative approach to parameterization of TGARCH models. In some applications, this new general TGARCH model fares better than the GJR model of Chapter 3.

Example 4.3. Consider the daily log returns, in percentage and including dividends, of IBM stock from July 3, 1962 to December 31, 2003 for 10,446 observations. Figure 4.3 shows the time plot of the series, which is one of the longer return series analyzed in the book. The volatility seems to be larger in the latter years of the data. Because general TGARCH models are used in the analysis, we use the SCA package to perform estimation in this example.

If GARCH models of Chapter 3 are entertained, we obtain the following AR(2)–GARCH(1,1) model for the series:

$$
\begin{array}{l} r _ {t} = 0. 0 6 2 - 0. 0 2 4 r _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \begin{array}{l} t _ {t} = 0. 0 6 2 - 0. 0 2 \mathrm {i} _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} c _ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 3 7 + 0. 0 7 7 a _ {t - 1} ^ {2} + 0. 9 1 3 \sigma_ {t - 1} ^ {2}, \end{array} \tag {4.12} \\ \end{array}
$$

where $r _ { t }$ is the log return, $\{ \epsilon _ { t } \}$ is a Gaussian white noise sequence with mean zero and variance 1.0, the standard errors of the parameters in the mean equation are 0.015 and 0.010, and those of the volatility equation are 0.004, 0.003, and 0.003, respectively. All estimates are statistically significant at the $5 \%$ level. The Ljung–Box statistics of the standardized residuals give $Q ( 1 0 ) = 5 . 1 9 ( 0 . 8 8 )$ and $Q ( 2 0 ) = 2 4 . 3 8 ( 0 . 2 3 )$ , where the number in parentheses denotes $p$ -value. For the squared standardized residuals, we obtain $Q ( 1 0 ) = 1 1 . 6 7 ( 0 . 3 1 )$ and $Q ( 2 0 ) =$ 18.25(0.57). The model is adequate in modeling the serial dependence and conditional heteroscedasticity of the data. But the unconditional mean for $r _ { t }$ of model (4.12) is 0.060, which is substantially larger than the sample mean 0.039, indicating that the model might be misspecified.

Next, we employ the TGARCH model of Chapter 3 and obtain

$$
\begin{array}{l} r _ {t} = 0. 0 1 4 - 0. 0 2 8 r _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 7 5 + 0. 0 8 1 P _ {t - 1} a _ {t - 1} ^ {2} + 0. 1 5 7 N _ {t - 1} a _ {t - 1} ^ {2} + 0. 8 6 3 \sigma_ {t - 1} ^ {2}, \tag {4.13} \\ \end{array}
$$

where $P _ { t - 1 } = 1 - N _ { t - 1 }$ , $N _ { t - 1 }$ is the indicator for negative $a _ { t - 1 }$ such that $N _ { t - 1 } = 1$ if $a _ { t - 1 } < 0$ and $= 0$ otherwise, the standard errors of the parameters in the mean

![](images/1476e0f01c7147b5d22576005a18c2d11b1e77d1361bba50067a5273f6b889fc.jpg)  
Figure 4.3. Time plot of the daily log returns for IBM stock from July 3, 1962 to December 31, 2003.

equation are 0.013 and 0.009, and those of the volatility equation are 0.007, 0.008, 0.010, and 0.010, respectively. All estimates except the constant term of the mean equation are significant. Let $\tilde { a } _ { t }$ be the standardized residuals of model (4.13). We have $Q ( 1 0 ) = 2 . 4 7 ( 0 . 9 9 )$ and $Q ( 2 0 ) = 2 5 . 9 0 ( 0 . 1 7 )$ for the $\{ \tilde { a } _ { t } \}$ series and $Q ( 1 0 ) = 9 7 . 0 7 ( 0 . 0 0 )$ and $Q ( 2 0 ) = 1 7 0 . 3 ( 0 . 0 0 )$ for $\{ \tilde { a } _ { t } ^ { 2 } \}$ . The model fails to describe the conditional heteroscedasticity of the data.

The idea of TAR models can be used to refine the prior TGARCH model by allowing for increased flexibility in modeling the asymmetric response in volatility. More specifically, we consider an AR(2)–TAR–GARCH(1,1) model for the series and obtain

$$
\begin{array}{l} r _ {t} = 0. 0 3 3 - 0. 0 2 3 r _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 7 5 + 0. 0 4 1 a _ {t - 1} ^ {2} + 0. 9 0 3 \sigma_ {t - 1} ^ {2} \tag {4.14} \\ + (0. 0 3 0 a _ {t - 1} ^ {2} + 0. 0 6 2 \sigma_ {t - 1} ^ {2}) N _ {t - 1}, \\ \end{array}
$$

where $N _ { t - 1 }$ is defined in Eq. (4.13). All estimates in model (4.14) are significantly different from zero at the usual $1 \%$ level. Let $\hat { a } _ { t }$ be the standardized residuals of model (4.14). We obtain $Q ( 1 0 ) = 6 . 0 9 ( 0 . 8 1 )$ and $Q ( 2 0 ) = 2 5 . 2 9 ( 0 . 1 9 )$ for $\{ \hat { a } _ { t } \}$ and $Q ( 1 0 ) = 1 3 . 5 4 ( 0 . 2 0 )$ and $Q ( 2 0 ) = 1 9 . 5 6 ( 0 . 4 9 )$ for $\{ \hat { a } _ { t } ^ { 2 } \}$ . Thus, model (4.14) is adequate in modeling the serial correlation and conditional heteroscedasticity of the daily log returns of IBM stock considered. The unconditional mean return

of model (4.14) is 0.033, which is much closer to the sample mean 0.039 than those implied by models (4.12) and (4.13). Comparing the two fitted TGARCH models, we see that the asymmetric behavior in daily IBM stock volatility is much stronger than what is allowed in a GJR model. Specifically, the coefficient of $\sigma _ { t - 1 } ^ { 2 }$ also depends on the sign of $a _ { t - 1 }$ . Note that model (4.14) can be further refined by imposing the constraint that the sum of the coefficients of $a _ { t - 1 } ^ { 2 }$ and $\sigma _ { t - 1 } ^ { 2 }$ is one when $a _ { t - 1 } < 0$ .

Remark. A RATS program to estimate the AR(2)–TAR–GARCH(1,1) model used is given in Appendix A. The results might be slightly different from those of SCA given in the text. 

# 4.1.3 Smooth Transition AR (STAR) Model

A criticism of the SETAR model is that its conditional mean equation is not continuous. The thresholds $\{ \gamma _ { j } \}$ are the discontinuity points of the conditional mean function $\mu _ { t }$ . In response to this criticism, smooth TAR models have been proposed; see Chan and Tong (1986) and Terasvirta (1994) and the references therein. A time ¨ series $x _ { t }$ is said to follow a 2-regime $\operatorname { S T A R } ( p )$ model if it satisfies

$$
x _ {t} = c _ {0} + \sum_ {i = 1} ^ {p} \phi_ {0, i} x _ {t - i} + F \left(\frac {x _ {t - d} - \Delta}{s}\right) \left(c _ {1} + \sum_ {i = 1} ^ {p} \phi_ {1, i} x _ {t - i}\right) + a _ {t}, \tag {4.15}
$$

where $d$ is the delay parameter, $\Delta$ and $s$ are parameters representing the location and scale of model transition, and $F ( . )$ is a smooth transition function. In practice, $F ( . )$ often assumes one of three forms—namely, logistic, exponential, or a cumulative distribution function. From Eq. (4.15), the conditional mean of a STAR model is a weighted linear combination between the following two equations:

$$
\begin{array}{l} \mu_ {1 t} = c _ {0} + \sum_ {i = 1} ^ {p} \phi_ {0, i} x _ {t - i}, \\ \mu_ {2 t} = \left(c _ {0} + c _ {1}\right) + \sum_ {i = 1} ^ {p} \left(\phi_ {0, i} + \phi_ {1, i}\right) x _ {t - i}. \\ \end{array}
$$

The weights are determined in a continuous manner by $F ( ( x _ { t - d } - \Delta ) / s )$ . The prior two equations also determine properties of a STAR model. For instance, a prerequisite for the stationarity of a STAR model is that all zeros of both AR polynomials are outside the unit circle. An advantage of the STAR model over the TAR model is that the conditional mean function is differentiable. However, experience shows that the transition parameters $\Delta$ and $s$ of a STAR model are hard to estimate. In particular, most empirical studies show that standard errors of the estimates of $\Delta$ and $s$ are often quite large, resulting in $t$ -ratios about 1.0; see Terasvirta (1994). This uncertainty leads to various complica ¨ tions in interpreting an estimated STAR model.

Example 4.4. To illustrate the application of STAR models in financial time series analysis, we consider the monthly simple stock returns for Minnesota Mining and Manufacturing (3M) Company from February 1946 to December 1997. If ARCH models are entertained, we obtain the following ARCH(2) model:

$$
R _ {t} = 0. 0 1 4 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = 0. 0 0 3 + 0. 1 0 8 a _ {t - 1} ^ {2} + 0. 1 5 1 a _ {t - 2} ^ {2}, \tag {4.16}
$$

where standard errors of the estimates are 0.002, 0.0003, 0.045, and 0.058, respectively. As discussed before, such an ARCH model fails to show the asymmetric responses of stock volatility to positive and negative prior shocks. The STAR model provides a simple alternative that may overcome this difficulty. Applying STAR models to the monthly returns of 3M stock, we obtain the model

$$
\begin{array}{l} R _ {t} = 0. 0 1 7 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = \left(0. 0 0 2 + 0. 2 5 6 a _ {t - 1} ^ {2} + 0. 1 4 1 a _ {t - 2} ^ {2}\right) + \frac {0 . 0 0 2 - 0 . 3 1 4 a _ {t - 1} ^ {2}}{1 + \exp (- 1 0 0 0 a _ {t - 1})}, \tag {4.17} \\ \end{array}
$$

where the standard error of the constant term in the mean equation is 0.002 and the standard errors of the estimates in the volatility equation are 0.0003, 0.092, 0.056, 0.001, and 0.102, respectively. The scale parameter 1000 of the logistic transition function is fixed a priori to simplify the estimation. This STAR model provides some support for asymmetric responses to positive and negative prior shocks. For a large negative $a _ { t - 1 }$ , the volatility model approaches the ARCH(2) model

$$
\sigma_ {t} ^ {2} = 0. 0 0 2 + 0. 2 5 6 a _ {t - 1} ^ {2} + 0. 1 4 1 a _ {t - 2} ^ {2}.
$$

Yet for a large positive $a _ { t - 1 }$ , the volatility process behaves like the ARCH(2) model

$$
\sigma_ {t} ^ {2} = 0. 0 0 5 - 0. 0 5 8 a _ {t - 1} ^ {2} + 0. 1 4 1 a _ {t - 2} ^ {2}.
$$

The negative coefficient of $a _ { t - 1 } ^ { 2 }$ in the prior model is counterintuitive, but the magnitude is small. As a matter of fact, for a large positive shock $a _ { t - 1 }$ , the ARCH effects appear to be weak even though the parameter estimates remain statistically significant. The RATS program used is given in Appendix A.

# 4.1.4 Markov Switching Model

The idea of using probability switching in nonlinear time series analysis is discussed in Tong (1983). Using a similar idea, but emphasizing aperiodic transition between various states of an economy, Hamilton (1989) considers the Markov switching autoregressive (MSA) model. Here the transition is driven by a hidden two-state Markov chain. A time series $x _ { t }$ follows an MSA model if it satisfies

$$
x _ {t} = \left\{ \begin{array}{l l} c _ {1} + \sum_ {i = 1} ^ {p} \phi_ {1, i} x _ {t - i} + a _ {1 t} & \text {i f} s _ {t} = 1, \\ c _ {2} + \sum_ {i = 1} ^ {p} \phi_ {2, i} x _ {t - i} + a _ {2 t} & \text {i f} s _ {t} = 2, \end{array} \right. \tag {4.18}
$$

where $s _ { t }$ assumes values in 1,2 and is a first-order Markov chain with transition probabilities

$$
P \left(s _ {t} = 2 \mid s _ {t - 1} = 1\right) = w _ {1}, \quad P \left(s _ {t} = 1 \mid s _ {t - 1} = 2\right) = w _ {2}.
$$

The innovational series $\left\{ a _ { 1 t } \right\}$ and $\left\{ { { a } _ { 2 t } } \right\}$ are sequences of iid random variables with mean zero and finite variance and are independent of each other. A small $w _ { i }$ means that the model tends to stay longer in state i. In fact, $1 / w _ { i }$ is the expected duration of the process to stay in state i. From the definition, an MSA model uses a hidden Markov chain to govern the transition from one conditional mean function to another. This is different from that of a SETAR model for which the transition is determined by a particular lagged variable. Consequently, a SETAR model uses a deterministic scheme to govern the model transition whereas an MSA model uses a stochastic scheme. In practice, the stochastic nature of the states implies that one is never certain about which state $x _ { t }$ belongs to in an MSA model. When the sample size is large, one can use some filtering techniques to draw inference on the state of $x _ { t }$ . Yet as long as $x _ { t - d }$ is observed, the regime of $x _ { t }$ is known in a SETAR model. This difference has important practical implications in forecasting. For instance, forecasts of an MSA model are always a linear combination of forecasts produced by submodels of individual states. But those of a SETAR model only come from a single regime provided that $x _ { t - d }$ is observed. Forecasts of a SETAR model also become a linear combination of those produced by models of individual regimes when the forecast horizon exceeds the delay $d$ . It is much harder to estimate an MSA model than other models because the states are not directly observable. Hamilton (1990) uses the EM algorithm, which is a statistical method iterating between taking expectation and maximization. McCulloch and Tsay (1994) consider a Markov chain Monte Carlo (MCMC) method to estimate a general MSA model. We discuss MCMC methods in Chapter 12.

McCulloch and Tsay (1993) generalize the MSA model in Eq. (4.18) by letting the transition probabilities $w _ { 1 }$ and $w _ { 2 }$ be logistic, or probit, functions of some explanatory variables available at time $t - 1$ . Chen, McCulloch, and Tsay (1997) use the idea of Markov switching as a tool to perform model comparison and selection between non-nested nonlinear time series models (e.g., comparing bilinear and SETAR models). Each competing model is represented by a state. This approach to select a model is a generalization of the odds ratio commonly used in Bayesian analysis. Finally, the MSA model can easily be generalized to the case of more than two states. The computational intensity involved increases rapidly, however. For more discussions of Markov switching models in econometrics, see Hamilton (1994, Chapter 22).

Example 4.5. Consider the growth rate, in percentages, of the U.S. quarterly real gross national product (GNP) from the second quarter of 1947 to the first quarter of 1991. The data are seasonally adjusted and shown in Figure 4.4, where a horizontal line of zero growth is also given. It is reassuring to see that a majority of the growth rates are positive. This series has been widely used in nonlinear

![](images/0edc94986bec6e8eb1dc8546ef5feab74d0539e29ce556a887345701779f83bf.jpg)  
Figure 4.4. Time plot of the growth rate of the U.S. quarterly real GNP from 1947.II to 1991.I. The data are seasonally adjusted and in percentages.

analysis of economic time series. Tiao and Tsay (1994) and Potter (1995) use TAR models, whereas Hamilton (1989) and McCulloch and Tsay (1994) employ Markov switching models.

Employing the MSA model in Eq. (4.18) with $p = 4$ and using a Markov chain Monte Carlo method, which is discussed in Chapter 12, McCulloch and Tsay (1994) obtain the estimates shown in Table 4.1. The results have several interesting findings. First, the mean growth rate of the marginal model for state 1 is $0 . 9 0 9 / ( 1 -$ $0 . 2 6 5 - 0 . 0 2 9 + 0 . 1 2 6 + 0 . 1 1 ) = 0 . 9 6 5$ and that of state 2 is $- 0 . 4 2 / ( 1 - 0 . 2 1 6 -$ $0 . 6 2 8 + 0 . 0 7 3 + 0 . 0 9 7 ) = - 1 . 2 8 8 .$ Thus, state 1 corresponds to quarters with positive growth, or expansion periods, whereas state 2 consists of quarters with negative growth, or a contraction period. Second, the relatively large posterior standard deviations of the parameters in state 2 reflect that there are few observations in that state. This is expected as Figure 4.4 shows few quarters with negative growth. Third, the transition probabilities appear to be different for different states. The estimates indicate that it is more likely for the U.S. GNP to get out of a contraction period than to jump into one—0.286 versus 0.118. Fourth, treating $1 / w _ { i }$ as the expected duration for the process to stay in state i, we see that the expected durations for a contraction period and an expansion period are approximately 3.69 and 11.31 quarters. Thus, on average, a contraction in the U.S. economy lasts about a year, whereas an expansion can last for 3 years. Finally, the estimated AR coefficients of $x _ { t - 2 }$ differ substantially between the two states, indicating that the dynamics of the U.S. economy are different between expansion and contraction periods.

Table 4.1. Estimation Results of a Markov Switching Model with $p = 4$ for the Growth Rate of U.S. Quarterly Real GNP, Seasonally Adjusteda   

<table><tr><td>Parameter</td><td>ci</td><td>φ1</td><td>φ2</td><td>φ3</td><td>φ4</td><td>σi</td><td>wi</td></tr><tr><td></td><td></td><td></td><td>State 1</td><td></td><td></td><td></td><td></td></tr><tr><td>Estimate</td><td>0.909</td><td>0.265</td><td>0.029</td><td>-0.126</td><td>-0.110</td><td>0.816</td><td>0.118</td></tr><tr><td>Standard error</td><td>0.202</td><td>0.113</td><td>0.126</td><td>0.103</td><td>0.109</td><td>0.125</td><td>0.053</td></tr><tr><td></td><td></td><td></td><td>State 2</td><td></td><td></td><td></td><td></td></tr><tr><td>Estimate</td><td>-0.420</td><td>0.216</td><td>0.628</td><td>-0.073</td><td>-0.097</td><td>1.017</td><td>0.286</td></tr><tr><td>Standard error</td><td>0.324</td><td>0.347</td><td>0.377</td><td>0.364</td><td>0.404</td><td>0.293</td><td>0.064</td></tr></table>

aThe estimates and their standard errors are posterior means and standard errors of a Gibbs sampling with 5000 iterations.

# 4.1.5 Nonparametric Methods

In some financial applications, we may not have sufficient knowledge to prespecify the nonlinear structure between two variables $Y$ and $X$ . In other applications, we may wish to take advantage of the advances in computing facilities and computational methods to explore the functional relationship between $Y$ and $X$ . These considerations lead to the use of nonparametric methods and techniques. Nonparametric methods, however, are not without cost. They are highly data dependent and can easily result in overfitting. Our goal here is to introduce some nonparametric methods for financial applications and some nonlinear models that make use of nonparametric methods and techniques. The nonparametric methods discussed include kernel regression, local least squares estimation, and neural network.

The essence of nonparametric methods is smoothing. Consider two financial variables $Y$ and $X$ , which are related by

$$
Y _ {t} = m \left(X _ {t}\right) + a _ {t}, \tag {4.19}
$$

where $m ( . )$ is an arbitrary, smooth, but unknown function and $\{ a _ { t } \}$ is a white noise sequence. We wish to estimate the nonlinear function $m ( . )$ from the data. For simplicity, consider the problem of estimating $m ( . )$ at a particular date for which $X = x$ . That is, we are interested in estimating $m ( x )$ . Suppose that at $X = x$ we have repeated independent observations $y _ { 1 } , \ldots , y _ { T }$ . Then the data become

$$
y _ {t} = m (x) + a _ {t}, \quad t = 1, \dots , T.
$$

Taking the average of the data, we have

$$
\frac {\sum_ {t = 1} ^ {T} y _ {t}}{T} = m (x) + \frac {\sum_ {t = 1} ^ {T} a _ {t}}{T}.
$$

By the law of large numbers, the average of the shocks converges to zero as $T$ increases. Therefore, the average $\textstyle { \overline { { y } } } = { \bigl ( } \sum _ { t = 1 } ^ { T } y _ { t } { \bigr ) } / T$ is a consistent estimate of

$m ( x )$ . That the average $\overline { { y } }$ provides a consistent estimate of $m ( x )$ or, alternatively, that the average of shocks converges to zero shows the power of smoothing.

In financial time series, we do not have repeated observations available at $X =$ $x$ . What we observed are $\{ ( y _ { t } , x _ { t } ) \}$ for $t = 1 , \dots , T$ . But if the function $m ( . )$ is sufficiently smooth, then the value of $Y _ { t }$ for which $X _ { t } \approx x$ continues to provide accurate approximation of $m ( x )$ . The value of $Y _ { t }$ for which $X _ { t }$ is far away from $x$ provides less accurate approximation for $m ( x )$ . As a compromise, one can use a weighted average of $y _ { t }$ instead of the simple average to estimate $m ( x )$ . The weight should be larger for those $Y _ { t }$ with $X _ { t }$ close to $x$ and smaller for those $Y _ { t }$ with $X _ { t }$ far away from $x$ . Mathematically, the estimate of $m ( x )$ for a given $x$ can be written as

$$
\hat {m} (x) = \frac {1}{T} \sum_ {t = 1} ^ {T} w _ {t} (x) y _ {t}, \tag {4.20}
$$

where the weights $w _ { t } ( x )$ are larger for those $y _ { t }$ with $x _ { t }$ close to $x$ and smaller for those $y _ { t }$ with $x _ { t }$ far away from $x$ . In Eq. (4.20), we assume that the weights sum to $T$ . One can treat $1 / T$ as part of the weights and make the weights sum to one.

From Eq. (4.20), the estimate ${ \hat { m } } ( x )$ is simply a local weighted average with weights determined by two factors. The first factor is the distance measure (i.e., the distance between $x _ { t }$ and $x$ ). The second factor is the assignment of weight for a given distance. Different ways to determine the distance between $x _ { t }$ and $x$ and to assign the weight using the distance give rise to different nonparametric methods. In what follows, we discuss the commonly used kernel regression and local linear regression methods.

# Kernel Regression

Kernel regression is perhaps the most commonly used nonparametric method in smoothing. The weights here are determined by a kernel, which is typically a probability density function, is denoted by $K ( x )$ , and satisfies

$$
K (x) \geq 0, \quad \int K (z) d z = 1.
$$

However, to increase the flexibility in distance measure, one often rescales the kernel using a variable $h > 0$ , which is referred to as the bandwidth. The rescaled kernel becomes

$$
K _ {h} (x) = \frac {1}{h} K (x / h), \quad \int K _ {h} (z) d z = 1. \tag {4.21}
$$

The weight function can now be defined as

$$
w _ {t} (x) = \frac {K _ {h} \left(x - x _ {t}\right)}{\sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right)}, \tag {4.22}
$$

where the denominator is a normalization constant that makes the smoother adaptive to the local intensity of the $X$ variable and ensures the weights sum to one.

Plugging Eq. (4.22) into the smoothing formula (4.20), we have the well-known Nadaraya–Watson kernel estimator

$$
\hat {m} (x) = \sum_ {t = 1} ^ {T} w _ {t} (x) y _ {t} = \frac {\sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right) y _ {t}}{\sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right)}; \tag {4.23}
$$

see Nadaraya (1964) and Watson (1964). In practice, many choices are available for the kernel $K ( x )$ . However, theoretical and practical considerations lead to a few choices, including the Gaussian kernel

$$
K _ {h} (x) = \frac {1}{h \sqrt {2 \pi}} \exp (- \frac {x ^ {2}}{2 h ^ {2}})
$$

and the Epanechnikov kernel (Epanechnikov, 1969)

$$
K _ {h} (x) = \frac {0 . 7 5}{h} \left(1 - \frac {x ^ {2}}{h ^ {2}}\right) I \left(\left| \frac {x}{h} \right| \leq 1\right),
$$

where $I ( A )$ is an indicator such that $I ( A ) = 1$ if $A$ holds and $I ( A ) = 0$ otherwise. Figure 4.5 shows the Gaussian and Epanechnikov kernels for $h = 1$ .

To understand the role played by the bandwidth $h$ , we evaluate the Nadaraya–Watson estimator with the Epanechnikov kernel at the observed values

![](images/12f6c9ff97ea816252374992e124a1b08ec24580527483a08119c14741c9b15e.jpg)  
Figure 4.5. Standard normal kernel (solid line) and Epanechnikov kernel (dashed line) with bandwidth $h = 1$ .

$\{ x _ { t } \}$ and consider two extremes. First, if $h  0$ , then

$$
\hat {m} \left(x _ {t}\right)\rightarrow \frac {K _ {h} (0) y _ {t}}{K _ {h} (0)} = y _ {t},
$$

indicating that small bandwidths reproduce the data. Second, if $h  \infty$ , then

$$
\hat {m} (x _ {t}) \rightarrow \frac {\sum_ {t = 1} ^ {T} K _ {h} (0) y _ {t}}{\sum_ {t = 1} ^ {T} K _ {h} (0)} = \frac {1}{T} \sum_ {t = 1} ^ {T} y _ {t} = \overline {{y}},
$$

suggesting that large bandwidths lead to an oversmoothed curve—the sample mean. In general, the bandwidth function $h$ acts as follows. If $h$ is very small, then the weights focus on a few observations that are in the neighborhood around each $x _ { t }$ . If $h$ is very large, then the weights will spread over a larger neighborhood of $x _ { t }$ . Consequently, the choice of $h$ plays an important role in kernel regression. This is the well-known problem of bandwidth selection in kernel regression.

# Bandwidth Selection

There are several approaches for bandwidth selection; see Hardle (1990) and Fan ¨ and Yao (2003). The first approach is the plug-in method, which is based on the asymptotic expansion of the mean integrated squared error (MISE) for kernel smoothers

$$
\mathrm {M I S E} = E \int_ {- \infty} ^ {\infty} [ \hat {m} (x) - m (x) ] ^ {2} d x,
$$

where $m ( . )$ is the true function. The quantity $E [ \hat { m } ( x ) - m ( x ) ] ^ { 2 }$ of the MISE is a pointwise measure of the mean squared error (MSE) of ${ \hat { m } } ( x )$ evaluated at $x$ . Under some regularity conditions, one can derive the optimal bandwidth that minimizes the MISE. The optimal bandwidth typically depends on several unknown quantities that must be estimated from the data with some preliminary smoothing. Several iterations are often needed to obtain a reasonable estimate of the optimal bandwidth. In practice, the choice of preliminary smoothing can become a problem. Fan and Yao (2003) give a normal reference bandwidth selector as

$$
\hat {h} _ {\mathrm {o p t}} = \left\{ \begin{array}{l l} 1. 0 6 s T ^ {- 1 / 5} \text {f o r t h e G a u s s i a n k e r n e l ,} \\ 2. 3 4 s T ^ {- 1 / 5} \text {f o r t h e E p a n e c h n i k o v k e r n e l ,} \end{array} \right.
$$

where $s$ is the sample standard error of the independent variable, which is assumed to be stationary.

The second approach to bandwidth selection is the leave-one-out cross-validation. First, one observation $( x _ { j } , y _ { j } )$ is left out. The remaining $T - 1$ data points are used to obtain the following smoother at $x _ { j }$ :

$$
\hat {m} _ {h, j} (x _ {j}) = \frac {1}{T - 1} \sum_ {t \neq j} w _ {t} (x _ {j}) y _ {t},
$$

which is an estimate of $y _ { j }$ , where the weights $w _ { t } ( x _ { j } )$ sum to $T - 1$ . Second, perform step 1 for $j = 1 , \dots , T$ and define the function

$$
C V (h) = \frac {1}{T} \sum_ {j = 1} ^ {T} \left[ y _ {j} - \hat {m} _ {h, j} \left(x _ {j}\right) \right] ^ {2} W \left(x _ {j}\right),
$$

where $W ( . )$ is a non-negative weight function satisfying $\textstyle \sum _ { j = 1 } ^ { n } W ( x _ { j } ) = T$ , that can be used to down-weight the boundary points if necessary. Decreasing the weights assigned to data points close to the boundary is needed because those points often have fewer neighboring observations. The function $C V ( h )$ is called the cross-validation function because it validates the ability of the smoother to predict $\{ y _ { t } \} _ { t = 1 } ^ { T }$ . One chooses the bandwidth $h$ that minimizes the $C V ( . )$ function.

# Local Linear Regression Method

Assume that the second derivative of $m ( . )$ in model (4.19) exists and is continuous at $x$ , where $x$ is a given point in the support of $m ( . )$ . Denote the data available by $\{ ( y _ { t } , x _ { t } ) \} _ { t = 1 } ^ { T }$ . The local linear regression method to nonparametric regression is to find $a$ and $b$ that minimize

$$
L (a, b) = \sum_ {t = 1} ^ {T} \left[ y _ {t} - a - b \left(x - x _ {t}\right) \right] ^ {2} K _ {h} \left(x - x _ {t}\right), \tag {4.24}
$$

where $K _ { h } ( . )$ is a kernel function defined in Eq. (4.21) and $h$ is a bandwidth. Denote the resulting value of $a$ by $\hat { a }$ . The estimate of $m ( x )$ is then defined as $\hat { a }$ . In practice, $x$ assumes an observed value of the independent variable. The estimate $\hat { b }$ can be used as an estimate of the first derivative of $m ( . )$ evaluated at $x$ .

Under the least squares theory, Eq. (4.24) is a weighted least squares problem and one can derive a closed-form solution for $a$ . Specifically, taking the partial derivatives of $L ( a , b )$ with respect to both $a$ and $b$ and equating the derivatives to zero, we have a system of two equations with two unknowns:

$$
\sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right) y _ {t} = a \sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right) + b \sum_ {t = 1} ^ {T} \left(x - x _ {t}\right) K _ {h} \left(x - x _ {t}\right),
$$

$$
\sum_ {t = 1} ^ {T} y _ {t} (x - x _ {t}) K _ {h} (x - x _ {t}) = a \sum_ {t = 1} ^ {T} (x - x _ {t}) K _ {h} (x - x _ {t}) + b \sum_ {t = 1} ^ {T} (x - x _ {t}) ^ {2} K _ {h} (x - x _ {t}).
$$

Define

$$
s _ {T, \ell} = \sum_ {t = 1} ^ {T} K _ {h} (x - x _ {t}) (x - x _ {t}) ^ {\ell}, \quad \ell = 0, 1, 2.
$$

The prior system of equations becomes

$$
\left[ \begin{array}{c c} s _ {T, 0} & s _ {T, 1} \\ s _ {T, 1} & s _ {T, 2} \end{array} \right] \left[ \begin{array}{c} a \\ b \end{array} \right] = \left[ \begin{array}{c} \sum_ {t = 1} ^ {T} K _ {h} (x - x _ {t}) y _ {t} \\ \sum_ {t = 1} ^ {T} (x - x _ {t}) K _ {h} (x - x _ {t}) y _ {t} \end{array} \right].
$$

Consequently, we have

$$
\hat {a} = \frac {s _ {T , 2} \sum_ {t = 1} ^ {T} K _ {h} (x - x _ {t}) y _ {t} - s _ {T , 1} \sum_ {t = 1} ^ {T} (x - x _ {t}) K _ {h} (x - x _ {t}) y _ {t}}{s _ {T , 0} s _ {T , 2} - s _ {T , 1} ^ {2}}.
$$

The numerator and denominator of the prior fraction can be further simplified as

$$
s _ {T, 2} \sum_ {t = 1} ^ {T} K _ {h} (x - x _ {t}) y _ {t} - s _ {T, 1} \sum_ {t = 1} ^ {T} (x - x _ {t}) K _ {h} (x - x _ {t}) y _ {t}
$$

$$
= \sum_ {t = 1} ^ {T} \left[ K _ {h} \left(x - x _ {t}\right) \left(s _ {T, 2} - \left(x - x _ {t}\right) s _ {T, 1}\right) \right] y _ {t}.
$$

$$
\begin{array}{l} s _ {T, 0} s _ {T, 2} - s _ {T, 1} ^ {2} = \sum_ {t = 1} ^ {T} K _ {h} (x - x _ {t}) s _ {T, 2} - \sum_ {t = 1} ^ {T} (x - x _ {t}) K _ {h} (x - x _ {t}) s _ {T, 1} \\ = \sum_ {t = 1} ^ {T} K _ {h} \left(x - x _ {t}\right) \left[ s _ {T, 2} - \left(x - x _ {t}\right) s _ {T, 1} \right]. \\ \end{array}
$$

In summary, we have

$$
\hat {a} = \frac {\sum_ {t = 1} ^ {T} w _ {t} y _ {t}}{\sum_ {t = 1} ^ {T} w _ {t}}, \tag {4.25}
$$

where $w _ { t }$ is defined as

$$
w _ {t} = K _ {h} (x - x _ {t}) \left[ s _ {T, 2} - (x - x _ {t}) s _ {T, 1} \right].
$$

In practice, to avoid possible zero in the denominator, we use ${ \hat { m } } ( x )$ next to estimate $m ( x )$ :

$$
\hat {m} (x) = \frac {\sum_ {t = 1} ^ {T} w _ {t} y _ {t}}{\sum_ {t = 1} ^ {T} w _ {t} + 1 / T ^ {2}}. \tag {4.26}
$$

Notice that a nice feature of Eq. (4.26) is that the weight $w _ { t }$ satisfies

$$
\sum_ {t = 1} ^ {T} (x - x _ {t}) w _ {t} = 0.
$$

Also, if one assumes that $m ( . )$ of Eq. (4.19) has the first derivative and finds the minimizer of

$$
\sum_ {t = 1} ^ {T} \left(y _ {t} - a\right) ^ {2} K _ {h} \left(x - x _ {t}\right),
$$

then the resulting estimator is the Nadaraya–Watson estimator mentioned earlier. In general, if one assumes that $m ( x )$ has a bounded kth derivative, then one can

replace the linear polynomial in Eq. (4.24) by a $( k - 1 )$ -order polynomial. We refer to the estimator in Eq. (4.26) as the local linear regression smoother. Fan (1993) shows that, under some regularity conditions, the local linear regression estimator has some important sampling properties. The selection of bandwidth can be carried out via the same methods as before.

# Time Series Application

In time series analysis, the explanatory variables are often the lagged values of the series. Consider the simple case of a single explanatory variable. Here model (4.19) becomes

$$
x _ {t} = m (x _ {t - 1}) + a _ {t},
$$

and the kernel regression and local linear regression method discussed before are directly applicable. When multiple explanatory variables exist, some modifications are needed to implement the nonparametric methods. For the kernel regression, one can use a multivariate kernel such as a multivariate normal density function with a prespecified covariance matrix:

$$
K _ {h} (\boldsymbol {x}) = \frac {1}{(h \sqrt {2 \pi}) ^ {p} | \boldsymbol {\Sigma} | ^ {1 / 2}} \exp \left(- \frac {1}{2 h ^ {2}} \boldsymbol {x} ^ {\prime} \boldsymbol {\Sigma} ^ {- 1} \boldsymbol {x}\right),
$$

where $p$ is the number of explanatory variables and $\pmb { \Sigma }$ is a prespecified positivedefinite matrix. Alternatively, one can use the product of univariate kernel functions as a multivariate kernel—for example,

$$
K _ {h} (\boldsymbol {x}) = \prod_ {i = 1} ^ {p} \frac {0 . 7 5}{h _ {i}} \left(1 - \frac {x _ {i} ^ {2}}{h _ {i} ^ {2}}\right) I \left(\left| \frac {x _ {i}}{h _ {i}} \right| <   1\right).
$$

This latter approach is simple, but it overlooks the relationship between the explanatory variables.

Example 4.6. To illustrate the application of nonparametric methods in finance, consider the weekly 3-month Treasury bill secondary market rate from 1970 to 1997 for 1460 observations. The data are obtained from the Federal Reserve Bank of St. Louis and are shown in Figure 4.6. This series has been used in the literature as an example of estimating stochastic diffusion equations using discretely observed data. See references in Chapter 6. Here we consider a simple model

$$
y _ {t} = \mu \left(x _ {t - 1}\right) d t + \sigma \left(x _ {t - 1}\right) d w _ {t},
$$

where $x _ { t }$ is the 3-month Treasury bill rate, $y _ { t } = x _ { t } - x _ { t - 1 }$ , $w _ { t }$ is a standard Brownian motion, and $\mu ( . )$ and $\sigma ( . )$ are smooth functions of $x _ { t - 1 }$ , and apply the local smoothing function lowess of S-Plus to obtain nonparametric estimates of $\mu ( . )$ and $\sigma ( . )$ ; see Cleveland (1979). For simplicity, we use $| y _ { t } |$ as a proxy of the volatility of $x _ { t }$ .

For the simple model considered, $\mu ( x _ { t - 1 } )$ is the conditional mean of $y _ { t }$ given $x _ { t - 1 }$ ; that is, $\mu ( x _ { t - 1 } ) = E ( y _ { t } | x _ { t - 1 } )$ . Figure 4.7a shows the scatterplot of $y ( t )$ versus

![](images/355bbe35f77933a17279443d591d5ee5b6c9d3e17fd8314b02f8fd8b5c79f5d1.jpg)  
Figure 4.6. Time plot of U.S. weekly 3-month Treasury bill rate in the secondary market from 1970 to 1997.

$x _ { t - 1 }$ . The plot also contains the local smooth estimate of $\mu ( x _ { t - 1 } )$ obtained by lowess of S-Plus. The estimate is essentially zero. However, to better understand the estimate, Figure 4.7b shows the estimate $\hat { \mu } ( x _ { t - 1 } )$ on a finer scale. It is interesting to see that $\hat { \mu } ( x _ { t - 1 } )$ is positive when $x _ { t - 1 }$ is small, but becomes negative when $x _ { t - 1 }$ is large. This is in agreement with the common sense that when the interest rate is high, it is expected to come down, and when the rate is low, it is expected to increase. Figure 4.7c shows the scatterplot of $| y ( t ) |$ versus $x _ { t - 1 }$ and the estimate of $\hat { \sigma } ( x _ { t - 1 } )$ via lowess. The plot confirms that the higher the interest rate, the larger the volatility. Figure 4.7d shows the estimate $\hat { \sigma } ( x _ { t - 1 } )$ on a finer scale. Clearly, the volatility is an increasing function of $x _ { t - 1 }$ and the slope seems to accelerate when $x _ { t - 1 }$ is approaching $10 \%$ . This example demonstrates that simple nonparametric methods can be helpful in understanding the dynamic structure of a financial time series.

# S-Plus Commands

Used in Example 4.6

> $z \beth =$ matrix(scan(file=’w-3mtbs7097.txt’),4)   
> x=z1[4,1:1460]/100   
> $\mathrm { y } =$ (z1[4,2:1461]-z1[4,1:1460])/100   
$>$ par(mfcol=c(2,2))  
$>$ plot(x,y,pch=’*’,xlab=’x(t-1)’,ylab=’y(t)’)

![](images/50504f217bdfafe083ab9909217ad007a2f225335928b2ff6997a3f3a0c9b216.jpg)  
(a)

![](images/3291e326c6c3493dc522c176b67315c0dbebe72a2c0b51ebfc21c8027fcde90f.jpg)  
(c)

![](images/ac83adc734302e2bfcb488bd7f29cccfed321d4ec39a8c73410425e2c8d87b40.jpg)  
(b)

![](images/fc46509f63fbb54fac6044709521d4380a6bd66b0c1ae0d0a9e09a04c6ac78ba.jpg)  
(d)   
Figure 4.7. Estimation of conditional mean and volatility of weekly 3-month Treasury bill rate via a local smoothing method: (a) $y _ { t }$ versus $x _ { t - 1 }$ , where $y _ { t } = x _ { t } - x _ { t - 1 }$ and $x _ { t }$ is the interest rate; (b) estimate of $\mu ( x _ { t - 1 } )$ ; (c) $\lvert y _ { t } \rvert$ versus $x _ { t - 1 }$ ; and (d) estimate of $\sigma ( x _ { t - 1 } )$ .

> lines(lowess(x,y))
> title(main=' (a) y(t) vs x(t-1)')
> fit=lowess(x,y)
> plot.fit\ $x,fit\$ y,xlab $=$ 'x(t-1)',ylab $=$ 'mu',type $=$ 'l',
+ylim=c(-.002,.002))
> title(main=' (b) Estimate of mu(.))'
> plot(x,abs(y),pch $=$ '\*',xlab $=$ 'x(t-1)',ylab $=$ 'abs(y)')
> lines(lowess(x,abs(y)))
> title(main=' (c) abs(y) vs x(t-1)')
> fit2=lowess(x,abs(y))
> plot.fit2\\)x,fit2\ $y,type \(=$ 'l',xlab $=$ 'x(t-1)',ylab $=$ 'sigma',
+ylim=c(0,.01))
> title(main=' (d) Estimate of sigma(.))

The following nonlinear models are derived with the help of nonparametric methods.

# 4.1.6 Functional Coefficient AR Model

Recent advances in nonparametric techniques enable researchers to relax parametric constraints in proposing nonlinear models. In some cases, nonparametric methods are used in a preliminary study to help select a parametric nonlinear model. This

is the approach taken by Chen and Tsay (1993a) in proposing the functionalcoefficient autoregressive (FAR) model that can be written as

$$
x _ {t} = f _ {1} \left(X _ {t - 1}\right) x _ {t - 1} + \dots + f _ {p} \left(X _ {t - 1}\right) x _ {t - p} + a _ {t}, \tag {4.27}
$$

where $X _ { t - 1 } = ( x _ { t - 1 } , \dots , x _ { t - k } ) ^ { \prime }$ is a vector of lagged values of $x _ { t }$ . If necessary, $X _ { t - 1 }$ may also include other explanatory variables available at time $t - 1$ . The functions $f _ { i } ( . )$ of Eq. (4.27) are assumed to be continuous, even twice differentiable, almost surely with respect to their arguments. Most of the nonlinear models discussed before are special cases of the FAR model. In application, one can use nonparametric methods such as kernel regression or local linear regression to estimate the functional coefficients $f _ { i } ( . )$ , especially when the dimension of $X _ { t - 1 }$ is low (e.g., $X _ { t - 1 }$ is a scalar). Recently, Cai, Fan, and Yao (2000) applied the local linear regression method to estimate $f _ { i } ( . )$ and showed that substantial improvements in 1-step ahead forecasts can be achieved by using FAR models.

# 4.1.7 Nonlinear Additive AR Model

A major difficulty in applying nonparametric methods to nonlinear time series analysis is the “curse of dimensionality.” Consider a general nonlinear $\operatorname { A R } ( p )$ process $x _ { t } = f ( x _ { t - 1 } , \ldots , x _ { t - p } ) + a _ { t }$ . A direct application of nonparametric methods to estimate $f ( . )$ would require $p$ -dimensional smoothing, which is hard to do when $p$ is large, especially if the number of data points is not large. A simple, yet effective way to overcome this difficulty is to entertain an additive model that only requires lower dimensional smoothing. A time series $x _ { t }$ follows a nonlinear additive AR (NAAR) model if

$$
x _ {t} = f _ {0} (t) + \sum_ {i = 1} ^ {p} f _ {i} \left(x _ {t - i}\right) + a _ {t}, \tag {4.28}
$$

where the $f _ { i } ( . )$ are continuous functions almost surely. Because each function $f _ { i } ( . )$ has a single argument, it can be estimated nonparametrically using one-dimensional smoothing techniques and hence avoids the curse of dimensionality. In application, an iterative estimation method that estimates $f _ { i } ( . )$ nonparametrically conditioned on estimates of $f _ { j } ( . )$ for all $j \neq i$ is used to estimate a NAAR model; see Chen and Tsay (1993b) for further details and examples of NAAR models.

The additivity assumption is rather restrictive and needs to be examined carefully in application. Chen, Liu, and Tsay (1995) consider test statistics for checking the additivity assumption.

# 4.1.8 Nonlinear State-Space Model

Making use of recent advances in MCMC methods (Gelfand and Smith, 1990), Carlin, Polson, and Stoffer (1992) propose a Monte Carlo approach for nonlinear state-space modeling. The model considered is

$$
S _ {t} = f _ {t} \left(S _ {t - 1}\right) + u _ {t}, \quad x _ {t} = g _ {t} \left(S _ {t}\right) + v _ {t}, \tag {4.29}
$$

where $S _ { t }$ is the state vector, $f _ { t } ( . )$ and $g _ { t } ( . )$ are known functions depending on some unknown parameters, $\left\{ u _ { t } \right\}$ is a sequence of iid multivariate random vectors with zero mean and non-negative definite covariance matrix $\Sigma _ { u }$ , $\{ v _ { t } \}$ is a sequence of iid random variables with mean zero and variance $\sigma _ { v } ^ { 2 }$ , and $\left\{ u _ { t } \right\}$ is independent of $\{ v _ { t } \}$ . Monte Carlo techniques are employed to handle the nonlinear evolution of the state transition equation because the whole conditional distribution function of $S _ { t }$ given $S _ { t - 1 }$ is needed for a nonlinear system. Other numerical smoothing methods for nonlinear time series analysis have been considered by Kitagawa (1998) and the references therein. MCMC methods (or computing-intensive numerical methods) are powerful tools for nonlinear time series analysis. Their potential has not been fully explored. However, the assumption of knowing $f _ { t } ( . )$ and $g _ { t } ( . )$ in model (4.29) may hinder practical use of the proposed method. A possible solution to overcome this limitation is to use nonparametric methods such as the analyses considered in FAR and NAAR models to specify $f _ { t } ( . )$ and $g _ { t } ( . )$ before using nonlinear state-space models.

# 4.1.9 Neural Networks

A popular topic in modern data analysis is neural network, which can be classified as a semiparametric method. The literature on neural network is enormous, and its application spreads over many scientific areas with varying degrees of success; see Section 2 of Ripley (1993) for a list of applications and Section 10 for remarks concerning its application in finance. Cheng and Titterington (1994) provide information on neural networks from a statistical viewpoint. In this subsection, we focus solely on the feed-forward neural networks in which inputs are connected to one or more neurons, or nodes, in the input layer, and these nodes are connected forward to further layers until they reach the output layer. Figure 4.8 shows an example of a simple feed-forward network for univariate time series analysis with one hidden layer. The input layer has two nodes, and the hidden layer has three. The input nodes are connected forward to each and every node in the hidden layer, and these hidden nodes are connected to the single node in the output layer. We call the network a 2-3-1 feed-forward network. More complicated neural networks, including those with feedback connections, have been proposed in the literature, but the feed-forward networks are most relevant to our study.

![](images/f39918a999ad88f2a4345b8832ad2bbfb2525e488095cefb425d14bb9b625338.jpg)  
Figure 4.8. A feed-forward neural network with one hidden layer for univariate time series analysis.

# Feed-Forward Neural Networks

A neural network processes information from one layer to the next by an “activation function.” Consider a feed-forward network with one hidden layer. The $j$ th node in the hidden layer is defined as

$$
h _ {j} = f _ {j} \left(\alpha_ {0 j} + \sum_ {i \rightarrow j} w _ {i j} x _ {i}\right), \tag {4.30}
$$

where $x _ { i }$ is the value of the ith input node, $f _ { j } ( . )$ is an activation function typically taken to be the logistic function

$$
f _ {j} (z) = \frac {\exp (z)}{1 + \exp (z)},
$$

$\alpha _ { 0 j }$ is called the bias, the summation $i  j$ means summing over all input nodes feeding to $j$ , and $w _ { i j }$ are the weights. For illustration, the $j$ th node of the hidden layer of the 2-3-1 feed-forward network in Figure 4.8 is

$$
h _ {j} = \frac {\exp \left(\alpha_ {0 j} + w _ {1 j} x _ {1} + w _ {2 j} x _ {2}\right)}{1 + \exp \left(\alpha_ {0 j} + w _ {1 j} x _ {1} + w _ {2 j} x _ {2}\right)}, \quad j = 1, 2, 3. \tag {4.31}
$$

For the output layer, the node is defined as

$$
o = f _ {o} \left(\alpha_ {0 o} + \sum_ {j \rightarrow o} w _ {j o} h _ {j}\right), \tag {4.32}
$$

where the activation function $f _ { o } ( . )$ is either linear or a Heaviside function. If $f _ { o } ( . )$ is linear, then

$$
o = \alpha_ {0 o} + \sum_ {j = 1} ^ {k} w _ {j o} h _ {j},
$$

where $k$ is the number of nodes in the hidden layer. By a Heaviside function, we mean $f _ { o } ( z ) = 1$ if $z > 0$ and $f _ { o } ( z ) = 0$ otherwise. A neuron with a Heaviside function is called a threshold neuron, with “1” denoting that the neuron fires its message. For example, the output of the 2-3-1 network in Figure 4.8 is

$$
o = \alpha_ {0 o} + w _ {1 o} h _ {1} + w _ {2 o} h _ {2} + w _ {3 o} h _ {3},
$$

if the activation function is linear; it is

$$
o = \left\{ \begin{array}{l} 1 \text {i f} \alpha_ {0 o} + w _ {1 o} h _ {1} + w _ {2 o} h _ {2} + w _ {3 o} h _ {3} > 0, \\ 0 \text {i f} \alpha_ {0 o} + w _ {1 o} h _ {1} + w _ {2 o} h _ {2} + w _ {3 o} h _ {3} \leq 0, \end{array} \right.
$$

if $f _ { o } ( . )$ is a Heaviside function.

Combining the layers, the output of a feed-forward neural network can be written as

$$
o = f _ {o} \left[ \alpha_ {0 o} + \sum_ {j \rightarrow o} w _ {j o} f _ {j} \left(\alpha_ {0 j} + \sum_ {i \rightarrow j} w _ {i j} x _ {i}\right)\right]. \tag {4.33}
$$

If one also allows for direct connections from the input layer to the output layer, then the network becomes

$$
o = f _ {o} \left[ \alpha_ {0 o} + \sum_ {i \rightarrow o} \alpha_ {i o} x _ {i} + \sum_ {j \rightarrow o} w _ {j o} f _ {j} \left(\alpha_ {0 j} + \sum_ {i \rightarrow j} w _ {i j} x _ {i}\right)\right], \tag {4.34}
$$

where the first summation is summing over the input nodes. When the activation function of the output layer is linear, the direct connections from the input nodes to the output node represent a linear function between the inputs and output. Consequently, in this particular case model (4.34) is a generalization of linear models. For the 2-3-1 network in Figure 4.8, if the output activation function is linear, then Eq. (4.33) becomes

$$
o = \alpha_ {0 o} + \sum_ {j = 1} ^ {3} w _ {j o} h _ {j},
$$

where $h _ { j }$ is given in Eq. (4.31). The network thus has 13 parameters. If Eq. (4.34) is used, then the network becomes

$$
o = \alpha_ {0 o} + \sum_ {i = 1} ^ {2} \alpha_ {i o} x _ {i} + \sum_ {j = 1} ^ {3} w _ {j o} h _ {j},
$$

where again $h _ { j }$ is given in Eq. (4.31). The number of parameters of the network increases to 15.

We refer to the function in Eq. (4.33) or (4.34) as a semiparametric function because its functional form is known, but the number of nodes and their biases and weights are unknown. The direct connections from the input layer to the output layer in Eq. (4.34) mean that the network can skip the hidden layer. We refer to such a network as a skip-layer feed-forward network.

Feed-forward networks are known as multilayer percetrons in the neural network literature. They can approximate any continuous function uniformly on compact sets by increasing the number of nodes in the hidden layer; see Hornik, Stinchcombe, and White (1989), Hornik (1993), and Chen and Chen (1995). This property of neural networks is the universal approximation property of the multilayer percetrons. In short, feed-forward neural networks with a hidden layer can be seen as a way to parameterize a general continuous nonlinear function.

# Training and Forecasting

Application of neural networks involves two steps. The first step is to train the network (i.e., to build a network, including determining the number of nodes and

estimating their biases and weights). The second step is inference, especially forecasting. The data are often divided into two nonoverlapping subsamples in the training stage. The first subsample is used to estimate the parameters of a given feed-forward neural network. The network so built is then used in the second subsample to perform forecasting and compute its forecasting accuracy. By comparing the forecasting performance, one selects the network that outperforms the others as the “best” network for making inference. This is the idea of cross-validation widely used in statistical model selection. Other model selection methods are also available.

In a time series application, let $\{ ( r _ { t } , \pmb { x } _ { t } ) | t = 1 , . . . , T \}$ be the available data for network training, where $\boldsymbol { x } _ { t }$ denotes the vector of inputs and $r _ { t }$ is the series of interest (e.g., log returns of an asset). For a given network, let $o _ { t }$ be the output of the network with input $\boldsymbol { x } _ { t }$ ; see Eq. (4.34). Training a neural network amounts to choosing its biases and weights to minimize some fitting criterion—for example, the least squares

$$
S ^ {2} = \sum_ {t = 1} ^ {T} \left(r _ {t} - o _ {t}\right) ^ {2}.
$$

This is a nonlinear estimation problem that can be solved by several iterative methods. To ensure the smoothness of the fitted function, some additional constraints can be added to the prior minimization problem. In the neural network literature, the back propagation (BP) learning algorithm is a popular method for network training. The BP method, introduced by Bryson and Ho (1969), works backward starting with the output layer and uses a gradient rule to modify the biases and weights iteratively. Appendix 2A of Ripley (1993) provides a derivation of back propagation. Once a feed-forward neural network is built, it can be used to compute forecasts in the forecasting subsample.

Example 4.7. To illustrate applications of the neural network in finance, we consider the monthly log returns, in percentages and including dividends, for IBM stock from January 1926 to December 1999. We divide the data into two subsamples. The first subsample consisting of returns from January 1926 to December 1997 for 864 observations is used for modeling. Using model (4.34) with three inputs and two nodes in the hidden layer, we obtain a 3-2-1 network for the series. The three inputs are $r _ { t - 1 } , r _ { t - 2 }$ , and $r _ { t - 3 }$ and the biases and weights are given next:

$$
\hat {r} _ {t} = 3. 2 2 - 1. 8 1 f _ {1} \left(\boldsymbol {r} _ {t - 1}\right) - 2. 2 8 f _ {2} \left(\boldsymbol {r} _ {t - 1}\right) - 0. 0 9 r _ {t - 1} - 0. 0 5 r _ {t - 2} - 0. 1 2 r _ {t - 3}, \tag {4.35}
$$

where $\pmb { r } _ { t - 1 } = ( r _ { t - 1 } , r _ { t - 2 } , r _ { t - 3 } )$ and the two logistic functions are

$$
f _ {1} \left(\boldsymbol {r} _ {t - 1}\right) = \frac {\exp (- 8 . 3 4 - 1 8 . 9 7 r _ {t - 1} + 2 . 1 7 r _ {t - 2} - 1 9 . 1 7 r _ {t - 3})}{1 + \exp (- 8 . 3 4 - 1 8 . 9 7 r _ {t - 1} + 2 . 1 7 r _ {t - 2} - 1 9 . 1 7 r _ {t - 3})},
$$

$$
f _ {2} \left(\boldsymbol {r} _ {t - 1}\right) = \frac {\exp \left(3 9 . 2 5 - 2 2 . 1 7 r _ {t - 1} - 1 7 . 3 4 r _ {t - 2} - 5 . 9 8 r _ {t - 3}\right)}{1 + \exp \left(3 9 . 2 5 - 2 2 . 1 7 r _ {t - 1} - 1 7 . 3 4 r _ {t - 2} - 5 . 9 8 r _ {t - 3}\right)}.
$$

The standard error of the residuals for the prior model is 6.56. For comparison, we also built an AR model for the data and obtained

$$
r _ {t} = 1. 1 0 1 + 0. 0 7 7 r _ {t - 1} + a _ {t}, \quad \sigma_ {a} = 6. 6 1. \tag {4.36}
$$

The residual standard error is slightly greater than that of the feed-forward model in Eq. (4.35).

# Forecast Comparison

The monthly returns of IBM stock in 1998 and 1999 form the second subsample and are used to evaluate the out-of-sample forecasting performance of neural networks. As a benchmark for comparison, we use the sample mean of $r _ { t }$ in the first subsample as the 1-step ahead forecast for all the monthly returns in the second subsample. This corresponds to assuming that the log monthly price of IBM stock follows a random walk with drift. The mean squared forecast error (MSFE) of this benchmark model is 91.85. For the AR(1) model in Eq. (4.36), the MSFE of 1-step ahead forecasts is 91.70. Thus, the AR(1) model slightly outperforms the benchmark. For the 3-2-1 feed-forward network in Eq. (4.35), the MSFE is 91.74, which is essentially the same as that of the AR(1) model.

Remark. The estimation of feed-forward networks is done by using the S-Plus program with default starting weights; see Venables and Ripley (1999) for more information. Our limited experience shows that the estimation results vary. For the IBM stock returns used in Example 4.7, the out-of-sample MSFE for a 3-2-1 network can be as low as 89.46 and as high as 93.65. If we change the number of nodes in the hidden layer, the range for the MSFE becomes even wider. The S-Plus commands used in Example 4.7 are given in Appendix B. 

Example 4.8. Nice features of the feed-forward network include its flexibility and wide applicability. For illustration, we use the network with a Heaviside activation function for the output layer to forecast the direction of price movement for IBM stock considered in Example 4.7. Define a direction variable as

$$
d _ {t} = \left\{ \begin{array}{l l} 1 & \text {i f} r _ {t} \geq 0, \\ 0 & \text {i f} r _ {t} <   0. \end{array} \right.
$$

We use eight input nodes consisting of the first four lagged values of both $r _ { t }$ and $d _ { t }$ and four nodes in the hidden layer to build an 8-4-1 feed-forward network for $d _ { t }$ in the first subsample. The resulting network is then used to compute the 1-step ahead probability of an “upward movement” (i.e., a positive return) for the following month in the second subsample. Figure 4.9 shows a typical output of probability forecasts and the actual directions in the second subsample with the latter denoted by circles. A horizontal line of 0.5 is added to the plot. If we take a rigid approach by letting $\hat { d } _ { t } = 1$ if the probability forecast is greater than or equal to 0.5 and $\bar { \hat { d } } _ { t } = 0$ otherwise, then the neural network has a successful rate of 0.58. The success rate of the network varies substantially from one estimation to another, and the network uses

![](images/96eae309b035672fcd397febe6f41c9f8b313e8838a8080924328deeafd8b202.jpg)  
Figure 4.9. One-step ahead probability forecasts for a positive monthly return for IBM stock using an 8-4-1 feed-forward neural network. The forecasting period is from January 1998 to December 1999.

![](images/e72844c06601891f14e0e2d482c44def2a98609fe0ed8125cd9e8b1931b8865d.jpg)

![](images/f3ee596d902b3b4c34f83fa612abab50d040ade0420003df7aee284a91b829a6.jpg)  
Figure 4.10. Histograms of the number of forecasting errors for the directional movements of monthly log returns of IBM stock. The forecasting period is from January 1998 to December 1999.

49 parameters. To gain more insight, we did a simulation study of running the 8-4-1 feed-forward network 500 times and computed the number of errors in predicting the upward and downward movement using the same method as before. The mean and median of errors over the 500 runs are 11.28 and 11, respectively, whereas the maximum and minimum number of errors are 18 and 4. For comparison, we also did a simulation with 500 runs using a random walk with drift—that is,

$$
\hat {d} _ {t} = \left\{ \begin{array}{l l} 1 & \text {i f} \hat {r} _ {t} = 1. 1 9 + \epsilon_ {t} \geq 0, \\ 0 & \text {o t h e r w i s e}, \end{array} \right.
$$

where 1.19 is the average monthly log return for IBM stock from January 1926 to December 1997 and $\{ \epsilon _ { t } \}$ is a sequence of iid $N ( 0 , 1 )$ random variables. The mean and median of the number of forecast errors become 10.53 and 11, whereas the maximum and minimum number of errors are 17 and 5, respectively. Figure 4.10 shows the histograms of the number of forecast errors for the two simulations. The results show that the 8-4-1 feed-forward neural network does not outperform the simple model that assumes a random walk with drift for the monthly log price of IBM stock.

# 4.2 NONLINEARITY TESTS

In this section, we discuss some nonlinearity tests available in the literature that have decent power against the nonlinear models considered in Section 4.3. The tests discussed include both parametric and nonparametric statistics. The Ljung–Box statistics of squared residuals, the bispectral test, and the Brock, Dechert, and Scheinkman (BDS) test are nonparametric methods. The RESET test (Ramsey, 1969), the $F$ tests of Tsay (1986, 1989), and other Lagrange multiplier and likelihood ratio tests depend on specific parametric functions. Because nonlinearity may occur in many ways, there exists no single test that dominates the others in detecting nonlinearity.

# 4.2.1 Nonparametric Tests

Under the null hypothesis of linearity, residuals of a properly specified linear model should be independent. Any violation of independence in the residuals indicates inadequacy of the entertained model, including the linearity assumption. This is the basic idea behind various nonlinearity tests. In particular, some of the nonlinearity tests are designed to check for possible violation in quadratic forms of the underlying time series.

# $\varrho$ -Statistic of Squared Residuals

McLeod and Li (1983) apply the Ljung–Box statistics to the squared residuals of an $\mathbf { A R M A } ( p , q )$ model to check for model inadequacy. The test statistic is

$$
Q (m) = T (T + 2) \sum_ {i = 1} ^ {m} \frac {\hat {\rho} _ {l} ^ {2} \left(a _ {l} ^ {2}\right)}{T - i},
$$

where $T$ is the sample size, m is a properly chosen number of autocorrelations used in the test, $a _ { t }$ denotes the residual series, and $\hat { \rho } _ { i } ( a _ { t } ^ { 2 } )$ is the lag-i ACF of $a _ { t } ^ { 2 }$ . If the entertained linear model is adequate, $Q ( m )$ is asymptotically a chi-squared random variable with $m - p - q$ degrees of freedom. As mentioned in Chapter 3, the prior $Q$ -statistic is useful in detecting conditional heteroscedasticity of $a _ { t }$ and is asymptotically equivalent to the Lagrange multiplier test statistic of Engle (1982) for ARCH models; see Section 3.4.3. The null hypothesis of the statistics is $H _ { o } : \beta _ { 1 } = \cdot \cdot \cdot = \beta _ { m } = 0$ , where $\beta _ { i }$ is the coefficient of $a _ { t - i } ^ { 2 }$ in the linear regression

$$
a _ {t} ^ {2} = \beta_ {0} + \beta_ {1} a _ {t - 1} ^ {2} + \dots + \beta_ {m} a _ {t - m} ^ {2} + e _ {t}
$$

for $t = m + 1 , . . . , T$ . Because the statistic is computed from residuals (not directly from the observed returns), the number of degrees of freedom is $m - p - q$ .

# Bispectral Test

This test can be used to test for linearity and Gaussianity. It depends on the result that a properly normalized bispectrum of a linear time series is constant over all frequencies and that the constant is zero under normality. The bispectrum of a time series is the Fourier transform of its third-order moments. For a stationary time series $x _ { t }$ in Eq. (4.1), the third-order moment is defined as

$$
c (u, v) = g \sum_ {k = - \infty} ^ {\infty} \psi_ {k} \psi_ {k + u} \psi_ {k + v}, \tag {4.37}
$$

where $u$ and $v$ are integers, $g = E ( a _ { t } ^ { 3 } )$ , $\psi _ { 0 } = 1$ , and $\psi _ { k } = 0$ for $k < 0$ . Taking Fourier transforms of Eq. (4.37), we have

$$
b _ {3} \left(w _ {1}, w _ {2}\right) = \frac {g}{4 \pi^ {2}} \Gamma \left[ - \left(w _ {1} + w _ {2}\right) \right] \Gamma \left(w _ {1}\right) \Gamma \left(w _ {2}\right), \tag {4.38}
$$

where $\begin{array} { r } { \Gamma ( w ) = \sum _ { u = 0 } ^ { \infty } \psi _ { u } \exp ( - i w u ) } \end{array}$ with $i = \sqrt { - 1 }$ , and $w _ { i }$ are frequencies. Yet =the spectral density function of $x _ { t }$ is given by

$$
p (w) = \frac {\sigma_ {a} ^ {2}}{2 \pi} | \Gamma (w) | ^ {2},
$$

where $w$ denotes the frequency. Consequently, the function

$$
b \left(w _ {1}, w _ {2}\right) = \frac {\left| b _ {3} \left(w _ {1} , w _ {2}\right) \right| ^ {2}}{p \left(w _ {1}\right) p \left(w _ {2}\right) p \left(w _ {1} + w _ {2}\right)} = \text {c o n s t a n t} (w _ {1}, w _ {2}). \tag {4.39}
$$

The bispectrum test makes use of the property in Eq. (4.39). Basically, it estimates the function $b ( w _ { 1 } , w _ { 2 } )$ in Eq. (4.39) over a suitably chosen grid of points and applies a test statistic similar to Hotelling’s $T ^ { 2 }$ statistic to check the constancy of $b ( w _ { 1 } , w _ { 2 } )$ . For a linear Gaussian series, $E ( a _ { t } ^ { 3 } ) = g = 0$ so that the bispectrum is zero for all frequencies $( w _ { 1 } , w _ { 2 } )$ . For further details of the bispectral test, see Priestley (1988), Subba Rao and Gabr (1984), and Hinich (1982). Limited experience shows that the test has decent power when the sample size is large.

# BDS Statistic

Brock, Dechert, and Scheinkman (1987) propose a test statistic, commonly referred to as the BDS test, to detect the iid assumption of a time series. The statistic is, therefore, different from other test statistics discussed because the latter mainly focus on either the second- or third-order properties of $x _ { t }$ . The basic idea of the BDS test is to make use of a “correlation integral” popular in chaotic time series analysis. Given a $k$ -dimensional time series $X _ { t }$ and observations $\{ X _ { t } \} _ { t = 1 } ^ { T _ { k } }$ , define the correlation integral as

$$
C _ {k} (\delta) = \lim  _ {T _ {k} \rightarrow \infty} \frac {2}{T _ {k} \left(T _ {k} - 1\right)} \sum_ {i <   j} I _ {\delta} \left(X _ {i}, X _ {j}\right), \tag {4.40}
$$

where $I _ { \delta } ( u , v )$ is an indicator variable that equals one if $\| u - v \| < \delta$ , and zero otherwise, where $\left. . \right.$ is the supnorm. The correlation integral measures the fraction of data pairs of $\{ X _ { t } \}$ that are within a distance of $\delta$ from each other. Consider next a time series $x _ { t }$ . Construct $k$ -dimensional vectors $X _ { t } ^ { k } = ( x _ { t } , x _ { t + 1 } , . . . , x _ { t + k - 1 } ) ^ { \prime }$ , which are called $k$ -histories. The idea of the BDS test is as follows. Treat a $k$ - history as a point in the $k$ -dimensional space. If $\{ x _ { t } \} _ { t = 1 } ^ { T }$ are indeed iid random variables, then the $k$ -histories $\{ X _ { t } \} _ { t = 1 } ^ { T _ { k } }$ = should show no pattern in the $k$ -dimensional space. Consequently, the correlation integrals should satisfy the relation $C _ { k } ( \delta ) =$ $[ C _ { 1 } ( \delta ) ] ^ { k }$ . Any departure from the prior relation suggests that $x _ { t }$ are not iid. As a simple, but informative example, consider a sequence of iid random variables from the uniform distribution over [0, 1]. Let $[ a , b ]$ be a subinterval of [0, 1] and consider the “2-history” $( x _ { t } , x _ { t + 1 } )$ , which represents a point in the two-dimensional space. Under the iid assumption, the expected number of 2-histories in the subspace $[ a , b ] \times [ a , b ]$ should equal the square of the expected number of $x _ { t }$ in $[ a , b ]$ . This idea can be formally examined by using sample counterparts of correlation integrals. Define

$$
C _ {\ell} (\delta , T) = \frac {2}{T _ {k} (T _ {k} - 1)} \sum_ {i <   j} I _ {\delta} (X _ {i} ^ {*}, X _ {j} ^ {*}), \quad \ell = 1, k,
$$

where $T _ { \ell } = T - \ell + 1$ and $X _ { i } ^ { * } = x _ { i }$ if $\ell = 1$ and $X _ { i } ^ { * } = X _ { i } ^ { k }$ if $\ell = k$ . Under the null hypothesis that $\{ x _ { t } \}$ are iid with a nondegenerated distribution function $F ( . )$ , Brock, Dechert, and Scheinkman (1987) show that

$$
C _ {k} (\delta , T) \rightarrow [ C _ {1} (\delta) ] ^ {k} \quad \text {w i t h p r o b a b i l i t y 1 ,} \quad \text {a s} \quad T \rightarrow \infty
$$

for any fixed $k$ and δ. Furthermore, the statistic $\sqrt { T } \{ C _ { k } ( \delta , T ) - [ C _ { 1 } ( \delta , T ) ] ^ { k } \}$ is asymptotically distributed as normal with mean zero and variance

$$
\sigma_ {k} ^ {2} (\delta) = 4 \left(N ^ {k} + 2 \sum_ {j = 1} ^ {k - 1} N ^ {k - j} C ^ {2 j} + (k - 1) ^ {2} C ^ {2 k} - k ^ {2} N C ^ {2 k - 2}\right),
$$

where $\begin{array} { r } { C = \int [ F ( z + \delta ) - F ( z - \delta ) ] d F ( z ) } \end{array}$ and $\begin{array} { r } { N = \int [ F ( z + \delta ) - F ( z - } \end{array}$ $\delta ) ] ^ { 2 } d F ( z )$ . Note that $C _ { 1 } ( \delta , T )$ is a consistent estimate of $C$ , and $N$ can be consistently estimated by

$$
N (\delta , T) = \frac {6}{T _ {k} (T _ {k} - 1) (T _ {k} - 2)} \sum_ {t <   s <   u} I _ {\delta} (x _ {t}, x _ {s}) I _ {\delta} (x _ {s}, x _ {u}).
$$

The BDS test statistic is then defined as

$$
D _ {k} (\delta , T) = \sqrt {T} \left\{C _ {k} (\delta , T) - \left[ C _ {1} (\delta , T) \right] ^ {k} \right\} / \sigma_ {k} (\delta , T), \tag {4.41}
$$

where $\sigma _ { k } ( \delta , T )$ is obtained from $\sigma _ { k } ( \delta )$ when $C$ and $N$ are replaced by $C _ { 1 } ( \delta , T )$ and $N ( \delta , T )$ , respectively. This test statistic has a standard normal limiting distribution. For further discussion and examples of applying the BDS test, see Hsieh (1989) and Brock, Hsieh, and LeBaron (1991). In application, one should remove linear dependence, if any, from the data before applying the BDS test. The test may be sensitive to the choices of $\delta$ and $k$ , especially when $k$ is large.

# 4.2.2 Parametric Tests

Turning to parametric tests, we consider the RESET test of Ramsey (1969) and its generalizations. We also discuss some test statistics for detecting threshold nonlinearity. To simplify the notation, we use vectors and matrices in the discussion. If necessary, readers may consult Appendix A of Chapter 8 for a brief review on vectors and matrices.

# The RESET Test

Ramsey (1969) proposes a specification test for linear least squares regression analysis. The test is referred to as a RESET test and is readily applicable to linear AR models. Consider the linear $\operatorname { A R } ( p )$ model

$$
x _ {t} = \boldsymbol {X} _ {t - 1} ^ {\prime} \boldsymbol {\phi} + a _ {t}, \tag {4.42}
$$

where $X _ { t - 1 } = ( 1 , x _ { t - 1 } , \ldots , x _ { t - p } ) ^ { \prime }$ and $\pmb { \phi } = ( \phi _ { 0 } , \phi _ { 1 } , \ldots , \phi _ { p } ) ^ { \prime }$ . The first step of the RESET test is to obtain the least squares estimate $\widehat { \phi }$ of Eq. (4.42) and compute $\hat { x } _ { t } = X _ { t - 1 } ^ { \prime } \widehat { \phi }$ the res, where $\hat { a } _ { t } = x _ { t } - \hat { x } _ { t }$ , and the sum of squared residualsize. In the second step, consider the $\begin{array} { r } { S S R _ { 0 } = \sum _ { t = p + 1 } ^ { T } \hat { a } _ { t } ^ { 2 } } \end{array}$ $T$

$$
\hat {a} _ {t} = \boldsymbol {X} _ {t - 1} ^ {\prime} \boldsymbol {\alpha} _ {1} + \boldsymbol {M} _ {t - 1} ^ {\prime} \boldsymbol {\alpha} _ {2} + v _ {t}, \tag {4.43}
$$

where $M _ { t - 1 } = ( \hat { x } _ { t } ^ { 2 } , \dots , \hat { x } _ { t } ^ { s + 1 } ) ^ { \prime }$ for some $s \geq 1$ , and compute the least squares residuals

$$
\hat {v} _ {t} = \hat {a} _ {t} - \boldsymbol {X} _ {t - 1} ^ {\prime} \widehat {\alpha} _ {1} - \boldsymbol {M} _ {t - 1} ^ {\prime} \widehat {\alpha} _ {2}
$$

and the sum of squared residuals SSR1 = -Tt=p+1 vˆ2t of the regression. The basic $\begin{array} { r } { S S R _ { 1 } = \sum _ { t = p + 1 } ^ { T } \hat { v } _ { t } ^ { 2 } } \end{array}$ idea of the RESET test is that if the linear $\operatorname { A R } ( p )$ model in Eq. (4.42) is adequate, then ${ \pmb { \alpha } } _ { 1 }$ and $\pmb { \alpha } _ { 2 }$ of Eq. (4.43) should be zero. This can be tested by the usual $F$ statistic of Eq. (4.43) given by

$$
F = \frac {\left(S S R _ {0} - S S R _ {1}\right) / g}{S S R _ {1} / (T - p - g)} \quad \text {w i t h} \quad g = s + p + 1, \tag {4.44}
$$

which, under the linearity and normality assumption, has an $F$ distribution with degrees of freedom $g$ and $T - p - g$ .

Remark. Because $\hat { x } _ { t } ^ { k }$ for $k = 2 , \ldots , s + 1$ tend to be highly correlated with $X _ { t - 1 }$ and among themselves, principal components of $M _ { t - 1 }$ that are not colinear with $X _ { t - 1 }$ are often used in fitting Eq. (4.43). Principal component analysis is a statistical tool for dimension reduction; see Chapter 8 for more information. 

Keenan (1985) proposes a nonlinearity test for time series that uses $\hat { x } _ { t } ^ { 2 }$ only and modifies the second step of the RESET test to avoid multicollinearity between $\hat { x } _ { t } ^ { 2 }$ and $X _ { t - 1 }$ . Specifically, the linear regression (4.43) is divided into two steps. In step 2(a), one removes linear dependence of $\hat { x } _ { t } ^ { 2 }$ on $X _ { t - 1 }$ by fitting the regression

$$
\hat {x} _ {t} ^ {2} = X _ {t - 1} ^ {\prime} \boldsymbol {\beta} + u _ {t}
$$

and obtaining the residual $\hat { u } _ { t } = \hat { x } _ { t } ^ { 2 } - X _ { t - 1 } \widehat { \pmb { \beta } } .$ . In step 2(b), consider the linear regression

$$
\hat {a} _ {t} = \hat {u} _ {t} \alpha + v _ {t},
$$

and obtain the sum of squared residuals $\begin{array} { r } { S S R _ { 1 } = \sum _ { t = p + 1 } ^ { T } ( \hat { a } _ { t } - \hat { u } _ { t } \hat { \alpha } ) ^ { 2 } = \sum _ { t = p + 1 } ^ { T } \hat { v } _ { t } ^ { 2 } } \end{array}$ to test the null hypothesis $\alpha = 0$ .

# The $F$ Test

To improve the power of Keenan’s test and the RESET test, Tsay (1986) uses a different choice of the regressor $M _ { t - 1 }$ . Specifically, he suggests using $M _ { t - 1 } =$ $v e c h ( X _ { t - 1 } X _ { t - 1 } ^ { \prime } )$ , where $v e c h ( A )$ denotes the half-stacking vector of the matrix $A$ using elements on and below the diagonal only; see Appendix B of Chapter 8 for more information about the operator. For example, if $p = 2$ , then $M _ { t - 1 } =$ $( x _ { t - 1 } ^ { 2 } , x _ { t - 1 } x _ { t - 2 } , x _ { t - 2 } ^ { 2 } ) ^ { \prime } .$ The dimension of $M _ { t - 1 }$ is $p ( p + 1 ) / 2$ for an $\operatorname { A R } ( p )$ model. In practice, the test is simply the usual partial $F$ statistic for testing ${ \pmb { \alpha } } = 0$ in the linear least squares regression

$$
x _ {t} = X _ {t - 1} ^ {\prime} \boldsymbol {\phi} + \boldsymbol {M} _ {t - 1} ^ {\prime} \boldsymbol {\alpha} + e _ {t},
$$

where $e _ { t }$ denotes the error term. Under the assumption that $x _ { t }$ is a linear $\operatorname { A R } ( p )$ process, the partial $F$ statistic follows an $F$ distribution with degrees of freedom

$g$ and $T - p - g - 1$ , where $g = p ( p + 1 ) / 2$ . We refer to this $F$ test as the Ori-$F$ test. Luukkonen, Saikkonen, and Terasvirta (1988) further extend the test by ¨ augmenting $M _ { t - 1 }$ with cubic terms $x _ { t - i } ^ { 3 }$ for $i = 1 , \ldots , p$ .

# Threshold Test

When the alternative model under study is a SETAR model, one can derive specific test statistics to increase the power of the test. One of the specific tests is the likelihood ratio statistic. This test, however, encounters the difficulty of undefined parameters under the null hypothesis of linearity because the threshold is undefined for a linear AR process. Another specific test seeks to transform testing threshold nonlinearity into detecting model changes. It is then interesting to discuss the differences between these two specific tests for threshold nonlinearity.

To simplify the discussion, let us consider the simple case that the alternative model is a 2-regime SETAR model with threshold variable $x _ { t - d }$ . The null hypothesis $H _ { o } \colon x _ { t }$ follows the linear $\operatorname { A R } ( p )$ model

$$
x _ {t} = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} x _ {t - i} + a _ {t}, \tag {4.45}
$$

whereas the alternative hypothesis $H _ { a } \colon x _ { t }$ follows the SETAR model

$$
x _ {t} = \left\{ \begin{array}{l l} \phi_ {0} ^ {(1)} + \sum_ {i = 1} ^ {p} \phi_ {i} ^ {(1)} x _ {t - i} + a _ {1 t} & \text {i f} x _ {t - d} <   r _ {1}, \\ \phi_ {0} ^ {(2)} + \sum_ {i = 1} ^ {p} \phi_ {i} ^ {(2)} x _ {t - i} + a _ {2 t} & \text {i f} x _ {t - d} \geq r _ {1}, \end{array} \right. \tag {4.46}
$$

where $r _ { 1 }$ is the threshold. For a given realization $\{ x _ { t } \} _ { t = 1 } ^ { T }$ and assuming normality, let $l _ { 0 } ( \hat { \phi } , \hat { \sigma } _ { a } ^ { 2 } )$ be the log likelihood function evaluated at the maximum likelihood estimates of $\pmb { \phi } = ( \phi _ { 0 } , \ldots , \phi _ { p } ) ^ { \prime }$ and $\sigma _ { a } ^ { 2 }$ . This is easy to compute. The likelihood function under the alternative is also easy to compute if the threshold $r _ { 1 }$ is given. Let $l _ { 1 } ( r _ { 1 } ; \hat { \pmb { \phi } } _ { 1 } , \hat { \sigma } _ { 1 } ^ { 2 } ; \hat { \pmb { \phi } } _ { 2 } , \hat { \sigma } _ { 2 } ^ { 2 } )$ be the log likelihood function evaluated at the maximum likelihood estimates of $\pmb { \phi } _ { i } = ( \phi _ { 0 } ^ { ( i ) } , \dots , \phi _ { p } ^ { ( i ) } ) ^ { \prime }$ and $\sigma _ { i } ^ { 2 }$ conditioned on knowing the threshold $r _ { 1 }$ . The log likelihood ratio $l ( r _ { 1 } )$ defined as

$$
l (r _ {1}) = l _ {1} (r _ {1}; \hat {\pmb {\phi}} _ {1}, \hat {\sigma} _ {1} ^ {2}; \hat {\pmb {\phi}} _ {2}, \hat {\sigma} _ {2} ^ {2}) - l _ {0} (\hat {\pmb {\phi}}, \hat {\sigma} _ {a} ^ {2})
$$

is then a function of the threshold $r _ { 1 }$ , which is unknown. Yet under the null hypothesis, there is no threshold and $r _ { 1 }$ is not defined. The parameter $r _ { 1 }$ is referred to as a nuisance parameter under the null hypothesis. Consequently, the asymptotic distribution of the likelihood ratio is very different from that of the conventional likelihood ratio statistics. See Chan (1991) for further details and critical values of the test. A common approach is to use $l _ { \mathrm { m a x } } = \operatorname* { s u p } _ { v < r _ { 1 } < u } l ( r _ { 1 } )$ as the test statistic, where $v$ and $u$ are prespecified lower and upper bounds of the threshold. Davis (1987) and Andrews and Ploberger (1994) provide further discussion on hypothesis testing involving nuisance parameters under the null hypothesis. Simulation is often used to obtain empirical critical values of the test statistic $l _ { \mathrm { m a x } }$ , which depends on

the choices of $v$ and $u$ . The average of $l ( r _ { 1 } )$ over $r _ { 1 } \in [ v , u ]$ is also considered by Andrews and Ploberger as a test statistic.

Tsay (1989) makes use of arranged autoregression and recursive estimation to derive an alternative test for threshold nonlinearity. The arranged autoregression seeks to transfer the SETAR model under the alternative hypothesis $H _ { a }$ into a model change problem with the threshold $r _ { 1 }$ serving as the change point. To see this, the SETAR model in Eq. (4.46) says that $x _ { t }$ follows essentially two linear models depending on whether $x _ { t - d } < r _ { 1 }$ or $x _ { t - d } \geq r _ { 1 }$ . For a realization $\{ x _ { t } \} _ { t = 1 } ^ { T }$ , $x _ { t - d }$ can assume values $\{ x _ { 1 } , \ldots , x _ { T - d } \} .$ . Let $x _ { ( 1 ) } \leq x _ { ( 2 ) } \leq \cdot \cdot \cdot \leq x _ { ( T - d ) }$ be the ordered statistics of $\{ x _ { t } \} _ { t = 1 } ^ { T - d }$ (i.e., arranging the observations in increasing order). The SETAR model can then be written as

$$
x _ {(j) + d} = \beta_ {0} + \sum_ {i = 1} ^ {p} \beta_ {i} x _ {(j) + d - i} + a _ {(j) + d}, \quad j = 1, \dots , T - d, \tag {4.47}
$$

where $\beta _ { i } = \phi _ { i } ^ { ( 1 ) }$ if $x _ { ( j ) } < r _ { 1 }$ and $\beta _ { i } = \phi _ { i } ^ { ( 2 ) }$ if $x _ { ( j ) } \geq r _ { 1 }$ . Consequently, the threshold $r _ { 1 }$ is a change point for the linear regression in Eq. (4.47), and we refer to Eq. (4.47) as an arranged autoregression (in increasing order of the threshold $x _ { t - d }$ ). Note that the arranged autoregression in (4.47) does not alter the dynamic dependence of $x _ { t }$ on $x _ { t - i }$ for $i = 1 , \ldots , p$ because $x _ { ( j ) + d }$ still depends on $x _ { ( j ) + d - i }$ for $i = 1 , \ldots , p$ . What is done is simply to present the SETAR model in the threshold space instead of in the time space. That is, the equation with a smaller $x _ { t - d }$ appears before that with a larger $x _ { t - d }$ . The threshold test of Tsay (1989) is obtained as follows.

Step 1 . Fit Eq. (4.47) using $j = 1 , \dots , m$ , where $m$ is a prespecified positive integer (e.g., 30). Denote the least squares estimates of $\beta _ { i }$ by $\hat { \beta } _ { i , m }$ , where m denotes the number of data points used in estimation.

Step 2 . Compute the predictive residual

$$
\hat {a} _ {(m + 1) + d} = x _ {(m + 1) + d} - \hat {\beta} _ {0, m} - \sum_ {i = 1} ^ {p} \hat {\beta} _ {i, m} x _ {(m + 1) + d - i}
$$

and its standard error. Let $\hat { e } _ { ( m + 1 ) + d }$ be the standardized predictive residual.

Step 3 . Use the recursive least squares method to update the least squares estimates to $\hat { \beta } _ { i , m + 1 }$ by incorporating the new data point $x _ { ( m + 1 ) + d }$ .

Step 4 . Repeat steps 2 and 3 until all data points are processed.

Step 5 . Consider the linear regression of the standardized predictive residual

$$
\hat {e} _ {(m + j) + d} = \alpha_ {0} + \sum_ {i = 1} ^ {p} \alpha_ {i} x _ {(m + j) + d - i} + v _ {t}, \quad j = 1, \dots , T - d - m \tag {4.48}
$$

and compute the usual $F$ statistic for testing $\alpha _ { i } = 0$ in Eq. (4.48) for $i =$ $0 , \ldots , p$ . Under the null hypothesis that $x _ { t }$ follows a linear $\operatorname { A R } ( p )$ model, the $F$ ratio has a limiting $F$ distribution with degrees of freedom $p + 1$ and T − d − m − p. $T - d - m - p$

We refer to the earlier $F$ test as a TAR-F test. The idea behind the test is that under the null hypothesis there is no model change in the arranged autoregression in Eq. (4.47) so that the standardized predictive residuals should be close to iid with mean zero and variance 1. In this case, they should have no correlations with the regressors $\ x { ( m + j ) + d - i }$ . For further details including formulas for a recursive least squares method and some simulation study on performance of the TAR- $F$ test, see Tsay (1989). The TAR- $F$ test avoids the problem of nuisance parameters encountered by the likelihood ratio test. It does not require knowing the threshold $r _ { 1 }$ . It simply tests that the predictive residuals have no correlations with regressors if the null hypothesis holds. Therefore, the test does not depend on knowing the number of regimes in the alternative model. Yet the TAR- $F$ test is not as powerful as the likelihood ratio test if the true model is indeed a 2-regime SETAR model with a known innovational distribution.

# 4.2.3 Applications

In this subsection, we apply some of the nonlinearity tests discussed previously to five time series. For a real financial time series, an AR model is used to remove any serial correlation in the data, and the tests apply to the residual series of the model. The five series employed are as follows:

1. $r _ { 1 t }$ : A simulated series of iid $N ( 0 , 1 )$ with 500 observations.   
2. $r _ { 2 t }$ : A simulated series of iid Student- $\cdot t$ distribution with 6 degrees of freedom. The sample size is 500.   
3. $a _ { 3 t }$ : The residual series of monthly log returns of CRSP equal-weighted index from 1926 to 1997 with 864 observations. The linear AR model used is

$$
(1 - 0. 1 8 0 B + 0. 0 9 9 B ^ {3} - 0. 1 0 5 B ^ {9}) r _ {3 t} = 0. 0 0 8 6 + a _ {3 t}.
$$

4. $a _ { 4 t }$ : The residual series of monthly log returns of CRSP value-weighted index from 1926 to 1997 with 864 observations. The linear AR model used is

$$
(1 - 0. 0 9 8 B + 0. 1 1 1 B ^ {3} - 0. 0 8 8 B ^ {5}) r _ {4 t} = 0. 0 0 7 8 + a _ {4 t}.
$$

5. $a _ { 5 t }$ : The residual series of monthly log returns of IBM stock from 1926 to 1997 with 864 observations. The linear AR model used is

$$
(1 - 0. 0 7 7 B) r _ {5 t} = 0. 0 1 1 + a _ {5 t}.
$$

Table 4.2 shows the results of the nonlinearity test. For the simulated series and IBM returns, the $F$ tests are based on an AR(6) model. For the index returns, the AR order is the same as the model given earlier. For the BDS test, we chose $\delta = \hat { \sigma } _ { a }$ and $\delta = 1 . 5 \hat { \sigma } _ { a }$ with $k = 2 , \ldots , 5 .$ . Also given in the table are the Ljung–Box statistics that confirm no serial correlation in the residual series before applying nonlinearity tests. Compared with their asymptotic critical values, the BDS test and

Table 4.2. Nonlinearity Tests for Simulated Series and Some Log Stock Returnsa   

<table><tr><td rowspan="2">Data</td><td rowspan="2">Q(5)</td><td rowspan="2">Q(10)</td><td colspan="4">BDS(δ = 1.5σa)</td></tr><tr><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>N(0,1)</td><td>3.2</td><td>6.5</td><td>-0.32</td><td>-0.14</td><td>-0.15</td><td>-0.33</td></tr><tr><td>t6</td><td>0.9</td><td>1.7</td><td>-0.87</td><td>-1.18</td><td>-1.56</td><td>-1.71</td></tr><tr><td>ln(ew)</td><td>2.9</td><td>4.9</td><td>9.94</td><td>11.72</td><td>12.83</td><td>13.65</td></tr><tr><td>ln(vw)</td><td>1.0</td><td>9.8</td><td>8.61</td><td>9.88</td><td>10.70</td><td>11.29</td></tr><tr><td>ln.ibm)</td><td>0.6</td><td>7.1</td><td>4.96</td><td>6.09</td><td>6.68</td><td>6.82</td></tr><tr><td rowspan="2">Data</td><td rowspan="2">Ori-F</td><td>d=1</td><td colspan="4">BDS(δ = σa)</td></tr><tr><td>TAR-F</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>N(0,1)</td><td>1.13</td><td>0.87</td><td>-0.77</td><td>-0.71</td><td>-1.04</td><td>-1.27</td></tr><tr><td>t6</td><td>0.69</td><td>0.81</td><td>-0.35</td><td>-0.76</td><td>-1.25</td><td>-1.49</td></tr><tr><td>ln(ew)</td><td>5.05</td><td>6.77</td><td>10.01</td><td>11.85</td><td>13.14</td><td>14.45</td></tr><tr><td>ln(vw)</td><td>4.95</td><td>6.85</td><td>7.01</td><td>7.83</td><td>8.64</td><td>9.53</td></tr><tr><td>ln.ibm)</td><td>1.32</td><td>1.51</td><td>3.82</td><td>4.70</td><td>5.45</td><td>5.72</td></tr></table>

aThe sample size of simulated series is 500 and that of stock returns is 864. The BDS test uses $k = 2 , \ldots , 5$ .

$F$ tests are insignificant at the $5 \%$ level for the simulated series. However, the BDS tests are highly significant for the real financial time series. The $F$ tests also show significant results for the index returns, but they fail to suggest nonlinearity in the IBM log returns. In summary, the tests confirm that the simulated series are linear and suggest that the stock returns are nonlinear.

# 4.3 MODELING

Nonlinear time series modeling necessarily involves subjective judgment. However, there are some general guidelines to follow. It starts with building an adequate linear model on which nonlinearity tests are based. For financial time series, the Ljung–Box statistics and Engle’s test are commonly used to detect conditional heteroscedasticity. For general series, other tests of Section 4.2 apply. If nonlinearity is statistically significant, then one chooses a class of nonlinear models to entertain. The selection here may depend on the experience of the analyst and the substantive matter of the problem under study. For volatility models, the order of an ARCH process can often be determined by checking the partial autocorrelation function of the squared series. For GARCH and EGARCH models, only lower orders such as (1,1), (1,2), and (2,1) are considered in most applications. Higher order models are hard to estimate and understand. For TAR models, one may use the procedures given in Tong (1990) and Tsay (1989, 1998) to build an adequate model. When the sample size is sufficiently large, one may apply nonparametric techniques to explore the nonlinear feature of the data and choose a proper nonlinear model

accordingly; see Chen and Tsay (1993a) and Cai, Fan, and Yao (2000). The MARS procedure of Lewis and Stevens (1991) can also be used to explore the dynamic structure of the data. Finally, information criteria such as the Akaike information criterion (Akaike, 1974) and the generalized odd ratios in Chen, McCulloch, and Tsay (1997) can be used to discriminate between competing nonlinear models. The chosen model should be carefully checked before it is used for prediction.

# 4.4 FORECASTING

Unlike the linear model, there exist no closed-form formulas to compute forecasts of most nonlinear models when the forecast horizon is greater than 1. We use parametric bootstraps to compute nonlinear forecasts. It is understood that the model used in forecasting has been rigorously checked and is judged to be adequate for the series under study. By a model, we mean the dynamic structure and innovational distributions. In some cases, we may treat the estimated parameters as given.

# 4.4.1 Parametric Bootstrap

Let $T$ be the forecast origin and $\ell$ be the forecast horizon $\ell > 0$ ). That is, we are at time index $T$ and interested in forecasting $x _ { T + \ell }$ . The parametric bootstrap considered computes realizations $x _ { T + 1 } , \dots , X _ { T + \ell }$ sequentially by (a) drawing a new innovation from the specified innovational distribution of the model, and (b) computing $x _ { T + i }$ using the model, data, and previous forecasts $x _ { T + 1 } , \dots , x _ { T + i - 1 }$ . This results in a realization for $x _ { T + \ell }$ . The procedure is repeated $M$ times to obtain $M$ realizations of $x _ { T + \ell }$ +denoted by $\{ x _ { T + \ell } ^ { ( j ) } \} _ { j = 1 } ^ { M }$ . The point forecast of $x _ { T + \ell }$ is then the sample average of $x _ { T + \ell } ^ { ( j ) }$ +  = . Let the forecast be $x _ { T } ( \ell )$ . We used $M = 3 0 0 0$ in T +
 some applications and the results seem fine. The realizations $\{ x _ { T + \ell } ^ { ( j ) } \} _ { j = 1 } ^ { M }$ can also be used to obtain an empirical distribution of $x _ { T + \ell }$ . We make use of this empirical distribution later to evaluate forecasting performance.

# 4.4.2 Forecasting Evaluation

There are many ways to evaluate the forecasting performance of a model, ranging from directional measures to magnitude measures to distributional measures. A directional measure considers the future direction (up or down) implied by the model. Predicting that tomorrow’s S&P 500 index will go up or down is an example of directional forecasts that are of practical interest. Predicting the year-end value of the daily S&P 500 index belongs to the case of magnitude measure. Finally, assessing the likelihood that the daily S&P 500 index will go up $10 \%$ or more between now and the year end requires knowing the future conditional probability distribution of the index. Evaluating the accuracy of such an assessment needs a distributional measure.

In practice, the available data set is divided into two subsamples. The first subsample of the data is used to build a nonlinear model, and the second subsample

is used to evaluate the forecasting performance of the model. We refer to the two subsamples of data as estimation and forecasting subsamples. In some studies, a rolling forecasting procedure is used in which a new data point is moved from the forecasting subsample into the estimation subsample as the forecast origin advances. In what follows, we briefly discuss some measures of forecasting performance that are commonly used in the literature. Keep in mind, however, that there exists no widely accepted single measure to compare models. A utility function based on the objective of the forecast might be needed to better understand the comparison.

# Directional Measure

A typical measure here is to use a $2 \times 2$ contingency table that summarizes the number of “hits” and “misses” of the model in predicting ups and downs of $x _ { T + \ell }$ in the forecasting subsample. Specifically, the contingency table is given as

<table><tr><td>Actual</td><td colspan="3">Predicted</td></tr><tr><td rowspan="2">up</td><td>up</td><td>down</td><td></td></tr><tr><td>m11</td><td>m12</td><td>m10</td></tr><tr><td>down</td><td>m21</td><td>m22</td><td>m20</td></tr><tr><td></td><td>m01</td><td>m02</td><td>m</td></tr></table>

where $m$ is the total number of 
-step ahead forecasts in the forecasting subsample, $m _ { 1 1 }$ is the number of “hits” in predicting upward movements, $m _ { 2 1 }$ is the number of “misses” in predicting downward movements of the market, and so on. Larger values in $m _ { 1 1 }$ and $m _ { 2 2 }$ indicate better forecasts. The test statistic

$$
\chi^ {2} = \sum_ {i = 1} ^ {2} \sum_ {j = 1} ^ {2} \frac {\left(m _ {i j} - m _ {i 0} m _ {0 j} / m\right) ^ {2}}{m _ {i 0} m _ {0 j} / m}
$$

can then be used to evaluate the performance of the model. A large $\chi ^ { 2 }$ signifies that the model outperforms the chance of random choice. Under some mild conditions, $\chi ^ { 2 }$ has an asymptotic chi-squared distribution with 1 degree of freedom. For further discussion of this measure, see Dahl and Hylleberg (1999).

For illustration of the directional measure, consider the 1-step ahead probability forecasts of the 8-4-1 feed-forward neural network shown in Figure 4.9. The $2 \times 2$ table of “hits” and “misses” of the network is

<table><tr><td>Actual</td><td colspan="3">Predicted</td></tr><tr><td></td><td>up</td><td>down</td><td></td></tr><tr><td>up</td><td>12</td><td>2</td><td>14</td></tr><tr><td>down</td><td>8</td><td>2</td><td>10</td></tr><tr><td></td><td>20</td><td>4</td><td>24</td></tr></table>

The table shows that the network predicts the upward movement well, but fares poorly in forecasting the downward movement of the stock. The chi-squared statistic

of the table is 0.137 with $p$ -value 0.71. Consequently, the network does not significantly outperform a random-walk model with equal probabilities for “upward” and “downward” movements.

# Magnitude Measure

Three statistics are commonly used to measure performance of point forecasts. They are the mean squared error (MSE), mean absolute deviation (MAD), and mean absolute percentage error (MAPE). For 
-step ahead forecasts, these measures are defined as

$$
M S E (\ell) = \frac {1}{m} \sum_ {j = 0} ^ {m - 1} \left[ x _ {T + \ell + j} - x _ {T + j} (\ell) \right] ^ {2}, \tag {4.49}
$$

$$
M A D (\ell) = \frac {1}{m} \sum_ {j = 0} ^ {m - 1} | x _ {T + \ell + j} - x _ {T + j} (\ell) |, \tag {4.50}
$$

$$
M A P E (\ell) = \frac {1}{m} \sum_ {j = 0} ^ {m - 1} \left| \frac {x _ {T + j} (\ell)}{x _ {T + j + \ell}} - 1 \right|, \tag {4.51}
$$

where $m$ is the number of $\ell$ -step ahead forecasts available in the forecasting subsample. In application, one often chooses one of the above three measures, and the model with the smallest magnitude on that measure is regarded as the best $\ell$ -step ahead forecasting model. It is possible that different 
 may result in selecting different models. The measures also have other limitations in model comparison; see, for instance, Clements and Hendry (1993).

# Distributional Measure

Practitioners recently began to assess forecasting performance of a model using its predictive distributions. Strictly speaking, a predictive distribution incorporates parameter uncertainty in forecasts. We call it conditional predictive distribution if the parameters are treated as fixed. The empirical distribution of $x _ { T + \ell }$ obtained by the parametric bootstrap is a conditional predictive distribution. This empirical distribution is often used to compute a distributional measure. Let $u _ { T } ( \ell )$ be the percentile of the observed $x _ { T + \ell }$ in the prior empirical distribution. We then have a set of $m$ percentiles $\{ u _ { T + j } ( \ell ) \} _ { j = 0 } ^ { m - 1 }$ 1 , where again $m$ is the number of 
-step ahead forecasts in the forecasting subsample. If the model entertained is adequate, $\{ u _ { T + j } ( \ell ) \}$ should be a random sample from the uniform distribution on [0, 1]. For a sufficiently large $m$ , one can compute the Kolmogorov–Smirnov statistic of $\{ u _ { T + j } ( \ell ) \}$ with respect to uniform [0, 1]. The statistic can be used for both model checking and forecasting comparison.

# 4.5 APPLICATION

In this section, we illustrate nonlinear time series models by analyzing the quarterly U.S. civilian unemployment rate, seasonally adjusted, from 1948 to 1993. This

![](images/48fc0bca2c7f79dd78e3d8ac89c8d251796b0d60c6b8133364df6085f87ade1e.jpg)  
Figure 4.11. Time plot of the U.S. quarterly unemployment rate, seasonally adjusted, from 1948 to 1993.

series was analyzed in detail by Montgomery, Zarnowitz, Tsay, and Tiao (1998). We repeat some of the analyses here using nonlinear models. Figure 4.11 shows the time plot of the data. Well-known characteristics of the series include that (a) it tends to move countercyclically with U.S. business cycles, and (b) the rate rises quickly but decays slowly. The latter characteristic suggests that the dynamic structure of the series is nonlinear.

Denote the series by $x _ { t }$ and let $\Delta x _ { t } = x _ { t } - x _ { t - 1 }$ be the change in unemployment rate. The linear model

$$
(1 - 0. 3 1 B ^ {4}) (1 - 0. 6 5 B) \Delta x _ {t} = (1 - 0. 7 8 B ^ {4}) a _ {t}, \quad \hat {\sigma} _ {a} ^ {2} = 0. 0 9 0 \tag {4.52}
$$

was built by Montgomery et al. (1998), where the standard errors of the three coefficients are 0.11, 0.06, and 0.07, respectively. This is a seasonal model even though the data were seasonally adjusted. It indicates that the seasonal adjustment procedure used did not successfully remove the seasonality. This model is used as a benchmark model for forecasting comparison.

To test for nonlinearity, we apply some of the nonlinearity tests of Section 4.2 with an AR(5) model for the differenced series $\Delta x _ { t }$ . The results are given in Table 4.3. All of the tests reject the linearity assumption. In fact, the linearity assumption is rejected for all $\operatorname { A R } ( p )$ models we applied, where $p = 2 , \ldots , 1 0$ .

Table 4.3. Nonlinearity Test for Changes in the U.S. Quarterly Unemployment Rate: 1948.II–1993.IVa   

<table><tr><td>Type</td><td>Ori-F</td><td>LST</td><td>TAR(1)</td><td>TAR(2)</td><td>TAR(3)</td><td>TAR(4)</td></tr><tr><td>Test</td><td>2.80</td><td>2.83</td><td>2.41</td><td>2.16</td><td>2.84</td><td>2.98</td></tr><tr><td>p-Value</td><td>0.0007</td><td>0.0002</td><td>0.0298</td><td>0.0500</td><td>0.0121</td><td>0.0088</td></tr></table>

aAn AR(5) model was used in the tests, where LST denotes the test of Luukkonen et al. (1988) and TAR(d) means threshold test with delay $d$ .

Using a modeling procedure similar to that of Tsay (1989), Montgomery et al. (1998) build the following TAR model for the $\Delta x _ { t }$ series:

$$
\Delta x _ {t} = \left\{ \begin{array}{l l} 0. 0 1 + 0. 7 3 \Delta x _ {t - 1} + 0. 1 0 \Delta x _ {t - 2} + a _ {1 t} & \text {i f} \Delta x _ {t - 2} \leq 0. 1, \\ 0. 1 8 + 0. 8 0 \Delta x _ {t - 1} - 0. 5 6 \Delta x _ {t - 2} + a _ {2 t} & \text {o t h e r w i s e .} \end{array} \right. \tag {4.53}
$$

The sample variances of $a _ { 1 t }$ and $a _ { 2 t }$ are 0.76 and 0.165, respectively, the standard errors of the three coefficients of regime 1 are 0.03, 0.10, and 0.12, respectively, and those of regime 2 are 0.09, 0.1, and 0.16. This model says that the change in the U.S. quarterly unemployment rate, $\Delta x _ { t }$ , behaves like a piecewise linear model in the reference space of $x _ { t - 2 } - x _ { t - 3 }$ with threshold 0.1. Intuitively, the model implies that the dynamics of unemployment act differently depending on the recent change in the unemployment rate. In the first regime, the unemployment rate has had either a decrease or a minor increase. Here the economy should be stable, and essentially the change in the rate follows a simple AR(1) model because the lag-2 coefficient is insignificant. In the second regime, there is a substantial jump in the unemployment rate (0.1 or larger). This typically corresponds to the contraction phase in the business cycle. It is also the period during which government interventions and industrial restructuring are likely to occur. Here $\Delta x _ { t }$ follows an AR(2) model with a positive constant, indicating an upward trend in $x _ { t }$ . The AR(2) polynomial contains two complex characteristic roots, which indicate possible cyclical behavior in $\Delta x _ { t }$ . Consequently, the chance of having a turning point in $x _ { t }$ increases, suggesting that the period of large increases in $x _ { t }$ should be short. This implies that the contraction phases in the U.S. economy tend to be shorter than the expansion phases.

Applying a Markov chain Monte Carlo method, Montgomery et al. (1998) obtain the following Markov switching model for $\Delta x _ { t }$ :

$$
\Delta x _ {t} = \left\{ \begin{array}{l l} - 0. 0 7 + 0. 3 8 \Delta x _ {t - 1} - 0. 0 5 \Delta x _ {t - 2} + \epsilon_ {1 t} & \text {i f} s _ {t} = 1, \\ 0. 1 6 + 0. 8 6 \Delta x _ {t - 1} - 0. 3 8 \Delta x _ {t - 2} + \epsilon_ {2 t} & \text {i f} s _ {t} = 2. \end{array} \right. \tag {4.54}
$$

The conditional means of $\Delta x _ { t }$ are $- 0 . 1 0$ for $s _ { t } = 1$ and 0.31 for $s _ { t } = 2$ . Thus, the first state represents the expansionary periods in the economy, and the second state represents the contractions. The sample variances of $\epsilon _ { 1 t }$ and $\epsilon _ { 2 t }$ are 0.031 and 0.192, respectively. The standard errors of the three parameters in state $s _ { t } = 1$ are 0.03,

0.14, and 0.11, and those of state $s _ { t } = 2$ are 0.04, 0.13, and 0.14, respectively. The state transition probabilities are $P ( s _ { t } = 2 | s _ { t - 1 } = 1 ) = 0 . 0 8 4 ( 0 . 0 6 0 )$ and $P ( s _ { t } =$ $1 | s _ { t - 1 } = 2 ) = 0 . 1 2 6 ( 0 . 0 5 3 )$ , where the number in parentheses is the corresponding standard error. This model implies that in the second state the unemployment rate $x _ { t }$ has an upward trend with an AR(2) polynomial possessing complex characteristic roots. This feature of the model is similar to the second regime of the TAR model in Eq. (4.53). In the first state, the unemployment rate $x _ { t }$ has a slightly decreasing trend with a much weaker autoregressive structure.

# Forecasting Performance

A rolling procedure was used by Montgomery et al. (1998) to forecast the unemployment rate $x _ { t }$ . The procedure works as follows:

1. Begin with forecast origin $T = 8 3$ , corresponding to 1968.II, which was used in the literature to monitor the performance of various econometric models in forecasting unemployment rate. Estimate the linear, TAR, and MSA models using the data from 1948.I to the forecast origin (inclusive).   
2. Perform 1-quarter to 5-quarter ahead forecasts and compute the forecast errors of each model. Forecasts of nonlinear models used are computed by using the parametric bootstrap method of Section 4.4.   
3. Advance the forecast origin by 1 and repeat the estimation and forecasting processes until all data are employed.   
4. Use MSE and mean forecast error to compare performance of the models.

Table 4.4 shows the relative MSE of forecasts and mean forecast errors for the linear model in Eq. (4.52), the TAR model in Eq. (4.53), and the MSA model in Eq. (4.54), using the linear model as a benchmark. The comparisons are based on overall performance as well as the status of the U.S. economy at the forecast origin. From the table, we make the following observations:

1. For the overall comparison, the TAR model and the linear model are very close in MSE, but the TAR model has smaller biases. Yet the MSA model has the highest MSE and smallest biases.   
2. For forecast origins in economic contractions, the TAR model shows improvements over the linear model both in MSE and bias. The MSA model also shows some improvement over the linear model, but the improvement is not as large as that of the TAR model.   
3. For forecast origins in economic expansions, the linear model outperforms both nonlinear models.

The results suggest that the contributions of nonlinear models over linear ones in forecasting the U.S. quarterly unemployment rate are mainly in the periods when the U.S. economy is in contraction. This is not surprising because, as mentioned before, it is during the economic contractions that government interventions and

Table 4.4. Out-of-Sample Forecast Comparison Among Linear, TAR, and MSA Models for the U.S. Quarterly Unemployment Ratea   

<table><tr><td rowspan="2">Model</td><td colspan="5">Relative MSE of Forecast</td></tr><tr><td>1-step</td><td>2-step</td><td>3-step</td><td>4-step</td><td>5-step</td></tr><tr><td colspan="6">Overall Comparison</td></tr><tr><td>Linear</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td></tr><tr><td>TAR</td><td>1.00</td><td>1.04</td><td>0.99</td><td>0.98</td><td>1.03</td></tr><tr><td>MSA</td><td>1.19</td><td>1.39</td><td>1.40</td><td>1.45</td><td>1.61</td></tr><tr><td>MSE</td><td>0.08</td><td>0.31</td><td>0.67</td><td>1.13</td><td>1.54</td></tr><tr><td colspan="6">Forecast Origins in Economic Contractions</td></tr><tr><td>Linear</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td></tr><tr><td>TAR</td><td>0.85</td><td>0.91</td><td>0.83</td><td>0.72</td><td>0.72</td></tr><tr><td>MSA</td><td>0.97</td><td>1.03</td><td>0.96</td><td>0.86</td><td>1.02</td></tr><tr><td>MSE</td><td>0.22</td><td>0.97</td><td>2.14</td><td>3.38</td><td>3.46</td></tr><tr><td colspan="6">Forecast Origins in Economic Expansions</td></tr><tr><td>Linear</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td><td>1.00</td></tr><tr><td>TAR</td><td>1.06</td><td>1.13</td><td>1.10</td><td>1.15</td><td>1.17</td></tr><tr><td>MSA</td><td>1.31</td><td>1.64</td><td>1.73</td><td>1.84</td><td>1.87</td></tr><tr><td>MSE</td><td>0.06</td><td>0.21</td><td>0.45</td><td>0.78</td><td>1.24</td></tr><tr><td colspan="6">Mean of Forecast Errors</td></tr><tr><td>Model</td><td>1-step</td><td>2-step</td><td>3-step</td><td>4-step</td><td>5-step</td></tr><tr><td colspan="6">Overall Comparison</td></tr><tr><td>Linear</td><td>0.03</td><td>0.09</td><td>0.17</td><td>0.25</td><td>0.33</td></tr><tr><td>TAR</td><td>-0.10</td><td>-0.02</td><td>-0.03</td><td>-0.03</td><td>-0.01</td></tr><tr><td>MSA</td><td>0.00</td><td>-0.02</td><td>-0.04</td><td>-0.07</td><td>-0.12</td></tr><tr><td colspan="6">Forecast Origins in Economic Contractions</td></tr><tr><td>Linear</td><td>0.31</td><td>0.68</td><td>1.08</td><td>1.41</td><td>1.38</td></tr><tr><td>TAR</td><td>0.24</td><td>0.56</td><td>0.87</td><td>1.01</td><td>0.86</td></tr><tr><td>MSA</td><td>0.20</td><td>0.41</td><td>0.57</td><td>0.52</td><td>0.14</td></tr><tr><td colspan="6">Forecast Origins in Economic Expansions</td></tr><tr><td>Linear</td><td>-0.01</td><td>0.00</td><td>0.03</td><td>0.08</td><td>0.17</td></tr><tr><td>TAR</td><td>-0.05</td><td>-0.11</td><td>-0.17</td><td>-0.19</td><td>-0.14</td></tr><tr><td>MSA</td><td>-0.03</td><td>-0.08</td><td>-0.13</td><td>-0.17</td><td>-0.16</td></tr></table>

aThe starting forecast origin is 1968.II, where the row marked by MSE shows the MSE of the benchmark linear model.

industrial restructuring are most likely to occur. These external events could introduce nonlinearity in the U.S. unemployment rate. Intuitively, such improvements are important because it is during the contractions that people pay more attention to economic forecasts.

# APPENDIX A: SOME RATS PROGRAMS FOR NONLINEAR VOLATILITY MODELS

Program Used to Estimate an AR(2)–TAR–GARCH(1,1) Model for Daily Log Returns of IBM Stock

Assume that the data file is d-ibmln03.txt.

```txt
all 0 10446:1
open data d-ibmln03.txt
data(org=obs) / rt
set h = 0.0
nonlin mu p2 a0 a1 b1 a2 b2
frml at = rt(t) -mu-p2*rt(t-2)
frml gvar = a0 + a1*at(t-1) **2+b1*h(t-1) $
	+ %if (at(t-1) < 0,a2*at(t-1)**2+b2*h(t-1),0)
frml garchln = -0.5*log(h(t)=gvar(t))-0.5*at(t)**2/h(t)
smpl 4 10446
compute mu = 0.03, p2 = -0.03
compute a0 = 0.07, a1 = 0.05, a2 = 0.05, b1 = 0.85, b2 = 0.05
maximize(method=simplex,iterations=10) garchln
smpl 4 10446
maximize(method=bhhh,recursive,iterations=150) garchln
set fv = gvar(t)
set resid = at(t)/sqrt(fv(t))
set residsq = resid(t)*resid(t)
cor(qstats,number=20, span=10) resid
cor(qstats,number=20, span=10) residsq 
```

# Program Used to Estimate a Smooth TAR Model for the Monthly Simple Returns of 3M Stock

The data file is ‘m-mmm.txt’.

```txt
all 0 623:1  
open data m-mmm.txt  
data(org=obs) / mmm  
set h = 0.0  
nonlin a0 a1 a2 a00 a11 mu  
frml at = mmm(t) - mu  
frml var1 = a0+a1*at(t-1)**2+a2*at(t-2)**2  
frml var2 = a00+a11*at(t-1)**2  
frml gvar = var1(t) + var2(t) / (1.0+exp(-at(t-1)*1000.0))  
frml garchlog = -0.5*log(h(t) = gvar(t)) - 0.5*at(t)**2/h(t) 
```

smpl 3 623   
compute a0 $= .01$ ,a1 $= 0.2$ ,a2 $= 0.1$ compute a00 $= .01$ ,a11 $= -.2$ ,mu $= 0.02$ maximize(method=bhhh,recursive,iterations $\coloneqq 150$ ) garchlog   
set fv $=$ gvar(t)   
set resid $=$ at(t)/sqrt(fv(t))   
set residsq $=$ resid(t)\*resid(t)   
cor(qstats,number $= 20$ ,span $= 10$ ) resid   
cor(qstats,number $= 20$ ,span $= 10$ ) residsq

# APPENDIX B: S-PLUS COMMANDS FOR NEURAL NETWORK

The following commands are used in S-Plus to build the 3-2-1 skip-layer feedforward network of Example 4.7. A line starting with # denotes a comment. The data file is $\cdot _ { \mathfrak { m } }$ -ibmln.txt’.

```txt
# load the data into S-Plus workspace.  
x_scan(file='m-ibmln.txt')  
# select the output: r(t)  
y_x[4:864]  
# obtain the input variables: r(t-1), r(t-2), and r(t-3)  
ibm.x_cbind(x[3:863], x[2:862], x[1:861])  
# build a 3-2-1 network with skip layer connections  
# and linear output.  
ibm.nn_nnet(IBM.x,y, size=2, linout=T, skip=T, maxit=10000, decay=1e-2, reltol=1e-7, abstol=1e-7, range=1.0)  
# print the summary results of the network summary(IBM.nn)  
# compute & print the residual sum of squares.  
sse_sum((y-predict(IBM.nn, IBM.x))^2)  
print(sse)  
# eigen(nnet.Hess(IBM.nn, IBM.x,y), T) $values  
# setup the input variables in the forecasting subsample  
ibm.p_cbind(x[864:887], x[863:886], x[862:885])  
# compute the forecasts  
yh_prediction(IBM.nn, IBM.p)  
# The observed returns in the forecasting subsample  
yo_x[865:888]  
# compute & print the sum of squares of forecast errors  
ssfe_sum((yo-yh)^2)  
print(ssfe)  
# quit S-Plus  
q() 
```

# EXERCISES

4.1. Consider the daily simple returns of Johnson and Johnson stock from January 1990 to December 2003. The data are in the file d-jnj9003.txt or can be

obtained from CRSP. Convert the returns into log returns in percentage.

(a) Build a GJR model for the log return series. Write down the fitted model. Is the leverage effect significant at the $1 \%$ level?   
(b) Build a general threshold volatility model for the log return series.   
(c) Compare the two TGARCH models.

4.2. Consider the monthly simple returns of General Electric (GE) stock from January 1926 to December 2003. You may download the data from CRSP or use the file $\mathtt { m - g e 2 6 0 3 }$ .txt on the Web. Convert the returns into log returns in percentages. Build a TGARCH model with GED innovations for the series using $a _ { t - 1 }$ as the threshold variable with zero threshold, where $a _ { t - 1 }$ is the shock at time $t - 1$ . Write down the fitted model. Is the leverage effect significant at the $5 \%$ level?

4.3. Suppose that the monthly log returns of GE stock, measured in percentages, follow a smooth threshold GARCH(1,1) model. For the sampling period from January 1926 to December 1999, the fitted model is

$$
\begin{array}{l} r _ {t} = 1. 0 6 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t} \\ \sigma_ {t} ^ {2} = 0. 1 0 3 a _ {t - 1} ^ {2} + 0. 9 5 2 \sigma_ {t - 1} ^ {2} + \frac {1}{1 + \exp (- 1 0 a _ {t - 1})} (4. 4 9 0 - 0. 1 9 3 \sigma_ {t - 1} ^ {2}), \\ \end{array}
$$

where all of the estimates are highly significant, the coefficient 10 in the exponent is fixed a priori to simplify the estimation, and $\{ \epsilon _ { t } \}$ are iid $N ( 0 , 1 )$ . Assume that $a _ { 8 8 8 } = 1 6 . 0$ and $\sigma _ { 8 8 8 } ^ { 2 } = 5 0 . 2$ . What is the 1-step ahead volatility forecast ${ \widehat \sigma } _ { 8 8 8 } ^ { 2 } ( 1 )  ?$ Suppose instead that $a _ { 8 8 8 } = - 1 6 . 0$ . What is the 1-step ahead volatility forecast ${ \widehat \sigma } _ { 8 8 8 } ^ { 2 } ( 1 ) ?$

4.4. Suppose that the monthly log returns, in percentages, of a stock follow the following Markov switching model:

$$
\begin{array}{l} r _ {t} = 1. 2 5 + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = \left\{ \begin{array}{l l} 0. 1 0 a _ {t - 1} ^ {2} + 0. 9 3 \sigma_ {t - 1} ^ {2} & \text {i f} s _ {t} = 1, \\ 4. 2 4 + 0. 1 0 a _ {t - 1} ^ {2} + 0. 7 8 \sigma_ {t - 1} ^ {2} & \text {i f} s _ {t} = 2, \end{array} \right. \\ \end{array}
$$

where the transition probabilities are

$$
P \left(s _ {t} = 2 \mid s _ {t - 1} = 1\right) = 0. 1 5, \quad P \left(s _ {t} = 1 \mid s _ {t - 1} = 2\right) = 0. 0 5.
$$

Suppose that $a _ { 1 0 0 } = 6 . 0$ , $\sigma _ { 1 0 0 } ^ { 2 } = 5 0 . 0$ , and $s _ { 1 0 0 } = 2$ with probability 1.0. What is the 1-step ahead volatility forecast at the forecast origin $t = 1 0 0 ?$ Also, if the probability of $s _ { 1 0 0 } = 2$ is reduced to 0.8, what is the 1-step ahead volatility forecast at the forecast origin $t = 1 0 0 ?$

4.5. Consider the monthly simple returns of GE stock from January 1926 to December 2003. Use the last three years of data for forecasting evaluation.

(a) Using lagged returns $r _ { t - 1 } , r _ { t - 2 } , r _ { t - 3 }$ as input, build a 3-2-1 feed-forward network to forecast 1-step ahead returns. Calculate the mean squared error of forecasts.   
(b) Again, use lagged returns $r _ { t - 1 } , r _ { t - 2 } , r _ { t - 3 }$ and their signs (directions) to build a 6-5-1 feed-forward network to forecast the 1-step ahead direction of GE stock price movement with 1 denoting upward movement. Calculate the mean squared error of forecasts.

Note: Let rtn denote a time series in S-Plus. To create a direction variable for rtn, use the command

$$
\operatorname {d r t n} = \text {i f e l s e} (\operatorname {r t n} > 0, 1, 0)
$$

4.6. Because of the existence of inverted yield curves in the term structure of interest rates, the spread of interest rates should be nonlinear. To verify this, consider the weekly U.S. interest rates of (a) Treasury 1-year constant maturity rate, and (b) Treasury 3-year constant maturity rate. As in Chapter 2, denote the two interest rates by $r _ { 1 t }$ and $r _ { 3 t }$ , respectively, and the data span is from January 5, 1962 to September 10, 1999. The data are in files w-gs3yr.txt and w-gs1yr.txt on the Web and can be obtained from the Federal Reserve Bank of St. Louis.

(a) Let $s _ { t } = r _ { 3 t } - r _ { 1 t }$ be the spread in log interest rates. Is $\left\{ { { s } _ { t } } \right\}$ linear? Perform some nonlinearity tests and draw the conclusion using the $5 \%$ significance level.   
(b) Let $s _ { t } ^ { * } = ( r _ { 3 t } - r _ { 3 , t - 1 } ) - ( r _ { 1 t } - r _ { 1 , t - 1 } ) = s _ { t } - s _ { t - 1 }$ be the change in interest rate spread. Is $\{ s _ { t } ^ { * } \}$ linear? Perform some nonlinearity tests and draw the conclusion using the $5 \%$ significance level.   
(c) Build a threshold model for the $s _ { t }$ series and check the fitted model.   
(d) Build a threshold model for the $s _ { t } ^ { * }$ series and check the fitted model.

# REFERENCES

Akaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control AC-19: 716–723.   
Andrews, D. W. K. and Ploberger, W. (1994). Optimal tests when a nuisance parameter is present only under the alternative. Econometrica 62: 1383–1414.   
Brock, W., Dechert, W. D., and Scheinkman, J. (1987). A test for independence based on the correlation dimension. Working paper, Department of Economics, University of Wisconsin, Madison.   
Brock, W., Hsieh, D. A., and LeBaron, B. (1991). Nonlinear Dynamics, Chaos and Instability: Statistical Theory and Economic Evidence. MIT Press, Cambridge, MA.   
Bryson, A. E. and Ho, Y. C. (1969). Applied Optimal Control. Blaisdell, New York.   
Cai, Z., Fan, J., and Yao, Q. (2000). Functional-coefficient regression models for nonlinear time series. Journal of the American Statistical Association 95: 941–956.

Carlin, B. P., Polson, N. G., and Stoffer, D. S. (1992). A Monte Carlo approach to nonnormal and nonlinear state space modeling. Journal of the American Statistical Association 87: 493–500.   
Chan, K. S. (1991). Percentage points of likelihood ratio tests for threshold autoregression. Journal of the Royal Statistical Society Series B 53: 691–696.   
Chan, K. S. (1993). Consistency and limiting distribution of the least squares estimator of a continuous autoregressive model. The Annals of Statistics 21: 520–533.   
Chan, K. S. and Tong, H. (1986). On estimating thresholds in autoregressive models. Journal of Time Series Analysis 7: 179–190.   
Chan, K. S. and Tsay, R. S. (1998). Limiting properties of the conditional least squares estimator of a continuous TAR model. Biometrika 85: 413–426.   
Chen, C., McCulloch, R. E., and Tsay, R. S. (1997). A unified approach to estimating and modeling univariate linear and nonlinear time series. Statistica Sinica 7: 451–472.   
Chen, R. and Tsay, R. S. (1991). On the ergodicity of TAR(1) processes. Annals of Applied Probability 1: 613–634.   
Chen, R. and Tsay, R. S. (1993a). Functional-coefficient autoregressive models. Journal of the American Statistical Association 88: 298–308.   
Chen, R. and Tsay, R. S. (1993b). Nonlinear additive ARX models. Journal of the American Statistical Association 88: 955–967.   
Chen, R., Liu, J., and Tsay, R. S. (1995). Additivity tests for nonlinear autoregressive models. Biometrika 82: 369–383.   
Chen, T. and Chen, H. (1995). Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems. IEEE Transactions on Neural Networks 6: 911–917.   
Cheng, B. and Titterington, D. M. (1994). Neural networks: A review from a statistical perspective. Statistical Science 9: 2–54.   
Clements, M. P. and Hendry, D. F. (1993). On the limitations of comparing mean square forecast errors. Journal of Forecasting 12: 617–637.   
Cleveland, W. S. (1979). Robust locally weighted regression and smoothing scatterplots. Journal of the American Statistical Association 74: 829–836.   
Dahl, C. M. and Hylleberg, S. (1999). Specifying nonlinear econometric models by flexible regression models and relative forecast performance. Working paper, Department of Economics, University of Aarhus, Denmark.   
Davis, R. B. (1987). Hypothesis testing when a nuisance parameter is present only under the alternative. Biometrika 74: 33–43.   
Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflations. Econometrica 50: 987–1007.   
Epanechnikov, V. (1969). Nonparametric estimates of a multivariate probability density. Theory of Probability and Its Applications 14: 153–158.   
Fan, J. (1993). Local linear regression smoothers and their minimax efficiencies. The Annals of Statistics 21: 196–216.   
Fan, J. and Yao, Q. (2003), Nonlinear Time Series: Nonparametric and Parametric Methods. Springer-Verlag, New York.   
Gelfand, A. E. and Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal densities. Journal of the American Statistical Association 85: 398–409.

Granger, C. W. J. and Andersen, A. P. (1978). An Introduction to Bilinear Time Series Models. Vandenhoek and Ruprecht, Gottingen.   
Hamilton, J. D. (1989). A new approach to the economic analysis of nonstationary time series and the business cycle. Econometrica 57: 357–384.   
Hamilton, J. D. (1990). Analysis of time series subject to changes in regime. Journal of Econometrics 45: 39–70.   
Hamilton, J. D. (1994). Time Series Analysis. Princeton University Press, Princeton, NJ.   
Hardle, W. (1990). ¨ Applied Nonparametric Regression. Cambridge University Press, New York.   
Hansen, B. E. (1997). Inference in TAR models. Studies in Nonlinear Dynamics and Econometrics 1: 119–131.   
Hinich, M. (1982). Testing for Gaussianity and linearity of a stationary time series. Journal of Time Series Analysis 3: 169–176.   
Hornik, K. (1993). Some new results on neural network approximation. Neural Networks 6: 1069–1072.   
Hornik, K., Stinchcombe, M., and White, H. (1989). Multilayer feedforward networks are universal approximators. Neural Networks 2: 359–366.   
Hsieh, D. A. (1989). Testing for nonlinear dependence in daily foreign exchange rates. Journal of Business 62: 339–368.   
Keenan, D. M. (1985). A Tukey non-additivity-type test for time series nonlinearity. Biometrika 72: 39–44.   
Kitagawa, G. (1998). A self-organizing state space model. Journal of the American Statistical Association 93: 1203–1215.   
Lewis, P. A. W. and Stevens, J. G. (1991). Nonlinear modeling of time series using multivariate adaptive regression spline (MARS). Journal of the American Statistical Association 86: 864–877.   
Liu, J. and Brockwell, P. J. (1988). On the general bilinear time-series model. Journal of Applied Probability 25: 553–564.   
Luukkonen, R., Saikkonen, P., and Terasvirta, T. (1988). Testing linearity against smooth ¨ transition autoregressive models. Biometrika 75: 491–499.   
McCulloch, R. E. and Tsay, R. S. (1993). Bayesian inference and prediction for mean and variance shifts in autoregressive time series. Journal of the American Statistical Association 88: 968–978.   
McCulloch, R. E. and Tsay, R. S. (1994). Statistical inference of macroeconomic time series via Markov switching models. Journal of Time Series Analysis 15: 523–539.   
McLeod, A. I. and Li, W. K. (1983). Diagnostic checking ARMA time series models using squared-residual autocorrelations. Journal of Time Series Analysis 4: 269–273.   
Montgomery, A. L., Zarnowitz, V., Tsay, R. S., and Tiao, G. C. (1998). Forecasting the U.S. unemployment rate. Journal of the American Statistical Association 93: 478–493.   
Nadaraya, E. A. (1964). On estimating regression. Theory and Probability Application 10: 186–190.   
Petruccelli, J. and Woolford, S. W. (1984). A threshold AR(1) model. Journal of Applied Probability 21: 270–286.   
Potter, S. M. (1995). A nonlinear approach to U.S. GNP. Journal of Applied Econometrics 10: 109–125.

Priestley, M. B. (1980). State-dependent models: a general approach to nonlinear time series analysis. Journal of Time Series Analysis 1: 47–71.   
Priestley, M. B. (1988). Non-linear and Non-stationary Time Series Analysis. Academic Press, London.   
Ramsey, J. B. (1969). Tests for specification errors in classical linear least squares regression analysis. Journal of the Royal Statistical Society Series B 31: 350–371.   
Ripley, B. D. (1993). Statistical aspects of neural networks. In O. E. Barndorff-Nielsen, J. L. Jensen, and W. S. Kendall, (eds.), Networks and Chaos—Statistical and Probabilistic Aspects, pp. 40–123. Chapman and Hall, London.   
Subba Rao, T. and Gabr, M. M. (1984). An Introduction to Bispectral Analysis and Bilinear Time Series Models, Lecture Notes in Statistics, 24. Springer-Verlag, New York.   
Terasvirta, T. (1994). Specification, estimation, and evaluat¨ ion of smooth transition autoregressive models. Journal of the American Statistical Association 89: 208–218.   
Tiao, G. C. and Tsay, R. S. (1994). Some advances in nonlinear and adaptive modeling in time series. Journal of Forecasting 13: 109–131.   
Tong, H. (1978). On a threshold model. In C. H. Chen (ed.), Pattern Recognition and Signal Processing. Sijhoff & Noordhoff, Amsterdam.   
Tong, H. (1983). Threshold Models in Nonlinear Time Series Analysis, Lecture Notes in Statistics. Springer-Verlag, New York.   
Tong, H. (1990). Non-Linear Time Series: A Dynamical System Approach. Oxford University Press, Oxford, UK.   
Tsay, R. S. (1986). Nonlinearity tests for time series. Biometrika 73: 461–466.   
Tsay, R. S. (1989). Testing and modeling threshold autoregressive processes. Journal of the American Statistical Association 84: 231–240.   
Tsay, R. S. (1998). Testing and modeling multivariate threshold models. Journal of the American Statistical Association 93: 1188–1202.   
Venables, W. N. and Ripley, B. D. (1999). Modern Applied Statistics with S-Plus, 3rd edition. Springer-Verlag, New York.   
Watson, G. S. (1964). Smooth regression analysis. Sankhya Series A 26: 359–372.

# High-Frequency Data Analysis and Market Microstructure

High-frequency data are observations taken at fine time intervals. In finance, they often mean observations taken daily or at a finer time scale. These data have become available primarily due to advances in data acquisition and processing techniques, and they have attracted much attention because they are important in empirical study of market microstructure. The ultimate high-frequency data in finance are the transaction-by-transaction or trade-by-trade data in security markets. Here time is often measured in seconds. The Trades and Quotes (TAQ) database of the New York Stock Exchange (NYSE) contains all equity transactions reported on the Consolidated Tape from 1992 to the present, which includes transactions on the NYSE, AMEX, NASDAQ, and the regional exchanges. The Berkeley Options Data Base provides similar data for options transactions from August 1976 to December 1996. Transactions data for many other securities and markets, both domestic and foreign, are continuously collected and processed. Wood (2000) provides some historical perspective of high-frequency financial study.

High-frequency financial data are important in studying a variety of issues related to the trading process and market microstructure. They can be used to compare the efficiency of different trading systems in price discovery (e.g., the open out-cry system of the NYSE and the computer trading system of NASDAQ). They can also be used to study the dynamics of bid and ask quotes of a particular stock (e.g., Hasbrouck, 1999; Zhang, Russell, and Tsay, 2001b). In an order-driven stock market (e.g., the Taiwan Stock Exchange), high-frequency data can be used to study the order dynamics and, more interesting, to investigate the question of “who provides the market liquidity.” Cho, Russell, Tiao, and Tsay (2003) use intraday 5-minute returns of more than 340 stocks traded on the Taiwan Stock Exchange to study the impact of daily stock price limits and find significant evidence of magnet effects toward the price ceiling.

However, high-frequency data have some unique characteristics that do not appear in lower frequencies. Analysis of these data thus introduces new challenges

to financial economists and statisticians. In this chapter, we study these special characteristics, consider methods for analyzing high-frequency data, and discuss implications of the results obtained. In particular, we discuss nonsynchronous trading, bid–ask spread, duration models, price movements that are in multiples of tick size, and bivariate models for price changes and time durations between transactions associated with price changes. The models discussed are also applicable to other scientific areas such as telecommunications and environmental studies.

# 5.1 NONSYNCHRONOUS TRADING

We begin with nonsynchronous trading. Stock tradings such as those on the NYSE do not occur in a synchronous manner; different stocks have different trading frequencies, and even for a single stock the trading intensity varies from hour to hour and from day to day. Yet we often analyze a return series in a fixed time interval such as daily, weekly, or monthly. For daily series, price of a stock is its closing price, which is the last transaction price of the stock in a trading day. The actual time of the last transaction of the stock varies from day to day. As such we incorrectly assume daily returns as an equally spaced time series with a 24-hour interval. It turns out that such an assumption can lead to erroneous conclusions about the predictability of stock returns even if the true return series are serially independent.

For daily stock returns, nonsynchronous trading can introduce (a) lag-1 crosscorrelation between stock returns, (b) lag-1 serial correlation in a portfolio return, and (c) in some situations negative serial correlations of the return series of a single stock. Consider stocks A and B. Assume that the two stocks are independent and stock A is traded more frequently than stock B. For special news affecting the market that arrives near the closing hour on one day, stock A is more likely than B to show the effect of the news on the same day simply because A is traded more frequently. The effect of the news on B will eventually appear, but it may be delayed until the following trading day. If this situation indeed happens, return of stock A appears to lead that of stock B. Consequently, the return series may show a significant lag-1 cross-correlation from A to B even though the two stocks are independent. For a portfolio that holds stocks A and B, the prior cross-correlation would become a significant lag-1 serial correlation.

In a more complicated manner, nonsynchronous trading can also induce erroneous negative serial correlations for a single stock. There are several models available in the literature to study this phenomenon; see Campbell, Lo, and MacKinlay (1997) and the references therein. Here we adopt a simplified version of the model proposed in Lo and MacKinlay (1990). Let $r _ { t }$ be the continuously compounded return of a security at the time index t. For simplicity, assume that $\{ r _ { t } \}$ is a sequence of independent and identically distributed random variables with mean $E ( r _ { t } ) = \mu$ and variance $\mathrm { V a r } ( r _ { t } ) = \sigma ^ { 2 }$ . For each time period, the probability that the security is not traded is $\pi$ , which is time-invariant and independent

of $r _ { t }$ . Let $r _ { t } ^ { o }$ be the observed return. When there is no trade at time index t, we have $r _ { t } ^ { o } = 0$ because there is no information available. Yet when there is a trade at time index $t$ , we define $r _ { t } ^ { o }$ as the cumulative return from the previous trade (i.e., $r _ { t } ^ { o } = r _ { t } + r _ { t - 1 } + \cdot \cdot \cdot + r _ { t - k _ { t } }$ , where $k _ { t }$ is the largest non-negative integer such that no trade occurred in the periods $t - k _ { t } , t - k _ { t } + 1 , \ldots , t - 1 )$ . Mathematically, the relationship between $r _ { t }$ and $r _ { t } ^ { o }$ is

$$
r _ {t} ^ {o} = \left\{ \begin{array}{l l} 0 & \text {w i t h p r o b a b i l i t y} \pi \\ r _ {t} & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {2} \\ r _ {t} + r _ {t - 1} & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {2} \pi \\ r _ {t} + r _ {t - 1} + r _ {t - 2} & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {2} \pi^ {2} \\ \vdots & \vdots \\ \sum_ {i = 0} ^ {k} r _ {t - i} & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {2} \pi^ {k} \\ \vdots & \vdots \end{array} \right. \tag {5.1}
$$

These probabilities are easy to understand. For example, $r _ { t } ^ { o } = r _ { t }$ if and only if there are trades at both $t$ and $t - 1$ , $r _ { t } ^ { o } = r _ { t } + r _ { t - 1 }$ if and only if there are trades at $t$ and $t - 2$ , but no trade at $t - 1$ , and $r _ { t } ^ { o } = r _ { t } + r _ { t - 1 } + r _ { t - 2 }$ if and only if there are trades at $t$ and $t - 3$ , but no trades at $t - 1$ and $t - 2$ , and so on. As expected, the total probability is 1 given by

$$
\pi + (1 - \pi) ^ {2} [ 1 + \pi + \pi^ {2} + \dots ] = \pi + (1 - \pi) ^ {2} \frac {1}{1 - \pi} = \pi + 1 - \pi = 1.
$$

We are ready to consider the moment equations of the observed return series $\{ r _ { t } ^ { o } \}$ . First, the expectation of $r _ { t } ^ { o }$ is

$$
\begin{array}{l} E \left(r _ {t} ^ {o}\right) = (1 - \pi) ^ {2} E \left(r _ {t}\right) + (1 - \pi) ^ {2} \pi E \left(r _ {t} + r _ {t - 1}\right) + \dots \\ = (1 - \pi) ^ {2} \mu + (1 - \pi) ^ {2} \pi 2 \mu + (1 - \pi) ^ {2} \pi^ {2} 3 \mu + \dots \\ = (1 - \pi) ^ {2} \mu \left[ 1 + 2 \pi + 3 \pi^ {2} + 4 \pi^ {3} + \dots \right] \\ = (1 - \pi) ^ {2} \mu \frac {1}{(1 - \pi) ^ {2}} = \mu . \tag {5.2} \\ \end{array}
$$

In the prior derivation, we use the result $1 + 2 \pi + 3 \pi ^ { 2 } + 4 \pi ^ { 3 } + \cdot \cdot \cdot = 1 / ( 1 - \pi ) ^ { 2 } .$ Next, for the variance of $r _ { t } ^ { o }$ , we use $\mathrm { V a r } ( r _ { t } ^ { o } ) = E [ ( r _ { t } ^ { o } ) ^ { 2 } ] - [ E ( r _ { t } ^ { o } ) ] ^ { 2 }$ and

$$
\begin{array}{l} E (r _ {t} ^ {o}) ^ {2} = (1 - \pi) ^ {2} E [ (r _ {t}) ^ {2} ] + (1 - \pi) ^ {2} \pi E [ (r _ {t} + r _ {t - 1}) ^ {2} ] + \dots \\ = (1 - \pi) ^ {2} \left[ \left(\sigma^ {2} + \mu^ {2}\right) + \pi \left(2 \sigma^ {2} + 4 \mu^ {2}\right) + \pi^ {2} \left(3 \sigma^ {2} + 9 \mu^ {2}\right) + \dots \right] (5.3) \\ = (1 - \pi) ^ {2} \left\{\sigma^ {2} \left[ 1 + 2 \pi + 3 \pi^ {2} + \dots \right] + \mu^ {2} \left[ 1 + 4 \pi + 9 \pi^ {2} + \dots \right] \right\} (5.4) \\ = \sigma^ {2} + \mu^ {2} \left[ \frac {2}{1 - \pi} - 1 \right]. (5.5) \\ \end{array}
$$

In Eq. (5.3), we use

$$
E \left(\sum_ {i = 0} ^ {k} r _ {t - i}\right) ^ {2} = \operatorname {V a r} \left(\sum_ {i = 0} ^ {k} r _ {t - i}\right) + \left[ E \left(\sum_ {i = 0} ^ {k} r _ {t - i}\right) \right] ^ {2} = (k + 1) \sigma^ {2} + [ (k + 1) \mu ] ^ {2}
$$

under the serial independence assumption of $r _ { t }$ . Using techniques similar to that of Eq. (5.2), we can show that the first term of Eq. (5.4) reduces to $\sigma ^ { 2 }$ . For the second term of Eq. (5.4), we use the identity

$$
1 + 4 \pi + 9 \pi^ {2} + 1 6 \pi^ {3} + \dots = \frac {2}{(1 - \pi) ^ {3}} - \frac {1}{(1 - \pi) ^ {2}},
$$

which can be obtained as follows. Let

$$
H = 1 + 4 \pi + 9 \pi^ {2} + 1 6 \pi^ {3} + \dots \quad \text {a n d} \quad G = 1 + 3 \pi + 5 \pi^ {2} + 7 \pi^ {3} + \dots .
$$

Then $( 1 - \pi ) H = G$ and

$$
\begin{array}{l} (1 - \pi) G = 1 + 2 \pi + 2 \pi^ {2} + 2 \pi^ {3} + \dots \\ = 2 (1 + \pi + \pi^ {2} + \dots) - 1 = \frac {2}{(1 - \pi)} - 1. \\ \end{array}
$$

Consequently, from Eqs. (5.2) and (5.5), we have

$$
\operatorname {V a r} \left(r _ {t} ^ {o}\right) = \sigma^ {2} + \mu^ {2} \left[ \frac {2}{1 - \pi} - 1 \right] - \mu^ {2} = \sigma^ {2} + \frac {2 \pi \mu^ {2}}{1 - \pi}. \tag {5.6}
$$

Consider next the lag-1 autocovariance of $\{ r _ { t } ^ { o } \}$ . Here we use $\mathrm { C o v } ( r _ { t } ^ { o } , r _ { t - 1 } ^ { o } ) =$ $E ( r _ { t } ^ { o } r _ { t - 1 } ^ { o } ) - E ( r _ { t } ^ { 0 } ) E ( r _ { t - 1 } ^ { o } ) = E ( r _ { t } ^ { o } r _ { t - 1 } ^ { o } ) - \mu ^ { 2 } .$ − . The question then reduces to finding $E ( r _ { t } ^ { o } r _ { t - 1 } ^ { o } )$ . Notice that $r _ { t } ^ { o } r _ { t - 1 } ^ { o }$ is zero if there is no trade at $t$ , no trade at $t - 1$ , or no trade at both $t$ and $t - 1$ . Therefore, we have

$$
r _ {t} ^ {o} r _ {t - 1} ^ {o} = \left\{ \begin{array}{l l} 0 & \text {w i t h p r o b a b i l i t y} 2 \pi - \pi^ {2} \\ r _ {t} r _ {t - 1} & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {3} \\ r _ {t} \left(r _ {t - 1} + r _ {t - 2}\right) & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {3} \pi \\ r _ {t} \left(r _ {t - 1} + r _ {t - 2} + r _ {t - 3}\right) & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {3} \pi^ {2} \\ \vdots & \vdots \\ r _ {t} \left(\sum_ {i = 1} ^ {k} r _ {t - i}\right) & \text {w i t h p r o b a b i l i t y} (1 - \pi) ^ {3} \pi^ {k - 1} \\ \vdots & \vdots \end{array} \right. \tag {5.7}
$$

Again the total probability is unity. To understand the prior result, notice that $r _ { t } ^ { o } r _ { t - 1 } ^ { o } = r _ { t } r _ { t - 1 }$ if and only if there are three consecutive trades at $t - 2 , t - 1$

and $t$ . Using Eq. (5.7) and the fact that $E ( r _ { t } r _ { t - j } ) = E ( r _ { t } ) E ( r _ { t - j } ) = \mu ^ { 2 }$ for $j > 0$ , we have

$$
\begin{array}{l} E (r _ {t} ^ {o} r _ {t - 1} ^ {o}) = (1 - \pi) ^ {3} \left\{E (r _ {t} r _ {t - 1}) + \pi E [ r _ {t} (r _ {t - 1} + r _ {t - 2}) ] \right. \\ + \pi^ {2} E \left[ r _ {t} \left(\sum_ {i = 1} ^ {3} r _ {t - i}\right) \right] + \dots \rbrace \\ = (1 - \pi) ^ {3} \mu^ {2} [ 1 + 2 \pi + 3 \pi^ {2} + \dots ] = (1 - \pi) \mu^ {2}. \\ \end{array}
$$

The lag-1 autocovariance of $\{ r _ { t } ^ { o } \}$ is then

$$
\operatorname {C o v} \left(r _ {t} ^ {o}, r _ {t - 1} ^ {o}\right) = - \pi \mu^ {2}. \tag {5.8}
$$

Provided that $\mu$ is not zero, the nonsynchronous trading induces a negative lag-1 autocorrelation in $r _ { t } ^ { o }$ given by

$$
\rho_ {1} (r _ {t} ^ {o}) = \frac {- (1 - \pi) \pi \mu^ {2}}{(1 - \pi) \sigma^ {2} + 2 \pi \mu^ {2}}.
$$

In general, we can extend the prior result and show that

$$
\operatorname {C o v} \left(r _ {t} ^ {o}, r _ {t - j} ^ {o}\right) = - \mu^ {2} \pi^ {j}, \quad j \geq 1.
$$

The magnitude of the lag-1 ACF depends on the choices of $\mu , \pi$ , and $\sigma$ and can be substantial. Thus, when $\mu \neq 0$ , the nonsynchronous trading induces negative autocorrelations in an observed security return series.

The previous discussion can be generalized to the return series of a portfolio that consists of $N$ securities; see Campbell, Lo, and MacKinlay (1997, Chapter 3). In the time series literature, effects of nonsynchronous trading on the return of a single security are equivalent to that of random temporal aggregation on a time series, with the trading probability $\pi$ governing the mechanism of aggregation.

# 5.2 BID–ASK SPREAD

In some stock exchanges (e.g., NYSE), market makers play an important role in facilitating trades. They provide market liquidity by standing ready to buy or sell whenever the public wishes to buy or sell. By market liquidity, we mean the ability to buy or sell significant quantities of a security quickly, anonymously, and with little price impact. In return for providing liquidity, market makers are granted monopoly rights by the exchange to post different prices for purchases and sales of a security. They buy at the bid price $P _ { b }$ and sell at a higher ask price $P _ { a }$ . (For the public, $P _ { b }$ is the sale price and $P _ { a }$ is the purchase price.) The difference $P _ { a } - P _ { b }$

is call the bid–ask spread, which is the primary source of compensation for market makers. Typically, the bid–ask spread is small—namely, one or two ticks.

The existence of a bid–ask spread, although small in magnitude, has several important consequences in time series properties of asset returns. We briefly discuss the bid–ask bounce—namely, the bid–ask spread introduces negative lag-1 serial correlation in an asset return. Consider the simple model of Roll (1984). The observed market price $P _ { t }$ of an asset is assumed to satisfy

$$
P _ {t} = P _ {t} ^ {*} + I _ {t} \frac {S}{2}, \tag {5.9}
$$

where $S = P _ { a } - P _ { b }$ is the bid–ask spread, $P _ { t } ^ { * }$ is the time-t fundamental value of the asset in a frictionless market, and $\{ I _ { t } \}$ is a sequence of independent binary random variables with equal probabilities (i.e., $I _ { t } = 1$ with probability 0.5 and $= - 1$ with probability 0.5). The $I _ { t }$ can be interpreted as an order-type indicator, with 1 signifying buyer-initiated transaction and $^ { - 1 }$ seller-initiated transaction. Alternatively, the model can be written as

$$
P _ {t} = P _ {t} ^ {*} + \left\{ \begin{array}{l l} + S / 2 & \text {w i t h p r o b a b i l i t y 0 . 5 ,} \\ - S / 2 & \text {w i t h p r o b a b i l i t y 0 . 5 .} \end{array} \right.
$$

If there is no change in $P _ { t } ^ { * }$ , then the observed process of price changes is

$$
\Delta P _ {t} = \left(I _ {t} - I _ {t - 1}\right) \frac {S}{2}. \tag {5.10}
$$

Under the assumption of $I _ { t }$ in Eq. (5.9), $E ( I _ { t } ) = 0$ and $\mathrm { V a r } ( I _ { t } ) = 1$ , and we have $E ( \Delta P _ { t } ) = 0$ and

$$
\operatorname {V a r} \left(\Delta P _ {t}\right) = S ^ {2} / 2, \tag {5.11}
$$

$$
\operatorname {C o v} \left(\Delta P _ {t}, \Delta P _ {t - 1}\right) = - S ^ {2} / 4, \tag {5.12}
$$

$$
\operatorname {C o v} \left(\Delta P _ {t}, \Delta P _ {t - j}\right) = 0, \quad j > 1. \tag {5.13}
$$

Therefore, the autocorrelation function of $\Delta P _ { t }$ is

$$
\rho_ {j} \left(\Delta P _ {t}\right) = \left\{ \begin{array}{l l} - 0. 5 & \text {i f} j = 1, \\ 0 & \text {i f} j > 1. \end{array} \right. \tag {5.14}
$$

The bid–ask spread thus introduces a negative lag-1 serial correlation in the series of observed price changes. This is referred to as the bid–ask bounce in the finance literature. Intuitively, the bounce can be seen as follows. Assume that the fundamental price $P _ { t } ^ { * }$ is equal to $( P _ { a } + P _ { b } ) / 2$ . Then $P _ { t }$ assumes the value $P _ { a }$ or $P _ { b }$ . If the previously observed price is $P _ { a }$ (the higher value), then the current observed price is either unchanged or lower at $P _ { b }$ . Thus, $\Delta P _ { t }$ is either 0 or $- S$ . However, if the previous observed price is $P _ { b }$ (the lower value), then $\Delta P _ { t }$ is either 0 or S. The negative lag-1 correlation in $\Delta P _ { t }$ becomes apparent. The bid–ask spread does not introduce any serial correlation beyond lag 1, however.

A more realistic formulation is to assume that $P _ { t } ^ { * }$ follows a random walk so that $\Delta P _ { t } ^ { * } = P _ { t } ^ { * } - P _ { t - 1 } ^ { * } = \epsilon _ { t }$ , which forms a sequence of independent and identically −distributed random variables with mean zero and variance $\sigma ^ { 2 }$ . In addition, $\{ \epsilon _ { t } \}$ is independent of $\{ I _ { t } \}$ . In this case, $\mathrm { V a r } ( \Delta P _ { t } ) = \sigma ^ { 2 } + S ^ { 2 } / 2$ , but $\mathrm { C o v } ( \Delta P _ { t } , \Delta P _ { t - j } )$ remains unchanged. Therefore,

$$
\rho_ {1} (\Delta P _ {t}) = \frac {- S ^ {2} / 4}{S ^ {2} / 2 + \sigma^ {2}} \leq 0.
$$

The magnitude of the lag-1 autocorrelation of $\Delta P _ { t }$ is reduced, but the negative effect remains when $S = P _ { a } - P _ { b } > 0$ . In finance, it might be of interest to study the components of the bid–ask spread. Interested readers are referred to Campbell, Lo, and MacKinlay (1997) and the references therein.

The effect of bid–ask spread continues to exist in portfolio returns and in multivariate financial time series. Consider the bivariate case. Denote the bivariate order-type indicator by $I _ { t } = ( I _ { 1 t } , I _ { 2 t } ) ^ { \prime }$ , where $I _ { 1 t }$ is for the first security and $I _ { 2 t }$ for the second security. If $I _ { 1 t }$ and $I _ { 2 t }$ are contemporaneously positively correlated, then the bid–ask spreads can introduce negative lag-1 cross-correlations.

# 5.3 EMPIRICAL CHARACTERISTICS OF TRANSACTIONS DATA

Let $t _ { i }$ be the calendar time, measured in seconds from midnight, at which the ith transaction of an asset takes place. Associated with the transaction are several variables such as the transaction price, the transaction volume, the prevailing bid and ask quotes, and so on. The collection of $t _ { i }$ and the associated measurements are referred to as the transactions data. These data have several important characteristics that do not exist when the observations are aggregated over time. Some of the characteristics are given next.

1. Unequally Spaced Time Intervals. Transactions such as stock tradings on an exchange do not occur at equally spaced time intervals. As such, the observed transaction prices of an asset do not form an equally spaced time series. The time duration between trades becomes important and might contain useful information about market microstructure (e.g., trading intensity).   
2. Discrete-Valued Prices. The price change of an asset from one transaction to the next only occurs in multiples of tick size. On the NYSE, the tick size was one-eighth of a dollar before June 24, 1997 and was one-sixteenth of a dollar before January 29, 2001. All NYSE and AMEX stocks started to trade in decimals on January 29, 2001. Therefore, the price is a discrete-valued variable in transactions data. In some markets, price change may also be subject to limit constraints set by regulators.   
3. Existence of a Daily Periodic or Diurnal Pattern. Under the normal trading conditions, transaction activity can exhibit a periodic pattern. For instance, on the NYSE, transactions are “heavier” at the beginning and closing of the trading hours and “thinner” during lunch hour, resulting in a U-shape

transaction intensity. Consequently, time durations between transactions also exhibit a daily cyclical pattern.

4. Multiple Transactions Within a Single Second. It is possible that multiple transactions, even with different prices, occur at the same time. This is partly due to the fact that time is measured in seconds that may be too long a time scale in periods of heavy trading.

To demonstrate these characteristics, we consider first the IBM transactions data from November 1, 1990 to January 31, 1991. These data are from the Trades, Orders Reports, and Quotes (TORQ) dataset; see Hasbrouck (1992). There are 63 trading days and 60,328 transactions. To simplify the discussion, we ignore the price changes between trading days and focus on the transactions that occurred in the normal trading hours from 9:30 am to $4 { : } 0 0 \ \mathrm { p m }$ Eastern time. It is well known that overnight stock returns differ substantially from intraday returns; see Stoll and Whaley (1990) and the references therein. Table 5.1 gives the frequencies in percentages of price change measured in the tick size of $\$ 1/8=90.125$ . From the table, we make the following observations:

1. About two-thirds of the intraday transactions were without price change.   
2. The price changed in one tick approximately $29 \%$ of the intraday transactions.   
3. Only $2 . 6 \%$ of the transactions were associated with two-tick price changes.   
4. Only about $1 . 3 \%$ of the transactions resulted in price changes of three ticks or more.   
5. The distribution of positive and negative price changes was approximately symmetric.

Consider next the number of transactions in a 5-minute time interval. Denote the series by $x _ { t }$ . That is, $x _ { 1 }$ is the number of IBM transactions from 9:30 am to 9:35 am on November 1, 1990 Eastern time, $x _ { 2 }$ is the number of transactions from 9:35 am to 9:40 am, and so on. The time gaps between trading days are ignored. Figure 5.1a shows the time plot of $x _ { t }$ , and Figure 5.1b the sample ACF of $x _ { t }$ for lags 1 to 260. Of particular interest is the cyclical pattern of the ACF with a periodicity of 78, which is the number of 5-minute intervals in a trading day. The number of transactions thus exhibits a daily pattern. To further illustrate the daily trading pattern, Figure 5.2 shows the average number of transactions within 5-minute time intervals over the 63 days. There are 78 such averages. The plot exhibits a “smiling” or U shape, indicating heavier trading at the opening and closing of the market and thinner trading during the lunch hours.

Table 5.1. Frequencies of Price Change in Multiples of Tick Size for IBM Stock from November 1, 1990 to January 31, 1991   

<table><tr><td>Number (tick)</td><td>≤ -3</td><td>-2</td><td>-1</td><td>0</td><td>1</td><td>2</td><td>≥ 3</td></tr><tr><td>Percentage</td><td>0.66</td><td>1.33</td><td>14.53</td><td>67.06</td><td>14.53</td><td>1.27</td><td>0.63</td></tr></table>

![](images/99592ef33b229a4ae333a330f0b2b9a6d77732976c00588c2c83d8ceb9e69b80.jpg)

![](images/337f22dd931f8a0f65ac6f7c1767d3a21cea6d970721d47dbae9dba0c95c5d67.jpg)  
Figure 5.1. IBM intraday transactions data from 11/01/90 to 1/31/91: (a) the number of transactions in 5-minute time intervals and (b) the sample ACF of the series in part(a).

![](images/6e3d9e6879a8fa0b11eb6005c95c0fbede1997a9818e1f5f13de785f31ffded2.jpg)  
Figure 5.2. Time plot of the average number of transactions in 5-minute time intervals. There are 78 observations, averaging over the 63 trading days from 11/01/90 to 1/31/91 for IBM stock.

Since we focus on transactions that occurred during normal trading hours of a trading day, there are 59,838 time intervals in the data. These intervals are called the intraday durations between trades. For IBM stock, there were 6531 zero time intervals. That is, during the normal trading hours of the 63 trading days from November 1, 1990 to January 31, 1991, multiple transactions in a second occurred 6531 times, which is about $1 0 . 9 1 \%$ . Among these multiple transactions, 1002 of them had different prices, which is about $1 . 6 7 \%$ of the total number of intraday transactions. Therefore, multiple transactions (i.e., zero durations) may become an issue in statistical modeling of the time durations between trades.

Table 5.2 provides a two-way classification of price movements. Here price movements are classified into “up,” “unchanged,” and “down.” We denote them by “+,” “0,” and “−,” respectively. The table shows the price movements between two consecutive trades (i.e., from the $( i - 1 )$ th to the ith transaction) in the sample. From the table, trade-by-trade data show that:

1. Consecutive price increases or decreases are relatively rare, which are about $4 4 1 / 5 9 8 3 7 = 0 . 7 4 \%$ and $4 1 0 / 5 9 8 3 7 = 0 . 6 9 \%$ , respectively.   
2. There is a slight edge to move from “up” to “unchanged” rather than to “down”; see row 1 of the table.   
3. There is a high tendency for the price to remain “unchanged.”   
4. The probabilities of moving from “down” to “up” or “unchanged” are about the same; see row 3.

The first observation mentioned before is a clear demonstration of bid–ask bounce, showing price reversals in intraday transactions data. To confirm this phenomenon, we consider a directional series $D _ { i }$ for price movements, where $D _ { i }$ assumes the value $+ 1 , 0$ , and $^ { - 1 }$ for up, unchanged, and down price movement, respectively, for the ith transaction. The ACF of $\{ D _ { i } \}$ has a single spike at lag 1 with value $- 0 . 3 8 9$ , which is highly significant for a sample size of 59,837 and confirms the price reversal in consecutive trades.

As a second illustration, we consider the transactions data of IBM stock in December 1999 obtained from the TAQ database. The normal trading hours are

Table 5.2. Two-Way Classification of Price Movements in Consecutive Intraday Trades for IBM Stocka   

<table><tr><td rowspan="2">(i-1)th Trade</td><td colspan="3">ith Trade</td><td rowspan="2">Margin</td></tr><tr><td>+</td><td>0</td><td>-</td></tr><tr><td>+</td><td>441</td><td>5498</td><td>3948</td><td>9887</td></tr><tr><td>0</td><td>4867</td><td>29779</td><td>5473</td><td>40119</td></tr><tr><td>-</td><td>4580</td><td>4841</td><td>410</td><td>9831</td></tr><tr><td>Margin</td><td>9888</td><td>40118</td><td>9831</td><td>59837</td></tr></table>

aThe price movements are classified into “up,” “unchanged,” and “down.” The data span is from 11/01/90 to 1/31/91.

from 9:30 am to $4 { : } 0 0 \ \mathrm { p m }$ Eastern time, except for December 31 when the market closed at $1 { : } 0 0 \ \mathrm { p m }$ . Comparing with the 1990–1991 data, two important changes have occurred. First, the number of intraday tradings has increased sixfold. There were 134,120 intraday tradings in December 1999 alone. The increased trading intensity also increased the chance of multiple transactions within a second. The percentage of trades with zero time duration doubled to $2 2 . 9 8 \%$ . At the extreme, there were 42 transactions within a given second that happened twice on December 3, 1999. Second, the tick size of price movement was $\$ 1/16=50.0625$ instead of $\$ 1/8$ . The change in tick size should reduce the bid–ask spread. Figure 5.3 shows the daily number of transactions in the new sample. Figure 5.4a shows the time plot of time durations between trades, measured in seconds, and Figure 5.4b is the time plot of price changes in consecutive intraday trades, measured in multiples of the tick size of $\$ 1/16$ . As expected, Figures 5.3 and 5.4a show clearly the inverse relationship between the daily number of transactions and the time interval between trades. Figure 5.4b shows two unusual price movements for IBM stock on December 3, 1999. They were a drop of 63 ticks followed by an immediate jump of 64 ticks and a drop of 68 ticks followed immediately by a jump of 68 ticks. Unusual price movements like these occurred infrequently in intraday transactions.

Focusing on trades recorded within regular trading hours, we have 61,149 trades out of 133,475 with no price change. This is about $4 5 . 8 \%$ and substantially lower than that between November 1990 and January 1991. It seems that reducing the tick size increased the chance of a price change. Table 5.3 gives the percentages of trades associated with a price change. The price movements remain approximately symmetric with respect to zero. Large price movements in intraday tradings are still relatively rare.

![](images/fab9bc600c21531c778f74406fcf2685005139d8c3d0b38767a5637b9297621c.jpg)  
Figure 5.3. IBM transactions data for December 1999. The plot shows the number of transactions in each trading day with the after-hours portion denoting the number of trades with time stamp after $4 { : } 0 0 \ \mathrm { p m }$ .

![](images/192082a4679f6c6e5cdae1794c1278490e106d91bccbd75d7bf63424deafa14a.jpg)  
(a)

![](images/c173289c63fc74cb4e2710088ca998ec30a1330ce296619e27c97b1d960957f7.jpg)  
(b)   
Figure 5.4. IBM transactions data for December 1999. (a) The time plot of time durations between trades. (b) The time plot of price changes in consecutive trades measured in multiples of the tick size of $\$ 1/16$ . Only data during normal trading hours are included.

Table 5.3. Percentages of Intraday Transactions Associated with a Price Change for IBM Stock Traded in December 1999a   

<table><tr><td>Size</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>&gt;7</td></tr><tr><td colspan="9">Upward Movements</td></tr><tr><td>Percentage</td><td>18.03</td><td>5.80</td><td>1.79</td><td>0.66</td><td>0.25</td><td>0.15</td><td>0.09</td><td>0.32</td></tr><tr><td colspan="9">Downward Movements</td></tr><tr><td>Percentage</td><td>18.24</td><td>5.57</td><td>1.79</td><td>0.71</td><td>0.24</td><td>0.17</td><td>0.10</td><td>0.31</td></tr></table>

aThe percentage of transactions without price change is $4 5 . 8 \%$ and the total number of transactions recorded within regular trading hours is 133,475. The size is measured in multiples of tick size $\$ 1/16$ .

Remark. The recordkeeping of high-frequency data is often not as good as that of observations taken at lower frequencies. Data cleaning becomes a necessity in high-frequency data analysis. For transactions data, missing observations may happen in many ways, and the accuracy of the exact transaction time might be questionable for some trades. For example, recorded trading times may be beyond 4:00 pm Eastern time even before the opening of after-hours tradings. How to handle

these observations deserves a careful study. A proper method of data cleaning requires a deep understanding of the way in which the market operates. As such, it is important to specify clearly and precisely the methods used in data cleaning. These methods must be taken into consideration in making inference. 

Again, let $t _ { i }$ be the calendar time, measured in seconds from midnight, when the ith transaction took place. Let $P _ { t _ { i } }$ be the transaction price. The price change from the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ to the ith trade is $y _ { i } \equiv \Delta P _ { t _ { i } } = P _ { t _ { i } } - P _ { t _ { i - 1 } }$ and the time duration is $\Delta t _ { i } = t _ { i } - t _ { i - 1 }$ . Here it is understood that the subscript $i$ in $\Delta t _ { i }$ and $y _ { i }$ denotes the time sequence of transactions, not the calendar time. In what follows, we consider models for $y _ { i }$ and $\Delta t _ { i }$ both individually and jointly.

# 5.4 MODELS FOR PRICE CHANGES

The discreteness and concentration on “no change” make it difficult to model the intraday price changes. Campbell, Lo, and MacKinlay (1997) discuss several econometric models that have been proposed in the literature. Here we mention two models that have the advantage of employing explanatory variables to study the intraday price movements. The first model is the ordered probit model used by Hauseman, Lo, and MacKinlay (1992) to study the price movements in transactions data. The second model has been considered recently by McCulloch and Tsay (2000) and is a simplified version of the model proposed by Rydberg and Shephard (2003); see also Ghysels (2000).

# 5.4.1 Ordered Probit Model

Let $y _ { i } ^ { * }$ be the unobservable price change of the asset under study (i.e., $y _ { i } ^ { * } = P _ { t _ { i } } ^ { * } -$ $P _ { t _ { i - 1 } } ^ { * } )$ , where $P _ { t } ^ { * }$ iis the virtual price of the asset at time t . The ordered probit model assumes that $y _ { i } ^ { * }$ is a continuous random variable and follows the model

$$
y _ {i} ^ {*} = x _ {i} \boldsymbol {\beta} + \epsilon_ {i}, \tag {5.15}
$$

where $x _ { i }$ is a $p$ -dimensional row vector of explanatory variables available at time $t _ { i - 1 }$ , $\beta$ is a $p \times 1$ parameter vector, $E ( \epsilon _ { i } | \pmb { x } _ { i } ) = 0$ , $\mathrm { V a r } ( \epsilon _ { i } | \pmb { x } _ { i } ) = \sigma _ { i } ^ { 2 }$ , and $\mathrm { C o v } ( \epsilon _ { i } , \epsilon _ { j } ) = 0$ for $i \neq j$ . The conditional variance $\sigma _ { i } ^ { 2 }$ is assumed to be a positive function of the explanatory variable ${ \pmb w } _ { i }$ — that is,

$$
\sigma_ {i} ^ {2} = g \left(\boldsymbol {w} _ {i}\right), \tag {5.16}
$$

where $g ( . )$ is a positive function. For financial transactions data, ${ \pmb w } _ { i }$ may contain the time interval $t _ { i } - t _ { i - 1 }$ and some conditional heteroscedastic variables. Typically, one also assumes that the conditional distribution of $\epsilon _ { i }$ given $x _ { i }$ and ${ \pmb w } _ { i }$ is Gaussian.

Suppose that the observed price change $y _ { i }$ may assume $k$ possible values. In theory, $k$ can be infinity, but countable. In practice, $k$ is finite and may involve combining several categories into a single value. For example, we have $k = 7$ in Table 5.1, where the first value “−3 ticks” means that the price change is $^ { - 3 }$ ticks

or lower. We denote the $k$ possible values as $\{ s _ { 1 } , \ldots , s _ { k } \}$ . The ordered probit model postulates the relationship between $y _ { i }$ and $y _ { i } ^ { * }$ as

$$
y _ {i} = s _ {j} \quad \text {i f} \quad \alpha_ {j - 1} <   y _ {i} ^ {*} \leq \alpha_ {j}, \quad j = 1, \dots , k, \tag {5.17}
$$

where $\alpha _ { j }$ are real numbers satisfying $- \infty = \alpha _ { 0 } < \alpha _ { 1 } < \cdot \cdot \cdot < \alpha _ { k - 1 } < \alpha _ { k } = \infty$ Under the assumption of conditional Gaussian distribution, we have

$$
\begin{array}{l} P \left(y _ {i} = s _ {j} \mid \boldsymbol {x} _ {i}, \boldsymbol {w} _ {i}\right) = P \left(\alpha_ {j - 1} <   \boldsymbol {x} _ {i} \boldsymbol {\beta} + \epsilon_ {i} \leq \alpha_ {j} \mid \boldsymbol {x} _ {i}, \boldsymbol {w} _ {i}\right) \\ = \left\{ \begin{array}{l l} P (\boldsymbol {x} _ {i} \boldsymbol {\beta} + \epsilon_ {i} \leq \alpha_ {1} | \boldsymbol {x} _ {i}, \boldsymbol {w} _ {i}) & \text {i f} j = 1, \\ P (\alpha_ {j - 1} <   \boldsymbol {x} _ {i} \boldsymbol {\beta} + \epsilon_ {i} \leq \alpha_ {j} | \boldsymbol {x} _ {i}, \boldsymbol {w} _ {i}) & \text {i f} j = 2, \ldots , k - 1, \\ P (\alpha_ {k - 1} <   \boldsymbol {x} _ {i} \boldsymbol {\beta} + \epsilon_ {i} | \boldsymbol {x} _ {i}, \boldsymbol {w} _ {i}) & \text {i f} j = k, \end{array} \right. \\ = \left\{ \begin{array}{l l} \Phi \left[ \frac {\alpha_ {1} - x _ {i} \boldsymbol {\beta}}{\sigma_ {i} (\boldsymbol {w} _ {i})} \right] & \text {i f} j = 1, \\ \Phi \left[ \frac {\alpha_ {j} - x _ {i} \boldsymbol {\beta}}{\sigma_ {i} (\boldsymbol {w} _ {i})} \right] - \Phi \left[ \frac {\alpha_ {j - 1} - x _ {i} \boldsymbol {\beta}}{\sigma_ {i} (\boldsymbol {w} _ {i})} \right] & \text {i f} j = 2, \dots , k - 1, \\ 1 - \Phi \left[ \frac {\alpha_ {k - 1} - x _ {i} \boldsymbol {\beta}}{\sigma_ {i} (\boldsymbol {w} _ {i})} \right] & \text {i f} j = k, \end{array} \right. \tag {5.18} \\ \end{array}
$$

where $\Phi ( x )$ is the cumulative distribution function of the standard normal random variable evaluated at $x$ , and we write $\sigma _ { i } ( { \pmb w } _ { i } )$ to denote that $\sigma _ { i } ^ { 2 }$ is a positive function of ${ \pmb w } _ { i }$ . From the definition, an ordered probit model is driven by an unobservable continuous random variable. The observed values, which have a natural ordering, can be regarded as categories representing the underlying process.

The ordered probit model contains parameters $\beta$ , $\alpha _ { i } ( i = 1 , \ldots , k - 1 )$ , and those in the conditional variance function $\sigma _ { i } ( { \pmb w } _ { i } )$ in Eq. (5.16). These parameters can be estimated by the maximum likelihood or Markov chain Monte Carlo methods.

Example 5.1. Hauseman, Lo, and MacKinlay (1992) apply the ordered probit model to the 1988 transactions data of more than 100 stocks. Here we only report their result for IBM. There are 206,794 trades. The sample mean (standard deviation) of price change $y _ { i }$ , time duration $\Delta t _ { i }$ , and bid–ask spread are 0.0010(0.753), 27.21(34.13), and 1.9470(1.4625), respectively. The bid–ask spread is measured in ticks. The model used has nine categories for price movement, and the functional specifications are

$$
\begin{array}{l} \boldsymbol {x} _ {i} \boldsymbol {\beta} = \beta_ {1} \Delta t _ {i} ^ {*} + \sum_ {v = 1} ^ {3} \beta_ {v + 1} y _ {i - v} + \sum_ {v = 1} ^ {3} \beta_ {v + 4} \mathrm {S P} 5 _ {i - v} + \sum_ {v = 1} ^ {3} \beta_ {v + 7} \mathrm {I B S} _ {i - v} \\ + \sum_ {v = 1} ^ {3} \beta_ {v + 1 0} \left[ T _ {\lambda} \left(V _ {i - v}\right) \times \mathrm {I B S} _ {i - v} \right], \tag {5.19} \\ \end{array}
$$

$$
\sigma_ {i} ^ {2} \left(\boldsymbol {w} _ {i}\right) = 1. 0 + \gamma_ {1} ^ {2} \Delta t _ {i} ^ {*} + \gamma_ {2} ^ {2} \mathrm {A B} _ {i - 1}, \tag {5.20}
$$

where $T _ { \lambda } ( V ) = ( V ^ { \lambda } - 1 ) / \lambda$ is the Box–Cox (1964) transformation of $V$ with $\lambda \in$ [0, 1] and the explanatory variables are defined by the following:

• $\Delta t _ { i } ^ { * } = ( t _ { i } - t _ { i - 1 } ) / 1 0 0$ is a rescaled time duration between the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ and ith trades with time measured in seconds.   
• $\mathrm { A B } _ { i - 1 }$ is the bid–ask spread prevailing at time $t _ { i - 1 }$ in ticks.   
• $y _ { i - v }$ $( v = 1 , 2 , 3$ ) is the lagged value of price change at $t _ { i - v }$ in ticks. With $k = 9$ , the possible values of price changes are $\{ - 4 , - 3 , - 2 , - 1 , 0 , 1 , 2 , 3 , 4 \}$ in ticks.   
• $V _ { i - v }$ $( v = 1 , 2 , 3$ ) is the lagged value of dollar volume at the $( i - v )$ th transaction, defined as the price of the $( i \mathrm { ~ - ~ } v ) \mathrm { t h }$ transaction in dollars times the number of shares traded (denominated in hundreds of shares). That is, the dollar volume is in hundreds of dollars.   
• $\mathrm { S P } 5 _ { i - v }$ $( v = 1 , 2 , 3$ ) is the 5-minute continuously compounded returns of the Standard and Poor’s 500 index futures price for the contract maturing in the closest month beyond the month in which transaction $( i - v )$ occurred, where the return is computed with the futures price recorded 1 minute before the nearest round minute prior to $t _ { i - v }$ and the price recorded 5 minutes before this.   
• $\mathrm { I B } { \cal S } _ { i - v }$ $( v = 1 , 2 , 3$ ) is an indicator variable defined by

$$
\mathrm {I B S} _ {i - v} = \left\{ \begin{array}{r l} & 1 \text {i f} P _ {i - v} > (P _ {i - v} ^ {a} + P _ {i - v} ^ {b}) / 2, \\ & 0 \text {i f} P _ {i - v} = (P _ {i - v} ^ {a} + P _ {i - v} ^ {b}) / 2, \\ & - 1 \text {i f} P _ {i - v} <   (P _ {i - v} ^ {a} + P _ {i - v} ^ {b}) / 2, \end{array} \right.
$$

where $P _ { j } ^ { a }$ and $P _ { j } ^ { b }$ are the ask and bid price at time $t _ { j }$

The parameter estimates and their $t$ -ratios are given in Table 5.4. All the $t$ -ratios are large except one, indicating that the estimates are highly significant. Such high $t$ -ratios are not surprising as the sample size is large. For the heavily traded IBM stock, the estimation results suggest the following conclusions:

1. The boundary partitions are not equally spaced, but are almost symmetric with respect to zero.   
2. The transaction duration $\Delta t _ { i }$ affects both the conditional mean and conditional variance of $y _ { i }$ in Eqs. (5.19) and (5.20).   
3. The coefficients of lagged price changes are negative and highly significant, indicating price reversals.   
4. As expected, the bid–ask spread at time $t _ { i - 1 }$ significantly affects the conditional variance.

Table 5.4. Parameter Estimates of the Ordered Probit Model in Eqs. (5.19) and (5.20) for the 1988 Transaction Data of IBM, Where t Denotes the t-Ratioa   

<table><tr><td colspan="9">Boundary Partitions of the Probit Model</td></tr><tr><td>Parameter</td><td>α1</td><td>α2</td><td>α3</td><td>α4</td><td>α5</td><td>α6</td><td>α7</td><td>α8</td></tr><tr><td>Estimate</td><td>-4.67</td><td>-4.16</td><td>-3.11</td><td>-1.34</td><td>1.33</td><td>3.13</td><td>4.21</td><td>4.73</td></tr><tr><td>t</td><td>-145.7</td><td>-157.8</td><td>-171.6</td><td>-155.5</td><td>154.9</td><td>167.8</td><td>152.2</td><td>138.9</td></tr><tr><td colspan="9">Equation Parameters of the Probit Model</td></tr><tr><td>Parameter</td><td>γ1</td><td>γ2</td><td>β1: Δti*</td><td>β2: y-1</td><td>β3</td><td>β4</td><td>β5</td><td>β6</td></tr><tr><td>Estimate</td><td>0.40</td><td>0.52</td><td>-0.12</td><td>-1.01</td><td>-0.53</td><td>-0.21</td><td>1.12</td><td>-0.26</td></tr><tr><td>t</td><td>15.6</td><td>71.1</td><td>-11.4</td><td>-135.6</td><td>-85.0</td><td>-47.2</td><td>54.2</td><td>-12.1</td></tr><tr><td>Parameter</td><td>β7</td><td>β8</td><td>β9:</td><td>β10</td><td>β11</td><td>β12</td><td>β13</td><td></td></tr><tr><td>Estimate</td><td>0.01</td><td>-1.14</td><td>-0.37</td><td>-0.17</td><td>0.12</td><td>0.05</td><td>0.02</td><td></td></tr><tr><td>t</td><td>0.26</td><td>-63.6</td><td>-21.6</td><td>-10.3</td><td>47.4</td><td>18.6</td><td>7.7</td><td></td></tr></table>

aReprinted with permission from Elsevier.

# 5.4.2 A Decomposition Model

An alternative approach to modeling price change is to decompose it into three components and use conditional specifications for the components; see Rydberg and Shephard (2003). The three components are an indicator for price change, the direction of price movement if there is a change, and the size of price change if a change occurs. Specifically, the price change at the ith transaction can be written as

$$
y _ {i} \equiv P _ {t _ {i}} - P _ {t _ {i - 1}} = A _ {i} D _ {i} S _ {i}, \tag {5.21}
$$

where $A _ { i }$ is a binary variable defined as

$$
A _ {i} = \left\{ \begin{array}{l l} 1 & \text {i f t h e r e i s a p r i c e c h a n g e a t t h e i t h t r a d e ,} \\ 0 & \text {i f p r i c e r e m a i n s t h e s a m e a t t h e i t h t r a d e ,} \end{array} \right. \tag {5.22}
$$

$D _ { i }$ is also a discrete variable signifying the direction of the price change if a change occurs—that is,

$$
D _ {i} \mid \left(A _ {i} = 1\right) = \left\{ \begin{array}{c c} 1 & \text {i f p r i c e i n c r e a s e s a t t h e i t h t r a d e ,} \\ - 1 & \text {i f p r i c e d r o p s a t t h e i t h t r a d e ,} \end{array} \right. \tag {5.23}
$$

where $D _ { i } | ( A _ { i } = 1 )$ means that $D _ { i }$ is defined under the condition of $A _ { i } = 1$ , and $S _ { i }$ is the size of the price change in ticks if there is a change at the ith trade and $S _ { i } = 0$ if there is no price change at the ith trade. When there is a price change, $S _ { i }$ is a positive integer-valued random variable.

Note that $D _ { i }$ is not needed when $A _ { i } = 0$ , and there is a natural ordering in the decomposition. $D _ { i }$ is well defined only when $A _ { i } = 1$ and $S _ { i }$ is meaningful when $A _ { i } = 1$ and $D _ { i }$ is given. Model specification under the decomposition makes use of the ordering.

Let $F _ { i }$ be the information set available at the ith transaction. Examples of elements in $F _ { i }$ are $\Delta t _ { i - j }$ , $A _ { i - j }$ , $D _ { i - j }$ , and $S _ { i - j }$ for $j \geq 0$ . The evolution of price change under model (5.21) can then be partitioned as

$$
P \left(y _ {i} \mid F _ {i - 1}\right) = P \left(A _ {i} D _ {i} S _ {i} \mid F _ {i - 1}\right) = P \left(S _ {i} \mid D _ {i}, A _ {i}, F _ {i - 1}\right) P \left(D _ {i} \mid A _ {i}, F _ {i - 1}\right) P \left(A _ {i} \mid F _ {i - 1}\right). \tag {5.24}
$$

Since $A _ { i }$ is a binary variable, it suffices to consider the evolution of the probability $p _ { i } = P ( A _ { i } = 1 )$ over time. We assume that

$$
\ln \left(\frac {p _ {i}}{1 - p _ {i}}\right) = x _ {i} \boldsymbol {\beta} \quad \text {o r} \quad p _ {i} = \frac {e ^ {\boldsymbol {x} _ {i} \boldsymbol {\beta}}}{1 + e ^ {\boldsymbol {x} _ {i} \boldsymbol {\beta}}}, \tag {5.25}
$$

where $x _ { i }$ is a finite-dimensional vector consisting of elements of $F _ { i - 1 }$ and $\beta$ is a parameter vector. Conditioned on $A _ { i } = 1$ , $D _ { i }$ is also a binary variable, and we use the following model for $\delta _ { i } = P ( D _ { i } = 1 | A _ { i } = 1 )$ ):

$$
\ln \left(\frac {\delta_ {i}}{1 - \delta_ {i}}\right) = z _ {i} \boldsymbol {\gamma} \quad \text {o r} \quad \delta_ {i} = \frac {e ^ {z _ {i}} \boldsymbol {\gamma}}{1 + e ^ {z _ {i}} \boldsymbol {\gamma}}, \tag {5.26}
$$

where $z _ { i }$ is a finite-dimensional vector consisting of elements of $F _ { i - 1 }$ and $\gamma$ is a parameter vector. To allow for asymmetry between positive and negative price changes, we assume that

$$
S _ {i} \mid \left(D _ {i}, A _ {i} = 1\right) \sim 1 + \left\{ \begin{array}{l} g \left(\lambda_ {u, i}\right) \text {i f} D _ {i} = 1, A _ {i} = 1, \\ g \left(\lambda_ {d, i}\right) \text {i f} D _ {i} = - 1, A _ {i} = 1, \end{array} \right. \tag {5.27}
$$

where $g ( \lambda )$ is a geometric distribution with parameter $\lambda$ and the parameters $\lambda _ { j , i }$ evolve over time as

$$
\ln \left(\frac {\lambda_ {j , i}}{1 - \lambda_ {j , i}}\right) = \boldsymbol {w} _ {i} \boldsymbol {\theta} _ {j} \quad \text {o r} \quad \lambda_ {j, i} = \frac {e \boldsymbol {w} _ {i} \boldsymbol {\theta} _ {j}}{1 + e \boldsymbol {w} _ {i} \boldsymbol {\theta} _ {j}}, \quad j = u, d, \tag {5.28}
$$

where ${ \pmb w } _ { i }$ is again a finite-dimensional explanatory variable in $F _ { i - 1 }$ and $\theta _ { j }$ is a parameter vector.

In Eq. (5.27), the probability mass function of a random variable $x$ , which follows the geometric distribution $g ( \lambda )$ , is

$$
p (x = m) = \lambda (1 - \lambda) ^ {m}, \quad m = 0, 1, 2, \ldots .
$$

We added 1 to the geometric distribution so that the price change, if it occurs, is at least 1 tick. In Eq. (5.28), we take the logistic transformation to ensure that $\lambda _ { j , i } \in [ 0 , 1 ]$ .

The previous specification classifies the ith trade, or transaction, into one of three categories:

1. No price change: $A _ { i } = 0$ and the associated probability is $( 1 - p _ { i } )$ .   
2. A price increase: $A _ { i } = 1$ , $D _ { i } = 1$ , and the associated probability is $p _ { i } \delta _ { i }$ . The size of the price increase is governed by $1 + g ( \lambda _ { u , i } )$ .

3. A price drop: $A _ { i } = 1$ , $D _ { i } = - 1$ , and the associated probability is $p _ { i } ( 1 - \delta _ { i } )$ The size of the price drop is governed by $1 + g ( \lambda _ { d , i } )$ .

Let $I _ { i } ( j )$ for $j = 1 , 2 , 3$ be the indicator variables of the prior three categories. That is, $I _ { i } ( j ) = 1$ if the $j$ th category occurs and $I _ { i } ( j ) = 0$ otherwise. The log likelihood function of Eq. (5.24) becomes

$$
\begin{array}{l} \ln \left[ P \left(y _ {i} \mid F _ {i - 1}\right) \right] \\ = I _ {i} (1) \ln [ (1 - p _ {i}) ] + I _ {i} (2) [ \ln (p _ {i}) + \ln (\delta_ {i}) + \ln (\lambda_ {u, i}) + (S _ {i} - 1) \ln (1 - \lambda_ {u, i}) ] \\ + I _ {i} (3) \left[ \ln \left(p _ {i}\right) + \ln \left(1 - \delta_ {i}\right) + \ln \left(\lambda_ {d, i}\right) + \left(S _ {i} - 1\right) \ln \left(1 - \lambda_ {d, i}\right) \right], \\ \end{array}
$$

and the overall log likelihood function is

$$
\ln \left[ P \left(y _ {1}, \dots , y _ {n} \mid F _ {0}\right) \right] = \sum_ {i = 1} ^ {n} \ln \left[ P \left(y _ {i} \mid F _ {i - 1}\right) \right], \tag {5.29}
$$

which is a function of parameters $\beta$ , γ , θ u, and $\pmb { \theta } _ { d }$ .

Example 5.2. We illustrate the decomposition model by analyzing the intraday transactions of IBM stock from November 1, 1990 to January 31, 1991. There were 63 trading days and 59,838 intraday transactions in the normal trading hours. The explanatory variables used are:

1. $A _ { i - 1 }$ : the action indicator of the previous trade (i.e., the $( i - 1 )$ th trade within a trading day).   
2. $D _ { i - 1 }$ : the direction indicator of the previous trade.   
3. $S _ { i - 1 }$ : the size of the previous trade.   
4. $V _ { i - 1 }$ : the volume of the previous trade, divided by 1000.   
5. $\Delta t _ { i - 1 }$ : time duration from the $( i - 2 ) \operatorname { t h }$ to $( i - 1 )$ th trade.   
6. $B A _ { i }$ : The bid–ask spread prevailing at the time of transaction.

Because we use lag-1 explanatory variables, the actual sample size is 59,775. It turns out that $V _ { i - 1 }$ , $\Delta t _ { i - 1 }$ , and $B A _ { i }$ are not statistically significant for the model entertained. Thus, only the first three explanatory variables are used. The model employed is

$$
\begin{array}{l} \ln \left(\frac {p _ {i}}{1 - p _ {i}}\right) = \beta_ {0} + \beta_ {1} A _ {i - 1}, \\ \ln \left(\frac {\delta_ {i}}{1 - \delta_ {i}}\right) = \gamma_ {0} + \gamma_ {1} D _ {i - 1}, \tag {5.30} \\ \ln \left(\frac {\lambda_ {u , i}}{1 - \lambda_ {u , i}}\right) = \theta_ {u, 0} + \theta_ {u, 1} S _ {i - 1}, \\ \ln \left(\frac {\lambda_ {d , i}}{1 - \lambda_ {d , i}}\right) = \theta_ {d, 0} + \theta_ {d, 1} S _ {i - 1}. \\ \end{array}
$$

Table 5.5. Parameter Estimates of the ADS Model in Eq. (5.30) for IBM Intraday Transactions from 11/01/90 to 1/31/91   

<table><tr><td>Parameter</td><td>β0</td><td>β1</td><td>γ0</td><td>γ1</td></tr><tr><td>Estimate</td><td>-1.057</td><td>0.962</td><td>-0.067</td><td>-2.307</td></tr><tr><td>Standard error</td><td>0.104</td><td>0.044</td><td>0.023</td><td>0.056</td></tr><tr><td>Parameter</td><td>θu,0</td><td>θu,1</td><td>θd,0</td><td>θd,1</td></tr><tr><td>Estimate</td><td>2.235</td><td>-0.670</td><td>2.085</td><td>-0.509</td></tr><tr><td>Standard error</td><td>0.029</td><td>0.050</td><td>0.187</td><td>0.139</td></tr></table>

The parameter estimates, using the log likelihood function in Eq. (5.29), are given in Table 5.5. The estimated simple model shows some dynamic dependence in the price change. In particular, the trade-by-trade price changes of IBM stock exhibit some appealing features:

1. The probability of a price change depends on the previous price change. Specifically, we have

$$
P \left(A _ {i} = 1 \mid A _ {i - 1} = 0\right) = 0. 2 5 8, \quad P \left(A _ {i} = 1 \mid A _ {i - 1} = 1\right) = 0. 4 7 6.
$$

The result indicates that a price change may occur in clusters and, as expected, most transactions are without price change. When no price change occurred at the $( i - 1 )$ th trade, then only about one out of four trades in the subsequent transaction has a price change. When there is a price change at the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ transaction, the probability of a price change in the ith trade increases to about 0.5.

2. The direction of price change is governed by

$$
P (D _ {i} = 1 | F _ {i - 1}, A _ {i}) = \left\{ \begin{array}{l l} 0. 4 8 3 \text {i f} D _ {i - 1} = 0 (\text {i . e . ,} A _ {i - 1} = 0), \\ 0. 0 8 5 \text {i f} D _ {i - 1} = 1, A _ {i} = 1, \\ 0. 9 0 4 \text {i f} D _ {i - 1} = - 1, A _ {i} = 1. \end{array} \right.
$$

This result says that (a) if no price change occurred at the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ trade, then the chances for a price increase or decrease at the ith trade are about even; and (b) the probabilities of consecutive price increases or decreases are very low. The probability of a price increase at the ith trade given that a price change occurs at the ith trade and there was a price increase at the $( i - 1 )$ th trade is only $8 . 6 \%$ . However, the probability of a price increase is about $90 \%$ given that a price change occurs at the ith trade and there was a price decrease at the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ trade. Consequently, this result shows the effect of bid–ask bounce and supports price reversals in high-frequency trading.

3. There is weak evidence suggesting that big price changes have a higher probability to be followed by another big price change. Consider the size of a price

increase. We have

$$
S _ {i} \left| \left(D _ {i} = 1\right) \sim 1 + g \left(\lambda_ {u, i}\right), \quad \lambda_ {u, i} = 2. 2 3 5 - 0. 6 7 0 S _ {i - 1}. \right.
$$

Using the probability mass function of a geometric distribution, we obtain that the probability of a price increase by one tick is 0.827 at the ith trade if the transaction results in a price increase and $S _ { i - 1 } = 1$ . The probability reduces to 0.709 if $S _ { i - 1 } = 2$ and to 0.556 if $S _ { i - 1 } = 3$ . Consequently, the probability of a large $S _ { i }$ is proportional to $S _ { i - 1 }$ given that there is a price increase at the ith trade.

A difference between the ADS and ordered probit models is that the former does not require any truncation or grouping in the size of a price change.

# 5.5 DURATION MODELS

Duration models are concerned with time intervals between trades. Longer durations indicate lack of trading activities, which in turn signify a period of no new information. The dynamic behavior of durations thus contains useful information about intraday market activities. Using concepts similar to the ARCH models for volatility, Engle and Russell (1998) propose an autoregressive conditional duration (ACD) model to describe the evolution of time durations for (heavily traded) stocks. Zhang, Russell, and Tsay (2001a) extend the ACD model to account for nonlinearity and structural breaks in the data. In this section, we introduce some simple duration models. As mentioned before, intraday transactions exhibit some diurnal pattern. Therefore, we focus on the adjusted time duration

$$
\Delta t _ {i} ^ {*} = \Delta t _ {i} / f (t _ {i}), \tag {5.31}
$$

where $f ( t _ { i } )$ is a deterministic function consisting of the cyclical component of $\Delta t _ { i }$ . Obviously, $f ( t _ { i } )$ depends on the underlying asset and the systematic behavior of the market. In practice, there are many ways to estimate $f ( t _ { i } )$ , but no single method dominates the others in terms of statistical properties. A common approach is to use smoothing spline. Here we use simple quadratic functions and indicator variables to take care of the deterministic component of daily trading activities.

For the IBM data employed in the illustration of ADS models, we assume

$$
f \left(t _ {i}\right) = \exp \left[ d \left(t _ {i}\right) \right], \quad d \left(t _ {i}\right) = \beta_ {0} + \sum_ {j = 1} ^ {7} \beta_ {j} f _ {j} \left(t _ {i}\right), \tag {5.32}
$$

where

$$
f _ {1} (t _ {i}) = - \left(\frac {t _ {i} - 4 3 2 0 0}{1 4 4 0 0}\right) ^ {2}, \quad f _ {3} (t _ {i}) = \left\{ \begin{array}{l l} - \left(\frac {t _ {i} - 3 8 7 0 0}{7 5 0 0}\right) ^ {2} & \text {i f t _ {i} <   4 3 2 0 0} \\ 0 & \text {o t h e r w i s e ,} \end{array} \right.
$$

$$
f _ {2} (t _ {i}) = - \left(\frac {t _ {i} - 4 8 3 0 0}{9 3 0 0}\right) ^ {2}, \quad f _ {4} (t _ {i}) = \left\{ \begin{array}{l l} - \left(\frac {t _ {i} - 4 8 6 0 0}{9 0 0 0}\right) ^ {2} & \text {i f} t _ {i} \geq 4 3 2 0 0 \\ 0 & \text {o t h e r w i s e ,} \end{array} \right.
$$

![](images/17d0ad3f4de46f28f42383fb40c217ead02486127fbd15f54bd1fb2e6c98ed84.jpg)  
(a)

![](images/43e690c3aa601470ffd5f772a6326803f09e7f7b6cb280d0a882679fc5b32771.jpg)  
(c)

![](images/d35bc40ff775a9bb06dc07c303322c97cb2517fcf1bfe18dfba2210ac4870fb8.jpg)  
(b)

![](images/d6813114428f70d92f9a6af0949976397dc7c0f9129eb72042f8d4039eefe411.jpg)  
(d)   
Figure 5.5. Quadratic functions used to remove the deterministic component of IBM intraday trading durations: (a)–(d) are the functions $f _ { 1 } ( . )$ to $f _ { 4 } ( . )$ of Eq. (5.32), respectively.

$f _ { 5 } ( t _ { i } )$ and $f _ { 6 } ( t _ { i } )$ are indicator variables for the first and second 5 minutes of market opening (i.e., $f _ { 5 } ( . ) = 1$ if and only if $t _ { i }$ is between 9:30 am and 9:35 am Eastern time), and $f _ { 7 } ( t _ { i } )$ is the indicator for the last 30 minutes of daily trading (i.e., $f _ { 7 } ( t _ { i } ) = 1$ if and only if the trade occurred between 3:30 pm and $4 { : } 0 0 \ \mathrm { p m }$ Eastern time). Figure 5.5 shows the plot of $f _ { i } ( . )$ for $i = 1 , \dots , 4$ , where the time scale on the $x$ -axis is in minutes. Note that $f _ { 3 } ( 4 3 2 0 0 ) = f _ { 4 } ( 4 3 2 0 0 )$ , where 43,200 corresponds to 12:00 noon.

The coefficients $\beta _ { j }$ of Eq. (5.32) are obtained by the least squares method of the linear regression

$$
\ln (\Delta t _ {i}) = \beta_ {0} + \sum_ {j = 1} ^ {7} \beta_ {j} f _ {j} (t _ {i}) + \epsilon_ {i}.
$$

The fitted model is

$$
\begin{array}{l} \ln (\widehat {\Delta t _ {i}}) = 2. 5 5 5 + 0. 1 5 9 f _ {1} (t _ {i}) + 0. 2 7 0 f _ {2} (t _ {i}) + 0. 3 8 4 f _ {3} (t _ {i}) \\ + 0. 0 6 1 f _ {4} \left(t _ {i}\right) - 0. 6 1 1 f _ {5} \left(t _ {i}\right) - 0. 1 5 7 f _ {6} \left(t _ {i}\right) + 0. 0 7 3 f _ {7} \left(t _ {i}\right). \\ \end{array}
$$

Figure 5.6 shows the time plot of average durations in 5-minute time intervals over the 63 trading days before and after adjusting for the deterministic component. Figure 5.6a shows the average durations of $\Delta t _ { i }$ and, as expected, exhibits a diurnal

![](images/a4092184571ae72ac7d67236ed6773cceaf09ca7eff8bc90c7c0952eb7549af8.jpg)  
(a)

![](images/29cc689d112956ad779c5045d9fa1e121ca32e70456a94187706ca5ec0addd16.jpg)  
(b)   
Figure 5.6. IBM transactions data from 11/01/90 to 1/31/91: (a) the average durations in 5-minute time intervals and (b) the average durations in 5-minute time intervals after adjusting for the deterministic component.

pattern. Figure 5.6b shows the average durations of $\Delta t _ { i } ^ { * }$ (i.e., after the adjustment), and the diurnal pattern is largely removed.

# 5.5.1 The ACD Model

The autoregressive conditional duration (ACD) model uses the idea of GARCH models to study the dynamic structure of the adjusted duration $\Delta t _ { i } ^ { * }$ of Eq. (5.31). For ease in notation, we define $x _ { i } = \Delta t _ { i } ^ { * }$ .

Let $\psi _ { i } = E ( x _ { i } | F _ { i - 1 } )$ be the conditional expectation of the adjusted duration between the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ and ith trades, where $F _ { i - 1 }$ is the information set available at the $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$ trade. In other words, $\psi _ { i }$ is the expected adjusted duration given $F _ { i - 1 }$ . The basic ACD model is defined as

$$
x _ {i} = \psi_ {i} \epsilon_ {i}, \tag {5.33}
$$

where $\left\{ \epsilon _ { i } \right\}$ is a sequence of independent and identically distributed non-negative random variables such that $E ( \epsilon _ { i } ) = 1$ . In Engle and Russell (1998), $\epsilon _ { i }$ follows a standard exponential or a standardized Weibull distribution, and $\psi _ { i }$ assumes the form

$$
\psi_ {i} = \omega + \sum_ {j = 1} ^ {r} \gamma_ {j} x _ {i - j} + \sum_ {j = 1} ^ {s} \omega_ {j} \psi_ {i - j}. \tag {5.34}
$$

Such a model is referred to as an $\operatorname { A C D } ( r , s )$ model. When the distribution of $\epsilon _ { i }$ is exponential, the resulting model is called an $\mathrm { E A C D } ( r , s )$ model. Similarly, if $\epsilon _ { i }$ follows a Weibull distribution, the model is a $\mathbf { W A C D } ( r , s )$ model. If necessary, readers are referred to Appendix A for a quick review of exponential and Weibull distributions.

Similar to GARCH models, the process $\eta _ { i } = x _ { i } - \psi _ { i }$ is a martingale difference sequence (i.e., $E ( \eta _ { i } | F _ { i - 1 } ) = 0 ,$ ), and the $\operatorname { A C D } ( r , s )$ model can be written as

$$
x _ {i} = \omega + \sum_ {j = 1} ^ {\max  (r, s)} \left(\gamma_ {j} + \omega_ {j}\right) x _ {i - j} - \sum_ {j = 1} ^ {s} \omega_ {j} \eta_ {i - j} + \eta_ {j}, \tag {5.35}
$$

which is in the form of an ARMA process with non-Gaussian innovations. It is understood here that $\gamma _ { j } = 0$ for $j > r$ and $\omega _ { j } = 0$ for $j > s$ . Such a representation can be used to obtain the basic conditions for weak stationarity of the ACD model. For instance, taking expectation on both sides of Eq. (5.35) and assuming weak stationarity, we have

$$
E (x _ {i}) = \frac {\omega}{1 - \sum_ {j = 1} ^ {\max (r , s)} (\gamma_ {j} + \omega_ {j})}.
$$

Therefore, we assume $\omega > 0$ and $\begin{array} { r } { 1 > \sum _ { j } ( \gamma _ { j } + \omega _ { j } ) } \end{array}$ because the expected duration is positive. As another application of Eq. (5.35), we study properties of the EACD(1,1) model.

# EACD(1,1) Model

An EACD(1,1) model can be written as

$$
x _ {i} = \psi_ {i} \epsilon_ {i}, \quad \psi_ {i} = \omega + \gamma_ {1} x _ {i - 1} + \omega_ {1} \psi_ {i - 1}, \tag {5.36}
$$

where $\epsilon _ { i }$ follows the standard exponential distribution. Using the moments of a standard exponential distribution in Appendix A, we have $E ( \epsilon _ { i } ) = 1$ , $\mathrm { V a r } ( \epsilon _ { i } ) = 1$ , and $E ( \epsilon _ { i } ^ { 2 } ) = \mathrm { V a r } ( x _ { i } ) + [ E ( x _ { i } ) ] ^ { 2 } = 2$ . Assuming that $x _ { i }$ is weakly stationary (i.e., the first two moments of $x _ { i }$ are time-invariant), we derive the variance of $x _ { i }$ . First, taking the expectation of Eq. (5.36), we have

$$
E \left(x _ {i}\right) = E \left[ E \left(\psi_ {i} \epsilon_ {i} \mid F _ {i - 1}\right) \right] = E \left(\psi_ {i}\right), \quad E \left(\psi_ {i}\right) = \omega + \gamma_ {1} E \left(x _ {i - 1}\right) + \omega_ {1} E \left(\psi_ {i - 1}\right). \tag {5.37}
$$

Under weak stationarity, $E ( \psi _ { i } ) = E ( \psi _ { i - 1 } )$ so that Eq. (5.37) gives

$$
\mu_ {x} \equiv E (x _ {i}) = E (\psi_ {i}) = \frac {\omega}{1 - \gamma_ {1} - \omega_ {1}}. \tag {5.38}
$$

Next, because $E ( \epsilon _ { i } ^ { 2 } ) = 2$ , we have $E ( x _ { i } ^ { 2 } ) = E [ E ( \psi _ { i } ^ { 2 } \epsilon _ { i } ^ { 2 } | F _ { i - 1 } ) ] = 2 E ( \psi _ { i } ^ { 2 } ) .$

Taking the square of $\psi _ { i }$ in Eq. (5.36) and the expectation and using weak stationarity of $\psi _ { i }$ and $x _ { i }$ , we have, after some algebra, that

$$
E \left(\psi_ {i} ^ {2}\right) = \mu_ {x} ^ {2} \times \frac {1 - \left(\gamma_ {1} + \omega_ {1}\right) ^ {2}}{1 - 2 \gamma_ {1} ^ {2} - \omega_ {1} ^ {2} - 2 \gamma_ {1} \omega_ {1}}. \tag {5.39}
$$

Finally, using $\mathrm { V a r } ( x _ { i } ) = E ( x _ { i } ^ { 2 } ) - [ E ( x _ { i } ) ] ^ { 2 }$ and $E ( x _ { i } ^ { 2 } ) = 2 E ( \psi _ { i } ^ { 2 } )$ , we have

$$
\operatorname {V a r} \left(x _ {i}\right) = 2 E \left(\psi_ {i} ^ {2}\right) - \mu_ {x} ^ {2} = \mu_ {x} ^ {2} \times \frac {1 - \omega_ {1} ^ {2} - 2 \gamma_ {1} \omega_ {1}}{1 - \omega_ {1} ^ {2} - 2 \gamma_ {1} \omega_ {1} - 2 \gamma_ {1} ^ {2}},
$$

where $\mu _ { x }$ is defined in Eq. (5.38). This result shows that, to have time-invariant unconditional variance, the EACD(1,1) model in Eq. (5.36) must satisfy $1 > 2 \gamma _ { 1 } ^ { 2 } +$ $\omega _ { 1 } ^ { 2 } + 2 \gamma _ { 1 } \omega _ { 1 }$ . The variance of a WACD(1,1) model can be obtained by using the same techniques and the first two moments of a standardized Weibull distribution.

# ACD Models with a Generalized Gamma Distribution

In the statistical literature, intensity function is often expressed in terms of hazard function. As shown in Appendix B, the hazard function of an EACD model is constant over time and that of a WACD model is a monotonous function. These hazard functions are rather restrictive in application as the intensity function of stock transactions might not be constant or monotone over time. To increase the flexibility of the associated hazard function, Zhang, Russell, and Tsay (2001a) employ a (standardized) generalized gamma distribution for $\epsilon _ { i }$ . See Appendix A for some basic properties of a generalized gamma distribution. The resulting hazard function may assume various patterns, including U shape or inverted U shape. We refer to an ACD model with innovations that follow a generalized gamma distribution as a $\mathbf { G A C D } ( r , s )$ model.

# 5.5.2 Simulation

To illustrate ACD processes, we generated 500 observations from the ACD(1,1) model

$$
x _ {i} = \psi_ {i} \epsilon_ {i}, \quad \psi_ {i} = 0. 3 + 0. 2 x _ {i - 1} + 0. 7 \psi_ {i - 1} \tag {5.40}
$$

using two different innovational distributions for $\epsilon _ { i }$ . In case 1, $\epsilon _ { i }$ is assumed to follow a standardized Weibull distribution with parameter $\alpha = 1 . 5$ . In case 2, $\epsilon _ { i }$ follows a (standardized) generalized gamma distribution with parameters $\kappa = 1 . 5$ and $\alpha = 0 . 5$ .

Figure 5.7a shows the time plot of the WACD(1,1) series, whereas Figure 5.8a is the GACD(1,1) series. Figure 5.9 plots the histograms of both simulated series. The difference between the two models is evident. Finally, the sample ACFs of the two simulated series are shown in Figure 5.10a and Figure 5.11b, respectively. The serial dependence of the data is clearly seen.

![](images/b4cbcb45f437337df571ec086345a2a4748da2b7846277ddc5251499150570b3.jpg)  
(a) A simulated WACD(1,1) series

![](images/26ff260cf3095bc9f0e760d0cf930c724b9b4fe1ea237b5df90d281c59ece31e.jpg)  
(b) Standardized residuals   
Figure 5.7. A simulated WACD(1,1) series in Eq. (5.40): (a) the original series and (b) the standardized series after estimation. There are 500 observations.

![](images/e3a7494f74c4c5576e7a8dc786798a4c4b710b8e720cb1306c42414a5613a154.jpg)  
(a) A simulated GACD(1,1) series

![](images/6805012aa3cd6f3f2e897789f225caa882587f14d27585f73e2c6a0a498960bf.jpg)  
(b) Standardized residuals   
Figure 5.8. A simulated GACD(1,1) series in Eq. (5.40): (a) the original series and (b) the standardized series after estimation. There are 500 observations.

![](images/1ac083e4edf5c8d018601351b4f455236869cd1a4b773926f3802627a4dc309b.jpg)

![](images/abe7606f57fcbba02586ff94cc5fc5f6a82badb84586ce52107212d34fa41b62.jpg)

![](images/ea65680d5575b37c41421df2f8d8d4c734088f5a053206d814a1248773cc8984.jpg)  
Figure 5.9. Histograms of simulated duration processes with 500 observations: (a) WACD(1,1) model and (b) GACD(1,1) model.

![](images/4637f5257e8fd92183f59a1fd791529201d07535db8cec26a2c1a18eb8ddcd80.jpg)  
Figure 5.10. The sample autocorrelation function of a simulated WACD(1,1) series with 500 observations: (a) the original series and (b) the standardized residual series.

![](images/bc3949ef2acb2e2c699147d662585dc726c2537ac7605d9705e847cdf7dceadc.jpg)  
(a) Original series

![](images/6110a458584453835511bd0de4e289e263d0e782e27f73b1649014a41c8a98e7.jpg)  
(b) Standardized residual series   
Figure 5.11. The sample autocorrelation function of a simulated GACD(1,1) series with 500 observations: (a) the original series and (b) the standardized residual series.

# 5.5.3 Estimation

For an $\mathbf { A C D } ( r , s )$ model, let $i _ { o } = \operatorname* { m a x } ( r , s )$ and $\pmb { x } _ { t } = ( x _ { 1 } , \dots , x _ { t } ) ^ { \prime }$ . The likelihood function of the durations $x _ { 1 } , \ldots , x _ { T }$ is

$$
f (\boldsymbol {x} _ {T} | \boldsymbol {\theta}) = \left[ \prod_ {i = i _ {o} + 1} ^ {T} f (x _ {i} | F _ {i - 1}, \boldsymbol {\theta}) \right] \times f (\boldsymbol {x} _ {i _ {o}} | \boldsymbol {\theta}),
$$

where $\pmb \theta$ denotes the vector of model parameters, and $T$ is the sample size. The marginal probability density function $f ( \pmb { x } _ { i _ { o } } | \pmb { \theta } )$ of the previous equation is rather complicated for a general ACD model. Because its impact on the likelihood function is diminishing as the sample size $T$ increases, this marginal density is often ignored, resulting in use of the conditional likelihood method. For a WACD model, we use the probability density function (pdf) of Eq. (5.55) and obtain the conditional log likelihood function

$$
\ell (\boldsymbol {x} \mid \boldsymbol {\theta}, \boldsymbol {x} _ {i _ {o}}) = \sum_ {i = i _ {0} + 1} ^ {T} \alpha \ln \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) \right] + \ln \left(\frac {\alpha}{x _ {i}}\right) + \alpha \ln \left(\frac {x _ {i}}{\psi_ {i}}\right) - \left(\frac {\Gamma (1 + 1 / \alpha) x _ {i}}{\psi_ {i}}\right) ^ {\alpha}, \tag {5.41}
$$

where $\begin{array} { r } { \psi _ { i } = \omega + \sum _ { j = 1 } ^ { r } \gamma _ { j } x _ { i - j } + \sum _ { j = 1 } ^ { s } \omega _ { j } \psi _ { i - j } , \pmb \theta = ( \omega , \gamma _ { 1 } , \ldots , \gamma _ { r } , \omega _ { 1 } , \ldots , \omega _ { s } , \alpha ) ^ { \prime } } \end{array}$ and $\pmb { x } = ( x _ { i _ { o } + 1 } , \dots , x _ { T } ) ^ { \prime }$ . When $\alpha = 1$ , the (conditional) log likelihood function reduces to that of an $\mathrm { E A C D } ( r , s )$ model.

For a $\mathrm { G A C D } ( r , s )$ model, the conditional log likelihood function is

$$
\ell (\boldsymbol {x} | \boldsymbol {\theta}, \boldsymbol {x} _ {i _ {o}}) = \sum_ {i = i _ {o} + 1} ^ {T} \ln \left(\frac {\alpha}{\Gamma (\kappa)}\right) + (\kappa \alpha - 1) \ln \left(x _ {i}\right) - \kappa \alpha \ln \left(\lambda \psi_ {i}\right) - \left(\frac {x _ {i}}{\lambda \psi_ {i}}\right) ^ {\alpha}, \tag {5.42}
$$

where $\lambda = \Gamma ( \kappa ) / \Gamma ( \kappa + 1 / \alpha )$ and the parameter vector $\pmb \theta$ now also includes $\kappa$ . As expected, when $\kappa = 1$ , $\lambda = 1 / \Gamma ( 1 + 1 / \alpha )$ and the log likelihood function in Eq. (5.42) reduces to that of a $\mathbf { W A C D } ( r , s )$ model in Eq. (5.41). This log likelihood function can be rewritten in many ways to simplify the estimation.

Under some regularity conditions, the conditional maximum likelihood estimates are asymptotically normal; see Engle and Russell (1998) and the references therein. In practice, simulation can be used to obtain finite-sample reference distributions for the problem of interest once a duration model is specified.

Example 5.3. (Simulated ACD(1,1) series continued). Consider the simulated WACD(1,1) and GACD(1,1) series of Eq. (5.40). We apply the conditional likelihood method and obtain the results in Table 5.6. The estimates appear to be reasonable. Let $\hat { \psi } _ { i }$ be the 1-step ahead prediction of $\psi _ { i }$ and $\hat { \epsilon } _ { i } = x _ { i } / \hat { \psi } _ { i }$ be the standardized series, which can be regarded as standardized residuals of the series. If the model is adequately specified, $\{ \hat { \epsilon } _ { i } \}$ should behave as a sequence of independent and identically distributed random variables. Figure 5.7b and Figure 5.8b show the time plot of $\hat { \epsilon } _ { i }$ for both models. The sample ACF of $\hat { \epsilon } _ { i }$ for both fitted models are shown in Figure 5.10b and Figure 5.11b, respectively. It is evident that no significant serial correlations are found in the $\hat { \epsilon } _ { i }$ series.

Table 5.6. Estimation Results for Simulated ACD(1,1) Series with 500 Observations for WACD(1,1) Series and GACD(1,1) Series   

<table><tr><td colspan="6">WACD(1,1) Model</td></tr><tr><td>Parameter</td><td>ω</td><td>γ1</td><td>ω1</td><td>α</td><td></td></tr><tr><td>True</td><td>0.3</td><td>0.2</td><td>0.7</td><td>1.5</td><td></td></tr><tr><td>Estimate</td><td>0.364</td><td>0.100</td><td>0.767</td><td>1.477</td><td></td></tr><tr><td>Standard error</td><td>(0.139)</td><td>(0.025)</td><td>(0.060)</td><td>(0.052)</td><td></td></tr><tr><td colspan="6">GACD(1,1) Model</td></tr><tr><td>Parameter</td><td>ω</td><td>γ1</td><td>ω1</td><td>α</td><td>κ</td></tr><tr><td>True</td><td>0.3</td><td>0.2</td><td>0.7</td><td>0.5</td><td>1.5</td></tr><tr><td>Estimate</td><td>0.401</td><td>0.343</td><td>0.561</td><td>0.436</td><td>2.077</td></tr><tr><td>Standard error</td><td>(0.117)</td><td>(0.074)</td><td>(0.065)</td><td>(0.078)</td><td>(0.653)</td></tr></table>

Example 5.4. As an illustration of duration models, we consider the transaction durations of IBM stock on five consecutive trading days from November 1 to November 7, 1990. Focusing on positive transaction durations, we have 3534 observations. In addition, the data have been adjusted by removing the deterministic component in Eq. (5.32). That is, we employ 3534 positive adjusted durations as defined in Eq. (5.31).

Figure 5.12a shows the time plot of the adjusted (positive) durations for the first five trading days of November 1990, and Figure 5.13a gives the sample ACF of the series. There exist some serial correlations in the adjusted durations. We fit a WACD(1,1) model to the data and obtain the model

$$
x _ {i} = \psi_ {i} \epsilon_ {i}, \quad \psi_ {i} = 0. 1 6 9 + 0. 0 6 4 x _ {i - 1} + 0. 8 8 5 \psi_ {i - 1}, \tag {5.43}
$$

where $\left\{ \epsilon _ { i } \right\}$ is a sequence of independent and identically distributed random variates that follow the standardized Weibull distribution with parameter $\hat { \alpha } = 0 . 8 7 9 ( 0 . 0 1 2 )$ , where 0.012 is the estimated standard error. Standard errors of the estimates in Eq. (5.43) are 0.039, 0.010, and 0.018, respectively. All $t$ -ratios of the estimates are greater than 4.2, indicating that the estimates are significant at the $1 \%$ level. Figure 5.12b shows the time plot of $\hat { \epsilon } _ { i } = x _ { i } / \hat { \psi } _ { i }$ , and Figure 5.13b provides the sample ACF of $\hat { \epsilon } _ { i }$ . The Ljung–Box statistics show $Q ( 1 0 ) = 4 . 9 6 $ and $Q ( 2 0 ) =$

![](images/b437a2fa20a7c6576c44ba0876667de3094aa967b959ea911409818b31ea6255.jpg)

![](images/7e97e5e5ba8633068925133c6f6caba912b4a2598c578a5d0cdb658243c0f7ff.jpg)  
Figure 5.12. Time plots of durations for IBM stock traded in the first five trading days of November 1990: (a) the adjusted series and (b) the normalized innovations of an WACD(1,1) model. There are 3534 nonzero durations.

![](images/612c520551d42948e2ab424376525fd91034b83328dcd1a585e0d03717fc2a62.jpg)

![](images/749f0738b849726c5928083585af20c0f0bf86f95a7c8c4fb25a9cb2b8dff86a.jpg)  
Figure 5.13. The sample autocorrelation function of adjusted durations for IBM stock traded in the first five trading days of November 1990: (a) the adjusted series and (b) the normalized innovations for a WACD(1,1) model.

10.75 for the $\hat { \epsilon } _ { i }$ series. Clearly, the standardized innovations have no significant serial correlations. In fact, the sample autocorrelations of the squared series $\{ \hat { \epsilon } _ { i } ^ { 2 } \}$ are also small with $Q ( 1 0 ) = 6 . 2 0 $ and $Q ( 2 0 ) = 1 1 . 1 6 $ , further confirming lack of serial dependence in the normalized innovations. In addition, the mean and standard deviation of a standardized Weibull distribution with $\alpha = 0 . 8 7 9$ are 1.00 and 1.14, respectively. These numbers are close to the sample mean and standard deviation of $\{ \hat { \epsilon } _ { i } \}$ , which are 1.01 and 1.22, respectively. The fitted model seems adequate.

In model (5.43), the estimated coefficients show $\hat { \gamma } _ { 1 } + \hat { \omega } _ { 1 } \approx 0 . 9 4 9$ , indicating certain persistence in the adjusted durations. The expected adjusted duration is $0 . 1 6 9 / ( 1 - 0 . 0 6 4 - 0 . 8 8 5 ) = 3 . 3 1$ seconds, which is close to the sample mean 3.29 of the adjusted durations. The estimated $\alpha$ of the standardized Weibull distribution is 0.879, which is less than but close to 1. Thus, the conditional hazard function is monotonously decreasing at a slow rate.

If a generalized gamma distribution function is used for the innovations, then the fitted GACD(1,1) model is

$$
x _ {i} = \psi_ {i} \epsilon_ {i}, \quad \psi_ {i} = 0. 1 4 1 + 0. 0 6 3 x _ {i - 1} + 0. 8 9 7 \psi_ {i - 1}, \tag {5.44}
$$

where $\left\{ \epsilon _ { i } \right\}$ follows a standardized, generalized gamma distribution in Eq. (5.56) with parameters $\kappa = 4 . 2 4 8 ( 1 . 0 4 6 )$ and $\alpha = 0 . 3 9 5 ( 0 . 0 5 3 )$ , where the number in

parentheses denotes estimated standard error. Standard errors of the three parameters in Eq. (5.44) are 0.041, 0.010, and 0.019, respectively. All of the estimates are statistically significant at the $1 \%$ level. Again, the normalized innovational process $\{ \hat { \epsilon } _ { i } \}$ and its squared series have no significant serial correlation, where $\hat { \epsilon } _ { i } \stackrel { \cdot } { = } x _ { i } / \hat { \psi } _ { i }$ based on model (5.44). Specifically, for the $\hat { \epsilon } _ { i }$ process, we have $Q ( 1 0 ) = 4 . 9 5$ and $Q ( 2 0 ) = 1 0 . 2 8 { \ : }$ . For the $\hat { \epsilon } _ { i } ^ { 2 }$ series, we have $Q ( 1 0 ) = 6 . 3 6 $ and $Q ( 2 0 ) = 1 0 . 8 9 $ .

The expected duration of model (5.44) is 3.52, which is slightly greater than that of the WACD(1,1) model in Eq. (5.43). Similarly, the persistence parameter $\hat { \gamma } _ { 1 } + \hat { \omega } _ { 1 }$ of model (5.44) is also slightly higher at 0.96.

Remark. Estimation of EACD models can be carried out by using programs for ARCH models with some minor modification; see Engle and Russell (1998). In this book, we use either the RATS program or some Fortran programs developed by the author to estimate the duration models. Limited experience indicates that it is harder to estimate a GACD model than an EACD or a WACD model. RATS programs used to estimate WACD and GACD models are given in Appendix C. 

# 5.6 NONLINEAR DURATION MODELS

Nonlinear features are also commonly found in high-frequency data. As an illustration, we apply some nonlinearity tests discussed in Chapter 4 to the normalized innovations $\hat { \epsilon } _ { i }$ of the WACD(1,1) model for the IBM transaction durations in Example 5.4; see Eq. (5.43). Based on an AR(4) model, the test results are given in part (a) of Table 5.7. As expected from the model diagnostics of Example 5.4, the Ori- $F$ test indicates no quadratic nonlinearity in the normalized innovations. However, the TAR- $F$ test statistics suggest strong nonlinearity.

Based on the test results in Table 5.7, we entertain a threshold duration model with two regimes for the IBM intraday durations. The threshold variable is $x _ { t - 1 }$ (i.e., lag-1 adjusted duration). The estimated threshold value is 3.79. The fitted

Table 5.7. Nonlinearity Tests for IBM Transaction Durations from November 1 to November 7, 1990a   

<table><tr><td>Type</td><td>Ori-F</td><td>TAR-F(1)</td><td>TAR-F(2)</td><td>TAR-F(3)</td><td>TAR-F(4)</td></tr><tr><td colspan="6">(a) Normalized Innovations of a WACD(1,1) Model</td></tr><tr><td>Test</td><td>0.343</td><td>3.288</td><td>3.142</td><td>3.128</td><td>0.297</td></tr><tr><td>p-Value</td><td>0.969</td><td>0.006</td><td>0.008</td><td>0.008</td><td>0.915</td></tr><tr><td colspan="6">(b) Normalized Innovations of a Threshold WACD(1,1) Model</td></tr><tr><td>Test</td><td>0.163</td><td>0.746</td><td>1.899</td><td>1.752</td><td>0.270</td></tr><tr><td>p-Value</td><td>0.998</td><td>0.589</td><td>0.091</td><td>0.119</td><td>0.929</td></tr></table>

aOnly intraday durations are used. The number in parentheses of TAR- $F$ tests denotes time delay.

threshold WACD(1,1) model is $x _ { i } = \psi _ { i } \epsilon _ { i }$ , where

$$
\psi_ {i} = \left\{ \begin{array}{l l} 0. 0 2 0 + 0. 2 5 7 x _ {i - 1} + 0. 8 4 7 \psi_ {i - 1}, & \epsilon_ {i} \sim w (0. 9 0 1) \text {i f} x _ {i - 1} \leq 3. 7 9, \\ 1. 8 0 8 + 0. 0 2 7 x _ {i - 1} + 0. 5 0 1 \psi_ {i - 1}, & \epsilon_ {i} \sim w (0. 8 4 5) \text {i f} x _ {i - 1} > 3. 7 9, \end{array} \right. \tag {5.45}
$$

where $w ( \alpha )$ denotes a standardized Weibull distribution with parameter $\alpha$ . The number of observations in the two regimes are 2503 and 1030, respectively. In Eq. (5.45), the standard errors of the parameters for the first regime are 0.043, 0.041, 0.024, and 0.014, whereas those for the second regime are 0.526, 0.020, 0.147, and 0.020, respectively.

Consider the normalized innovations $\hat { \epsilon } _ { i } = x _ { i } / \hat { \psi } _ { i }$ of the threshold WACD(1,1) model in Eq. (5.45). We obtain $Q ( 1 2 ) = 9 . 8 $ and $Q ( 2 4 ) = 2 3 . 9 $ for $\hat { \epsilon } _ { i }$ and $Q ( 1 2 ) =$ 8.0 and $Q ( 2 4 ) = 1 6 . 7 $ for $\hat { \epsilon } _ { i } ^ { 2 }$ . Thus, there are no significant serial correlations in the $\hat { \epsilon } _ { i }$ and $\hat { \epsilon } _ { i } ^ { 2 }$ series. Furthermore, applying the same nonlinearity tests as before to this newly normalized innovational series $\hat { \epsilon } _ { i }$ , we detect no nonlinearity; see part (b) of Table 5.7. Consequently, the two-regime threshold WACD(1,1) model in Eq. (5.45) is adequate.

If we classify the two regimes as heavy and thin trading periods, then the threshold model suggests that the trading dynamics measured by intraday transaction durations are different between heavy and thin trading periods for IBM stock even after the adjustment of diurnal pattern. This is not surprising as market activities are often driven by the arrival of news and other information.

The estimated threshold WACD(1,1) model in Eq. (5.45) contains some insignificant parameters. We refine the model and obtain the result:

$$
\psi_ {i} = \left\{ \begin{array}{l l} 0. 2 2 5 x _ {i - 1} + 0. 8 6 7 \psi_ {i - 1}, & \epsilon_ {i} \sim w (0. 9 0 2) \text {i f} x _ {i - 1} \leq 3. 7 9, \\ 1. 6 1 8 + 0. 6 1 4 \psi_ {i - 1}, & \epsilon_ {i} \sim w (0. 8 4 6) \text {i f} x _ {i - 1} > 3. 7 9. \end{array} \right.
$$

All of the estimates of the refined model are highly significant. The Ljung–Box statistics of the standardized innovations $\hat { \epsilon } _ { i } = \bar { x } _ { i } / \hat { \psi } _ { i }$ show $Q ( 1 0 ) = 5 . 9 1 ( $ (0.82) and $Q ( 2 0 ) = 1 6 . 0 4 ( 0 . 7 1 )$ and those of $\hat { \epsilon } _ { i } ^ { 2 }$ give $Q ( 1 0 ) = 5 . 3 5 ( 0 . 8 7 )$ and $Q ( 2 0 ) =$ 15.20(0.76), where the number in parentheses is the $p$ -value. Therefore, the refined model is adequate. The RATS program used to estimate the prior model is given in Appendix C.

# 5.7 BIVARIATE MODELS FOR PRICE CHANGE AND DURATION

In this section, we introduce a model that considers jointly the process of price change and the associated duration. As mentioned before, many intraday transactions of a stock result in no price change. Those transactions are highly relevant to trading intensity, but they do not contain direct information on price movement. Therefore, to simplify the complexity involved in modeling price change, we focus on transactions that result in a price change and consider a price change

and duration (PCD) model to describe the multivariate dynamics of price change and the associated time duration.

We continue to use the same notation as before, but the definition is changed to transactions with a price change. Let $t _ { i }$ be the calendar time of the ith price change of an asset. As before, $t _ { i }$ is measured in seconds from midnight of a trading day. Let $P _ { t _ { i } }$ be the transaction price when the ith price change occurred and $\Delta t _ { i } = t _ { i } - t _ { i - 1 }$ be the time duration between price changes. In addition, let $N _ { i }$ be the number of trades in the time interval $( t _ { i - 1 } , t _ { i } )$ that result in no price change. This new variable is used to represent trading intensity during a period of no price change. Finally, let $D _ { i }$ be the direction of the ith price change with $D _ { i } = 1$ when price goes up and $D _ { i } = - 1$ when the price comes down, and let $S _ { i }$ be the size of the ith price change measured in ticks. Under the new definitions, the price of a stock evolves over time by

$$
P _ {t _ {i}} = P _ {t _ {i - 1}} + D _ {i} S _ {i}, \tag {5.46}
$$

and the transactions data consist of $\{ \Delta t _ { i } , N _ { i } , D _ { i } , S _ { i } \}$ for the ith price change. The PCD model is concerned with the joint analysis of $\left( \Delta t _ { i } , N _ { i } , D _ { i } , S _ { i } \right)$ .

Remark. Focusing on transactions associated with a price change can reduce the sample size dramatically. For example, consider the intraday data of IBM stock from November 1, 1990 to January 31, 1991. There were 60,265 intraday trades, but only 19,022 of them resulted in a price change. In addition, there is no diurnal pattern in time durations between price changes.

To illustrate the relationship among the price movements of all transactions and those of transactions associated with a price change, we consider the intraday tradings of IBM stock on November 21, 1990. There were 726 transactions on that day during normal trading hours, but only 195 trades resulted in a price change. Figure 5.14 shows the time plot of the price series for both cases. As expected, the price series are the same.

The PCD model decomposes the joint distribution of $\left( \Delta t _ { i } , N _ { i } , D _ { i } , S _ { i } \right)$ given $F _ { i - 1 }$ as

$$
\begin{array}{l} f \left(\Delta t _ {i}, N _ {i}, D _ {i}, S _ {i} \mid F _ {i - 1}\right) \\ = f \left(S _ {i} \mid D _ {i}, N _ {i}, \Delta t _ {i}, F _ {i - 1}\right) f \left(D _ {i} \mid N _ {i}, \Delta t _ {i}, F _ {i - 1}\right) f \left(N _ {i} \mid \Delta t _ {i}, F _ {i - 1}\right) f \left(\Delta t _ {i} \mid F _ {i - 1}\right). \tag {5.47} \\ \end{array}
$$

This partition enables us to specify suitable econometric models for the conditional distributions and, hence, to simplify the modeling task. There are many ways to specify models for the conditional distributions. A proper specification might depend on the asset under study. Here we employ the specifications used by McCulloch and Tsay (2000), who use generalized linear models for the discretevalued variables and a time series model for the continuous variable $\ln ( \Delta t _ { i } )$ .

For the time duration between price changes, we use the model

$$
\ln \left(\Delta t _ {i}\right) = \beta_ {0} + \beta_ {1} \ln \left(\Delta t _ {i - 1}\right) + \beta_ {2} S _ {i - 1} + \sigma \epsilon_ {i}, \tag {5.48}
$$

![](images/819e6f622f7c8f9d5f944ef9312bfe70c2b38c10fa398435b6bf77703519ccfe.jpg)  
(a) All transactions

![](images/10b06f1f10b5311523aa768f04aa645bd06fa77b5b8040b83c0766ae711cdcb6.jpg)  
(b) Transactions with a price change   
Figure 5.14. Time plots of the intraday transaction prices of IBM stock on November 21, 1990: (a) all transactions and (b) transactions that resulted in a price change.

where $\sigma$ is a positive number and $\left\{ \epsilon _ { i } \right\}$ is a sequence of iid $N ( 0 , 1 )$ random variables. This is a multiple linear regression model with lagged variables. Other explanatory variables can be added if necessary. The log transformation is used to ensure the positiveness of time duration.

The conditional model for $N _ { i }$ is further partitioned into two parts because empirical data suggest a concentration of $N _ { i }$ at 0. The first part of the model for $N _ { i }$ is the logit model

$$
p \left(N _ {i} = 0 \mid \Delta t _ {i}, F _ {i - 1}\right) = \operatorname {l o g i t} \left[ \alpha_ {0} + \alpha_ {1} \ln \left(\Delta t _ {i}\right) \right], \tag {5.49}
$$

where $\mathrm { l o g i t } ( x ) = \exp ( x ) / [ 1 + \exp ( x ) ]$ , whereas the second part of the model is

$$
N _ {i} \left| \left(N _ {i} > 0, \Delta t _ {i}, F _ {i - 1}\right) \sim 1 + g \left(\lambda_ {i}\right), \quad \lambda_ {i} = \frac {\exp \left[ \gamma_ {0} + \gamma_ {1} \ln \left(\Delta t _ {i}\right) \right]}{1 + \exp \left[ \gamma_ {0} + \gamma_ {1} \ln \left(\Delta t _ {i}\right) \right]}, \right. \tag {5.50}
$$

where $\sim$ means “is distributed as,” and $g ( \lambda )$ denotes a geometric distribution with parameter $\lambda$ , which is in the interval (0, 1).

The model for direction $D _ { i }$ is

$$
D _ {i} \left| \left(N _ {i}, \Delta t _ {i}, F _ {i - 1}\right) = \operatorname {s i g n} \left(\mu_ {i} + \sigma_ {i} \epsilon\right), \right. \tag {5.51}
$$

where $\epsilon$ is a $N ( 0 , 1 )$ random variable, and

$$
\mu_ {i} = \omega_ {0} + \omega_ {1} D _ {i - 1} + \omega_ {2} \ln (\Delta t _ {i}),
$$

$$
\ln (\sigma_ {i}) = \beta \left| \sum_ {j = 1} ^ {4} D _ {i - j} \right| = \beta | D _ {i - 1} + D _ {i - 2} + D _ {i - 3} + D _ {i - 4} |.
$$

In other words, $D _ { i }$ is governed by the sign of a normal random variable with mean $\mu _ { i }$ and variance $\sigma _ { i } ^ { 2 }$ . A special characteristic of the prior model is the function for $\ln ( \sigma _ { i } )$ . For intraday transactions, a key feature is the price reversal between consecutive price changes. This feature is modeled by the dependence of $D _ { i }$ on $D _ { i - 1 }$ in the mean equation with a negative $\omega _ { 1 }$ parameter. However, there exists an occasional local trend in the price movement. The previous variance equation allows for such a local trend by increasing the uncertainty in the direction of price movement when the past data showed evidence of a local trend. For a normal distribution with a fixed mean, increasing its variance makes a random draw have the same chance to be positive and negative. This in turn increases the chance for a sequence of all positive or all negative draws. Such a sequence produces a local trend in price movement.

To allow for different dynamics between positive and negative price movements, we use different models for the size of a price change. Specifically, we have

$$
S _ {i} \left| \left(D _ {i} = - 1, N _ {i}, \Delta t _ {i}, F _ {i - 1}\right) \sim p \left(\lambda_ {d, i}\right) + 1, \quad \text {w i t h} \right.
$$

$$
\ln \left(\lambda_ {d, i}\right) = \eta_ {d, 0} + \eta_ {d, 1} N _ {i} + \eta_ {d, 2} \ln \left(\Delta t _ {i}\right) + \eta_ {d, 3} S _ {i - 1} \tag {5.52}
$$

$$
S _ {i} \left| \left(D _ {i} = 1, N _ {i}, \Delta t _ {i}, F _ {i - 1}\right) \sim p \left(\lambda_ {u, i}\right) + 1, \quad \text {w i t h} \right.
$$

$$
\ln \left(\lambda_ {u, i}\right) = \eta_ {u, 0} + \eta_ {u, 1} N _ {i} + \eta_ {u, 2} \ln \left(\Delta t _ {i}\right) + \eta_ {u, 3} S _ {i - 1}, \tag {5.53}
$$

where $p ( \lambda )$ denotes a Poisson distribution with parameter λ, and 1 is added to the size because the minimum size is 1 tick when there is a price change.

The specified models in Eqs. (5.48)−(5.53) can be estimated jointly by either the maximum likelihood method or the Markov chain Monte Carlo methods. Based on Eq. (5.47), the models consist of six conditional models that can be estimated separately.

Example 5.5. Consider the intraday transactions of IBM stock on November 21, 1990. There are 194 price changes within normal trading hours. Figure 5.15 shows the histograms of $\ln ( \Delta t _ { i } )$ , $N _ { i }$ , Di , and $S _ { i }$ . The data for $D _ { i }$ are about equally distributed between “upward” and “downward” movements. Only a few transactions resulted in a price change of more than 1 tick; as a matter of fact, there were seven changes with two ticks and one change with three ticks. Using Markov chain Monte Carlo (MCMC) methods (see Chapter 12), we obtained the following models for the data. The reported estimates and their standard deviations are the posterior means and standard deviations of MCMC draws with 9500 iterations. The model for the time duration between price changes is

$$
\ln (\Delta t _ {i}) = 4. 0 2 3 + 0. 0 3 2 \ln (\Delta t _ {i - 1}) - 0. 0 2 5 S _ {i - 1} + 1. 4 0 3 \epsilon_ {i},
$$

![](images/10fe31c93349337505d4cf1a76b380032a954b29954a7d6418805e4bb78ad2f1.jpg)  
(a)

![](images/bbfae1580c7eac57e7cccd1eff4c741276ccd25776c002fe7d0841bbbeb288c4.jpg)  
(b)

![](images/ea6d35ea313d51d249ae4f7ccfed478642a2c7ef0d5eee78ead5d8f22cee5356.jpg)  
(c)

![](images/8282809afaf26635903ef060e5861eba69fbfc92e453fdd77d791e0eb26c3cf1.jpg)  
(d)   
Figure 5.15. Histograms of intraday transactions data for IBM stock on November 21, 1990: (a) log durations between price changes, (b) direction of price movement, (c) size of price change measured in ticks, and (d) number of trades without a price change.

where standard deviations of the coefficients are 0.415, 0.073, 0.384, and 0.073, respectively. The fitted model indicates that there was no dynamic dependence in the time duration. For the $N _ { i }$ variable, we have

$$
\Pr \left(N _ {i} > 0 \mid \Delta t _ {i}, F _ {i - 1}\right) = \operatorname {l o g i t} \left[ - 0. 6 3 7 + 1. 7 4 0 \ln \left(\Delta t _ {i}\right) \right],
$$

where standard deviations of the estimates are 0.238 and 0.248, respectively. Thus, as expected, the number of trades with no price change in the time interval $( t _ { i - 1 } , t _ { i } )$ depends positively on the length of the interval. The magnitude of $N _ { i }$ when it is positive is

$$
N _ {i} | (N _ {i} > 0, \Delta t _ {i}, F _ {i - 1}) \sim 1 + g (\lambda_ {i}), \quad \lambda_ {i} = \frac {\exp [ 0 . 1 7 8 - 0 . 9 1 0 \ln (\Delta t _ {i}) ]}{1 + \exp [ 0 . 1 7 8 - 0 . 9 1 0 \ln (\Delta t _ {i}) ]},
$$

where standard deviations of the estimates are 0.246 and 0.138, respectively. The negative and significant coefficient of $\ln ( \Delta t _ { i } )$ means that $N _ { i }$ is positively related to the length of the duration $\Delta t _ { i }$ because a large $\ln ( \Delta t _ { i } )$ implies a small $\lambda _ { i }$ , which in turn implies higher probabilities for larger $N _ { i }$ ; see the geometric distribution in Eq. (5.27).

The fitted model for $D _ { i }$ is

$$
\mu_ {i} = 0. 0 4 9 - 0. 8 4 0 D _ {i - 1} - 0. 0 0 4 \ln (\Delta t _ {i}),
$$

$$
\ln \left(\sigma_ {i}\right) = 0. 2 4 4 \left| D _ {i - 1} + D _ {i - 2} + D _ {i - 3} + D _ {i - 4} \right|,
$$

where standard deviations of the parameters in the mean equation are 0.129, 0.132, and 0.082, respectively, whereas the standard deviation for the parameter in the variance equation is 0.182. The price reversal is clearly shown by the highly significant negative coefficient of $D _ { i - 1 }$ . The marginally significant parameter in the variance equation is exactly as expected. Finally, the fitted models for the size of a price change are

$$
\ln \left(\lambda_ {d, i}\right) = 1. 0 2 4 - 0. 3 2 7 N _ {i} + 0. 4 1 2 \ln \left(\Delta t _ {i}\right) - 4. 4 7 4 S _ {i - 1},
$$

$$
\ln \left(\lambda_ {u, i}\right) = - 3. 6 8 3 - 1. 5 4 2 N _ {i} + 0. 4 1 9 \ln \left(\Delta t _ {i}\right) + 0. 9 2 1 S _ {i - 1},
$$

where standard deviations of the parameters for the “down size” are 3.350, 0.319, 0.599, and 3.188, respectively, whereas those for the “up size” are 1.734, 0.976, 0.453, and 1.459. The interesting estimates of the prior two equations are the negative estimates of the coefficient of $N _ { i }$ . A large $N _ { i }$ means there were more transactions in the time interval $( t _ { i - 1 } , t _ { i } )$ with no price change. This can be taken as evidence of no new information available in the time interval $( t _ { i - 1 } , t _ { i } )$ . Consequently, the size for the price change at $t _ { i }$ should be small. A small $\lambda _ { u , i }$ or $\lambda _ { d , i }$ for a Poisson distribution gives precisely that.

In summary, granted that a sample of 194 observations in a given day may not contain sufficient information about the trading dynamics of IBM stock, but the fitted models appear to provide some sensible results. McCulloch and Tsay (2000) extend the PCD model to a hierarchical framework to handle all the data of the 63 trading days between November 1, 1990 and January 31, 1991. Many of the parameter estimates become significant in this extended sample, which has more than 19,000 observations. For example, the overall estimate of the coefficient of $\ln ( \Delta t _ { i - 1 } )$ in the model for time duration ranges from 0.04 to 0.1, which is small, but significant.

Finally, using transactions data to test microstructure theory often requires a careful specification of the variables used. It also requires a deep understanding of the way by which the market operates and the data are collected. However, ideas of the econometric models discussed in this chapter are useful and widely applicable in analysis of high-frequency data.

# APPENDIX A: REVIEW OF SOME PROBABILITY DISTRIBUTIONS

# Exponential Distribution

A random variable $X$ has an exponential distribution with parameter $\beta > 0$ if its probability density function (pdf) is given by

$$
f (x | \beta) = \left\{ \begin{array}{l l} \frac {1}{\beta} e ^ {- x / \beta} & \text {i f} x \geq 0, \\ 0 & \text {o t h e r w i s e}. \end{array} \right.
$$

Denoting such a distribution by $X \sim \exp ( \beta )$ , we have $E ( X ) = \beta$ and $\operatorname { V a r } ( X ) = \beta ^ { 2 }$ The cumulative distribution function (CDF) of $X$ is

$$
F (x | \beta) = \left\{ \begin{array}{l l} 0 & \text {i f} x <   0, \\ 1 - e ^ {- x / \beta} & \text {i f} x \geq 0. \end{array} \right.
$$

When $\beta = 1$ , $X$ is said to have a standard exponential distribution.

# Gamma Function

For $\kappa > 0$ , the gamma function $\Gamma ( \kappa )$ is defined by

$$
\Gamma (\kappa) = \int_ {0} ^ {\infty} x ^ {\kappa - 1} e ^ {- x} d x.
$$

The most important properties of the gamma function are:

1. For any $\kappa > 1$ , $\Gamma ( \kappa ) = ( \kappa - 1 ) \Gamma ( \kappa - 1 )$ .   
2. For any positive integer $m$ , $\Gamma ( m ) = ( m - 1 ) !$   
3. $\Gamma ( { \textstyle { \frac { 1 } { 2 } } } ) = { \sqrt { \pi } }$

The integration

$$
\Gamma (y | \kappa) = \int_ {0} ^ {y} x ^ {\kappa - 1} e ^ {- x} d x, \quad y > 0
$$

is an incomplete gamma function. Its values have been tabulated in the literature. Computer programs are now available to evaluate the incomplete gamma function.

# Gamma Distribution

A random variable $X$ has a gamma distribution with parameter $\kappa$ and $\beta$ $\mathbf { \Phi } _ { K } > 0$ $\beta > 0$ ) if its pdf is given by

$$
f (x | \kappa , \beta) = \left\{ \begin{array}{l l} \frac {1}{\beta^ {\kappa} \Gamma (\kappa)} x ^ {\kappa - 1} e ^ {- x / \beta} & \text {i f} x \geq 0, \\ 0 & \text {o t h e r w i s e}. \end{array} \right.
$$

By changing variable $y = x / \beta$ , one can easily obtain the moments of $X$ :

$$
\begin{array}{l} E (X ^ {m}) = \int_ {0} ^ {\infty} x ^ {m} f (x | \kappa , \beta) d x = \frac {1}{\beta^ {\kappa} \Gamma (\kappa)} \int_ {0} ^ {\infty} x ^ {\kappa + m - 1} e ^ {- x / \beta} d x \\ = \frac {\beta^ {m}}{\Gamma (\kappa)} \int_ {0} ^ {\infty} y ^ {\kappa + m - 1} e ^ {- y} d y = \frac {\beta^ {m} \Gamma (\kappa + m)}{\Gamma (\kappa)}. \\ \end{array}
$$

In particular, the mean and variance of $X$ are $E ( X ) = \kappa \beta$ and $\operatorname { V a r } ( X ) = \kappa \beta ^ { 2 }$ . When $\beta = 1$ , the distribution is called a standard gamma distribution with parameter $\kappa$

We use the notation $G \sim \mathrm { g a m m a } ( \kappa )$ to denote that $G$ follows a standard gamma distribution with parameter $\kappa$ . The moments of $G$ are

$$
E \left(G ^ {m}\right) = \frac {\Gamma (\kappa + m)}{\Gamma (\kappa)}, \quad m > 0. \tag {5.54}
$$

# Weibull Distribution

A random variable $X$ has a Weibull distribution with parameters $\alpha$ and $\beta$ $( \alpha > 0$ , $\beta > 0$ ) if its pdf is given by

$$
f (x | \alpha , \beta) = \left\{ \begin{array}{l l} \frac {\alpha}{\beta^ {\alpha}} x ^ {\alpha - 1} e ^ {- (x / \beta) ^ {\alpha}} & \text {i f} x \geq 0, \\ 0 & \text {i f} x <   0, \end{array} \right.
$$

where $\beta$ and $\alpha$ are the scale and shape parameters of the distribution. The mean and variance of $X$ are

$$
E (X) = \beta \Gamma \left(1 + \frac {1}{\alpha}\right), \quad \operatorname {V a r} (X) = \beta^ {2} \left\{\Gamma \left(1 + \frac {2}{\alpha}\right) - \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) \right] ^ {2} \right\},
$$

and the CDF of $X$ is

$$
F (x | \alpha , \beta) = \left\{ \begin{array}{l l} 0 & \text {i f} x <   0, \\ 1 - e ^ {- (x / \beta) ^ {\alpha}} & \text {i f} x \geq 0. \end{array} \right.
$$

When $\alpha = 1$ , the Weibull distribution reduces to an exponential distribution.

Define $Y = X / [ \beta \Gamma ( 1 + 1 / \alpha ) ]$ . We have $E ( Y ) = 1$ and the pdf of $Y$ is

$$
f (y | \alpha) = \left\{ \begin{array}{l l} \alpha \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) \right] ^ {\alpha} y ^ {\alpha - 1} \exp \left\{- \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) y \right] ^ {\alpha} \right\} & \text {i f} y \geq 0, \\ 0 & \text {o t h e r w i s e}, \end{array} \right. \tag {5.55}
$$

where the scale parameter $\beta$ disappears due to standardization. The CDF of the standardized Weibull distribution is

$$
F (y | \alpha) = \left\{ \begin{array}{l l} 0 & \text {i f} y <   0, \\ 1 - \exp \left\{- \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) y \right] ^ {\alpha} \right\} & \text {i f} y > 0, \end{array} \right.
$$

and we have $E ( Y ) = 1$ and $\mathrm { V a r } ( Y ) = \Gamma ( 1 + 2 / \alpha ) / [ \Gamma ( 1 + 1 / \alpha ) ] ^ { 2 } - 1$ . For a duration model with Weibull innovations, the pdf in Eq. (5.55) is used in the maximum likelihood estimation.

# Generalized Gamma Distribution

A random variable $X$ has a generalized gamma distribution with parameter α, β, κ ( $( \alpha > 0$ , $\beta > 0$ , and $\kappa > 0$ ) if its pdf is given by

$$
f (x | \alpha , \beta , \kappa) = \left\{ \begin{array}{l l} \frac {\alpha x ^ {\kappa \alpha - 1}}{\beta^ {\kappa \alpha} \Gamma (\kappa)} \exp \left[ - \left(\frac {x}{\beta}\right) ^ {\alpha} \right] & \text {i f} x \geq 0, \\ 0 & \text {o t h e r w i s e}, \end{array} \right.
$$

where $\beta$ is a scale parameter, and $\alpha$ and $\kappa$ are shape parameters. This distribution can be written as

$$
G = \left(\frac {X}{\beta}\right) ^ {\alpha},
$$

where $G$ is a standard gamma random variable with parameter $\kappa$ . The pdf of $X$ can be obtained from that of $G$ by the technique of changing variables. Similarly, the moments of $X$ can be obtained from that of $G$ in Eq. (5.54) by

$$
E (X ^ {m}) = E [ (\beta G ^ {1 / \alpha}) ^ {m} ] = \beta^ {m} E (G ^ {m / \alpha}) = \beta^ {m} \frac {\Gamma (\kappa + m / \alpha)}{\Gamma (\kappa)} = \frac {\beta^ {m} \Gamma (\kappa + m / \alpha)}{\Gamma (\kappa)}.
$$

When $\kappa = 1$ , the generalized gamma distribution reduces to that of a Weibull distribution. Thus, the exponential and Weibull distributions are special cases of the generalized gamma distribution.

The expectation of a generalized gamma distribution is $E ( X ) = \beta \Gamma ( \kappa + 1 / \alpha ) /$ $\Gamma ( \kappa )$ . In duration models, we need a distribution with unit expectation. Therefore, defining a random variable $Y = \lambda X / \beta$ , where $\lambda = \Gamma ( \kappa ) / \Gamma ( \kappa + 1 / \alpha )$ , we have $E ( Y ) = 1$ and the pdf of $Y$ is

$$
f (y | \alpha , \kappa) = \left\{ \begin{array}{l l} \frac {\alpha y ^ {\kappa \alpha - 1}}{\lambda^ {\kappa \alpha} \Gamma (\kappa)} \exp \left[ - \left(\frac {y}{\lambda}\right) ^ {\alpha} \right] & \text {i f} y > 0, \\ 0 & \text {o t h e r w i s e}, \end{array} \right. \tag {5.56}
$$

where again the scale parameter $\beta$ disappears and $\lambda = \Gamma ( \kappa ) / \Gamma ( \kappa + 1 / \alpha )$ .

# APPENDIX B: HAZARD FUNCTION

A useful concept in modeling duration is the hazard function implied by a distribution function. For a random variable $X$ , the survival function is defined as

$$
S (x) \equiv P (X > x) = 1 - P (X \leq x) = 1 - \operatorname {C D F} (x), \quad x > 0,
$$

which gives the probability that a subject, which follows the distribution of $X$ survives at the time $x$ . The hazard function (or intensity function) of $X$ is then defined by

$$
h (x) = \frac {f (x)}{S (x)}, \tag {5.57}
$$

where $f ( . )$ and $S ( . )$ are the pdf and survival function of $X$ , respectively.

Example 5.6. For the Weibull distribution with parameters $\alpha$ and $\beta$ , the survival function and hazard function are

$$
S (x | \alpha , \beta) = \exp \left[ - \left(\frac {x}{\beta}\right) ^ {\alpha} \right], \quad h (x | \alpha , \beta) = \frac {\alpha}{\beta^ {\alpha}} x ^ {\alpha - 1}, \quad x > 0.
$$

In particular, when $\alpha = 1$ , we have $h ( x | \beta ) = 1 / \beta$ . Therefore, for an exponential distribution, the hazard function is constant. For a Weibull distribution, the hazard is a monotone function. If $\alpha > 1$ , then the hazard function is monotonously increasing. If $\alpha < 1$ , the hazard function is monotonously decreasing. For the generalized gamma distribution, the survival function and, hence, the hazard function involve the incomplete gamma function. Yet the hazard function may exhibit various patterns, including U shape or inverted U shape. Thus, the generalized gamma distribution provides a flexible approach to modeling the duration of stock transactions.

For the standardized Weibull distribution, the survival and hazard functions are

$$
S (y | \alpha) = \exp \left\{- \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) y \right] ^ {\alpha} \right\}, h (y | \alpha) = \alpha \left[ \Gamma \left(1 + \frac {1}{\alpha}\right) \right] ^ {\alpha} y ^ {\alpha - 1}, y > 0.
$$

# APPENDIX C: SOME RATS PROGRAMS FOR DURATION MODELS

The data used are adjusted time durations of intraday transactions of IBM stock from November 1 to November 9, 1990. The file name is ibm1to5.txt and it has 3534 observations.

# Program for Estimating a WACD(1,1) Model

```txt
all 0 3534:1
open data ibmlto5.txt
data(org=obs) / x r1
set psi = 1.0
nonlin a0 a1 b1 al
frml gvar = a0+a1*x(t-1)+b1*psi(t-1)
frml gma = %LNGAMMA(1.0+1.0/al)
frml gln =al*gma(t)+log(al)-log(x(t)) $
	+al*log(x(t)/(psi(t)=gvar(t)))-(exp(gma(t))*x(t)/psi(t))**
smpl 2 3534
compute a0 = 0.2, a1 = 0.1, b1 = 0.1, al = 0.8
maximize(method=bhhh,recursive,iterations=150) gln
set fv = gvar(t)
set resid = x(t)/fv(t)
set residsq = resid(t)*resid(t)
cor(qstats,number=20, span=10) resid
cor(qstats,number=20, span=10) residsq 
```

Program for Estimating a GACD(1,1) Model   
Program for Estimating a TAR-WACD(1,1) Model   
```txt
all 0 3534:1  
open data ibm1to5.txt  
data(org=obs) / x r1  
set psi = 1.0  
nonlin a0 a1 b1 al ka  
frml cv = a0+a1*x(t-1)+b1*psi(t-1)  
frml gma = %LNGAMMA(ka)  
frml lam = exp(gma(t)) / exp(%LNGAMMA(ka+(1.0/al)))  
frml xlam = x(t)/(lam(t)*(psi(t)=cv(t)))  
frml gln = -gma(t)+log(al/x(t))+ka*al*log(xlam(t))- (xlam(t))**al  
spl2 3534  
compute a0 = 0.238, al = 0.075, b1 = 0.857, al = 0.5, ka = 4.0  
nlpar(criterion=value,cvcrit=0.00001)  
maximize(method=bhhh, recursive, iterations=150) gln  
set fv = cv(t)  
set resid = x(t)/fv(t)  
set residsq = resid(t)*resid(t)  
cor(qstats,number=20, span=10) resid  
cor(qstats,number=20, span=10) residsq 
```

The threshold 3.79 is prespecified.

```matlab
all 0 3534:1
open data ibm1to5.txt
data(org=obs) / x rt
set psi = 1.0
nonlin a1 a2 al b0 b2 bl
frml u = ((x(t-1)-3.79)/abs(x(t-1)-3.79)+1.0)/2.0
frml cp1 = al*x(t-1)+a2*psi(t-1)
frml gma1 = %LNGAMMA(1.0+1.0/al)
frml cp2 = b0+b2*psi(t-1)
frml gma2 = %LNGAMMA(1.0+1.0/bl)
frml cp = cp1(t)*(1-u(t))+cp2(t)*u(t)
frml gln1 = al*gma1(t)+log(al)-log(x(t)) $
	+al*log(x(t)/(psi(t)=cp(t)))-(exp(gma1(t))*x(t)/psi(t))**
frml gln2 = bl*gma2(t)+log(bl)-log(x(t)) $
	+bl*log(x(t)/(psi(t)=cp(t)))-(exp(gma2(t))*x(t)/psi(t))**
frml gln = gln1(t)*(1-u(t))+gln2(t)*u(t)
mpl 2 3534
compute a1 = 0.2, a2 = 0.85, al = 0.9
compute b0 = 1.8, b2 = 0.5, bl = 0.8
maximize(method=bhhh,recursive,iterations=150) gln
set fv = cp(t)
set resid = x(t)/fv(t)
set residsq = resid(t)*resid(t)
cor(qstats,number=20, span=10) resid
cor(qstats,number=20, span=10) residsq 
```

# EXERCISES

5.1. Let $r _ { t }$ be the log return of an asset at time t. Assume that $\{ r _ { t } \}$ is a Gaussian white noise series with mean 0.05 and variance 1.5. Suppose that the probability of a trade at each time point is $40 \%$ and is independent of $r _ { t }$ . Denote the observed return by $r _ { t } ^ { o }$ . Is $r _ { t } ^ { o }$ serially correlated? If yes, calculate the first three lags of autocorrelations of $r _ { t } ^ { o }$ .   
5.2. Let $P _ { t }$ be the observed market price of an asset, which is related to the fundamental value of the asset $P _ { t } ^ { * }$ via Eq. (5.9). Assume that $\Delta P _ { t } ^ { * } = P _ { t } ^ { * } - P _ { t - 1 } ^ { * }$ forms a Gaussian white noise series with mean zero and variance 1.0. Suppose that the bid–ask spread is two ticks. What is the lag-1 autocorrelation of the price change series $\Delta P _ { t } = P _ { t } - P _ { t - 1 }$ when the tick size is $\$ 1/8?$ What is the lag-1 autocorrelation of the price change when the tick size is $\$ 1/16?$   
5.3. The file ibm-d2-dur.txt contains the adjusted durations between trades of IBM stock on November 2, 1990. The file has three columns consisting of day, time of trade measured in seconds from midnight, and adjusted durations.

(a) Build an EACD model for the adjusted duration and check the fitted model.   
(b) Build a WACD model for the adjusted duration and check the fitted model.   
(c) Build a GACD model for the adjusted duration and check the fitted model.   
(d) Compare the prior three duration models.

5.4. The file mmm9912-dtp.txt contains the transactions data of the stock of 3M Company in December 1999. There are three columns: day of the month, time of transaction in seconds from midnight, and transaction price. Transactions that occurred after 4:00 pm Eastern time are excluded.

(a) Is there a diurnal pattern in 3M stock trading? You may construct a time series $n _ { t }$ , which denotes the number of trades in a 5-minute time interval to answer this question.   
(b) Use the price series to confirm the existence of a bid–ask bounce in intraday trading of 3M stock.   
(c) Tabulate the frequencies of price change in multiples of tick size $\$ 1/16$ You may combine changes with 5 ticks or more into a category and those with $- 5$ ticks or beyond into another category.

5.5. Consider again the transactions data of 3M stock in December 1999.

(a) Use the data to construct an intraday 5-minute log return series. Use the simple average of all transaction prices within a 5-minute interval as the stock price for the interval. Is the series serially correlated? You may use Ljung–Box statistics to test the hypothesis with the first 10 lags of the sample autocorrelation function.

(b) There are seventy-seven 5-minute returns in a normal trading day. Some researchers suggest that the sum of squares of the intraday 5-minute returns can be used as a measure of daily volatility. Apply this approach and calculate the daily volatility of the log return of 3M stock in December 1999. Discuss the validity of such a procedure to estimate daily volatility.

5.6. The file mmm9912-adur.txt contains an adjusted intraday trading duration of 3M stock in December 1999. There are thirty-nine 10-minute time intervals in a trading day. Let $d _ { i }$ be the average of all log durations for the ith 10- minute interval across all trading days in December 1999. Define an adjusted duration as $t _ { j } / \exp ( d _ { i } )$ , where $j$ is in the ith 10-minute interval. Note that more sophisticated methods can be used to adjust the diurnal pattern of trading duration. Here we simply use a local average.

(a) Is there a diurnal pattern in the adjusted duration series? Why?   
(b) Build a duration model for the adjusted series using exponential innovations. Check the fitted model.   
(c) Build a duration model for the adjusted series using Weibull innovations. Check the fitted model.   
(d) Build a duration model for the adjusted series using generalized gamma innovations. Check the fitted model.   
(e) Compare and comment on the three duration models built before.

5.7. To gain experience in analyzing high-frequency financial data, consider the trade data of GE stock from December 1 to December 5, 2003 in the file taq-t-ge-dec5.txt. The file has four major columns; day, time (hour, minute, second), price, and volume. Ignore all transactions outside normal trading hours (9:30 am to $4 { : } 0 0 \ \mathrm { p m }$ Eastern time). Construct a time series of the number of trades in an intraday 5-minute time interval. Is there any diurnal pattern in the constructed series? You can simply compute the sample ACF of the series to answer this question. The number of trades is in the file taq-ge-dec5-nt.txt.   
5.8. Again, consider the high-frequency data of GE stock from December 1 to December 5, 2003 and ignore the transactions outside normal trading hours. Construct an intraday 5-minute return series. Note that the price of the stock in a 5-minute interval (e.g., 9:30 and 9:35 am) is the last transaction price within the time interval. For simplicity, ignore overnight returns. Are there serial correlations in the 5-minute return series? Use 10 lags of the ACF and $5 \%$ level to perform the test. See file taq-ge-dec5-5m.txt.   
5.9. Consider the same problem as in Exercise 5.8, but use 10-minute time intervals. See file taq-ge-dec5-10m.txt.   
5.10. Again, consider the high-frequency data of GE stock and ignore transactions outside normal trading hours. Compute the percentage of consecutive transactions without price change in the sample.

# REFERENCES

Box, G. E. P. and Cox, D. R. (1964). An analysis of transformations. Journal of the Royal Statistical Society Series B 26: 211–243.   
Campbell, J. Y., Lo, A. W., and MacKinlay, A. C. (1997). The Econometrics of Financial Markets. Princeton University Press, Princeton, NJ.   
Cho, D., Russell, J. R., Tiao, G. C., and Tsay, R. S. (2003). The magnet effect of price limits: Evidence from high frequency data on Taiwan stock exchange. Journal of Empirical Finance 10: 133–168.   
Engle, R. F. and Russell, J. R. (1998). Autoregressive conditional duration: a new model for irregularly spaced transaction data. Econometrica 66: 1127–1162.   
Ghysels, E. (2000). Some econometric recipes for high-frequency data cooking. Journal of Business and Economic Statistics 18: 154–163.   
Hasbrouck, J. (1992). Using the TORQ Database. Stern School of Business, New York University, New York.   
Hasbrouck, J. (1999). The dynamics of discrete bid and ask quotes. Journal of Finance 54: 2109–2142.   
Hauseman, J., Lo, A., and MacKinlay, C. (1992). An ordered probit analysis of transaction stock prices. Journal of Financial Economics 31: 319–379.   
Lo, A. and MacKinlay, A. C. (1990). An econometric analysis of nonsynchronous trading. Journal of Econometrics 45: 181–212.   
McCulloch, R. E. and Tsay, R. S. (2000). Nonlinearity in high frequency data and hierarchical models. Studies in Nonlinear Dynamics and Econometrics 5: 1–17.   
Roll, R. (1984). A simple implicit measure of the effective bid–ask spread in an efficient market. Journal of Finance 39: 1127–1140.   
Rydberg, T. H. and Shephard, N. (2003). Dynamics of trade-by-trade price movements: Decomposition and models. Journal of Financial Econometrics 1: 2–25.   
Stoll, H. and Whaley, R. (1990). Stock market structure and volatility. Review of Financial Studies 3: 37–71.   
Wood, R. A. (2000). Market microstructure research databases: History and projections. Journal of Business & Economic Statistics 18: 140–145.   
Zhang, M. Y., Russell, J. R., and Tsay, R. S. (2001a). A nonlinear autoregressive conditional duration model with applications to financial transaction data. Journal of Econometrics 104: 179–207.   
Zhang, M. Y., Russell, J. R., and Tsay, R. S. (2001b). Determinants of bid and ask quotes and implications for the cost of trading. Working paper, Graduate School of Business, University of Chicago.

# Continuous-Time Models and Their Applications

The price of a financial asset evolves over time and forms a stochastic process, which is a statistical term used to describe the evolution of a random variable over time. The observed prices are a realization of the underlying stochastic process. The theory of stochastic process is the basis on which the observed prices are analyzed and statistical inference is made.

There are two types of stochastic process for modeling the price of an asset. The first type is called the discrete-time stochastic process, in which the price changes at discrete time points. All the processes discussed in the previous chapters belong to this category. For example, the daily closing price of IBM stock on the New York Stock Exchange forms a discrete-time stochastic process. Here the price changes only at the closing of a trading day. Price movements within a trading day are not necessarily relevant to the observed daily price. The second type of stochastic process is the continuous-time process, in which the price changes continuously, even though the price is only observed at discrete time points. One can think of the price as the “true value” of the stock that always exists and is time varying.

For both types of process, the price can be continuous or discrete. A continuous price can assume any positive real number, whereas a discrete price can only assume a countable number of possible values. Assume that the price of an asset is a continuous-time stochastic process. If the price is a continuous random variable, then we have a continuous-time continuous process. If the price itself is discrete, then we have a continuous-time discrete process. Similar classifications apply to discrete-time processes. The series of price change in Chapter 5 is an example of a discrete-time discrete process.

In this chapter, we treat the price of an asset as a continuous-time continuous stochastic process. Our goal is to introduce the statistical theory and tools needed to model financial assets and to price options. We begin the chapter with some terminologies of stock options used in the chapter. In Section 6.2, we provide a brief

introduction of Brownian motion, which is also known as a Wiener process. We then discuss some diffusion equations and stochastic calculus, including the wellknown Ito’s lemma. Most option pricing formulas are derived under the assumption that the price of an asset follows a diffusion equation. We use the Black–Scholes formula to demonstrate the derivation. Finally, to handle the price variations caused by rare events (e.g., a profit warning), we also study some simple diffusion models with jumps.

If the price of an asset follows a diffusion equation, then the price of an option contingent to the asset can be derived by using hedging methods. However, with jumps the market becomes incomplete and there is no perfect hedging of options. The price of an option is then valued either by using diversifiability of jump risk or defining a notion of risk and choosing a price and a hedge that minimize this risk. For basic applications of stochastic processes in derivative pricing, see Cox and Rubinstein (1985) and Hull (2002).

# 6.1 OPTIONS

A stock option is a financial contract that gives the holder the right to trade a certain number of shares of a specified common stock by a certain date for a specified price. There are two types of options. A call option gives the holder the right to buy the underlying stock; see Chapter 3 for a formal definition. A put option gives the holder the right to sell the underlying stock. The specified price in the contract is called the strike price or exercise price. The date in the contract is known as the expiration date or maturity. American options can be exercised at any time up to the expiration date. European options can be exercised only on the expiration date.

The value of a stock option depends on the value of the underlying stock. Let $K$ be the strike price and $P$ be the stock price. A call option is in-the-money when $P > K$ , at-the-money when $P = K$ , and out-of-the-money when $P < K$ . A put option is in-the-money when $P < K$ , at-the-money when $P = K$ , and out-of-themoney when $P > K$ . In general, an option is in-the-money when it would lead to a positive cash flow to the holder if it were exercised immediately. An option is out-of-the-money when it would lead to a negative cash flow to the holder if it were exercised immediately. Finally, an option is at-the-money when it would lead to zero cash flow if it were exercised immediately. Obviously, only in-the-money options are exercised in practice. For more information on options, see Hull (2002).

# 6.2 SOME CONTINUOUS-TIME STOCHASTIC PROCESSES

In mathematical statistics, a continuous-time continuous stochastic process is defined on a probability space $( \Omega , F , { \bf P } )$ , where $\Omega$ is a nonempty space, $F$ is a $\sigma$ -field consisting of subsets of $\Omega$ , and $\mathbf { P }$ is a probability measure; see Chapter 1 of Billingsley (1986). The process can be written as $\{ x ( \eta , t ) \}$ , where $t$ denotes time and is continuous in $\lbrack 0 , \infty )$ . For a given t , $x ( \eta , t )$ is a real-valued continuous random variable (i.e., a mapping from $\Omega$ to the real line), and $\eta$ is an element of $\Omega$ .

For the price of an asset at time $t$ , the range of $x ( \eta , t )$ is the set of non-negative real numbers. For a given η, $\{ x ( \eta , t ) \}$ is a time series with values depending on the time t. For simplicity, we write a continuous-time stochastic process as $\{ x _ { t } \}$ with the understanding that, for a given t, $x _ { t }$ is a random variable. In the literature, some authors use $x ( t )$ instead of $x _ { t }$ to emphasize that $t$ is continuous. However, we use the same notation $x _ { t }$ , but call it a continuous-time stochastic process.

# 6.2.1 The Wiener Process

In a discrete-time econometric model, we assume that the shocks form a white noise process, which is not predictable. What is the counterpart of shocks in a continuous-time model? The answer is the increments of a Wiener process, which is also known as a standard Brownian motion. There are many ways to define a Wiener process $\{ w _ { t } \}$ . We use a simple approach that focuses on the small change $\Delta w _ { t } = w _ { t + \Delta t } - w _ { t }$ associated with a small increment $\Delta t$ in time. A continuoustime stochastic process $\{ w _ { t } \}$ is a Wiener process if it satisfies

1. $\Delta w _ { t } = \epsilon \sqrt { \Delta t }$ , where $\epsilon$ is a standard normal random variable; and   
2. $\Delta w _ { t }$ is independent of $w _ { j }$ for all $j \le t$

The second condition is a Markov property saying that conditional on the present value $w _ { t }$ , any past information of the process, $w _ { j }$ with $j < t$ , is irrelevant to the future $w _ { t + \ell }$ with $\ell > 0$ . From this property, it is easily seen that for any two nonoverlapping time intervals $\Delta _ { 1 }$ and $\Delta _ { 2 }$ , the increments $w _ { t _ { 1 } + \Delta _ { 1 } } - w _ { t _ { 1 } }$ and $w _ { t _ { 2 } + \Delta _ { 2 } } - w _ { t _ { 2 } }$ are independent. In finance, this Markov property is related to a weak form of efficient market.

From the first condition, $\Delta w _ { t }$ is normally distributed with mean zero and variance $\Delta t$ . That is, $\Delta w _ { t } \sim N ( 0 , \Delta t )$ , where $\sim$ denotes probability distribution. Consider next the process $w _ { t }$ . We assume that the process starts at $t = 0$ with initial value $w _ { 0 }$ , which is fixed and often set to zero. Then $w _ { t } - w _ { 0 }$ can be treated as a sum of many small increments. More specifically, define $T = t / \Delta t$ , where $\Delta t$ is a small positive increment. Then

$$
w _ {t} - w _ {0} = w _ {T \Delta t} - w _ {0} = \sum_ {i = 1} ^ {T} \Delta w _ {i} = \sum_ {i = 1} ^ {T} \epsilon_ {i} \sqrt {\Delta t},
$$

where $\Delta w _ { i } = w _ { i \Delta t } - w _ { ( i - 1 ) \Delta t }$ . Because the $\epsilon _ { i }$ are independent, we have

$$
E (w _ {t} - w _ {0}) = 0, \quad \operatorname {V a r} (w _ {t} - w _ {0}) = \sum_ {i = 1} ^ {T} \Delta t = T \Delta t = t.
$$

Thus, the increment in $w _ { t }$ from time 0 to time $t$ is normally distributed with mean zero and variance t. To put it formally, for a Wiener process $w _ { t }$ , we have

![](images/5a7090b2913dc2993904e1482a7aa7a7e31675bf8099f6d5d2a1f7a8f8311bb9.jpg)

![](images/ff901ae5a3970f98645e8b65b92ede0644cb9c9bd29021085c79bfd1446998bb.jpg)

![](images/5f92c31bea93c8ee8b9152c097cfe94ae0abde06312c8f47e2221ebe2c09568a.jpg)

![](images/978283e76a55ff1a61d75ec85087798c279d441eea9bf47d787918a46b27edae.jpg)  
Figure 6.1. Four simulated Wiener processes.

that $w _ { t } - w _ { 0 } \sim N ( 0 , t )$ . This says that the variance of a Wiener process increases linearly with the length of time interval.

Figure 6.1 shows four simulated Wiener processes on the unit time interval [0, 1]. They are obtained by using a simple version of Donsker’s theorem in the statistical literature with $n = 3 0 0 0$ ; see Donsker (1951) or Billingsley (1968). The four plots start with $w _ { 0 } = 0$ but drift apart as time increases, illustrating that the variance of a Wiener process increases with time. A simple time transformation from [0, 1) to $\lbrack 0 , \infty )$ can be used to obtain simulated Wiener processes for $t \in [ 0 , \infty )$ .

# Donsker’s Theorem

For any Assume that $t \in [ 0 , 1 ]$ $\{ z _ { i } \} _ { i = 1 } ^ { n }$ =1, let [nt ] be the integer part of is a sequence of independent standard normal random variates. $n t$ . Define $\begin{array} { r } { w _ { n , t } = ( 1 / \sqrt { n } ) \sum _ { i = 1 } ^ { [ n t ] } z _ { i } } \end{array}$ Then $w _ { n , t }$ converges in distribution to a Wiener process $w _ { t }$ on [0, 1] as $n$ goes to infinity.

# S-Plus Commands for Generating a Wiener Process

```txt
n = 3000  
epsilon = rnorm(n, 0, 1)  
w = cumsum(epsi) / sqrt(n)  
plot(w, type='1') 
```

Remark. A formal definition of a Brownian motion $w _ { t }$ on a probability space $( \Omega , F , { \bf P } )$ is that it is a real-valued, continuous stochastic process for $t \geq 0$ with independent and stationary increments. In other words, $w _ { t }$ satisfies

1. Continuity: the map from $t$ to $w _ { t }$ is continuous almost surely with respect to the probability measure P;   
2. Independent increments: if $s \leq t$ , $w _ { t } - w _ { s }$ is independent of $w _ { v }$ for all $v \leq s$ and   
3. Stationary increments: if $s \leq t$ , $w _ { t } - w _ { s }$ and $w _ { t - s } - w _ { 0 }$ have the same probability distribution.

It can be shown that the probability distribution of the increment $w _ { t } - w _ { s }$ is normal with mean $\mu ( t - s )$ and variance $\sigma ^ { 2 } ( t - s )$ . Furthermore, for any given time indexes $0 \leq t _ { 1 } < t _ { 2 } < \cdot \cdot \cdot < t _ { k }$ , the random vector $( w _ { t _ { 1 } } , w _ { t _ { 2 } } , \dots , w _ { t _ { k } } )$ follows a multivariate normal distribution. Finally, a Brownian motion is standard if $w _ { 0 } = 0$ almost surely, $\mu = 0$ , and $\sigma ^ { 2 } = 1$ . 

Remark. An important property of Brownian motions is that their paths are not differentiable almost surely. In other words, for a standard Brownian motion $w _ { t }$ , it can be shown that $d w _ { t } / d t$ does not exist for all elements of $\Omega$ except for elements in a subset $\Omega _ { 1 } \subset \Omega$ such that $\mathbf P ( \Omega _ { 1 } ) = 0$ . As a result, we cannot use the usual integration in calculus to handle integrals involving a standard Brownian motion when we consider the value of an asset over time. Another approach must be sought. This is the purpose of discussing Ito’s calculus in the next section. 

# 6.2.2 Generalized Wiener Processes

The Wiener process is a special stochastic process with zero drift and variance proportional to the length of the time interval. This means that the rate of change in expectation is zero and the rate of change in variance is 1. In practice, the mean and variance of a stochastic process can evolve over time in a more complicated manner. Hence, further generalization of a stochastic process is needed. To this end, we consider the generalized Wiener process in which the expectation has a drift rate $\mu$ and the rate of variance change is $\sigma ^ { 2 }$ . Denote such a process by $x _ { t }$ and use the notation $d y$ for a small change in the variable $y$ . Then the model for $x _ { t }$ is

$$
d x _ {t} = \mu d t + \sigma d w _ {t}, \tag {6.1}
$$

where $w _ { t }$ is a Wiener process. If we consider a discretized version of Eq. (6.1), then

$$
x _ {t} - x _ {0} = \mu t + \sigma \epsilon \sqrt {t}
$$

for increment from 0 to t. Consequently,

$$
E (x _ {t} - x _ {0}) = \mu t, \quad \operatorname {V a r} (x _ {t} - x _ {0}) = \sigma^ {2} t.
$$

The results say that the increment in $x _ { t }$ has a growth rate of $\mu$ for the expectation and a growth rate of $\sigma ^ { 2 }$ for the variance. In the literature, $\mu$ and $\sigma$ of Eq. (6.1) are referred to as the drift and volatility parameters of the generalized Wiener process $x _ { t }$ .

# 6.2.3 Ito Processes

The drift and volatility parameters of a generalized Wiener process are timeinvariant. If one further extends the model by allowing $\mu$ and $\sigma$ to be functions of the stochastic process $x _ { t }$ , then we have an Ito process. Specifically, a process $x _ { t }$ is an Ito process if it satisfies

$$
d x _ {t} = \mu \left(x _ {t}, t\right) d t + \sigma \left(x _ {t}, t\right) d w _ {t}, \tag {6.2}
$$

where $w _ { t }$ is a Wiener process. This process plays an important role in mathematical finance and can be written as

$$
x _ {t} = x _ {0} + \int_ {0} ^ {t} \mu (x _ {s}, s) d s + \int_ {0} ^ {t} \sigma (x _ {s}, s) d w _ {s},
$$

where $x _ { 0 }$ denotes the starting value of the process at time 0 and the last term on the right-hand side is a stochastic integral. Equation (6.2) is referred to as a stochastic diffusion equation with $\mu ( x _ { t } , t )$ and $\sigma ( x _ { t } , t )$ being the drift and diffusion functions, respectively.

The Wiener process is a special Ito process because it satisfies Eq. (6.2) with $\mu ( x _ { t } , t ) = 0$ and $\sigma ( x _ { t } , t ) = 1$ .

# 6.3 ITO’S LEMMA

In finance, when using continuous-time models, it is common to assume that the price of an asset is an Ito process. Therefore, to derive the price of a financial derivative, one needs to use Ito’s calculus. In this section, we briefly review Ito’s lemma by treating it as a natural extension of the differentiation in calculus. Ito’s lemma is the basis of stochastic calculus.

# 6.3.1 Review of Differentiation

Let $G ( x )$ be a differentiable function of $x$ . Using Taylor expansion, we have

$$
\Delta G \equiv G (x + \Delta x) - G (x) = \frac {\partial G}{\partial x} \Delta x + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} (\Delta x) ^ {2} + \frac {1}{6} \frac {\partial^ {3} G}{\partial x ^ {3}} (\Delta x) ^ {3} + \dots .
$$

Taking the limit as $\Delta x \to 0$ and ignoring the higher order terms of $\Delta x$ , we have

$$
d G = \frac {\partial G}{\partial x} d x.
$$

When $G$ is a function of $x$ and $y$ , we have

$$
\Delta G = \frac {\partial G}{\partial x} \Delta x + \frac {\partial G}{\partial y} \Delta y + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} (\Delta x) ^ {2} + \frac {\partial^ {2} G}{\partial x \partial y} \Delta x \Delta y + \frac {1}{2} \frac {\partial^ {2} G}{\partial y ^ {2}} (\Delta y) ^ {2} + \dots .
$$

Taking the limit as $\Delta x  0$ and $\Delta y  0$ , we have

$$
d G = \frac {\partial G}{\partial x} d x + \frac {\partial G}{\partial y} d y.
$$

# 6.3.2 Stochastic Differentiation

Turn next to the case in which $G$ is a differentiable function of $x _ { t }$ and $t$ , and $x _ { t }$ is an Ito process. The Taylor expansion becomes

$$
\Delta G = \frac {\partial G}{\partial x} \Delta x + \frac {\partial G}{\partial t} \Delta t + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} (\Delta x) ^ {2} + \frac {\partial^ {2} G}{\partial x \partial t} \Delta x \Delta t + \frac {1}{2} \frac {\partial^ {2} G}{\partial t ^ {2}} (\Delta t) ^ {2} + \dots . \tag {6.3}
$$

A discretized version of Ito process is

$$
\Delta x = \mu \Delta t + \sigma \epsilon \sqrt {\Delta t}, \tag {6.4}
$$

where, for simplicity, we omit the arguments of $\mu$ and $\sigma$ , and $\Delta x = x _ { t + \Delta t } - x _ { t }$ From Eq. (6.4), we have

$$
(\Delta x) ^ {2} = \mu^ {2} (\Delta t) ^ {2} + \sigma^ {2} \epsilon^ {2} \Delta t + 2 \mu \sigma \epsilon (\Delta t) ^ {3 / 2} = \sigma^ {2} \epsilon^ {2} \Delta t + H (\Delta t), \tag {6.5}
$$

where $H ( \Delta t )$ denotes higher order terms of $\Delta t$ . This result shows that $( \Delta x ) ^ { 2 }$ contains a term of order $\Delta t$ , which cannot be ignored when we take the limit as $\Delta t \to 0$ . However, the first term on the right-hand side of Eq. (6.5) has some nice properties:

$$
E (\sigma^ {2} \epsilon^ {2} \Delta t) = \sigma^ {2} \Delta t,
$$

$$
\operatorname {V a r} \left(\sigma^ {2} \epsilon^ {2} \Delta t\right) = E \left[ \sigma^ {4} \epsilon^ {4} (\Delta t) ^ {2} \right] - \left[ E \left(\sigma^ {2} \epsilon^ {2} \Delta t\right) \right] ^ {2} = 2 \sigma^ {4} (\Delta t) ^ {2},
$$

where we use $E ( \epsilon ^ { 4 } ) = 3$ for a standard normal random variable. These two properties show that $\sigma ^ { 2 } \epsilon ^ { 2 } \Delta t$ converges to a nonstochastic quantity $\sigma ^ { 2 } \Delta t$ as $\Delta t \to 0$ . Consequently, from Eq. (6.5), we have

$$
(\Delta x) ^ {2} \rightarrow \sigma^ {2} d t \quad \text {a s} \quad \Delta t \rightarrow 0.
$$

Plugging the prior result into Eq. (6.3) and using Ito’s equation of $x _ { t }$ in Eq. (6.2), we obtain

$$
\begin{array}{l} d G = \frac {\partial G}{\partial x} d x + \frac {\partial G}{\partial t} d t + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} \sigma^ {2} d t \\ = \left(\frac {\partial G}{\partial x} \mu + \frac {\partial G}{\partial t} + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} \sigma^ {2}\right) d t + \frac {\partial G}{\partial x} \sigma d w _ {t}, \\ \end{array}
$$

which is the well-known Ito’s lemma in stochastic calculus.

Recall that we suppressed the argument $( x _ { t } , t )$ from the drift and volatility terms $\mu$ and $\sigma$ in the derivation of Ito’s lemma. To avoid any possible confusion in the future, we restate the lemma as follows.

# Ito’s Lemma

Assume that $x _ { t }$ is a continuous-time stochastic process satisfying

$$
d x _ {t} = \mu \left(x _ {t}, t\right) d t + \sigma \left(x _ {t}, t\right) d w _ {t},
$$

where $w _ { t }$ is a Wiener process. Furthermore, $G ( x _ { t } , t )$ is a differentiable function of $x _ { t }$ and $t$ . Then,

$$
d G = \left[ \frac {\partial G}{\partial x} \mu \left(x _ {t}, t\right) + \frac {\partial G}{\partial t} + \frac {1}{2} \frac {\partial^ {2} G}{\partial x ^ {2}} \sigma^ {2} \left(x _ {t}, t\right) \right] d t + \frac {\partial G}{\partial x} \sigma \left(x _ {t}, t\right) d w _ {t}. \tag {6.6}
$$

Example 6.1. As a simple illustration, consider the square function $G ( w _ { t } , t ) =$ $w _ { t } ^ { 2 }$ of the Wiener process. Here we have $\mu ( w _ { t } , t ) = 0$ , $\sigma ( w _ { t } , t ) = 1$ and

$$
\frac {\partial G}{\partial w _ {t}} = 2 w _ {t}, \quad \frac {\partial G}{\partial t} = 0, \quad \frac {\partial^ {2} G}{\partial w _ {t} ^ {2}} = 2.
$$

Therefore,

$$
d w _ {t} ^ {2} = \left(2 w _ {t} \times 0 + 0 + \frac {1}{2} \times 2 \times 1\right) d t + 2 w _ {t} d w _ {t} = d t + 2 w _ {t} d w _ {t}. \tag {6.7}
$$

# 6.3.3 An Application

Let $P _ { t }$ be the price of a stock at time $t$ , which is continuous in $\lbrack 0 , \infty )$ . In the literature, it is common to assume that $P _ { t }$ follows the special Ito process

$$
d P _ {t} = \mu P _ {t} d t + \sigma P _ {t} d w _ {t}, \tag {6.8}
$$

where $\mu$ and $\sigma$ are constant. Using the notation of the general Ito process in Eq. (6.2), we have $\mu ( x _ { t } , t ) = \mu x _ { t }$ and $\sigma ( x _ { t } , t ) = \sigma x _ { t }$ , where $x _ { t } = P _ { t }$ . Such a special process is referred to as a geometric Brownian motion. We now apply Ito’s lemma to obtain a continuous-time model for the logarithm of the stock price $P _ { t }$ . Let $G ( P _ { t } , t ) = \ln ( P _ { t } )$ be the log price of the underlying stock. Then we have

$$
\frac {\partial G}{\partial P _ {t}} = \frac {1}{P _ {t}}, \quad \frac {\partial G}{\partial t} = 0, \quad \frac {1}{2} \frac {\partial^ {2} G}{\partial P _ {t} ^ {2}} = \frac {1}{2} \frac {(- 1)}{P _ {t} ^ {2}}.
$$

Consequently, via Ito’s lemma, we obtain

$$
\begin{array}{l} d \ln (P _ {t}) = \left(\frac {1}{P _ {t}} \mu P _ {t} + \frac {1}{2} \frac {(- 1)}{P _ {t} ^ {2}} \sigma^ {2} P _ {t} ^ {2}\right) d t + \frac {1}{P _ {t}} \sigma P _ {t} d w _ {t} \\ = \left(\mu - \frac {\sigma^ {2}}{2}\right) d t + \sigma d w _ {t}. \\ \end{array}
$$

This result shows that the logarithm of a price follows a generalized Wiener process with drift rate $\mu - \sigma ^ { 2 } / 2$ and variance rate $\sigma ^ { 2 }$ if the price is a geometric Brownian

motion. Consequently, the change in logarithm of price (i.e., log return) between current time $t$ and some future time $T$ is normally distributed with mean $( \mu -$ $\sigma ^ { 2 } / 2 ) ( T - t )$ and variance $\sigma ^ { 2 } ( T - t )$ . If the time interval $T - t = \Delta$ is fixed and we are interested in equally spaced increments in log price, then the increment series is a Gaussian process with mean $( \mu - \sigma ^ { 2 } / 2 ) \Delta$ and variance $\sigma ^ { 2 } \Delta$ .

# 6.3.4 Estimation of $\pmb { \mu }$ and $\pmb { \sigma }$

The two unknown parameters $\mu$ and $\sigma$ of the geometric Brownian motion in Eq. (6.8) can be estimated empirically. Assume that we have $n + 1$ observations of stock price $P _ { t }$ at equally spaced time interval $\Delta$ (e.g., daily, weekly, or monthly). We measure $\Delta$ in years. Denote the observed prices as $\{ P _ { 0 } , P _ { 1 } , \ldots , P _ { n } \}$ and let $r _ { t } = \ln ( P _ { t } ) - \ln ( P _ { t - 1 } )$ for $t = 1 , \ldots , n$ .

Since $P _ { t } = P _ { t - 1 } \exp ( r _ { t } )$ , $r _ { t }$ is the continuously compounded return in the tth time interval. Using the result of the previous subsection and assuming that the stock price $P _ { t }$ follows a geometric Brownian motion, we obtain that $r _ { t }$ is normally distributed with mean $( \mu - \sigma ^ { 2 } / 2 ) \Delta$ and variance $\sigma ^ { 2 } \Delta$ . In addition, the $r _ { t }$ are not serially correlated.

For simplicity, define $\mu _ { r } = E ( r _ { t } ) = ( \mu - \sigma ^ { 2 } / 2 ) \Delta$ and $\sigma _ { r } ^ { 2 } = \mathrm { v a r } ( r _ { t } ) = \sigma ^ { 2 } \Delta$ . Let $\overline { r }$ and $s _ { r }$ be the sample mean and standard deviation of the data—that is,

$$
\bar {r} = \frac {\sum_ {t = 1} ^ {n} r _ {t}}{n}, \quad s _ {r} = \sqrt {\frac {1}{n - 1} \sum_ {t = 1} ^ {n} (r _ {t} - \bar {r}) ^ {2}}.
$$

As mentioned in Chapter 1, $\overline { r }$ and $s _ { r }$ are consistent estimates of the mean and standard deviation of $r _ { i }$ , respectively. That is, $\overline { r }  \mu _ { r }$ and $s _ { r } \to \sigma _ { r }$ as $n \to \infty$ . Therefore, we may estimate $\sigma$ by

$$
\hat {\sigma} = \frac {s _ {r}}{\sqrt {\Delta}}.
$$

Furthermore, it can be shown that the standard error of this estimate is approximately $\hat { \sigma } / \sqrt { 2 n }$ . From $\hat { \mu } _ { r } = \overline { { r } }$ , we can estimate $\mu$ by

$$
\hat {\mu} = \frac {\overline {{r}}}{\Delta} + \frac {\hat {\sigma} ^ {2}}{2} = \frac {\overline {{r}}}{\Delta} + \frac {s _ {r} ^ {2}}{2 \Delta}.
$$

When the series $r _ { t }$ is serially correlated or when the price of the asset does not follow the geometric Brownian motion in Eq. (6.8), then other estimation methods must be used to estimate the drift and volatility parameters of the diffusion equation. We return to this issue later.

Example 6.2. Consider the daily log returns of IBM stock in 1998. Figure 6.2a shows the time plot of the data, which have 252 observations. Figure 6.2b shows the sample autocorrelations of the series. It is seen that the log returns are indeed serially uncorrelated. The Ljung–Box statistic gives $Q ( 1 0 ) = 4 . 9 $ , which is highly insignificant compared with a chi-squared distribution with 10 degrees of freedom.

![](images/d2bc3a4544facb943a17f6ffd47086b305a450bca9243abc2c66118ec0b01ca9.jpg)

![](images/6842a116319fb8c06f824b2be7f72da5f80eba0c18e5be800b22abb0eac56b47.jpg)  
Figure 6.2. Daily returns of IBM stock in 1998: (a) log returns and (b) sample autocorrelations.

If we assume that the price of IBM stock in 1998 follows the geometric Brownian motion in Eq. (6.8), then we can use the daily log returns to estimate the parameters $\mu$ and $\sigma$ . From the data, we have $\overline { { r } } = 0 . 0 0 2 2 7 6$ and $s _ { r } = 0 . 0 1 9 1 5$ . Since 1 trading day is equivalent to $\Delta = 1 / 2 5 2$ year, we obtain that

$$
\hat {\sigma} = \frac {s _ {r}}{\sqrt {\Delta}} = 0. 3 0 4 0, \quad \hat {\mu} = \frac {\overline {{r}}}{\Delta} + \frac {\hat {\sigma} ^ {2}}{2} = 0. 6 1 9 8.
$$

Thus, the estimated expected return was $6 1 . 9 8 \%$ and the standard deviation was $3 0 . 4 \%$ per annum for IBM stock in 1998.

The normality assumption of the daily log returns may not hold, however. In this particular instance, the skewness $- 0 . 4 6 4 ( 0 . 1 5 3 )$ and excess kurtosis 2.396(0.306) raise some concern, where the number in parentheses denotes asymptotic standard error.

Example 6.3. Consider the daily log return of the stock of Cisco Systems, Inc. in 1999. There are 252 observations, and the sample mean and standard deviation are 0.00332 and 0.026303, respectively. The log return series also shows no serial correlation with $Q ( 1 2 ) = 1 0 . 8 $ , which is not significant even at the $10 \%$ level. Therefore, we have

$$
\hat {\sigma} = \frac {s _ {r}}{\sqrt {\Delta}} = \frac {0 . 0 2 6 3 0 3}{\sqrt {1 . 0 / 2 5 2 . 0}} = 0. 4 1 8, \quad \hat {\mu} = \frac {\overline {{r}}}{\Delta} + \frac {\hat {\sigma} ^ {2}}{2} = 0. 9 2 4.
$$

Consequently, the estimated expected return for Cisco Systems’ stock was $9 2 . 4 \%$ per annum, and the estimated standard deviation was $4 1 . 8 \%$ per annum in 1999.

# 6.4 DISTRIBUTIONS OF STOCK PRICES AND LOG RETURNS

The result of the previous section shows that if one assumes that price of a stock follows the geometric Brownian motion

$$
d P _ {t} = \mu P _ {t} d t + \sigma P _ {t} d w _ {t},
$$

then the logarithm of the price follows a generalized Wiener process

$$
d \ln (P _ {t}) = \left(\mu - \frac {\sigma^ {2}}{2}\right) d t + \sigma d w _ {t},
$$

where $P _ { t }$ is the price of the stock at time $t$ and $w _ { t }$ is a Wiener process. Therefore, the change in log price from time $t$ to $T$ is normally distributed as

$$
\ln \left(P _ {T}\right) - \ln \left(P _ {t}\right) \sim N \left[ \left(\mu - \frac {\sigma^ {2}}{2}\right) (T - t), \sigma^ {2} (T - t) \right]. \tag {6.9}
$$

Consequently, conditional on the price $P _ { t }$ at time $t$ , the log price at time $T > t$ is normally distributed as

$$
\ln \left(P _ {T}\right) \sim N \left[ \ln \left(P _ {t}\right) + \left(\mu - \frac {\sigma^ {2}}{2}\right) (T - t), \sigma^ {2} (T - t) \right]. \tag {6.10}
$$

Using the result of lognormal distribution discussed in Chapter 1, we obtain the (conditional) mean and variance of $P _ { T }$ as

$$
E \left(P _ {T}\right) = P _ {t} \exp [ \mu (T - t) ],
$$

$$
\operatorname {V a r} \left(P _ {T}\right) = P _ {t} ^ {2} \exp \left[ 2 \mu (T - t) \right] \left\{\exp \left[ \sigma^ {2} (T - t) \right] - 1 \right\}.
$$

Note that the expectation confirms that $\mu$ is the expected rate of return of the stock.

The prior distribution of stock price can be used to make inference. For example, suppose that the current price of stock A is $\$ 50$ , the expected return of the stock is $15 \%$ per annum, and the volatility is $40 \%$ per annum. Then the expected price of stock A in 6 months (0.5 year) and the associated variance are given by

$$
E \left(P _ {T}\right) = 5 0 \exp (0. 1 5 \times 0. 5) = 5 3. 8 9,
$$

$$
\operatorname {V a r} \left(P _ {T}\right) = 2 5 0 0 \exp (0. 3 \times 0. 5) [ \exp (0. 1 6 \times 0. 5) - 1 ] = 2 4 1. 9 2.
$$

The standard deviation of the price 6 months from now is ${ \sqrt { 2 4 1 . 9 2 } } = 1 5 . 5 5$

Next, let $r$ be the continuously compounded rate of return per annum from time $t$ to $T$ . Then we have

$$
P _ {T} = P _ {t} \exp [ r (T - t) ],
$$

where $T$ and $t$ are measured in years. Therefore,

$$
r = \frac {1}{T - t} \ln \left(\frac {P _ {T}}{P _ {t}}\right).
$$

By Eq. (6.9), we have

$$
\ln \left(\frac {P _ {T}}{P _ {t}}\right) \sim N \left[ \left(\mu - \frac {\sigma^ {2}}{2}\right) (T - t), \sigma^ {2} (T - t) \right].
$$

Consequently, the distribution of the continuously compounded rate of return per annum is

$$
r \sim N \left(\mu - \frac {\sigma^ {2}}{2}, \frac {\sigma^ {2}}{T - t}\right).
$$

The continuously compounded rate of return is, therefore, normally distributed with mean $\mu - \sigma ^ { 2 } / 2$ and standard deviation $\sigma / \sqrt { T - t }$ .

Consider a stock with an expected rate of return of $15 \%$ per annum and a volatility of $10 \%$ per annum. The distribution of the continuously compounded rate of return of the stock over 2 years is normal with mean $0 . 1 5 - 0 . 0 1 / 2 = 0 . 1 4 5$ or $1 4 . 5 \%$ per annum and standard deviation $0 . 1 / \sqrt { 2 } = 0 . 0 7 1$ or $7 . 1 \%$ per annum. These results allow us to construct confidence intervals (C.I.) for $r$ . For instance, a $9 5 \%$ C.I. for $r$ is $0 . 1 4 5 \pm 1 . 9 6 \times 0 . 0 7 1$ per annum (i.e., 0.6%, $2 8 . 4 \%$ .

# 6.5 DERIVATION OF BLACK–SCHOLES DIFFERENTIAL EQUATION

In this section, we use Ito’s lemma and assume no arbitrage to derive the Black–Scholes differential equation for the price of a derivative contingent to a stock valued at $P _ { t }$ . Assume that the price $P _ { t }$ follows the geometric Brownian motion in Eq. (6.8) and $G _ { t } = G ( P _ { t } , t )$ is the price of a derivative (e.g., a call option) contingent on $P _ { t }$ . By Ito’s lemma,

$$
d G _ {t} = \left(\frac {\partial G _ {t}}{\partial P _ {t}} \mu P _ {t} + \frac {\partial G _ {t}}{\partial t} + \frac {1}{2} \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} \sigma^ {2} P _ {t} ^ {2}\right) d t + \frac {\partial G _ {t}}{\partial P _ {t}} \sigma P _ {t} d w _ {t}.
$$

The discretized versions of the process and previous result are

$$
\Delta P _ {t} = \mu P _ {t} \Delta t + \sigma P _ {t} \Delta w _ {t}, \tag {6.11}
$$

$$
\Delta G _ {t} = \left(\frac {\partial G _ {t}}{\partial P _ {t}} \mu P _ {t} + \frac {\partial G _ {t}}{\partial t} + \frac {1}{2} \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} \sigma^ {2} P _ {t} ^ {2}\right) \Delta t + \frac {\partial G _ {t}}{\partial P _ {t}} \sigma P _ {t} \Delta w _ {t}, \tag {6.12}
$$

where $\Delta P _ { t }$ and $\Delta G _ { t }$ are changes in $P _ { t }$ and $G _ { t }$ in a small time interval $\Delta t$ . Because $\Delta w _ { t } = \epsilon \sqrt { \Delta t }$ for both Eqs. (6.11) and (6.12), one can construct a portfolio of the stock and the derivative that does not involve the Wiener process. The appropriate

portfolio is short on derivative and long $\partial G _ { t } / \partial P _ { t }$ shares of the stock. Denote the value of the portfolio by $V _ { t }$ . By construction,

$$
V _ {t} = - G _ {t} + \frac {\partial G _ {t}}{\partial P _ {t}} P _ {t}. \tag {6.13}
$$

The change in $V _ { t }$ is then

$$
\Delta V _ {t} = - \Delta G _ {t} + \frac {\partial G _ {t}}{\partial P _ {t}} \Delta P _ {t}. \tag {6.14}
$$

Substituting Eqs. (6.11) and (6.12) into Eq. (6.14), we have

$$
\Delta V _ {t} = \left(- \frac {\partial G _ {t}}{\partial t} - \frac {1}{2} \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} \sigma^ {2} P _ {t} ^ {2}\right) \Delta t. \tag {6.15}
$$

This equation does not involve the stochastic component $\Delta w _ { t }$ . Therefore, under the no arbitrage assumption, the portfolio $V _ { t }$ must be riskless during the small time interval $\Delta t$ . In other words, the assumptions used imply that the portfolio must instantaneously earn the same rate of return as other short-term, risk-free securities. Otherwise there exists an arbitrage opportunity between the portfolio and the short-term, risk-free securities. Consequently, we have

$$
\Delta V _ {t} = r V _ {t} \Delta t = (r \Delta t) V _ {t}, \tag {6.16}
$$

where $r$ is the risk-free interest rate. By Eqs. (6.13) – (6.16), we have

$$
\left(\frac {\partial G _ {t}}{\partial t} + \frac {1}{2} \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} \sigma^ {2} P _ {t} ^ {2}\right) \Delta t = r \left(G _ {t} - \frac {\partial G _ {t}}{\partial P _ {t}} P _ {t}\right) \Delta t.
$$

Therefore,

$$
\frac {\partial G _ {t}}{\partial t} + r P _ {t} \frac {\partial G _ {t}}{\partial P _ {t}} + \frac {1}{2} \sigma^ {2} P _ {t} ^ {2} \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} = r G _ {t}. \tag {6.17}
$$

This is the Black–Scholes differential equation for derivative pricing. It can be solved to obtain the price of a derivative with $P _ { t }$ as the underlying variable.

The solution so obtained depends on the boundary conditions of the derivative. For a European call option, the boundary condition is

$$
G _ {T} = \max  (P _ {T} - K, 0),
$$

where $T$ is the expiration time and $K$ is the strike price. For a European put option, the boundary condition becomes

$$
G _ {T} = \max  (K - P _ {T}, 0).
$$

Example 6.4. As a simple example, consider a forward contract on a stock that pays no dividend. In this case, the value of the contract is given by

$$
G _ {t} = P _ {t} - K \exp [ - r (T - t) ],
$$

where $K$ is the delivery price, $r$ is the risk-free interest rate, and $T$ is the expiration time. For such a function, we have

$$
\frac {\partial G _ {t}}{\partial t} = - r K \exp [ - r (T - t) ], \quad \frac {\partial G _ {t}}{\partial P _ {t}} = 1, \quad \frac {\partial^ {2} G _ {t}}{\partial P _ {t} ^ {2}} = 0.
$$

Substituting these quantities into the left-hand side of Eq. (6.17) yields

$$
- r K \exp [ - r (T - t) ] + r P _ {t} = r \left\{P _ {t} - K \exp [ - r (T - t) ] \right\},
$$

which equals the right-hand side of Eq. (6.17). Thus, the Black–Scholes differential equation is indeed satisfied.

# 6.6 BLACK–SCHOLES PRICING FORMULAS

Black and Scholes (1973) successfully solve their differential equation in Eq. (6.17) to obtain exact formulas for the price of European call and put options. In what follows, we derive these formulas using what is called risk-neutral valuation in finance.

# 6.6.1 Risk-Neutral World

The drift parameter $\mu$ drops out from the Black–Scholes differential equation. In finance, this means the equation is independent of risk preferences. In other words, risk preferences cannot affect the solution of the equation. A nice consequence of this property is that one can assume that investors are risk-neutral. In a risk-neutral world, we have the following results:

• The expected return on all securities is the risk-free interest rate $r$ .   
• The present value of any cash flow can be obtained by discounting its expected value at the risk-free rate.

# 6.6.2 Formulas

The expected value of a European call option at maturity in a risk-neutral world is

$$
E _ {*} [ \max  (P _ {T} - K, 0) ],
$$

where $E _ { * }$ denotes expected value in a risk-neutral world. The price of the call option at time $t$ is

$$
c _ {t} = \exp [ - r (T - t) ] E _ {*} [ \max  \left(P _ {T} - K, 0\right) ]. \tag {6.18}
$$

Yet in a risk-neutral world, we have $\mu = r$ , and by Eq. (6.10), $\ln ( P _ { T } )$ is normally distributed as

$$
\ln \left(P _ {T}\right) \sim N \left[ \ln \left(P _ {t}\right) + \left(r - \frac {\sigma^ {2}}{2}\right) (T - t), \sigma^ {2} (T - t) \right].
$$

Let $g ( P _ { T } )$ be the probability density function of $P _ { T }$ . Then the price of the call option in Eq. (6.18) is

$$
c _ {t} = \exp [ - r (T - t) ] \int_ {K} ^ {\infty} (P _ {T} - K) g (P _ {T}) d P _ {T}.
$$

By changing the variable in the integration and some algebraic calculations (details are given in Appendix A), we have

$$
c _ {t} = P _ {t} \Phi \left(h _ {+}\right) - K \exp \left[ - r (T - t) \right] \Phi \left(h _ {-}\right), \tag {6.19}
$$

where $\Phi ( x )$ is the cumulative distribution function (CDF) of the standard normal random variable evaluated at $x$ ,

$$
\begin{array}{l} h _ {+} = \frac {\ln (P _ {t} / K) + (r + \sigma^ {2} / 2) (T - t)}{\sigma \sqrt {T - t}}, \\ h _ {-} = \frac {\ln (P _ {t} / K) + (r - \sigma^ {2} / 2) (T - t)}{\sigma \sqrt {T - t}} = h _ {+} - \sigma \sqrt {T - t}. \\ \end{array}
$$

In practice, $\Phi ( x )$ can easily be obtained from most statistical packages. Alternatively, one can use an approximation given in Appendix B.

The Black–Scholes call formula in Eq. (6.19) has some nice interpretations. First, if we exercise the call option on the expiration date, we receive the stock, but we have to pay the strike price. This exchange will take place only when the call finishes in-the-money (i.e., $P _ { T } > K$ ). The first term $P _ { t } \Phi ( h _ { + } )$ is the present value of receiving the stock if and only if $P _ { T } > K$ and the second term $- K \exp [ - r ( T -$ $t ) ] \Phi ( h _ { - } )$ is the present value of paying the strike price if and only if $P _ { T } > K$ . A second interpretation is particularly useful. As shown in the derivation of the Black–Scholes differential equation in Section 6.5, $\Phi ( h _ { + } ) = \partial G _ { t } / \partial P _ { t }$ is the number of shares in the portfolio that does not involve uncertainty, the Wiener process. This quantity is known as the delta in hedging. We know that $c _ { t } = P _ { t } \Phi ( h _ { + } ) + B _ { t }$ , where $B _ { t }$ is the dollar amount invested in risk-free bonds in the portfolio (or short on the derivative). We can then see that $B _ { t } = - K \exp [ - r ( T - t ) ] \Phi ( h _ { - } )$ directly from inspection of the Black–Scholes formula. The first term of the formula, $P _ { t } \Phi ( h _ { + } )$ , is the amount invested in the stock, whereas the second term, $K \exp [ - r ( T - t ) ] \Phi ( h _ { - } )$ , is the amount borrowed.

Similarly, we can obtain the price of a European put option as

$$
p _ {t} = K \exp [ - r (T - t) ] \Phi (- h _ {-}) - P _ {t} \Phi (- h _ {+}). \tag {6.20}
$$

Since the standard normal distribution is symmetric with respect to its mean 0.0, we have $\Phi ( x ) = 1 - \Phi ( - x )$ for all $x$ . Using this property, we have $\Phi ( - h _ { i } ) = $ $1 - \Phi ( h _ { i } )$ . Thus, the information needed to compute the price of a put option is the same as that of a call option. Alternatively, using the symmetry of normal distribution, it is easy to verify that

$$
p _ {t} - c _ {t} = K \exp [ - r (T - t) ] - P _ {t},
$$

which is referred to as the put–call parity and can be used to obtain $p _ { t }$ from $c _ { t }$ . The put–call parity can also be obtained by considering the following two portfolios:

1. Portfolio A. One European call option plus an amount of cash equal to $K \exp [ - r ( T - t ) ]$ .   
2. Portfolio $B$ . One European put option plus one share of the underlying stock.

The payoff of these two portfolios is

$$
\max  \left(P _ {T}, K\right)
$$

at the expiration of the options. Since the options can only be exercised at the expiration date, the portfolios must have identical value today. This means

$$
c _ {t} + K \exp [ - r (T - t) ] = p _ {t} + P _ {t},
$$

which is the put – call parity given earlier.

Example 6.5. Suppose that the current price of Intel stock is $\$ 80$ per share with volatility $\sigma = 2 0 \%$ per annum. Suppose further that the risk-free interest rate is $8 \%$ per annum. What is the price of a European call option on Intel with a strike price of $\$ 90$ that will expire in 3 months?

From the assumptions, we have $P _ { t } = 8 0$ , $K = 9 0$ , $T - t = 0 . 2 5$ , $\sigma = 0 . 2$ , and $r = 0 . 0 8$ . Therefore,

$$
\begin{array}{l} h _ {+} = \frac {\ln (8 0 / 9 0) + (0 . 0 8 + 0 . 0 4 / 2) \times 0 . 2 5}{0 . 2 \sqrt {0 . 2 5}} = - 0. 9 2 7 8, \\ h _ {-} = h _ {+} - 0. 2 \sqrt {0 . 2 5} = - 1. 0 2 7 8. \\ \end{array}
$$

Using any statistical software (e.g., Minitab or SCA) or the approximation in Appendix B, we have

$$
\Phi (- 0. 9 2 7 8) = 0. 1 7 6 7, \quad \Phi (- 1. 0 2 7 8) = 0. 1 5 2 0.
$$

Consequently, the price of a European call option is

$$
c _ {t} = \mathbb {S} 8 0 \Phi (- 0. 9 2 7 8) - \mathbb {S} 9 0 \Phi (- 1. 0 2 7 8) \exp (- 0. 0 2) = \mathbb {S} 0. 7 3.
$$

The stock price has to rise by $\$ 10.73$ for the purchaser of the call option to break even.

Under the same assumptions, the price of a European put option is

$$
p _ {t} = \$ 90 \exp (- 0. 0 8 \times 0. 2 5) \Phi (1. 0 2 7 8) - \$ 8 0 \Phi (0. 9 2 7 8) = \$ 8. 9 5.
$$

Thus, the stock price can rise an additional $\$ 1.05$ for the purchaser of the put option to break even.

Example 6.6. The strike price of the previous example is well beyond the current stock price. A more realistic strike price is $\$ 81$ . Assume that the other conditions of the previous example continue to hold. We now have $P _ { t } = 8 0$ , $K = 8 1$ $r = 0 . 0 8$ , and $T - t = 0 . 2 5$ , and the $h _ { i }$ become

$$
\begin{array}{l} h _ {+} = \frac {\ln (8 0 / 8 1) + (0 . 0 8 + 0 . 0 4 / 2) \times 0 . 2 5}{0 . 2 \sqrt {0 . 2 5}} = 0. 1 2 5 7 7 5, \\ h _ {-} = h _ {+} - 0. 2 \sqrt {0 . 2 5} = 0. 0 2 5 7 7 5. \\ \end{array}
$$

Using the approximation in Appendix B, we have $\Phi ( 0 . 1 2 5 7 7 5 ) = 0 . 5 5 0 0$ and $\Phi ( 0 . 0 2 5 7 7 5 ) = 0 . 5 1 0 3$ . The price of a European call option is then

$$
c _ {t} = \\( 8 0 \Phi (0. 1 2 5 7 7 5) - \\) 8 1 \exp (- 0. 0 2) \Phi (0. 0 2 5 7 7 5) = \\) 3. 4 9.
$$

The price of the stock has to rise by $\$ 4.49$ for the purchaser of the call option to break even. On the other hand, under the same assumptions, the price of a European put option is

$$
\begin{array}{l} p _ {t} = \$ 81 \exp (- 0. 0 2) \Phi (- 0. 0 2 5 7 7 5) - \$ 8 0 \Phi (- 0. 1 2 5 7 7 5) \\ = \$ 81 \exp (- 0.02) \times 0.48972 - \$ 80 \times 0.44996 = \$ 2.89. \\ \end{array}
$$

The stock price must fall $\$ 1.89$ for the purchaser of the put option to break even.

# 6.6.3 Lower Bounds of European Options

Consider the call option of a nondividend-paying stock. It can be shown that the price of a European call option satisfies

$$
c _ {t} \geq P _ {t} - K \exp [ - r (T - t) ];
$$

that is, the lower bound for a European call price is $P _ { t } - K \exp [ - r ( T - t ) ]$ . This result can be verified by considering two portfolios:

1. Portfolio A. One European call option plus an amount of cash equal to $K \exp [ - r ( T - t ) ]$ .   
2. Portfolio $B$ . One share of the stock.

For portfolio A, if the cash is invested at the risk-free interest rate, it will result in $K$ at time $T$ . If $P _ { T } > K$ , the call option is exercised at time $T$ and the portfolio is worth $P _ { T }$ . If $P _ { T } < K$ , the call option expires worthless and the portfolio is

worth $K$ . Therefore, the value of portfolio is

$$
\max  \left(P _ {T}, K\right).
$$

The value of portfolio B is $P _ { T }$ at time $T$ . Hence, portfolio A is always worth more than (or, at least, equal to) portfolio B. It follows that portfolio A must be worth more than portfolio B today; that is,

$$
c _ {t} + K \exp [ - r (T - t) ] \geq P _ {t}, \quad \text {o r} \quad c _ {t} \geq P _ {t} - K \exp [ - r (T - t) ].
$$

Furthermore, since $c _ { t } \geq 0$ , we have

$$
c _ {t} \geq \max  \left(P _ {t} - K \exp \left[ - r (T - t) \right], 0\right).
$$

A similar approach can be used to show that the price of a corresponding European put option satisfies

$$
p _ {t} \geq \max  (K \exp [ - r (T - t) ] - P _ {t}, 0).
$$

Example 6.7. Suppose that $P _ { t } = \$ 30$ $P _ { t } = \ S 3 0 , \ K = \ S 2 8 , \ r = 6 \%$ per annum, and $T - t = 0 . 5$ . In this case,

$$
P _ {t} - K \exp [ - r (T - t) ] = \\( [ 3 0 - 2 8 \exp (- 0. 0 6 \times 0. 5) ] \approx \\) 2. 8 3 .
$$

Assume that the European call price of the stock is $\$ 2.50$ , which is less than the theoretical minimum of $\$ 2.83$ . An arbitrageur can buy the call option and short the stock. This provides a new cash flow of $\mathbb { S } ( 3 0 - 2 . 5 0 ) = \mathbb { S } 2 7 . 5 0$ . If invested for 6 months at the risk-free interest rate, the $\$ 27.50$ grows to $\$ 27.50\exp (0.06\times$ $0 . 5 ) = \mathbb { S } 2 8 . 3 4$ . At the expiration time, if $P _ { T } > \$ 28$ , the arbitrageur exercises the option, closes out the short position, and makes a profit of $\mathbb { S } ( 2 8 . 3 4 - 2 8 ) = \mathbb { S } 0 . 3 4$ . On the other hand, if $P _ { T } < \$ 28$ , the stock is bought in the market to close the short position. The arbitrageur then makes an even greater profit. For illustration, suppose that $P _ { T } = \$ 27.00$ , then the profit is $\mathbb { S } ( 2 8 . 3 4 - 2 7 . 0 0 ) = \mathbb { S } 1 . 3 4$ .

# 6.6.4 Discussion

From the formulas, the price of a call or put option depends on five variables— namely, the current stock price $P _ { t }$ , the strike price $K$ , the time to expiration $T - t$ measured in years, the volatility $\sigma$ per annum, and the interest rate $r$ per annum. It pays to study the effects of these five variables on the price of an option.

# Marginal Effects

Consider first the marginal effects of the five variables on the price of a call option $c _ { t }$ . By marginal effects we mean that changing one variable while holding the others fixed. The effects on a call option can be summarized as follows:

![](images/97301263df71227ae50478ac46e338a2424562d3827cf865b311b22ab00769f0.jpg)  
(a) Call options

![](images/16fd5e5307a54e2d8aaeaa1f5aa3819355c34e53f19132253dbc67dcd82e5920.jpg)  
(b) Put options   
Figure 6.3. Marginal effects of the current stock price on the price of an option with $K = 8 0$ , $T - t =$ 0.25, $\sigma = 0 . 3$ , and $r = 0 . 0 6$ : (a) call option and (b) put option.

1. Current Stock Price $P _ { t }$ . $c _ { t }$ is positively related to $\ln ( P _ { t } )$ . In particular, $c _ { t } \to 0$ as $P _ { t } \to 0$ and $c _ { t } \to \infty$ as $P _ { t } \to \infty$ . Figure 6.3a illustrates the effects with $K = 8 0$ , $r = 6 \%$ per annum, $T - t = 0 . 2 5$ year, and $\sigma = 3 0 \%$ per annum.   
2. Strike Price $K$ . $c _ { t }$ is negatively related to $\operatorname { l n } ( K )$ . In particular, $c _ { t }  P _ { t }$ as $K  0$ and $c _ { t } \to 0$ as $K  \infty$ .   
3. Time to Expiration. $c _ { t }$ is related to $T - t$ in a complicated manner, but we can obtain the limiting results by writing $h _ { + }$ and $h _ { - }$ as

$$
h _ {+} = \frac {\ln (P _ {t} / K)}{\sigma \sqrt {T - t}} + \frac {(r + \sigma^ {2} / 2) \sqrt {T - t}}{\sigma},
$$

$$
h _ {-} = \frac {\ln (P _ {t} / K)}{\sigma \sqrt {T - t}} + \frac {(r - \sigma^ {2} / 2) \sqrt {T - t}}{\sigma}.
$$

If $P _ { t } < K$ , then $c _ { t } \to 0$ as $( T - t ) \to 0$ . If $P _ { t } > K$ , then $c _ { t }  P _ { t } - K$ as $( T - t ) \to 0$ and $c _ { t }  P _ { t }$ as $( T - t ) \to \infty$ . Figure 6.4a shows the marginal effects of $T - t$ on $c _ { t }$ for three different current stock prices. The fixed variables are $K = 8 0$ , $r = 6 \%$ , and $\sigma = 3 0 \%$ . The solid, dotted, and dashed lines of the plot are for $P _ { t } = 7 0$ , 80, and 90, respectively.

![](images/1ed28d6a520df0c0648ef65a7a25bd1465b0739ca9bbd05b6c279798347ad901.jpg)

![](images/f64f98be63c0bda45d5a7da648812303c90540997b3e09b2d4222cb64bdd227a.jpg)  
Figure 6.4. Marginal effects of the time to expiration on the price of an option with $K = 8 0$ , $\sigma = 0 . 3$ , and $r = 0 . 0 6 \mathrm { : }$ (a) call option and (b) put option. The solid, dotted, and dashed lines are for the current stock price $P _ { t } = 7 0$ , 80, and 90, respectively.

4. Volatility $\sigma$ . Rewriting $h _ { + }$ and $h _ { - }$ as

$$
h _ {+} = \frac {\ln (P _ {t} / K) + r (T - t)}{\sigma \sqrt {T - t}} + \frac {\sigma}{2} \sqrt {T - t},
$$

$$
h _ {-} = \frac {\ln (P _ {t} / K) + r (T - t)}{\sigma \sqrt {T - t}} - \frac {\sigma}{2} \sqrt {T - t},
$$

we obtain that (a) if $\ln ( P _ { t } / K ) + r ( T - t ) < 0$ , then $c _ { t } \to 0$ as $\sigma  0$ , and (b) if $\ln ( P _ { t } / K ) + r ( T - t ) \geq 0$ , then $c _ { t }  P _ { t } - K e ^ { - r ( T - t ) }$ as $\sigma \to 0$ and $c _ { t }  P _ { t }$ as $\sigma \to \infty$ . Figure 6.5a shows the effects of $\sigma$ on $c _ { t }$ for $K = 8 0$ , $T - t = 0 . 2 5$ , $r = 0 . 0 6$ , and three different values of $P _ { t }$ . The solid, dotted, and dashed lines are for $P _ { t } = 7 0$ , 80, and 90, respectively.

5. Interest Rate. $c _ { t }$ is positively related to $r$ such that $c _ { t }  P _ { t }$ as $r  \infty$ .

The marginal effects of the five variables on a put option can be obtained similarly. Figures 6.3b, 6.4b, and 6.5b illustrate the effects for some selected cases.

# Some Joint Effects

Figure 6.6 shows the joint effects of volatility and strike price on a call option, where the other variables are fixed at $P _ { t } = 8 0$ , $r = 0 . 0 6$ , and $T - t = 0 . 2 5$ . As

![](images/36aab4fc2d3c22d42cf739844db1f8eb809d9c9af1ce4ed97aa005cfc8ee56cd.jpg)  
(a) Call options

![](images/404214daf0dabf67c110e0064b89329a0ee3306feb62978e21fb4460d94014e8.jpg)  
(b) Put options   
Figure 6.5. Marginal effects of stock volatility on the price of an option with $K = 8 0$ , $T - t = 0 . 2 5$ , and $r = 0 . 0 6$ : (a) call option and (b) put option. The solid, dotted, and dashed lines are for the current stock price $P _ { t } = 7 0$ , 80, and 90, respectively.

![](images/db38a05662b78d5729564af5f43e424e2b0214a1d78e321b9753694c1893617c.jpg)  
Figure 6.6. Joint effects of stock volatility and the strike price on a call option with $P _ { t } = 8 0$ , $r = 0 . 0 6$ , and $T - t = 0 . 2 5$ .

![](images/787647c395aaabbd143ece2c2fed6ff89f7a04de14c392c48ebdfe2ccb97492a.jpg)  
Figure 6.7. Joint effects of stock volatility and the strike price on a put option with $K = 8 0$ , $T - t =$ 0.25, and $r = 0 . 0 6$ .

expected, the price of a call option is higher when the volatility is high and the strike price is well below the current stock price. Figure 6.7 shows the effects on a put option under the same conditions. The price of a put option is higher when the volatility is high and the strike price is well above the current stock price. Furthermore, the plot also shows that the effects of a strike price on the price of a put option becomes more linear as the volatility increases.

# 6.7 AN EXTENSION OF ITO’S LEMMA

In derivative pricing, a derivative may be contingent on multiple securities. When the prices of these securities are driven by multiple factors, the price of the derivative is a function of several stochastic processes. The two-factor model for the term structure of interest rate is an example of two stochastic processes. In this section, we briefly discuss the extension of Ito’s lemma to the case of several stochastic processes.

Consider a $k$ -dimensional continuous-time process $\pmb { x } _ { t } = ( x _ { 1 t } , \ldots , x _ { k t } ) ^ { \prime }$ , where $k$ is a positive integer and $x _ { i t }$ is a continuous-time stochastic process satisfying

$$
d x _ {i t} = \mu_ {i} \left(\boldsymbol {x} _ {t}\right) d t + \sigma_ {i} \left(\boldsymbol {x} _ {t}\right) d w _ {i t}, \quad i = 1, \dots , k, \tag {6.21}
$$

where $w _ { i t }$ is a Wiener process. It is understood that the drift and volatility functions $\mu _ { i } ( x _ { i t } )$ and $\sigma _ { i } ( x _ { i t } )$ are functions of time index $t$ as well. We omit $t$ from their

arguments to simplify the notation. For $i \neq j$ , the Wiener processes $w _ { i t }$ and $w _ { j t }$ are different. We assume that the correlation between $d w _ { i t }$ and $d w _ { j t }$ is $\rho _ { i j }$ . This means that $\rho _ { i j }$ is the correlation between the two standard normal random variables $\epsilon _ { i }$ and $\epsilon _ { j }$ defined by $\Delta w _ { i t } = \epsilon _ { i } \Delta t$ and $\Delta w _ { j t } = \epsilon _ { j } \Delta t$ . Assume that $G _ { t } = G ( \pmb { x } _ { t } , t )$ is a function of the stochastic processes $x _ { i t }$ and time t. The Taylor expansion gives

$$
\begin{array}{l} \Delta G _ {t} = \sum_ {i = 1} ^ {k} \frac {\partial G _ {t}}{\partial x _ {i t}} \Delta x _ {i t} + \frac {\partial G _ {t}}{\partial t} \Delta t + \frac {1}{2} \sum_ {i = 1} ^ {k} \sum_ {j = 1} ^ {k} \frac {\partial^ {2} G _ {t}}{\partial x _ {i t} \partial x _ {j t}} \Delta x _ {i t} \Delta x _ {j t} \\ + \frac {1}{2} \sum_ {i = 1} ^ {k} \frac {\partial^ {2} G _ {t}}{\partial x _ {i t} \partial t} \Delta x _ {i t} \Delta t + \dots . \\ \end{array}
$$

The discretized version of Eq. (6.21) is

$$
\Delta w _ {i t} = \mu_ {i} \left(\boldsymbol {x} _ {t}\right) \Delta t + \sigma_ {i} \left(\boldsymbol {x} _ {t}\right) \Delta w _ {i t}, \quad i = 1, \dots , k.
$$

Using a similar argument as that of Eq. (6.5) in Section 6.3, we can obtain that

$$
\lim  _ {\Delta t \rightarrow 0} \left(\Delta x _ {i t}\right) ^ {2} \rightarrow \sigma_ {i} ^ {2} \left(\boldsymbol {x} _ {t}\right) d t, \tag {6.22}
$$

$$
\lim  _ {\Delta t \rightarrow 0} \left(\Delta x _ {i t} \Delta x _ {j t}\right)\rightarrow \sigma_ {i} \left(\boldsymbol {x} _ {t}\right) \sigma_ {j} \left(\boldsymbol {x} _ {t}\right) \rho_ {i j} d t. \tag {6.23}
$$

Using Eqs. (6.21)–(6.23), taking the limit as $\Delta t \to 0$ , and ignoring higher order terms of $\Delta t$ , we have

$$
\begin{array}{l} d G _ {t} = \left[ \sum_ {i = 1} ^ {k} \frac {\partial G _ {t}}{\partial x _ {i t}} \mu_ {i} (\boldsymbol {x} _ {t}) + \frac {\partial G _ {t}}{\partial t} + \frac {1}{2} \sum_ {i = 1} ^ {k} \sum_ {j = 1} ^ {k} \frac {\partial^ {2} G _ {t}}{\partial x _ {i t} \partial x _ {j t}} \sigma_ {i} (\boldsymbol {x} _ {t}) \sigma_ {j} (\boldsymbol {x} _ {t}) \rho_ {i j} \right] d t \\ + \sum_ {i = 1} ^ {k} \frac {\partial G _ {t}}{\partial x _ {i t}} \sigma_ {i} \left(\boldsymbol {x} _ {t}\right) d w _ {i t}. \tag {6.24} \\ \end{array}
$$

This is a generalization of Ito’s lemma to the case of multiple stochastic processes.

# 6.8 STOCHASTIC INTEGRAL

We briefly discuss stochastic integration so that the price of an asset can be obtained under the assumption that it follows an Ito process. We deduce the integration result using Ito’s formula. For a rigorous treatment on the topic, readers may consult textbooks on stochastic calculus. First, like the usual integration of a deterministic function, integration is the opposite of differentiation so that

$$
\int_ {0} ^ {t} d x _ {s} = x _ {t} - x _ {0}
$$

continues to hold for a stochastic process $x _ { t }$ . In particular, for the Wiener process $w _ { t }$ , we have $\textstyle \int _ { 0 } ^ { t } d w _ { s } = w _ { t }$ because $w _ { 0 } = 0$ . Next, consider the integration $\begin{array} { r } { \int _ { 0 } ^ { t } w _ { s } d w _ { s } } \end{array}$ . Using the prior result and taking integration of Eq. (6.7), we have

$$
w _ {t} ^ {2} = t + 2 \int_ {0} ^ {t} w _ {s} d w _ {s}.
$$

Therefore,

$$
\int_ {0} ^ {t} w _ {s} d w _ {s} = \frac {1}{2} (w _ {t} ^ {2} - t).
$$

This is different from the usual deterministic integration for which $\textstyle \int _ { 0 } ^ { t } y d y = ( y _ { t } ^ { 2 } -$ $y _ { 0 } ^ { 2 } ) / 2$ .

Turn to the case that $x _ { t }$ is a geometric Brownian motion—that is, $x _ { t }$ satisfies

$$
d x _ {t} = \mu x _ {t} d t + \sigma x _ {t} d w _ {t},
$$

where $\mu$ and $\sigma$ are constant with $\sigma > 0$ ; see Eq. (6.8). Applying Ito’s lemma to $G ( x _ { t } , t ) = \ln ( x _ { t } )$ , we obtain

$$
d \ln (x _ {t}) = \left(\mu - \frac {\sigma^ {2}}{2}\right) d t + \sigma d w _ {t}.
$$

Performing the integration and using the results obtained before, we have

$$
\int_ {0} ^ {t} d \ln (x _ {s}) = \left(\mu - \frac {\sigma^ {2}}{2}\right) \int_ {0} ^ {t} d s + \sigma \int_ {0} ^ {t} d w _ {s}.
$$

Consequently,

$$
\ln (x _ {t}) = \ln (x _ {0}) + (\mu - \sigma^ {2} / 2) t + \sigma w _ {t}
$$

and

$$
x _ {t} = x _ {0} \exp [ (\mu - \sigma^ {2} / 2) t + \sigma w _ {t} ].
$$

Changing the notation $x _ { t }$ to $P _ { t }$ for the price of an asset, we have a solution for the price under the assumption that it is a geometric Brownian motion. The price is

$$
P _ {t} = P _ {0} \exp \left[ \left(\mu - \sigma^ {2} / 2\right) t + \sigma w _ {t} \right]. \tag {6.25}
$$

# 6.9 JUMP DIFFUSION MODELS

Empirical studies have found that the stochastic diffusion model based on Brownian motion fails to explain some characteristics of asset returns and the prices of their derivatives (e.g., the “volatility smile” of implied volatilities; see Bakshi, Cao, and Chen, 1997, and the references therein). Volatility smile is referred to as the convex

function between the implied volatility and strike price of an option. Both out-ofthe-money and in-the-money options tend to have higher implied volatilities than at-the-money options especially in the foreign exchange markets. Volatility smile is less pronounced for equity options. The inadequacy of the standard stochastic diffusion model has led to the developments of alternative continuous-time models. For example, jump diffusion and stochastic volatility models have been proposed in the literature to overcome the inadequacy; see Merton (1976) and Duffie (1995).

Jumps in stock prices are often assumed to follow a probability law. For example, the jumps may follow a Poisson process, which is a continuous-time discrete process. For a given time $t$ , let $X _ { t }$ be the number of times a special event occurs during the time period $[ 0 , t ]$ . Then $X _ { t }$ is a Poisson process if

$$
\Pr \left(X _ {t} = m\right) = \frac {\lambda^ {m} t ^ {m}}{m !} \exp (- \lambda t), \quad \lambda > 0.
$$

That is, $X _ { t }$ follows a Poisson distribution with parameter λt. The parameter λ governs the occurrence of the special event and is referred to as the rate or intensity of the process. A formal definition also requires that $X _ { t }$ be a right-continuous homogeneous Markov process with left-hand limit.

In this section, we discuss a simple jump diffusion model proposed by Kou (2002). This simple model enjoys several nice properties. The returns implied by the model are leptokurtic and asymmetric with respect to zero. In addition, the model can reproduce volatility smile and provide analytical formulas for the prices of many options. The model consists of two parts, with the first part being continuous and following a geometric Brownian motion and the second part being a jump process. The occurrences of jump are governed by a Poisson process, and the jump size follows a double exponential distribution. Let $P _ { t }$ be the price of an asset at time t. The simple jump diffusion model postulates that the price follows the stochastic differential equation

$$
\frac {d P _ {t}}{P _ {t}} = \mu d t + \sigma d w _ {t} + d \left(\sum_ {i = 1} ^ {n _ {t}} \left(J _ {i} - 1\right)\right), \tag {6.26}
$$

where $w _ { t }$ is a Wiener process, $n _ { t }$ is a Poisson process with rate $\lambda$ , and $\{ J _ { i } \}$ is a sequence of independent and identically distributed non-negative random variables such that $X = \ln ( J )$ has a double exponential distribution with probability density function

$$
f _ {X} (x) = \frac {1}{2 \eta} e ^ {- | x - \kappa | / \eta}, \quad 0 <   \eta <   1. \tag {6.27}
$$

The double exponential distribution is also referred to as the Laplacian distribution. In model (6.26), $n _ { t }$ , $w _ { t }$ , and $J _ { i }$ are independent so that there is no relation between the randomness of the model. Notice that $n _ { t }$ is the number of jumps in the time interval $[ 0 , t ]$ and follows a Poisson distribution with parameter λt, where $\lambda$ is a constant. At the ith jump, the proportion of price jump is $J _ { i } - 1$ .

The double exponential distribution can be written as

$$
X - \kappa = \left\{ \begin{array}{c} \xi \text {w i t h p r o b a b i l i t y} 0. 5, \\ - \xi \text {w i t h p r o b a b i l i t y} 0. 5, \end{array} \right. \tag {6.28}
$$

where $\xi$ is an exponential random variable with mean $\eta$ and variance $\eta ^ { 2 }$ . The probability density function of $\xi$ is

$$
f (x) = \frac {1}{\eta} e ^ {- x / \eta}, \quad 0 <   x <   \infty .
$$

Some useful properties of the double exponential distribution are

$$
E (X) = \kappa , \quad \operatorname {V a r} (X) = 2 \eta^ {2}, \quad E (e ^ {X}) = \frac {e ^ {\kappa}}{1 - \eta^ {2}}.
$$

For finite samples, it is hard to distinguish a double exponential distribution from a Student-t distribution. However, a double exponential distribution is more tractable analytically and can generate a higher probability concentration (e.g., higher peak) around its mean value. As stated in Chapter 1, histograms of observed asset returns tend to have a higher peak than the normal density. Figure 6.8 shows the probability density function of a double exponential random variable in the solid line and that of a normal random variable in the dotted line. Both variables have mean zero and variance 0.0008. The high peak of the double exponential density is clearly seen.

Solving the stochastic differential equation in Eq. (6.26), we obtain the dynamics of the asset price as

$$
P _ {t} = P _ {0} \exp [ (\mu - \sigma^ {2} / 2) t + \sigma w _ {t} ] \prod_ {i = 1} ^ {n _ {t}} J _ {i}, \tag {6.29}
$$

where it is understood that $\textstyle \prod _ { i = 1 } ^ { 0 } = 1$ . This result is a generalization of Eq. (6.25) by including the stochastic jumps. It can be obtained as follows. Let $t _ { i }$ be the time of the ith jump. For $t \in [ 0 , t _ { 1 } )$ , there is no jump and the price is given in Eq. (6.25). Consequently, the left-hand price limit at time $t _ { 1 }$ is

$$
P _ {t _ {1} ^ {-}} = P _ {0} \exp [ (\mu - \sigma^ {2} / 2) t _ {1} + \sigma w _ {t _ {1}} ].
$$

At time $t _ { 1 }$ , the proportion of price jump is $J _ { 1 } - 1$ so that the price becomes

$$
P _ {t _ {1}} = (1 + J _ {1} - 1) P _ {t _ {1} ^ {-}} = J _ {1} P _ {t _ {1} ^ {-}} = P _ {0} \exp [ (\mu - \sigma^ {2} / 2) t _ {1} + \sigma w _ {t _ {1}} ] J _ {1}.
$$

For $t \in ( t _ { 1 } , t _ { 2 } )$ , there is no jump in the interval $( t _ { 1 } , t ]$ so that

$$
P _ {t} = P _ {t _ {1}} \exp \left[ \left(\mu - \sigma^ {2} / 2\right) \left(t - t _ {1}\right) + \sigma \left(w _ {t} - w _ {t _ {1}}\right) \right].
$$

![](images/d2479b7cf8858fb7ec5c54abae770ffd70b76adc8dd4fd8f2a6b08e95cfac8e1.jpg)  
Figure 6.8. Probability density functions of a double exponential and a normal random variable with mean zero and variance 0.0008. The solid line denotes the double exponential distribution.

Plugging in $P _ { t _ { 1 } }$ , we have

$$
P _ {t} = P _ {0} \exp \left[ \left(\mu - \sigma^ {2} / 2\right) t + \sigma w _ {t} \right] J _ {1}.
$$

Repeating the scheme, we obtain Eq. (6.29).

From Eq. (6.29), the simple return of the underlying asset in a small time increment $\Delta t$ becomes

$$
\frac {P _ {t + \Delta t} - P _ {t}}{P _ {t}} = \exp \left((\mu - \frac {1}{2} \sigma^ {2}) \Delta t + \sigma (w _ {t + \Delta t} - w _ {t}) + \sum_ {i = n _ {t} + 1} ^ {n _ {t + \Delta t}} X _ {i}\right) - 1,
$$

where it is understood that a summation over an empty set is zero and $X _ { i } = \ln ( J _ { i } )$ . For a small $\Delta t$ , we may use the approximation $e ^ { x } \approx 1 + x + x ^ { 2 } / 2$ and the result $( \Delta w _ { t } ) ^ { 2 } \approx \Delta t$ discussed in Section 6.3 to obtain

$$
\begin{array}{l} \frac {P _ {t + \Delta t} - P _ {t}}{P _ {t}} \approx (\mu - \frac {1}{2} \sigma^ {2}) \Delta t + \sigma \Delta w _ {t} + \sum_ {i = n _ {t} + 1} ^ {n _ {t + \Delta t}} X _ {i} + \frac {1}{2} \sigma^ {2} (\Delta w _ {t}) ^ {2} \\ \approx \mu \Delta t + \sigma \epsilon \sqrt {\Delta t} + \sum_ {i = n _ {t} + 1} ^ {n _ {t + \Delta t}} X _ {i}, \\ \end{array}
$$

where $\Delta w _ { t } = w _ { t + \Delta t } - w _ { t }$ and $\epsilon$ is a standard normal random variable.

Under the assumption of a Poisson process, the probability of having one jump in the time interval $( t , t + \Delta t ]$ is $\lambda \ \Delta t$ and that of having more than one jump is $o ( \Delta t )$ , where the symbol $o ( \Delta t )$ means that if we divide this term by $\Delta t$ then its value tends to zero as $\Delta t$ tends to zero. Therefore, for a small $\Delta t$ , by ignoring multiple jumps, we have

$$
\sum_ {i = n _ {t} + 1} ^ {n _ {t + \Delta t}} X _ {i} \approx \left\{ \begin{array}{l l} X _ {n _ {t} + 1} & \text {w i t h p r o b a b i l i t y \lambda \Delta t ,} \\ 0 & \text {w i t h p r o b a b i l i t y 1 - \lambda \Delta t .} \end{array} \right.
$$

Combining the prior results, we see that the simple return of the underlying asset is approximately distributed as

$$
\frac {P _ {t + \Delta t} - P _ {t}}{P _ {t}} \approx \mu \Delta t + \sigma \epsilon \sqrt {\Delta t} + I \times X, \tag {6.30}
$$

where $I$ is a Bernoulli random variable with $\operatorname* { P r } \left( I = 1 \right) = \lambda \ \Delta t$ and $\Pr \left( I = 0 \right) =$ $1 - \lambda \Delta t$ , and $X$ is a double exponential random variable defined in Eq. (6.28). Equation (6.30) reduces to that of a geometric Brownian motion without jumps.

Let $G = \mu \ \Delta t + \sigma \epsilon \sqrt { \Delta t } + I \times \bar { X }$ be the random variable on the right-hand side of Eq. (6.30). Using the independence between the exponential and normal distributions used in the model, Kou (2002) obtains the probability density function of $G$ as

$$
\begin{array}{l} g (x) = \frac {\lambda \Delta t}{2 \eta} e ^ {\sigma^ {2} \Delta t / (2 \eta^ {2})} \left[ e ^ {- \omega / \eta} \Phi \left(\frac {\omega \eta - \sigma^ {2} \Delta t}{\sigma \eta \sqrt {\Delta t}}\right) + e ^ {\omega / \eta} \Phi \left(\frac {\omega \eta + \sigma^ {2} \Delta t}{\sigma \eta \sqrt {\Delta t}}\right) \right] \\ + (1 - \lambda \Delta t) \frac {1}{\sigma \sqrt {\Delta t}} f \left(\frac {x - \mu \Delta t}{\sigma \sqrt {\Delta t}}\right), \tag {6.31} \\ \end{array}
$$

where $\omega = x - \mu \Delta t - \kappa$ , and $f ( . )$ and $\Phi ( . )$ are, respectively, the probability density and cumulative distribution functions of the standard normal random variable. Furthermore,

$$
E (G) = \mu \Delta t + \kappa \lambda \Delta t, \quad \operatorname {V a r} (G) = \sigma^ {2} \Delta t + \lambda \Delta t [ 2 \eta^ {2} + \kappa^ {2} (1 - \lambda \Delta t) ].
$$

Figure 6.9 shows some comparisons between probability density functions of a normal distribution and the distribution of Eq. (6.31). Both distributions have mean zero and variance $2 . 0 5 7 2 \times 1 0 ^ { - 4 }$ . The mean and variance are obtained by assuming that the return of the underlying asset satisfies $\mu = 2 0 \%$ per annum, $\sigma = 2 0 \%$ per annum, $\Delta t = 1 \ \mathrm { d a y } = 1 / 2 5 2$ year, $\lambda = 1 0$ , $\kappa = - 0 . 0 2$ , and $\eta = 0 . 0 2$ . In other words, we assume that there are about 10 daily jumps per year with average jump size $- 2 \%$ , and the jump size standard error is $2 \%$ . These values are reasonable for a U.S. stock. From the plots, the leptokurtic feature of the distribution derived from the jump diffusion process in Eq. (6.26) is clearly shown. The distribution has a higher peak and fatter tails than the corresponding normal distribution.

![](images/6a96c30193ea6f9fd00ed17fce633d61893968a4873c2c46c7363121f8963339.jpg)

![](images/f5772b8b0b23f8c3cbd71541d397a68058c2fdba29e53a01bfe27c6f18107d23.jpg)

![](images/235fbf1b539296f0a428eb4b216ec21b74c6ddfd5ad8d1f0b2e3b166ad46e260.jpg)

![](images/5f2ecacc3657b3712f516ffc4a1f5a1abfaa763b529c081672cd05d4af2590b1.jpg)  
Figure 6.9. Density comparisons between a normal distribution and the distribution of Eq. (6.31). The dotted line denotes the normal distribution. Both distributions have mean zero and variance $2 . 0 5 7 2 \times$ $1 0 ^ { - 4 }$ . (a) Overall comparison, (b) comparison of the peaks, (c) left tails, and (d) right tails.

# 6.9.1 Option Pricing Under Jump Diffusion

In the presence of random jumps, the market becomes incomplete. In this case, the standard hedging arguments are not applicable to price an option. But we can still derive an option pricing formula that does not depend on attitudes toward risk by assuming that the number of securities available is very large so that the risk of the sudden jumps is diversifiable and the market will therefore pay no risk premium over the risk-free rate for bearing this risk. Alternatively, for a given set of risk premiums, one can consider a risk-neutral measure $P ^ { * }$ such that

$$
\begin{array}{l} \frac {d P _ {t}}{P _ {t}} = [ r - \lambda E (J - 1) ] d t + \sigma d w _ {t} + d \left(\sum_ {i = 1} ^ {n _ {t}} \left(J _ {i} - 1\right)\right) \\ = (r - \lambda \psi) d t + \sigma d w _ {t} + d \left(\sum_ {i = 1} ^ {n _ {t}} \left(J _ {i} - 1\right)\right), \\ \end{array}
$$

where $r$ is the risk-free interest rate, $J = \exp ( X )$ such that $X$ follows the double exponential distribution of Eq. (6.27), $\psi = e ^ { \kappa } / ( 1 - \eta ^ { 2 } ) - 1 , 0 < \eta < 1$ $0 < \eta < 1$ , and the parameters $\kappa , \eta , \psi$ , and $\sigma$ become risk-neutral parameters taking consideration of the risk premiums; see Kou (2002) for more details. The unique solution of the

prior equation is given by

$$
P _ {t} = P _ {0} \exp \left[ \left(r - \frac {\sigma^ {2}}{2} - \lambda \psi\right) t + \sigma w _ {t} \right] \prod_ {i = 1} ^ {n _ {t}} J _ {i}.
$$

To price a European option in the jump diffusion model, it remains to compute the expectation, under the measure $P ^ { * }$ , of the discounted final payoff of the option. In particular, the price of a European call option at time $t$ is given by

$$
\begin{array}{l} c _ {t} = E _ {*} [ e ^ {- r (T - t)} (P _ {T} - K) _ {+} ] \\ = E _ {*} \left[ e ^ {- r (T - t)} \left(P _ {t} \exp \left[ \left(r - \sigma^ {2} / 2 - \lambda \psi\right) (T - t) + \sigma \sqrt {T - t} \epsilon \right] \prod_ {i = 1} ^ {n _ {T}} J _ {i} - K\right) _ {+} \right], \tag {6.32} \\ \end{array}
$$

where $T$ is the expiration time, $( T - t )$ is the time to expiration measured in years, $K$ is the strike price, $( y ) _ { + } = \operatorname* { m a x } ( 0 , y )$ , and $\epsilon$ is a standard normal random variable. Kou (2002) shows that $c _ { t }$ is analytically tractable as

$$
\begin{array}{l} c _ {t} = \sum_ {n = 1} ^ {\infty} \sum_ {j = 1} ^ {n} e ^ {- \lambda (T - t)} \frac {\lambda^ {n} (T - t) ^ {n}}{n !} \frac {2 ^ {j}}{2 ^ {2 n - 1}} \left( \begin{array}{c} 2 n - j - 1 \\ n - 1 \end{array} \right) (A _ {1, n, j} + A _ {2, n, j} + A _ {3, n, j}) \\ + e ^ {- \lambda (T - t)} \left[ P _ {t} e ^ {- \lambda \psi (T - t)} \Phi \left(h _ {+}\right) - K e ^ {- r (T - t)} \Phi \left(h _ {-}\right) \right], \tag {6.33} \\ \end{array}
$$

where $\Phi ( . )$ is the CDF of the standard normal random variable,

$$
A _ {1, n, j} = P _ {t} e ^ {- \lambda \psi (T - t) + n \kappa} \frac {1}{2} \left(\frac {1}{(1 - \eta) ^ {j}} + \frac {1}{(1 + \eta) ^ {j}}\right) \Phi (b _ {+}) - e ^ {- r (T - t)} K \Phi (b _ {-}),
$$

$$
\begin{array}{l} A _ {2, n, j} = \frac {1}{2} e ^ {- r (T - t) - \omega / \eta + \sigma^ {2} (T - t) / (2 \eta^ {2})} K \\ \times \sum_ {i = 0} ^ {j - 1} \left(\frac {1}{(1 - \eta) ^ {j - i}} - 1\right) \left(\frac {\sigma \sqrt {T - t}}{\eta}\right) ^ {i} \frac {1}{\sqrt {2 \pi}} H h _ {i} (c _ {-}), \\ \end{array}
$$

$$
\begin{array}{l} A _ {3, n, j} = \frac {1}{2} e ^ {- r (T - t) + \omega / \eta + \sigma^ {2} (T - t) / (2 \eta^ {2})} K \\ \times \sum_ {i = 0} ^ {j - 1} \left(1 - \frac {1}{(1 + \eta) ^ {j - i}}\right) \left(\frac {\sigma \sqrt {T - t}}{\eta}\right) ^ {i} \frac {1}{\sqrt {2 \pi}} H h _ {i} (c _ {+}), \\ \end{array}
$$

$$
b _ {\pm} = \frac {\ln (P _ {t} / K) + (r \pm \sigma^ {2} / 2 - \lambda \psi) (T - t) + n \kappa}{\sigma \sqrt {T - t}},
$$

$$
h _ {\pm} = \frac {\ln (P _ {t} / K) + (r \pm \sigma^ {2} / 2 - \lambda \psi) (T - t)}{\sigma \sqrt {T - t}},
$$

$$
c _ {\pm} = \frac {\sigma \sqrt {T - t}}{\eta} \pm \frac {\omega}{\sigma \sqrt {T - t}},
$$

$$
\omega = \ln (K / P _ {t}) + \lambda \psi (T - t) - (r - \sigma^ {2} / 2) (T - t) - n \kappa ,
$$

$$
\psi = \frac {e ^ {\kappa}}{1 - \eta^ {2}} - 1,
$$

and the $H h _ { i } ( . )$ functions are defined as

$$
H h _ {n} (x) = \frac {1}{n !} \int_ {x} ^ {\infty} (s - x) ^ {n} e ^ {- s ^ {2} / 2} d s, \quad n = 0, 1, \dots , \tag {6.34}
$$

and $H h _ { - 1 } ( x ) = \exp ( - x ^ { 2 } / 2 )$ , which is ${ \sqrt { 2 \pi } } f ( x )$ with $f ( x )$ being the probability density function of a standard normal random variable; see Abramowitz and Stegun (1972). The $H h _ { n } ( x )$ functions satisfy the recursion

$$
n H h _ {n} (x) = H h _ {n - 2} (x) - x H h _ {n - 1} (x), \quad n \geq 1, \tag {6.35}
$$

with starting values $H h _ { - 1 } ( x ) = e ^ { - x ^ { 2 } / 2 }$ and $H h _ { 0 } ( x ) = \sqrt { 2 \pi } \Phi ( - x )$

The pricing formula involves an infinite series, but its numerical value can be approximated quickly and accurately through truncation (e.g., the first 10 terms). Also, if $\lambda = 0$ (i.e., there are no jumps), then it is easily seen that $c _ { t }$ reduces to the Black–Scholes formula for a call option discussed before.

Finally, the price of a European put option under the jump diffusion model considered can be obtained by using the put–call parity; that is,

$$
p _ {t} = c _ {t} + K e ^ {- r (T - t)} - P _ {t}.
$$

Pricing formulas for other options under the jump diffusion model in Eq. (6.26) can be found in Kou (2002).

Example 6.8. Consider the stock of Example 6.6, which has a current price of $\$ 80$ . As before, assume that the strike price of a European option is $K = \$ 85$ and other parameters are $r = 0 . 0 8$ and $T - t = 0 . 2 5 .$ . In addition, assume that the price of the stock follows the jump diffusion model in Eq. (6.26) with parameters $\lambda = 1 0$ , $\kappa = - 0 . 0 2$ , and $\eta = 0 . 0 2$ . In other words, there are about 10 jumps per year with average jump size $- 2 \%$ and jump size standard error $2 \%$ . Using the formula in Eq. (6.33), we obtain $c _ { t } = \$ 3.92$ , which is higher than the $\$ 3.49$ of Example 6.6 when there are no jumps. The corresponding put option assumes the value $p _ { t } = \$ 3.31$ , which is also higher than what we had before. As expected, adding the jumps while keeping the other parameters fixed increases the prices of both European options. Keep in mind, however, that adding the jump process to the stock price in a real application often leads to different estimates for the stock volatility $\sigma$ .

# 6.10 ESTIMATION OF CONTINUOUS-TIME MODELS

Next, we consider the problem of estimating directly the diffusion equation (i.e., Ito process) from discretely sampled data. Here the drift and volatility functions $\mu ( x _ { t } , t )$ and $\sigma ( x _ { t } , t )$ are time-varying and may not follow a specific parametric form. This is a topic of considerable interest in recent years. Details of the available methods are beyond the scope of this chapter. Hence, we only outline the approaches proposed in the literature. Interested readers can consult the corresponding references and Lo (1988).

There are several approaches available for estimating a diffusion equation. The first approach is the quasi-maximum likelihood approach, which makes use of the fact that for a small time interval $d w _ { t }$ is normally distributed; see Kessler (1997) and the references therein. The second approach uses methods of moments; see Conley, Hansen, Luttmer, and Scheinkman (1997) and the references therein. The third approach uses nonparametric methods; see Ait-Sahalia (1996, 2002). The fourth approach uses semiparametric and reprojection methods; see Gallant and Long (1997) and Gallant and Tauchen (1997). Recently, many researchers have applied Markov chain Monte Carlo methods to estimate the diffusion equation; see Eraker (2001) and Elerian, Chib, and Shephard (2001).

# APPENDIX A: INTEGRATION OF BLACK–SCHOLES FORMULA

In this appendix, we derive the price of a European call option given in Eq. (6.19). Let $x = \ln ( P _ { T } )$ . By changing variable and using $g ( P _ { T } ) d P _ { T } = f ( x ) d x$ , where $f ( x )$ is the probability density function of $x$ , we have

$$
\begin{array}{l} c _ {t} = \exp [ - r (T - t) ] \int_ {K} ^ {\infty} \left(P _ {T} - K\right) g \left(P _ {T}\right) d P _ {t} \\ = e ^ {- r (T - t)} \int_ {\ln (K)} ^ {\infty} \left(e ^ {x} - K\right) f (x) d x \\ = e ^ {- r (T - t)} \left(\int_ {\ln (K)} ^ {\infty} e ^ {x} f (x) d x - K \int_ {\ln (K)} ^ {\infty} f (x) d x\right). \tag {6.36} \\ \end{array}
$$

Because $x = \ln ( P _ { T } ) \sim N [ \ln ( P _ { t } ) + ( r - \sigma ^ { 2 } / 2 ) ( T - t ) , \sigma ^ { 2 } ( T - t ) ]$ , the integration of the second term of Eq. (6.36) reduces to

$$
\begin{array}{l} \int_ {\ln (K)} ^ {\infty} f (x) d x = 1 - \int_ {- \infty} ^ {\ln (K)} f (x) d x \\ = 1 - \operatorname {C D F} (\ln (K)) \\ = 1 - \Phi (- h _ {-}) = \Phi (h _ {-}), \\ \end{array}
$$

where $\mathrm { C D F } ( \ln ( K ) )$ is the cumulative distribution function (CDF) of $x = \ln ( P _ { T } )$ evaluated at $\ln ( K ) , \Phi ( . )$ is the CDF of the standard normal random variable, and

$$
\begin{array}{l} - h _ {-} = \frac {\ln (K) - \ln (P _ {t}) - (r - \sigma^ {2} / 2) (T - t)}{\sigma \sqrt {T - t}} \\ = \frac {- \ln (P _ {t} / K) - (r - \sigma^ {2} / 2) (T - t)}{\sigma \sqrt {T - t}}. \\ \end{array}
$$

The integration of the first term of Eq. (6.36) can be written as

$$
\int_ {\ln (K)} ^ {\infty} \frac {1}{\sqrt {2 \pi} \sqrt {\sigma^ {2} (T - t)}} \exp \left(x - \frac {[ x - \ln (P _ {t}) - (r - \sigma^ {2} / 2) (T - t) ] ^ {2}}{2 \sigma^ {2} (T - t)}\right) d x,
$$

where the exponent can be simplified to

$$
\begin{array}{l} x - \frac {\{x - [ \ln (P _ {t}) + (r - \sigma^ {2} / 2) (T - t) ] \} ^ {2}}{2 \sigma^ {2} (T - t)} \\ = - \frac {\left\{x - \left[ \ln \left(P _ {t}\right) + (r + \sigma^ {2} / 2) (T - t) \right] \right\} ^ {2}}{2 \sigma^ {2} (T - t)} + \ln \left(P _ {t}\right) + r (T - t). \\ \end{array}
$$

Consequently, the first integration becomes

$$
\begin{array}{l} \int_ {\ln (K)} ^ {\infty} e ^ {x} f (x) d x = P _ {t} e ^ {r (T - t)} \int_ {\ln (K)} ^ {\infty} \frac {1}{\sqrt {2 \pi} \sqrt {\sigma^ {2} (T - t)}} \\ \times \exp \left(- \frac {\{x - [ \ln (P _ {t}) + (r + \sigma^ {2} / 2) (T - t) ] \} ^ {2}}{2 \sigma^ {2} (T - t)}\right) d x, \\ \end{array}
$$

which involves the CDF of a normal distribution with mean $\ln ( P _ { t } ) + ( r +$ $\sigma ^ { 2 } / 2 ) ( T - t )$ and variance $\sigma ^ { 2 } ( T - t )$ . By using the same techniques as those of the second integration shown before, we have

$$
\int_ {\ln (K)} ^ {\infty} e ^ {x} f (x) d x = P _ {t} e ^ {r (T - t)} \Phi (h _ {+}),
$$

where $h _ { + }$ is given by

$$
h _ {+} = \frac {\ln (P _ {t} / K) + (r + \sigma^ {2} / 2) (T - t)}{\sigma \sqrt {T - t}}.
$$

Putting the two integration results together, we have

$$
c _ {t} = e ^ {- r (T - t)} \left[ P _ {t} e ^ {r (T - t)} \Phi \left(h _ {+}\right) - K \Phi \left(h _ {-}\right) \right] = P _ {t} \Phi \left(h _ {+}\right) - K e ^ {- r (T - t)} \Phi \left(h _ {-}\right).
$$

# APPENDIX B: APPROXIMATION TO STANDARD NORMAL PROBABILITY

The CDF $\Phi ( x )$ of a standard normal random variable can be approximated by

$$
\Phi (x) = \left\{ \begin{array}{l l} 1 - f (x) [ c _ {1} k + c _ {2} k ^ {2} + c _ {3} k ^ {3} + c _ {4} k ^ {4} + c _ {5} k ^ {5} ] & \mathrm {i f} x \geq 0, \\ 1 - \Phi (- x) & \mathrm {i f} x <   0, \end{array} \right.
$$

where $f ( x ) = \exp ( - x ^ { 2 } / 2 ) / \sqrt { 2 \pi }$ , $k = 1 / ( 1 + 0 . 2 3 1 6 4 1 9 x )$ , $c _ { 1 } = 0 . 3 1 9 3 8 1 5 3 0$ , $c _ { 2 } = - 0 . 3 5 6 5 6 3 7 8 2$ , c3 = 1.781477937, $c _ { 4 } = - 1 . 8 2 1 2 5 5 9 7 8 .$ and $c _ { 5 } =$ 1.330274429.

For illustration, using the earlier approximation, we obtain $\Phi ( 1 . 9 6 ) = 0 . 9 7 5 0 0 2$ , $\Phi ( 0 . 8 2 ) = 0 . 7 9 3 8 9 2$ , and $\Phi ( - 0 . 6 1 ) = 0 . 2 7 0 9 3 1 .$ . These probabilities are very close to that obtained from a typical normal probability table.

# EXERCISES

6.1. Assume that the log price $p _ { t } = \ln ( P _ { t } )$ follows a stochastic differential equation

$$
d p _ {t} = \gamma d t + \sigma d w _ {t},
$$

where $w _ { t }$ is a Wiener process. Derive the stochastic equation for the price $P _ { t }$ .

6.2. Considering the forward price $F$ of a nondividend-paying stock, we have

$$
F _ {t, T} = P _ {t} e ^ {r (T - t)},
$$

where $r$ is the risk-free interest rate, which is constant, and $P _ { t }$ is the current stock price. Suppose $P _ { t }$ follows the geometric Brownian motion $d P _ { t } =$ $\mu P _ { t } d t + \sigma P _ { t } d w _ { t }$ . Derive a stochastic diffusion equation for $F _ { t , T }$ .

6.3. Assume that the price of IBM stock follows Ito process

$$
d P _ {t} = \mu P _ {t} d t + \sigma P _ {t} d w _ {t},
$$

where $\mu$ and $\sigma$ are constant and $w _ { t }$ is a standard Brownian motion. Consider the daily log returns of IBM stock in 1997. The average return and the sample standard deviation are 0.00131 and 0.02215, respectively. Use the data to estimate the parameters $\mu$ and $\sigma$ assuming that there were 252 trading days in 1997.

6.4. Suppose that the current price of a stock is $\$ 120$ per share with volatility $\sigma = 5 0 \%$ per annum. Suppose further that the risk-free interest rate is $7 \%$ per annum and the stock pays no dividend. (a) What is the price of a European call option contingent on the stock with a strike price of $\$ 125$ that will expire in 3 months? (b) What is the price of a European put option on the same stock with a strike price of $\$ 118$ that will expire in 3 months? If the volatility $\sigma$ is increased to $80 \%$ per annum, then what are the prices of the two options?

6.5. Derive the limiting marginal effects of the five variables $K , P _ { t } , T - t , \sigma$ $K$ $P _ { t }$ , and $r$ on a European put option contingent on a stock.   
6.6. A stock price is currently $\$ 60$ per share and follows the geometric Brownian motion $d P _ { t } = \mu P _ { t } d t + \sigma P _ { t } d t$ . Assume that the expected return $\mu$ from the stock is $20 \%$ per annum and its volatility is $40 \%$ per annum. What is the probability distribution for the stock price in 2 years? Obtain the mean and standard deviation of the distribution and construct a $9 5 \%$ confidence interval for the stock price.   
6.7. A stock price is currently $\$ 60$ per share and follows the geometric Brownian motion $d P _ { t } = \mu P _ { t } d t + \sigma P _ { t } d t$ . Assume that the expected return $\mu$ from the stock is $20 \%$ per annum and its volatility is $40 \%$ per annum. What is the probability distribution for the continuously compounded rate of return of the stock over 2 years? Obtain the mean and standard deviation of the distribution.   
6.8. Suppose that the current price of stock A is $\$ 70$ per share and the price follows the jump diffusion model in Eq. (6.26). Assume that the risk-free interest rate is $8 \%$ per annum, the stock pays no dividend, and its volatility $( \sigma )$ is $30 \%$ per annum. In addition, the price on average has about 15 jumps per year with average jump size $- 2 \%$ and jump volatility $3 \%$ . What is the price of a European call option with strike price $\$ 75$ that will expire in 3 months? What is the price of the corresponding European put option?   
6.9. Consider the European call option of a nondividend-paying stock. Suppose that $P _ { t } = \$ 20$ , $K = \$ 18$ , $r = 6 \%$ per annum, and $T - t = 0 . 5$ year. If the price of a European call option of the stock is $\$ 2.10$ , what opportunities are there for an arbitrageur?   
6.10. Consider the put option of a nondividend-paying stock. Suppose that $P _ { t } =$ $\$ 44$ , $K = \$ 47$ , $r = 6 \%$ per annum, and $T - t = 0 . 5$ year. If the European put option of the stock is selling at $\$ 1.00$ , what opportunities are there for an arbitrageur?

# REFERENCES

Abramowitz, M. and Stegun, I. A. (1972). Handbook of Mathematical Functions, 10th edition. U.S. National Bureau of Standards, Washington, DC.   
Ait-Sahalia, Y. (1996). Testing continuous-time models for the spot interest rate. Review of Financial Studies 9: 385–426.   
Ait-Sahalia, Y. (2002). Maximum likelihood estimation of discretely sampled diffusions: A closed-form approach. Econometrica 70: 223–262.   
Bakshi, G., Cao, C., and Chen, Z. (1997). Empirical performance of alternative option pricing models. Journal of Finance 52: 2003–2049.   
Billingsley, P. (1968). Convergence of Probability Measures. Wiley, Hoboken, NJ.   
Billingsley, P. (1986). Probability and Measure, 2nd edition. Wiley, Hoboken, NJ.

Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities. Journal of Political Economy 81: 637–654.   
Conley, T. G., Hansen, L. P., Luttmer, E. G. J., and Scheinkman, J. A. (1997). Short-term interest rates as subordinated diffusions. Review of Financial Studies 10: 525–577.   
Cox, J. C. and Rubinstein, M. (1985). Options Markets. Prentice Hall, Englewood Cliffs, NJ.   
Donsker, M. (1951). An invariance principle for certain probability limit theorems. Memoirs American Mathematical Society, No. 6.   
Duffie, D. (1995). Dynamic Asset Pricing Theory, 2nd edition. Princeton University Press, Princeton, NJ.   
Elerian, O., Chib, S., and Shephard, N. (2001). Likelihood inference for discretely observed non-linear diffusions. Econometrica 69: 959–993.   
Eraker, B. (2001). MCMC analysis of diffusion models with application to finance. Journal of Business & Economic Statistics 19: 177–191.   
Gallant, A. R. and Long, J. R. (1997). Estimating stochastic diffusion equations efficiently by minimum chi-squared. Biometrika 84: 125–141.   
Gallant, A. R. and Tauchen, G. (1997). The relative efficiency of method of moments estimators. Working paper, Economics Department, University of North Carolina.   
Hull, J. C. (2002). Options, Futures, and Other Derivatives, 5th edition. Prentice Hall, Upper Saddle River, NJ.   
Kessler, M. (1997). Estimation of an ergodic diffusion from discrete observations. Scandinavian Journal of Statistics 24: 1–19.   
Kou, S. (2002). A jump diffusion model for option pricing. Management Science 48: 1086–1101.   
Lo, A. W. (1988). Maximum likelihood estimation of generalized Ito’s processes with discretely sampled data. Econometric Theory 4: 231–247.   
Merton, R. C. (1976). Option pricing when the underlying stock returns are discontinuous. Journal of Financial Economics 5: 125–144.

# Extreme Values, Quantile Estimation, and Value at Risk

Extreme price movements in the financial markets are rare, but important. The stock market crash on Wall Street in October 1987 and other big financial crises such as the Long Term Capital Management have attracted a great deal of attention among practitioners and researchers, and some people even called for government regulations on the derivative markets. In recent years, the seemingly large daily price movements in high-tech stocks have further generated discussions on market risk and margin setting for financial institutions. As a result, value at risk (VaR) has become a widely used measure of market risk in risk management.

In this chapter, we discuss various methods for calculating VaR and the statistical theories behind these methods. In particular, we consider the extreme value theory developed in the statistical literature for studying rare (or extraordinary) events and its application to VaR. Both unconditional and conditional concepts of extreme values are discussed. The unconditional approach to VaR calculation for a financial position uses the historical returns of the instruments involved to compute VaR. However, a conditional approach uses the historical data and explanatory variables to calculate VaR.

Other approaches to VaR calculation discussed in the chapter are RiskMetrics, econometric modeling using volatility models, and empirical quantile. We use daily log returns of IBM stock to illustrate the actual calculation of all the methods discussed. The results obtained can therefore be used to compare the performance of different methods. Figure 7.1 shows the time plot of daily log returns of IBM stock from July 3, 1962 to December 31, 1998 for 9190 observations.

# 7.1 VALUE AT RISK

There are several types of risk in financial markets. Credit risk, operational risk, and market risk are the three main categories of financial risk. Value at risk (VaR)

![](images/ea6a8c2a2325e4da38213f42faf5a52b1b5105e30415c7d667741568f378ecd8.jpg)  
Figure 7.1. Time plot of daily log returns of IBM stock from July 3, 1962 to December 31, 1998.

is mainly concerned with market risk, but the concept is also applicable to other types of risk. VaR is a single estimate of the amount by which an institution’s position in a risk category could decline due to general market movements during a given holding period; see Duffie and Pan (1997) and Jorion (1997) for a general exposition of VaR. The measure can be used by financial institutions to assess their risks or by a regulatory committee to set margin requirements. In either case, VaR is used to ensure that the financial institutions can still be in business after a catastrophic event. From the viewpoint of a financial institution, VaR can be defined as the maximal loss of a financial position during a given time period for a given probability. In this view, one treats VaR as a measure of loss associated with a rare (or extraordinary) event under normal market conditions. Alternatively, from the viewpoint of a regulatory committee, VaR can be defined as the minimal loss under extraordinary market circumstances. Both definitions will lead to the same VaR measure, even though the concepts appear to be different.

In what follows, we define VaR under a probabilistic framework. Suppose that at the time index t we are interested in the risk of a financial position for the next  periods. Let $\Delta V ( \ell )$ be the change in value of the assets in the financial position from time $t$ to $t + \ell$ . This quantity is measured in dollars and is a random variable at the time index t. Denote the cumulative distribution function (CDF) of $\Delta V ( \ell )$ by $F _ { \ell } ( x )$ . We define the VaR of a long position over the time horizon  with probability $p$ as

$$
p = \Pr [ \Delta V (\ell) \leq \mathrm {V a R} ] = F _ {\ell} (\mathrm {V a R}). \tag {7.1}
$$

Since the holder of a long financial position suffers a loss when $\Delta V ( \ell ) < 0$ , the VaR defined in Eq. (7.1) typically assumes a negative value when $p$ is small. The negative sign signifies a loss. From the definition, the probability that the holder would encounter a loss greater than or equal to VaR over the time horizon $\ell$ is $p$ . Alternatively, VaR can be interpreted as follows. With probability $( 1 - p )$ , the potential loss encountered by the holder of the financial position over the time horizon  is less than or equal to VaR.

The holder of a short position suffers a loss when the value of the asset increases [i.e., $\Delta V ( \ell ) > 0 ]$ . The VaR is then defined as

$$
p = \Pr [ \Delta V (\ell) \geq \mathrm {V a R} ] = 1 - \Pr [ \Delta V (\ell) \leq \mathrm {V a R} ] = 1 - F _ {\ell} (\mathrm {V a R}).
$$

For a small $p$ , the VaR of a short position typically assumes a positive value. The positive sign signifies a loss.

The previous definitions show that VaR is concerned with tail behavior of the CDF $F _ { \ell } ( x )$ . For a long position, the left tail of $F _ { \ell } ( x )$ is important. Yet a short position focuses on the right tail of $F _ { \ell } ( x )$ . Notice that the definition of VaR in Eq. (7.1) continues to apply to a short position if one uses the distribution of $- \Delta V ( \ell )$ . Therefore, it suffices to discuss methods of VaR calculation using a long position.

For any univariate CDF $F _ { \ell } ( x )$ and probability $p$ , such that $0 < p < 1$ , the quantity

$$
x _ {p} = \inf  \{x \mid F _ {\ell} (x) \geq p \}
$$

is called the $p$ th quantile of $F _ { \ell } ( x )$ , where inf denotes the smallest real number satisfying $F _ { \ell } ( x ) \geq p$ . If the CDF $F _ { \ell } ( x )$ of Eq. (7.1) is known, then VaR is simply its $p$ th quantile (i.e., ${ \mathrm { V a R } } = x _ { p }$ ). The CDF is unknown in practice, however. Studies of VaR are essentially concerned with estimation of the CDF and/or its quantile, especially the tail behavior of the CDF.

In practical applications, calculation of VaR involves several factors:

1. The probability of interest $p$ , such as $p = 0 . 0 1$ or $p = 0 . 0 5$   
2. The time horizon . It might be set by a regulatory committee, such as 1 day or 10 days.   
3. The frequency of the data, which might not be the same as the time horizon . Daily observations are often used.   
4. The CDF $F _ { \ell } ( x )$ or its quantiles.   
5. The amount of the financial position or the mark-to-market value of the portfolio.

Among these factors, the CDF $F _ { \ell } ( x )$ is the focus of econometric modeling. Different methods for estimating the CDF give rise to different approaches to VaR calculation.

Remark. The definition of VaR in Eq. (7.1) is in dollar amount. Since log returns correspond approximately to percentage changes in value of a financial position, we use log returns $r _ { t }$ in data analysis. The VaR calculated from the quantile of the distribution of $r _ { t + 1 }$ given information available at time $t$ is therefore in percentage. The dollar amount of VaR is then the cash value of the financial position times the VaR of the log return series. That is, $\mathrm { V a R } = \mathrm { V a l u e } \times \mathrm { V a R } ( $ (of log returns). If necessary, one can also use the approximation ${ \mathrm { V a R } } = { \mathrm { V a l u e } } \times $ [exp(VaR of log returns)  1]. 

Remark. VaR is a prediction concerning possible loss of a portfolio in a given time horizon. It should be computed using the predictive distribution of future returns of the financial position. For example, the VaR for a 1-day horizon of a portfolio using daily returns $r _ { t }$ should be calculated using the predictive distribution of $r _ { t + 1 }$ given information available at time t . From a statistical viewpoint, predictive distribution takes into account the parameter uncertainty in a properly specified model. However, predictive distribution is hard to obtain, and most of the available methods for VaR calculation ignore the effects of parameter uncertainty. 

# 7.2 RiskMetrics

J. P. Morgan developed the RiskMetricsTM methodology to VaR calculation; see Longerstaey and More (1995). In its simple form, RiskMetrics assumes that the continuously compounded daily return of a portfolio follows a conditional normal distribution. Denote the daily log return by $r _ { t }$ and the information set available at time $t - 1$ by $F _ { t - 1 }$ . RiskMetrics assumes that $r _ { t } | F _ { t - 1 } \sim N ( \mu _ { t } , \sigma _ { t } ^ { 2 } )$ , where $\mu _ { t }$ is the conditional mean and $\sigma _ { t } ^ { 2 }$ is the conditional variance of $r _ { t }$ . In addition, the method assumes that the two quantities evolve over time according to the simple model:

$$
\mu_ {t} = 0, \quad \sigma_ {t} ^ {2} = \alpha \sigma_ {t - 1} ^ {2} + (1 - \alpha) r _ {t - 1} ^ {2}, \quad 1 > \alpha > 0. \tag {7.2}
$$

Therefore, the method assumes that the logarithm of the daily price, $p _ { t } = \ln ( P _ { t } )$ , of the portfolio satisfies the difference equation $p _ { t } - p _ { t - 1 } = a _ { t }$ , where $a _ { t } = \sigma _ { t } \epsilon _ { t }$ is an IGARCH(1,1) process without drift. The value of $\alpha$ is often in the interval (0.9, 1) with a typical value of 0.94.

A nice property of such a special random-walk IGARCH model is that the conditional distribution of a multiperiod return is easily available. Specifically, for a $k$ -period horizon, the log return from time $t + 1$ to time $t + k$ (inclusive) is $r _ { t } [ k ] = r _ { t + 1 } + \cdot \cdot \cdot + r _ { t + k - 1 } + r _ { t + k }$ . We use the square bracket $[ k ]$ to denote a $k$ - horizon return. Under the special IGARCH(1,1) model in Eq. (7.2), the conditional distribution $r _ { t } [ k ] | F _ { t }$ is normal with mean zero and variance $\sigma _ { t } ^ { 2 } [ k ]$ , where $\sigma _ { t } ^ { 2 } [ k ]$ can be computed using the forecasting method discussed in Chapter 3. Using the independence assumption of $\epsilon _ { t }$ and model (7.2), we have

$$
\sigma_ {t} ^ {2} [ k ] = \operatorname {V a r} (r _ {t} [ k ] | F _ {t}) = \sum_ {i = 1} ^ {k} \operatorname {V a r} (a _ {t + i} | F _ {t}),
$$

where $\mathrm { V a r } ( a _ { t + i } | F _ { t } ) = E ( \sigma _ { t + i } ^ { 2 } | F _ { t } )$ can be obtained recursively. Using $r _ { t - 1 } = a _ { t - 1 } =$ $\sigma _ { t - 1 } \epsilon _ { t - 1 }$ , we can rewrite the volatility equation of the IGARCH(1,1) model in Eq. (7.2) as

$$
\sigma_ {t} ^ {2} = \sigma_ {t - 1} ^ {2} + (1 - \alpha) \sigma_ {t - 1} ^ {2} \left(\epsilon_ {t - 1} ^ {2} - 1\right) \quad \text {f o r a l l} t.
$$

In particular, we have

$$
\sigma_ {t + i} ^ {2} = \sigma_ {t + i - 1} ^ {2} + (1 - \alpha) \sigma_ {t + i - 1} ^ {2} \left(\epsilon_ {t + i - 1} ^ {2} - 1\right) \quad \text {f o r} \quad i = 2, \dots , k.
$$

Since $E ( \epsilon _ { t + i - 1 } ^ { 2 } - 1 | F _ { t } ) = 0$ for $i \geq 2$ , the prior equation shows that

$$
E \left(\sigma_ {t + i} ^ {2} \mid F _ {t}\right) = E \left(\sigma_ {t + i - 1} ^ {2} \mid F _ {t}\right) \quad \text {f o r} \quad i = 2, \dots , k. \tag {7.3}
$$

For the 1-step ahead volatility forecast, Eq. (7.2) shows that $\sigma _ { t + 1 } ^ { 2 } = \alpha \sigma _ { t } ^ { 2 } + ( 1 -$ $\alpha ) r _ { t } ^ { 2 }$ . Therefore, Eq. (7.3) shows that $\mathrm { V a r } ( r _ { t + i } | F _ { t } ) = \sigma _ { t + 1 } ^ { 2 }$ for $i \geq 1$ t + − and, hence, $\sigma _ { t } ^ { 2 } [ k ] = k \sigma _ { t + 1 } ^ { 2 }$ . The results show that $r _ { t } [ k ] | F _ { t } \sim N ( 0 , k \sigma _ { t + 1 } ^ { 2 } )$ . Consequently, under the special IGARCH(1,1) model in Eq. (7.2) the conditional variance of $r _ { t } [ k ]$ is proportional to the time horizon $k$ . The conditional standard deviation of a $k$ -period horizon log return is then $\sqrt { k } \sigma _ { t + 1 }$ .

Suppose that the financial position is a long position so that loss occurs when there is a big price drop (i.e., a large negative return). If the probability is set to $5 \%$ , then RiskMetrics uses $1 . 6 5 \sigma _ { t + 1 }$ to measure the risk of the portfolio; that is, it uses the one-sided $5 \%$ quantile of a normal distribution with mean zero and standard deviation $\sigma _ { t + 1 }$ . The actual $5 \%$ quantile is $- 1 . 6 5 \sigma _ { t + 1 }$ , but the negative sign is ignored with the understanding that it signifies a loss. Consequently, if the standard deviation is measured in percentage, then the daily VaR of the portfolio under RiskMetrics is

$$
\mathrm {V a R} = \text {A m o u n t} \times 1. 6 5 \sigma_ {t + 1},
$$

and that of a $k$ -day horizon is

$$
\operatorname {V a R} (k) = \text {A m o u n t o f p o s i t i o n} \times 1. 6 5 \sqrt {k} \sigma_ {t + 1},
$$

where the argument $( k )$ of VaR is used to denote the time horizon. Consequently, under RiskMetrics, we have

$$
\operatorname {V a R} (k) = \sqrt {k} \times \operatorname {V a R}.
$$

This is referred to as the square root of time rule in VaR calculation under Risk-Metrics.

Example 7.1. The sample standard deviation of the continuously compounded daily return of the German mark/U.S. dollar exchange rate was about $0 . 5 3 \%$ in June 1997. Suppose that an investor was long in $\$ 10$ million worth of mark/dollar exchange rate contract. Then the $5 \%$ VaR for a 1-day horizon of the investor is

$$
\$ 10,000,000 \times (1.65 \times 0.0053) = \$ 87,450.
$$

The corresponding VaR for a 1-month horizon (30 days) is

$$
\$ 10,000,000 \times (\sqrt {3 0} \times 1. 6 5 \times 0. 0 0 5 3) \approx \$ 4 7 8, 9 8 3.
$$

Example 7.2. Consider the daily IBM log returns of Figure 7.1. As mentioned in Chapter 1, the sample mean of the returns is significantly different from zero. However, for demonstration of VaR calculation using RiskMetrics, we assume in this example that the conditional mean is zero and the volatility of the returns follows an IGARCH(1,1) model without drift. The fitted model is

$$
r _ {t} = a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \sigma_ {t} ^ {2} = 0. 9 3 9 6 \sigma_ {t - 1} ^ {2} + (1 - 0. 9 3 9 6) a _ {t - 1} ^ {2}, \tag {7.4}
$$

where $\left\{ \epsilon _ { t } \right\}$ is a standard Gaussian white noise series. As expected, this model is rejected by the $Q$ -statistics. For instance, we have a highly significant statistic $Q ( 1 0 ) = 5 6 . 1 9$ for the squared standardized residuals.

a and the fitted model, we have . Therefore, the 1-step ahead volatility $r \mathrm { 9 1 9 0 } = - 0 . 0 1 2 8$ $\hat { \sigma } _ { 9 1 9 0 } ^ { 2 } = 0 . 0 0 0 3 4 7 2$ $\hat { \sigma } _ { 9 1 9 0 } ^ { 2 } ( 1 ) =$ $5 \%$ $r _ { 9 1 9 1 } | F _ { 9 1 9 0 }$ $- 1 . 6 5 \times$ $\sqrt { 0 . 0 0 0 3 3 6 } = - 0 . 0 \dot { 3 } 0 2 5$ , where it is understood that the negative sign signifies a loss. Consequently, the 1-day horizon $5 \%$ VaR of a long position of $\$ 10$ million is

$$
\mathrm {V a R} = \$ 1 0, 0 0 0, 0 0 0 \times 0. 0 3 0 2 5 = \$ 3 0 2, 5 0 0.
$$

The $1 \%$ quantile is $- 2 . 3 2 6 2 \times { \sqrt { 0 . 0 0 0 3 3 6 } } = - 0 . 0 4 2 6 5$ , and the corresponding $1 \%$ VaR for the same long position is $\$ 426,500$ .

Remark. To implement RiskMetrics in S-Plus, one can use ewma1 (exponentially weighted moving-average of order 1) under the mgarch (multivariate GARCH) command to obtain the estimate of $1 - \alpha$ . Then, use the command predict to obtain volatility forecasts. For the IBM data used, the estimate of $\alpha$ is $1 - 0 . 0 3 6 = 0 . 9 6 4$ and the 1-step ahead volatility forecast is $\hat { \sigma } _ { 9 1 9 0 } ( 1 ) = 0 . 0 1 8 8 8$ . Please see the demonstration below. This leads to $\mathrm { V a R } = \ S 1 0 , 0 0 0 , 0 0 0 \times ( 1 . 6 5 \times$ $0 . 0 1 8 8 8 ) = \$ 31 1 , 5 2 0$ and $\mathrm { V a R } = \$ 439,187$ for $p = 0 . 0 5$ and 0.01, respectively. These two values are slightly higher than those of Example 7.2, which are based on estimates of the RATS package. 

# S-Plus Demonstration

Output simplified.

```txt
> ibm.risk=mgarch(IBM~-1, ~ewma1)
> ibm.risk
ALPHA 0.036
> predict(IBM.risk,2)
$sigma_pred 0.01888
```

# 7.2.1 Discussion

An advantage of RiskMetrics is simplicity. It is easy to understand and apply. Another advantage is that it makes risk more transparent in the financial markets. However, as security returns tend to have heavy tails (or fat tails), the normality assumption used often results in underestimation of VaR. Other approaches to VaR calculation avoid making such an assumption.

The square root of time rule is a consequence of the special model used by RiskMetrics. If either the zero mean assumption or the special IGARCH(1,1) model assumption of the log returns fails, then the rule is invalid. Consider the simple model

$$
\begin{array}{l} r _ {t} = \mu + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \mu \neq 0, \\ \sigma_ {t} ^ {2} = \alpha \sigma_ {t - 1} ^ {2} + (1 - \alpha) a _ {t - 1} ^ {2}, \\ \end{array}
$$

where $\left\{ \epsilon _ { t } \right\}$ is a standard Gaussian white noise series. The assumption that $\mu \neq 0$ holds for returns of many heavily traded stocks on the NYSE; see Chapter 1. For this simple model, the distribution of $r _ { t + 1 }$ given $F _ { t }$ is $N ( \mu , \sigma _ { t + 1 } ^ { 2 } )$ . The $5 \%$ quantile used to calculate the 1-period horizon VaR becomes $\mu - 1 . 6 5 \sigma _ { t + 1 }$ . For a $k$ -period horizon, the distribution of $r _ { t } [ k ]$ given $F _ { t }$ is $N ( k \mu , k \sigma _ { t + 1 } ^ { 2 } )$ , where as before $r _ { t } [ k ] =$ $r _ { t + 1 } + \cdot \cdot \cdot + r _ { t + k }$ . The $5 \%$ quantile used in the $k$ -period horizon VaR calculation is $k \mu - 1 . 6 5 \sqrt { k } \sigma _ { t + 1 } = \sqrt { k } ( \sqrt { k } \mu - 1 . 6 5 \sigma _ { t + 1 } )$ . Consequently, $\operatorname { V a R } ( k ) \neq { \sqrt { k } } \times \operatorname { V a R }$ when the mean return is not zero. It is also easy to show that the rule fails when the volatility model of the return is not an IGARCH(1,1) model without drift.

# 7.2.2 Multiple Positions

In some applications, an investor may hold multiple positions and needs to compute the overall VaR of the positions. RiskMetrics adopts a simple approach for doing such a calculation under the assumption that daily log returns of each position follow a random-walk IGARCH(1,1) model. The additional quantities needed are the cross-correlation coefficients between the returns. Consider the case of two positions. Let $\operatorname { V a R } _ { 1 }$ and $\operatorname { V a R } _ { 2 }$ be the VaR for the two positions and $\rho _ { 1 2 }$ be the cross-correlation coefficient between the two returns—that is, $\rho _ { 1 2 } = \mathrm { C o v } ( r _ { 1 t } , r _ { 2 t } ) / [ \mathrm { V a r } ( r _ { 1 t } ) \mathrm { V a r } ( r _ { 2 t } ) ] ^ { 0 . 5 }$ . Then the overall VaR of the investor is

$$
\mathrm {V a R} = \sqrt {\mathrm {V a R} _ {1} ^ {2} + \mathrm {V a R} _ {2} ^ {2} + 2 \rho_ {1 2} \mathrm {V a R} _ {1} \mathrm {V a R} _ {2}}.
$$

The generalization of VaR to a position consisting of $m$ instruments is straightforward as

$$
\mathrm {V a R} = \sqrt {\sum_ {i = 1} ^ {m} \mathrm {V a R} _ {i} ^ {2} + 2 \sum_ {i <   j} ^ {m} \rho_ {i j} \mathrm {V a R} _ {i} \mathrm {V a R} _ {j}},
$$

where $\rho _ { i j }$ is the cross-correlation coefficient between returns of the ith and $j$ th instruments and $\operatorname { V a R } _ { i }$ is the VaR of the ith instrument.

# 7.3 AN ECONOMETRIC APPROACH TO VaR CALCULATION

A general approach to VaR calculation is to use the time series econometric models of Chapters 2–4. For a log return series, the time series models of Chapter 2 can be used to model the mean equation, and the conditional heteroscedastic models of Chapter 3 or 4 are used to handle the volatility. For simplicity, we use GARCH models in our discussion and refer to the approach as an econometric approach to VaR calculation. Other volatility models, including the nonlinear ones in Chapter 4, can also be used.

Consider the log return $r _ { t }$ of an asset. A general time series model for $r _ { t }$ can be written as

$$
r _ {t} = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {t - i} + a _ {t} - \sum_ {j = 1} ^ {q} \theta_ {j} a _ {t - j}, \tag {7.5}
$$

$$
a _ {t} = \sigma_ {t} \epsilon_ {t},
$$

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \sum_ {i = 1} ^ {u} \alpha_ {i} a _ {t - i} ^ {2} + \sum_ {j = 1} ^ {v} \beta_ {j} \sigma_ {t - j} ^ {2}. \tag {7.6}
$$

Equations (7.5) and (7.6) are the mean and volatility equations for $r _ { t }$ . These two equations can be used to obtain 1-step ahead forecasts of the conditional mean and conditional variance of $r _ { t }$ assuming that the parameters are known. Specifically, we have

$$
\hat {r} _ {t} (1) = \phi_ {0} + \sum_ {i = 1} ^ {p} \phi_ {i} r _ {t + 1 - i} - \sum_ {j = 1} ^ {q} \theta_ {j} a _ {t + 1 - j},
$$

$$
\hat {\sigma} _ {t} ^ {2} (1) = \alpha_ {0} + \sum_ {i = 1} ^ {u} \alpha_ {i} a _ {t + 1 - i} ^ {2} + \sum_ {j = 1} ^ {v} \beta_ {j} \sigma_ {t + 1 - j} ^ {2}.
$$

If one further assumes that $\epsilon _ { t }$ is Gaussian, then the conditional distribution of $r _ { t + 1 }$ given the information available at time $t$ is N [rt (1), $\hat { \sigma } _ { t } ^ { 2 } ( 1 ) ]$ . Quantiles of this conditional distribution can easily be obtained for VaR calculation. For example, the $5 \%$ quantile is $\hat { r } _ { t } ( 1 ) - 1 . 6 5 \hat { \sigma } _ { t } ( 1 )$ . If one assumes that $\epsilon _ { t }$ is a standardized Student-$t$ distribution with $v$ degrees of freedom, then the quantile is $\hat { r } _ { t } ( 1 ) - t _ { v } ^ { * } ( p ) \hat { \sigma } _ { t } ( 1 )$ , where $t _ { v } ^ { * } ( p )$ is the $p$ th quantile of a standardized Student-t distribution with $v$ degrees of freedom.

The relationship between quantiles of a Student-t distribution with $v$ degrees of freedom, denoted by $t _ { v }$ , and those of its standardized distribution, denoted by $t _ { v } ^ { * }$ , is

$$
p = \operatorname * {P r} \left(t _ {v} \leq q\right) = \operatorname * {P r} \left(\frac {t _ {v}}{\sqrt {v / (v - 2)}} \leq \frac {q}{\sqrt {v / (v - 2)}}\right) = \operatorname * {P r} \left(t _ {v} ^ {*} \leq \frac {q}{\sqrt {v / (v - 2)}}\right),
$$

where $v > 2$ . That is, if $q$ is the $p$ th quantile of a Student-t distribution with $v$ degrees of freedom, then $q / \sqrt { v / ( v - 2 ) }$ is the $p$ th quantile of a standardized

Student- $\cdot t$ distribution with $v$ degrees of freedom. Therefore, if $\epsilon _ { t }$ of the GARCH model in Eq. (7.6) is a standardized Student-t distribution with $v$ degrees of freedom and the probability is $p$ , then the quantile used to calculate the 1-period horizon VaR at time index $t$ is

$$
\hat {r} _ {t} (1) + \frac {t _ {v} (p) \hat {\sigma} _ {t} (1)}{\sqrt {v / (v - 2)}},
$$

where $t _ { v } ( p )$ is the $p$ th quantile of a Student-t distribution with $v$ degrees of freedom and assumes a negative value for a small $p$ .

Example 7.3. Consider again the daily IBM log returns of Example 7.2. We use two volatility models to calculate VaR of 1-day horizon at $t = 9 1 9 0$ for a long position of $\$ 10$ million. These econometric models are reasonable based on the modeling techniques of Chapters 2 and 3.

Case 1. Assume that $\epsilon _ { t }$ is standard normal. The fitted model is

$$
\begin{array}{l} r _ {t} = 0. 0 0 0 6 6 - 0. 0 2 4 7 r _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 0 0 0 0 3 8 9 + 0. 0 7 9 9 a _ {t - 1} ^ {2} + 0. 9 0 7 3 \sigma_ {t} ^ {2}. \\ \end{array}
$$

From the data, we have $r _ { 9 1 8 9 } = - 0 . 0 0 2 0 1$ , $r _ { 9 1 9 0 } = - 0 . 0 1 2 8$ , and $\sigma _ { 9 1 9 0 } ^ { 2 } =$ 0.00033455. Consequently, the prior AR(2)–GARCH(1,1) model produces 1-step ahead forecasts as

$$
\hat {r} _ {9 1 9 0} (1) = 0. 0 0 0 7 1 \quad \text {a n d} \quad \hat {\sigma} _ {9 1 9 0} ^ {2} (1) = 0. 0 0 0 3 2 1 1.
$$

The $5 \%$ quantile is then

$$
0. 0 0 0 7 1 - 1. 6 4 4 9 \times \sqrt {0 . 0 0 0 3 2 1 1} = - 0. 0 2 8 7 7,
$$

where it is understood that the negative sign denotes the left tail of the conditional normal distribution. The VaR for a long position of $\$ 10$ million with probability 0.05 is ${ \mathrm { V a R } } = \ S 1 0 , 0 0 0 , 0 0 0 \times 0 . 0 2 8 7 7 = \ S 2 8 7 , 7 0 0$ . The result shows that, with probability $9 5 \%$ , the potential loss of holding that position next day is $\$ 287,200$ or less assuming that the AR(2)–GARCH(1,1) model holds. If the probability is 0.01, then the $1 \%$ quantile is

$$
0. 0 0 0 7 1 - 2. 3 2 6 2 \times \sqrt {0 . 0 0 0 3 2 1 1} = - 0. 0 4 0 9 7 3 8.
$$

The VaR for the position becomes $\$ 409,738$ .

Case 2. Assume that $\epsilon _ { t }$ is a standardized Student-t distribution with 5 degrees of freedom. The fitted model is

$$
\begin{array}{l} r _ {t} = 0. 0 0 0 3 - 0. 0 3 3 5 r _ {t - 2} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 0. 0 0 0 0 0 3 + 0. 0 5 5 9 a _ {t - 1} ^ {2} + 0. 9 3 5 0 \sigma_ {t - 1} ^ {2}. \\ \end{array}
$$

From the data, we have $r _ { 9 1 8 9 } = - 0 . 0 0 2 0 1$ , $r \mathrm { 9 1 9 0 } = - 0 . 0 1 2 8$ , and $\sigma _ { 9 1 9 0 } ^ { 2 } = 0 . 0 0 0 3 4 9$ Consequently, the prior Student- $\cdot t$ AR(2)–GARCH(1,1) model produces 1-step ahead forecasts

$$
\hat {r} _ {9 1 9 0} (1) = 0. 0 0 0 3 6 7 \quad \text {a n d} \quad \hat {\sigma} _ {9 1 9 0} ^ {2} (1) = 0. 0 0 0 3 3 8 6.
$$

The $5 \%$ quantile of a Student-t distribution with 5 degrees of freedom is $- 2 . 0 1 5$ and that of its standardized distribution is $- 2 . 0 1 5 / \sqrt { 5 / 3 } = - 1 . 5 6 0 8$ . Therefore, the $5 \%$ quantile of the conditional distribution of r9191 given $F _ { 9 1 9 0 }$ is

$$
0. 0 0 0 3 6 7 - 1. 5 6 0 8 \sqrt {0 . 0 0 0 3 3 8 6} = - 0. 0 2 8 3 5 4.
$$

The VaR for a long position of $\$ 10$ million is

$$
\mathrm {V a R} = \$ 1 0, 0 0 0, 0 0 0 \times 0. 0 2 8 3 5 2 = \$ 2 8 3, 5 2 0,
$$

which is essentially the same as that obtained under the normality assumption. The $1 \%$ quantile of the conditional distribution is

$$
0. 0 0 0 3 6 7 - (3. 3 6 4 9 / \sqrt {5 / 3}) \sqrt {0 . 0 0 0 3 3 8 6} = - 0. 0 4 7 5 9 4 3.
$$

The corresponding VaR is $\$ 475,943$ . Comparing with that of Case 1, we see the heavy-tail effect of using a Student-t distribution with 5 degrees of freedom; it increases the VaR when the tail probability becomes smaller. In S-Plus, the quantile of a Student- $\cdot t$ distribution with m degrees of freedom can be obtained by $\begin{array} { r l } { \mathrm { x p } } & { { } = } \end{array}$ qt(p,m), for example, $\mathbf { x p } ~ = ~ \mathsf { q t } \left( 0 . 0 1 , 5 . 2 3 \right)$ .

# 7.3.1 Multiple Periods

Suppose that at time $h$ we want to compute the $k$ -horizon VaR of an asset whose log return is $r _ { t }$ . The variable of interest is the $k$ -period log return at the forecast origin $h$ (i.e., $r _ { h } [ k ] = r _ { h + 1 } + \cdot \cdot \cdot + r _ { h + k } )$ . If the return $r _ { t }$ follows the time series model in Eqs. (7.5) and (7.6), then the conditional mean and variance of $r _ { h } [ k ]$ given the information set $F _ { h }$ can be obtained by the forecasting methods discussed in Chapters 2 and 3.

# Expected Return and Forecast Error

The conditional mean $E ( r _ { h } [ k ] | F _ { h } )$ can be obtained by the forecasting method of ARMA models in Chapter 2. Specifically, we have

$$
\hat {r} _ {h} [ k ] = r _ {h} (1) + \dots + r _ {h} (k),
$$

where $r _ { h } ( \ell )$ is the -step ahead forecast of the return at the forecast origin $h$ . These forecasts can be computed recursively as discussed in Section 2.6.4. Using the MA representation

$$
r _ {t} = \mu + a _ {t} + \psi_ {1} a _ {t - 1} + \psi_ {2} a _ {t - 2} + \dots
$$

of the ARMA model in Eq. (7.5), we can write the -step ahead forecast error at the forecast origin $h$ a s

$$
e _ {h} (\ell) = r _ {h + \ell} - r _ {h} (\ell) = a _ {h + \ell} + \psi_ {1} a _ {h + \ell - 1} + \dots + \psi_ {\ell - 1} a _ {h + 1};
$$

see Eq. (2.33) and the associated forecast error. The forecast error of the expected $k$ -period return $\hat { r } _ { h } [ k ]$ is the sum of 1-step to $k$ -step forecast errors of $r _ { t }$ at the forecast origin $h$ and can be written as

$$
\begin{array}{l} e _ {h} [ k ] = e _ {h} (1) + e _ {h} (2) + \dots + e _ {h} (k) \\ = a _ {h + 1} + \left(a _ {h + 2} + \psi_ {1} a _ {h + 1}\right) + \dots + \sum_ {i = 0} ^ {k - 1} \psi_ {i} a _ {h + k - i} \\ = a _ {h + k} + \left(1 + \psi_ {1}\right) a _ {h + k - 1} + \dots + \left(\sum_ {i = 0} ^ {k - 1} \psi_ {i}\right) a _ {h + 1}, \tag {7.7} \\ \end{array}
$$

where $\psi _ { 0 } = 1$ .

# Expected Volatility

The volatility forecast of the $k$ -period return at the forecast origin $h$ is the conditional variance of $e _ { h } [ k ]$ given $F _ { h }$ . Using the independent assumption of $\epsilon _ { t + i }$ for $i = 1 , \ldots , k$ , where $a _ { t + i } = \sigma _ { t + i } \epsilon _ { t + i }$ , we have

$$
\begin{array}{l} \mathrm {V} _ {h} \left(e _ {h} [ k ]\right) = \mathrm {V} _ {h} \left(a _ {h + k}\right) + \left(1 + \psi_ {1}\right) ^ {2} \mathrm {V} _ {h} \left(a _ {h + k - 1}\right) + \dots + \left(\sum_ {i = 0} ^ {k - 1} \psi_ {i}\right) ^ {2} \mathrm {V} _ {h} \left(a _ {h + 1}\right) \\ = \sigma_ {h} ^ {2} (k) + (1 + \psi_ {1}) ^ {2} \sigma_ {h} ^ {2} (k - 1) + \dots + \left(\sum_ {i = 0} ^ {k - 1} \psi_ {i}\right) ^ {2} \sigma_ {h} ^ {2} (1), \tag {7.8} \\ \end{array}
$$

where $\mathrm { V } _ { h } ( z )$ denotes the conditional variance of z given $F _ { h }$ and $\sigma _ { h } ^ { 2 } ( \ell )$ is the -step ahead volatility forecast at the forecast origin $h$ . If the volatility model is the GARCH model in Eq. (7.6), then these volatility forecasts can be obtained recursively by the methods discussed in Chapter 3.

As an illustration, consider the special time series model

$$
r _ {t} = \mu + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t},
$$

$$
\sigma_ {t} ^ {2} = \alpha_ {0} + \alpha_ {1} a _ {t - 1} ^ {2} + \beta_ {1} \sigma_ {t - 1} ^ {2}.
$$

Then we have $\psi _ { i } = 0$ for all $i > 0$ . The point forecast of the $k$ -period return at the forecast origin $h$ is $\hat { r } _ { h } [ k ] = k \mu$ and the associated forecast error is

$$
e _ {h} [ k ] = a _ {h + k} + a _ {h + k - 1} + \dots + a _ {h + 1}.
$$

Consequently, the volatility forecast for the $k$ -period return at the forecast origin $h$ is

$$
\operatorname {V a r} (e _ {h} [ k ] | F _ {h}) = \sum_ {\ell = 1} ^ {k} \sigma_ {h} ^ {2} (\ell).
$$

Using the forecasting method of GARCH(1,1) models in Section 3.5, we have

$$
\begin{array}{l} \sigma_ {h} ^ {2} (1) = \alpha_ {0} + \alpha_ {1} a _ {h} ^ {2} + \beta_ {1} \sigma_ {h} ^ {2}, \\ \sigma_ {h} ^ {2} (\ell) = \alpha_ {0} + \left(\alpha_ {1} + \beta_ {1}\right) \sigma_ {h} ^ {2} (\ell - 1), \quad \ell = 2, \dots , k. \tag {7.9} \\ \end{array}
$$

Using Eq. (7.9), we obtain that for the case of $\psi _ { i } = 0$ for $i > 0$ ,

$$
\operatorname {V a r} \left(e _ {h} [ k ] \mid F _ {h}\right) = \frac {\alpha_ {0}}{1 - \phi} \left[ k - \frac {1 - \phi^ {k}}{1 - \phi} \right] + \frac {1 - \phi^ {k}}{1 - \phi} \sigma_ {h} ^ {2} (1), \tag {7.10}
$$

where $\phi = \alpha _ { 1 } + \beta _ { 1 } < 1 .$ . If $\psi _ { i } \neq 0$ for some $i > 0$ , then one should use the general formula of $\mathrm { V a r } ( e _ { h } [ k ] | F _ { h } )$ in Eq. (7.8). If $\epsilon _ { t }$ is Gaussian, then the conditional distribution of $r _ { h } [ k ]$ given $F _ { h }$ is normal with mean $k \mu$ and variance $\mathrm { V a r } ( e _ { h } [ k ] | F _ { h } )$ . The quantiles needed in VaR calculation are readily available. If the conditional distribution of $a _ { t }$ is not Gaussian (e.g., a Student- $\cdot t$ or generalized error distribution), simulation can be used to obtain the multiperiod VaR.

Example 7.3 (Continued). Consider the Gaussian AR(2)–GARCH(1,1) model of Example 7.3 for the daily log returns of IBM stock. Suppose that we are interested in the VaR of a 15-day horizon starting at the forecast origin 9190 (i.e., December 31, 1998). We can use the fitted model to compute the conditional mean and variance for the 15-day log return via $r _ { 9 1 9 0 } [ 1 5 ] = \textstyle \sum _ { i = 1 } ^ { 1 5 } r _ { 9 1 9 0 + i }$ given $F _ { 9 1 9 0 }$ . The conditional mean is 0.00998 and the conditional variance is 0.0047948, which is obtained by the recursion in Eq. (7.9). The $5 \%$ quantile of the conditional distribution is then $0 . 0 0 9 9 8 - 1 . 6 4 4 9 \sqrt { 0 . 0 0 4 7 9 4 8 } = - \bar { 0 . 1 0 3 9 } 1 9 1$ . Consequently, the 15-day horizon VaR for a long position of $\$ 10$ million is $\mathrm { V a R } = \ S 1 0 , 0 0 0 , 0 0 0 \times 0 . 1 0 3 9 1 9 1 = \ S 1 , 0 3 9 , 1 9 1$ . This amount is smaller than $\$ 287,700\times \sqrt { 15 } = \$ 1,114,257$ . This example further demonstrates that the square root of time rule used by RiskMetrics holds only for the special white noise IGARCH(1,1) model used. When the conditional mean is not zero, proper steps must be taken to compute the $k$ -horizon VaR.

# 7.4 QUANTILE ESTIMATION

Quantile estimation provides a nonparametric approach to VaR calculation. It makes no specific distributional assumption on the return of a portfolio except that the distribution continues to hold within the prediction period. There are two types of quantile methods. The first method is to use empirical quantile directly, and the second method uses quantile regression.

# 7.4.1 Quantile and Order Statistics

Assuming that the distribution of return in the prediction period is the same as that in the sample period, one can use the empirical quantile of the return $r _ { t }$ to calculate VaR. Let $r _ { 1 } , \ldots , r _ { n }$ be the returns of a portfolio in the sample period. The order statistics of the sample are these values arranged in increasing order. We use the notation

$$
r _ {(1)} \leq r _ {(2)} \leq \dots \leq r _ {(n)}
$$

to denote the arrangement and refer to $r _ { ( i ) }$ as the ith order statistic of the sample. In particular, $r _ { ( 1 ) }$ is the sample minimum and $r _ { ( n ) }$ the sample maximum.

Assume that the returns are independent and identically distributed random variables that have a continuous distribution with probability density function (pdf) $f ( x )$ and CDF $F ( x )$ . Then we have the following asymptotic result from the statistical literature (e.g., Cox and Hinkley, 1974, Appendix 2), for the order statistic $r _ { \left( \ell \right) }$ , where $\ell = n p$ with $0 < p < 1$ .

Result. Let $x _ { p }$ be the $p$ th quantile of $F ( x )$ , that is, $x _ { p } = F ^ { - 1 } ( p )$ . Assume that the pdf $f ( x )$ is not zero at $x _ { p }$ (i.e., $f ( x _ { p } ) \neq 0 )$ ). Then the order statistic $r _ { \left( \ell \right) }$ is asymptotically normal with mean $x _ { p }$ and variance $p ( 1 - p ) / [ n f ^ { 2 } ( x _ { p } ) ]$ . That is,

$$
r _ {(\ell)} \sim N \left[ x _ {p}, \frac {p (1 - p)}{n [ f (x _ {p}) ] ^ {2}} \right], \quad \ell = n p. \tag {7.11}
$$

Based on the prior result, one can use $r _ { \left( \ell \right) }$ to estimate the quantile $x _ { p }$ , where $\ell = n p$ . In practice, the probability of interest $p$ may not satisfy that $n p$ is a positive integer. In this case, one can use simple interpolation to obtain quantile estimates. More specifically, for noninteger $n p$ , let $\ell _ { 1 }$ and $\ell _ { 2 }$ be the two neighboring positive integers such that $\ell _ { 1 } < n p < \ell _ { 2 }$ . Define $p _ { i } = \ell _ { i } / n$ . The previous result shows that $r _ { ( \ell _ { i } ) }$ is a consistent estimate of the quantile $x _ { p _ { i } }$ . From the definition, $p _ { 1 } < p < p _ { 2 }$ . Therefore, the quantile $x _ { p }$ can be estimated by

$$
\hat {x} _ {p} = \frac {p _ {2} - p}{p _ {2} - p _ {1}} r _ {(\ell_ {1})} + \frac {p - p _ {1}}{p _ {2} - p _ {1}} r _ {(\ell_ {2})}. \tag {7.12}
$$

Example 7.4. Consider the daily log returns of Intel stock from December 15, 1972 to December 31, 1997. There are 6329 observations. The empirical $5 \%$ quantile of the data can be obtained as

$$
\hat {x} _ {0.05} = 0.55 r _ {(316)} + 0.45 r _ {(317)} = - 4.229 \%,
$$

where $n p = 6 3 2 9 \times 0 . 0 5 = 3 1 6 . 4 5$ and $r _ { ( i ) }$ is the ith order statistic of the sample. In this particular instance, $r _ { ( 3 1 6 ) } = - 4 . 2 3 7 \%$ and $r _ { ( 3 1 7 ) } = - 4 . 2 2 0 \%$ . Here we use the lower tail of the empirical distribution because it is relevant to holding a long position in VaR calculation.

Example 7.5. Consider again the daily log returns of IBM stock from July 3, 1962 to December 31, 1998. Using all 9190 observations, the empirical $5 \%$ quantile can be obtained as $( r _ { ( 4 5 9 ) } + r _ { ( 4 6 0 ) } ) / 2 = - 0 . 0 2 1 6 0 3$ , where $r _ { ( i ) }$ is the ith order statistic and $n p = 9 1 9 0 \times 0 . 0 5 = 4 5 9 . 5$ . The VaR of a long position of $\$ 10$ million is $\$ 216,030$ , which is much smaller than those obtained by the econometric approach discussed before. Because the sample size is 9190, we have $9 1 < 9 1 9 0 \times 0 . 0 1 <$ 92. Let $p _ { 1 } = 9 1 / 9 1 9 0 = 0 . 0 0 9 9$ and $p _ { 2 } = 9 2 / 9 1 9 0 = 0 . 0 1 0 0 1$ . The empirical $1 \%$ quantile can be obtained as

$$
\begin{array}{l} \hat {x} _ {0. 0 1} = \frac {p _ {2} - 0 . 0 1}{p _ {2} - p _ {1}} r _ {(9 1)} + \frac {0 . 0 1 - p _ {1}}{p _ {2} - p _ {1}} r _ {(9 2)} \\ = \frac {0 . 0 0 0 0 1}{0 . 0 0 0 1 1} (- 3. 6 5 8) + \frac {0 . 0 0 0 1}{0 . 0 0 0 1 1} (- 3. 6 5 7) \\ \approx - 3. 6 5 7. \\ \end{array}
$$

The $1 \%$ 1-day horizon VaR of the long position is $\$ 365,709$ . Again this amount is lower than those obtained before by other methods.

Discussion. Advantages of using the prior quantile method to VaR calculation include (a) simplicity and (b) using no specific distributional assumption. However, the approach has several drawbacks. First, it assumes that the distribution of the return $r _ { t }$ remains unchanged from the sample period to the prediction period. Given that VaR is concerned mainly with tail probability, this assumption implies that the predicted loss cannot be greater than that of the historical loss. It is definitely not so in practice. Second, for extreme quantiles (i.e., when $p$ is close to zero or unity), the empirical quantiles are not efficient estimates of the theoretical quantiles. Third, the direct quantile estimation fails to take into account the effect of explanatory variables that are relevant to the portfolio under study. In real application, VaR obtained by the empirical quantile can serve as a lower bound for the actual VaR. 

# 7.4.2 Quantile Regression

In real application, one often has explanatory variables available that are important to the problem under study. For example, the action taken by Federal Reserve Banks on interest rates could have important impacts on the returns of U.S. stocks. It is then more appropriate to consider the distribution function $r _ { t + 1 } | F _ { t }$ , where $F _ { t }$ includes the explanatory variables. In other words, we are interested in the quantiles of the distribution function of $r _ { t + 1 }$ given $F _ { t }$ . Such a quantile is referred to as a regression quantile in the literature; see Koenker and Bassett (1978).

To understand regression quantile, it is helpful to cast the empirical quantile of the previous subsection as an estimation problem. For a given probability $p$ , the $p$ th quantile of $\{ r _ { t } \}$ is obtained by

$$
\hat {x} _ {p} = \operatorname {a r g m i n} _ {\beta} \sum_ {i = 1} ^ {n} w _ {p} (r _ {i} - \beta),
$$

where $w _ { p } ( z )$ is defined by

$$
w _ {p} (z) = \left\{ \begin{array}{l l} p z & \text {i f} z \geq 0, \\ (p - 1) z & \text {i f} z <   0. \end{array} \right.
$$

Regression quantile is a generalization of such an estimate.

To see the generalization, suppose that we have the linear regression

$$
r _ {t} = \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t} + a _ {t}, \tag {7.13}
$$

where $\beta$ is a $k$ -dimensional vector of parameters and $\scriptstyle { x _ { t } }$ is a vector of predictors that are elements of $F _ { t - 1 }$ . The conditional distribution of $r _ { t }$ given $F _ { t - 1 }$ is a translation of the distribution of $a _ { t }$ because $\beta ^ { \prime } x _ { t }$ is known. Viewing the problem this way, Koenker and Bassett (1978) suggest estimating the conditional quantile $x _ { p } | F _ { t - 1 }$ of $r _ { t }$ given $F _ { t - 1 }$ as

$$
\hat {x} _ {p} \left| F _ {t - 1} \equiv \inf  \left\{\boldsymbol {\beta} _ {o} ^ {\prime} \boldsymbol {x} \mid R _ {p} \left(\boldsymbol {\beta} _ {o}\right) = \min  \right\}, \right. \tag {7.14}
$$

where ${ } ^ { \bullet } R _ { p } ( \beta _ { o } ) = \operatorname* { m i n } ^ { \prime }$ means that $\beta _ { o }$ is obtained by

$$
\boldsymbol {\beta} _ {o} = \operatorname {a r g m i n} _ {\boldsymbol {\beta}} \sum_ {t = 1} ^ {n} w _ {p} \left(r _ {t} - \boldsymbol {\beta} ^ {\prime} x _ {t}\right),
$$

where $w _ { p } ( . )$ is defined as before. A computer program to obtain such an estimated quantile can be found in Koenker and D’Orey (1987).

# 7.5 EXTREME VALUE THEORY

In this section, we review some extreme value theory in the statistical literature. Denote the return of an asset, measured in a fixed time interval such as daily, by $r _ { t }$ . Consider the collection of $n$ returns, $\{ r _ { 1 } , \ldots , r _ { n } \}$ . The minimum return of the collection is $r _ { ( 1 ) }$ , that is, the smallest order statistic, whereas the maximum return is $r _ { ( n ) }$ , the maximum order statistic. Specifically, $r _ { ( 1 ) } = \mathrm { m i n } _ { 1 \leq j \leq n } \{ r _ { j } \}$ and $r _ { ( n ) } = \mathrm { m a x } _ { 1 \leq j \leq n } \{ r _ { j } \}$ . We focus on properties of the minimum return $r _ { ( 1 ) }$ because this minimum is highly relevant to VaR calculation for a long position. However, the theory discussed also applies to the maximum return of an asset over a given time period because properties of the maximum return can be obtained from those of the minimum by a simple sign change. Specifically, we have $r _ { ( n ) } =$ $- \mathrm { m i n } _ { 1 \le j \le n } \{ - r _ { j } \} = - r _ { ( 1 ) } ^ { c }$ , where $r _ { t } ^ { c } = - r _ { t }$ with the superscript $c$ denoting sign change. The maximum return is relevant to holding a short financial position.

# 7.5.1 Review of Extreme Value Theory

Assume that the returns $r _ { t }$ are serially independent with a common cumulative distribution function $F ( x )$ and that the range of the return $r _ { t }$ is $[ l , u ]$ . For log

returns, we have $l = - \infty$ and $u = \infty$ . Then the CDF of $r _ { ( 1 ) }$ , denoted by $F _ { n , 1 } ( x )$ , is given by

$$
\begin{array}{l} F _ {n, 1} (x) = \Pr [ r _ {(1)} \leq x ] = 1 - \Pr [ r _ {(1)} > x ] \\ = 1 - \Pr \left(r _ {1} > x, r _ {2} > x, \dots , r _ {n} > x\right) \\ = 1 - \prod_ {j = 1} ^ {n} \Pr \left(r _ {j} > x\right) \quad (\text {b y}) \\ = 1 - \prod_ {j = 1} ^ {n} [ 1 - \Pr (r _ {j} \leq x) ] \\ = 1 - \prod_ {j = 1} ^ {n} [ 1 - F (x) ] \quad (\text {b y}) \\ = 1 - [ 1 - F (x) ] ^ {n}. \tag {7.15} \\ \end{array}
$$

In practice, the CDF $F ( x )$ of $r _ { t }$ is unknown and, hence, $F _ { n , 1 } ( x )$ of $r _ { ( 1 ) }$ is unknown. However, as $n$ increases to infinity, $F _ { n , 1 } ( x )$ becomes degenerated—namely, $F _ { n , 1 } ( x ) \to 0$ if $x \le l$ and $F _ { n , 1 } ( x ) \to 1$ if $x > l$ as $n$ goes to infinity. This degenerated CDF has no practical value. Therefore, the extreme value theory is concerned with finding two sequences $\{ \beta _ { n } \}$ and $\{ \alpha _ { n } \}$ , where $\alpha _ { n } > 0$ , such that the distribution of $r _ { ( 1 * ) } \equiv ( r _ { ( 1 ) } - \beta _ { n } ) / \alpha _ { n }$ converges to a nondegenerated distribution as $n$ goes to infinity. The sequence $\{ \beta _ { n } \}$ is a location series and $\{ \alpha _ { n } \}$ is a series of scaling factors. Under the independent assumption, the limiting distribution of the normalized minimum $r _ { ( 1 * ) }$ is given by

$$
F _ {*} (x) = \left\{ \begin{array}{l l} 1 - \exp [ - (1 + k x) ^ {1 / k} ] & \text {i f} k \neq 0, \\ 1 - \exp [ - \exp (x) ] & \text {i f} k = 0, \end{array} \right. \tag {7.16}
$$

for $x < - 1 / k$ if $k < 0$ and for $x > - 1 / k$ if $k > 0$ , where the subscript $^ *$ signifies the minimum. The case of $k = 0$ is taken as the limit when $k  0$ . The parameter $k$ is referred to as the shape parameter that governs the tail behavior of the limiting distribution. The parameter $\alpha = - 1 / k$ is called the tail index of the distribution.

The limiting distribution in Eq. (7.16) is the generalized extreme value (GEV) distribution of Jenkinson (1955) for the minimum. It encompasses the three types of limiting distribution of Gnedenko (1943):

• Type I: $k = 0$ , the Gumbel family. The CDF is

$$
F _ {*} (x) = 1 - \exp [ - \exp (x) ], \quad - \infty <   x <   \infty . \tag {7.17}
$$

• Type II: $k < 0$ , the Frechet family. The CDF is ´

$$
F _ {*} (x) = \left\{ \begin{array}{l l} 1 - \exp [ - (1 + k x) ^ {1 / k} ] & \text {i f} x <   - 1 / k, \\ 1 & \text {o t h e r w i s e .} \end{array} \right. \tag {7.18}
$$

• Type III: $k > 0$ , the Weibull family. The CDF here is

$$
F _ {*} (x) = \left\{ \begin{array}{l l} 1 - \exp [ - (1 + k x) ^ {1 / k} ] & \text {i f} x > - 1 / k, \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

Gnedenko (1943) gave necessary and sufficient conditions for the CDF $F ( x )$ of $r _ { t }$ to be associated with one of the three types of limiting distribution. Briefly speaking, the tail behavior of $F ( x )$ determines the limiting distribution $F _ { * } ( x )$ of the minimum. The (left) tail of the distribution declines exponentially for the Gumbel family, by a power function for the Frechet family, and is finite for the Weibull ´ family (Figure 7.2). Readers are referred to Embrechts, Kuppelberg, and Mikosch (1997) for a comprehensive treatment of the extreme value theory. For risk management, we are mainly interested in the Frechet family that includes stable and ´ Student-t distributions. The Gumbel family consists of thin-tailed distributions such as normal and lognormal distributions. The probability density function (pdf) of the generalized limiting distribution in Eq. (7.16) can be obtained easily by differentiation:

$$
f _ {*} (x) = \left\{ \begin{array}{l l} (1 + k x) ^ {1 / k - 1} \exp [ - (1 + k x) ^ {1 / k} ] & \text {i f} k \neq 0, \\ \exp [ x - \exp (x) ] & \text {i f} k = 0, \end{array} \right. \tag {7.19}
$$

where $- \infty < x < \infty$ for $k = 0$ , $x < - 1 / k$ for $k < 0$ , and $x > - 1 / k$ for $k > 0$ .

![](images/cd9483d3b9c23fe8ef98fa1e1b6595a48f462a52177adf3f4813ea5394f1001c.jpg)  
Figure 7.2. Probability density functions of extreme value distributions for minimum. The solid line is for a Gumbel distribution, the dotted line is for the Weibull distribution with $k = 0 . 5$ , and the dashed line is for the Frechet distribution with ´ $k = - 0 . 9$ .

The aforementioned extreme value theory has two important implications. First, the tail behavior of the CDF $F ( x )$ of $r _ { t }$ , not the specific distribution, determines the limiting distribution $F _ { * } ( x )$ of the (normalized) minimum. Thus, the theory is generally applicable to a wide range of distributions for the return $r _ { t }$ . The sequences $\{ \beta _ { n } \}$ and $\{ \alpha _ { n } \}$ , however, may depend on the CDF $F ( x )$ . Second, Feller (1971, p. 279) shows that the tail index $k$ does not depend on the time interval of $r _ { t }$ . That is, the tail index (or equivalently the shape parameter) is invariant under time aggregation. This second feature of the limiting distribution becomes handy in the VaR calculation.

The extreme value theory has been extended to serially dependent observations $\{ r _ { t } \} _ { t = 1 } ^ { n }$ provided that the dependence is weak. Berman (1964) shows that the same form of the limiting extreme value distribution holds for stationary normal sequences provided that the autocorrelation function of $r _ { t }$ is squared summable (i.e., $\textstyle \sum _ { i = 1 } ^ { \infty } \rho _ { i } ^ { 2 } < \infty ,$ ), where $\rho _ { i }$ is the lag-i autocorrelation function of $r _ { t }$ . For further results concerning the effect of serial dependence on the extreme value theory, readers are referred to Leadbetter, Lindgren, and Rootzen (1983, Chapter 3). ´

# 7.5.2 Empirical Estimation

The extreme value distribution contains three parameters— $k$ , $\beta _ { n }$ , and $\alpha _ { n }$ . These parameters are referred to as the shape, location, and scale parameters, respectively. They can be estimated by using either parametric or nonparametric methods. We review some of the estimation methods.

For a given sample, there is only a single minimum or maximum, and we cannot estimate the three parameters with only an extreme observation. Alternative ideas must be used. One of the ideas used in the literature is to divide the sample into subsamples and apply the extreme value theory to the subsamples. Assume that there are $T$ returns $\{ r _ { j } \} _ { j = 1 } ^ { T }$ available. We divide the sample into $g$ non-overlapping subsamples each with $n$ observations, assuming for simplicity that $T = n g$ . In other words, we divide the data as

$$
\left\{r _ {1}, \dots , r _ {n} \mid r _ {n + 1}, \dots , r _ {2 n} \mid r _ {2 n + 1}, \dots , r _ {3 n} \right\} \dots \left| r _ {(g - 1) n + 1}, \dots , r _ {n g} \right\rbrace
$$

and write the observed returns as $r _ { i n + j }$ , where $1 \leq j \leq n$ and $i = 0 , \ldots , g - 1$ . Note that each subsample corresponds to a subperiod of the data span. When $n$ is sufficiently large, we hope that the extreme value theory applies to each subsample. In application, the choice of $n$ can be guided by practical considerations. For example, for daily returns, $n = 2 1$ corresponds approximately to the number of trading days in a month and $n = 6 3$ denotes the number of trading days in a quarter.

Let $r _ { n , i }$ be the minimum of the ith subsample (i.e., $r _ { n , i }$ is the smallest return of the ith subsample), where the subscript $n$ is used to denote the size of the subsample. When $n$ is sufficiently large, $x _ { n , i } = ( r _ { n , i } - \beta _ { n } ) / \alpha _ { n }$ should follow an extreme value distribution, and the collection of subsample minima $\{ r _ { n , i } | i = 1 , \ldots , g \}$ can then be regarded as a sample of $g$ observations from that extreme value distribution. Specifically, we define

$$
r _ {n, i} = \min  _ {1 \leq j \leq n} \left\{r _ {(i - 1) n + j} \right\}, \quad i = 1, \dots , g. \tag {7.20}
$$

The collection of subsample minima $\{ r _ { n , i } \}$ are the data we use to estimate the unknown parameters of the extreme value distribution. Clearly, the estimates obtained may depend on the choice of subperiod length $n$ .

# The Parametric Approach

Two parametric approaches are available. They are the maximum likelihood and regression methods.

# Maximum Likelihood Method

Assuming that the subperiod minima $\{ r _ { n , i } \}$ follow a generalized extreme value distribution such that the pdf of $x _ { i } = ( r _ { n , i } - \beta _ { n } ) / \alpha _ { n }$ is given in Eq. (7.19), we can obtain the pdf of $r _ { n , i }$ by a simple transformation as

$$
\begin{array}{l} f (r _ {n, i}) = \\ \left\{ \begin{array}{l l} \frac {1}{\alpha_ {n}} \left(1 + \frac {k _ {n} (r _ {n , i} - \beta_ {n})}{\alpha_ {n}}\right) ^ {1 / k _ {n} - 1} \exp \left[ - \left(1 + \frac {k _ {n} (r _ {n , i} - \beta_ {n})}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right] & \text {i f} k _ {n} \neq 0, \\ \frac {1}{\alpha_ {n}} \exp \left[ \frac {r _ {n , i} - \beta_ {n}}{\alpha_ {n}} - \exp \left(\frac {r _ {n , i} - \beta_ {n}}{\alpha_ {n}}\right) \right] & \text {i f} k _ {n} = 0, \end{array} \right. \\ \end{array}
$$

where it is understood that $1 + k _ { n } ( r _ { n , i } - \beta _ { n } ) / \alpha _ { n } > 0$ if ${ { k } _ { n } } \neq 0$ . The subscript $n$ is added to the shape parameter $k$ to signify that its estimate depends on the choice of $n$ . Under the independence assumption, the likelihood function of the subperiod minima is

$$
\ell \left(r _ {n, 1}, \dots , r _ {n, g} \mid k _ {n}, \alpha_ {n}, \beta_ {n}\right) = \prod_ {i = 1} ^ {g} f \left(r _ {n, i}\right).
$$

Nonlinear estimation procedures can then be used to obtain maximum likelihood estimates of $k _ { n }$ , $\beta _ { n }$ , and $\alpha _ { n }$ . These estimates are unbiased, asymptotically normal, and of minimum variance under proper assumptions. See Embrechts et al. (1997) and Coles (2001) for details. We apply this approach to some stock return series later.

# Regression Method

This method assumes that $\{ r _ { n , i } \} _ { i = 1 } ^ { g }$ is a random sample from the generalized extreme value distribution in Eq. (7.16) and makes use of properties of order statistics; see Gumbel (1958). Denote the order statistics of the subperiod minima $\{ r _ { n , i } \} _ { i = 1 } ^ { g }$ as

$$
r _ {n (1)} \leq r _ {n (2)} \leq \dots \leq r _ {n (g)}.
$$

Using properties of order statistics (e.g., Cox and Hinkley, 1974, p. 467), we have

$$
E \left\{F _ {*} \left[ r _ {n (i)} \right] \right\} = \frac {i}{g + 1}, \quad i = 1, \dots , g. \tag {7.21}
$$

For simplicity, we separate the discussion into two cases depending on the value of $k$ . First, consider the case of $k \neq 0$ . From Eq. (7.16), we have

$$
F _ {*} \left[ r _ {n (i)} \right] = 1 - \exp \left[ - \left(1 + k _ {n} \frac {r _ {n (i)} - \beta_ {n}}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right]. \tag {7.22}
$$

Consequently, using Eqs. (7.21) and (7.22) and approximating expectation by an observed value, we have

$$
\frac {i}{g + 1} = 1 - \exp \left[ - \left(1 + k _ {n} \frac {r _ {n (i)} - \beta_ {n}}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right].
$$

Therefore,

$$
\exp \left[ - \left(1 + k _ {n} \frac {r _ {n (i)} - \beta_ {n}}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right] = 1 - \frac {i}{g + 1} = \frac {g + 1 - i}{g + 1}, \quad i = 1, \dots , g.
$$

Taking the natural logarithm twice, the prior equation gives

$$
\ln \left[ - \ln \left(\frac {g + 1 - i}{g + 1}\right) \right] = \frac {1}{k _ {n}} \ln \left(1 + k _ {n} \frac {r _ {n (i)} - \beta_ {n}}{\alpha_ {n}}\right), \quad i = 1, \dots , g.
$$

In practice, letting $e _ { i }$ be the deviation between the previous two quantities and assuming that the series $\{ e _ { t } \}$ is not serially correlated, we have a regression setup

$$
\ln \left[ - \ln \left(\frac {g + 1 - i}{g + 1}\right) \right] = \frac {1}{k _ {n}} \ln \left(1 + k _ {n} \frac {r _ {n (i)} - \beta_ {n}}{\alpha_ {n}}\right) + e _ {i}, \quad i = 1, \dots , g. \tag {7.23}
$$

The least squares estimates of $k _ { n } , \beta _ { n }$ , and $\alpha _ { n }$ can be obtained by minimizing the sum of squares of $e _ { i }$ .

When $k _ { n } = 0$ , the regression setup reduces to

$$
\ln \left[ - \ln \left(\frac {g + 1 - i}{g + 1}\right) \right] = \frac {1}{\alpha_ {n}} r _ {n (i)} - \frac {\beta_ {n}}{\alpha_ {n}} + e _ {i}, \quad i = 1, \ldots , g.
$$

The least squares estimates are consistent but less efficient than the likelihood estimates. We use the likelihood estimates in this chapter.

# The Nonparametric Approach

The shape parameter $k$ can be estimated using some nonparametric methods. We mention two such methods here. These two methods are proposed by Hill (1975) and Pickands (1975) and are referred to as the Hill estimator and Pickands estimator,

respectively. Both estimators apply directly to the returns $\{ r _ { t } \} _ { t = 1 } ^ { T }$ . Thus, there is no need to consider subsamples. Denote the order statistics of the sample as

$$
r _ {(1)} \leq r _ {(2)} \leq \dots \leq r _ {(T)}.
$$

Let $q$ be a positive integer. The two estimators of $k$ are defined as

$$
k _ {p} (q) = - \frac {1}{\ln (2)} \ln \left(\frac {- r _ {(q)} + r _ {(2 q)}}{- r _ {(2 q)} + r _ {(4 q)}}\right), \tag {7.24}
$$

$$
k _ {h} (q) = \frac {- 1}{q} \sum_ {i = 1} ^ {q} \left[ \ln \left(- r _ {(i)}\right) - \ln \left(- r _ {(q + 1)}\right) \right], \tag {7.25}
$$

where the argument $( q )$ is used to emphasize that the estimators depend on $q$ . The choice of $q$ differs between Hill and Pickands estimators. It has been investigated by several researchers, but there is no general consensus on the best choice available. Dekkers and De Haan (1989) show that $k _ { p } ( q )$ is consistent if $q$ increases at a properly chosen pace with the sample size $T$ . In addition, $\sqrt { q } [ k _ { p } ( q ) - k ]$ is asymptotically normal with mean zero and variance $k ^ { 2 } ( 2 ^ { - 2 k + 1 } + 1 ) / [ 2 ( 2 ^ { - k } - 1 ) \ln ( 2 ) ] ^ { 2 }$ . The Hill estimator is applicable to the Frechet distribution only, but it is more effi- ´ cient than the Pickands estimator when applicable. Goldie and Smith (1987) show that $\sqrt { q } [ k _ { h } ( q ) - k ]$ is asymptotically normal with mean zero and variance $k ^ { 2 }$ . In practice, one may plot the Hill estimator $k _ { h } ( q )$ against $q$ and find a proper $q$ such that the estimate appears to be stable. The estimated tail index $\alpha = - 1 / k _ { h } ( q )$ can then be used to obtain extreme quantiles of the return series; see Zivot and Wang (2003).

# 7.5.3 Application to Stock Returns

We apply the extreme value theory to the daily log returns of IBM stock from July 3, 1962 to December 31, 1998. The returns are measured in percentages, and the sample size is 9190 (i.e., $T = 9 1 9 0$ ). Figure 7.3 shows the time plots of extreme daily log returns when the length of the subperiod is 21 days, which corresponds approximately to a month. The October 1987 crash is clearly seen from the plot. Excluding the 1987 crash, the range of extreme daily log returns is between $0 . 5 \%$ and $13 \%$ .

Table 7.1 summarizes some estimation results of the shape parameter $k$ via the Hill estimator. Three choices of $q$ are reported in the table, and the results are stable. To provide an overall picture of the performance of the Hill estimator, Figure 7.4 shows the scatterplots of the Hill estimator $k _ { h } ( q )$ against $q$ . For both positive and negative extreme daily log returns, the estimator is stable except for cases when $q$ is small. The estimated shape parameters are about $- 0 . 3 0$ and are significantly different from zero at the asymptotic $5 \%$ level. The plots also indicate that the shape parameter $k$ appears to be smaller for the negative extremes, indicating that the daily log return may have a heavier left tail. Overall, the result indicates that

![](images/9f7d6f881f930ba23a2c9dc3ff73cca6d38698440fd2a5440d7bc7ff3e90670e.jpg)  
(a) Monthly maximum log returns

![](images/2f762ad5ec151e3830a9b9506decc9f758c1fc4845dbde16b39b0ba54f0d0132.jpg)  
(b) Monthly minimum log returns   
Figure 7.3. Maximum and minimum daily log returns of IBM stock when the subperiod is 21 trading days. The data span is from July 3, 1962 to December 31, 1998: (a) positive returns and (b) negative returns.

Table 7.1. Results of the Hill Estimatora for Daily Log Returns of IBM Stock from July 3, 1962 to December 31, 1998   

<table><tr><td>q</td><td>190</td><td>200</td><td>210</td></tr><tr><td>Maximum</td><td>-0.300(0.022)</td><td>-0.297(0.021)</td><td>-0.303(0.021)</td></tr><tr><td>Minimum</td><td>-0.290(0.021)</td><td>-0.292(0.021)</td><td>-0.289(0.020)</td></tr></table>

aStandard errors are in parentheses.

the distribution of daily log returns of IBM stock belongs to the Frechet family. ´ The analysis thus rejects the normality assumption commonly used in practice. Such a conclusion is in agreement with that of Longin (1996), who used a U.S. stock market index series. In S-Plus, the Hill estimator can be obtained using the command hill, for example,

ibm.hill $=$ hill(ibm,option=’xi’,end=500).

Next, we apply the maximum likelihood method to estimate parameters of the generalized extreme value distribution for IBM daily log returns. Table 7.2 summarizes the estimation results for different choices of the length of subperiods ranging

![](images/79761e3414ead4491e74598515ddcbc433f35f3164eee9c027efce3fee012876.jpg)  
(a) Upper (or right) tail

![](images/7aef44d267c7628e7ad34aeac015b52565fe16a408d98a042b8ee5ec64584df7.jpg)  
(b) Lower (or left) tail   
Figure 7.4. Scatterplots of the Hill estimator for the daily log returns of IBM stock. The sample period is from July 3, 1962 to December 31, 1998: (a) positive returns and (b) negative returns.

from 1 month $( n = 2 1$ ) to 1 year $n = 2 5 2$ ). From the table, we make the following observations:

• Estimates of the location and scale parameters $\beta _ { n }$ and $\alpha _ { n }$ increase in modulus as $n$ increases. This is expected as magnitudes of the subperiod minimum and maximum are nondecreasing functions of $n$ .   
• Estimates of the shape parameter (or equivalently the tail index) are stable for the negative extremes when $n \geq 6 3$ and are approximately $- 0 . 3 3$ .   
• Estimates of the shape parameter are less stable for the positive extremes. The estimates are smaller in magnitude but remain significantly different from zero.   
• The results for $n = 2 5 2$ have higher variabilities as the number of subperiods $g$ is relatively small.

Again the conclusion obtained is similar to that of Longin (1996), who provided a good illustration of applying the extreme value theory to stock market returns.

The results of Table 7.2 were obtained using a Fortran program developed by Professor Richard Smith and modified by the author. S-Plus can also be used to perform the estimation. I demonstrate below the commands used in analyzing the minimal returns of subperiods of 21 trading days. Note that the returns are multiplied by $- 1 0 0$ because (a) S-Plus focuses on the right-hand tail of a distribution

Table 7.2. Maximum Likelihood Estimatesa of the Extreme Value Distribution for Daily Log Returns of IBM Stock from July 3, 1962 to December 31, 1998   

<table><tr><td>Length of Subperiod</td><td>Scale αn</td><td>Location βn</td><td>Shape kn</td></tr><tr><td colspan="4">Minimal Returns</td></tr><tr><td>1 month (n = 21, g = 437)</td><td>0.823(0.035)</td><td>-1.902(0.044)</td><td>-0.197(0.036)</td></tr><tr><td>1 quarter (n = 63, g = 145)</td><td>0.945(0.077)</td><td>-2.583(0.090)</td><td>-0.335(0.076)</td></tr><tr><td>6 months (n = 126, g = 72)</td><td>1.147(0.131)</td><td>-3.141(0.153)</td><td>-0.330(0.101)</td></tr><tr><td>1 year (n = 252, g = 36)</td><td>1.542(0.242)</td><td>-3.761(0.285)</td><td>-0.322(0.127)</td></tr><tr><td colspan="4">Maximal Returns</td></tr><tr><td>1 month (n = 21, g = 437)</td><td>0.931(0.039)</td><td>2.184(0.050)</td><td>-0.168(0.036)</td></tr><tr><td>1 quarter (n = 63, g = 145)</td><td>1.157(0.087)</td><td>3.012(0.108)</td><td>-0.217(0.066)</td></tr><tr><td>6 months (n = 126, g = 72)</td><td>1.292(0.158)</td><td>3.471(0.181)</td><td>-0.349(0.130)</td></tr><tr><td>1 year (n = 252, g = 36)</td><td>1.624(0.271)</td><td>4.475(0.325)</td><td>-0.264(0.186)</td></tr></table>

aStandard errors are in parentheses.

and (b) the returns used are in percentages. Furthermore, (xi, sigma, mu) in S-Plus corresponds to $( - k _ { n } , \alpha _ { n } , \beta _ { n } )$ of the table. The estimates obtained by S-Plus are close to those in Table 7.2.

# S-Plus Demonstration of GEV Estimation

Return series is ibm.

```diff
> length.ibm)  
[1] 9190  
> grp=floor(9190/21)  
> grp  
[1] 437  
> for (i in 1:grp){  
+ jend=9190-(i-1)*21  
+ jst=jend-21+1  
+ xmin[i]=min.ibm[jst:jend])  
+ }  
> y=xmin*(-100)  
> nibm.gev.21=gev(y)  
> names(nibm.gev.21)  
[1] "n.all" "n" "call" "block" "data"  
[6] "par.estss" "par.ses" "varcov" "converged" "nllh.final"  
> nibm.gev.21\$par.estss  
xi sigma mu  
0.1953325 0.8187631 1.921797  
> nibm.gev.21\$par.estss  
xi sigma mu  
0.03539358 0.03456347 0.04387343 
```

![](images/1937a07266cf4cfe04787889ccb28f76ffe2661bd8bd7eb374d242b76e3afa36.jpg)

![](images/3eecac3ed659ce963c536f748239713fba01b259b4e10dcc23602e9c245cd9bd.jpg)  
Figure 7.5. Residual plots from fitting a GEV distribution to daily negative IBM log returns, in percentage, for data from July 3, 1962 to December 31, 1998 with a subperiod length of 21 days.

```txt
> plot(nibm.gev.21)  
Make a plot selection (or 0 to exit):  
1: plot: Scatterplot of Residuals  
2: plot: QQplot of Residuals  
Selection: 
```

Define the residuals of a GEV distribution fit as

$$
w _ {i} = \left(1 + k _ {n} \frac {r _ {n , i} - \beta_ {n}}{\alpha_ {n}}\right) ^ {1 / k _ {n}}.
$$

Using the pdf of the GEV distribution and transformation of variables, one can easily show that $\{ w _ { i } \}$ should form an iid random sample of exponentially distributed random variables if the fitted model is correctly specified. Figure 7.5 shows the residual plots of the GEV distribution fit to the daily negative IBM log returns with subperiod length of 21 days. The left panel gives the residuals and the right panel shows a quantile-to-quantile (QQ) plot against an exponential distribution. The plots indicate that the fit is reasonable.

# 7.6 EXTREME VALUE APPROACH TO VaR

In this section, we discuss an approach to VaR calculation using the extreme value theory. The approach is similar to that of Longin (1999a,b), who proposed an

eight-step procedure for the same purpose. We divide the discussion into two parts. The first part is concerned with parameter estimation using the method discussed in the previous subsections. The second part focuses on VaR calculation by relating the probabilities of interest associated with different time intervals.

# Part I

Assume that there are $T$ observations of an asset return available in the sample period. We partition the sample period into $g$ nonoverlapping subperiods of length $n$ such that $T = n g$ . If $T = n g + m$ with $1 \leq m < n$ , then we delete the first m observations from the sample. The extreme value theory discussed in the previous section enables us to obtain estimates of the location, scale, and shape parameters $\beta _ { n }$ , $\alpha _ { n }$ , and $k _ { n }$ for the subperiod minima $\{ r _ { n , i } \}$ . Plugging the maximum likelihood estimates into the CDF in Eq. (7.16) with $x = ( r - \beta _ { n } ) / \alpha _ { n }$ , we can obtain the quantile of a given probability of the generalized extreme value distribution. Because we focus on holding a long financial position, the lower probability (or left) quantiles are of interest. Let $p ^ { * }$ be a small probability that indicates the potential loss of a long position and $r _ { n } ^ { * }$ be the $p ^ { * }$ th quantile of the subperiod minimum under the limiting generalized extreme value distribution. Then we have

$$
p ^ {*} = \left\{ \begin{array}{l l} 1 - \exp \left[ - \left(1 + \frac {k _ {n} (r _ {n} ^ {*} - \beta_ {n})}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right] & \mathrm {i f} k _ {n} \neq 0, \\ 1 - \exp \left[ - \exp \left(\frac {r _ {n} ^ {*} - \beta_ {n}}{\alpha_ {n}}\right) \right] & \mathrm {i f} k _ {n} = 0, \end{array} \right.
$$

where it is understood that $1 + k _ { n } ( r _ { n } ^ { * } - \beta _ { n } ) / \alpha _ { n } > 0$ for ${ { k } _ { n } } \neq 0$ . Rewriting this equation as

$$
\ln (1 - p ^ {*}) = \left\{ \begin{array}{l l} - \left(1 + \frac {k _ {n} (r _ {n} ^ {*} - \beta_ {n})}{\alpha_ {n}}\right) ^ {1 / k _ {n}} & \mathrm {i f} k _ {n} \neq 0, \\ - \exp \left(\frac {r _ {n} ^ {*} - \beta_ {n}}{\alpha_ {n}}\right) & \mathrm {i f} k _ {n} = 0, \end{array} \right.
$$

we obtain the quantile as

$$
r _ {n} ^ {*} = \left\{ \begin{array}{l l} \beta_ {n} - \frac {\alpha_ {n}}{k _ {n}} \left\{1 - \left[ - \ln \left(1 - p ^ {*}\right) \right] ^ {k _ {n}} \right\} & \text {i f} k _ {n} \neq 0, \\ \beta_ {n} + \alpha_ {n} \ln \left[ - \ln \left(1 - p ^ {*}\right) \right] & \text {i f} k _ {n} = 0. \end{array} \right. \tag {7.26}
$$

In financial applications, the case of ${ { k } _ { n } } \neq 0$ is of major interest.

# Part II

For a given lower (or left tail) probability $p ^ { * }$ , the quantile $r _ { n } ^ { * }$ of Eq. (7.26) is the VaR based on the extreme value theory for the subperiod minima. The next step is to make explicit the relationship between subperiod minima and the observed return $r _ { t }$ series.

Because most asset returns are either serially uncorrelated or have weak serial correlations, we may use the relationship in Eq. (7.15) and obtain

$$
p ^ {*} = P \left(r _ {n, i} \leq r _ {n} ^ {*}\right) = 1 - \left[ 1 - P \left(r _ {t} \leq r _ {n} ^ {*}\right) \right] ^ {n}
$$

or, equivalently,

$$
1 - p ^ {*} = \left[ 1 - P \left(r _ {t} \leq r _ {n} ^ {*}\right) \right] ^ {n}. \tag {7.27}
$$

This relationship between probabilities allows us to obtain VaR for the original asset return series $r _ { t }$ . More precisely, for a specified small lower probability $p$ , the $p$ th quantile of $r _ { t }$ is $r _ { n } ^ { * }$ if the probability $p ^ { * }$ is chosen based on Eq. (7.27), where $p = P ( r _ { t } \leq r _ { n } ^ { * } )$ . Consequently, for a given small probability $p$ , the VaR of holding a long position in the asset underlying the log return $r _ { t }$ is

$$
\mathrm {V a R} = \left\{ \begin{array}{l l} \beta_ {n} - \frac {\alpha_ {n}}{k _ {n}} \left\{1 - \left[ - n \ln (1 - p) \right] ^ {k _ {n}} \right\} & \text {i f} k _ {n} \neq 0, \\ \beta_ {n} + \alpha_ {n} \ln [ - n \ln (1 - p) ] & \text {i f} k _ {n} = 0, \end{array} \right. \tag {7.28}
$$

where $n$ is the length of subperiod.

# Summary

We summarize the approach of applying the traditional extreme value theory to VaR calculation as follows:

1. Select the length of the subperiod $n$ and obtain subperiod minima $\{ r _ { n , i } \}$ $i = 1 , \ldots , g$ , where $g = [ T / n ]$ .   
2. Obtain the maximum likelihood estimates of $\beta _ { n }$ $\beta _ { n } , \alpha _ { n }$ , and $k _ { n }$ .   
3. Check the adequacy of the fitted extreme value model; see the next section for some methods of model checking.   
4. If the extreme value model is adequate, apply Eq. (7.28) to calculate VaR.

Remark. Since we focus on holding a long financial position and, hence, on the quantile in the left tail of a return distribution, the quantile is negative. Yet it is customary in practice to use a positive number for VaR calculation. Thus, in using Eq. (7.28), one should be aware that the negative sign signifies a loss. 

Example 7.6. Consider the daily log return, in percentage, of IBM stock from July 7, 1962 to December 31, 1998. From Table 7.2, we have $\hat { \alpha } _ { n } = 0 . 9 4 5$ $\hat { \beta } _ { n } = - \hat { 2 . 5 8 3 }$ , and $\hat { k } _ { n } = - 0 . 3 3 5$ for $n = 6 3$ . Therefore, for the left-tail probability $p = 0 . 0 1$ , the corresponding VaR is

$$
\begin{array}{l} \mathrm {V a R} = - 2. 5 8 3 - \frac {0 . 9 4 5}{- 0 . 3 3 5} \left\{1 - [ - 6 3 \ln (1 - 0. 0 1) ] ^ {- 0. 3 3 5} \right\} \\ = - 3. 0 4 9 6 9. \\ \end{array}
$$

Thus, for daily log returns of the stock, the $1 \%$ quantile is −3.04969. If one holds a long position on the stock worth $\$ 10$ million, then the estimated VaR with

probability $1 \%$ is $\$ 10,000,000$ . If the probability is 0.05, then the corresponding VaR is $\$ 166,641$ .

If we chose $n = 2 1$ (i.e., approximately 1 month), then $\hat { \alpha } _ { n } = 0 . 8 2 3$ , $\hat { \beta } _ { n } =$ $- 1 . 9 0 2$ , and $\hat { k } _ { n } = - 0 . 1 9 7$ . The $1 \%$ quantile of the extreme value distribution is

$$
\mathrm {V a R} = - 1. 9 0 2 - \frac {0 . 8 2 3}{- 0 . 1 9 7} \{1 - [ - 2 1 \ln (1 - 0. 0 1) ] ^ {- 0. 1 9 7} \} = - 3. 4 0 0 1 3.
$$

Therefore, for a long position of $\$ 10,000,000$ , the corresponding 1-day horizon VaR is $\$ 340,013$ at the $1 \%$ risk level. If the probability is 0.05, then the corresponding VaR is $\$ 184,127$ . In this particular case, the choice of $n = 2 1$ gives higher VaR values.

It is somewhat surprising to see that the VaR values obtained in Example 7.6 using the extreme value theory are smaller than those of Example 7.3 that uses a GARCH(1,1) model. In fact, the VaR values of Example 7.6 are even smaller than those based on the empirical quantile in Example 7.5. This is due in part to the choice of probability 0.05. If one chooses probability $0 . 0 0 1 = 0 . 1 \%$ and considers the same financial position, then we have $\mathrm { V a R } = \mathbb { S } 5 4 6 , 6 4 1$ for the Gaussian AR(2)–GARCH(1,1) model and $\mathrm { V a R } = \$ 666,59 0$ for the extreme value theory with $n = 2 1$ . Furthermore, the VaR obtained here via the traditional extreme value theory may not be adequate because the independent assumption of daily log returns is often rejected by statistical testings. Finally, the use of subperiod minima overlooks the fact of volatility clustering in the daily log returns. The new approach of extreme value theory discussed in the next section overcomes these weaknesses.

Remark. As shown by the results of Example 7.6, the VaR calculation based on the traditional extreme value theory depends on the choice of $n$ , which is the length of subperiods. For the limiting extreme value distribution to hold, one would prefer a large $n$ . But a larger $n$ means a smaller $g$ when the sample size $T$ is fixed, where $g$ is the effective sample size used in estimating the three parameters $\alpha _ { n }$ , $\beta _ { n }$ , and $k _ { n }$ . Therefore, some compromise between the choices of $n$ and $g$ is needed. A proper choice may depend on the returns of the asset under study. We recommend that one should check the stability of the resulting VaR in applying the traditional extreme value theory. 

# 7.6.1 Discussion

We have applied various methods of VaR calculation to the daily log returns of IBM stock for a long position of $\$ 10$ million. Consider the VaR of the position for the next trading day. If the probability is $5 \%$ , which means that with probability 0.95 the loss will be less than or equal to the VaR for the next trading day, then the results obtained are

1. $\$ 302,500$ for the RiskMetrics,   
2. $\$ 287,200$ for a Gaussian AR(2)–GARCH(1,1) model,

3. $\$ 283,520$ for an AR(2)–GARCH(1,1) model with a standardized Student-t distribution with 5 degrees of freedom,   
4. $\$ 216,030$ for using the empirical quantile, and   
5. $\$ 184,127$ for applying the traditional extreme value theory using monthly minima (i.e., subperiod length $n = 2 1$ ).

If the probability is $1 \%$ , then the VaR is

1. $\$ 426,500$ for the RiskMetrics,   
2. $\$ 409,738$ for a Gaussian AR(2)–GARCH(1,1) model,   
3. $\$ 475,943$ for an AR(2)–GARCH(1,1) model with a standardized Student-t distribution with 5 degrees of freedom,   
4. $\$ 365,709$ for using the empirical quantile, and   
5. $\$ 340,013$ for applying the traditional extreme value theory using monthly minima (i.e., subperiod length $n = 2 1$ ).

If the probability is $0 . 1 \%$ , then the VaR becomes

1. $\$ 566,443$ for the RiskMetrics,   
2. $\$ 546,641$ for a Gaussian AR(2)–GARCH(1,1) model,   
3. $\$ 836,341$ for an AR(2)–GARCH(1,1) model with a standardized Student-t distribution with 5 degrees of freedom,   
4. $\$ 780,712$ for using the empirical quantile, and   
5. $\$ 666,590$ for applying the traditional extreme value theory using monthly minima (i.e., subperiod length $n = 2 1$ ).

There are substantial differences among different approaches. This is not surprising because there exists substantial uncertainty in estimating tail behavior of a statistical distribution. Since there is no true VaR available to compare the accuracy of different approaches, we recommend that one applies several methods to gain insight into the range of VaR.

The choice of tail probability also plays an important role in VaR calculation. For the daily IBM stock returns, the sample size is 9190 so that the empirical quantiles of $5 \%$ and $1 \%$ are decent estimates of the quantiles of the return distribution. In this case, we can treat the results based on empirical quantiles as conservative estimates of the true VaR (i.e., lower bounds). In this view, the approach based on the traditional extreme value theory seems to underestimate the VaR for the daily log returns of IBM stock. The conditional approach of extreme value theory discussed in the next section overcomes this weakness.

When the tail probability is small (e.g., $0 . 1 \%$ ), the empirical quantile is a less reliable estimate of the true quantile. The VaR based on empirical quantiles can no longer serve as a lower bound of the true VaR. Finally, the earlier results show clearly the effects of using a heavy-tail distribution in VaR calculation when the tail probability is small. The VaR based on either a Student- $\mathbf { \nabla } \cdot \mathbf { \boldsymbol { t } }$ distribution with 5

degrees of freedom or the extreme value distribution is greater than that based on the normal assumption when the probability is $0 . 1 \%$ .

# 7.6.2 Multiperiod VaR

The square root of time rule of the RiskMetrics methodology becomes a special case under the extreme value theory. The proper relationship between $\ell$ -day and 1-day horizons is

$$
\mathrm {V a R} (\ell) = \ell^ {1 / \alpha} \mathrm {V a R} = \ell^ {- k} \mathrm {V a R},
$$

where $\alpha$ is the tail index and $k$ is the shape parameter of the extreme value distribution; see Danielsson and de Vries (1997a). This relationship is referred to as the $\alpha$ -root of time rule. Here $\alpha = - 1 / k$ , not the scale parameter $\alpha _ { n }$ .

For illustration, consider the daily log returns of IBM stock in Example 7.6. If we use $p = 0 . 0 5$ and the results of $n = 2 1$ , then for a 30-day horizon we have

$$
\mathrm {V a R} (3 0) = (3 0) ^ {0. 3 3 5} \mathrm {V a R} = 3. 1 2 5 \times \$ 1 8 4, 1 2 7 = \$ 5 7 5, 3 9 7.
$$

Because $\ell ^ { 0 . 3 3 5 } < \ell ^ { 0 . 5 }$ , the $\alpha$ -root of time rule produces lower -day horizon VaR than the square root of time rule does.

# 7.6.3 VaR for a Short Position

In this subsection, we give the formulas of VaR calculation for holding short positions. Here the quantity of interest is the subperiod maximum and the limiting extreme value distribution becomes

$$
F _ {*} (r) = \left\{ \begin{array}{l l} \exp \left[ - \left(1 - \frac {k _ {n} \left(r - \beta_ {n}\right)}{\alpha_ {n}}\right) ^ {1 / k _ {n}} \right] & \text {i f} k _ {n} \neq 0, \\ \exp \left[ - \exp \left(\frac {r - \beta_ {n}}{\alpha_ {n}}\right) \right] & \text {i f} k _ {n} = 0, \end{array} \right. \tag {7.29}
$$

where $r$ denotes a value of the subperiod maximum and it is understood that $1 - k _ { n } ( r - \beta _ { n } ) / \alpha _ { n } > 0$ for ${ { k } _ { n } } \ne 0$ .

Following similar procedures as those of long positions, we obtain the $( 1 - p )$ th quantile of the return $r _ { t }$ as

$$
\mathrm {V a R} = \left\{ \begin{array}{l l} \beta_ {n} + \frac {\alpha_ {n}}{k _ {n}} \left\{1 - \left[ - n \ln (1 - p) \right] ^ {k _ {n}} \right\} & \text {i f} k _ {n} \neq 0, \\ \beta_ {n} + \alpha_ {n} \ln [ - n \ln (1 - p) ] & \text {i f} k _ {n} = 0, \end{array} \right. \tag {7.30}
$$

where $p$ is a small probability denoting the chance of loss for holding a short position and $n$ is the length of subperiod.

# 7.6.4 Return Level

Another risk measure based on the extreme values of subperiods is the return level. The g n-subperiod return level, $L _ { n , g }$ , is defined as the level that is exceeded in one out of every $g$ subperiods of length $n$ . That is,

$$
P \left(r _ {n, i} <   L _ {n, g}\right) = \frac {1}{g},
$$

where $r _ { n , i }$ denotes subperiod minimum. The subperiod in which the return level is exceeded is called a stress period. If the subperiod length $n$ is sufficiently large so that normalized $r _ { n , i }$ follows the GEV distribution, then the return level is

$$
L _ {n, g} = \beta_ {n} + \frac {\alpha_ {n}}{k _ {n}} \left\{\left[ - \ln (1 - 1 / g) \right] ^ {k _ {n}} - 1 \right\},
$$

provided that ${ { k } _ { n } } \neq 0$ . Note that this is precisely the quantile of extreme value distribution given in Eq. (7.26) with tail probability $p ^ { * } = 1 / g$ , even though we write it in a slightly different way. Thus, return level applies to the subperiod minimum (or maximum), not to the underlying returns. This marks the difference between VaR and return level.

For the daily negative IBM log returns with subperiod length of 21 days, we can use the fitted model to obtain the return level for 12 such subperiods (i.e., $g = 1 2$ ). The return level is $- 4 . 4 8 3 5 \%$ .

# S-Plus Commands for Obtaining Return Level

>rl.21.12=rlevel.gev(nibm.gev.21,k.blocks=12, +type='profile') $>$ class(rl.21.12) [1]"list" $>$ names(rl.21.12) [1]"Range""rlevel" $>$ rl.21.12\$rlevel [1]4.483506

In S-Plus, the number of subperiods is denoted by k.blocks and the subcommand, type=‘profile’, produces a plot of the profile log-likelihood confidence interval for the return level. The plot is not shown here. Another subcommand for type is type $\ l = \ l ^ { 1 }$ RetLevel’.

If the subperiod maximum is used, the return level is defined as $P ( r _ { n , i } > L _ { n , g } ) =$ $1 / g$ , where $r _ { n , i }$ denotes the subperiod maximum. Again, using the GEV distribution for maximum, we have

$$
L _ {n, g} = \beta_ {n} + \frac {\alpha_ {n}}{k _ {n}} \left\{1 - \left[ - \ln (1 - 1 / g) \right] ^ {k _ {n}} \right\},
$$

where $g$ is the number of subperiods.

# 7.7 A NEW APPROACH BASED ON THE EXTREME VALUE THEORY

The aforementioned approach to VaR calculation using the extreme value theory encounters some difficulties. First, the choice of subperiod length $n$ is not clearly defined. Second, the approach is unconditional and, hence, does not take into consideration effects of other explanatory variables. To overcome these difficulties, a modern approach to extreme value theory has been proposed in the statistical literature; see Davison and Smith (1990) and Smith (1989). Instead of focusing on the extremes (maximum or minimum), the new approach focuses on exceedances of the measurement over some high threshold and the times at which the exceedances occur. Thus, this new approach is also referred to as peaks over thresholds (POT). For illustration, consider the daily log returns $r _ { t }$ of IBM stock used in this chapter and a long position on the stock. Let $\eta$ be a prespecified high threshold. We may choose $\eta = - 2 . 5 \%$ . Suppose that the ith exceedance occurs at day $t _ { i }$ (i.e., $r _ { t _ { i } } \le \eta )$ . Then the new approach focuses on the data $( t _ { i } , r _ { t _ { i } } - \eta )$ . Here $r _ { t _ { i } } - \eta$ is the exceedance over the threshold $\eta$ and $t _ { i }$ is the time at which the ith exceedance occurs. Similarly, for a short position, we may choose $\eta = 2 \%$ and focus on the data $( t _ { i } , r _ { t _ { i } } - \eta )$ for which $r _ { t _ { i } } \geq \eta$ .

In practice, the occurrence times $\left\{ t _ { i } \right\}$ provide useful information about the intensity of the occurrence of important “rare events” (e.g., less than the threshold $\eta$ for a long position). A cluster of $t _ { i }$ indicates a period of large market declines. The exceeding amount (or exceedance) $r _ { t _ { i } } \mathrm { ~ - ~ } \eta$ is also of importance as it provides the actual quantity of interest.

Based on the prior introduction, the new approach does not require the choice of a subperiod length $n$ , but it requires the specification of threshold $\eta$ . Different choices of the threshold $\eta$ lead to different estimates of the shape parameter $k$ (and hence the tail index $- 1 / k )$ . In the literature, some researchers believe that the choice of $\eta$ is a statistical problem as well as a financial one, and it cannot be determined based purely on statistical theory. For example, different financial institutions (or investors) have different risk tolerances. As such, they may select different thresholds even for an identical financial position. For the daily log returns of IBM stock considered in this chapter, the calculated VaR is not sensitive to the choice of $\eta$ .

The choice of threshold $\eta$ also depends on the observed log returns. For a stable return series, $\eta = - 2 . 5 \%$ may fare well for a long position. For a volatile return series (e.g., daily returns of a dot-com stock), $\eta$ may be as low as $- 1 0 \%$ . Limited experience shows that $\eta$ can be chosen so that the number of exceedances is sufficiently large (e.g., about $5 \%$ of the sample). For a more formal study on the choice of $\eta$ , see Danielsson and de Vries (1997b).

# 7.7.1 Statistical Theory

Again consider the log return $r _ { t }$ of an asset. Suppose that the ith exceedance occurs at $t _ { i }$ . Focusing on the exceedance $r _ { t } - \eta$ and exceeding time $t _ { i }$ results in a fundamental change in statistical thinking. Instead of using the marginal distribution

(e.g., the limiting distribution of the minimum or maximum), the new approach employs a conditional distribution to handle the magnitude of exceedance given that the measurement exceeds a threshold. The chance of exceeding the threshold is governed by a probability law. In other words, the new approach considers the conditional distribution of $x = r _ { t } - \eta$ given $r _ { t } \le \eta$ for a long position. Occurrence of the event $\{ r _ { t } \le \eta \}$ follows a point process (e.g., a Poisson process). See Section 6.9 for the definition of a Poisson process. In particular, if the intensity parameter $\lambda$ of the process is time-invariant, then the Poisson process is homogeneous. If $\lambda$ is time-variant, then the process is nonhomogeneous. The concept of Poisson process can be generalized to the multivariate case.

For ease in presentation, in what follows we use a positive threshold and the right-hand side of a return distribution to discuss the statistical theory behind the new approach of extreme value theory. This corresponds to holding a short financial position. However, the theory applies equally well to holding a long position if it is applied to the $\boldsymbol { r } _ { t } ^ { c }$ series, where $r _ { t } ^ { c } = - r _ { t }$ . This is easily seen because $r _ { t } ^ { c } \geq \eta$ for a positive threshold is equivalent to $r _ { t } \le - \eta$ , where $- \eta$ becomes a negative threshold.

The basic theory of the new approach is to consider the conditional distribution of $r = x + \eta$ given $r > \eta$ for the limiting distribution of the maximum given in Eq. (7.29). Since there is no need to choose the subperiod length $n$ , we do not use it as a subscript of the parameters. Then the conditional distribution of $r \leq x + \eta$ given $r > \eta$ is

$$
\Pr (r \leq x + \eta | r > \eta) = \frac {\Pr (\eta \leq r \leq x + \eta)}{\Pr (r > \eta)} = \frac {\Pr (r \leq x + \eta) - \Pr (r \leq \eta)}{1 - \Pr (r \leq \eta)}. \tag {7.31}
$$

Using the CDF $F _ { * } ( . )$ of Eq. (7.29) and the approximation $e ^ { - y } \approx 1 - y$ and after some algebra, we obtain that

$$
\begin{array}{l} \operatorname * {P r} \left(r \leq x + \eta | r > \eta\right) \\ = \frac {F _ {*} (x + \eta) - F _ {*} (\eta)}{1 - F _ {*} (\eta)} \\ = \frac {\exp \left[ - \left(1 - \frac {k (x + \eta - \beta)}{\alpha}\right) ^ {1 / k} \right] - \exp \left[ - \left(1 - \frac {k (\eta - \beta)}{\alpha}\right) ^ {1 / k} \right]}{1 - \exp \left[ - \left(1 - \frac {k (\eta - \beta)}{\alpha}\right) ^ {1 / k} \right]} \\ \approx 1 - \left(1 - \frac {k x}{\alpha - k (\eta - \beta)}\right) ^ {1 / k}, \tag {7.32} \\ \end{array}
$$

where $x > 0$ and $1 - k ( \eta - \beta ) / \alpha > 0$ . As is seen later, this approximation makes explicit the connection of the new approach to the traditional extreme value theory.

The case of $k = 0$ is taken as the limit of $k  0$ so that

$$
\Pr \left(r \leq x + \eta | r > \eta\right) \approx 1 - \exp (- x / \alpha).
$$

The distribution with cumulative distribution function

$$
G _ {k, \psi (\eta)} (x) = \left\{ \begin{array}{l l} 1 - \left[ 1 - \frac {k x}{\psi (\eta)} \right] ^ {1 / k} & \text {f o r} k \neq 0, \\ 1 - \exp [ - x / \psi (\eta) ] & \text {f o r} k = 0, \end{array} \right. \tag {7.33}
$$

where $\psi ( \eta ) > 0$ , $x \ge 0$ when $k \leq 0$ , and $0 \leq x \leq \psi ( \eta ) / k$ when $k > 0$ , is called the generalized Pareto distribution (GPD). Thus, the result of Eq. (7.32) shows that the conditional distribution of $r$ given $r > \eta$ is well approximated by a GPD with parameters $k$ and $\psi ( \eta ) = \alpha - k ( \eta - \beta )$ . See Embrechts et al. (1997) for further information. An important property of the GPD is as follows. Suppose that the excess distribution of $r$ given a threshold $\eta _ { o }$ is a GPD with shape parameter $k$ and scale parameter $\psi ( \eta _ { o } )$ . Then, for an arbitrary threshold $\eta > \eta _ { o }$ , the excess distribution over the threshold $\eta$ is also a GPD with shape parameter $k$ and scale parameter $\psi ( \eta ) = \psi ( \eta _ { o } ) - k ( \eta - \eta _ { o } )$ .

When $k = 0$ , the GPD in Eq. (7.33) reduces to an exponential distribution. This result motivates the use of a QQ-plot of excess returns over a threshold against exponential distribution to infer the tail behavior of the returns. If $k = 0$ , then the QQ-plot should be linear. Figure 7.6a shows the QQ-plot of daily negative IBM log returns used in this chapter with threshold 0.025. The nonlinear feature of the plot clearly shows that the left-tail of the daily IBM log returns is heavier than that of a normal distribution, that is, $k \neq 0$ .

# S-Plus Commands Used to Produce Figure 7.6

```txt
> par(mfcol=c(2,1))  
> qplot(-ibm, threshold=0.025,  
+ main='Negative daily IBM log returns')  
> meplot(-ibm)  
> title(main='Mean excess plot') 
```

# 7.7.2 Mean Excess Function

Given a high threshold $\eta _ { o }$ , suppose that the excess $r - \eta _ { o }$ follows a GPD with parameter $k$ and $\psi ( \eta _ { o } )$ , where $0 > k > - 1$ . Then the mean excess over the threshold $\eta _ { o }$ is

$$
E (r - \eta_ {o} | r > \eta_ {o}) = \frac {\psi (\eta_ {o})}{1 + k}.
$$

For any $\eta > \eta _ { o }$ , define the mean excess function $e ( \eta )$ a s

$$
e (\eta) = E (r - \eta | r > \eta) = \frac {\psi (\eta_ {o}) - k (\eta - \eta_ {o})}{1 + k}.
$$

![](images/6e23ff249a7919ba81b45c5c9d8d6412ba617a49704ef5727d285de33bc829a3.jpg)

![](images/bcb39f8ce07b498f4aee4c99da036a9cd60316f84a7f074f46cd2358b62bc773.jpg)  
Figure 7.6. Plots for daily negative IBM log returns from July 3, 1962 to December 31, 1998. (a) QQplot of excess returns over the threshold $2 . 5 \%$ and (b) the mean excess plot.

In other words, for any $y > 0$ ,

$$
e (\eta_ {o} + y) = E [ r - (\eta_ {o} + y) | r > \eta_ {o} + y ] = \frac {\psi (\eta_ {o}) - k y}{1 + k}.
$$

Thus, for a fixed $k$ , the mean excess function is a linear function of $y = \eta - \eta _ { o }$ . This result leads to a simple graphical method to infer the appropriate threshold value $\eta _ { o }$ for the GPD. Define the empirical mean excess function as

$$
e _ {T} (\eta) = \frac {1}{N _ {\eta}} \sum_ {i = 1} ^ {N _ {\eta}} \left(r _ {t _ {i}} - \eta\right), \tag {7.34}
$$

where $N _ { \eta }$ is the number of returns that exceed $\eta$ and $r _ { t _ { i } }$ are the values of the corresponding returns. See the next subsection for more information on the notation. The scatterplot of $e _ { T } ( \eta )$ against $\eta$ is called the mean excess plot, which should be linear in $\eta$ for $\eta > \eta _ { o }$ . Figure 7.6b shows the mean excess plot of the daily negative IBM log returns. It shows that, among others, a threshold of about $3 \%$ is reasonable for the negative return series. In S-Plus, the command for mean excess plot is meplot.

# 7.7.3 A New Approach to Modeling Extreme Values

Using the statistical result in Eq. (7.32) and considering jointly the exceedances and exceeding times, Smith (1989) proposes a two-dimensional Poisson process to model $( t _ { i } , r _ { t _ { i } } )$ . This approach was used by Tsay (1999) to study VaR in risk management. We follow the same approach.

Assume that the baseline time interval is $D$ , which is typically a year. In the United States, $D = 2 5 2$ is used as there are typically 252 trading days in a year. Let $t$ be the time interval of the data points (e.g., daily) and denote the data span by $t = 1 , 2 , \dots , T$ , where $T$ is the total number of data points. For a given threshold $\eta$ , the exceeding times over the threshold are denoted by $\{ t _ { i } , \ i = 1 , \dots , N _ { \eta } \}$ and the observed log return at $t _ { i }$ is $r _ { t _ { i } }$ . Consequently, we focus on modeling $\{ ( t _ { i } , r _ { t _ { i } } ) \}$ for $i = 1 , \ldots , N _ { \eta }$ , where $N _ { \eta }$ depends on the threshold $\eta$ .

The new approach to applying the extreme value theory is to postulate that the exceeding times and the associated returns (i.e., $( t _ { i } , r _ { t _ { i } } ) )$ jointly form a twodimensional Poisson process with intensity measure given by

$$
\Lambda \left[ \left(D _ {2}, D _ {1}\right) \times (r, \infty) \right] = \frac {D _ {2} - D _ {1}}{D} S (r; k, \alpha , \beta), \tag {7.35}
$$

where

$$
S (r; k, \alpha , \beta) = \left[ 1 - \frac {k (r - \beta)}{\alpha} \right] _ {+} ^ {1 / k},
$$

$0 \leq D _ { 1 } \leq D _ { 2 } \leq T$ , $r > \eta$ , $\alpha > 0$ , $\beta$ , and $k$ are parameters, and the notation $[ x ] _ { + }$ is defined as $[ x ] _ { + } = \operatorname* { m a x } ( x , 0 )$ . This intensity measure says that the occurrence of exceeding the threshold is proportional to the length of the time interval $[ D _ { 1 } , D _ { 2 } ]$ and the probability is governed by a survival function similar to the exponent of the CDF $F _ { * } ( r )$ in Eq. (7.29). A survival function of a random variable $X$ is defined as $S ( x ) = \operatorname* { P r } \left( X > x \right) = 1 - \operatorname* { P r } \left( X \leq x \right) = 1 - C D F ( x )$ . When $k = 0$ , the intensity measure is taken as the limit of $k  0$ ; that is,

$$
\Lambda \left[ \left(D _ {2}, D _ {1}\right) \times (r, \infty) \right] = \frac {D _ {2} - D _ {1}}{D} \exp \left[ \frac {- (r - \beta)}{\alpha} \right].
$$

In Eq. (7.35), the length of time interval is measured with respect to the baseline interval $D$ .

The idea of using the intensity measure in Eq. (7.35) becomes clear when one considers its implied conditional probability of $r = x + \eta$ given $r > \eta$ over the time interval $[ 0 , D ]$ , where $x > 0$ ,

$$
\frac {\Lambda [ (0 , D) \times (x + \eta , \infty) ]}{\Lambda [ (0 , D) \times (\eta , \infty) ]} = \left[ \frac {1 - k (x + \eta - \beta) / \alpha}{1 - k (\eta - \beta) / \alpha} \right] ^ {1 / k} = \left[ 1 - \frac {k x}{\alpha - k (\eta - \beta)} \right] ^ {1 / k},
$$

which is precisely the survival function of the conditional distribution given in Eq. (7.32). This survival function is obtained from the extreme limiting distribution

for maximum in Eq. (7.29). We use survival function here because it denotes the probability of exceedance.

The relationship between the limiting extreme value distribution in Eq. (7.29) and the intensity measure in Eq. (7.35) directly connects the new approach of extreme value theory to the traditional one.

Mathematically, the intensity measure in Eq. (7.35) can be written as an integral of an intensity function:

$$
\Lambda [ (D _ {2}, D _ {1}) \times (r, \infty) ] = \int_ {D _ {1}} ^ {D _ {2}} \int_ {r} ^ {\infty} \lambda (t, z; k, \alpha , \beta) d t d z,
$$

where the intensity function $\lambda ( t , z ; k , \alpha , \beta )$ is defined as

$$
\lambda (t, z; k, \alpha , \beta) = \frac {1}{D} g (z; k, \alpha , \beta), \tag {7.36}
$$

where

$$
g (z; k, \alpha , \beta) = \left\{ \begin{array}{l l} \frac {1}{\alpha} \left[ 1 - \frac {k (z - \beta)}{\alpha} \right] ^ {1 / k - 1} & \text {i f} k \neq 0, \\ \frac {1}{\alpha} \exp \left[ \frac {- (z - \beta)}{\alpha} \right] & \text {i f} k = 0. \end{array} \right.
$$

Using the results of a Poisson process, we can write down the likelihood function for the observed exceeding times and their corresponding returns $\{ ( t _ { i } , r _ { t _ { i } } ) \}$ over the two-dimensional space $[ 0 , N ] \times ( \eta , \infty )$ as

$$
L (k, \alpha , \beta) = \left(\prod_ {i = 1} ^ {N _ {\eta}} \frac {1}{D} g \left(r _ {t _ {i}}; k, \alpha , \beta\right)\right) \times \exp \left[ - \frac {T}{D} S (\eta ; k, \alpha , \beta) \right]. \tag {7.37}
$$

The parameters $k , \alpha$ , and $\beta$ can then be estimated by maximizing the logarithm of this likelihood function. Since the scale parameter $\alpha$ is non-negative, we use $\ln ( \alpha )$ in the estimation.

Example 7.7. Consider again the daily log returns of IBM stock from July 3, 1962 to December 31, 1998. There are 9190 daily returns. Table 7.3 gives some estimation results of the parameters $k , \alpha$ , and $\beta$ for three choices of the threshold when the negative series $\{ - r _ { t } \}$ is used. We use the negative series $\{ - r _ { t } \}$ , instead of $\{ r _ { t } \}$ , because we focus on holding a long financial position. The table also shows the number of exceeding times for a given threshold. It is seen that the chance of dropping $2 . 5 \%$ or more in a day for IBM stock occurred with probability $3 1 0 / 9 1 9 0 \approx 3 . 4 \%$ . Because the sample mean of IBM stock returns is not zero, we also consider the case when the sample mean is removed from the original daily log returns. From the table, removing the sample mean has little impact on the parameter estimates. These parameter estimates are used next to calculate

Table 7.3. Estimation Resultsa of a Two-Dimensional Homogeneous Poisson Model for the Daily Negative Log Returns of IBM Stock from July 3, 1962 to December 31, 1998   

<table><tr><td>Thr.</td><td>Exc.</td><td>Shape Parameter k</td><td>Log(Scale) ln(α)</td><td>Location β</td></tr><tr><td colspan="5">Original Log Returns</td></tr><tr><td>3.0%</td><td>175</td><td>-0.30697(0.09015)</td><td>0.30699(0.12380)</td><td>4.69204(0.19058)</td></tr><tr><td>2.5%</td><td>310</td><td>-0.26418(0.06501)</td><td>0.31529(0.11277)</td><td>4.74062(0.18041)</td></tr><tr><td>2.0%</td><td>554</td><td>-0.18751(0.04394)</td><td>0.27655(0.09867)</td><td>4.81003(0.17209)</td></tr><tr><td colspan="5">Removing the Sample Mean</td></tr><tr><td>3.0%</td><td>184</td><td>-0.30516(0.08824)</td><td>0.30807(0.12395)</td><td>4.73804(0.19151)</td></tr><tr><td>2.5%</td><td>334</td><td>-0.28179(0.06737)</td><td>0.31968(0.12065)</td><td>4.76808(0.18533)</td></tr><tr><td>2.0%</td><td>590</td><td>-0.19260(0.04357)</td><td>0.27917(0.09913)</td><td>4.84859(0.17255)</td></tr></table>

aThe baseline time interval is 252 (i.e., 1 year). The numbers in parentheses are standard errors, where “Thr.” and “Exc.” stand for threshold and the number of exceedings.

VaR, keeping in mind that in a real application one needs to check carefully the adequacy of a fitted Poisson model. We discuss methods of model checking in the next subsection.

# 7.7.4 VaR Calculation Based on the New Approach

As shown in Eq. (7.32), the two-dimensional Poisson process model used, which employs the intensity measure in Eq. (7.35), has the same parameters as those of the extreme value distribution in Eq. (7.29). Therefore, one can use the same formula as that of Eq. (7.30) to calculate VaR of the new approach. More specifically, for a given upper tail probability $p$ , the $( 1 - p )$ th quantile of the log return $r _ { t }$ is

$$
\mathrm {V a R} = \left\{ \begin{array}{l l} \beta + \frac {\alpha}{k} \left\{1 - \left[ - D \ln (1 - p) \right] ^ {k} \right\} & \text {i f} k \neq 0, \\ \beta + \alpha \ln [ - D \ln (1 - p) ] & \text {i f} k = 0, \end{array} \right. \tag {7.38}
$$

where $D$ is the baseline time interval used in estimation. In the United States, one typically uses $D = 2 5 2$ , which is approximately the number of trading days in a year.

Example 7.8. Consider again the case of holding a long position of IBM stock valued at $\$ 10$ million. We use the estimation results of Table 7.3 to calculate 1-day horizon VaR for the tail probabilities of 0.05 and 0.01.

• Case I: Use the original daily log returns. The three choices of threshold $\eta$ result in the following VaR values:

1. $\eta = 3 . 0 \%$ : $\mathrm { V a R } ( 5 \% ) = \mathbb { S } 2 2 8 , 2 3 9$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 5 9 . 3 0 3$ .   
2. $\eta = 2 . 5 \%$ : $\mathrm { V a R } ( 5 \% ) = \mathbb { S } 2 1 9 , 1 0 6$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 6 1 , 1 1 9$ .   
3. $\eta = 2 . 0 \%$ : $\operatorname { V a R } ( 5 \% ) = \mathbb { S } 2 1 2 { , } 9 8 1$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 6 8 . 5 5 2$ .

• Case II: The sample mean of the daily log returns is removed. The three choices of threshold $\eta$ result in the following VaR values:

1. $\eta = 3 . 0 \%$ : $\operatorname { V a R } ( 5 \% ) = \mathbb { S } 2 3 2 , 0 9 4$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 6 3 , 6 9 7$   
2. $\eta = 2 . 5 \%$ : $\mathrm { V a R } ( 5 \% ) = \mathbb { S } 2 2 5 , 7 8 2$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 6 4 , 2 5 4$   
3. $\eta = 2 . 0 \%$ : $\mathrm { V a R } ( 5 \% ) = \mathbb { S } 2 1 7 { , } 7 4 0$ , $\mathrm { V a R } ( 1 \% ) = \mathbb { S } 3 7 2 , 3 7 2$

As expected, removing the sample mean, which is positive, slightly increases the VaR. However, the VaR is rather stable among the three threshold values used. In practice, we recommend that one removes the sample mean first before applying this new approach to VaR calculation.

Discussion. Compared with the VaR of Example 7.6 that uses the traditional extreme value theory, the new approach provides a more stable VaR calculation. The traditional approach is rather sensitive to the choice of the subperiod length $n$ . 

# 7.7.5 An Alternative Parameterization

As mentioned before, for a given threshold $\eta$ , the GPD can also be parameterized by the shape parameter $k$ and the scale parameter $\psi ( \eta ) = \alpha - k ( \eta - \beta )$ . This is the parameterization used in S-Plus. In fact, (xi,beta) of S-Plus corresponds to $( - k , \psi ( \eta ) )$ of this chapter. The command for estimating a GPD model in S-Plus is gpd. For illustration, consider the daily negative IBM log return series from 1962 to 1998. The results are given below:

```matlab
> nibm.gpd = gpd(-ibm, threshold=0.025)  
> names(nibm.gpd)  
[1] "n" "data"  
[3] "upper.exceed" "lower.exceed"  
[5] "upper.thresh" "lower.thresh"  
[7] "p.less upper.thresh" "p.larger.lower.thresh"  
[9] "n.upper.exceed" "n.lower.exceed"  
[11] "upper.method" "lower.method"  
[13] "upper.par.estst" "lower.par.estst"  
[15] "upper.par.ses" "lower.par.ses"  
[17] "upper.varcov" "lower.varcov"  
[19] "upper.info" "lower.info"  
[21] "upper.converged" "lower.converged"  
[23] "upper.nllh.final" "lower.nllh.final"  
> nibm.gpd$upper.thresh  
[1] 0.025  
> nibm.gpd$n.upper.exceed % number of exceedances  
[1] 310 
```

```txt
> nibm.gpd\\(p.less upper.thresh \) \%$ 1-prob(exceedance)  
[1] 0.9662677  
> nibm.gpd\\)upper.par.eststxi beta0.2641418 0.00778777  
> nibm.gpd\\)upper.par.sesxi beta0.06659759 0.0006715558  
> par(mfcol=c(2,2))  
> plot(nibm.gpd)
```

```txt
Make a plot selection (or 0 to exit):  
1: plot: Excess Distribution  
2: plot: Tail of Underlying Distribution  
3: plot: Scatterplot of Residuals  
4: plot: QQplot of Residuals  
Selection: 
```

Note that the results are very close to those in Table 7.3, where percentage log returns are used. The estimates of $k$ and $\psi ( \eta )$ are $- 0 . 2 6 4 1 8$ and $\alpha - k ( \eta - \beta ) =$ $\exp ( 0 . 3 1 5 2 9 ) - ( - 0 . 2 6 4 1 8 ) ( 2 . 5 - 4 . 7 4 0 6 ) = 0 . 7 7 8 7 3$ , respectively, in Table 7.3. In terms of log returns, the estimate of $\psi ( \eta )$ is 0.007787, which is the same as the S-Plus estimate.

Figure 7.7 shows the diagnostic plots for the GPD fit to the daily negative log returns of IBM stock. The QQ-plot (lower-right panel) and the tail probability estimate (in log scale and in the lower-left panel) show some minor deviation from a straight line, indicating further improvement is possible.

From the conditional distributions in Eqs. (7.31) and (7.32) and the GPD in Eq. (7.33), we have

$$
\frac {F (y) - F (\eta)}{1 - F (\eta)} \approx G _ {\eta , \psi (\eta)} (x),
$$

where $y = x + \eta$ with $x > 0$ . If we estimate the CDF $F ( \eta )$ of the returns by the empirical CDF, then

$$
\hat {F} (\eta) = \frac {T - N _ {\eta}}{T},
$$

where $N _ { \eta }$ is the number of exceedances of the threshold $\eta$ and $T$ is the sample size. Consequently,

$$
\begin{array}{l} F (y) = F (\eta) + G (x) [ 1 - F (\eta) ] \\ \approx 1 - \frac {N _ {\eta}}{T} \left[ 1 - \frac {k (y - \eta)}{\psi (\eta)} \right] ^ {1 / k}. \\ \end{array}
$$

This leads to an alternative estimate of the quantile of $F ( y )$ for use in VaR calculation. Specifically, for an upper tail probability $p$ , where $0 < p < 0 . 0 5$ , let

![](images/2fdbd62957521473fd7804dbf500ef7f8eff6745c87c3744626f0db387715e9c.jpg)

![](images/258bdb202afb6fdb45cfa43cfd745adfe65bc2390dcc2871d95e09c14390e64b.jpg)

![](images/5aebc4a15f7b082fae7e102af17d44de87a672512538eef9dd1f455eccb4d0b7.jpg)

![](images/226a21666eaed41872190b1b2a1eff6cbfccbc179d926d9f91a75062d35157c1.jpg)  
Figure 7.7. Diagnostic plots for GPD fit to the daily negative log returns of IBM stock from July 3, 1962 to December 31, 1998.

$q = 1 - p$ . Then, the $q$ th quantile of $F ( y )$ , denoted by $\operatorname { V a R } _ { q }$ , can be estimated by

$$
\mathrm {V a R} _ {q} = \eta + \frac {\psi (\eta)}{k} \left\{1 - \left[ \frac {T}{N _ {\eta}} (1 - q) \right] ^ {k} \right\}, \tag {7.39}
$$

where, as before, $\eta$ is the threshold, $T$ is the sample size, $N _ { \eta }$ is the number of exceedances, and $\psi ( \eta )$ and $k$ are the scale and shape parameters of the GPD distribution. This method to VaR calculation is used in S-Plus.

Another commonly used risk measure associated with VaR is the expected shortfall (ES), which is defined as the expected loss given that the VaR is exceeded. Specifically, for a given probability $q$ (typically $0 . 9 5 \leq q \leq 1 ,$ ), the expected shortfall is defined by

$$
\mathrm {E S} _ {q} = E (r | r > \mathrm {V a R} _ {q}) = \mathrm {V a R} _ {q} + E (r - \mathrm {V a R} _ {q} | r > \mathrm {V a R} _ {q}). \tag {7.40}
$$

Using properties of the GPD, it can be shown that

$$
E (r - \mathrm {V a R} _ {q} | r > \mathrm {V a R} _ {q}) = \frac {\psi (\eta) - k (\mathrm {V a R} _ {q} - \eta)}{1 + k},
$$

provided that $0 > k > - 1$ . Consequently, we have

$$
\mathrm {E S} _ {q} = \frac {\mathrm {V a R} _ {q}}{1 + k} + \frac {\psi (\eta) + k \eta}{1 + k}.
$$

To illustrate the new method to VaR and ES calculations, we again use the daily negative log returns of IBM stock with threshold $2 . 5 \%$ . The S-Plus command is riskmeasures:

```txt
> riskmeasures(nibm.gpd, c(0.95, 0.99))  
p quantile sfall  
[1,] 0.95 0.02208893 0.03162723  
[2,] 0.99 0.03616619 0.05075763 
```

From the output, the VaR values for the financial position are $\$ 220,889$ and $\$ 361,661$ , respectively, for tail probability of 0.05 and 0.01. These two values are rather close to those given in Example 7.8 that are based on the method of the previous subsection. The expected shortfalls for the financial position are $\$ 316,272$ and $\$ 507,576$ , respectively, for tail probability of 0.05 and 0.01.

# 7.7.6 Use of Explanatory Variables

The two-dimensional Poisson process model discussed earlier is homogeneous because the three parameters $k , \alpha$ , and $\beta$ are constant over time. In practice, such a model may not be adequate. Furthermore, some explanatory variables are often available that may influence the behavior of the log returns $r _ { t }$ . A nice feature of the new extreme value theory approach to VaR calculation is that it can easily take explanatory variables into consideration. We discuss such a framework in this subsection. In addition, we also discuss methods that can be used to check the adequacy of a fitted two-dimensional Poisson process model.

Suppose that $\pmb { x } _ { t } = ( x _ { 1 t } , \ldots , x _ { v t } ) ^ { \prime }$ is a vector of $v$ explanatory variables that are available prior to time $t$ . For asset returns, the volatility $\sigma _ { t } ^ { 2 }$ of $r _ { t }$ discussed in Chapter 3 is an example of explanatory variables. Another example of explanatory variables in the U.S. equity markets is an indicator variable denoting the meetings of the Federal Open Market Committee. A simple way to make use of explanatory variables is to postulate that the three parameters $k , \alpha$ , and $\beta$ are time-varying and are linear functions of the explanatory variables. Specifically, when explanatory variables $\scriptstyle { x _ { t } }$ are available, we assume that

$$
k _ {t} = \gamma_ {0} + \gamma_ {1} x _ {1 t} + \dots + \gamma_ {v} x _ {v t} \equiv \gamma_ {0} + \boldsymbol {\gamma} ^ {\prime} \boldsymbol {x} _ {t},
$$

$$
\ln \left(\alpha_ {t}\right) = \delta_ {0} + \delta_ {1} x _ {1 t} + \dots + \delta_ {v} x _ {v t} \equiv \delta_ {0} + \delta^ {\prime} x _ {t}, \tag {7.41}
$$

$$
\beta_ {t} = \theta_ {0} + \theta_ {1} x _ {1 t} + \dots + \theta_ {v} x _ {v t} \equiv \theta_ {0} + \boldsymbol {\theta} ^ {\prime} \boldsymbol {x} _ {t}.
$$

If $\gamma = 0$ , then the shape parameter $k _ { t } = \gamma _ { 0 }$ , which is time-invariant. Thus, testing the significance of $\gamma$ can provide information about the contribution of the explanatory variables to the shape parameter. Similar methods apply to the scale and location parameters. In Eq. (7.41), we use the same explanatory variables for all three parameters $k _ { t }$ , $\ln ( \alpha _ { t } )$ , and $\beta _ { t }$ . In an application, different explanatory variables may be used for different parameters.

When the three parameters of the extreme value distribution are time-varying, we have an inhomogeneous Poisson process. The intensity measure becomes

$$
\Lambda \left[ \left(D _ {1}, D _ {2}\right) \times (r, \infty) \right] = \frac {D _ {2} - D _ {1}}{D} \left[ 1 - \frac {k _ {t} \left(r - \beta_ {t}\right)}{\alpha_ {t}} \right] _ {+} ^ {1 / k _ {t}}, \quad r > \eta . \tag {7.42}
$$

The likelihood function of the exceeding times and returns $\{ ( t _ { i } , r _ { t _ { i } } ) \}$ becomes

$$
L = \left(\prod_ {i = 1} ^ {N _ {\eta}} \frac {1}{D} g \left(r _ {t _ {i}}; k _ {t _ {i}}, \alpha_ {t _ {i}}, \beta_ {t _ {i}}\right)\right) \times \exp \left[ - \frac {1}{D} \int_ {0} ^ {T} S (\eta ; k _ {t}, \alpha_ {t}, \beta_ {t}) d t \right],
$$

which reduces to

$$
L = \left(\prod_ {i = 1} ^ {N _ {\eta}} \frac {1}{D} g \left(r _ {t _ {i}}; k _ {t _ {i}}, \alpha_ {t _ {i}}, \beta_ {t _ {i}}\right)\right) \times \exp \left[ - \frac {1}{D} \sum_ {t = 1} ^ {T} S (\eta ; k _ {t}, \alpha_ {t}, \beta_ {t}) \right] \tag {7.43}
$$

if one assumes that the parameters $k _ { t }$ , $\alpha _ { t }$ , and $\beta _ { t }$ are constant within each trading day, where $g ( z ; k _ { t } , \alpha _ { t } , \beta _ { t } )$ and $S ( \eta ; k _ { t } , \alpha _ { t } , \beta _ { t } )$ are given in Eqs. (7.36) and (7.35), respectively. For given observations $\{ r _ { t } , \boldsymbol { x } _ { t } | t = 1 , . . . , T \}$ , the baseline time interval $D$ , and the threshold $\eta$ , the parameters in Eq. (7.41) can be estimated by maximizing the logarithm of the likelihood function in Eq. (7.43). Again we use $\ln ( \alpha _ { t } )$ to satisfy the positive constraint of $\alpha _ { t }$ .

Remark. The parameterization in Eq. (7.41) is similar to that of the volatility models of Chapter 3 in the sense that the three parameters are exact functions of the available information at time t. Other functions can be used if necessary. 

# 7.7.7 Model Checking

Checking an entertained two-dimensional Poisson process model for exceedance times and excesses involves examining three key features of the model. The first feature is to verify the adequacy of the exceedance rate, the second feature is to examine the distribution of exceedances, and the final feature is to check the independence assumption of the model. We discuss briefly some statistics that are useful for checking these three features. These statistics are based on some basic statistical theory concerning distributions and stochastic processes.

# Exceedance Rate

A fundamental property of univariate Poisson processes is that the time durations between two consecutive events are independent and exponentially distributed. To exploit a similar property for checking a two-dimensional process model, Smith and Shively (1995) propose examining the time durations between consecutive exceedances. If the two-dimensional Poisson process model is appropriate for the exceedance times and excesses, the time duration between the ith and $( i \mathrm { ~ - ~ } 1 ) \mathrm { t h }$

exceedances should follow an exponential distribution. More specifically, letting $t _ { 0 } = 0$ , we expect that

$$
z _ {t _ {i}} = \int_ {t _ {i - 1}} ^ {t _ {i}} \frac {1}{D} g (\eta ; k _ {s}, \alpha_ {s}, \beta_ {s}) d s, \quad i = 1, 2, \dots
$$

are independent and identically distributed (iid) as a standard exponential distribution. Because daily returns are discrete-time observations, we employ the time durations

$$
z _ {t _ {i}} = \frac {1}{D} \sum_ {t = t _ {i - 1} + 1} ^ {t _ {i}} S (\eta ; k _ {t}, \alpha_ {t}, \beta_ {t}) \tag {7.44}
$$

and use the QQ-plot to check the validity of the iid standard exponential distribution. If the model is adequate, the QQ-plot should show a straight line through the origin with unit slope.

# Distribution of Excesses

Under the two-dimensional Poisson process model considered, the conditional distribution of the excess $x _ { t } = r _ { t } - \eta$ over the threshold $\eta$ is a GPD with shape parameter $k _ { t }$ and scale parameter $\psi _ { t } = \alpha _ { t } - k _ { t } ( \eta - \beta _ { t } )$ . Therefore, we can make use of the relationship between a standard exponential distribution and GPD, and define

$$
w _ {t _ {i}} = \left\{ \begin{array}{l l} - \frac {1}{k _ {t _ {i}}} \ln \left(1 - k _ {t _ {i}} \frac {r _ {t _ {i}} - \eta}{\psi_ {t _ {i}}}\right) _ {+} & \text {i f} k _ {t _ {i}} \neq 0, \\ \frac {r _ {t _ {i}} - \eta}{\psi_ {t _ {i}}} & \text {i f} k _ {t _ {i}} = 0. \end{array} \right. \tag {7.45}
$$

If the model is adequate, $\{ w _ { t _ { i } } \}$ are independent and exponentially distributed with mean 1; see also Smith (1999). We can then apply the QQ-plot to check the validity of the GPD assumption for excesses.

# Independence

A simple way to check the independence assumption, after adjusting for the effects of explanatory variables, is to examine the sample autocorrelation functions of $z _ { t _ { i } }$ and $w _ { t _ { i } }$ . Under the independence assumption, we expect that both $z _ { t _ { i } }$ and $w _ { t _ { i } }$ have no serial correlations.

# 7.7.8 An Illustration

In this subsection, we apply a two-dimensional inhomogeneous Poisson process model to the daily log returns, in percentages, of IBM stock from July 3, 1962 to December 31, 1998. We focus on holding a long position of $\$ 10$ million. The analysis enables us to compare the results with those obtained before by using other approaches to calculating VaR.

![](images/59eeda22059d5a2c0cde728da1d0e563109c668ca9beef6c8267947ef9740eec.jpg)

![](images/05efea8b275cb3481de6e91101ef083d9a13214e3bad3427168fd12a2b1e3221.jpg)

![](images/6598982ad2ad133b29848ff5918aadabd40bd55ac301e7c31e49bcbc5fe220fa.jpg)

![](images/4106b8989b8220ff5a134e2303e6f43f2c94c67890884aa004d912f382a16634.jpg)  
Figure 7.8. Sample autocorrelation functions of the $z$ and $w$ measures for two-dimensional Poisson models. Parts (a) and (b) are for the homogeneous model and parts (c) and (d) are for the inhomogeneous model. The data are daily mean-corrected log returns, in percentages, of IBM stock from July 3, 1962 to December 31, 1998, and the threshold is $2 . 5 \%$ . A long financial position is used.

We begin by pointing out that the two-dimensional homogeneous model of Example 7.7 needs further refinements because the fitted model fails to pass the model checking statistics of the previous subsection. Figures 7.8a and 7.8b show the autocorrelation functions of the statistics $z _ { t _ { i } }$ and $w _ { t _ { i } }$ , defined in Eqs. (7.44) and (7.45), of the homogeneous model when the threshold is $\eta = 2 . 5 \%$ . The horizontal lines in the plots denote asymptotic limits of two standard errors. It is seen that both $z _ { t _ { i } }$ and $w _ { t _ { i } }$ series have some significant serial correlations. Figures 7.9a and 7.9b show the QQ-plots of $z _ { t _ { i } }$ and $w _ { t _ { i } }$ series. The straight line in each plot is the theoretical line, which passes through the origin and has a unit slope under the assumption of a standard exponential distribution. The QQ-plot of $z _ { t _ { i } }$ shows some discrepancy.

To refine the model, we use the mean-corrected log return series

$$
r _ {t} ^ {o} = r _ {t} - \overline {{r}}, \quad \overline {{r}} = \frac {1}{9 1 9 0} \sum_ {t = 1} ^ {9 1 9 0} r _ {t},
$$

where $r _ { t }$ is the daily log return in percentages, and employ the following explanatory variables:

![](images/7baf0cddfc78705940490ee8120cb98298bd72c1fca889ab30fce510474cfe4d.jpg)

![](images/3926c9290150fd74400776d68d2515017829cd2c81ba8ea1537109cc791f09e4.jpg)

![](images/d5f17096c50da62fb119ab081fcd1042014ae1cafd7407a36e8332d676702598.jpg)

![](images/a12321089c369bf4d91b58065541588585460f057d873e2171e703adb71913d0.jpg)  
Figure 7.9. Quantile-to-quantile plot of the $z$ and $w$ measures for two-dimensional Poisson models. Parts (a) and (b) are for the homogeneous model and parts (c) and (d) are for the inhomogeneous model. The data are daily mean-corrected log returns, in percentages, of IBM stock from July 3, 1962 to December 31, 1998, and the threshold is $2 . 5 \%$ . A long financial position is used.

1. $x _ { 1 t }$ : an indicator variable for October, November, and December. That is, $x _ { 1 t } = 1$ if $t$ is in October, November, or December. This variable is chosen to take care of the fourth-quarter effect (or year-end effect), if any, on the daily IBM stock returns.   
2. $x _ { 2 t }$ : an indicator variable for the behavior of the previous trading day. Specifically, $x _ { 2 t } = 1$ if and only if the log return $r _ { t - 1 } ^ { o } \leq - 2 . 5 \%$ . Since we focus on holding a long position with threshold $2 . 5 \%$ , an exceedance occurs when the daily price drops over $2 . 5 \%$ . Therefore, $x _ { 2 t }$ is used to capture the possibility of panic selling when the price of IBM stock dropped $2 . 5 \%$ or more on the previous trading day.   
3. $x _ { 3 t }$ : a qualitative measurement of volatility, which is the number of days between $t - 1$ and $t - 5$ (inclusive) that has a log return with magnitude exceeding the threshold. In our case, $x _ { 3 t }$ is the number of $r _ { t - i } ^ { o }$ satisfying $| r _ { t - i } ^ { o } | \geq 2 . 5 \%$ for $i = 1 , \ldots , 5$ .   
4. $x _ { 4 t }$ : an annual trend defined as $x _ { 4 t } =$ (year of time $t - 1 9 6 1 ) / 3 8$ . This variable is used to detect any trend in the behavior of extreme returns of IBM stock.   
5. $x _ { 5 t }$ : a volatility series based on a Gaussian GARCH(1,1) model for the mean-corrected series $r _ { t } ^ { o }$ . Specifically, $x _ { 5 t } = \sigma _ { t }$ , where $\sigma _ { t } ^ { 2 }$ is the conditional

variance of the GARCH(1,1) model

$$
r _ {t} ^ {\sigma} = a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \quad \epsilon_ {t} \sim N (0, 1),
$$

$$
\sigma_ {t} ^ {2} = 0. 0 4 5 6 5 + 0. 0 8 0 7 a _ {t - 1} ^ {2} + 0. 9 0 3 1 \sigma_ {t - 1} ^ {2}.
$$

These five explanatory variables are all available at time $t - 1$ . We use two volatility measures $x _ { 3 t }$ and $x _ { 5 t }$ ) to study the effect of market volatility on VaR. As shown in Example 7.3 by the fitted AR(2)–GARCH(1,1) model, the serial correlations in $r _ { t }$ are weak so that we do not entertain any ARMA model for the mean equation.

Using the prior five explanatory variables and deleting insignificant parameters, we obtain the estimation results shown in Table 7.4. Figures 7.8c and 7.8d and Figures 7.9c and 7.9d show the model checking statistics for the fitted twodimensional inhomogeneous Poisson process model when the threshold is $\eta =$ $2 . 5 \%$ . All autocorrelation functions of $z _ { t _ { i } }$ and $w _ { t _ { i } }$ are within the asymptotic two standard-error limits. The QQ-plots also show marked improvements as they indicate no model inadequacy. Based on these checking results, the inhomogeneous model seems adequate.

Consider the case of threshold $2 . 5 \%$ . The estimation results show the following:

1. All three parameters of the intensity function depend significantly on the annual time trend. In particular, the shape parameter has a negative annual

Table 7.4. Estimation Resultsa of a Two-Dimensional Inhomogeneous Poisson Process Model for Daily Log Returns, in Percentages, of IBM Stock from July 3, 1962 to December 31, 1998   

<table><tr><td>Parameter</td><td>Constant</td><td>Coefficient of x3t</td><td>Coefficient of x4t</td><td>Coefficient of x5t</td></tr><tr><td colspan="5">Threshold 2.5% with 334 Exceedances</td></tr><tr><td rowspan="2">βt(Std. error)</td><td>0.3202</td><td></td><td>1.4772</td><td>2.1991</td></tr><tr><td>(0.3387)</td><td></td><td>(0.3222)</td><td>(0.2450)</td></tr><tr><td>ln(αt)</td><td>-0.8119</td><td>0.3305</td><td>1.0324</td><td></td></tr><tr><td>(Std. error)</td><td>(0.1798)</td><td>(0.0826)</td><td>(0.2619)</td><td></td></tr><tr><td>kt</td><td>-0.1805</td><td>-0.2118</td><td>-0.3551</td><td>0.2602</td></tr><tr><td>(Std. error)</td><td>(0.1290)</td><td>(0.0580)</td><td>(0.1503)</td><td>(0.0461)</td></tr><tr><td colspan="5">Threshold 3.0% with 184 Exceedances</td></tr><tr><td rowspan="2">βt(Std. error)</td><td>1.1569</td><td></td><td></td><td>2.1918</td></tr><tr><td>(0.4082)</td><td></td><td></td><td>(0.2909)</td></tr><tr><td>ln(αt)</td><td>-0.0316</td><td>0.3336</td><td></td><td></td></tr><tr><td>(Std. error)</td><td>(0.1201)</td><td>(0.0861)</td><td></td><td></td></tr><tr><td>kt</td><td>-0.6008</td><td>-0.2480</td><td></td><td>0.3175</td></tr><tr><td>(Std. error)</td><td>(0.1454)</td><td>(0.0731)</td><td></td><td>(0.0685)</td></tr></table>

aFour explanatory variables defined in the text are used. The model is for holding a long position on IBM stock. The sample mean of the log returns is removed from the data.

trend, indicating that the log returns of IBM stock are moving farther away from normality as time passes. Both the location and scale parameters increase over time.

2. Indicators for the fourth quarter, $x _ { 1 t }$ , and for panic selling, $x _ { 2 t }$ , are not significant for all three parameters.   
3. The location and shape parameters are positively affected by the volatility of the GARCH(1,1) model; see the coefficients of $x _ { 5 t }$ . This is understandable because the variability of log returns increases when the volatility is high. Consequently, the dependence of log returns on the tail index is reduced.   
4. The scale and shape parameters depend significantly on the qualitative measure of volatility. Signs of the estimates are also plausible.

The explanatory variables for December 31, 1998 assumed the values $x _ { 3 , 9 1 9 0 } =$ 0, $, x _ { 4 , 9 1 9 0 } = 0 . 9 7 3 7$ , and $x _ { 5 , 9 1 9 0 } = 1 . 9 7 6 6$ . Using these values and the fitted model in Table 7.4, we obtain

$$
k _ {9 1 9 0} = - 0. 0 1 1 9 5, \quad \ln (\alpha_ {9 1 9 0}) = 0. 1 9 3 3 1, \quad \beta_ {9 1 9 0} = 6. 1 0 5.
$$

Assume that the tail probability is 0.05. The VaR quantile shown in Eq. (7.38) gives $\mathrm { V a R } = 3 . 0 3 7 5 6 \%$ . Consequently, for a long position of $\$ 10$ million, we have

$$
\mathrm {V a R} = \\mathbb {1 0 , 0 0 0 , 0 0 0 \times 0 . 0 3 0 3 7 5 6} = \\mathbb {1 0 , 0 0 0 , 0 0 0 \times 0 . 0 3 0 3 7 5 6}.
$$

If the tail probability is 0.01, the VaR is $\$ 497,425$ . The $5 \%$ VaR is slightly larger than that of Example 7.3, which uses a Gaussian AR(2)–GARCH(1,1) model. The $1 \%$ VaR is larger than that of Case 1 of Example 7.3. Again, as expected, the effect of extreme values (i.e., heavy tails) on VaR is more pronounced when the tail probability used is small.

An advantage of using explanatory variables is that the parameters are adaptive to the change in market conditions. For example, the explanatory variables for December 30, 1998 assumed the values $x _ { 3 , 9 1 8 9 } = 1$ , $x _ { 4 , 9 1 8 9 } = 0 . 9 7 3 7$ , and $x 5 , 9 1 8 9 =$ 1.8757. In this case, we have

$$
k _ {9 1 8 9} = - 0. 2 5 0 0, \quad \ln (\alpha_ {9 1 8 9}) = 0. 5 2 3 8 5, \quad \beta_ {9 1 8 9} = 5. 8 8 3 4.
$$

The $9 5 \%$ quantile (i.e., the tail probability is $5 \%$ ) then becomes $2 . 6 9 1 3 9 \%$ . Consequently, the VaR is

$$
\mathrm {V a R} = \$ 1 0, 0 0 0, 0 0 0 \times 0. 0 2 6 9 1 3 9 = \$ 2 6 9, 1 3 9.
$$

If the tail probability is 0.01, then VaR becomes $\$ 448,323$ . Based on this example, the homogeneous Poisson model shown in Example 7.8 seems to underestimate the VaR.

# EXERCISES

7.1. Consider the daily returns of GE stock from July 3, 1962 to December 31, 1999. The data can be obtained from CRSP or the file d-ge6299.txt Convert the simple returns into log returns. Suppose that you hold a long position on the stock valued at $\$ 1$ million. Use the tail probability 0.05. Compute the value at risk of your position for 1-day horizon and 15-day horizon using the following methods:

(a) The RiskMetrics method.   
(b) A Gaussian ARMA–GARCH model.   
(c) An ARMA–GARCH model with a Student-t distribution. You should also estimate the degrees of freedom.   
(d) The traditional extreme value theory with subperiod length $n = 2 1$ .

7.2. The file d-csco9199.txt contains the daily simple returns of Cisco Systems stock from 1991 to 1999 with 2275 observations. Transform the simple returns to log returns. Suppose that you hold a long position of Cisco stock valued at $\$ 1$ million. Compute the value at risk of your position for the next trading day using probability $p = 0 . 0 1$ .

(a) Use the RiskMetrics method.   
(b) Use a GARCH model with a conditional Gaussian distribution.   
(c) Use a GARCH model with a Student-t distribution. You may also estimate the degrees of freedom.   
(d) Use the unconditional sample quantile.   
(e) Use a two-dimensional homogeneous Poisson process with threshold $2 \%$ that is, focusing on the exceeding times and exceedances that the daily stock price drops $2 \%$ or more. Check the fitted model.   
(f) Use a two-dimensional nonhomogeneous Poisson process with threshold $2 \%$ . The explanatory variables are (1) an annual time trend, (2) a dummy variable for October, November, and December, and (3) a fitted volatility based on a Gaussian GARCH(1,1) model. Perform a diagnostic check on the fitted model.   
(g) Repeat the prior two-dimensional nonhomogeneous Poisson process with threshold $2 . 5 \%$ or $3 \%$ . Comment on the selection of threshold.

7.3. Use Hill’s estimator and the data d-csco9199.txt to estimate the tail index for daily log returns of Cisco stock.

7.4. The file d-hwp3dx8099.txt contains dates and the daily simple returns of Hewlett-Packard, the CRSP value-weighted index, equal-weighted index, and the S&P 500 index from 1980 to 1999. The returns include dividend distributions. Transform the simple returns to log returns. Assume that the tail probability of interest is 0.01. Calculate value at risk for the following financial positions for the first trading day of year 2000.

(a) Long on Hewlett-Packard stock of $\$ 1$ million dollars and the S&P 500 index of $\$ 1$ million using RiskMetrics. The $\alpha$ coefficient of the IGARCH(1,1) model for each series should be estimated.   
(b) The same position as part (a), but using a univariate ARMA–GARCH model for each return series.   
(c) A long position on Hewlett-Packard stock of $\$ 1$ million using a twodimensional nonhomogeneous Poisson model with the following explanatory variables: (1) an annual time trend, (2) a fitted volatility based on a Gaussian GARCH model for Hewlett-Packard stock, (3) a fitted volatility based on a Gaussian GARCH model for the S&P 500 index returns, and (4) a fitted volatility based on a Gaussian GARCH model for the valueweighted index return. Perform a diagnostic check for the fitted models. Are the market volatility as measured by the S&P 500 index and valueweighted index returns helpful in determining the tail behavior of stock returns of Hewlett-Packard? You may choose several thresholds.

7.5. Consider the daily returns of Alcoa (AA) stock and the S&P 500 composite index (SPX) from 1980 to 2003. The simple returns and dates are in the file d-aaspx8003.txt. Transform the simple returns to log returns and focus on the daily negative log returns of AA stock.

(a) Fit the generalized extreme value distribution to the negative AA log returns, in percentages, with subperiods of 21 trading days. Write down the parameter estimates and their standard errors. Obtain a scatterplot and a QQ-plot of the residuals.   
(b) What is the return level of the prior fitted model when 24 subperiods of 21 days are used?   
(c) Obtain a QQ-plot (against exponential distribution) of the negative log returns with threshold $2 . 5 \%$ and a mean excess plot of the returns.   
(d) Fit a generalize Pareto distribution to the negative log returns with threshold $3 . 5 \%$ . Write down the parameter estimates and their standard errors.   
(e) Obtain (i) a plot of excess distribution, (ii) a plot of the tail of the underlying distribution, (iii) a scatterplot of residuals, and (iv) a QQ-plot of the residuals for the fitted GPD.   
(f) Based on the fitted GPD model, compute the VaR and expected shortfall for probabilities $q = 0 . 9 5$ , 0.99, and 0.999.

7.6. Consider, again, the daily log returns of Alcoa (AA) stock in Exercise 7.5. Focus now on the daily positive log returns. Answer the same questions as in Exercise 7.5. However, use threshold $3 \%$ in fitting the GPD model.

7.7. Consider the daily returns of SPX in d-aaspx8003.txt. Transform the returns into log returns and focus on the daily negative log returns.

(a) Fit the generalized extreme value distribution to the negative SPX log returns, in percentages, with subperiods of 21 trading days. Write down

the parameter estimates and their standard errors. Obtain a scatterplot and a QQ-plot of the residuals.   
(b) What is the return level of the prior fitted model when 24 subperiods of 21 days are used?   
(c) Obtain a QQ-plot (against exponential distribution) of the negative log returns with threshold $2 . 5 \%$ and a mean excess plot of the returns.   
(d) Fit a generalize Pareto distribution to the negative log returns with threshold $2 . 5 \%$ . Write down the parameter estimates and their standard errors.   
(e) Obtain (i) a plot of excess distribution, (ii) a plot of the tail of the underlying distribution, (iii) a scatterplot of residuals, and (iv) a QQ-plot of the residuals for the fitted GPD.   
(f) Based on the fitted GPD model, compute the VaR and expected shortfall for probabilities $q = 0 . 9 5$ , 0.99, and 0.999.

# REFERENCES

Berman, S. M. (1964). Limiting theorems for the maximum term in stationary sequences. Annals of Mathematical Statistics 35: 502–516.   
Coles, S. (2001). An Introduction to Statistical Modeling of Extreme Values. Springer-Verlag, New York.   
Cox, D. R. and Hinkley, D. V. (1974). Theoretical Statistics. Chapman and Hall, London.   
Danielsson, J. and de Vries, C. G. (1997a). Value at risk and extreme returns. Working paper, London School of Economics, London, U.K.   
Danielsson, J. and de Vries, C. G. (1997b). Tail index and quantile estimation with very high frequency data. Journal of Empirical Finance 4: 241–257.   
Davison, A. C. and Smith, R. L. (1990). Models for exceedances over high thresholds (with discussion). Journal of the Royal Statistical Society Series B 52: 393–442.   
Dekkers, A. L. M. and De Haan, L. (1989). On the estimation of extreme value index and large quantile estimation. Annals of Statistics 17: 1795–1832.   
Duffie, D. and Pan, J. (1997). An overview of value at risk. Journal of Derivatives Spring: 7–48.   
Embrechts, P., Kuppelberg, C., and Mikosch, T. (1997). Modelling Extremal Events. Springer Verlag, Berlin.   
Feller, W. (1971). An Introduction to Probability Theory and Its Applications, Volume 2. Wiley, Hoboken, NJ.   
Goldie, C. M., and Smith, R. L. (1987). Slow variation with remainder: Theory and applications. Quarterly Journal of Mathematics 38: 45–71.   
Gnedenko, B. V. (1943). Sur la distribution limite du terme maximum of d’une serie ´ Aleatorie. ´ Annals of Mathematics 44: 423–453.   
Gumbel, E. J. (1958). Statistics of Extremes. Columbia University Press, New York.   
Hill, B. M. (1975). A simple general approach to inference about the tail of a distribution. Annals of Statistics 3: 1163–1173.

Jenkinson, A. F. (1955). The frequency distribution of the annual maximum (or minimum) of meteorological elements. Quarterly Journal of the Royal Meteorological Society 81: 158–171.   
Jorion, P. (1997). Value at Risk: The New Benchmark for Controlling Market Risk. McGraw-Hill, Chicago.   
Koenker, R. W. and Bassett, G. W. (1978). Regression quantiles. Econometrica 46: 33–50.   
Koenker, R. W. and D’Orey, V. (1987). Computing regression quantiles. Applied Statistics 36: 383–393.   
Leadbetter, M. R., Lindgren, G., and Rootzen, H. (1983). ´ Extremes and Related Properties of Random Sequences and Processes. Springer-Verlag, New York.   
Longerstaey, J. and More, L. (1995). Introduction to RiskMetricsTM, 4th edition. Morgan Guaranty Trust Company, New York.   
Longin, F. M. (1996). The asymptotic distribution of extreme stock market returns. Journal of Business 69: 383–408.   
Longin, F. M. (1999a). Optimal margin level in futures markets: Extreme price movements. The Journal of Futures Markets 19: 127–152.   
Longin, F. M. (1999b). From value at risk to stress testing: the extreme value approach. Working paper, Centre for Economic Policy Research, London, UK.   
Pickands, J. (1975). Statistical inference using extreme order statistics. Annals of Statistics 3: 119–131.   
Smith, R. L. (1989). Extreme value analysis of environmental time series: An application to trend detection in ground-level ozone (with discussion). Statistical Science 4: 367–393.   
Smith, R. L. (1999). Measuring risk with extreme value theory. Working paper, Department of Statistics, University of North Carolina at Chapel Hill.   
Smith, R. L. and Shively, T. S. (1995). A point process approach to modeling trends in tropospheric ozone. Atmospheric Environment 29: 3489–3499.   
Tsay, R. S. (1999). Extreme value analysis of financial data. Working paper, Graduate School of Business, University of Chicago.   
Zivot, E. and Wang, J. (2003). Modeling Financial Time Series with S-Plus. Springer-Verlag, New York.

# Multivariate Time Series Analysis and Its Applications

Economic globalization and internet communication have accelerated the integration of world financial markets in recent years. Price movements in one market can spread easily and instantly to another market. For this reason, financial markets are more dependent on each other than ever before, and one must consider them jointly to better understand the dynamic structure of global finance. One market may lead the other market under some circumstances, yet the relationship may be reversed under other circumstances. Consequently, knowing how the markets are interrelated is of great importance in finance. Similarly, for an investor or a financial institution holding multiple assets, the dynamic relationships between returns of the assets play an important role in decision making. In this and the next two chapters, we introduce econometric models and methods useful for studying jointly multiple return series. In the statistical literature, these models and methods belong to vector or multivariate time series analysis.

A multivariate time series consists of multiple single series referred to as components. As such, concepts of vector and matrix are important in multivariate time series analysis. We use boldface notation to indicate vectors and matrices. If necessary, readers may consult Appendix A of this chapter for some basic operations and properties of vectors and matrices. Appendix B provides some results of multivariate normal distribution, which is widely used in multivariate statistical analysis (e.g., Johnson and Wichern, 1998).

Let $\pmb { r } _ { t } = ( r _ { 1 t } , r _ { 2 t } , . . . , r _ { k t } ) ^ { \prime }$ be the log returns of $k$ assets at time $t$ , where $\mathbf { \Delta } \mathbf { a ^ { \prime } }$ denotes the transpose of $\pmb { a }$ . For example, an investor holding stocks of IBM, Microsoft, Exxon Mobil, General Motors, and Wal-Mart Stores may consider the five-dimensional daily log returns of these companies. Here $r _ { 1 t }$ denotes the daily log return of IBM stock, $r _ { 2 t }$ is that of Microsoft, and so on. As a second example, an investor who is interested in global investment may consider the return series of the S&P 500 index of the United States, the FTSE 100 index of the United

Kingdom, and the Nikkei 225 index of Japan. Here the series is three-dimensional, with $r _ { 1 t }$ denoting the return of the S&P 500 index, $r _ { 2 t }$ the return of the FTSE 100 index, and $r _ { 3 t }$ the return of the Nikkei 225. The goal of this chapter is to study econometric models for analyzing the multivariate process $r _ { t }$ .

Many of the models and methods discussed in previous chapters can be generalized directly to the multivariate case. But there are situations in which the generalization requires some attention. In some situations, one needs new models and methods to handle the complicated relationships between multiple series. In this chapter, we discuss these issues with emphasis on intuition and applications. For statistical theory of multivariate time series analysis, readers are referred to Lutkepohl (1991) and Reinsel (1993). ¨

# 8.1 WEAK STATIONARITY AND CROSS-CORRELATION MATRICES

Consider a $k$ -dimensional time series $\pmb { r } _ { t } = ( r _ { 1 t } , \ldots , r _ { k t } ) ^ { \prime }$ . The series $r _ { t }$ is weakly stationary if its first and second moments are time-invariant. In particular, the mean vector and covariance matrix of a weakly stationary series are constant over time. Unless stated explicitly to the contrary, we assume that the return series of financial assets are weakly stationary.

For a weakly stationary time series $r _ { t }$ , we define its mean vector and covariance matrix as

$$
\boldsymbol {\mu} = E \left(\boldsymbol {r} _ {t}\right), \quad \Gamma_ {0} = E \left[ \left(\boldsymbol {r} _ {t} - \boldsymbol {\mu}\right) \left(\boldsymbol {r} _ {t} - \boldsymbol {\mu}\right) ^ {\prime} \right], \tag {8.1}
$$

where the expectation is taken element by element over the joint distribution of $r _ { t }$ . The mean $\pmb { \mu }$ is a $k$ -dimensional vector consisting of the unconditional expectations of the components of $r _ { t }$ . The covariance matrix $\Gamma _ { 0 }$ is a $k \times k$ matrix. The ith diagonal element of $\Gamma _ { 0 }$ is the variance of $r _ { i t }$ , whereas the $( i , j )$ th element of $\Gamma _ { 0 }$ is the covariance between $r _ { i t }$ and $r _ { j t }$ . We write $\pmb { \mu } = ( \mu _ { 1 } , \ldots , \mu _ { k } ) ^ { \prime }$ and $\Gamma _ { 0 } = [ \Gamma _ { i j } ( 0 ) ]$ when the elements are needed.

# 8.1.1 Cross-Correlation Matrices

Let $\pmb { D }$ be a $k \times k$ diagonal matrix consisting of the standard deviations of $r _ { i t }$ for $i = 1 , \ldots , k$ . In other words, $\pmb { D } = \mathrm { d i a g } \{ \sqrt { \Gamma _ { 1 1 } ( 0 ) } , \dots , \sqrt { \Gamma _ { k k } ( 0 ) } \}$ . The concurrent, or lag-zero, cross-correlation matrix of $r _ { t }$ is defined as

$$
\pmb {\rho} _ {0} \equiv [ \rho_ {i j} (0) ] = \pmb {D} ^ {- 1} \pmb {\Gamma} _ {0} \pmb {D} ^ {- 1}.
$$

More specifically, the $( i , j )$ th element of ${ \pmb \rho } _ { 0 }$ is

$$
\rho_ {i j} (0) = \frac {\Gamma_ {i j} (0)}{\sqrt {\Gamma_ {i i} (0) \Gamma_ {j j} (0)}} = \frac {\mathrm {C o v} (r _ {i t} , r _ {j t})}{\mathrm {s t d} (r _ {i t}) \mathrm {s t d} (r _ {j t})},
$$

which is the correlation coefficient between $r _ { i t }$ and $r _ { j t }$ . In time series analysis, such a correlation coefficient is referred to as a concurrent, or contemporaneous, correlation coefficient because it is the correlation of the two series at time t . It is

easy to see that $\rho _ { i j } ( 0 ) = \rho _ { j i } ( 0 )$ , $- 1 \le \rho _ { i j } ( 0 ) \le 1$ , and $\rho _ { i i } ( 0 ) = 1$ for $1 \leq i , j \leq k$ Thus, $\pmb { \rho } ( 0 )$ is a symmetric matrix with unit diagonal elements.

An important topic in multivariate time series analysis is the lead–lag relationships between component series. To this end, the cross-correlation matrices are used to measure the strength of linear dependence between time series. The lag- $\ell$ cross-covariance matrix of $r _ { t }$ is defined as

$$
\boldsymbol {\Gamma} _ {\ell} \equiv \left[ \Gamma_ {i j} (\ell) \right] = E \left[ \left(\boldsymbol {r} _ {t} - \boldsymbol {\mu}\right) \left(\boldsymbol {r} _ {t - \ell} - \boldsymbol {\mu}\right) ^ {\prime} \right], \tag {8.2}
$$

where $\pmb { \mu }$ is the mean vector of $r _ { t }$ . Therefore, the $( i , j )$ th element of $\mathbf { \Gamma } \Gamma _ { \ell }$ is the covariance between $r _ { i t }$ and $r _ { j , t - \ell }$ . For a weakly stationary series, the cross-covariance matrix $\mathbf { \Gamma } \Gamma _ { \ell }$ is a function of $\ell$ , not the time index $t$ .

The lag- $\ell$ cross-correlation matrix (CCM) of $r _ { t }$ is defined as

$$
\boldsymbol {\rho} _ {\ell} \equiv [ \rho_ {i j} (\ell) ] = \boldsymbol {D} ^ {- 1} \boldsymbol {\Gamma} _ {\ell} \boldsymbol {D} ^ {- 1}, \tag {8.3}
$$

where, as before, $\pmb { D }$ is the diagonal matrix of standard deviations of the individual series $r _ { i t }$ . From the definition,

$$
\rho_ {i j} (\ell) = \frac {\Gamma_ {i j} (\ell)}{\sqrt {\Gamma_ {i i} (0) \Gamma_ {j j} (0)}} = \frac {\operatorname {C o v} \left(r _ {i t} , r _ {j , t - \ell}\right)}{\operatorname {s t d} \left(r _ {i t}\right) \operatorname {s t d} \left(r _ {j t}\right)}, \tag {8.4}
$$

which is the correlation coefficient between $r _ { i t }$ and $r _ { j , t - \ell }$ . When $\ell > 0$ , this correlation coefficient measures the linear dependence of $r _ { i t }$ on $r _ { j , t - \ell }$ , which occurred prior to time t . Consequently, if $\rho _ { i j } ( \ell ) \neq 0$ and $\ell > 0$ , we say that the series $r _ { j t }$ leads the series $r _ { i t }$ at lag . Similarly, $\rho _ { j i } ( \ell )$ measures the linear dependence of $r _ { j t }$ and $r _ { i , t - \ell }$ , and we say that the series $r _ { i t }$ leads the series $r _ { j t }$ at lag $\ell$ if $\rho _ { j i } ( \ell ) \neq 0$ and $\ell > 0$ . Equation (8.4) also shows that the diagonal element $\rho _ { i i } ( \ell )$ is simply the lag- autocorrelation coefficient of $r _ { i t }$ .

Based on this discussion, we obtain some important properties of the crosscorrelations when $\ell > 0$ . First, in general, $\rho _ { i j } ( \ell ) \neq \rho _ { j i } ( \ell )$ for $i \neq j$ because the two correlation coefficients measure different linear relationships between $\{ r _ { i t } \}$ and $\{ r _ { j t } \}$ . Therefore, $\mathbf { \Gamma } \Gamma _ { \ell }$ and $\pmb { \rho } _ { \ell }$ are in general not symmetric. Second, using $\mathrm { C o v } ( x , y ) = \mathrm { C o v } ( y , x )$ and the weak stationarity assumption, we have

$$
\operatorname {C o v} \left(r _ {i t}, r _ {j, t - \ell}\right) = \operatorname {C o v} \left(r _ {j, t - \ell}, r _ {i t}\right) = \operatorname {C o v} \left(r _ {j t}, r _ {i, t + \ell}\right) = \operatorname {C o v} \left(r _ {j t}, r _ {i, t - (- \ell)}\right),
$$

so that $\Gamma _ { i j } ( \ell ) = \Gamma _ { j i } ( - \ell )$ . Because $\Gamma _ { j i } ( - \ell )$ is the $( j , i )$ th element of the matrix $\Gamma _ { - \ell }$ and the equality holds for 1  i, $j \le k$ , we have $\mathbf { \Gamma } \Gamma _ { \ell } = \mathbf { \Gamma } \Gamma _ { - \ell } ^ { \prime }$ and ${ \pmb \rho } _ { \ell } = { \pmb \rho } _ { - \ell } ^ { \prime }$ . Consequently, unlike the univariate case, $\pmb { \rho } _ { \ell } \neq \pmb { \rho } _ { - \ell }$ for a general vector time series when $\ell > 0$ . Because ${ \pmb \rho } _ { \ell } = { \pmb \rho } _ { - \ell } ^ { \prime }$ , it suffices in practice to consider the cross-correlation matrices $\pmb { \rho } _ { \ell }$ for $\ell \geq 0$ .

# 8.1.2 Linear Dependence

Considered jointly, the cross-correlation matrices $\{ \pmb { \rho } _ { \ell } | \ell = 0 , 1 , \ldots \}$ of a weakly stationary vector time series contain the following information:

1. The diagonal elements $\{ \rho _ { i i } ( \ell ) | \ell = 0 , 1 , \ldots \}$ are the autocorrelation function of $r _ { i t }$ .

2. The off-diagonal element $\rho _ { i j } ( 0 )$ measures the concurrent linear relationship between $r _ { i t }$ and $r _ { j t }$ .   
3. For $\ell > 0$ , the off-diagonal element $\rho _ { i j } ( \ell )$ measures the linear dependence of $r _ { i t }$ on the past value $r _ { j , t - \ell }$ .

Therefore, if $\rho _ { i j } ( \ell ) = 0$ for all $\ell > 0$ , then $r _ { i t }$ does not depend linearly on any past value $r _ { j , t - \ell }$ of the $r _ { j t }$ series.

In general, the linear relationship between two time series $\{ r _ { i t } \}$ and $\{ r _ { j t } \}$ can be summarized as follows:

1. $r _ { i t }$ and $r _ { j t }$ have no linear relationship if $\rho _ { i j } ( \ell ) = \rho _ { j i } ( \ell ) = 0$ for all $\ell \geq 0$ .   
2. $r _ { i t }$ and $r _ { j t }$ are concurrently correlated if $\rho _ { i j } ( 0 ) \neq 0$ .   
3. $r _ { i t }$ and $r _ { j t }$ have no lead–lag relationship if $\rho _ { i j } ( \ell ) = 0$ and $\rho _ { j i } ( \ell ) = 0$ for all $\ell > 0$ . In this case, we say the two series are uncoupled.   
4. There is a unidirectional relationship from $r _ { i t }$ to $r _ { j t }$ if $\rho _ { i j } ( \ell ) = 0$ for all $\ell > 0$ , but $\rho _ { j i } ( v ) \neq 0$ for some $v > 0$ . In this case, $r _ { i t }$ does not depend on any past value of $r _ { j t }$ , but $r _ { j t }$ depends on some past values of $r _ { i t }$ .   
5. There is a feedback relationship between $r _ { i t }$ and $r _ { j t }$ if $\rho _ { i j } ( \ell ) \neq 0$ for some $\ell > 0$ and $\rho _ { j i } ( v ) \neq 0$ for some $v > 0$ .

The conditions stated earlier are sufficient conditions. A more informative approach to study the relationship between time series is to build a multivariate model for the series because a properly specified model considers simultaneously the serial and cross-correlations among the series.

# 8.1.3 Sample Cross-Correlation Matrices

Given the data $\{ r _ { t } | t = 1 , \ldots , T \}$ , the cross-covariance matrix $\mathbf { \Gamma } \Gamma _ { \ell }$ can be estimated by

$$
\widehat {\Gamma} _ {\ell} = \frac {1}{T} \sum_ {t = \ell + 1} ^ {T} \left(\boldsymbol {r} _ {t} - \overline {{\boldsymbol {r}}}\right) \left(\boldsymbol {r} _ {t - \ell} - \overline {{\boldsymbol {r}}}\right) ^ {\prime}, \quad \ell \geq 0, \tag {8.5}
$$

where $\textstyle { \overline { { \pmb { r } } } } = \big ( \sum _ { t = 1 } ^ { T } { \pmb { r } } _ { t } \big ) / T$ is the vector of sample means. The cross-correlation matrix $\pmb { \rho } _ { \ell }$ is estimated by

$$
\widehat {\boldsymbol {\rho}} _ {\ell} = \widehat {\boldsymbol {D}} ^ {- 1} \widehat {\boldsymbol {\Gamma}} _ {\ell} \widehat {\boldsymbol {D}} ^ {- 1}, \quad \ell \geq 0, \tag {8.6}
$$

where $\widehat { \pmb { D } }$ is the $k \times k$ diagonal matrix of the sample standard deviations of the component series.

Similar to the univariate case, asymptotic properties of the sample crosscorrelation matrix $\widehat { \pmb { \rho } } _ { \ell }$ have been investigated under various assumptions; see, for instance, Fuller (1976, Chapter 6). The estimate is consistent but is biased in a finite sample. For asset return series, the finite sample distribution of $\widehat { \pmb { \rho } } _ { \ell }$ is

rather complicated partly because of the presence of conditional heteroscedasticity and high kurtosis. If the finite-sample distribution of cross-correlations is needed, we recommend that proper bootstrap resampling methods be used to obtain an approximate estimate of the distribution. For many applications, a crude approximation of the variance of $\hat { \rho } _ { i j } ( \ell )$ is sufficient.

Example 8.1. Consider the monthly log returns of IBM stock and the S&P 500 index from January 1926 to December 1999 with 888 observations. The returns include dividend payments and are in percentages. Denote the returns of IBM stock and the S&P 500 index by $r _ { 1 t }$ and $r _ { 2 t }$ , respectively. These two returns form a bivariate time series $\pmb { r } _ { t } = ( r _ { 1 t } , r _ { 2 t } ) ^ { \prime }$ . Figure 8.1 shows the time plots of $r _ { t }$ using the same scale. Figure 8.2 shows some scatterplots of the two series. The plots show that the two return series are concurrently correlated. Indeed, the sample concurrent correlation coefficient between the two returns is 0.64, which is statistically significant at the $5 \%$ level. However, the cross-correlations at lag 1 are weak if any.

Table 8.1 provides some summary statistics and cross-correlation matrices of the two series. For a bivariate series, each CCM is a $2 \times 2$ matrix with four correlations. Empirical experience indicates that it is rather hard to absorb simultaneously many cross-correlation matrices, especially when the dimension $k$ is greater than 3. To overcome this difficulty, we use the simplifying notation of Tiao and Box (1981)

![](images/eb333034e7d562f371604858d8485eaa80b265bf5bef02bedcc26d63ffb22845.jpg)

![](images/4bbca5cd718aa6d1d63334a9d306abf1b46e2c337e398c2aa5f9d922b08ce754.jpg)  
Figure 8.1. Time plots of (a) monthly log returns in percentages for IBM stock and (b) the S&P 500 index from January 1926 to December 1999.

![](images/f4e889a69cf8e70a17929c7953e44d14e987232194880dc30e7cd592e85479a9.jpg)

![](images/bc3861f2d8bceb476cda64150ecd598c828c56898f78cbcbb01300ee36c9a27a.jpg)

![](images/4366fabdbc34d6f5667392e6361aefd9767abf2414b12ebca195994c6e73fe49.jpg)

![](images/81035daf60c44015d5f1cd4f567f586d7e6cc009a19100402da3bab08cb4a052.jpg)  
Figure 8.2. Some scatterplots for monthly log returns of IBM stock and the S&P 500 index: (a) concurrent plot of IBM versus S&P 500 (b) S&P 500 versus lag-1 IBM, (c) IBM versus lag-1 S&P 500, and (d) S&P 500 versus lag-1 S&P 500.

and define a simplified cross-correlation matrix consisting of three symbols “ $^ { + }$ ,” “−,” and “.,” where

1. $" + "$ means that the corresponding correlation coefficient is greater than or equal to $2 / \sqrt { T }$ ,   
2. “−” means that the corresponding correlation coefficient is less than or equal to $- 2 / \sqrt { T }$ , and   
3. “.” means that the corresponding correlation coefficient is between $- 2 / \sqrt { T }$ and $2 / \sqrt { T }$ ,

where $1 / \sqrt { T }$ is the asymptotic $5 \%$ critical value of the sample correlation under the assumption that $r _ { t }$ is a white noise series.

Table 8.1c shows the simplified CCM for the monthly log returns of IBM stock and the S&P 500 index. It is easily seen that significant cross-correlations at the approximate $5 \%$ level appear mainly at lags 1 and 3. An examination of the sample CCMs at these two lags indicates that (a) S&P 500 index returns have some marginal autocorrelations at lags 1 and 3, and (b) IBM stock returns depend weakly on the previous returns of the S&P 500 index. The latter observation is based on the significance of cross-correlations at the (1, 2)th element of lag-1 and lag-3 CCMs.

Table 8.1. Summary Statistics and Cross-Correlation Matrices of Monthly Log Returns of IBM Stock and the S&P 500 Index: January 1926 to December 1999   

<table><tr><td colspan="8">(a) Summary Statistics</td></tr><tr><td>Ticker</td><td>Mean</td><td>Standard Error</td><td>Skewness</td><td>Excess Kurtosis</td><td>Minimum</td><td>Maximum</td><td></td></tr><tr><td>IBM</td><td>1.240</td><td>6.729</td><td>-0.237</td><td>1.917</td><td>-30.37</td><td>30.10</td><td></td></tr><tr><td>S&amp;P 500</td><td>0.537</td><td>5.645</td><td>-0.521</td><td>8.117</td><td>-35.58</td><td>35.22</td><td></td></tr><tr><td colspan="8">(b) Cross-Correlation Matrices</td></tr><tr><td></td><td>Lag 1</td><td>Lag 2</td><td>Lag 3</td><td>Lag 4</td><td>Lag 5</td><td></td><td></td></tr><tr><td></td><td>0.08 0.10</td><td>0.02 -0.06</td><td>-0.02 -0.07</td><td>-0.02 -0.03</td><td>0.00 0.07</td><td></td><td></td></tr><tr><td></td><td>0.04 0.08</td><td>0.02 -0.02</td><td>-0.07 -0.11</td><td>0.04 0.02</td><td>0.00 0.08</td><td></td><td></td></tr><tr><td colspan="8">(c) Simplified Notation</td></tr><tr><td></td><td></td><td>[ + + ]</td><td>[ • • ]</td><td>[ • - ]</td><td>[ • • ]</td><td>[ • + ]</td><td></td></tr></table>

Figure 8.3 shows the sample autocorrelations and cross-correlations of the two series. Since the ACF is symmetric with respect to lag 0, only those of positive lags are shown. Because lagged values of the S&P 500 index return are used to compute the cross-correlations, the plot associated with positive lags in Figure 8.3c shows the dependence of IBM stock return on the past S&P 500 index returns, and the plot associated with negative lags shows the linear dependence of the index return on the past IBM stock returns. The horizontal lines in the plots are the asymptotic two standard-error limits of the sample auto- and cross-correlation coefficients. From the plots, the dynamic relationship is weak between the two return series, but their contemporaneous correlation is statistically significant.

Example 8.2. Consider the simple returns of monthly indexes of U.S. government bonds with maturities in 30 years, 20 years, 10 years, 5 years, and 1 year. The data obtained from the CRSP database have 696 observations starting from January 1942 to December 1999. Let $\pmb { r } _ { t } = ( r _ { 1 t } , \ldots , r _ { 5 t } ) ^ { \prime }$ be the return series with decreasing time to maturity. Figure 8.4 shows the time plots of $r _ { t }$ on the same scale. The variability of the 1-year bond returns is much smaller than that of returns with longer maturities. The sample means and standard deviations of the data are $\widehat { \pmb { \mu } } =$ $1 0 ^ { - 2 } ( 0 . 4 3 , 0 . 4 5 , 0 . 4 5 , 0 . 4 6 , 0 . 4 4 ) ^ { \prime }$ and $\widehat { \pmb { \sigma } } = 1 0 ^ { - 2 } ( 2 . 5 3 , 2 . 4 3 , 1 . 9 7 , 1 . 3 9 , 0 . 5 3 ) ^ { \prime } .$ The concurrent correlation matrix of the series is

$$
\widehat {\boldsymbol {p}} _ {0} = \left[ \begin{array}{c c c c c} 1. 0 0 & 0. 9 8 & 0. 9 2 & 0. 8 5 & 0. 6 3 \\ 0. 9 8 & 1. 0 0 & 0. 9 1 & 0. 8 6 & 0. 6 4 \\ 0. 9 2 & 0. 9 1 & 1. 0 0 & 0. 9 0 & 0. 6 8 \\ 0. 8 5 & 0. 8 6 & 0. 9 0 & 1. 0 0 & 0. 8 2 \\ 0. 6 3 & 0. 6 4 & 0. 6 8 & 0. 8 2 & 1. 0 0 \end{array} \right].
$$

![](images/a2c36b4ae2d2996de436f3cf686be91bb0ca65569ff243a9db5e1c8d47b4aef1.jpg)

![](images/e0cbdcfdfeb6df6d20cea92682e9cfe0fe912e4af52eed4a827650fdd5d78b9a.jpg)

![](images/dcca3b36791afb331accb6c3db3783f8367db9564f82379ca965a19df91e6a9a.jpg)  
Figure 8.3. Sample auto- and cross-correlation functions of two monthly log returns: (a) sample ACF of IBM stock returns, (b) sample ACF of S&P 500 index returns, and (c) cross-correlations between IBM stock return and lagged S&P 500 index returns.

It is not surprising that (a) the series have high concurrent correlations, and (b) the correlations between long-term bonds are higher than those between shortterm bonds.

Table 8.2 gives the lag-1 and lag-2 cross-correlation matrices of $r _ { t }$ and the corresponding simplified matrices. Most of the significant cross-correlations are at lag 1, and the five return series appear to be intercorrelated. In addition, lag-1 and lag-2 sample ACFs of the 1-year bond returns are substantially higher than those of other series with longer maturities.

# 8.1.4 Multivariate Portmanteau Tests

The univariate Ljung–Box statistic $Q ( m )$ has been generalized to the multivariate case by Hosking (1980, 1981) and Li and McLeod (1981). For a multivariate series, the null hypothesis of the test statistic is $H _ { 0 } : \pmb { \rho } _ { 1 } = \cdot \cdot \cdot = \pmb { \rho } _ { m } = \pmb { 0 }$ , and the

![](images/364873a322c9ff20097d69730e8f57b0371886049a0b169c3033743772480b3b.jpg)

![](images/cbeac2365d390795a954892a4b2c59e3c6e828a06bab36ce298d05868518af0b.jpg)

![](images/46572c4b709d0c788ebd174b798a542fadeab9e463eec9da60fa662b193b92eb.jpg)

![](images/cc549526a6dbc7f66683b60964f8fffa79705914a9691157cebdc96f74dce9c9.jpg)

![](images/c4506e6a4f001f7ed4901ab2b42eedbb874857f5f2475a1e03cd96e5b61d0b94.jpg)  
Figure 8.4. Time plots of monthly simple returns of five indexes of U.S. government bonds with maturities in (a) 30 years, (b) 20 years, (c) 10 years, (d) 5 years, and (e) 1 year. The sample period is from January 1942 to December 1999.

alternative hypothesis $H _ { a } : \pmb { \rho } _ { i } \neq \pmb { 0 }$ for some $i \in \{ 1 , \ldots , m \}$ . Thus, the statistic is used to test that there are no auto- and cross-correlations in the vector series $r _ { t }$ . The test statistic assumes the form

$$
Q _ {k} (m) = T ^ {2} \sum_ {\ell = 1} ^ {m} \frac {1}{T - \ell} t r \left(\widehat {\boldsymbol {\Gamma}} _ {\ell} ^ {\prime} \widehat {\boldsymbol {\Gamma}} _ {0} ^ {- 1} \widehat {\boldsymbol {\Gamma}} _ {\ell} \widehat {\boldsymbol {\Gamma}} _ {0} ^ {- 1}\right), \tag {8.7}
$$

where $T$ is the sample size, $k$ is the dimension of $r _ { t }$ , and $t r ( A )$ is the trace of the matrix $A$ , which is the sum of the diagonal elements of $A$ . Under the null hypothesis and some regularity conditions, $Q _ { k } ( m )$ follows asymptotically a chi-squared distribution with $k ^ { 2 } m$ degrees of freedom.

Table 8.2. Sample Cross-Correlation Matrices of Monthly Simple Returns of Five Indexes of U.S. Government Bonds: January 1942 to December 1999   

<table><tr><td colspan="5">Lag 1</td><td colspan="5">Lag 2</td></tr><tr><td colspan="10">Cross-Correlations</td></tr><tr><td>0.10</td><td>0.08</td><td>0.11</td><td>0.12</td><td>0.16</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>-0.03</td><td>0.03</td></tr><tr><td>0.10</td><td>0.08</td><td>0.12</td><td>0.14</td><td>0.17</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>-0.04</td><td>0.02</td></tr><tr><td>0.09</td><td>0.08</td><td>0.09</td><td>0.13</td><td>0.18</td><td>0.01</td><td>0.01</td><td>0.01</td><td>-0.02</td><td>0.07</td></tr><tr><td>0.14</td><td>0.12</td><td>0.15</td><td>0.14</td><td>0.22</td><td>-0.02</td><td>-0.01</td><td>0.00</td><td>-0.04</td><td>0.07</td></tr><tr><td>0.17</td><td>0.15</td><td>0.21</td><td>0.22</td><td>0.40</td><td>-0.02</td><td>0.00</td><td>0.02</td><td>0.02</td><td>0.22</td></tr></table>

Simplified Cross-Correlation Matrices   

<table><tr><td>[++++]</td><td>[...]</td></tr></table>

Remark. The $Q _ { k } ( m )$ statistics can be rewritten in terms of the sample crosscorrelation matrixes $\widehat { \pmb { \rho } } _ { \ell }$ . Using the Kronecker product $\otimes$ and vectorization of matrices discussed in Appendix A of this chapter, we have

$$
Q _ {k} (m) = T ^ {2} \sum_ {\ell = 1} ^ {m} \frac {1}{T - \ell} \boldsymbol {b} _ {\ell} ^ {\prime} \left(\widehat {\boldsymbol {\rho}} _ {0} ^ {- 1} \otimes \widehat {\boldsymbol {\rho}} _ {0} ^ {- 1}\right) \boldsymbol {b} _ {\ell},
$$

where $\pmb { b } _ { \ell } = \mathrm { v e c } ( \widetilde { \pmb { \rho } } _ { \ell } ^ { \prime } )$ . The test statistic proposed by Li and McLeod (1981) is

$$
Q _ {k} ^ {*} (m) = T \sum_ {\ell = 1} ^ {m} \boldsymbol {b} _ {\ell} ^ {\prime} (\widehat {\boldsymbol {\rho}} _ {0} ^ {- 1} \otimes \widehat {\boldsymbol {\rho}} _ {0} ^ {- 1}) \boldsymbol {b} _ {\ell} + \frac {k ^ {2} m (m + 1)}{2 T},
$$

which is asymptotically equivalent to $Q _ { k } ( m )$ .

Applying the $Q _ { k } ( m )$ statistics to the bivariate monthly log returns of IBM stock and the S&P 500 index of Example 8.1, we have $Q _ { 2 } ( 1 ) = 9 . 8 1$ , $Q _ { 2 } ( 5 ) = 4 7 . 0 6$ , and $Q _ { 2 } ( 1 0 ) = 7 1 . 6 5$ . Based on asymptotic chi-squared distributions with degrees of freedom 4, 20, and 40, the $p$ -values of these $Q _ { 2 } ( m )$ statistics are 0.044, 0.001, and 0.002, respectively. The portmanteau tests thus confirm the existence of serial dependence in the bivariate return series at the $5 \%$ significance level. For the five-dimensional monthly simple returns of bond indexes in Example 8.2, we

have $Q _ { 5 } ( 5 ) = 1 0 6 5 . 6 3$ , which is highly significant compared with a chi-squared distribution with 125 degrees of freedom.

The $Q _ { k } ( m )$ statistic is a joint test for checking the first m cross-correlation matrices of $r _ { t }$ . If it rejects the null hypothesis, then we build a multivariate model for the series to study the lead–lag relationships between the component series. In what follows, we discuss some simple vector models useful for modeling the linear dynamic structure of a multivariate financial time series.

# 8.2 VECTOR AUTOREGRESSIVE MODELS

A simple vector model useful in modeling asset returns is the vector autoregressive (VAR) model. A multivariate time series $r _ { t }$ is a VAR process of order 1, or VAR(1) for short, if it follows the model

$$
\boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} \boldsymbol {r} _ {t - 1} + \boldsymbol {a} _ {t}, \tag {8.8}
$$

where $\phi _ { 0 }$ is a $k$ -dimensional vector, $\Phi$ is a $k \times k$ matrix, and $\left\{ \pmb { a } _ { t } \right\}$ is a sequence of serially uncorrelated random vectors with mean zero and covariance matrix $\pmb { \Sigma }$ . In application, the covariance matrix $\pmb { \Sigma }$ is required to be positive definite; otherwise, the dimension of $r _ { t }$ can be reduced. In the literature, it is often assumed that $\pmb { a } _ { t }$ is multivariate normal.

Consider the bivariate case (i.e., $k = 2$ , $\pmb { r } _ { t } = ( r _ { 1 t } , r _ { 2 t } ) ^ { \prime }$ , and $\pmb { a } _ { t } = ( a _ { 1 t } , a _ { 2 t } ) ^ { \prime } )$ . The VAR(1) model consists of the following two equations:

$$
\begin{array}{l} r _ {1 t} = \phi_ {1 0} + \Phi_ {1 1} r _ {1, t - 1} + \Phi_ {1 2} r _ {2, t - 1} + a _ {1 t}, \\ r _ {2 t} = \phi_ {2 0} + \Phi_ {2 1} r _ {1, t - 1} + \Phi_ {2 2} r _ {2, t - 1} + a _ {2 t}, \\ \end{array}
$$

where $\Phi _ { i j }$ is the $( i , j )$ th element of $\Phi$ and $\phi _ { i 0 }$ is the $i$ th element of $\phi _ { 0 }$ . Based on the first equation, $\Phi _ { 1 2 }$ denotes the linear dependence of $r _ { 1 t }$ on $r _ { 2 , t - 1 }$ in the presence of $r _ { 1 , t - 1 }$ . Therefore, $\Phi _ { 1 2 }$ is the conditional effect of $r _ { 2 , t - 1 }$ on $r _ { 1 t }$ given $r _ { 1 , t - 1 }$ . If $\Phi _ { 1 2 } = 0$ , then $r _ { 1 t }$ does not depend on $r _ { 2 , t - 1 }$ , and the model shows that $r _ { 1 t }$ only depends on its own past. Similarly, if $\Phi _ { 2 1 } = 0$ , then the second equation shows that $r _ { 2 t }$ does not depend on $r _ { 1 , t - 1 }$ when $r _ { 2 , t - 1 }$ is given.

Consider the two equations jointly. If $\Phi _ { 1 2 } = 0$ and $\Phi _ { 2 1 } \neq 0$ , then there is a unidirectional relationship from $r _ { 1 t }$ to $r _ { 2 t }$ . If $\Phi _ { 1 2 } = \Phi _ { 2 1 } = 0$ , then $r _ { 1 t }$ and $r _ { 2 t }$ are uncoupled. If $\Phi _ { 1 2 } \neq 0$ and $\Phi _ { 2 1 } \neq 0$ , then there is a feedback relationship between the two series.

# 8.2.1 Reduced and Structural Forms

In general, the coefficient matrix $\Phi$ of Eq. (8.8) measures the dynamic dependence of $r _ { t }$ . The concurrent relationship between $r _ { 1 t }$ and $r _ { 2 t }$ is shown by the off-diagonal element $\sigma _ { 1 2 }$ of the covariance matrix $\pmb { \Sigma }$ of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi$ . If $\sigma _ { 1 2 } = 0$ , then there is no concurrent linear relationship between the two component series. In the econometric literature, the VAR(1) model in Eq. (8.8) is called a reduced-form model because it

does not show explicitly the concurrent dependence between the component series. If necessary, an explicit expression involving the concurrent relationship can be deduced from the reduced-form model by a simple linear transformation. Because $\pmb { \Sigma }$ is positive definite, there exists a lower triangular matrix $\pmb { L }$ with unit diagonal elements and a diagonal matrix $\textbf { G }$ such that $\pmb { \Sigma } = \pmb { L G L ^ { \prime } }$ ; see Appendix A on Cholesky decomposition. Therefore, $\pmb { L } ^ { - 1 } \pmb { \Sigma } ( \pmb { L } ^ { \prime } ) ^ { - 1 } = \pmb { G }$ .

Define $\pmb { b } _ { t } = ( b _ { 1 t } , \dots , b _ { k t } ) ^ { \prime } = L ^ { - 1 } \pmb { a } _ { t }$ . Then

$$
E \left(\boldsymbol {b} _ {t}\right) = \boldsymbol {L} ^ {- 1} E \left(\boldsymbol {a} _ {t}\right) = \boldsymbol {0}, \quad \operatorname {C o v} \left(\boldsymbol {b} _ {t}\right) = \boldsymbol {L} ^ {- 1} \boldsymbol {\Sigma} \left(\boldsymbol {L} ^ {- 1}\right) ^ {\prime} = \boldsymbol {L} ^ {- 1} \boldsymbol {\Sigma} \left(\boldsymbol {L} ^ {\prime}\right) ^ {- 1} = \boldsymbol {G}.
$$

Since $\textbf { G }$ is a diagonal matrix, the components of $\mathbf { } _ { \pmb { b } _ { t } }$ are uncorrelated. Multiplying $L ^ { - 1 }$ from the left to model (8.8), we obtain

$$
\boldsymbol {L} ^ {- 1} \boldsymbol {r} _ {t} = \boldsymbol {L} ^ {- 1} \boldsymbol {\phi} _ {0} + \boldsymbol {L} ^ {- 1} \boldsymbol {\Phi} \boldsymbol {r} _ {t - 1} + \boldsymbol {L} ^ {- 1} \boldsymbol {a} _ {t} = \boldsymbol {\phi} _ {0} ^ {*} + \boldsymbol {\Phi} ^ {*} \boldsymbol {r} _ {t - 1} + \boldsymbol {b} _ {t}, \tag {8.9}
$$

where $\pmb { \phi } _ { 0 } ^ { * } = \pmb { L } ^ { - 1 } \pmb { \phi } _ { 0 }$ is a $k$ -dimensional vector and $\Phi ^ { * } = { \cal L } ^ { - 1 } \Phi$ is a $k \times k$ matrix. Because of the special matrix structure, the kth row of $L ^ { - 1 }$ is in the form $( w _ { k 1 } , w _ { k 2 } , \dots , w _ { k , k - 1 } , 1 )$ . Consequently, the $k$ th equation of model (8.9) is

$$
r _ {k t} + \sum_ {i = 1} ^ {k - 1} w _ {k i} r _ {i t} = \phi_ {k, 0} ^ {*} + \sum_ {i = 1} ^ {k} \Phi_ {k i} ^ {*} r _ {i, t - 1} + b _ {k t}, \tag {8.10}
$$

where $\phi _ { k , 0 } ^ { * }$ is the $k$ th element of $\phi _ { 0 } ^ { * }$ and $\Phi _ { k i } ^ { * }$ is the $( k , i )$ th element of $\Phi ^ { * }$ . Because $b _ { k t }$ is uncorrelated with $b _ { i t }$ for $1 \leq i < k$ , Eq. (8.10) shows explicitly the concurrent linear dependence of $r _ { k t }$ on $r _ { i t }$ , where $1 \leq i \leq k - 1$ . This equation is referred to as a structural equation for $r _ { k t }$ in the econometric literature.

For any other component $r _ { i t }$ of $r _ { t }$ , we can rearrange the VAR(1) model so that $r _ { i t }$ becomes the last component of $r _ { t }$ . The prior transformation method can then be applied to obtain a structural equation for $r _ { i t }$ . Therefore, the reduced-form model (8.8) is equivalent to the structural form used in the econometric literature. In time series analysis, the reduced-form model is commonly used for two reasons. The first reason is ease in estimation. The second and main reason is that the concurrent correlations cannot be used in forecasting.

Example 8.3. To illustrate the transformation from a reduced-form model to structural equations, consider the bivariate AR(1) model

$$
\left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{c} 0. 2 \\ 0. 4 \end{array} \right] + \left[ \begin{array}{c c} 0. 2 & 0. 3 \\ - 0. 6 & 1. 1 \end{array} \right] \left[ \begin{array}{c} r _ {1, t - 1} \\ r _ {2, t - 1} \end{array} \right] + \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right], \quad \boldsymbol {\Sigma} = \left[ \begin{array}{c c} 2 & 1 \\ 1 & 1 \end{array} \right].
$$

For this particular covariance matrix $\pmb { \Sigma }$ , the lower triangular matrix

$$
L ^ {- 1} = \left[ \begin{array}{c c} 1. 0 & 0. 0 \\ - 0. 5 & 1. 0 \end{array} \right]
$$

provides a Cholesky decomposition (i.e., ${ \pmb L } ^ { - 1 } { \pmb \Sigma } ( { \pmb L } ^ { \prime } ) ^ { - 1 }$ is a diagonal matrix). Premultiplying $L ^ { - 1 }$ to the previous bivariate AR(1) model, we obtain

$$
\begin{array}{l} \left[ \begin{array}{c c} 1. 0 & 0. 0 \\ - 0. 5 & 1. 0 \end{array} \right] \left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{c} 0. 2 \\ 0. 3 \end{array} \right] + \left[ \begin{array}{c c} 0. 2 & 0. 3 \\ - 0. 7 & 0. 9 5 \end{array} \right] \left[ \begin{array}{c} r _ {1, t - 1} \\ r _ {2, t - 1} \end{array} \right] + \left[ \begin{array}{c} b _ {1 t} \\ b _ {2 t} \end{array} \right], \\ \boldsymbol {G} = \left[ \begin{array}{c c} 2 & 0 \\ 0 & 0. 5 \end{array} \right], \\ \end{array}
$$

where $G = \mathrm { C o v } (  { \boldsymbol { b } } _ { t } )$ . The second equation of this transformed model gives

$$
r _ {2 t} = 0. 3 + 0. 5 r _ {1 t} - 0. 7 r _ {1, t - 1} + 0. 9 5 r _ {2, t - 1} + b _ {2 t},
$$

which shows explicitly the linear dependence of $r _ { 2 t }$ on $r _ { 1 t }$ .

Rearranging the order of elements in $r _ { t }$ , the bivariate AR(1) model becomes

$$
\left[ \begin{array}{c} r _ {2 t} \\ r _ {1 t} \end{array} \right] = \left[ \begin{array}{c} 0. 4 \\ 0. 2 \end{array} \right] + \left[ \begin{array}{c c} 1. 1 & - 0. 6 \\ 0. 3 & 0. 2 \end{array} \right] \left[ \begin{array}{c} r _ {2, t - 1} \\ r _ {1, t - 1} \end{array} \right] + \left[ \begin{array}{c} a _ {2 t} \\ a _ {1 t} \end{array} \right], \quad \boldsymbol {\Sigma} = \left[ \begin{array}{c c} 1 & 1 \\ 1 & 2 \end{array} \right].
$$

The lower triangular matrix needed in the Cholesky decomposition of $\pmb { \Sigma }$ becomes

$$
L ^ {- 1} = \left[ \begin{array}{c c} 1. 0 & 0. 0 \\ - 1. 0 & 1. 0 \end{array} \right].
$$

Premultiplying $L ^ { - 1 }$ to the earlier rearranged VAR(1) model, we obtain

$$
\begin{array}{l} \left[ \begin{array}{c c} 1. 0 & 0. 0 \\ - 1. 0 & 1. 0 \end{array} \right] \left[ \begin{array}{c} r _ {2 t} \\ r _ {1 t} \end{array} \right] = \left[ \begin{array}{c} 0. 4 \\ - 0. 2 \end{array} \right] + \left[ \begin{array}{c c} 1. 1 & - 0. 6 \\ - 0. 8 & 0. 8 \end{array} \right] \left[ \begin{array}{c} r _ {2, t - 1} \\ r _ {1, t - 1} \end{array} \right] + \left[ \begin{array}{c} c _ {1 t} \\ c _ {2 t} \end{array} \right], \\ \boldsymbol {G} = \left[ \begin{array}{c c} 1 & 0 \\ 0 & 1 \end{array} \right], \\ \end{array}
$$

where $\pmb { G } = \mathbf { C } \mathrm { o v } ( \pmb { c } _ { t } )$ . The second equation now gives

$$
r _ {1 t} = - 0. 2 + 1. 0 r _ {2 t} - 0. 8 r _ {2, t - 1} + 0. 8 r _ {1, t - 1} + c _ {2 t}.
$$

Again this equation shows explicitly the concurrent linear dependence of $r _ { 1 t }$ on $r _ { 2 t }$

# 8.2.2 Stationarity Condition and Moments of a VAR(1) Model

Assume that the VAR(1) model in Eq. (8.8) is weakly stationary. Taking expectation of the model and using $E ( { \boldsymbol { \mathbf { \mathit { a } } } } _ { t } ) = \mathbf { \boldsymbol { \mathbf { \mathit { 0 } } } }$ , we obtain

$$
E \left(\boldsymbol {r} _ {t}\right) = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} E \left(\boldsymbol {r} _ {t - 1}\right).
$$

Since $E ( \boldsymbol { r } _ { t } )$ is time-invariant, we have

$$
\boldsymbol {\mu} \equiv E (\boldsymbol {r} _ {t}) = (\boldsymbol {I} - \boldsymbol {\Phi}) ^ {- 1} \boldsymbol {\phi} _ {0}
$$

provided that the matrix $I - \Phi$ is nonsingular, where $\pmb { I }$ is the $k \times k$ identity matrix.

Using $\pmb { \phi } _ { 0 } = ( \pmb { I } - \pmb { \Phi } ) \pmb { \mu }$ , the VAR(1) model in Eq. (8.8) can be written as

$$
\left(\boldsymbol {r} _ {t} - \boldsymbol {\mu}\right) = \boldsymbol {\Phi} \left(\boldsymbol {r} _ {t - 1} - \boldsymbol {\mu}\right) + \boldsymbol {a} _ {t}.
$$

Let $\tilde { \pmb { r } } _ { t } = \pmb { r } _ { t } - \pmb { \mu }$ be the mean-corrected time series. Then the VAR(1) model becomes

$$
\tilde {\boldsymbol {r}} _ {t} = \boldsymbol {\Phi} \tilde {\boldsymbol {r}} _ {t - 1} + \boldsymbol {a} _ {t}. \tag {8.11}
$$

This model can be used to derive properties of a VAR(1) model. By repeated substitutions, we can rewrite Eq. (8.11) as

$$
\tilde {\boldsymbol {r}} _ {t} = \boldsymbol {a} _ {t} + \boldsymbol {\Phi} \boldsymbol {a} _ {t - 1} + \boldsymbol {\Phi} ^ {2} \boldsymbol {a} _ {t - 2} + \boldsymbol {\Phi} ^ {3} \boldsymbol {a} _ {t - 3} + \dots .
$$

This expression shows several characteristics of a VAR(1) process. First, since $\pmb { a } _ { t }$ is serially uncorrelated, it follows that $\mathrm { C o v } ( { \pmb a } _ { t } , { \pmb r } _ { t - 1 } ) = { \pmb 0 }$ . In fact, $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ is not correlated with $r _ { t - \ell }$ for all $\ell > 0$ . For this reason, $\pmb { a } _ { t }$ is referred to as the shock or innovation of the series at time $t$ . It turns out that, similar to the univariate case, $\pmb { a } _ { t }$ is uncorrelated with the past value $r _ { t - j }$ $( j > 0 )$ ) for all time series models. Second, postmultiplying the expression by $\pmb { a } _ { t } ^ { \prime }$ , taking expectation, and using the fact of no serial correlations in the $\pmb { a } _ { t }$ process, we obtain $\mathrm { C o v } ( { \pmb r } _ { t } , { \pmb a } _ { t } ) = \pmb \Sigma$ . Third, for a VAR(1) model, $r _ { t }$ depends on the past innovation $\mathbf { \delta } _ { \pmb { a } _ { t - j } }$ with coefficient matrix $\Phi ^ { j }$ . For such dependence to be meaningful, $\Phi ^ { j }$ must converge to zero as $j \to \infty$ . This means that the $k$ eigenvalues of $\Phi$ must be less than 1 in modulus; otherwise, $\Phi ^ { j }$ will either explode or converge to a nonzero matrix as $j \to \infty$ . As a matter of fact, the requirement that all eigenvalues of $\Phi$ are less than 1 in modulus is the necessary and sufficient condition for weak stationarity of $r _ { t }$ provided that the covariance matrix of $\pmb { a } _ { t }$ exists. Notice that this stationarity condition reduces to that of the univariate AR(1) case in which the condition is $| \phi | < 1$ . Furthermore, because

$$
| \lambda I - \Phi | = \lambda^ {k} \left| I - \Phi \frac {1}{\lambda} \right|,
$$

the eigenvalues of $\Phi$ are the inverses of the zeros of the determinant $| I - \Phi B |$ . Thus, an equivalent sufficient and necessary condition for stationarity of $r _ { t }$ is that all zeros of the determinant $| \Phi ( B ) |$ are greater than one in modulus; that is, all zeros are outside the unit circle in the complex plane. Fourth, using the expression, we have

$$
\operatorname {C o v} (\boldsymbol {r} _ {t}) = \boldsymbol {\Gamma} _ {0} = \boldsymbol {\Sigma} + \boldsymbol {\Phi} \boldsymbol {\Sigma} \boldsymbol {\Phi} ^ {\prime} + \boldsymbol {\Phi} ^ {2} \boldsymbol {\Sigma} (\boldsymbol {\Phi} ^ {2}) ^ {\prime} + \dots = \sum_ {i = 0} ^ {\infty} \boldsymbol {\Phi} ^ {i} \boldsymbol {\Sigma} (\boldsymbol {\Phi} ^ {i}) ^ {\prime},
$$

where it is understood that $\Phi ^ { 0 } = I$ , the $k \times k$ identity matrix.

Postmultiplying $\tilde { r } _ { t - \ell } ^ { \prime }$ to Eq. (8.11), taking expectation, and using the result $\mathrm { C o v } ( { \pmb a } _ { t } , { \pmb r } _ { t - j } ) = E ( { \pmb a } _ { t } { \tilde { \pmb r } } _ { t - j } ^ { \prime } ) = { \bf 0 }$ for $j > 0$ , we obtain

$$
E \left(\tilde {\boldsymbol {r}} _ {t} \tilde {\boldsymbol {r}} _ {t - \ell} ^ {\prime}\right) = \Phi E \left(\tilde {\boldsymbol {r}} _ {t - 1} \tilde {\boldsymbol {r}} _ {t - \ell}\right) ^ {\prime}, \quad \ell > 0.
$$

Therefore,

$$
\boldsymbol {\Gamma} _ {\ell} = \boldsymbol {\Phi} \boldsymbol {\Gamma} _ {\ell - 1}, \quad \ell > 0, \tag {8.12}
$$

where $\Gamma _ { j }$ is the lag- $j$ cross-covariance matrix of $r _ { t }$ . Again this result is a generalization of that of a univariate AR(1) process. By repeated substitutions, Eq. (8.12) shows that

$$
\boldsymbol {\Gamma} _ {\ell} = \boldsymbol {\Phi} ^ {\ell} \boldsymbol {\Gamma} _ {0}, \quad \text {f o r} \quad \ell > 0.
$$

Pre- and postmultiplying Eq. (8.12) by ${ \pmb D } ^ { - 1 / 2 }$ , we obtain

$$
\rho_ {\ell} = D ^ {- 1 / 2} \Phi \Gamma_ {\ell - 1} D ^ {- 1 / 2} = D ^ {- 1 / 2} \Phi D ^ {1 / 2} D ^ {- 1 / 2} \Gamma_ {\ell - 1} D ^ {- 1 / 2} = \Upsilon \rho_ {\ell - 1},
$$

where $\Upsilon = D ^ { - 1 / 2 } \Phi D ^ { 1 / 2 }$ . Consequently, the CCM of a VAR(1) model satisfies

$$
\boldsymbol {\rho} _ {\ell} = \Upsilon^ {\ell} \boldsymbol {\rho} _ {0}, \quad \text {f o r} \quad \ell > 0.
$$

# 8.2.3 Vector $\mathbf { A R } ( p )$ Models

The generalization of VAR(1) to $\operatorname { V A R } ( p )$ models is straightforward. The time series $r _ { t }$ follows a $\operatorname { V A R } ( p )$ model if it satisfies

$$
\boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} _ {1} \boldsymbol {r} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p} \boldsymbol {r} _ {t - p} + \boldsymbol {a} _ {t}, \quad p > 0, \tag {8.13}
$$

where $\phi _ { 0 }$ and $\pmb { a } _ { t }$ are defined as before, and $\Phi _ { j }$ are $k \times k$ matrices. Using the back-shift operator $B$ , the $\operatorname { V A R } ( p )$ model can be written as

$$
\left(\boldsymbol {I} - \Phi_ {1} \boldsymbol {B} - \dots - \Phi_ {p} \boldsymbol {B} ^ {p}\right) \boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {a} _ {t},
$$

where $\pmb { I }$ is the $k \times k$ identity matrix. This representation can be written in a compact form as

$$
\boldsymbol {\Phi} (B) \boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {a} _ {t},
$$

where $\Phi ( B ) = I - \Phi _ { 1 } B - \cdot \cdot \cdot - \Phi _ { p } B ^ { p }$ is a matrix polynomial. If $r _ { t }$ is weakly stationary, then we have

$$
\boldsymbol {\mu} = E \left(\boldsymbol {r} _ {t}\right) = \left(\boldsymbol {I} - \boldsymbol {\Phi} _ {1} - \dots - \boldsymbol {\Phi} _ {p}\right) ^ {- 1} \boldsymbol {\phi} _ {0} = [ \boldsymbol {\Phi} (1) ] ^ {- 1} \boldsymbol {\phi} _ {0}
$$

provided that the inverse exists. Let $\tilde { \pmb { r } } _ { t } = \pmb { r } _ { t } - \pmb { \mu }$ . The $\operatorname { V A R } ( p )$ model becomes

$$
\tilde {\boldsymbol {r}} _ {t} = \Phi_ {1} \tilde {\boldsymbol {r}} _ {t - 1} + \dots + \Phi_ {p} \tilde {\boldsymbol {r}} _ {t - p} + \boldsymbol {a} _ {t}. \tag {8.14}
$$

Using this equation and the same techniques as those for VAR(1) models, we obtain that:

• $\mathrm { C o v } ( { \pmb r } _ { t } , { \pmb a } _ { t } ) = { \pmb \Sigma }$ , the covariance matrix of $\pmb { a } _ { t }$ ;   
• $\mathrm { C o v } ( r _ { t - \ell } , \pmb { a } _ { t } ) = \mathbf { 0 }$ for $\ell > 0$ ;   
• $\Gamma _ { \ell } = \Phi _ { 1 } \Gamma _ { \ell - 1 } + \cdot \cdot \cdot + \Phi _ { p } \Gamma _ { \ell - p }$ $\Gamma _ { \ell } = \Phi _ { 1 } \Gamma _ { \ell - 1 } + \cdot \cdot \cdot + \Phi _ { p } \Gamma _ { \ell - p } ~ \mathrm { f o r } ~ \ell > 0 .$

The last property is called the moment equations of a $\operatorname { V A R } ( p )$ model. It is a multivariate version of the Yule–Walker equation of a univariate $\operatorname { A R } ( p )$ model. In terms of CCM, the moment equations become

$$
\boldsymbol {\rho} _ {\ell} = \Upsilon_ {1} \boldsymbol {\rho} _ {\ell - 1} + \dots + \Upsilon_ {p} \boldsymbol {\rho} _ {\ell - p} \quad \text {f o r} \quad \ell > 0,
$$

where $\pmb { \Upsilon } _ { i } = \pmb { D } ^ { - 1 / 2 } \pmb { \Phi } _ { i } \pmb { D } ^ { 1 / 2 }$ .

A simple approach to understanding properties of the $\operatorname { V A R } ( p )$ model in Eq. (8.13) is to make use of the results of the VAR(1) model in Eq. (8.8). This can be achieved by transforming the $\operatorname { V A R } ( p )$ model of $r _ { t }$ into a $k p$ -dimensional VAR(1) model. Specifically, let $\pmb { x } _ { t } = ( \widetilde { \pmb { r } } _ { t - p + 1 } ^ { \prime } , \widetilde { \pmb { r } } _ { t - p + 2 } ^ { \prime } , \ldots , \widetilde { \pmb { r } } _ { t } ^ { \prime } ) ^ { \prime }$ and $\pmb { b } _ { t } = ( 0 , \dots , 0 , \pmb { a } _ { t } ^ { \prime } ) ^ { \prime }$ be two $k p$ -dimensional processes. The mean of $\pmb { b } _ { t }$ is zero and the covariance matrix of $\mathbf { } _ { \pmb { b } _ { t } }$ is a $k p \times k p$ matrix with zero everywhere except for the lower right corner, which is $\pmb { \Sigma }$ . The $\operatorname { V A R } ( p )$ model for $r _ { t }$ can then be written in the form

$$
\boldsymbol {x} _ {t} = \boldsymbol {\Phi} ^ {*} \boldsymbol {x} _ {t - 1} + \boldsymbol {b} _ {t}, \tag {8.15}
$$

where $\Phi ^ { * }$ is a $k p \times k p$ matrix given by

$$
\boldsymbol {\Phi} ^ {*} = \left[ \begin{array}{c c c c c c} \mathbf {0} & \boldsymbol {I} & \mathbf {0} & \mathbf {0} & \dots & \mathbf {0} \\ \mathbf {0} & \mathbf {0} & \boldsymbol {I} & \mathbf {0} & \dots & \mathbf {0} \\ \vdots & \vdots & \vdots & & & \vdots \\ \mathbf {0} & \mathbf {0} & \mathbf {0} & \mathbf {0} & \dots & \boldsymbol {I} \\ \boldsymbol {\Phi} _ {p} & \boldsymbol {\Phi} _ {p - 1} & \boldsymbol {\Phi} _ {p - 2} & \boldsymbol {\Phi} _ {p - 3} & \dots & \boldsymbol {\Phi} _ {1} \end{array} \right],
$$

where 0 and $\pmb { I }$ are the $k \times k$ zero matrix and identity matrix, respectively. In the literature, $\Phi ^ { * }$ is called the companion matrix of the matrix polynomial $\Phi ( B )$ .

Equation (8.15) is a VAR(1) model for $\boldsymbol { x } _ { t }$ , which contains $r _ { t }$ as its last $k$ components. The results of a VAR(1) model shown in the previous subsection can now be used to derive properties of the $\operatorname { V A R } ( p )$ model via Eq. (8.15). For example, from the definition, $\boldsymbol { x } _ { t }$ is weakly stationary if and only if $r _ { t }$ is weakly stationary. Therefore, the necessary and sufficient condition of weak stationarity for the $\operatorname { V A R } ( p )$ model in Eq. (8.13) is that all eigenvalues of $\Phi ^ { * }$ in Eq. (8.15) are less than 1 in modulus. Similar to the VAR(1) case, it can be shown that the condition is equivalent to all zeros of the determinant $| \Phi ( B ) |$ being outside the unit circle.

Of particular relevance to financial time series analysis is the structure of the coefficient matrices $\Phi _ { \ell }$ of a $\operatorname { V A R } ( p )$ model. For instance, if the $( i , j )$ th element $\Phi _ { i j } ( \ell )$ of $\Phi _ { \ell }$ is zero for all , then $r _ { i t }$ does not depend on the past values of $r _ { j t }$ . The structure of the coefficient matrices $\Phi _ { \ell }$ thus provides information on the lead–lag relationship between the components of $r _ { t }$ .

# 8.2.4 Building a $\mathbf { V A R } ( p )$ Model

We continue to use the iterative procedure of order specification, estimation, and model checking to build a vector AR model for a given time series. The concept of

partial autocorrelation function of a univariate series can be generalized to specify the order $p$ of a vector series. Consider the following consecutive VAR models:

$$
\begin{array}{l} \boldsymbol {r} _ {t} = \phi_ {0} + \Phi_ {1} \boldsymbol {r} _ {t - 1} + \boldsymbol {a} _ {t} \\ \boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} _ {1} \boldsymbol {r} _ {t - 1} + \boldsymbol {\Phi} _ {2} \boldsymbol {r} _ {t - 2} + \boldsymbol {a} _ {t} \\ \begin{array}{c} \vdots = \vdots \\ \vdots = \vdots \end{array} \\ \boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} _ {1} \boldsymbol {r} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {i} \boldsymbol {r} _ {t - i} + \boldsymbol {a} _ {t} \tag {8.16} \\ \begin{array}{c} \vdots = \vdots \end{array} \\ \end{array}
$$

Parameters of these models can be estimated by the ordinary least squares (OLS) method. This is called the multivariate linear regression estimation in multivariate statistical analysis; see Johnson and Wichern (1998).

For the ith equation in Eq. (8.16), let $\widehat { \Phi } _ { j } ^ { ( i ) }$ be the OLS estimate of $\Phi _ { j }$ and let $\widehat { \phi } _ { 0 } ^ { ( i ) }$ be the estimate of $\phi _ { 0 }$ , where the superscript $( i )$ is used to denote that the estimates are for a $\mathrm { V A R } ( i )$ model. Then the residual is

$$
\widehat {\boldsymbol {a}} _ {t} ^ {(i)} = \boldsymbol {r} _ {t} - \widehat {\boldsymbol {\phi}} _ {0} ^ {(i)} - \widehat {\boldsymbol {\Phi}} _ {1} ^ {(i)} \boldsymbol {r} _ {t - 1} - \dots - \widehat {\boldsymbol {\Phi}} _ {i} ^ {(i)} \boldsymbol {r} _ {t - i}.
$$

For $i = 0$ , the residual is defined as $\widehat { \pmb { r } } _ { t } ^ { ( 0 ) } = { \pmb { r } } _ { t } - \overline { { \pmb { r } } }$ , where $\overline { r }$ is the sample mean of $r _ { t }$ . The residual covariance matrix is defined as

$$
\widehat {\boldsymbol {\Sigma}} _ {i} = \frac {1}{T - 2 i - 1} \sum_ {t = i + 1} ^ {T} \widehat {\boldsymbol {a}} _ {t} ^ {(i)} \left(\widehat {\boldsymbol {a}} _ {t} ^ {(i)}\right) ^ {\prime}, \quad i \geq 0. \tag {8.17}
$$

To specify the order $p$ , one can test the hypothesis $H _ { o } : \Phi _ { \ell } = \mathbf { 0 }$ versus the alternative hypothesis $H _ { a } : \Phi _ { \ell } \neq 0$ sequentially for $\ell = 1 , 2 , \ldots$ . For example, using the first equation in Eq. (8.16), we can test the hypothesis $H _ { o } : \Phi _ { 1 } = \mathbf { 0 }$ versus the alternative hypothesis $H _ { a } : \Phi _ { 1 } \neq \mathbf { 0 } .$ . The test statistic is

$$
M (1) = - (T - k - \frac {5}{2}) \ln \left(\frac {| \widehat {\boldsymbol {\Sigma}} _ {1} |}{| \widehat {\boldsymbol {\Sigma}} _ {0} |}\right),
$$

where $\widehat { \pmb { \Sigma } } _ { i }$ is defined in Eq. (8.17) and $| A |$ denotes the determinant of the matrix A. Under some regularity conditions, the test statistic $M ( 1 )$ is asymptotically a chi-squared distribution with $k ^ { 2 }$ degrees of freedom; see Tiao and Box (1981).

In general, we use the $i$ th and $( i - 1 )$ th equations in Eq. (8.16) to test $H _ { o } : \Phi _ { i } =$ 0 versus $H _ { a } : \Phi _ { i } \neq \mathbf { 0 }$ ; that is, testing a VAR(i) model versus a $\mathrm { V A R } ( i - 1 )$ model. The test statistic is

$$
M (i) = - \left(T - k - i - \frac {3}{2}\right) \ln \left(\frac {\left| \widehat {\boldsymbol {\Sigma}} _ {i} \right|}{\left| \boldsymbol {\Sigma} _ {i - 1} \right|}\right). \tag {8.18}
$$

Asymptotically, $M ( i )$ is distributed as a chi-squared distribution with $k ^ { 2 }$ degrees of freedom.

Alternatively, one can use the Akaike information criterion (AIC) or its variants to select the order $p$ . Assume that $\pmb { a } _ { t }$ is multivariate normal and consider the ith equation in Eq. (8.16). One can estimate the model by the maximum likelihood (ML) method. For AR models, the OLS estimates $\widehat { \pmb { \phi } } _ { 0 }$ and $\widehat { \Phi } _ { j }$ are equivalent to the (conditional) ML estimates. However, there are differences between the estimates of $\pmb { \Sigma }$ . The ML estimate of $\pmb { \Sigma }$ is

$$
\tilde {\boldsymbol {\Sigma}} _ {i} = \frac {1}{T} \sum_ {t = i + 1} ^ {T} \hat {\boldsymbol {a}} _ {t} ^ {(i)} [ \hat {\boldsymbol {a}} _ {t} ^ {(i)} ] ^ {\prime}. \tag {8.19}
$$

The AIC of a VAR(i) model under the normality assumption is defined as

$$
\operatorname {A I C} (i) = \ln (| \tilde {\boldsymbol {\Sigma}} _ {i} |) + \frac {2 k ^ {2} i}{T}.
$$

For a given vector time series, one selects the AR order $p$ such that $\operatorname { A I C } ( p ) =$ $\begin{array} { r } { \operatorname* { m i n } _ { 0 \leq i \leq p _ { 0 } } \mathrm { A I C } ( i ) } \end{array}$ , where $p _ { 0 }$ is a prespecified positive integer.

Other information criteria available for VAR(i) models are

$$
\operatorname {B I C} (i) = \ln (| \tilde {\boldsymbol {\Sigma}} _ {i} |) + \frac {k ^ {2} i \ln (T)}{T},
$$

$$
\mathrm {H Q} (i) = \ln \left(\left| \tilde {\boldsymbol {\Sigma}} _ {i} \right|\right) + \frac {2 k ^ {2} i \ln (\ln (T))}{T}.
$$

The HQ criterion is proposed by Hannan and Quinn (1979).

Example 8.4. Assuming that the bivariate series of monthly log returns of IBM stock and the S&P 500 index discussed in Example 8.1 follows a VAR model, we apply the $M ( i )$ statistics and AIC to the data. Table 8.3 shows the results of these statistics. Both statistics indicate that a VAR(3) model might be adequate for the data. The $M ( i )$ statistics are marginally significant at lags 1, 3, and 5 at the $5 \%$ level. The minimum of AIC occurs at order 3. For this particular instance, the $M ( i )$ statistics are nonsignificant at the $1 \%$ level, confirming the previous observation that the dynamic linear dependence between the two return series is weak.

Table 8.3. Order-Specification Statisticsa for the Monthly Log Returns of IBM Stock and the S&P 500 Index from January 1926 to December 1999   

<table><tr><td>Order</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>M(i)</td><td>9.81</td><td>8.93</td><td>12.57</td><td>6.08</td><td>9.56</td><td>2.80</td></tr><tr><td>AIC</td><td>6.757</td><td>6.756</td><td>6.750</td><td>6.753</td><td>6.751</td><td>6.756</td></tr></table>

aThe $5 \%$ and $1 \%$ critical values of a chi-squared distribution with 4 degrees of freedom are 9.5 and 13.3.

# Estimation and Model Checking

For a specified VAR model, one can estimate the parameters using either the ordinary least squares method or the maximum likelihood method. The two methods are asymptotically equivalent. Under some regularity conditions, the estimates are asymptotically normal; see Reinsel (1993). A fitted model should then be checked carefully for any possible inadequacy. The $Q _ { k } ( m )$ statistic can be applied to the residual series to check the assumption that there are no serial or crosscorrelations in the residuals. For a fitted $\operatorname { V A R } ( p )$ model, the $Q _ { k } ( m )$ statistic of the residuals is asymptotically a chi-squared distribution with $k ^ { 2 } m - g$ degrees of freedom, where $g$ is the number of estimated parameters in the AR coefficient matrices.

Example 8.4 (Continued). Table 8.4a shows the estimation results of a VAR(3) model for the bivariate series of monthly log returns of IBM stock and the S&P 500 index. The specified model is in the form

$$
\boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} _ {1} \boldsymbol {r} _ {t - 1} + \boldsymbol {\Phi} _ {3} \boldsymbol {r} _ {t - 3} + \boldsymbol {a} _ {t}, \tag {8.20}
$$

where the first component of $r _ { t }$ denotes IBM stock returns. For this particular instance, we only use AR coefficient matrices at lags 1 and 3 because of the weak serial dependence of the data. In general, when the $M ( i )$ statistics and the AIC criterion specify a VAR(3) model, all three AR lags should be used. Table 8.4b shows the estimation results after some statistically insignificant parameters are set to zero. The $Q _ { k } ( m )$ statistics of the residual series for the fitted model in Table 8.4b give $Q _ { 2 } ( 4 ) = 1 8 . 1 7$ and $Q _ { 2 } ( 8 ) = 4 1 . 2 6$ . Since the fitted VAR(3) model has four parameters in the AR coefficient matrices, these two $Q _ { k } ( m )$ statistics are distributed asymptotically as a chi-squared distribution with degrees of freedom 12 and 28, respectively. The $p$ -values of the test statistics are 0.111 and 0.051, and hence the fitted model is adequate at the $5 \%$ significance level. As shown by the univariate analysis, the return series are likely to have conditional heteroscedasticity. We discuss multivariate volatility in Chapter 10.

From the fitted model in Table 8.4b, we make the following observations. (a) The concurrent correlation coefficient between the two innovational series is $2 3 . 5 1 / \sqrt { 4 4 . 4 8 \times 3 1 . 2 9 } = 0 . 6 3$ , which, as expected, is close to the sample correlation coefficient between $r _ { 1 t }$ and $r _ { 2 t }$ . (b) The two log return series have positive and significant means, implying that the log prices of the two series had an upward trend over the data span. (c) The model shows that

$$
\mathrm {I B M} _ {t} = 1. 2 4 + 0. 1 1 7 \mathrm {S P} 5 _ {t - 1} - 0. 0 8 3 \mathrm {S P} 5 _ {t - 3} + a _ {1 t},
$$

$$
\mathrm {S P} 5 _ {t} = 0. 5 7 + 0. 0 7 3 \mathrm {S P} 5 _ {t - 1} - 0. 1 0 9 \mathrm {S P} 5 _ {t - 3} + a _ {2 t}.
$$

Consequently, at the $5 \%$ significance level, there is a unidirectional dynamic relationship from the monthly S&P 500 index return to the IBM return. If the S&P 500 index represents the U.S. stock market, then IBM return is affected by the past movements of the market. However, past movements of IBM stock returns do not

Table 8.4. Estimation Results of a VAR(3) Model for the Monthly Log Returns, in Percentages, of IBM Stock and the S&P 500 Index from January 1926 to December 1999   

<table><tr><td>Parameter</td><td>φ0</td><td>Φ1</td><td>Φ3</td><td>Σ</td></tr></table>

(a) Full Model   

<table><tr><td rowspan="2">Estimate</td><td>1.20</td><td>0.011</td><td>0.108</td><td>0.039</td><td>-0.112</td><td>44.44</td><td>23.51</td></tr><tr><td>0.58</td><td>-0.013</td><td>0.084</td><td>-0.007</td><td>-0.105</td><td>23.51</td><td>31.29</td></tr><tr><td rowspan="2">Standard error</td><td>0.23</td><td>0.043</td><td>0.051</td><td>0.044</td><td>0.052</td><td></td><td></td></tr><tr><td>0.19</td><td>0.036</td><td>0.043</td><td>0.037</td><td>0.044</td><td></td><td></td></tr></table>

(b) Simplified Model   

<table><tr><td rowspan="2">Estimate</td><td>1.24</td><td>0</td><td>0.117</td><td>0</td><td>-0.083</td><td>44.48</td><td>23.51</td></tr><tr><td>0.57</td><td>0</td><td>0.073</td><td>0</td><td>-0.109</td><td>23.51</td><td>31.29</td></tr><tr><td rowspan="2">Standard error</td><td>0.23</td><td>—</td><td>0.040</td><td>—</td><td>0.040</td><td></td><td></td></tr><tr><td>0.19</td><td>—</td><td>0.033</td><td>—</td><td>0.033</td><td></td><td></td></tr></table>

significantly affect the U.S. market, even though the two returns have substantial concurrent correlation. Finally, the fitted model can be written as

$$
\left[ \begin{array}{c} \mathrm {I B M} _ {t} \\ \mathrm {S P 5} _ {t} \end{array} \right] = \left[ \begin{array}{c} 1. 2 4 \\ 0. 5 7 \end{array} \right] + \left[ \begin{array}{c} 0. 1 1 7 \\ 0. 0 7 3 \end{array} \right] \mathrm {S P 5} _ {t - 1} - \left[ \begin{array}{c} 0. 0 8 3 \\ 0. 1 0 9 \end{array} \right] \mathrm {S P 5} _ {t - 3} + \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right],
$$

indicating that $\mathrm { S P } 5 _ { t }$ is the driving factor of the bivariate series.

# Forecasting

Treating a properly built model as the true model, one can apply the same techniques as those in the univariate analysis to produce forecasts and standard deviations of the associated forecast errors. For a $\operatorname { V A R } ( p )$ model, the 1-step ahead forecast at the time origin $h$ is $\begin{array} { r } { \pmb { r } _ { h } ( 1 ) = \pmb { \phi } _ { 0 } + \sum _ { i = 1 } ^ { p } \pmb { \Phi } _ { i } \pmb { r } _ { h + 1 - i } } \end{array}$ , and the associated forecast error is $\pmb { e } _ { h } ( 1 ) = \pmb { a } _ { h + 1 }$ . The covariance matrix of the forecast error is $\pmb { \Sigma }$ . For 2-step ahead forecasts, we substitute $r _ { h + 1 }$ by its forecast to obtain

$$
\boldsymbol {r} _ {h} (2) = \boldsymbol {\phi} _ {0} + \boldsymbol {\Phi} _ {1} \boldsymbol {r} _ {h} (1) + \sum_ {i = 2} ^ {p} \boldsymbol {\Phi} _ {i} \boldsymbol {r} _ {h + 2 - i},
$$

and the associated forecast error is

$$
\boldsymbol {e} _ {h} (2) = \boldsymbol {a} _ {h + 2} + \Phi_ {1} [ \boldsymbol {r} _ {t} - \boldsymbol {r} _ {h} (1) ] = \boldsymbol {a} _ {h + 2} + \Phi_ {1} \boldsymbol {a} _ {h + 1}.
$$

The covariance matrix of the forecast error is ${ \pmb \Sigma } + \Phi _ { 1 } { \pmb \Sigma } \Phi _ { 1 } ^ { \prime }$ . If $r _ { t }$ is weakly stationary, then the -step ahead forecast $r _ { h } ( \ell )$ converges to its mean vector $\pmb { \mu }$ as

Table 8.5. Forecasts of a VAR(3) Model for the Monthly Log Returns, in Percentages, of IBM Stock and the S&P 500 Index: Forecast Origin December 1999   

<table><tr><td>Step</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>IBM forecast</td><td>1.40</td><td>1.12</td><td>0.82</td><td>1.21</td><td>1.27</td><td>1.31</td></tr><tr><td>Standard error</td><td>6.67</td><td>6.70</td><td>6.70</td><td>6.72</td><td>6.72</td><td>6.72</td></tr><tr><td>S&amp;P forecast</td><td>0.32</td><td>0.38</td><td>-0.02</td><td>0.53</td><td>0.56</td><td>0.61</td></tr><tr><td>Standard error</td><td>5.59</td><td>5.61</td><td>5.61</td><td>5.64</td><td>5.64</td><td>5.64</td></tr></table>

the forecast horizon $\ell$ increases and the covariance matrix of its forecast error converges to the covariance matrix of $r _ { t }$ .

Table 8.5 provides 1-step to 6-step ahead forecasts of the monthly log returns, in percentages, of IBM stock and the S&P 500 index at the forecast origin $h = 8 8 8$ . These forecasts are obtained by the refined VAR(3) model in Table 8.4.

In summary, building a VAR model involves three steps: (a) use the test statistic $M ( i )$ or some information criterion to identify the order, (b) estimate the specified model by using the least squares method and, if necessary, reestimate the model by removing statistically insignificant parameters, and (c) use the $Q _ { k } ( m )$ statistic of the residuals to check the adequacy of a fitted model. Other characteristics of the residual series, such as conditional heteroscedasticity and outliers, can also be checked. If the fitted model is adequate, then it can be used to obtain forecasts and make inference concerning the dynamic relationship between the variables.

We used SCA to perform the analysis in this subsection. The commands used include miden, mtsm, mest, and mfore, where the prefix m stands for multivariate. Details of the commands and output are shown below.

# SCA Demonstration

Output edited and $\%$ denotes explanation.

```txt
input ibm,sp5. file 'm-ibmspln.txt' -- % Order selection  
miden ibm,sp5. no ccm. arfits 1 to 6. 
```

```txt
TIME PERIODANALYZED 1 TO 888 
```

```txt
SERIES NAME MEAN STD. ERROR 1 IBM 1.2402 6.7249 2 SP5 0.5372 5.6415 \(= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
```

```txt
I RESIDUAL I EIGENVAL. I CHI-SQ I I SIGN.  
LAG I VARIANCESI OF SIGMA I TEST I AIC I
```

```javascript
1 I .447E+02 I .135E+02 I 9.81 I 6.757 I . +
```

<table><tr><td colspan="4">I .318E+02 I .629E+02 I</td><td colspan="3">I</td><td>I . .</td></tr><tr><td colspan="4">+</td><td colspan="3">+</td><td>+</td></tr><tr><td colspan="4">2 I .443E+02 I .135E+02 I</td><td colspan="2">8.93 I</td><td colspan="2">6.756 I + -</td></tr><tr><td colspan="4">I .317E+02 I .625E+02 I</td><td colspan="3">I</td><td>I . .</td></tr><tr><td colspan="4">+</td><td colspan="3">+</td><td>+</td></tr><tr><td colspan="4">3 I .441E+02 I .134E+02 I</td><td colspan="2">12.57 I</td><td colspan="2">6.750 I .</td></tr><tr><td colspan="4">I .313E+02 I .619E+02 I</td><td colspan="3">I</td><td>I . -</td></tr><tr><td colspan="4">+</td><td colspan="3">+</td><td>+</td></tr><tr><td colspan="4">4 I .441E+02 I .133E+02 I</td><td colspan="2">6.08 I</td><td colspan="2">6.753 I .</td></tr><tr><td colspan="4">I .312E+02 I .619E+02 I</td><td colspan="3">I</td><td>I . .</td></tr><tr><td colspan="4">+</td><td colspan="3">+</td><td>+</td></tr><tr><td colspan="4">5 I .437E+02 I .133E+02 I</td><td colspan="2">9.56 I</td><td colspan="2">6.751 I .</td></tr><tr><td colspan="4">I .309E+02 I .613E+02 I</td><td colspan="3">I</td><td>I - +</td></tr><tr><td colspan="4">+</td><td colspan="3">+</td><td>+</td></tr><tr><td colspan="4">6 I .437E+02 I .133E+02 I</td><td colspan="2">2.80 I</td><td colspan="2">6.756 I .</td></tr><tr><td colspan="4">I .308E+02 I .613E+02 I</td><td colspan="3">I</td><td>I . .</td></tr></table>

SUMMARY FOR MULTIVARIATE ARMA MODEL -- FIT1  
```txt
CHI-SQUARED CRITICAL VALUES WITH 4 DEGREES OF FREEDOM ARE 5 PERCENT: 9.5 1 PERCENT: 13.3 -- % Specify a VAR(3) model with lags 1 & 3 only. mtsm fit1. series.ibm, sp5. @ model (i-p1\*b-p3\*b\*\*3) series=c+noise. 
```

```batch
PARAMETER FACTOR ORDER CONSTRAINT1 C CONSTANT 0 CC2 P1 REG AR 1 CP13 P3 REG AR 3 CP3--% Perform multivariate estimationmestim fit1. hold resi(r1,r2)CONSTANT VECTOR (STD ERROR) --1.201 (0.232 )0.583 (0.194) PHI MATRICES ----ESTIMATES OF PHI(1) MATRIX AND SIGNIFICANCE.011 .108 .+-.013 .084 .STANDARD ERRORS.043 .051.036 .043ESTIMATES OF PHI(3) MATRIX AND SIGNIFICANCE.039 -.112 .--.007 -.105 .STANDARD ERRORS.044 .052.037 .044ERROR COVARIANCE MATRIX 
```

```txt
1 2   
1 44.438125   
2 23.518578 31.287280   
-- % Set parameter to 0   
p1(1,1)=0   
--   
p1(2,1)=0   
-- % Set constraint to fix the parameter   
cp1(1,1)=1   
--   
cp1(2,1)=1   
--   
p3(1,1)=0   
--   
p3(2,1)=0   
--   
cp3(1,1)=1   
--   
cp3(2,1)=1   
--   
mestim fit1. hold resi(r1,r2).   
---- CONSTANT VECTOR (STD ERROR) ----   
1.243 ( 0.226 )   
0.566 ( 0.190 )   
---- PHI MATRICES ----   
ESTIMATES OF PHI(1) MATRIX AND SIGNIFICANCE .000 .117 .+ .000 .073 .+   
STANDARD ERRORS -- .040 -- .033   
ESTIMATES OF PHI(3) MATRIX AND SIGNIFICANCE .000 -.083 .- .000 -.109 .-   
STANDARD ERRORS -- .040 -- .033   
ERROR COVARIANCE MATRIX   
1 2   
1 44.482888   
2 23.506951 31.293592   
-- % Compute residual CCM   
miden r1,r2. maxl 12.   
-- % Produce 1 to 6-step ahead forecasts   
mfore fit1. nofs 6. 
```

# 8.2.5 Impulse Response Function

Similar to the univariate case, a $\operatorname { V A R } ( p )$ model can be written as a linear function of the past innovations, that is,

$$
\boldsymbol {r} _ {t} = \boldsymbol {\mu} + \boldsymbol {a} _ {t} + \Psi_ {1} \boldsymbol {a} _ {t - 1} + \Psi_ {2} \boldsymbol {a} _ {t - 2} + \dots , \tag {8.21}
$$

where $\pmb { \mu } = [ \pmb { \Phi } ( 1 ) ] ^ { - 1 } \pmb { \phi } _ { 0 }$ provided that the inverse exists, and the coefficient matrices $\boldsymbol { \psi } _ { i }$ can be obtained by equating the coefficients of $B ^ { i }$ in the equation

$$
\left(\boldsymbol {I} - \Phi_ {1} \boldsymbol {B} - \dots - \Phi_ {p} \boldsymbol {B} ^ {p}\right) \left(\boldsymbol {I} + \Psi_ {1} \boldsymbol {B} + \Psi_ {2} \boldsymbol {B} ^ {2} + \dots\right) = \boldsymbol {I},
$$

where $\pmb { I }$ is the identity matrix. This is a moving-average representation of $r _ { t }$ with the coefficient matrix $\Psi _ { i }$ being the impact of the past innovation $\mathbf { \delta } _ { \pmb { a } _ { t - i } }$ on $r _ { t }$ . Equivalently, $\Psi _ { i }$ is the effect of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ on the future observation $r _ { t + i }$ . Therefore, $\Psi _ { i }$ is often referred to as the impulse response function of $r _ { t }$ . However, since the components of $\pmb { a } _ { t }$ are often correlated, the interpretation of elements in $\Psi _ { i }$ of Eq. (8.21) is not straightforward. To aid interpretation, one can use the Cholesky decomposition mentioned earlier to transform the innovations so that the resulting components are uncorrelated. Specifically, there exists a lower triangular matrix $\pmb { L }$ such that $\pmb { \Sigma } = \pmb { L G L ^ { \prime } }$ , where $\textbf { G }$ is a diagonal matrix and the diagonal elements of $\pmb { L }$ are unity. See Eq. (8.9). Let $\pmb { b } _ { t } = \pmb { L } ^ { - 1 } \pmb { a } _ { t }$ . Then, $\mathrm { C o v } ( \pmb { b } _ { t } ) = \pmb { G }$ so that the elements $b _ { j t }$ are uncorrelated. Rewrite Eq. (8.21) as

$$
\begin{array}{l} \boldsymbol {r} _ {t} = \boldsymbol {\mu} + \boldsymbol {a} _ {t} + \Psi_ {1} \boldsymbol {a} _ {t - 1} + \Psi_ {2} \boldsymbol {a} _ {t - 2} + \dots \\ = \boldsymbol {\mu} + \boldsymbol {L L} ^ {- 1} \boldsymbol {a} _ {t} + \boldsymbol {\Psi} _ {1} \boldsymbol {L L} ^ {- 1} \boldsymbol {a} _ {t - 1} + \boldsymbol {\Psi} _ {2} \boldsymbol {L L} ^ {- 1} \boldsymbol {a} _ {t - 2} + \dots \\ = \boldsymbol {\mu} + \Psi_ {0} ^ {*} \boldsymbol {b} _ {t} + \Psi_ {1} ^ {*} \boldsymbol {b} _ {t - 1} + \Psi_ {2} ^ {*} \boldsymbol {b} _ {t - 2} + \dots , \tag {8.22} \\ \end{array}
$$

where $\Psi _ { 0 } ^ { * } = L$ and $\Psi _ { i } ^ { * } = \Psi _ { i } L$ . The coefficient matrices $\Psi _ { i } ^ { * }$ are called the impulse response function of $r _ { t }$ with the orthogonal innovations $\mathbf { } _ { \pmb { b } _ { t } }$ . Specifically, the $( i , j ) \mathrm { t h }$ element of $\Psi _ { \ell } ^ { * }$ , that is, $\Psi _ { i j } ^ { * } ( \ell )$ , is the impact of $b _ { j , t }$ on the future observation $r _ { i , t + \ell }$ . In practice, one can further normalize the orthogonal innovation $\mathbf { } _ { \pmb { b } _ { t } }$ such that the variance of $b _ { i t }$ is one. A weakness of the above orthogonalization is that the result depends on the ordering of the components of $r _ { t }$ . In particular, $b _ { 1 t } = a _ { 1 t }$ so that $a _ { 1 t }$ is not transformed. Different orderings of the components of $r _ { t }$ may lead to different impulse response functions.

Both SCA and S-Plus enable one to obtain the impulse response function of a fitted VAR model. To demonstrate analysis of VAR models in S-Plus, we again use the monthly log return series of IBM stock and the S&P 500 index of Example 8.1. For details of S-Plus commands, see Zivot and Wang (2003).

# S-Plus Demonstration

Output edited.

> $\mathrm { _ { x = } }$ matrix(scan(file=’m-ibmspln.txt’),2) % Load data   
> ibm $_ { 1 = \times }$ [1,]   
> $\mathtt { S p 5 = x }$ [2,]

```txt
> y=cbind.ibm,sp5) % Create a vector series  
> y1=data.frame(y) % create a data frame  
> ord.choice=VAR(y1,max.ar=6) % order selection  
> ord.choice$info  
ar(1) ar(2) ar(3) ar(4) ar(5) ar(6)  
BIC 10998.47 11016.61 11031.07 11052.05 11069.49 11093.78  
> ord.choice=VAR(y1,max.ar=6,criterion='AIC')  
> ord.choice$info  
ar(1) ar(2) ar(3) ar(4) ar(5) ar(6)  
AIC 10969.78 10968.79 10964.11 10965.97 10964.28 10969.44 
```

The AIC selects a VAR(3) model as before, but BIC selects a VAR(1) model. For simplicity, we shall use VAR(1) specification in the demonstration. Note that different normalizations are used between the two packages so that the values of information criteria appear to be different; see the AIC in Table 8.3. This is not important because normalization does not affect order selection. Turn to estimation.

```txt
> var1.fit=VAR(y~ar(1)) % Estimation  
> summary(var1.fit)  
Call:  
VAR(formula = y ~ ar(1))  
Coefficients:  
	ibm sp5  
(Intercept) 1.1627 0.4993  
(std.err) 0.2290 0.1925  
(t.stat) 5.0777 2.5935  
ibm.lag1 0.0192 -0.0054  
(std.err) 0.0433 0.0364  
(t.stat) 0.4429 -0.1487  
sp5.lag1 0.1062 0.0802  
(std.err) 0.0517 0.0435  
(t.stat) 2.0544 1.8454  
Regression Diagnostics:  
	ibm sp5  
R-squared 0.0105 0.0058  
Adj. R-squared 0.0082 0.0036  
Resid. Scale 6.7043 5.6376 
```

```txt
> plot(var1.fit)  
Make a plot selection (or 0 to exit):  
1: plot: All  
2: plot: Response and Fitted Values  
3: plot: Residuals  
...  
8: plot: PACF of Squared Residuals  
Selection: 3 
```

The fitted model is

$$
\mathrm {I B M} _ {t} = 1. 1 6 + 0. 0 2 \mathrm {I B M} _ {t - 1} + 0. 1 1 \mathrm {S P} _ {t - 1} + a _ {1 t},
$$

$$
\mathrm {S P} 5 _ {t} = 0. 5 0 - 0. 0 1 \mathrm {I B M} _ {t - 1} + 0. 0 8 \mathrm {S P} 5 _ {t - 1} + a _ {2 t}.
$$

Based on $t$ -statistics of the estimates in the output, only the lagged variable $\mathrm { S P } 5 _ { t - 1 }$ is informative in both equations. Figure 8.5 shows the time plots of the two residual series, where the two horizontal lines indicate the two standard-error limits. As expected, there exist clusters of outlying observations.

Next, we compute 1-step to 6-step ahead forecasts and the impulse response function of the fitted VAR(1) model when the IBM stock return is the first component of $r _ { t }$ . Compared with those of a VAR(3) model in Table 8.5, the forecasts of the VAR(1) model converge faster to the sample mean of the series.

$>$ var1.pred $=$ predict(var1.fit,n.predict ${ } = 6$ ) % Compute prediction $>$ summary(var1.pred)

Predicted Values with Standard Errors: ibm sp5

1-step-ahead 1.8472 0.9255

(std.err) 6.7043 5.6376

2-step-ahead 1.2964 0.5636

(std.err) 6.7394 5.6539

3-step-ahead 1.2474 0.5375

(std.err) 6.7397 5.6540

6-step-ahead 1.2434 0.5356

(std.err) 6.7397 5.6540

![](images/e2a668f61e744b22f8ba690449aa83207e583893882c72ebdeb763629324cbb4.jpg)  
Residuals versus Time

![](images/10e0156b158476b2498b185623d350675792480fe5fef2d39f22bf2dc7f4624a.jpg)  
Figure 8.5. Residual plots of fitting a VAR(1) model to the monthly log returns, in percentages, of IBM stock and the S&P 500 index. The sample period is from January 1926 to December 1999.

```txt
> plot(var1_pred, y, n_old=12) % Plot forecasts  
> var1.irdf=impRes(var1.fit, period=6, std.err='asymptotic')  
> summary(var1.irdf)  
Impulse Response Function: 
```

```txt
(with responses in rows, and innovations in columns)  
, lag.0  
ibm sp5  
ibm 6.6929 0.0000  
(std.err) 0.1589 0.0000  
sp5 3.5645 4.3553  
(std.err) 0.1690 0.1034  
, lag.1  
ibm sp5  
ibm 0.5069 0.4624  
(std.err) 0.2244 0.2249  
sp5 0.2496 0.3492  
(std.err) 0.1885 0.1891  
...  
> plot(var1.arf) 
```

Figure 8.6 shows the forecasts and their pointwise $9 5 \%$ confidence intervals along with the last 12 data points of the series. Figure 8.7 shows the impulse response functions of the fitted VAR(1) model where the IBM stock return is the first component of $r _ { t }$ . Since the dynamic dependence of the returns is weak, the impulse response functions exhibit simple patterns and decay quickly.

# 8.3 VECTOR MOVING-AVERAGE MODELS

A vector moving-average model of order $q$ , or $\mathrm { V M A } ( q )$ , is in the form

$$
\boldsymbol {r} _ {t} = \boldsymbol {\theta} _ {0} + \boldsymbol {a} _ {t} - \boldsymbol {\Theta} _ {1} \boldsymbol {a} _ {t - 1} - \dots - \boldsymbol {\Theta} _ {q} \boldsymbol {a} _ {t - q} \quad \text {o r} \quad \boldsymbol {r} _ {t} = \boldsymbol {\theta} _ {0} + \boldsymbol {\Theta} (B) \boldsymbol {a} _ {t}, \tag {8.23}
$$

where $\pmb { \theta } _ { 0 }$ is a $k$ -dimensional vector, $\mathbf { \Theta } _ { \mathbf { e } }$ are $k \times k$ matrices, and $\Theta ( B ) = I -$ $\Theta _ { 1 } B - \cdot \cdot \cdot - \Theta _ { q } B ^ { q }$ is the MA matrix polynomial in the back-shift operator $B$ . Similar to the univariate case, $\mathrm { V M A } ( q )$ processes are weakly stationary provided that the covariance matrix $\pmb { \Sigma }$ of $\pmb { a } _ { t }$ exists. Taking expectation of Eq. (8.23), we obtain that $\pmb { \mu } = E ( \pmb { r } _ { t } ) = \pmb { \theta } _ { 0 }$ . Thus, the constant vector $\pmb { \theta } _ { 0 }$ is the mean vector of $r _ { t }$ for a VMA model.

Let $\tilde { \pmb { r } } _ { t } = \pmb { r } _ { t } - \pmb { \theta } _ { 0 }$ be the mean-corrected ${ \mathrm { V A R } } ( q )$ process. Then using Eq. (8.23) and the fact that $\left\{ \pmb { a } _ { t } \right\}$ has no serial correlations, we have

1. $\mathrm { C o v } ( { \pmb r } _ { t } , { \pmb a } _ { t } ) = \pmb \Sigma$   
2. $\boldsymbol { \Gamma } _ { 0 } = \boldsymbol { \Sigma } + \boldsymbol { \Theta } _ { 1 } \boldsymbol { \Sigma } \boldsymbol { \Theta } _ { 1 } ^ { \prime } + \cdot \cdot \cdot + \boldsymbol { \Theta } _ { q } \boldsymbol { \Sigma } \boldsymbol { \Theta } _ { q } ^ { \prime } ,$   
3. $\Gamma _ { \ell } = \mathbf { 0 }$ if $\ell > q$ , and   
4. $\begin{array} { r } { \Gamma _ { \ell } = \sum _ { j = \ell } ^ { q } \Theta _ { j } \pmb { \Sigma } \Theta _ { j - \ell } ^ { \prime } } \end{array}$ if $1 \leq \ell \leq q$ , where $\Theta _ { 0 } = - I$

![](images/b4491d6bcca32ec56d422f7d95dde46df27fea28ffa718848491e2dd0b3e8c0a.jpg)

![](images/56ab26af578378354d4e7166e67d5c46aa9cdab2e8c64cd705119bf56310568c.jpg)  
Figure 8.6. Forecasting plots of a fitted VAR(1) model to the monthly log returns, in percentages, of IBM stock and the S&P 500 index. The sample period is from January 1926 to December 1999.

Since $\Gamma _ { \ell } = \mathbf { 0 }$ for $\ell > q$ , the cross-correlation matrices (CCMs) of a VMA(q) process $r _ { t }$ satisfy

$$
\rho_ {\ell} = \mathbf {0}, \quad \ell > q. \tag {8.24}
$$

Therefore, similar to the univariate case, the sample CCMs can be used to identify the order of a VMA process.

To better understand the VMA processes, let us consider the bivariate MA(1) model

$$
\boldsymbol {r} _ {t} = \boldsymbol {\theta} _ {0} + \boldsymbol {a} _ {t} - \boldsymbol {\Theta} \boldsymbol {a} _ {t - 1} = \boldsymbol {\mu} + \boldsymbol {a} _ {t} - \boldsymbol {\Theta} \boldsymbol {a} _ {t - 1}, \tag {8.25}
$$

where, for simplicity, the subscript of $\mathbf { \Theta } _ { \Theta _ { 1 } }$ is removed. This model can be written explicitly as

$$
\left[ \begin{array}{l} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{l} \mu_ {1} \\ \mu_ {2} \end{array} \right] + \left[ \begin{array}{l} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{l l} \Theta_ {1 1} & \Theta_ {1 2} \\ \Theta_ {2 1} & \Theta_ {2 2} \end{array} \right] \left[ \begin{array}{l} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right]. \tag {8.26}
$$

It says that the current return series $r _ { t }$ only depends on the current and past shocks. Therefore, the model is a finite-memory model.

Consider the equation for $r _ { 1 t }$ in Eq. (8.26). The parameter $\Theta _ { 1 2 }$ denotes the linear dependence of $r _ { 1 t }$ on $_ { a _ { 2 , t - 1 } }$ in the presence of $_ { a _ { 1 , t - 1 } }$ . If $\Theta _ { 1 2 } = 0$ , then $r _ { 1 t }$ does not depend on the lagged values of $a _ { 2 t }$ and, hence, the lagged values of $r _ { 2 t }$ . Similarly,

![](images/b560a22bb2d59a1c8ae40194779ff99ef2a55182afd85cbc6cc35c3f31be4464.jpg)

![](images/3d25612cc31a2e8d0bed9e07d22d3e1c8626531b4ae7d43e9d3854ee7f09aaf2.jpg)  
Figure 8.7. Plots of impulse response functions of orthogonal innovations for a fitted VAR(1) model to the monthly log returns, in percentages, of IBM stock and the S&P 500 index. The sample period is from January 1926 to December 1999.

if $\Theta _ { 2 1 } = 0$ , then $r _ { 2 t }$ does not depend on the past values of $r _ { 1 t }$ . The off-diagonal elements of $\mathbf { \Theta } _ { \Theta }$ thus show the dynamic dependence between the component series. For this simple VMA(1) model, we can classify the relationships between $r _ { 1 t }$ and $r _ { 2 t }$ as follows:

1. They are uncoupled series if $\Theta _ { 1 2 } = \Theta _ { 2 1 } = 0$ .   
2. There is a unidirectional dynamic relationship from $r _ { 1 t }$ to $r _ { 2 t }$ if $\Theta _ { 1 2 } = 0$ , but $\Theta _ { 2 1 } \neq 0$ . The opposite unidirectional relationship holds if $\Theta _ { 2 1 } = 0$ , but $\Theta _ { 1 2 } \neq 0$ .   
3. There is a feedback relationship between $r _ { 1 t }$ and $r _ { 2 t }$ if $\Theta _ { 1 2 } \neq 0$ and $\Theta _ { 2 1 } \neq 0$ .

Finally, the concurrent correlation between $r _ { i t }$ is the same as that between $a _ { i t }$ . The previous classification can be generalized to a $\mathrm { V M A } ( q )$ model.

# Estimation

Unlike the VAR models, estimation of VMA models is much more involved; see Hillmer and Tiao (1979), Lutkepohl (1991), and the references therein. For the¨ likelihood approach, there are two methods available. The first is the conditional likelihood method that assumes that $\mathbf { \nabla } \pmb { a } _ { t } = \mathbf { 0 }$ for $t \leq 0$ . The second is the exact likelihood method that treats $\pmb { a } _ { t }$ with $t \leq 0$ as additional parameters of

the model. To gain some insight into the problem of estimation, we consider the VMA(1) model in Eq. (8.25). Suppose that the data are $\{ r _ { t } | t = 1 , \ldots , T \}$ and $\pmb { a } _ { t }$ is multivariate normal. For a VMA(1) model, the data depend on $\pmb { a } _ { 0 }$ .

# Conditional MLE

The conditional likelihood method assumes that $\pmb { a } _ { 0 } = \pmb { 0 }$ . Under such an assumption and rewriting the model as $\pmb { a } _ { t } = \pmb { r } _ { t } - \pmb { \theta } _ { 0 } + \pmb { \Theta } \pmb { a } _ { t - 1 }$ , we can compute the shock $\pmb { a } _ { t }$ recursively as

$$
\boldsymbol {a} _ {1} = \boldsymbol {r} _ {1} - \boldsymbol {\theta} _ {0}, \quad \boldsymbol {a} _ {2} = \boldsymbol {r} _ {2} - \boldsymbol {\theta} _ {0} + \boldsymbol {\Theta} _ {1} \boldsymbol {a} _ {1}, \quad \dots .
$$

Consequently, the likelihood function of the data becomes

$$
f \left(\boldsymbol {r} _ {1}, \dots , \boldsymbol {r} _ {T} \mid \boldsymbol {\theta} _ {0}, \boldsymbol {\Theta} _ {1}, \boldsymbol {\Sigma}\right) = \prod_ {t = 1} ^ {T} \frac {1}{(2 \pi) ^ {k / 2} \left| \boldsymbol {\Sigma} \right| ^ {1 / 2}} \exp \left(- \frac {1}{2} \boldsymbol {a} _ {t} ^ {\prime} \boldsymbol {\Sigma} ^ {- 1} \boldsymbol {a} _ {t}\right),
$$

which can be evaluated to obtain the parameter estimates.

# Exact MLE

For the exact likelihood method, $\pmb { a } _ { 0 }$ is an unknown vector that must be estimated from the data to evaluate the likelihood function. For simplicity, let $\tilde { r } _ { t } = r _ { t } - \theta _ { 0 }$ be the mean-corrected series. Using $\tilde { \boldsymbol { r } } _ { t }$ and Eq. (8.25), we have

$$
\boldsymbol {a} _ {t} = \tilde {\boldsymbol {r}} _ {t} + \boldsymbol {\Theta} \boldsymbol {a} _ {t - 1}. \tag {8.27}
$$

By repeated substitutions, $\pmb { a } _ { 0 }$ is related to all $\tilde { \boldsymbol { r } } _ { t }$ as

$$
\boldsymbol {a} _ {1} = \tilde {\boldsymbol {r}} _ {1} + \boldsymbol {\Theta} \boldsymbol {a} _ {0},
$$

$$
\boldsymbol {a} _ {2} = \tilde {\boldsymbol {r}} _ {2} + \boldsymbol {\Theta} \boldsymbol {a} _ {1} = \tilde {\boldsymbol {r}} _ {2} + \boldsymbol {\Theta} \tilde {\boldsymbol {r}} _ {1} + \boldsymbol {\Theta} ^ {2} \boldsymbol {a} _ {0},
$$

$$
\dot {:=} \dot {:} \tag {8.28}
$$

$$
\boldsymbol {a} _ {T} = \tilde {\boldsymbol {r}} _ {T} + \boldsymbol {\Theta} \tilde {\boldsymbol {r}} _ {T - 1} + \dots + \boldsymbol {\Theta} ^ {T - 1} \tilde {\boldsymbol {r}} _ {1} + \boldsymbol {\Theta} ^ {T} \boldsymbol {a} _ {0}.
$$

Thus, $\pmb { a } _ { 0 }$ is a linear function of the data if $\pmb { \theta } _ { 0 }$ and $\mathbf { \Theta } _ { \Theta }$ are given. This result enables us to estimate $\pmb { a } _ { 0 }$ using the data and initial estimates of $\pmb { \theta } _ { 0 }$ and $\mathbf { \Theta } _ { \Theta }$ . More specifically, given $\pmb { \theta } _ { 0 }$ , $\mathbf { \Theta } _ { \Theta }$ , and the data, we can define

$$
\boldsymbol {r} _ {t} ^ {*} = \tilde {\boldsymbol {r}} _ {t} + \boldsymbol {\Theta} \tilde {\boldsymbol {r}} _ {t - 1} + \dots + \boldsymbol {\Theta} ^ {t - 1} \tilde {\boldsymbol {r}} _ {1}, \quad \text {f o r} \quad t = 1, 2, \dots , T.
$$

Equation (8.28) can then be rewritten as

$$
r _ {1} ^ {*} = - \Theta a _ {0} + a _ {1},
$$

$$
r _ {2} ^ {*} = - \Theta^ {2} a _ {0} + a _ {2},
$$

$$
\begin{array}{c} \vdots = \vdots \\ \vdots = \vdots \end{array}
$$

$$
\boldsymbol {r} _ {T} ^ {*} = - \boldsymbol {\Theta} ^ {T} \boldsymbol {a} _ {0} + \boldsymbol {a} _ {T}.
$$

This is in the form of a multiple linear regression with parameter vector $\pmb { a } _ { 0 }$ , even though the covariance matrix $\pmb { \Sigma }$ of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi$ may not be a diagonal matrix. If initial estimate of $\pmb { \Sigma }$ is also available, one can premultiply each equation of the prior system by ${ \pmb { \Sigma } } ^ { - 1 / 2 }$ , which is the square-root matrix of $\pmb { \Sigma }$ . The resulting system is indeed a multiple linear regression, and the ordinary least squares method can be used to obtain an estimate of $\pmb { a } _ { 0 }$ . Denote the estimate by $\widehat { \pmb { a } } _ { 0 }$ .

Using the estimate $\widehat { \pmb { a } } _ { 0 }$ , we can compute the shocks $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \mathbf \Psi \Psi \mathbf \Psi $ recursively as

$$
\boldsymbol {a} _ {1} = \boldsymbol {r} _ {1} - \boldsymbol {\theta} _ {0} + \Theta \widehat {\boldsymbol {a}} _ {0}, \quad \boldsymbol {a} _ {2} = \boldsymbol {r} _ {2} - \boldsymbol {\theta} _ {0} + \Theta \boldsymbol {a} _ {1}, \quad \dots .
$$

This recursion is a linear transformation from $( \pmb { a } _ { 0 } , \pmb { r } _ { 1 } , \dots , \pmb { r } _ { T } )$ to $( { \pmb a } _ { 0 } , { \pmb a } _ { 1 } , \dots , { \pmb a } _ { T } )$ , from which we can (a) obtain the joint distribution of $\pmb { a } _ { 0 }$ and the data, and (2) integrate out $\pmb { a } _ { 0 }$ to derive the exact likelihood function of the data. The resulting likelihood function can then be evaluated to obtain the exact ML estimates. For details, see Hillmer and Tiao (1979).

In summary, the exact likelihood method works as follows. Given initial estimates of θ 0, , and $\pmb { \Sigma }$ , one uses Eq. (8.28) to derive an estimate of $\pmb { a } _ { 0 }$ . This estimate is in turn used to compute $\pmb { a } _ { t }$ recursively using Eq. (8.27) and starting with $\pmb { a } _ { 1 } = \widetilde { \pmb { r } } _ { 1 } + \Theta \widehat { \pmb { a } } _ { 0 }$ . The resulting $\{ { \pmb a } _ { t } \} _ { t = 1 } ^ { T }$ are then used to evaluate the exact likelihood function of the data to update the estimates of $\pmb { \theta } _ { 0 }$ , , and $\pmb { \Sigma }$ . The whole process is then repeated until the estimates converge. This iterative method to evaluate the exact likelihood function applies to the general $\mathrm { V M A } ( q )$ models.

From the previous discussion, the exact likelihood method requires more intensive computation than the conditional likelihood approach does. But it provides more accurate parameter estimates, especially when some eigenvalues of $\mathbf { \Theta } _ { \Theta }$ are close to 1 in modulus. Hillmer and Tiao (1979) provide some comparison between the conditional and exact likelihood estimations of VMA models. In multivariate time series analysis, the exact maximum likelihood method becomes important if one suspects that the data might have been overdifferenced. Overdifferencing may occur in many situations (e.g., differencing individual components of a cointegrated system; see discussion later on cointegration).

In summary, building a VMA model involves three steps: (a) use the sample cross-correlation matrices to specify the order $q$ —for a VMA(q) model, $\pmb { \rho } _ { \ell } = \pmb { 0 }$ for $\ell > q$ ; (b) estimate the specified model by using either the conditional or exact likelihood method—the exact method is preferred when the sample size is not large; and (c) the fitted model should be checked for adequacy (e.g., applying the $Q _ { k } ( m )$ statistics to the residual series). Finally, forecasts of a VMA model can be obtained by using the same procedure as a univariate MA model.

Example 8.5. Consider again the bivariate series of monthly log returns in percentages of IBM stock and the S&P 500 index from January 1926 to December 1999. Since significant cross-correlations occur mainly at lags 1 and 3, we employ

Table 8.6. Estimation Results for Monthly Log Returns of IBM Stock and the S&P 500 Index Using the Vector Moving-Average Model in Eq. (8.29): January 1926 to December 1999   

<table><tr><td>Parameter</td><td>θ0</td><td colspan="2">Θ1</td><td colspan="2">Θ3</td><td colspan="2">Σ</td></tr><tr><td colspan="8">(a) Full Model with Conditional Likelihood Method</td></tr><tr><td rowspan="2">Estimate</td><td>1.24</td><td>-0.013</td><td>-0.121</td><td>-0.038</td><td>0.108</td><td>44.48</td><td>23.52</td></tr><tr><td>0.54</td><td>0.020</td><td>-0.101</td><td>0.014</td><td>0.105</td><td>23.52</td><td>31.20</td></tr><tr><td rowspan="2">Standard error</td><td>0.24</td><td>0.043</td><td>0.051</td><td>0.044</td><td>0.052</td><td></td><td></td></tr><tr><td>0.18</td><td>0.036</td><td>0.043</td><td>0.036</td><td>0.043</td><td></td><td></td></tr><tr><td colspan="8">(b) Full Model with Exact Likelihood Method</td></tr><tr><td rowspan="2">Estimate</td><td>1.24</td><td>-0.013</td><td>-0.121</td><td>-0.038</td><td>0.108</td><td>44.48</td><td>23.52</td></tr><tr><td>0.54</td><td>0.020</td><td>-0.101</td><td>0.013</td><td>0.105</td><td>23.52</td><td>31.20</td></tr><tr><td rowspan="2">Standard error</td><td>0.24</td><td>0.043</td><td>0.051</td><td>0.044</td><td>0.052</td><td></td><td></td></tr><tr><td>0.18</td><td>0.036</td><td>0.043</td><td>0.036</td><td>0.043</td><td></td><td></td></tr><tr><td colspan="8">(c) Simplified Model with Exact Likelihood Method</td></tr><tr><td rowspan="2">Estimate</td><td>1.24</td><td>0.000</td><td>-0.126</td><td>0.000</td><td>0.082</td><td>44.54</td><td>23.51</td></tr><tr><td>0.54</td><td>0.000</td><td>-0.084</td><td>0.000</td><td>0.114</td><td>23.51</td><td>31.21</td></tr><tr><td rowspan="2">Standard error</td><td>0.23</td><td>—</td><td>0.040</td><td>—</td><td>0.040</td><td></td><td></td></tr><tr><td>0.18</td><td>—</td><td>0.033</td><td>—</td><td>0.033</td><td></td><td></td></tr></table>

the VMA(3) model

$$
\boldsymbol {r} _ {t} = \boldsymbol {\theta} _ {0} + \boldsymbol {a} _ {t} - \Theta_ {1} \boldsymbol {a} _ {t - 1} - \Theta_ {3} \boldsymbol {a} _ {t - 3} \tag {8.29}
$$

for the data. Table 8.6 shows the estimation results of the model. The $Q _ { k } ( m )$ statistics for the residuals of the simplified model give $Q _ { 2 } ( 4 ) = 1 7 . 2 5$ and $Q _ { 2 } ( 8 ) =$ 39.30. Compared with chi-squared distributions with 12 and 28 degrees of freedom, the $p$ -values of these statistics are 0.1404 and 0.0762, respectively. Thus, the model is adequate at the $5 \%$ significance level.

From Table 8.6, we make the following observations:

1. The difference between conditional and exact likelihood estimates is small for this particular example. This is not surprising because the sample size is not small and, more important, the dynamic structure of the data is weak.   
2. The VMA(3) model provides essentially the same dynamic relationship for the series as that of the VAR(3) model in Example 8.4. The monthly log return of IBM stock depends on the previous returns of the S&P 500 index. The market return, in contrast, does not depend on lagged returns of IBM stock. In other words, the dynamic structure of the data is driven by the market return, not by IBM return. The concurrent correlation between the two returns remains strong, however.

# 8.4 VECTOR ARMA MODELS

Univariate ARMA models can also be generalized to handle vector time series. The resulting models are called VARMA models. The generalization, however, encounters some new issues that do not occur in developing VAR and VMA models. One of the issues is the identifiability problem. Unlike the univariate ARMA models, VARMA models may not be uniquely defined. For example, the VMA(1) model

$$
\left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0 & 2 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right]
$$

is identical to the VAR(1) model

$$
\left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0 & - 2 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} r _ {1, t - 1} \\ r _ {2, t - 1} \end{array} \right] = \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

The equivalence of the two models can easily be seen by examining their component models. For the VMA(1) model, we have

$$
r _ {1 t} = a _ {1 t} - 2 a _ {2, t - 1}, \quad r _ {2 t} = a _ {2 t}.
$$

For the VAR(1) model, the equations are

$$
r _ {1 t} + 2 r _ {2, t - 1} = a _ {1 t}, \quad r _ {2 t} = a _ {2 t}.
$$

From the model for $r _ { 2 t }$ , we have $r _ { 2 , t - 1 } = a _ { 2 , t - 1 }$ . Therefore, the models for $r _ { 1 t }$ are identical. This type of identifiability problem is harmless because either model can be used in a real application.

Another type of identifiability problem is more troublesome. Consider the VARMA(1,1) model

$$
\left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 8 & - 2 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} r _ {1, t - 1} \\ r _ {2, t - 1} \end{array} \right] = \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} - 0. 5 & 0 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right].
$$

This model is identical to the VARMA(1,1) model

$$
\left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 8 & - 2 + \eta \\ 0 & \omega \end{array} \right] \left[ \begin{array}{c} r _ {1, t - 1} \\ r _ {2, t - 1} \end{array} \right] = \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} - 0. 5 & \eta \\ 0 & \omega \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right],
$$

for any nonzero $\omega$ and $\eta$ . In this particular instance, the equivalence occurs because we have $r _ { 2 t } = a _ { 2 t }$ in both models. The effects of the parameters $\omega$ and $\eta$ on the system cancel out between AR and MA parts of the second model. Such an identifiability problem is serious because, without proper constraints, the likelihood function of a vector ARMA(1,1) model for the data is not uniquely defined, resulting in a situation similar to the exact multicollinearity in a regression analysis.

This type of identifiability problem can occur in a vector model even if none of the components is a white noise series.

These two simple examples highlight the new issues involved in the generalization to VARMA models. Building a VARMA model for a given data set thus requires some attention. In the time series literature, methods of structural specification have been proposed to overcome the identifiability problem; see Tiao and Tsay (1989), Tsay (1991), and the references therein. We do not discuss the detail of structural specification here because VAR and VMA models are sufficient in most financial applications. When VARMA models are used, only lower order models are entertained (e.g., a VARMA(1,1) or VARMA(2,1) model) especially when the time series involved are not seasonal.

A VARMA $( p , q )$ model can be written as

$$
\boldsymbol {\Phi} (B) \boldsymbol {r} _ {t} = \boldsymbol {\phi} _ {0} + \boldsymbol {\Theta} (B) \boldsymbol {a} _ {t},
$$

where $\Phi ( B ) = I - \Phi _ { 1 } B - \cdot \cdot \cdot - \Phi _ { p } B ^ { p }$ and $\Theta ( B ) = I - \Theta _ { 1 } B - \cdot \cdot \cdot - \Theta _ { q } B ^ { q }$ are two $k \times k$ matrix polynomials. We assume that the two matrix polynomials have no left common factors; otherwise, the model can be simplified. The necessary and sufficient condition of weak stationarity for $r _ { t }$ is the same as that for the $\operatorname { V A R } ( p )$ model with matrix polynomial $\Phi ( B )$ . For $v > 0$ , the $( i , j )$ th elements of the coefficient matrices $\Phi _ { v }$ and $\Theta _ { v }$ measure the linear dependence of $r _ { 1 t }$ on $r _ { j , t - v }$ and $\boldsymbol { a } _ { j , t - v }$ , respectively. If the $( i , j )$ th element is zero for all AR and MA coefficient matrices, then $r _ { i t }$ does not depend on the lagged values of $r _ { j t }$ . However, the converse proposition does not hold in a VARMA model. In other words, nonzero coefficients at the $( i , j )$ th position of AR and MA matrices may exist even when $r _ { i t }$ does not depend on any lagged value of $r _ { j t }$ .

To illustrate, consider the following bivariate model:

$$
\left[ \begin{array}{l l} \Phi_ {1 1} (B) & \Phi_ {1 2} (B) \\ \Phi_ {2 1} (B) & \Phi_ {2 2} (B) \end{array} \right] \left[ \begin{array}{l} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{l l} \Theta_ {1 1} (B) & \Theta_ {1 2} (B) \\ \Theta_ {2 1} (B) & \Theta_ {2 2} (B) \end{array} \right] \left[ \begin{array}{l} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

Here the necessary and sufficient conditions for the existence of a unidirectional dynamic relationship from $r _ { 1 t }$ to $r _ { 2 t }$ are

$$
\Phi_ {2 2} (B) \Theta_ {1 2} (B) - \Phi_ {1 2} (B) \Theta_ {2 2} (B) = 0,
$$

but

$$
\Phi_ {1 1} (B) \Theta_ {2 1} (B) - \Phi_ {2 1} (B) \Theta_ {1 1} (B) \neq 0. \tag {8.30}
$$

These conditions can be obtained as follows. Letting

$$
\Omega (B) = | \Phi (B) | = \Phi_ {1 1} (B) \Phi_ {2 2} (B) - \Phi_ {1 2} (B) \Phi_ {2 1} (B)
$$

be the determinant of the AR matrix polynomial and premultiplying the model by the matrix

$$
\left[ \begin{array}{c c} \Phi_ {2 2} (B) & - \Phi_ {1 2} (B) \\ - \Phi_ {2 1} (B) & \Phi_ {1 1} (B) \end{array} \right],
$$

we can rewrite the bivariate model as

$$
\begin{array}{l} \Omega (B) \left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \\ \left[ \begin{array}{l l} \Phi_ {2 2} (B) \Theta_ {1 1} (B) - \Phi_ {1 2} (B) \Theta_ {2 1} (B) & \Phi_ {2 2} (B) \Theta_ {1 2} (B) - \Phi_ {1 2} (B) \Theta_ {2 2} (B) \\ \Phi_ {1 1} (B) \Theta_ {2 1} (B) - \Phi_ {2 1} (B) \Theta_ {1 1} (B) & \Phi_ {1 1} (B) \Theta_ {2 2} (B) - \Phi_ {2 1} (B) \Theta_ {1 2} (B) \end{array} \right] \left[ \begin{array}{l} a _ {1 t} \\ a _ {2 t} \end{array} \right]. \\ \end{array}
$$

Consider the equation for $r _ { 1 t }$ . The first condition in Eq. (8.30) shows that $r _ { 1 t }$ does not depend on any past value of $a _ { 2 t }$ or $r _ { 2 t }$ . From the equation for $r _ { 2 t }$ , the second condition in Eq. (8.30) implies that $r _ { 2 t }$ indeed depends on some past values of $a _ { 1 t }$ . Based on Eq. (8.30), $\Theta _ { 1 2 } ( B ) = \Phi _ { 1 2 } ( B ) = 0$ is a sufficient, but not necessary, condition for the unidirectional relationship from $r _ { 1 t }$ to $r _ { 2 t }$ .

Estimation of a VARMA model can be carried out by either the conditional or exact maximum likelihood method. The $Q _ { k } ( m )$ statistic continues to apply to the residual series of a fitted model, but the degrees of freedom of its asymptotic chisquared distribution are $k ^ { 2 } m - g$ , where $g$ is the number of estimated parameters in both the AR and MA coefficient matrices.

Example 8.6. To demonstrate VARMA modeling, we consider two U.S. monthly interest-rate series. The first series is the 1-year Treasury constant maturity rate, and the second series is the 3-year Treasury constant maturity rate. The data are obtained from the Federal Reserve Bank of St. Louis, and the sampling period is from April 1953 to January 2001. There are 574 observations. To ensure the positiveness of U.S. interest rates, we analyze the log series. Figure 8.8 shows the time plots of the two log interest-rate series. The solid line denotes the 1-year maturity rate. The two series moved closely in the sampling period.

The $M ( i )$ statistics and AIC criterion specify a VAR(4) model for the data. However, we employ a VARMA(2,1) model because the two models provide similar fits. Table 8.7 shows the parameter estimates of the VARMA(2,1) model obtained by the exact likelihood method. We removed the insignificant parameters and reestimated the simplified model. The residual series of the fitted model has some minor serial and cross-correlations at lags 7 and 11. Figure 8.9 shows the residual plots and indicates the existence of some outlying data points. The model can be further improved, but it seems to capture the dynamic structure of the data reasonably well.

The final VARMA(2,1) model shows some interesting characteristics of the data. First, the interest-rate series are highly contemporaneously correlated. The concurrent correlation coefficient is $2 . 5 / \bar { \sqrt { 3 . 5 8 \times 2 . 1 9 } } = 0 . 8 9 3$ . Second, there is a unidirectional linear relationship from the 3-year rate to the 1-year rate because the (2, 1)th elements of all AR and MA matrices are zero, but some (1, 2)th element is not zero. As a matter of fact, the model in Table 8.7 shows that

$$
\begin{array}{l} r _ {3 t} = 0. 0 2 5 + 0. 9 9 r _ {3, t - 1} + a _ {3 t} + 0. 4 7 a _ {3, t - 1}, \\ r _ {1 t} = 0. 0 2 8 + 1. 8 2 r _ {1, t - 1} - 0. 8 4 r _ {1, t - 2} - 0. 9 7 r _ {3, t - 1} + 0. 9 8 r _ {3, t - 2} \\ + a _ {1 t} - 0. 9 0 a _ {1, t - 1} + 1. 6 6 a _ {3, t - 1}, \\ \end{array}
$$

![](images/de49f4eafa2b9aa650b0919b4654b2d55e99ec678e36a52950fb39d75d9a6b0d.jpg)  
Figure 8.8. Time plots of log U.S. monthly interest rates from April 1953 to January 2001. The solid line denotes the 1-year Treasury constant maturity rate, and the dashed line denotes the 3-year rate.

Table 8.7. Parameter Estimates of a VARMA(2,1) Model for Two Monthly U.S. Interest-Rate Series Based on the Exact Likelihood Method   

<table><tr><td>Parameter</td><td colspan="2">Φ1</td><td colspan="2">Φ2</td><td>φ0</td><td colspan="2">Θ1</td><td colspan="2">Σ × 103</td></tr><tr><td rowspan="2">Estimate</td><td>1.82</td><td>-0.97</td><td>-0.84</td><td>0.98</td><td>0.028</td><td>0.90</td><td>-1.66</td><td>3.58</td><td>2.50</td></tr><tr><td></td><td>0.99</td><td></td><td></td><td>0.025</td><td></td><td>-0.47</td><td>2.50</td><td>2.19</td></tr><tr><td rowspan="2">Standard error</td><td>0.03</td><td>0.08</td><td>0.03</td><td>0.08</td><td>0.014</td><td>0.03</td><td>0.10</td><td></td><td></td></tr><tr><td></td><td>0.01</td><td></td><td></td><td>0.011</td><td></td><td>0.04</td><td></td><td></td></tr></table>

where $r _ { i t }$ is the log series of $i$ -year interest rate and $a _ { i t }$ is the corresponding shock series. Therefore, the 3-year interest rate does not depend on the past values of the 1-year rate, but the 1-year rate depends on the past values of the 3-year rate. Third, the two interest-rate series appear to be unit-root nonstationary. Using the back-shift operator $B$ , the model can be rewritten approximately as

$$
(1 - B) r _ {3 t} = 0. 0 3 + (1 + 0. 4 7 B) a _ {3 t},
$$

$$
(1 - B) (1 - 0. 8 2 B) r _ {1 t} = 0. 0 3 - 0. 9 7 B (1 - B) r _ {3, t} + (1 - 0. 9 B) a _ {1 t} + 1. 6 6 B a _ {3, t}.
$$

Finally, the SCA commands used in the analysis are given in Appendix C.

![](images/16e7af9ad7b9f981b98d1628aab61716635735bcf2facf45b9a75cdad4ec07a0.jpg)

![](images/4d4b4ab9113b056e3ef9789ac1f9edf78d994e687a6e972d813f4de70f7d2783.jpg)  
Figure 8.9. Residual plots for log U.S. monthly interest-rate series of Example 8.6. The fitted model is a VARMA(2,1).

# 8.4.1 Marginal Models of Components

Given a vector model for $r _ { t }$ , the implied univariate models for the components $r _ { i t }$ are the marginal models. For a $k$ -dimensional $\mathbf { A R M A } ( p , q )$ model, the marginal models are ARMA[kp, $( k - 1 ) p + q ]$ . This result can be obtained in two steps. First, the marginal model of a $\mathrm { V M A } ( q )$ model is univariate $\mathrm { M A } ( q )$ . Assume that $r _ { t }$ is a $\mathrm { V M A } ( q )$ process. Because the cross-correlation matrix of $r _ { t }$ vanishes after  =   an MA process and its univariate model is in the form lag $q$ (i.e., $\pmb { \rho } _ { \ell } = \pmb { 0 }$ for $\ell > q$ ), the ACF of $r _ { i t }$ is zero beyond lag $\begin{array} { r } { r _ { i t } = \theta _ { i , 0 } + \sum _ { j = 1 } ^ { q } \theta _ { i , j } b _ { i , t - j } } \end{array}$ $q$ . Therefore, $r _ { i t }$ is , where $\{ b _ { i t } \}$ is a sequence of uncorrelated random variables with mean zero and variance $\sigma _ { i b } ^ { 2 }$ . The parameters $\theta _ { i , j }$ and $\sigma _ { i b }$ are functions of the parameters of the VMA model for $r _ { t }$ .

The second step to obtain the result is to diagonalize the AR matrix polynomial of a $\mathrm { V A R M A } ( p , q )$ model. For illustration, consider the bivariate AR(1) model

$$
\left[ \begin{array}{c c} 1 - \Phi_ {1 1} B & - \Phi_ {1 2} B \\ - \Phi_ {2 1} B & 1 - \Phi_ {2 2} B \end{array} \right] \left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

Premultiplying the model by the matrix polynomial

$$
\left[ \begin{array}{c c} 1 - \Phi_ {2 2} B & \Phi_ {1 2} B \\ \Phi_ {2 1} B & 1 - \Phi_ {1 1} B \end{array} \right],
$$

we obtain

$$
[ (1 - \Phi_ {1 1} B) (1 - \Phi_ {2 2} B) - \Phi_ {1 2} \Phi_ {2 2} B ^ {2} ] \left[ \begin{array}{c} r _ {1 t} \\ r _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} 1 - \Phi_ {2 2} B & - \Phi_ {1 2} B \\ - \Phi_ {2 1} B & 1 - \Phi_ {1 1} B \end{array} \right] \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

The left-hand side of the prior equation shows that the univariate AR polynomials for $r _ { i t }$ are of order 2. In contrast, the right-hand side of the equation is in a VMA(1) form. Using the result of VMA models in step 1, we show that the univariate model for $r _ { i t }$ is ARMA(2,1). The technique generalizes easily to the $k$ -dimensional VAR(1) model, and the marginal models are $\mathrm { A R M A } ( k , k - 1 )$ . More generally, for a $k$ -dimensional $\operatorname { V A R } ( p )$ model, the marginal models are $\mathrm { A R M A } [ k p , ( k - 1 ) p ]$ $( k - 1 ) p ]$ . The result for VARMA models follows directly from those of VMA and VAR models.

The order $[ k p , ( k - 1 ) p + q ]$ is the maximum order (i.e., the upper bound) for the marginal models. The actual marginal order of $r _ { i t }$ can be much lower.

# 8.5 UNIT-ROOT NONSTATIONARITY AND COINTEGRATION

When modeling several unit-root nonstationary time series jointly, one may encounter the case of cointegration. Consider the bivariate ARMA(1,1) model

$$
\left[ \begin{array}{l} x _ {1 t} \\ x _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 5 & - 1. 0 \\ - 0. 2 5 & 0. 5 \end{array} \right] \left[ \begin{array}{l} x _ {1, t - 1} \\ x _ {2, t - 1} \end{array} \right] = \left[ \begin{array}{l} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 2 & - 0. 4 \\ - 0. 1 & 0. 2 \end{array} \right] \left[ \begin{array}{l} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right], \tag {8.31}
$$

where the covariance matrix $\pmb { \Sigma }$ of the shock $\pmb { a } _ { t }$ is positive definite. This is not a weakly stationary model because the two eigenvalues of the AR coefficient matrix are 0 and 1. Figure 8.10 shows the time plots of a simulated series of the model with 200 data points and $\Sigma = I$ , whereas Figure 8.11 shows the sample autocorrelations of the two component series $x _ { i t }$ . It is easy to see that the two series have high autocorrelations and exhibit features of unit-root nonstationarity. The two marginal models of $\boldsymbol { x } _ { t }$ are indeed unit-root nonstationary. Rewrite the model as

$$
\left[ \begin{array}{c c} 1 - 0. 5 B & B \\ 0. 2 5 B & 1 - 0. 5 B \end{array} \right] \left[ \begin{array}{c} x _ {1 t} \\ x _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} 1 - 0. 2 B & 0. 4 B \\ 0. 1 B & 1 - 0. 2 B \end{array} \right] \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

Premultiplying the above equation by

$$
\left[ \begin{array}{c c} 1 - 0. 5 B & - B \\ - 0. 2 5 B & 1 - 0. 5 B \end{array} \right],
$$

we obtain the result

$$
\left[ \begin{array}{c c} 1 - B & 0 \\ 0 & 1 - B \end{array} \right] \left[ \begin{array}{c} x _ {1 t} \\ x _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} 1 - 0. 7 B & - 0. 6 B \\ - 0. 1 5 B & 1 - 0. 7 B \end{array} \right] \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right].
$$

![](images/9437cbb0fdc59f7f831e5852bff99d1508f18ef7d1fdbadf9892a4d306f0dd44.jpg)

![](images/9ee6ad4091e2f30847685f9b1cf4c1d3c2c8661f2f36db00d7aa474f243fede2.jpg)  
Figure 8.10. Time plots of a simulated series based on model (8.31) with identity covariance matrix for the shocks.

![](images/8c36ba8f7cd23feaa128b0a8b1734edf6c1032607565a3690157d1a0b7be6447.jpg)

![](images/38339d5b923de180d15da9376358e50366a33dc4f9442ef406c1658365f631f9.jpg)  
Figure 8.11. Sample autocorrelation functions of two simulated component series. There are 200 observations, and the model is given by Eq. (8.31) with identity covariance matrix for the shocks.

Therefore, each component $x _ { i t }$ of the model is unit-root nonstationary and follows an ARIMA(0,1,1) model.

However, we can consider a linear transformation by defining

$$
\left[ \begin{array}{c} y _ {1 t} \\ y _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} 1. 0 & - 2. 0 \\ 0. 5 & 1. 0 \end{array} \right] \left[ \begin{array}{c} x _ {1 t} \\ x _ {2 t} \end{array} \right] \equiv L \boldsymbol {x} _ {t},
$$

$$
\left[ \begin{array}{c} b _ {1 t} \\ b _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} 1. 0 & - 2. 0 \\ 0. 5 & 1. 0 \end{array} \right] \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] \equiv \boldsymbol {L} \boldsymbol {a} _ {t}.
$$

The VARMA model of the transformed series $\mathbf { } y _ { t }$ can be obtained as follows:

$$
\begin{array}{l} \boldsymbol {L} \boldsymbol {x} _ {t} = \boldsymbol {L} \boldsymbol {\Phi} \boldsymbol {x} _ {t - 1} + \boldsymbol {L} \boldsymbol {a} _ {t} - \boldsymbol {L} \boldsymbol {\Theta} \boldsymbol {a} _ {t - 1} \\ = L \Phi L ^ {- 1} L x _ {t - 1} + L a _ {t} - L \Theta L ^ {- 1} L a _ {t - 1} \\ = L \Phi L ^ {- 1} \left(L x _ {t - 1}\right) + b _ {t} - L \Theta L ^ {- 1} b _ {t - 1}. \\ \end{array}
$$

Thus, the model for $\mathbf { } y _ { t }$ is

$$
\left[ \begin{array}{l} y _ {1 t} \\ y _ {2 t} \end{array} \right] - \left[ \begin{array}{l l} 1. 0 & 0 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{l} y _ {1, t - 1} \\ y _ {2, t - 1} \end{array} \right] = \left[ \begin{array}{l} b _ {1 t} \\ b _ {2 t} \end{array} \right] - \left[ \begin{array}{l l} 0. 4 & 0 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{l} b _ {1, t - 1} \\ b _ {2, t - 1} \end{array} \right]. \tag {8.32}
$$

From the prior model, we see that (a) $y _ { 1 t }$ and $y _ { 2 t }$ are uncoupled series with concurrent correlation equal to that between the shocks $b _ { 1 t }$ and $b _ { 2 t }$ , (b) $y _ { 1 t }$ follows a univariate ARIMA(0,1,1) model, and (c) $y _ { 2 t }$ is a white noise series (i.e., $y _ { 2 t } = b _ { 2 t }$ ). In particular, the model in Eq. (8.32) shows that there is only a single unit root in the system. Consequently, the unit roots of $x _ { 1 t }$ and $x _ { 2 t }$ are introduced by the unit root of $y _ { 1 t }$ . In the literature, $y _ { 1 t }$ is referred to as the common trend of $x _ { 1 t }$ and $x _ { 2 t }$ .

The phenomenon that both $x _ { 1 t }$ and $x _ { 2 t }$ are unit-root nonstationary, but there is only a single unit root in the vector series, is referred to as cointegration in the econometric and time series literature. Another way to define cointegration is to focus on linear transformations of unit-root nonstationary series. For the simulated example of model (8.31), the transformation shows that the linear combination $y _ { 2 t } = 0 . 5 x _ { 1 t } + x _ { 2 t }$ does not have a unit root. Consequently, $x _ { 1 t }$ and $x _ { 2 t }$ are cointegrated if (a) both of them are unit-root nonstationary, and (b) they have a linear combination that is unit-root stationary.

Generally speaking, for a $k$ -dimensional unit-root nonstationary time series, cointegration exists if there are less than $k$ unit roots in the system. Let $h$ be the number of unit roots in the $k$ -dimensional series $\boldsymbol { x } _ { t }$ . Cointegration exists if $0 < h < k$ , and the quantity $k - h$ is called the number of cointegrating factors. Alternatively, the number of cointegrating factors is the number of different linear combinations that are unit-root stationary. The linear combinations are called the cointegrating vectors. For the prior simulated example, $y _ { 2 t } = ( 0 . 5 , 1 ) x _ { t }$ so that $( 0 . 5 , 1 ) ^ { \prime }$ is a

cointegrating vector for the system. For more discussions on cointegration and cointegration tests, see Box and Tiao (1977), Engle and Granger (1987), Stock and Watson (1988), and Johansen (1988). We discuss cointegrated VAR models in Section 8.6.

The concept of cointegration is interesting and has attracted a lot of attention in the literature. However, there are difficulties in testing for cointegration in a real application. The main source of difficulties is that cointegration tests overlook the scaling effects of the component series. Interested readers are referred to Cochrane (1988) and Tiao, Tsay, and Wang (1993) for further discussion.

While I have some misgivings on the practical value of cointegration tests, the idea of cointegration is highly relevant in financial study. For example, consider the stock of Finnish Nokia Corporation. Its price on the Helsinki Stock Market must move in unison with the price of its American Depositary Receipts on the New York Stock Exchange; otherwise there exists some arbitrage opportunity for investors. If the stock price has a unit root, then the two price series must be cointegrated. In practice, such a cointegration can exist after adjusting for transaction costs and exchange-rate risk. We discuss issues like this later in Section 8.7.

# 8.5.1 An Error-Correction Form

Because there are more unit-root nonstationary components than the number of unit roots in a cointegrated system, differencing individual components to achieve stationarity results in overdifferencing. Overdifferencing leads to the problem of unit roots in the MA matrix polynomial, which in turn may encounter difficulties in parameter estimation. If the MA matrix polynomial contains unit roots, the vector time series is said to be noninvertible.

Engle and Granger (1987) discuss an error-correction representation for a cointegrated system that overcomes the difficulty of estimating noninvertible VARMA models. Consider the cointegrated system in Eq. (8.31). Let $\Delta \pmb { x } _ { t } = \pmb { x } _ { t } - \pmb { x } _ { t - 1 }$ be the differenced series. Subtracting $x _ { t - 1 }$ from both sides of the equation, we obtain a model for $\Delta \boldsymbol { x } _ { t }$ as

$$
\begin{array}{l} \left[ \begin{array}{c} \Delta x _ {1 t} \\ \Delta x _ {2 t} \end{array} \right] = \left[ \begin{array}{c c} - 0. 5 & - 1. 0 \\ - 0. 2 5 & - 0. 5 \end{array} \right] \left[ \begin{array}{c} x _ {1, t - 1} \\ x _ {2, t - 1} \end{array} \right] + \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 2 & - 0. 4 \\ - 0. 1 & 0. 2 \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right] \\ = \left[ \begin{array}{c} - 1 \\ - 0. 5 \end{array} \right] [ 0. 5, 1. 0 ] \left[ \begin{array}{c} x _ {1, t - 1} \\ x _ {2, t - 1} \end{array} \right] + \left[ \begin{array}{c} a _ {1 t} \\ a _ {2 t} \end{array} \right] - \left[ \begin{array}{c c} 0. 2 & - 0. 4 \\ - 0. 1 & 0. 2 \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} \\ a _ {2, t - 1} \end{array} \right]. \\ \end{array}
$$

This is a stationary model because both $\Delta \boldsymbol { x } _ { t }$ and $[ 0 . 5 , 1 . 0 ] { \pmb x } _ { t } = y _ { 2 t }$ are unit-root stationary. Because $x _ { t - 1 }$ is used on the right-hand side of the previous equation, the MA matrix polynomial is the same as before and, hence, the model does not encounter the problem of noninvertibility. Such a formulation is referred to as an error-correction model for $\Delta \boldsymbol { x } _ { t }$ , and it can be extended to the general cointegrated VARMA model. For a cointegrated ${ \mathrm { V A R M A } } ( p , q )$ model with $m$ cointegrating

factors $( m < k )$ ), an error-correction representation is

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\alpha} \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t - 1} + \sum_ {i = 1} ^ {p - 1} \boldsymbol {\Phi} _ {i} ^ {*} \Delta \boldsymbol {x} _ {t - i} + \boldsymbol {a} _ {t} - \sum_ {j = 1} ^ {q} \boldsymbol {\Theta} _ {j} \boldsymbol {a} _ {t - j}, \tag {8.33}
$$

where $\pmb { \alpha }$ and $\beta$ are $k \times m$ full-rank matrices. The AR coefficient matrices $\Phi _ { i } ^ { * }$ are functions of the original coefficient matrices $\Phi _ { j }$ . Specifically, we have

$$
\boldsymbol {\Phi} _ {j} ^ {*} = - \sum_ {i = j + 1} ^ {p} \boldsymbol {\Phi} _ {i}, \quad j = 1, \ldots , p - 1,
$$

$$
\alpha \boldsymbol {\beta} ^ {\prime} = \Phi_ {p} + \Phi_ {p - 1} + \dots + \Phi_ {1} - I = - \Phi (1). \tag {8.34}
$$

These results can be obtained by equating coefficient matrices of the AR matrix polynomials. The time series $\beta ^ { \prime } x _ { t }$ is unit-root stationary, and the columns of $\beta$ are the cointegrating vectors of $\scriptstyle { \boldsymbol { x } } _ { t }$ .

Existence of the stationary series $\beta ^ { \prime } x _ { t - 1 }$ in the error-correction representation (8.33) is natural. It can be regarded as a “compensation” term for the overdifferenced system $\Delta \boldsymbol { x } _ { t }$ . The stationarity of $\beta ^ { \prime } x _ { t - 1 }$ can be justified as follows. The theory of unit-root time series shows that the sample correlation coefficient between a unit-root nonstationary series and a stationary series converges to zero as the sample size goes to infinity; see Tsay and Tiao (1990) and the references therein. In an error-correction representation, $x _ { t - 1 }$ is unit-root nonstationary, but $\Delta \ v { x } _ { t }$ is stationary. Therefore, the only way that $\Delta \boldsymbol { x } _ { t }$ can relate meaningfully to $\boldsymbol { x } _ { t - 1 }$ is through a stationary series $\beta ^ { \prime } x _ { t - 1 }$ .

Remark. Our discussion of cointegration assumes that all unit roots are of multiplicity 1, but the concept can be extended to cases in which the unit roots have different multiplicities. Also, if the number of cointegrating factors $m$ is given, then the error-correction model in Eq. (8.33) can be estimated by likelihood methods. We discuss the simple case of cointegrated VAR models in the next section. Finally, there are many ways to construct an error-correction representation. In fact, one can use any $\pmb { \alpha \beta ^ { \prime } x _ { t - v } }$ for $1 \leq v \leq p$ in Eq. (8.33) with some modifications to the AR coefficient matrices $\Phi _ { i } ^ { * }$ . 

# 8.6 COINTEGRATED VAR MODELS

To better understand cointegration, we focus on VAR models for their simplicity in estimation. Consider a $k$ -dimensional $\operatorname { V A R } ( p )$ time series $\scriptstyle { x _ { t } }$ with possible time trend so that the model is

$$
\boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {t} + \boldsymbol {\Phi} _ {1} \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p} \boldsymbol {x} _ {t - p} + \boldsymbol {a} _ {t}, \tag {8.35}
$$

where the innovation $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \Xi \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Lambda \mathbf { } \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf { } \Lambda \mathbf \Lambda \mathbf { } \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda $ is assumed to be Gaussian and ${ \pmb { \mu } } _ { t } = { \pmb { \mu } } _ { 0 } + { \pmb { \mu } } _ { 1 } t$ , where ${ \pmb \mu } _ { 0 }$ and $\pmb { \mu } _ { 1 }$ are $k$ -dimensional constant vectors. Write $\Phi ( B ) = I - \Phi _ { 1 } B - \cdot \cdot \cdot - \Phi _ { p } B ^ { p }$ . Recall that if all zeros of the determinant $| \Phi ( B ) |$ are outside the unit circle, then

$\scriptstyle { x _ { t } }$ is unit-root stationary. In the literature, a unit-root stationary series is said to be an $I ( 0 )$ process; that is, it is not integrated. If $| \Phi ( 1 ) | = 0$ , then $\mathbf { \boldsymbol { x } } _ { t }$ is unit-root nonstationary. For simplicity, we assume that $\scriptstyle { x _ { t } }$ is at most an integrated process of order 1, that is, an $I ( 1 )$ process. This means that $( 1 - B ) x _ { i t }$ is unit-root stationary if $x _ { i t }$ itself is not.

An error-correction model (ECM) for the $\operatorname { V A R } ( p )$ process $\scriptstyle { \boldsymbol { x } } _ { t }$ is

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {t} + \boldsymbol {\Pi} \boldsymbol {x} _ {t - 1} + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t}, \tag {8.36}
$$

where $\Phi _ { j } ^ { * }$ are defined in Eq. (8.34) and $\Pi = \alpha \beta ^ { ' } = - \Phi ( 1 )$ . We refer to the term $\Pi \boldsymbol { x } _ { t - 1 }$ of Eq. (8.36) as the error-correction term, which plays a key role in cointegration study. Notice that $\Phi _ { i }$ can be recovered from the ECM representation via

$$
\begin{array}{l} \Phi_ {1} = I + \Pi + \Phi_ {1} ^ {*}, \\ \boldsymbol {\Phi} _ {i} = \boldsymbol {\Phi} _ {i} ^ {*} - \boldsymbol {\Phi} _ {i - 1} ^ {*}, \quad i = 2, \ldots , p, \\ \end{array}
$$

where $\Phi _ { p } ^ { * } = \mathbf { 0 }$ , the zero matrix. Based on the assumption that $\scriptstyle { x _ { t } }$ is at most $I ( 1 )$ $\Delta \boldsymbol { x } _ { t }$ of Eq. (8.36) is an $I ( 0 )$ process.

If $\boldsymbol { x } _ { t }$ contains unit roots, then $| \Phi ( 1 ) | = 0$ so that $\Pi = - \Phi ( 1 )$ is singular. Therefore, three cases are of interest in considering the ECM in Eq. (8.36):

1. $\mathrm { R a n k } ( \mathbf { I I } ) = 0$ . This implies $\Pi = \mathbf { 0 }$ and $\scriptstyle { x _ { t } }$ is not cointegrated. The ECM of Eq. (8.36) reduces to

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {t} + \Phi_ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \Phi_ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t},
$$

so that $\Delta \boldsymbol { x } _ { t }$ follows a $\mathrm { V A R } ( p - 1 )$ model with deterministic trend ${ \pmb { \mu } } _ { t }$ .

2. $\mathrm { R a n k } ( \boldsymbol { \Pi } ) = k$ . This implies that $| \Phi ( 1 ) | \neq 0$ and $\boldsymbol { x } _ { t }$ contains no unit roots; that is, $\mathbf { \boldsymbol { x } } _ { t }$ is $I ( 0 )$ . The ECM model is not informative and one studies $\mathbf { \boldsymbol { x } } _ { t }$ directly.

3. $0 < \mathrm { R a n k } ( \mathbf { I I } ) = m < k$ . In this case, one can write $\boldsymbol { \Pi }$ a s

$$
\boldsymbol {\Pi} = \alpha \boldsymbol {\beta} ^ {\prime}, \tag {8.37}
$$

where $\pmb { \alpha }$ and $\beta$ are $k \times m$ matrices with $\operatorname { R a n k } ( \alpha ) = \operatorname { R a n k } ( \beta ) = m$ . The ECM of Eq. (8.36) becomes

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {t} + \boldsymbol {\alpha} \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t - 1} + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t}. \tag {8.38}
$$

This means that $\scriptstyle { x _ { t } }$ is cointegrated with m linearly independent cointegrating vectors, ${ \pmb w } _ { t } = { \pmb \beta } ^ { \prime } { \pmb x } _ { t }$ , and has $k - m$ unit roots that give $k - m$ common stochastic trends of $\boldsymbol { x } _ { t }$ .

If $\scriptstyle { x _ { t } }$ is cointegrated with $\operatorname { R a n k } ( \Pi ) = m$ , then a simple way to obtain a presentation of the $k - m$ common trends is to obtain an orthogonal complement matrix $\pmb { \alpha } _ { \bot }$ of $\pmb { \alpha }$ ; that is, $\pmb { \alpha } _ { \bot }$ is a $k \times ( k - m )$ matrix such that ${ \pmb { \alpha } } _ { \perp } ^ { \prime } { \pmb { \alpha } } = { \bf 0 }$ , a $( k - m ) \times m$ zero matrix, and use $\mathbf { y } _ { t } = \pmb { \alpha } _ { \perp } ^ { \prime } \pmb { x } _ { t }$ ⊥. To see this, one can premultiply the ECM by $\pmb { \alpha } _ { \bot } ^ { \prime }$ and use $\Pi = \alpha \beta ^ { \prime }$ to see that there would be no error-correction

term in the resulting equation. Consequently, the $( k - m )$ -dimensional series $\displaystyle \boldsymbol { y } _ { t }$ should have $k - m$ unit roots. For illustration, consider the bivariate example of Section 8.5.1. For this special series, $\pmb { \alpha } = ( - 1 , - 0 . 5 ) ^ { \prime }$ and $\pmb { \alpha } _ { \bot } = ( 1 , - 2 ) ^ { \prime }$ . Therefore, $y _ { t } = ( 1 , - 2 ) { \pmb x } _ { t } = x _ { 1 t } - 2 x _ { 2 t }$ , which is precisely the unit-root nonstationary series $y _ { 1 t }$ in Eq. (8.32).

Note that the factorization in Eq. (8.37) is not unique, because for any $m \times m$ orthogonal matrix $\pmb { \Omega }$ satisfying $\pmb { \Omega } \pmb { \Omega } ^ { \prime } = \pmb { I }$ , we have

$$
\alpha \beta^ {\prime} = \alpha \Omega \Omega^ {\prime} \beta^ {\prime} = (\alpha \Omega) (\beta \Omega) ^ {\prime} \equiv \alpha_ {*} \beta_ {*} ^ {\prime},
$$

where both $\pmb { \alpha } _ { \ast }$ and $\beta _ { * }$ are also of rank $m$ . Additional constraints are needed to uniquely identify $\pmb { \alpha }$ and $\beta$ . It is common to require that $\pmb { \beta } ^ { \prime } = [ \pmb { I } _ { m } , \pmb { \beta } _ { 1 } ^ { \prime } ]$ , where $\boldsymbol { I } _ { m }$ is the $m \times m$ identity matrix and $\beta _ { 1 }$ is a $( k - m ) \times m$ matrix. In practice, this may require reordering of the elements of $\mathbf { \boldsymbol { x } } _ { t }$ such that the first $m$ components all have a unit root. The elements of $\pmb { \alpha }$ and $\beta$ must also satisfy other constraints for the process ${ \pmb w } _ { t } = { \pmb \beta } ^ { \prime } { \pmb x } _ { t }$ to be unit-root stationary. For example, consider the case of a bivariate VAR(1) model with one cointegrating vector. Here $k = 2$ , $m = 1$ , and the ECM is

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {t} + \left[ \begin{array}{c} \alpha_ {1} \\ \alpha_ {2} \end{array} \right] [ 1, \beta_ {1} ] \boldsymbol {x} _ {t - 1} + \boldsymbol {a} _ {t}.
$$

Premultiplying the prior equation by $\beta ^ { \prime }$ , using $w _ { t - i } = \pmb { \beta } ^ { \prime } \pmb { x } _ { t - i }$ , and moving $w _ { t - 1 }$ to the right-hand side of the equation, we obtain

$$
w _ {t} = \boldsymbol {\beta} ^ {\prime} \boldsymbol {\mu} _ {t} + (1 + \alpha_ {1} + \alpha_ {2} \beta_ {1}) w _ {t - 1} + b _ {t},
$$

where $b _ { t } = \beta ^ { \prime } \mathbf { a } _ { t }$ . This implies that $w _ { t }$ is a stationary AR(1) process. Consequently, $\alpha _ { i }$ and $\beta _ { 1 }$ must satisfy the stationarity constraint $| 1 + \alpha _ { 1 } + \alpha _ { 2 } \beta _ { 1 } | < 1$ .

The prior discussion shows that the rank of $\boldsymbol { \Pi }$ in the ECM of Eq. (8.36) is the number of cointegrating vectors. Thus, to test for cointegration, one can examine the rank of . This is the approach taken by Johansen (1988, 1995) and Reinsel and Ahn (1992).

# 8.6.1 Specification of the Deterministic Function

Similar to the univariate case, the limiting distributions of cointegration tests depend on the deterministic function ${ \pmb { \mu } } _ { t }$ . In this subsection, we discuss some specifications of ${ \pmb { \mu } } _ { t }$ that have been proposed in the literature. To understand some of the statements made below, keep in mind that ${ \pmb { \alpha } } _ { \perp } ^ { \prime } { \pmb { x } } _ { t }$ provides a presentation for the common stochastic trends of $\boldsymbol { x } _ { t }$ if it is cointegrated.

1. ${ \pmb { \mu } } _ { t } = { \bf 0 }$ : In this case, all the component series of $\boldsymbol { x } _ { t }$ are $I ( 1 )$ without drift and the stationary series ${ \pmb w } _ { t } = { \pmb \beta } ^ { \prime } { \pmb x } _ { t }$ has mean zero.   
2. ${ \pmb { \mu } } _ { t } = { \pmb { \mu } } _ { 0 } = { \pmb { \alpha } } { \pmb { c } } _ { 0 }$ , where $c _ { 0 }$ is an $m$ -dimensional nonzero constant vector. The ECM becomes

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\alpha} \left(\boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t - 1} + \boldsymbol {c} _ {0}\right) + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t},
$$

so that the components of $\scriptstyle { \boldsymbol { x } } _ { t }$ are $I ( 1 )$ without drift, but ${ \pmb w } _ { t }$ have a nonzero mean $- \pmb { c } _ { 0 }$ . This is referred to as the case of restricted constant.

3. $\pmb { \mu } _ { t } = \pmb { \mu } _ { 0 }$ , which is nonzero. Here the component series of $\scriptstyle { x _ { t } }$ are $I ( 1 )$ with drift $\pmb { \mu } _ { 0 }$ and ${ \pmb w } _ { t }$ may have a nonzero mean.   
4. ${ \pmb { \mu } } _ { t } = { \pmb { \mu } } _ { 0 } + \alpha { \pmb { c } } _ { 1 } t$ , where $c _ { 1 }$ is a nonzero vector. The ECM becomes

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} _ {0} + \boldsymbol {\alpha} \left(\boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t - 1} + \boldsymbol {c} _ {1} t\right) + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t},
$$

so that the components of $\boldsymbol { x } _ { t }$ are $I ( 1 )$ with drift $\pmb { \mu } _ { 0 }$ and ${ \pmb w } _ { t }$ has a linear time trend related to $c _ { 1 } t$ . This is the case of restricted trend.

5. $\pmb { \mu } _ { t } = \pmb { \mu } _ { 0 } + \pmb { \mu } _ { 1 } t$ , where ${ \pmb \mu } _ { i }$ are nonzero. Here both the constant and trend are unrestricted. The components of $\boldsymbol { x } _ { t }$ are $I ( 1 )$ and have a quadratic time trend and ${ \pmb w } _ { t }$ have a linear trend.

Obviously, the last case is not common in empirical work. The first case is not common for economic time series but may represent the log price series of some assets. The third case is also useful in modeling asset prices.

# 8.6.2 Maximum Likelihood Estimation

In this subsection, we briefly outline the maximum likelihood estimation of a cointegrated $\operatorname { V A R } ( p )$ model. Suppose that the data are $\{ \boldsymbol { x } _ { t } | t = 1 , \ldots , T \}$ . Without loss of generality, we write $\pmb { \mu } _ { t } = \pmb { \mu } \pmb { d } _ { t }$ , where $\pmb { d } _ { t } = [ 1 , t ] ^ { \prime }$ , and it is understood that ${ \pmb { \mu } } _ { t }$ depends on the specification of the previous subsection. For a given $m$ , which is the rank of $\boldsymbol { \Pi }$ , the ECM model becomes

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} \boldsymbol {d} _ {t} + \alpha \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t - 1} + \Phi_ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \Phi_ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t}, \tag {8.39}
$$

where $t = p + 1 , . . . , T$ . A key step in the estimation is to concentrate the likelihood function with respect to the deterministic term and the stationary effects. This is done by considering the following two multivariate linear regressions:

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\gamma} _ {0} \boldsymbol {d} _ {t} + \boldsymbol {\Omega} _ {1} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Omega} _ {p - 1} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {u} _ {t}, \tag {8.40}
$$

$$
\boldsymbol {x} _ {t - 1} = \boldsymbol {\gamma} _ {1} \boldsymbol {d} _ {t} + \boldsymbol {\Xi} _ {1} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Xi} _ {p - 1} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {v} _ {t}. \tag {8.41}
$$

Let $\hat { \pmb u } _ { t }$ and $\hat { \pmb { v } } _ { t }$ be the residuals of Eqs. (8.40) and (8.41), respectively. Define the sample covariance matrices

$$
S _ {0 0} = \frac {1}{T - p} \sum_ {t = p + 1} ^ {T} \hat {\boldsymbol {u}} _ {t} \hat {\boldsymbol {u}} _ {t} ^ {\prime}, \quad S _ {0 1} = \frac {1}{T - p} \sum_ {t = p + 1} ^ {T} \hat {\boldsymbol {u}} _ {t} \hat {\boldsymbol {v}} _ {t} ^ {\prime}, \quad S _ {1 1} = \frac {1}{T - p} \sum_ {t = p + 1} ^ {T} \hat {\boldsymbol {v}} _ {t} \hat {\boldsymbol {v}} _ {t} ^ {\prime}.
$$

Next, compute the eigenvalues and eigenvectors of $S _ { 1 0 } S _ { 0 0 } ^ { - 1 } S _ { 0 1 }$ with respect to $S _ { 1 1 }$ This amounts to solving the eigenvalue problem

$$
| \lambda S _ {1 1} - S _ {1 0} S _ {0 0} ^ {- 1} S _ {0 1} | = 0.
$$

Denote the eigenvalue and eigenvector pairs by $( \hat { \lambda } _ { i } , e _ { i } )$ , where $\hat { \lambda } _ { 1 } > \hat { \lambda } _ { 2 } > \dots > \hat { \lambda } _ { k }$ . Here the eigenvectors are normalized so that $e ^ { \prime } S _ { 1 1 } e = I$ , where $\pmb { e } = [ \pmb { e } _ { 1 } , \dots , \pmb { e } _ { k } ]$ is the matrix of eigenvectors.

The unnormalized maximum likelihood estimate (MLE) of the cointegrating vector $\beta$ is $\hat { \pmb { \beta } } = [ \pmb { e } _ { 1 } , \dots , \pmb { e } _ { m } ]$ , from which we can obtain a MLE for $\beta$ that satisfies the identifying constraint and normalization condition. Denote the resulting estimate by $\hat { \boldsymbol { \beta } } _ { c }$ with the subscript $c$ signifying constraints. The MLE of other parameters can then be obtained by the multivariate linear regression

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} \boldsymbol {d} _ {t} + \boldsymbol {\alpha} \hat {\boldsymbol {\beta}} _ {c} ^ {\prime} \boldsymbol {x} _ {t - 1} + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t}.
$$

The maximized value of the likelihood function based on $m$ cointegrating vectors is

$$
L _ {\max } ^ {- 2 / T} \propto | S _ {0 0} | \prod_ {i = 1} ^ {m} (1 - \hat {\lambda} _ {i}).
$$

This value is used in the maximum likelihood ratio test for testing $\operatorname { R a n k } ( \Pi ) = m$ . Finally, estimates of the orthogonal complements of $\pmb { \alpha }$ and $\beta$ can be obtained using

$$
\hat {\boldsymbol {\alpha}} _ {\perp} = S _ {0 0} ^ {- 1} S _ {1 1} \left[ \boldsymbol {e} _ {m + 1}, \dots , \boldsymbol {e} _ {k} \right], \quad \hat {\boldsymbol {\beta}} _ {\perp} = S _ {1 1} \left[ \boldsymbol {e} _ {m + 1}, \dots , \boldsymbol {e} _ {k} \right].
$$

# 8.6.3 A Cointegration Test

For a specified deterministic term ${ \pmb { \mu } } _ { t }$ , we now discuss the maximum likelihood test for testing the rank of the  matrix in Eq. (8.36). Let $H ( m )$ be the null hypothesis that the rank of $\boldsymbol { \Pi }$ is m. For example, under $H ( 0 )$ , Rank()  0 so that $\mathbf { I } = \mathbf { 0 }$ and there is no cointegration. The hypotheses of interest are

$$
H (0) \subset \dots \subset H (m) \subset \dots \subset H (k).
$$

For testing purpose, the ECM in Eq. (8.39) becomes

$$
\Delta \boldsymbol {x} _ {t} = \boldsymbol {\mu} \boldsymbol {d} _ {t} + \boldsymbol {\Pi} \boldsymbol {x} _ {t - 1} + \boldsymbol {\Phi} _ {1} ^ {*} \Delta \boldsymbol {x} _ {t - 1} + \dots + \boldsymbol {\Phi} _ {p - 1} ^ {*} \Delta \boldsymbol {x} _ {t - p + 1} + \boldsymbol {a} _ {t},
$$

where $t = p + 1 , . . . , T$ . Our goal is to test the rank of . Mathematically, the rank of $\boldsymbol { \Pi }$ is the number of nonzero eigenvalues of , which can be obtained if a consistent estimate of $\boldsymbol { \Pi }$ is available. Based on the prior equation, which is in the form of a multivariate linear regression, we see that  is related to the covariance matrix between $x _ { t - 1 }$ and $\Delta \boldsymbol { x } _ { t }$ after adjusting for the effects of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf \Xi \Lambda \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf $ and $\Delta \boldsymbol { x } _ { t - i }$ for $i = 1 , \ldots , p - 1$ . The necessary adjustments can be achieved by the techniques of multivariate linear regression shown in the previous subsection. Indeed, the adjusted series of $x _ { t - 1 }$ and $\Delta \boldsymbol { x } _ { t }$ are $\hat { \pmb { v } } _ { t }$ and $\hat { \pmb u } _ { t }$ , respectively. The equation of interest for the cointegration test then becomes

$$
\hat {\boldsymbol {u}} _ {t} = \boldsymbol {\Pi} \hat {\boldsymbol {v}} _ {t} + \boldsymbol {a} _ {t}.
$$

Under the normality assumption, the likelihood ratio test for testing the rank of  in the prior equation can be done by using the canonical correlation analysis

between $\hat { \pmb u } _ { t }$ and $\hat { \pmb { v } } _ { t }$ . See Johnson and Wichern (1998) for information on canonical correlation analysis. The associated canonical correlations are the partial canonical correlations between $\Delta \boldsymbol { x } _ { t - 1 }$ and $x _ { t - 1 }$ because the effects of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf \Xi \mathbf { } \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \mathbf { } \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \mathbf \Xi \Xi \Xi \mathbf \Xi \Xi \mathbf { } \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \Xi \mathbf \mathbf \Xi \mathbf \Xi \mathbf \mathbf \Lambda \mathbf \mathbf \mathbf \Lambda \mathbf \mathbf \mathbf \Lambda \mathbf \mathbf \mathbf \mathbf \Lambda \mathbf \mathbf \mathbf \mathbf \Lambda \mathbf $ and $\Delta \boldsymbol { x } _ { t - i }$ have been adjusted. The quantities $\{ \hat { \lambda } _ { i } \}$ are the squared canonical correlations between $\hat { \pmb { u } } _ { t }$ and $\hat { \pmb { v } } _ { t }$ .

Consider the hypotheses

$$
H _ {o}: \operatorname {R a n k} (\Pi) = m \quad \text {v e r s u s} \quad H _ {a}: \operatorname {R a n k} (\Pi) > m.
$$

Johansen (1988) proposes the likelihood ratio (LR) statistic

$$
L K _ {\mathrm {t r}} (m) = - (T - p) \sum_ {i = m + 1} ^ {k} \ln \left(1 - \hat {\lambda} _ {i}\right) \tag {8.42}
$$

to perform the test. If $\operatorname { R a n k } ( \Pi ) = m$ , then $\hat { \lambda } _ { i }$ should be small for $i > m$ and hence $L K _ { \mathrm { t r } } ( m )$ should be small. This test is referred to as the trace cointegration test. Due the presence of unit roots, the asymptotic distribution of $L K _ { \mathrm { t r } } ( m )$ is not chisquared, but a function of standard Brownian motions. Thus, critical values of $L K _ { \mathrm { t r } } ( m )$ must be obtained via simulation.

Johansen (1988) also considers a sequential procedure to determine the number of cointegrating vectors. Specifically, the hypotheses of interest are

$$
H _ {o}: \operatorname {R a n k} (\Pi) = m \quad \text {v e r s u s} \quad H _ {a}: \operatorname {R a n k} (\Pi) = m + 1.
$$

The LK ratio test statistic, called the maximum eigenvalue statistic, is

$$
L K _ {\max } (m) = - (T - p) \ln \left(1 - \hat {\lambda} _ {m + 1}\right).
$$

Again, critical values of the test statistics are nonstandard and must be evaluated via simulation.

# 8.6.4 Forecasting of Cointegrated VAR Models

The fitted ECM model can be used to produce forecasts. First, conditioned on the estimated parameters, the ECM equation can be used to produce forecasts of the differenced series $\Delta \boldsymbol { x } _ { t }$ . Such forecasts can in turn be used to obtain forecasts of $\boldsymbol { x } _ { t }$ . A difference between ECM forecasts and the traditional VAR forecasts is that the ECM approach imposes the cointegration relationships in producing the forecasts.

# 8.6.5 An Example

To demonstrate the analysis of cointegrated VAR models, we consider two weekly U.S. short-term interest rates. The series are the 3-month Treasury bill (TB) rate and 6-month Treasury bill rate from December 12, 1958 to August 6, 2004 for 2383 observations. The TB rates are from the secondary market and obtained from the Federal Reserve Bank of St. Loius. Figure 8.12 shows the time plots of the interest rates. As expected, the two series move closely together.

![](images/141ef8848e16da7ba9222dc5851d6a9e7bbfaa406a3b5fc9a253082814a963cb.jpg)  
(a) 3-month-Bill

![](images/4490d2ace11dcb2f836337309dfd8afcc9d4f8e285ec33b880cc7dafc15fe702.jpg)  
(b) 6-month-Bill   
Figure 8.12. Time plots of weekly U.S. interest rate from December 12, 1958 to August 6, 2004. (a) The 3-month Treasury bill rate and (b) the 6-month Treasury bill rate. The rates are from the secondary market.

Our analysis uses the S-Plus software with commands VAR for VAR analysis, coint for cointegration test, and VECM for vector error-correction estimation. Denote the two series by tb3m and tb6m and define the vector series $x _ { t } =$ $( \mathrm { t b } 3 \mathrm { m } _ { t } , \mathrm { t b } 6 \mathrm { m } _ { t } ) ^ { \prime }$ . The augmented Dickey–Fuller unit-root tests fail to reject the hypothesis of a unit root in the individual series; see Chapter 2. Indeed, the test statistics are $- 2 . 3 4$ and $- 2 . 3 3$ with $p$ -value about 0.16 for the 3-month and 6- month interest rate when an AR(3) model is used. Thus, we proceed to VAR modeling.

For the bivariate series $\boldsymbol { x } _ { t }$ , the BIC criterion selects a VAR(3) model.

> $\mathrm { \ x = }$ cbind(tb3m,tb6m)   
> $\mathrm { y } =$ data.frame(x)  
$>$ ord.choice$ar.order

[1] 3

To perform a cointegration test, we choose a restricted constant for ${ \pmb { \mu } } _ { t }$ because there is no reason a priori to believe the existence of a drift in the U.S. interest rate. Both Johansen’s tests confirm that the two series are cointegrated with one cointegrating vector when a VAR(3) model is entertained.

> cointst.rc $=$ coint(x,trend $\mathbf { \omega } = \mathbf { \vec { \Gamma } }$ rc’, lags $^ { = 2 }$ ) % lags = p-1.

```julia
> cointst.rc  
Call:  
coint(Y = x, lags = 2, trend = "rc") 
```

```typescript
Trend Specification: H1\*(r): Restricted constant 
```

Trace tests sign. at the $5\%$ level are flagged by $' + ''.$ Trace tests sign. at the $1 \%$ level are flagged by $' + + ^ { \prime }$ Max Eig. tests sign. at the $5 \%$ level are flagged by $' * '$ Max Eig. tests sign. at the $1 \%$ level are flagged by $' * * ^ { \prime }$

```txt
Tests for Cointegration Rank:  
Eigenvalue Trace Stat 95% CV 99% CV  
H(0) ++** 0.0322 83.2712 19.96 24.60  
H(1) 0.0023 5.4936 9.24 12.97 
```

```txt
Max Stat 95% CV 99% CV  
H(0) ++** 77.7776 15.67 20.20  
H(1) 5.4936 9.24 12.97 
```

Next, we perform the maximum likelihood estimation of the specified cointegrated VAR(3) model using an ECM presentation. The results are given below:

```txt
> vecm.fit = VECM(cointst.mc)  
> summary( vecm.fit)  
Call:  
VECM(test = cointst.mc) 
```

```txt
Cointegrating Vectors: coint.1 1.0000 
```

```txt
tb6m -1.0124  
(std.err) 0.0086  
(t.stat) -118.2799 
```

```txt
Intercept* 0.2254
(std.err) 0.0545
(t.stat) 4.1382 
```

```txt
VECM Coefficients: tb3m tb6m coint.1 -0.0949 -0.0211 (std.err) 0.0199 0.0179 (t.stat) -4.7590 -1.1775 
```

```txt
tb3m.lag1 0.0466 -0.0419  
(std.err) 0.0480 0.0432 
```

(t.stat) 0.9696 -0.9699

tb6m.lag1 0.2650 0.3164

(std.err) 0.0538 0.0484

(t.stat) 4.9263 6.5385

tb3m.lag2 -0.2067 -0.0346

(std.err) 0.0481 0.0433

(t.stat) -4.2984 -0.8005

tb6m.lag2 0.2547 0.0994

(std.err) 0.0543 0.0488

(t.stat) 4.6936 2.0356

Regression Diagnostics:

tb3m tb6m

R-squared 0.1081 0.0913

Adj. R-squared 0.1066 0.0898

Resid. Scale 0.2009 0.1807

> plot(vecm.fit)

Make a plot selection (or 0 to exit):

1: plot: All   
2: plot: Response and Fitted Values   
3: plot: Residuals

13: plot: PACF of Squared Cointegrating Residuals

Selection:

As expected, the output shows that the stationary series is $w _ { t } \approx { \mathrm { t b } } 3 { \mathrm { m } } _ { t } - { \mathrm { t b } } 6 { \mathrm { m } } _ { t }$ and the mean of $w _ { t }$ is about $- 0 . 2 2 5$ . The fitted ECM model is

$$
\begin{array}{l} \Delta \boldsymbol {x} _ {t} = \left[ \begin{array}{c} - 0. 0 9 \\ - 0. 0 2 \end{array} \right] (w _ {t - 1} + 0. 2 3) + \left[ \begin{array}{c c} 0. 0 5 & 0. 2 7 \\ - 0. 0 4 & 0. 3 2 \end{array} \right] \Delta \boldsymbol {x} _ {t - 1} \\ + \left[ \begin{array}{c c} - 0. 2 1 & 0. 2 5 \\ - 0. 0 3 & 0. 1 0 \end{array} \right] \Delta \boldsymbol {x} _ {t - 2} + \boldsymbol {a} _ {t}, \\ \end{array}
$$

and the estimated standard errors of $a _ { i t }$ are 0.20 and 0.18, respectively. Adequacy of the fitted ECM model can be examined via various plots. For illustration, Figure 8.13 shows the cointegrating residuals. Some large residuals are shown in the plot, which occurred in the early 1980s when the interest rates were high and volatile.

Finally, we use the fitted ECM model to produce 1-step to 10-step ahead forecasts for both $\Delta \boldsymbol { x } _ { t }$ and $\boldsymbol { x } _ { t }$ . The forecast origin is August 6, 2004.

$>$ vecm.fst $=$ predict(vecm.fit, n.predict ${ \bf \Lambda } = \mathtt { I } 0$ )   
$>$ summary(vecm.fst)

![](images/89f3cb88c614a8607db876286375fa4de6126ea1976b335e33db10175ff55428.jpg)  
Figure 8.13. Time plot of cointegrating residuals for an ECM fit to the weekly U.S. interest rate series. The data span is from December 12, 1958 to August 6, 2004.

```txt
Predicted Values with Standard Errors: tb3m tb6m 1-step-ahead -0.0378 -0.0642 (std.err) 0.2009 0.1807 2-step-ahead -0.0870 -0.0864 (std.err) 0.3222 0.2927 ... 10-step-ahead -0.2276 -0.1314 (std.err) 0.8460 0.8157 > plot(vecm.fst,xold=diff(x),n.old=12) > vecm.fit.level=VECM(cointst.rc,levels=T) > vecm.fst.level=predict(vecm.fit.level,n.predict=10) > summary(vecm.fst.level) Predicted Values with Standard Errors: tb3m tb6m 1-step-ahead 1.4501 1.7057 (std.err) 0.2009 0.1807 2-step-ahead 1.4420 1.7017 (std.err) 0.3222 0.2927 ... 10-step-ahead 1.4722 1.7078 (std.err) 0.8460 0.8157 > plot(vecm.fst.level,xold=x,n.old=50) 
```

![](images/1fe98d1a2767e4ccd97520405f98cf73dbb73ca3a64ffc8706f2de02ac7850aa.jpg)  
Figure 8.14. Forecasting plots of a fitted ECM model for the weekly U.S. interest rate series. The forecasts are for the differenced series and the forecast origin is August 6, 2004.

The forecasts are shown in Figures 8.14 and 8.15 for the differenced data and the original series, respectively, along with some observed data points. The dashed lines in the plots are pointwise $9 5 \%$ confidence intervals. Because of unit-root nonstationarity, the intervals are wide and not informative.

# 8.7 THRESHOLD COINTEGRATION AND ARBITRAGE

In this section, we focus on detecting arbitrage opportunities in index trading by using multivariate time series methods. We also demonstrate that simple univariate nonlinear models of Chapter 4 can be extended naturally to the multivariate case in conjunction with the idea of cointegration.

Our study considers the relationship between the price of the S&P 500 index futures and the price of the shares underlying the index on the cash market. Let $f _ { t , \ell }$ be the log price of the index futures at time t with maturity , and let $s _ { t }$ be the log price of the shares underlying the index on the cash market at time t. A version of the cost-of-carry model in the finance literature states

$$
f _ {t, \ell} - s _ {t} = \left(r _ {t, \ell} - q _ {t, \ell}\right) (\ell - t) + z _ {t} ^ {*}, \tag {8.43}
$$

where $r _ { t , \ell }$ is the risk-free interest rate, $q _ { t , \ell }$ is the dividend yield with respect to the cash price at time $t$ , and $( \ell - t )$ is the time to maturity of the futures contract;

![](images/5fb502bc768e18ef59b0c4f3e12955077a205dbfea0447636d570c9d47c87b9d.jpg)  
Figure 8.15. Forecasting plots of a fitted ECM model for the weekly U.S. interest rate series. The forecasts are for the interest rates and the forecast origin is August 6, 2004.

see Brenner and Kroner (1995), Dwyer, Locke, and Yu (1996), and the references therein.

The $z _ { t } ^ { * }$ process of model (8.43) must be unit-root stationary; otherwise there exist persistent arbitrage opportunities. Here an arbitrage trading consists of simultaneously buying (short-selling) the security index and selling (buying) the index futures whenever the log prices diverge by more than the cost of carrying the index over time until maturity of the futures contract. Under the weak stationarity of $z _ { t } ^ { * }$ , for arbitrage to be profitable, $z _ { t } ^ { * }$ must exceed a certain value in modulus determined by transaction costs and other economic and risk factors.

It is commonly believed that the $f _ { t , \ell }$ and $s _ { t }$ series of the S&P 500 index contain a unit root, but Eq. (8.43) indicates that they are cointegrated after adjusting for the effect of interest rate and dividend yield. The cointegrating vector is $( 1 , - 1 )$ after the adjustment, and the cointegrated series is $z _ { t } ^ { * }$ . Therefore, one should use an error-correction form to model the return series $\pmb { r } _ { t } = ( \Delta f _ { t } , \Delta s _ { t } ) ^ { \prime }$ , where $\Delta f _ { t } =$ $f _ { t , \ell } - f _ { t - 1 , \ell }$ and $\Delta s _ { t } = s _ { t } - s _ { t - 1 }$ , where for ease in notation we drop the maturity time $\ell$ from the subscript of $\Delta f _ { t }$ .

# 8.7.1 Multivariate Threshold Model

In practice, arbitrage tradings affect the dynamics of the market, and hence the model for $r _ { t }$ may vary over time depending on the presence or absence of arbitrage

tradings. Consequently, the prior discussions lead naturally to the model

$$
\boldsymbol {r} _ {t} = \left\{ \begin{array}{l} \boldsymbol {c} _ {1} + \sum_ {i = 1} ^ {p} \boldsymbol {\Phi} _ {i} ^ {(1)} \boldsymbol {r} _ {t - i} + \boldsymbol {\beta} _ {1} z _ {t - 1} + \boldsymbol {a} _ {t} ^ {(1)} \text {i f} z _ {t - 1} \leq \gamma_ {1}, \\ \boldsymbol {c} _ {2} + \sum_ {i = 1} ^ {p} \boldsymbol {\Phi} _ {i} ^ {(2)} \boldsymbol {r} _ {t - i} + \boldsymbol {\beta} _ {2} z _ {t - 1} + \boldsymbol {a} _ {t} ^ {(2)} \text {i f} \gamma_ {1} <   z _ {t - 1} \leq \gamma_ {2}, \\ \boldsymbol {c} _ {3} + \sum_ {i = 1} ^ {p} \boldsymbol {\Phi} _ {i} ^ {(3)} \boldsymbol {r} _ {t - i} + \boldsymbol {\beta} _ {3} z _ {t - 1} + \boldsymbol {a} _ {t} ^ {(3)} \text {i f} \gamma_ {2} <   z _ {t - 1}, \end{array} \right. \tag {8.44}
$$

where $z _ { t } = 1 0 0 z _ { t } ^ { * }$ , $\gamma _ { 1 } < 0 < \gamma _ { 2 }$ are two real numbers, and $\{ \pmb { a } _ { t } ^ { ( i ) } \}$ are sequences of two-dimensional white noises and are independent of each other. Here we use $z _ { t } = 1 0 0 z _ { t } ^ { * }$ because the actual value of $z _ { t } ^ { * }$ is relatively small.

The model in Eq. (8.44) is referred to as a multivariate threshold model with three regimes. The two real numbers $\gamma _ { 1 }$ and $\gamma _ { 2 }$ are the thresholds and $z _ { t - 1 }$ is the threshold variable. The threshold variable $z _ { t - 1 }$ is supported by the data; see Tsay (1998). In general, one can select $z _ { t - d }$ as a threshold variable by considering $d \in \{ 1 , \ldots , d _ { 0 } \}$ , where $d _ { 0 }$ is a prespecified positive integer.

Model (8.44) is a generalization of the threshold autoregressive model of Chapter 4. It is also a generalization of the error-correlation model of Eq. (8.33). As mentioned earlier, an arbitrage trading is profitable only when $z _ { t } ^ { * }$ or, equivalently, $z _ { t }$ is large in modulus. Therefore, arbitrage tradings only occurred in regimes 1 and 3 of model (8.44). As such, the dynamic relationship between $f _ { t , \ell }$ and $s _ { t }$ in regime 2 is determined mainly by the normal market force, and hence the two series behave more or less like a random walk. In other words, the two log prices in the middle regime should be free from arbitrage effects and, hence, free from the cointegration constraint. From an econometric viewpoint, this means that the estimate of $\beta _ { 2 }$ in the middle regime should be insignificant.

In summary, we expect that the cointegration effects between the log price of the futures and the log price of security index on the cash market are significant in regimes 1 and 3, but insignificant in regime 2. This phenomenon is referred to as a threshold cointegration; see Balke and Fomby (1997).

# 8.7.2 The Data

The data used in this case study are the intraday transaction data of the S&P 500 index in May 1993 and its June futures contract traded at the Chicago Mercantile Exchange; see Forbes, Kalb, and Kofman (1999), who used the data to construct a minute-by-minute bivariate price series with 7060 observations. To avoid the undue influence of unusual returns, I replaced 10 extreme values (5 on each side) by the simple average of their two nearest neighbors. This step does not affect the qualitative conclusion of the analysis but may affect the conditional heteroscedasticity in the data. For simplicity, we do not consider conditional heteroscedasticity in the study. Figure 8.16 shows the time plots of the log returns of the index futures and cash prices and the associated threshold variable $z _ { t } = 1 0 0 z _ { t } ^ { * }$ of model (8.43).

![](images/5017fa6ef174393498bafa160f59ccbf20a5d2f9be0dac1df0cc0005f86b89b1.jpg)  
(a) First differenced in(future)

![](images/db5bf9e1222e4a65225d2d4160388db1b8185e9d8b4f70476ccb052e2035349d.jpg)  
(b) First differenced in(price)

![](images/9172a4ef4d09ce1a09357048a18a099a42906cf4f62a9a406614940d80437a26.jpg)  
(c) z(t) series   
Figure 8.16. Time plots of 1-minute log returns of the S&P 500 index futures and cash prices and the associated threshold variable in May 1993: (a) log returns of the index futures, (b) log returns of the index cash prices, and (c) the $z _ { t }$ series.

# 8.7.3 Estimation

A formal specification of the multivariate threshold model in Eq. (8.44) includes selecting the threshold variable, determining the number of regimes, and choosing the order $p$ for each regime. Interested readers are referred to Tsay (1998) and Forbes, Kalb, and Kofman (1999). The thresholds $\gamma _ { 1 }$ and $\gamma _ { 2 }$ can be estimated by using some information criteria (e.g., the Akaike information criterion [AIC] or the sum of squares of residuals). Assuming $p = 8$ , $d \in \{ 1 , 2 , 3 , 4 \}$ , $\gamma _ { 1 } \in$ $[ - 0 . 1 5 , - 0 . 0 2 ]$ , and $\gamma _ { 2 } \in [ 0 . 0 2 5 , 0 . 1 4 5 ]$ , and using a grid search method with 300 points on each of the two intervals, the AIC selects $z _ { t - 1 }$ as the threshold variable with thresholds $\hat { \gamma } _ { 1 } = - 0 . 0 2 2 6$ and $\hat { \gamma } _ { 2 } = 0 . 0 3 7 7$ . Details of the parameter estimates are given in Table 8.8.

From Table 8.8, we make the following observations. First, the $t$ -ratios of $\widehat { \beta } _ { 2 }$ in the middle regime show that, as expected, the estimates are insignificant at the $5 \%$ level, confirming that there is no cointegration between the two log prices in

Table 8.8. Least Squares Estimates and Their $t$ -Ratios of the Multivariate Threshold Model in Eq. (8.44) for the S&P 500 Index Data in May 1993a   

<table><tr><td rowspan="2"></td><td colspan="2">Regime 1</td><td colspan="2">Regime 2</td><td colspan="2">Regime 3</td></tr><tr><td>Δft</td><td>Δst</td><td>Δft</td><td>Δst</td><td>Δft</td><td>Δst</td></tr><tr><td>φ0</td><td>0.00002</td><td>0.00005</td><td>0.00000</td><td>0.00000</td><td>-0.00001</td><td>-0.00005</td></tr><tr><td>t</td><td>(1.47)</td><td>(7.64)</td><td>(-0.07)</td><td>(0.53)</td><td>(-0.74)</td><td>(-6.37)</td></tr><tr><td>Δft-1</td><td>-0.08468</td><td>0.07098</td><td>-0.03861</td><td>0.04037</td><td>-0.04102</td><td>0.02305</td></tr><tr><td>t</td><td>(-3.83)</td><td>(6.15)</td><td>(-1.53)</td><td>(3.98)</td><td>(-1.72)</td><td>(1.96)</td></tr><tr><td>Δft-2</td><td>-0.00450</td><td>0.15899</td><td>0.04478</td><td>0.08621</td><td>-0.02069</td><td>0.09898</td></tr><tr><td>t</td><td>(-0.20)</td><td>(13.36)</td><td>(1.85)</td><td>(8.88)</td><td>(-0.87)</td><td>(8.45)</td></tr><tr><td>Δft-3</td><td>0.02274</td><td>0.11911</td><td>0.07251</td><td>0.09752</td><td>0.00365</td><td>0.08455</td></tr><tr><td>t</td><td>(0.95)</td><td>(9.53)</td><td>(3.08)</td><td>(10.32)</td><td>(0.15)</td><td>(7.02)</td></tr><tr><td>Δft-4</td><td>0.02429</td><td>0.08141</td><td>0.01418</td><td>0.06827</td><td>-0.02759</td><td>0.07699</td></tr><tr><td>t</td><td>(0.99)</td><td>(6.35)</td><td>(0.60)</td><td>(7.24)</td><td>(-1.13)</td><td>(6.37)</td></tr><tr><td>Δft-5</td><td>0.00340</td><td>0.08936</td><td>0.01185</td><td>0.04831</td><td>-0.00638</td><td>0.05004</td></tr><tr><td>t</td><td>(0.14)</td><td>(7.10)</td><td>(0.51)</td><td>(5.13)</td><td>(-0.26)</td><td>(4.07)</td></tr><tr><td>Δft-6</td><td>0.00098</td><td>0.07291</td><td>0.01251</td><td>0.03580</td><td>-0.03941</td><td>0.02615</td></tr><tr><td>t</td><td>(0.04)</td><td>(5.64)</td><td>(0.54)</td><td>(3.84)</td><td>(-1.62)</td><td>(2.18)</td></tr><tr><td>Δft-7</td><td>-0.00372</td><td>0.05201</td><td>0.02989</td><td>0.04837</td><td>-0.02031</td><td>0.02293</td></tr><tr><td>t</td><td>(-0.15)</td><td>(4.01)</td><td>(1.34)</td><td>(5.42)</td><td>(-0.85)</td><td>(1.95)</td></tr><tr><td>Δft-8</td><td>0.00043</td><td>0.00954</td><td>0.01812</td><td>0.02196</td><td>-0.04422</td><td>0.00462</td></tr><tr><td>t</td><td>(0.02)</td><td>(0.76)</td><td>(0.85)</td><td>(2.57)</td><td>(-1.90)</td><td>(0.40)</td></tr><tr><td>Δst-1</td><td>-0.08419</td><td>0.00264</td><td>-0.07618</td><td>-0.05633</td><td>0.06664</td><td>0.11143</td></tr><tr><td>t</td><td>(-2.01)</td><td>(0.12)</td><td>(-1.70)</td><td>(-3.14)</td><td>(1.49)</td><td>(5.05)</td></tr><tr><td>Δst-2</td><td>-0.05103</td><td>0.00256</td><td>-0.10920</td><td>-0.01521</td><td>0.04099</td><td>-0.01179</td></tr><tr><td>t</td><td>(-1.18)</td><td>(0.11)</td><td>(-2.59)</td><td>(-0.90)</td><td>(0.92)</td><td>(-0.53)</td></tr><tr><td>Δst-3</td><td>0.07275</td><td>-0.03631</td><td>-0.00504</td><td>0.01174</td><td>-0.01948</td><td>-0.01829</td></tr><tr><td>t</td><td>(1.65)</td><td>(-1.58)</td><td>(-0.12)</td><td>(0.71)</td><td>(-0.44)</td><td>(-0.84)</td></tr><tr><td>Δst-4</td><td>0.04706</td><td>0.01438</td><td>0.02751</td><td>0.01490</td><td>0.01646</td><td>0.00367</td></tr><tr><td>t</td><td>(1.03)</td><td>(0.60)</td><td>(0.71)</td><td>(0.96)</td><td>(0.37)</td><td>(0.17)</td></tr><tr><td>Δst-5</td><td>0.08118</td><td>0.02111</td><td>0.03943</td><td>0.02330</td><td>-0.03430</td><td>-0.00462</td></tr><tr><td>t</td><td>(1.77)</td><td>(0.88)</td><td>(0.97)</td><td>(1.43)</td><td>(-0.83)</td><td>(-0.23)</td></tr><tr><td>Δst-6</td><td>0.04390</td><td>0.04569</td><td>0.01690</td><td>0.01919</td><td>0.06084</td><td>-0.00392</td></tr><tr><td>t</td><td>(0.96)</td><td>(1.92)</td><td>(0.44)</td><td>(1.25)</td><td>(1.45)</td><td>(-0.19)</td></tr><tr><td>Δst-7</td><td>-0.03033</td><td>0.02051</td><td>-0.08647</td><td>0.00270</td><td>-0.00491</td><td>0.03597</td></tr><tr><td>t</td><td>(-0.70)</td><td>(0.91)</td><td>(-2.09)</td><td>(0.16)</td><td>(-0.13)</td><td>(1.90)</td></tr><tr><td>Δst-8</td><td>-0.02920</td><td>0.03018</td><td>0.01887</td><td>-0.00213</td><td>0.00030</td><td>0.02171</td></tr><tr><td>t</td><td>(-0.68)</td><td>(1.34)</td><td>(0.49)</td><td>(-0.14)</td><td>(0.01)</td><td>(1.14)</td></tr><tr><td>zt-1</td><td>0.00024</td><td>0.00097</td><td>-0.00010</td><td>0.00012</td><td>0.00025</td><td>0.00086</td></tr><tr><td>t</td><td>(1.34)</td><td>(10.47)</td><td>(-0.30)</td><td>(0.86)</td><td>(1.41)</td><td>(9.75)</td></tr></table>

aThe number of data points for the three regimes are 2234, 2410, and 2408, respectively.

the absence of arbitrage opportunities. Second, $\Delta f _ { t }$ depends negatively on $\Delta f _ { t - 1 }$ in all three regimes. This is in agreement with the bid–ask bounce discussed in Chapter 5. Third, past log returns of the index futures seem to be more informative than the past log returns of the cash prices because there are more significant $t$ -ratios in $\Delta f _ { t - i }$ than in $\Delta s _ { t - i }$ . This is reasonable because futures series are in general more liquid. For more information on index arbitrage, see Dwyer, Locke, and Yu (1996).

# APPENDIX A: REVIEW OF VECTORS AND MATRICES

In this appendix, we briefly review some algebra and properties of vectors and matrices. No proofs are given as they can be found in standard textbooks on matrices (e.g., Graybill, 1969).

An $m \times n$ real-valued matrix is an m by $n$ array of real numbers. For example,

$$
A = \left[ \begin{array}{r r r} 2 & 5 & 8 \\ - 1 & 3 & 4 \end{array} \right]
$$

is a $2 \times 3$ matrix. This matrix has two rows and three columns. In general, an $m \times n$ matrix is written as

$$
\boldsymbol {A} \equiv \left[ a _ {i j} \right] = \left[ \begin{array}{c c c c c} a _ {1 1} & a _ {1 2} & \dots & a _ {1, n - 1} & a _ {1 n} \\ a _ {2 1} & a _ {2 2} & \dots & a _ {2, n - 1} & a _ {2 n} \\ \vdots & \vdots & & \vdots & \vdots \\ a _ {m 1} & a _ {m 2} & \dots & a _ {m, n - 1} & a _ {m n} \end{array} \right]. \tag {8.45}
$$

The positive integers $m$ and $n$ are the row dimension and column dimension of $\pmb { A }$ . The real number $a _ { i j }$ is referred to as the $( i , j )$ th element of $A$ . In particular, the elements $a _ { i i }$ are the diagonal elements of the matrix.

An $m \times 1$ matrix forms an $m$ -dimensional column vector, and a $1 \times n$ matrix is an $n$ -dimensional row vector. In the literature, a vector is often meant to be a column vector. If $m = n$ , then the matrix is a square matrix. If $a _ { i j } = 0$ for $i \neq j$ and $m = n$ , then the matrix $A$ is a diagonal matrix. If $a _ { i j } = 0$ for $i \neq j$ and $a _ { i i } = 1$ for all $i$ , then $A$ is the $m \times m$ identity matrix, which is commonly denoted by $\boldsymbol { I } _ { m }$ or simply $\pmb { I }$ if the dimension is clear.

The $n \times m$ matrix

$$
\boldsymbol {A} ^ {\prime} = \left[ \begin{array}{c c c c c} a _ {1 1} & a _ {2 1} & \dots & a _ {m - 1, 1} & a _ {m 1} \\ a _ {1 2} & a _ {2 2} & \dots & a _ {m - 1, 2} & a _ {m 2} \\ \vdots & \vdots & & \vdots & \vdots \\ a _ {1 n} & a _ {2 n} & \dots & a _ {m - 1, n} & a _ {m n} \end{array} \right]
$$

is the transpose of the matrix $\pmb { A }$ . For example,

$$
\left[ \begin{array}{c c} 2 & - 1 \\ 5 & 3 \\ 8 & 4 \end{array} \right] \quad \text {i s t h e t r a n s p o s e o f} \quad \left[ \begin{array}{c c c} 2 & 5 & 8 \\ - 1 & 3 & 4 \end{array} \right].
$$

We use the notation $A ^ { \prime } = [ a _ { i j } ^ { \prime } ]$ to denote the transpose of $A$ . From the definition, $a _ { i j } ^ { \prime } = a _ { j i }$ and $( A ^ { \prime } ) ^ { \prime } = A$ . If $\overset { \triangledown } { \boldsymbol { A } } ^ { \prime } = \boldsymbol { A }$ , then $A$ is a symmetric matrix.

# Basic Operations

Suppose that $\pmb { A } = [ a _ { i j } ] _ { m \times n }$ and $C = [ c _ { i j } ] _ { p \times q }$ are two matrices with dimensions given in the subscript. Let $b$ be a real number. Some basic matrix operations are defined next:

• Addition: $A + C = [ a _ { i j } + c _ { i j } ] _ { m \times n }$ if $m = p$ and $n = q$   
• Subtraction: $A - C = [ a _ { i j } - c _ { i j } ] _ { m \times n }$ if $m = p$ and $n = q$   
• Scalar multiplication: $b \pmb { A } = [ b a _ { i j } ] _ { m \times n }$   
• Multiplication: $\begin{array} { r } { A C = [ \sum _ { v = 1 } ^ { n } a _ { i v } c _ { v j } ] _ { m \times q } } \end{array}$ provided that $n = p$

When the dimensions of matrices satisfy the condition for multiplication to take place, the two matrices are said to be conformable. An example of matrix multiplication is

$$
\begin{array}{l} \left[ \begin{array}{l l} 2 & 1 \\ 1 & 1 \end{array} \right] \left[ \begin{array}{r r r} 1 & 2 & 3 \\ - 1 & 2 & - 4 \end{array} \right] = \left[ \begin{array}{l} 2 \cdot 1 - 1 \cdot 1 & 2 \cdot 2 + 1 \cdot 2 & 2 \cdot 3 - 1 \cdot 4 \\ 1 \cdot 1 - 1 \cdot 1 & 1 \cdot 2 + 1 \cdot 2 & 1 \cdot 3 - 1 \cdot 4 \end{array} \right] \\ = \left[ \begin{array}{c c c} 1 & 6 & 2 \\ 0 & 4 & - 1 \end{array} \right]. \\ \end{array}
$$

Important rules of matrix operations include (a) $( \pmb { A } \pmb { C } ) ^ { \prime } = \pmb { C } ^ { \prime } \pmb { A } ^ { \prime }$ and (b) $A C \neq C A$ in general.

# Inverse, Trace, Eigenvalue, and Eigenvector

A square matrix $A _ { m \times m }$ is nonsingular or invertible if there exists a unique matrix $C _ { m \times m }$ such that $A C = C A = I _ { m } $ , the $m \times m$ identity matrix. In this case, $c$ is called the inverse matrix of $A$ and is denoted by $C = A ^ { - 1 }$ .

The trace of $A _ { m \times m }$ =  is the sum of its diagonal elements (i.e., $\textstyle t r ( A ) = \sum _ { i = 1 } ^ { m } a _ { i i } )$ It is easy to see that (a) $t r ( A + C ) = t r ( A ) + t r ( C )$ , (b) $t r ( A ) = t r ( A ^ { \prime } )$ , and (c) $t r ( A C ) = t r ( C A )$ provided that the two matrices are conformable.

A number $\lambda$ and an $m \times 1$ vector $\pmb { b }$ , possibly complex-valued, are a right eigenvalue and eigenvector pair of the matrix $A$ if $A b = \lambda b$ . There are m possible eigenvalues for the matrix A. For a real-valued matrix $A$ , complex eigenvalues occur in conjugated pairs. The matrix $A$ is nonsingular if and only if all of its eigenvalues are nonzero. Denote the eigenvalues by $\{ \lambda _ { i } | i = 1 , \ldots , m \}$ : we have $\begin{array} { r } { t r ( A ) = \sum _ { i = 1 } ^ { m } \lambda _ { i } } \end{array}$ . In addition, the determinant of the matrix $A$ can be defined as $\begin{array} { r } { | A | = \prod _ { i = 1 } ^ { m } \lambda _ { i } } \end{array}$ . For a general definition of determinant of a matrix, see a standard textbook on matrices (e.g., Graybill, 1969).

Finally, the rank of the matrix $A _ { m \times n }$ is the number of nonzero eigenvalues of the symmetric matrix $A A ^ { \prime }$ . Also, for a nonsingular matrix $A$ , $( A ^ { - 1 } ) ^ { \prime } = ( A ^ { \prime } ) ^ { - 1 }$ .

# Positive-Definite Matrix

A square matrix A $( m \times m )$ is a positive-definite matrix if (a) $A$ is symmetric, and (b) all eigenvalues of $A$ are positive. Alternatively, $A$ is a positive-definite matrix if for any nonzero $m$ -dimensional vector $\pmb { b }$ , we have ${ \pmb b } ^ { \prime } A { \pmb b } > 0$ .

Useful properties of a positive-definite matrix $A$ include (a) all eigenvalues of $A$ are real and positive, and (b) the matrix can be decomposed as

$$
A = P \Lambda P ^ {\prime},
$$

where $\pmb { \Lambda }$ is a diagonal matrix consisting of all eigenvalues of $A$ and $P$ is an $m \times m$ matrix consisting of the m right eigenvectors of $A$ . It is common to write the eigenvalues as $\lambda _ { 1 } \geq \lambda _ { 2 } \geq \dots \geq \lambda _ { m }$ and the eigenvectors as $e _ { 1 } , \ldots , e _ { m }$ such that $A e _ { i } = \lambda _ { i } e _ { i }$ and $e _ { i } ^ { \prime } e _ { i } = 1$ . In addition, these eigenvectors are orthogonal to each other—namely, $e _ { i } ^ { \prime } e _ { j } = 0$ if $i \neq j$ —if the eigenvalues are distinct. The matrix $P$ is an orthogonal matrix and the decomposition is referred to as the spectral decomposition of the matrix $A$ . Consider, for example, the simple $2 \times 2$ matrix

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c c} 2 & 1 \\ 1 & 2 \end{array} \right],
$$

which is positive definite. Simple calculations show that

$$
\left[ \begin{array}{c c} 2 & 1 \\ 1 & 2 \end{array} \right] \left[ \begin{array}{l} 1 \\ 1 \end{array} \right] = 3 \left[ \begin{array}{l} 1 \\ 1 \end{array} \right], \quad \left[ \begin{array}{c c} 2 & 1 \\ 1 & 2 \end{array} \right] \left[ \begin{array}{l} 1 \\ - 1 \end{array} \right] = \left[ \begin{array}{l} 1 \\ - 1 \end{array} \right].
$$

Therefore, 3 and 1 are eigenvalues of $\pmb { \Sigma }$ with normalized eigenvectors $( 1 / \sqrt { 2 } , 1 / \sqrt { 2 } ) ^ { \prime }$ and $( 1 / \sqrt { 2 } , - \bar { 1 } / \sqrt { 2 } ) ^ { \prime }$ , respectively. It is easy to verify that the spectral decomposition holds—that is,

$$
\left[ \begin{array}{c c} \frac {1}{\sqrt {2}} & \frac {1}{\sqrt {2}} \\ \frac {1}{\sqrt {2}} & \frac {- 1}{\sqrt {2}} \end{array} \right] \left[ \begin{array}{c c} 2 & 1 \\ 1 & 2 \end{array} \right] \left[ \begin{array}{c c} \frac {1}{\sqrt {2}} & \frac {1}{\sqrt {2}} \\ \frac {1}{\sqrt {2}} & \frac {- 1}{\sqrt {2}} \end{array} \right] = \left[ \begin{array}{c c} 3 & 0 \\ 0 & 1 \end{array} \right].
$$

For a symmetric matrix $A$ , there exists a lower triangular matrix $L$ with diagonal elements being 1 and a diagonal matrix $\textbf { G }$ such that $A = L G L ^ { \prime }$ ; see Chapter 1 of Strang (1980). If $A$ is positive definite, then the diagonal elements of $\textbf { G }$ are positive. In this case, we have

$$
A = L \sqrt {G} \sqrt {G} L ^ {\prime} = (L \sqrt {G}) (L \sqrt {G}) ^ {\prime},
$$

where $L { \sqrt { G } }$ is again a lower triangular matrix and the square root is taken element by element. Such a decomposition is called the Cholesky decomposition of $A$ . This decomposition shows that a positive-definite matrix A can be diagonalized as

$$
\boldsymbol {L} ^ {- 1} \boldsymbol {A} \left(\boldsymbol {L} ^ {\prime}\right) ^ {- 1} = \boldsymbol {L} ^ {- 1} \boldsymbol {A} \left(\boldsymbol {L} ^ {- 1}\right) ^ {\prime} = \boldsymbol {G}.
$$

Since $\pmb { L }$ is a lower triangular matrix with unit diagonal elements, $L ^ { - 1 }$ is also a lower triangular matrix with unit diagonal elements. Consider again the prior $2 \times 2$ matrix $\pmb { \Sigma }$ . It is easy to verify that

$$
\boldsymbol {L} = \left[ \begin{array}{l l} 1. 0 & 0. 0 \\ 0. 5 & 1. 0 \end{array} \right] \quad \text {a n d} \quad \boldsymbol {G} = \left[ \begin{array}{l l} 2. 0 & 0. 0 \\ 0. 0 & 1. 5 \end{array} \right]
$$

satisfy $\pmb { \Sigma } = \pmb { L G L } ^ { \prime }$ . In addition,

$$
L ^ {- 1} = \left[ \begin{array}{c c} 1. 0 & 0. 0 \\ - 0. 5 & 1. 0 \end{array} \right] \quad \text {a n d} \quad L ^ {- 1} \Sigma (L ^ {- 1}) ^ {\prime} = G.
$$

# Vectorization and Kronecker Product

Writing an $m \times n$ matrix $\pmb { A }$ in its columns as $\pmb { A } = [ \pmb { a } _ { 1 } , \dots , \pmb { a } _ { n } ]$ , we define the stacking operation as $\operatorname { v e c } ( A ) = ( \pmb { a } _ { 1 } ^ { \prime } , \pmb { a } _ { 2 } ^ { \prime } , \dots , \pmb { a } _ { m } ^ { \prime } ) ^ { \prime }$ , which is an $m n \times 1$ vector. For two matrices $A _ { m \times n }$ and $C _ { p \times q }$ , the Kronecker product between $A$ and $c$ is

$$
\boldsymbol {A} \otimes \boldsymbol {C} = \left[ \begin{array}{c c c c} a _ {1 1} \boldsymbol {C} & a _ {1 2} \boldsymbol {C} & \dots & a _ {1 n} \boldsymbol {C} \\ a _ {2 1} \boldsymbol {C} & a _ {2 2} \boldsymbol {C} & \dots & a _ {2 n} \boldsymbol {C} \\ \vdots & \vdots & & \vdots \\ a _ {m 1} \boldsymbol {C} & a _ {m 2} \boldsymbol {C} & \dots & a _ {m n} \boldsymbol {C} \end{array} \right] _ {m p \times n q}.
$$

For example, assume that

$$
\boldsymbol {A} = \left[ \begin{array}{c c} 2 & 1 \\ - 1 & 3 \end{array} \right], \quad \boldsymbol {C} = \left[ \begin{array}{c c c} 4 & - 1 & 3 \\ - 2 & 5 & 2 \end{array} \right].
$$

Then $\operatorname { v e c } ( A ) = ( 2 , - 1 , 1 , 3 ) ^ { \prime }$ , $\mathrm { v e c } ( { C } ) = ( 4 , - 2 , - 1 , 5 , 3 , 2 ) ^ { \prime }$ , and

$$
\boldsymbol {A} \otimes \boldsymbol {C} = \left[ \begin{array}{c c c c c c} 8 & - 2 & 6 & 4 & - 1 & 3 \\ - 4 & 1 0 & 4 & - 2 & 5 & 2 \\ - 4 & 1 & - 3 & 1 2 & - 3 & 9 \\ 2 & - 5 & - 2 & - 6 & 1 5 & 6 \end{array} \right].
$$

Assuming that the dimensions are appropriate, we have the following useful properties for the two operators:

1. $A \otimes C \neq C \otimes A$ in general.

2. $( A \otimes C ) ^ { \prime } = A ^ { \prime } \otimes C ^ { \prime }$ .

3. $A \otimes ( C + D ) = A \otimes C + A \otimes D .$ .

4. $( A \otimes C ) ( F \otimes G ) = ( A F ) \otimes ( C G )$

5. If $A$ and $c$ are invertible, then $( A \otimes C ) ^ { - 1 } = A ^ { - 1 } \otimes C ^ { - 1 }$ .

6. For square matrices $A$ and $c$ , $t r ( A \otimes C ) = t r ( A ) t r ( C )$ .

7. $\operatorname { v e c } ( A + C ) = \operatorname { v e c } ( A ) + \operatorname { v e c } ( C )$ .

8. vec $( A B C ) = ( C ^ { \prime } \otimes A ) \mathrm { v e c } ( B ) .$

9. $t r ( A C ) = \operatorname { v e c } ( C ^ { \prime } ) ^ { \prime } \operatorname { v e c } ( A ) = \operatorname { v e c } ( A ^ { \prime } ) ^ { \prime } \operatorname { v e c } ( C )$

10. $t r ( A B C ) = \operatorname { v e c } ( A ^ { \prime } ) ^ { \prime } ( C ^ { \prime } \otimes I ) \operatorname { v e c } ( B ) = \operatorname { v e c } ( A ^ { \prime } ) ^ { \prime } ( I \otimes B ) \operatorname { v e c } ( C )$

$$
\begin{array}{l} = \operatorname {v e c} \left(\boldsymbol {B} ^ {\prime}\right) ^ {\prime} (\boldsymbol {A} ^ {\prime} \otimes \boldsymbol {I}) \operatorname {v e c} (\boldsymbol {C}) = \operatorname {v e c} \left(\boldsymbol {B} ^ {\prime}\right) ^ {\prime} (\boldsymbol {I} \otimes \boldsymbol {C}) \operatorname {v e c} (\boldsymbol {A}) \\ = \operatorname {v e c} \left(\boldsymbol {C} ^ {\prime}\right) ^ {\prime} (\boldsymbol {B} ^ {\prime} \otimes \boldsymbol {I}) \operatorname {v e c} (\boldsymbol {A}) = \operatorname {v e c} \left(\boldsymbol {C} ^ {\prime}\right) ^ {\prime} (\boldsymbol {I} \otimes \boldsymbol {A}) \operatorname {v e c} (\boldsymbol {B}). \\ \end{array}
$$

In multivariate statistical analysis, we often deal with symmetric matrices. It is therefore convenient to generalize the stacking operation to the half-stacking operation, which consists of elements on or below the main diagonal. Specifically, for a symmetric square matrix $\pmb { A } = [ a _ { i j } ] _ { k \times k }$ , define

$$
\operatorname {v e c h} (A) = \left(a _ {1} ^ {\prime}, a _ {2 *} ^ {\prime}, \dots , a _ {k *} ^ {\prime}\right) ^ {\prime},
$$

where $\mathbf { \delta } _ { \mathbf { a } _ { 1 } }$ is the first column of $A$ , and $\pmb { a } _ { i * } = ( a _ { i i } , a _ { i + 1 , i } , \ldots , a _ { k i } ) ^ { \prime }$ is a $( k - i + 1 )$ - dimensional vector. The dimension of vech $( A )$ is $k ( k + 1 ) / 2$ . For example, suppose that $k = 3$ . Then we have vech $( A ) = ( a _ { 1 1 } , a _ { 2 1 } , a _ { 3 1 } , a _ { 2 2 } , a _ { 3 2 } , a _ { 3 3 } ) ^ { \prime }$ , which is a sixdimensional vector.

# APPENDIX B: MULTIVARIATE NORMAL DISTRIBUTIONS

A $k$ -dimensional random vector ${ \pmb x } = ( x _ { 1 } , \dots , x _ { k } ) ^ { \prime }$ follows a multivariate normal distribution with mean $\pmb { \mu } = ( \mu _ { 1 } , \ldots , \mu _ { k } ) ^ { \prime }$ and positive-definite covariance matrix $\pmb { \Sigma } = [ \sigma _ { i j } ]$ if its probability density function (pdf) is

$$
f (\boldsymbol {x} | \boldsymbol {\mu}, \boldsymbol {\Sigma}) = \frac {1}{(2 \pi) ^ {k / 2} | \boldsymbol {\Sigma} | ^ {1 / 2}} \exp \left[ - \frac {1}{2} (\boldsymbol {x} - \boldsymbol {\mu}) ^ {\prime} \boldsymbol {\Sigma} ^ {- 1} (\boldsymbol {x} - \boldsymbol {\mu}) \right]. \tag {8.46}
$$

We use the notation $\pmb { x } \sim N _ { k } ( \pmb { \mu } , \pmb { \Sigma } )$ to denote that $\boldsymbol { x }$ follows such a distribution. This normal distribution plays an important role in multivariate statistical analysis and it has several nice properties. Here we consider only those properties that are relevant to our study. Interested readers are referred to Johnson and Wichern (1998) for details.

To gain insight into multivariate normal distributions, consider the bivariate case (i.e., $k = 2$ ). In this case, we have

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c c} \sigma_ {1 1} & \sigma_ {1 2} \\ \sigma_ {1 2} & \sigma_ {2 2} \end{array} \right], \quad \boldsymbol {\Sigma} ^ {- 1} = \frac {1}{\sigma_ {1 1} \sigma_ {2 2} - \sigma_ {1 2} ^ {2}} \left[ \begin{array}{c c} \sigma_ {2 2} & - \sigma_ {1 2} \\ - \sigma_ {1 2} & \sigma_ {1 1} \end{array} \right].
$$

Using the correlation coefficient $\rho = \sigma _ { 1 2 } / ( \sigma _ { 1 } \sigma _ { 2 } )$ , where $\sigma _ { i } = \sqrt { \sigma _ { i i } }$ is the standard deviation of $x _ { i }$ , we have $\sigma _ { 1 2 } = \rho \sqrt { \sigma _ { 1 1 } \sigma _ { 2 2 } }$ and $| \pmb { \Sigma } | = \sigma _ { 1 1 } \sigma _ { 2 2 } ( 1 - \rho ^ { 2 } )$ . The pdf of $\boldsymbol { x }$ then becomes

$$
f (x _ {1}, x _ {2} | \boldsymbol {\mu}, \boldsymbol {\Sigma}) = \frac {1}{2 \pi \sigma_ {1} \sigma_ {2} \sqrt {1 - \rho^ {2}}} \exp \left(- \frac {1}{2 (1 - \rho^ {2})} [ Q (\boldsymbol {x}, \boldsymbol {\mu}, \boldsymbol {\Sigma}) ]\right),
$$

where

$$
Q (\boldsymbol {x}, \boldsymbol {\mu}, \boldsymbol {\Sigma}) = \left(\frac {x _ {1} - \mu_ {1}}{\sigma_ {1}}\right) ^ {2} + \left(\frac {x _ {2} - \mu_ {2}}{\sigma_ {2}}\right) ^ {2} - 2 \rho \left(\frac {x _ {1} - \mu_ {1}}{\sigma_ {1}}\right) \left(\frac {x _ {2} - \mu_ {2}}{\sigma_ {2}}\right).
$$

Chapter 4 of Johnson and Wichern (1998) contains some plots of this pdf function.

Let $\pmb { c } = ( c _ { 1 } , \ldots , c _ { k } ) ^ { \prime }$ be a nonzero $k$ -dimensional vector. Partition the random vector as $\pmb { x } = ( \pmb { x } _ { 1 } ^ { \prime } , \pmb { x } _ { 2 } ^ { \prime } ) ^ { \prime }$ , where $\pmb { x } _ { 1 } = ( x _ { 1 } , \dots , x _ { p } ) ^ { \prime }$ and $\pmb { x } _ { 2 } = ( x _ { p + 1 } , \ldots , x _ { k } ) ^ { \prime }$ with $1 \leq p < k$ . Also partition $\pmb { \mu }$ and $\pmb { \Sigma }$ accordingly as

$$
\left[ \begin{array}{c} \boldsymbol {x} _ {1} \\ \boldsymbol {x} _ {2} \end{array} \right] \sim N \left(\left[ \begin{array}{c} \boldsymbol {\mu} _ {1} \\ \boldsymbol {\mu} _ {2} \end{array} \right], \left[ \begin{array}{c c} \boldsymbol {\Sigma} _ {1 1} & \boldsymbol {\Sigma} _ {1 2} \\ \boldsymbol {\Sigma} _ {2 1} & \boldsymbol {\Sigma} _ {2 2} \end{array} \right]\right).
$$

Some properties of $x$ are as follows:

1. $\displaystyle c ^ { \prime } x \sim N ( c ^ { \prime } \mu , c ^ { \prime } \Sigma c )$ . That is, any nonzero linear combination of $\boldsymbol { x }$ is univariate normal. The inverse of this property also holds. Specifically, if $\boldsymbol { c ^ { \prime } } \boldsymbol { x }$ is univariate normal for any nonzero vector $c$ , then $x$ is multivariate normal.

2. The marginal distribution of $x _ { i }$ is normal. In fact, $\pmb { x } _ { i } \sim N _ { k _ { i } } ( \pmb { \mu } _ { i } , \pmb { \Sigma } _ { i i } )$ for $i = 1$ and 2, where $k _ { 1 } = p$ and $k _ { 2 } = k - p$ .   
3. $\pmb { \Sigma } _ { 1 2 } = \pmb { 0 }$ if and only if $x _ { 1 }$ and $x _ { 2 }$ are independent.   
4. The random variable $y = ( { \pmb x } - { \pmb \mu } ) ^ { \prime } { \pmb \Sigma } ^ { - 1 } ( { \pmb x } - { \pmb \mu } )$ follows a chi-squared distribution with $m$ degrees of freedom.   
5. The conditional distribution of $x _ { 1 }$ given $\mathbf { \delta } _ { x _ { 2 } } = \mathbf { \delta } _ { b }$ is also normally distributed as

$$
\left(\boldsymbol {x} _ {1} \mid \boldsymbol {x} _ {2} = \boldsymbol {b}\right) \sim N _ {p} \left[ \boldsymbol {\mu} _ {1} + \boldsymbol {\Sigma} _ {1 2} \boldsymbol {\Sigma} _ {2 2} ^ {- 1} (\boldsymbol {b} - \boldsymbol {\mu} _ {2}), \boldsymbol {\Sigma} _ {1 1} - \boldsymbol {\Sigma} _ {1 2} \boldsymbol {\Sigma} _ {2 2} ^ {- 1} \boldsymbol {\Sigma} _ {2 1} \right].
$$

The last property is useful in many scientific areas. For instance, it forms the basis for time series forecasting under the normality assumption and for recursive least squares estimation.

# APPENDIX C: SOME SCA COMMANDS

The following SCA commands are used in the analysis of Example 8.6.

```prolog
input x1,x2. file 'm-gs1n3-5301.txt' % Load data
-- 
r1=ln(x1) % Take log transformation
-- 
r2=ln(x2)
-- 
miden r1,r2. no ccm. arfits 1 to 8.
-- % Denote the model by v21.
mtsm v21. series r1,r2. @ 
model (i-p1*b-p2*b**2) series=c+ (i-t1*b) noise.
-- 
mestim v21. % Initial estimation
-- 
p1(2,1)=0 % Set zero constraints
-- 
cp1(2,1)=1
-- 
p2(2,1)=0
-- 
cp2(2,1)=1
-- 
p2(2,2)=0
-- 
cp2(2,2)=1
-- 
t1(2,1)=0
-- 
ct1(2,1)=1
-- % Refine estimation and store residuals
mestim v21. method exact. hold resi(res1,res2)
-- 
miden res1,res2. 
```

# EXERCISES

8.1. Consider the monthly log stock returns, in percentages and including dividends, of Merck & Company, Johnson & Johnson, General Electric, General Motors, Ford Motor Company, and value-weighted index from January 1960 to December 1999; see the file m-mrk2vw.txt, which has six columns in the order listed before.

(a) Compute the sample mean, covariance matrix, and correlation matrix of the data.   
(b) Test the hypothesis $H _ { o } : \pmb { \rho } _ { 1 } = \cdot \cdot \cdot = \pmb { \rho } _ { 6 } = \pmb { 0 }$ , where $\pmb { \rho } _ { i }$ is the lag- $i$ crosscorrelation matrix of the data. Draw conclusions based on the $5 \%$ significance level.   
(c) Is there any lead–lag relationship among the six return series?

8.2. The Federal Reserve Bank of St. Louis publishes selected interest rates and U.S. financial data on its Web site: http://research.stlouisfed.org/ fred2/. Consider the monthly 1-year and 10-year Treasury constant maturity rates from April 1953 to October 2000 for 571 observations; see the file m-gs1n10.txt. The rates are in percentages.

(a) Let $c _ { t } = r _ { t } - r _ { t - 1 }$ be the change series of the monthly interest rate $r _ { t }$ Build a bivariate autoregressive model for the two change series. Discuss the implications of the model. Transform the model into a structural form.   
(b) Build a bivariate moving-average model for the two change series. Discuss the implications of the model and compare it with the bivariate AR model built earlier.

8.3. Again consider the monthly 1-year and 10-year Treasury constant maturity rates from April 1953 to October 2000. Consider the log series of the data and build a VARMA model for the series. Discuss the implications of the model obtained.   
8.4. Again consider the monthly 1-year and 10-year Treasury constant maturity rates from April 1953 to October 2000. Are the two interest rate series threshold-cointegrated? Use the interest spread $s _ { t } = r _ { 1 0 , t } - r _ { 1 , t }$ as the threshold variable, where $r _ { i t }$ is the $i$ -year Treasury constant maturity rate. If they are threshold-cointegrated, build a multivariate threshold model for the two series.   
8.5. The bivariate AR(4) model $\pmb { x } _ { t } - \pmb { \Phi } _ { 4 } \pmb { x } _ { t - 4 } = \pmb { \phi } _ { 0 } + \pmb { a } _ { t }$ is a special seasonal model with periodicity 4, where $\{ \pmb { a } _ { t } \}$ is a sequence of independent and identically distributed normal random vectors with mean zero and covariance matrix $\pmb { \Sigma }$ . Such a seasonal model may be useful in studying quarterly earnings of a company. (a) Assume that $\boldsymbol { x } _ { t }$ is weakly stationary. Derive the mean vector

and covariance matrix of $\scriptstyle { \boldsymbol { x } } _ { t }$ . (b) Derive the necessary and sufficient condition of weak stationarity for $\scriptstyle { x _ { t } }$ . (c) Show that $\Gamma _ { \ell } = \Phi _ { 4 } \Gamma _ { \ell - 4 }$ for $\ell > 0$ , where $\mathbf { \Gamma } \Gamma _ { \ell }$ is the lag- autocovariance matrix of $\scriptstyle { x _ { t } }$ .

8.6. The bivariate MA(4) model $\pmb { x } _ { t } = \pmb { a } _ { t } - \pmb { \Theta } _ { 4 } \pmb { a } _ { t - 4 }$ is another seasonal model with periodicity 4, where $\{ \pmb { a } _ { t } \}$ is a sequence of independent and identically distributed normal random vectors with mean zero and covariance matrix $\pmb { \Sigma }$ . Derive the covariance matrices $\mathbf { \Gamma } \Gamma _ { \ell }$ of $\boldsymbol { x } _ { t }$ for $\ell = 0 , \ldots , 5$ .

8.7. Consider the monthly U.S. 1-year and 3-year Treasury constant maturity rates from April 1953 to March 2004. The data can be obtained from the Federal Reserve Bank of St. Louis or from the file m-gs1n3-5304.txt (1-year, 3- year, dates). See also Example 8.6 that uses a shorter data span. Here we use the interest rates directly without the log transformation and define $x _ { t } =$ $( x _ { 1 t } , x _ { 2 t } ) ^ { \prime }$ , where $x _ { 1 t }$ is the 1-year maturity rate and $x _ { 2 t }$ is the 3-year maturity rate.

(a) Identify a VAR model for the bivariate interest rate series. Write down the fitted model.   
(b) Compute the impulse response functions of the fitted VAR model. It suffices to use the first 6 lags.   
(c) Use the fitted VAR model to produce 1-step to 12-step ahead forecasts of the interest rates, assuming that the forecast origin is March 2004.   
(d) Are the two interest rate series cointegrated, when a restricted constant term is used? Use $5 \%$ significance level to perform the test.   
(e) If the series are cointegrated, build an ECM for the series. Write down the fitted model.   
(f) Use the fitted ECM to produce 1-step to 12-step ahead forecasts of the interest rates, assuming that the forecast origin is March 2004.   
(g) Compare the forecasts produced by the VAR model and the ECM.

# REFERENCES

Balke, N. S. and Fomby, T. B. (1997). Threshold cointegration. International Economic Review 38: 627–645.   
Box, G. E. P. and Tiao, G. C. (1977). A canonical analysis of multiple time series. Biometrika 64: 355–366.   
Brenner, R. J. and Kroner, K. F. (1995). Arbitrage, cointegration, and testing the unbiasedness hypothesis in financial markets. Journal of Financial and Quantitative Analysis 30: 23–42.   
Cochrane, J. H. (1988). How big is the random walk in the GNP? Journal of Political Economy 96: 893–920.   
Dwyer, G. P. Jr., Locke, P., and Yu, W. (1996). Index arbitrage and nonlinear dynamics between the S&P 500 futures and cash. Review of Financial Studies 9: 301–332.

Engle, R. F. and Granger, C. W. J. (1987). Co-integration and error correction representation, estimation and testing. Econometrica 55: 251–276.   
Forbes, C. S., Kalb, G. R. J., and Kofman, P. (1999). Bayesian arbitrage threshold analysis. Journal of Business & Economic Statistics 17: 364–372.   
Fuller, W. A. (1976). Introduction to Statistical Time Series. Wiley, Hoboken, NJ.   
Graybill, F. A. (1969). Introduction to Matrices with Applications in Statistics. Wadsworth, Belmont, CA.   
Hannan, E. J. and Quinn, B. G. (1979). The determination of the order of an autoregression. Journal of the Royal Statistical Society Series B 41: 190–195.   
Hillmer, S. C. and Tiao, G. C. (1979). Likelihood function of stationary multiple autoregressive moving average models. Journal of the American Statistical Association 74: 652–660.   
Hosking, J. R. M. (1980). The multivariate portmanteau statistic. Journal of the American Statistical Association 75: 602–608.   
Hosking, J. R. M. (1981). Lagrange-multiplier tests of multivariate time series models. Journal of the Royal Statistical Society Series B 43: 219–230.   
Johansen, S. (1988). Statistical analysis of co-integration vectors. Journal of Economic Dynamics and Control 12: 231–254.   
Johansen, S. (1995). Likelihood Based Inference in Cointegrated Vector Error Correction Models. Oxford University Press, Oxford, UK.   
Johnson, R. A. and Wichern, D. W. (1998). Applied Multivariate Statistical Analysis, 4th edition. Prentice Hall, Upper Saddle River, NJ.   
Li, W. K. and McLeod, A. I. (1981). Distribution of the residual autocorrelations in multivariate ARMA time series models. Journal of the Royal Statistical Society Series B 43: 231–239.   
Lutkepohl, H. (1991). ¨ Introduction to Multiple Time Series Analysis. Springer-Verlag, New York.   
Reinsel, G. C. (1993). Elements of Multivariate Time Series Analysis. Springer-Verlag, New York.   
Reinsel, G. C. and Ahn, S. K. (1992). Vector autoregressive models with unit roots and reduced rank structure: estimation, likelihood ratio test, and forecasting. Journal of Time Series Analysis 13: 353–375.   
Stock, J. H. and Watson, M.W. (1988). Testing for common trends. Journal of the American Statistical Association 83: 1097–1107.   
Strang, G. (1980). Linear Algebra and Its Applications, 2nd edition. Harcourt Brace Jovanovich, Chicago.   
Tiao, G. C. and Box, G. E. P. (1981). Modeling multiple time series with applications. Journal of the American Statistical Association 76: 802–816.   
Tiao, G. C. and Tsay, R. S. (1989). Model specification in multivariate time series (with discussions). Journal of the Royal Statistical Society Series B 51: 157–213.   
Tiao, G. C., Tsay, R. S., and Wang, T. (1993). Usefulness of linear transformations in multivariate time series analysis. Empirical Economics 18: 567–593.   
Tsay, R. S. (1991). Two canonical forms for vector ARMA processes. Statistica Sinica 1: 247–269.

Tsay, R. S. (1998). Testing and modeling multivariate threshold models. Journal of the American Statistical Association 93: 1188–1202.   
Tsay, R. S., and Tiao, G. C. (1990). Asymptotic properties of multivariate nonstationary processes with applications to autoregressions. Annals of Statistics 18: 220–250.   
Zivot, E. and Wang, J. (2003). Modeling Financial Time Series with S-Plus. Springer-Verlag, New York.

# Principal Component Analysis and Factor Models

Most financial portfolios consist of multiple assets, and their returns depend concurrently and dynamically on many economic and financial variables. Therefore, it is important to use proper multivariate statistical analyses to study the behavior and properties of portfolio returns. However, as demonstrated in the previous chapter, analysis of multiple asset returns often requires high-dimensional statistical models that are complicated and hard to apply. To simplify the task of modeling multiple returns, we discuss in this chapter some dimension reduction methods to search for the underlying structure of the assets. Principal component analysis (PCA) is perhaps the most commonly used statistical method in dimension reduction, and we start our discussion with the method. In practice, observed return series often exhibit similar characteristics leading to the belief that they might be driven by some common sources, often referred to as common factors. To study the common pattern in asset returns and to simplify portfolio analysis, various factor models have been proposed in the literature to analyze multiple asset returns. The second goal of this chapter is to introduce some useful factor models and demonstrate their applications in finance.

Three types of factor models are available for studying asset returns; see Connor (1995) and Campbell, Lo, and MacKinlay (1997). The first type is the macroeconomic factor models that use macroeconomic variables such as growth rate of GDP, interest rates, inflation rate, and unemployment numbers to describe the common behavior of asset returns. Here the factors are observable and the model can be estimated via linear regression methods. The second type is the fundamental factor models that use firm or asset specific attributes such as firm size, book and market values, and industrial classification to construct common factors. The third type is the statistical factor models that treat the common factors as unobservable or latent variables to be estimated from the returns series. In this chapter, we discuss all three types of factor models and their applications in finance. Principal component

analysis and factor models for asset returns are also discussed in Alexander (2001) and Zivot and Wang (2003).

The chapter is organized as follows. Section 9.1 introduces a general factor model for asset returns, and Section 9.2 discusses macroeconomic factor models with some simple examples. The fundamental factor model and its applications are given in Section 9.3. Section 9.4 introduces principal component analysis that serves as the basic method for statistical factor analysis. The PCA can also be used to reduce the dimension in multivariate analysis. Section 9.5 discusses the orthogonal factor models, including factor rotation and its estimation, and provides several examples. Finally, Section 9.6 introduces asymptotic principal component analysis.

# 9.1 A FACTOR MODEL

Suppose that there are $k$ assets and $T$ time periods. Let $r _ { i t }$ be the return of asset $i$ in the time period $t$ . A general form for the factor model is

$$
r _ {i t} = \alpha_ {i} + \beta_ {i 1} f _ {1 t} + \dots + \beta_ {i m} f _ {m t} + \epsilon_ {i t}, \quad t = 1, \dots , T; \quad i = 1, \dots , k, \tag {9.1}
$$

where $\alpha _ { i }$ is a constant representing the intercept, $\{ f _ { j t } | j = 1 , \ldots , m \}$ are m common factors, $\beta _ { i j }$ is the factor loading for asset $i$ on the $j$ th factor, and $\epsilon _ { i t }$ is the specific factor of asset $i$ .

For asset returns, the factor $\pmb { f } _ { t } = ( f _ { 1 t } , \ldots , f _ { m t } ) ^ { \prime }$ is assumed to be an mdimensional stationary process such that

$$
E \left(\boldsymbol {f} _ {t}\right) = \boldsymbol {\mu} _ {f},
$$

$$
\operatorname {C o v} \left(\boldsymbol {f} _ {t}\right) = \boldsymbol {\Sigma} _ {f}, \quad \text {a n} m \times m \text {m a t r i x},
$$

and the asset specific factor $\epsilon _ { i t }$ is a white noise series and uncorrelated with the common factors $f _ { j t }$ and other specific factors. Specifically, we assume that

$$
E (\epsilon_ {i t}) = 0 \quad \text {f o r a l l} i \text {a n d} t,
$$

$$
\operatorname {C o v} \left(f _ {j t}, \epsilon_ {i s}\right) = 0 \quad \text {f o r a l l} j, i, t \text {a n d} s,
$$

$$
\operatorname {C o v} (\epsilon_ {i t}, \epsilon_ {j s}) = \left\{ \begin{array}{l l} \sigma_ {i} ^ {2}, & \text {i f} i = j \text {a n d} t = s, \\ 0, & \text {o t h e r w i s e .} \end{array} \right.
$$

Thus, the common factors are uncorrelated with the specific factors, and the specific factors are uncorrelated among each other. The common factors, however, need not be uncorrelated with each other in some factor models.

In some applications, the number of assets $k$ may be larger than the number of time periods T . We discuss an approach to analyze such data in Section 9.6. It is also common to assume that the factors, hence $r _ { t }$ , are serially uncorrelated in factor analysis. In applications, if the observed returns are serially dependent, then the models in Chapter 8 can be used to remove the serial dependence.

In matrix form, the factor model in Eq. (9.1) can be written as

$$
r _ {i t} = \alpha_ {i} + \boldsymbol {\beta} _ {i} ^ {\prime} \boldsymbol {f} _ {t} + \epsilon_ {i t},
$$

where $\pmb { \beta } _ { i } = ( \beta _ { i 1 } , \dots , \beta _ { i m } ) ^ { \prime }$ , and the joint model for the $k$ assets at time $t$ is

$$
\boldsymbol {r} _ {t} = \boldsymbol {\alpha} + \boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t}, \quad t = 1, \dots , T \tag {9.2}
$$

where $\pmb { r } _ { t } = ( r _ { 1 t } , \ldots , r _ { k t } ) ^ { \prime }$ , β = [βij ] is a $k \times m$ factor-loading matrix, and $\epsilon _ { t } =$ $( \epsilon _ { 1 t } , \dots , \epsilon _ { k t } ) ^ { \prime }$ is the error vector with $\operatorname { C o v } ( \epsilon _ { t } ) = D = \mathrm { d i a g } \{ \sigma _ { 1 } ^ { 2 } , \dots , \sigma _ { k } ^ { 2 } \}$ , a $k \times k$ diagonal matrix. The covariance matrix of the return $r _ { t }$ is then

$$
\operatorname {C o v} \left(\boldsymbol {r} _ {t}\right) = \boldsymbol {\beta} \boldsymbol {\Sigma} _ {f} \boldsymbol {\beta} ^ {\prime} + \boldsymbol {D}.
$$

The model presentation in Eq. (9.2) is in a cross-sectional regression form if the factors $f _ { j t }$ are observed.

Treating the factor model in Eq. (9.1) as a time series, we have

$$
\boldsymbol {R} _ {i} = \alpha_ {i} \mathbf {1} _ {T} + \boldsymbol {F} \boldsymbol {\beta} _ {i} + \boldsymbol {E} _ {i}, \tag {9.3}
$$

for the $i$ th asset $( i = 1 , \ldots , k$ ), where $\pmb { R } _ { i } = ( r _ { i 1 } , \ldots , r _ { i T } ) ^ { \prime }$ , ${ \bf 1 } _ { T }$ is a $T$ -dimensional vector of ones, $F$ is a $T \times m$ matrix whose tth row is $\boldsymbol { f } _ { t } ^ { \prime }$ , and $\pmb { { \cal E } } _ { i } = ( \epsilon _ { i 1 } , \dots , \epsilon _ { i T } ) ^ { \prime }$ The covariance matrix of $E _ { i }$ is $\operatorname { C o v } ( E _ { i } ) = \sigma _ { i } ^ { 2 } I$ , a diagonal $T \times T$ matrix.

Finally, we can rewrite Eq. (9.2) as

$$
\boldsymbol {r} _ {t} = \boldsymbol {\xi} \boldsymbol {g} _ {t} + \boldsymbol {\epsilon} _ {t},
$$

where $\mathbf { \Delta } \mathbf { g } _ { t } = ( 1 , \mathbf { \Delta } \mathbf { f } _ { t } ^ { \prime } ) ^ { \prime }$ and $\pmb { \xi } = [ \pmb { \alpha } , \pmb { \beta } ]$ , which is a $k \times ( m + 1 )$ matrix. Taking the transpose of the prior equation and stacking all data together, we have

$$
\boldsymbol {R} = \boldsymbol {G} \boldsymbol {\xi} ^ {\prime} + \boldsymbol {E}, \tag {9.4}
$$

where $\pmb { R }$ is a $T \times k$ matrix of returns whose t th row is $\boldsymbol { r } _ { t } ^ { \prime }$ or, equivalently, whose ith column is $\pmb { R } _ { i }$ of Eq. (9.3), $\textbf { G }$ is a $T \times ( m + 1 )$ matrix whose t th row is ${ \pmb g } _ { t } ^ { \prime }$ , and $E$ is a $T \times k$ matrix of specific factors whose tth row is $\pmb { \epsilon } _ { t } ^ { \prime }$ . If the common factors $\boldsymbol { f } _ { t }$ are observed, then Eq. (9.4) is a special form of the multivariate linear regression (MLR) model; see Johnson and Wichern (2002). For a general MLR model, the covariance matrix of $\epsilon _ { t }$ need not be diagonal.

# 9.2 MACROECONOMETRIC FACTOR MODELS

For macroeconomic factor models, the factors are observed and we can apply the least squares method to the MLR model in Eq. (9.4) to perform estimation. The estimate is

$$
\widehat {\boldsymbol {\xi} ^ {\prime}} = \left[ \begin{array}{c} \widehat {\alpha} ^ {\prime} \\ \widehat {\beta} ^ {\prime} \end{array} \right] = (\boldsymbol {G} ^ {\prime} \boldsymbol {G}) ^ {- 1} (\boldsymbol {G} ^ {\prime} \boldsymbol {R}),
$$

from which the estimates of $\pmb { \alpha }$ and $\beta$ are readily available. The residuals of Eq. (9.4) are

$$
\widehat {E} = R - G \widehat {\xi^ {\prime}}.
$$

Based on the model assumption, the covariance matrix of $\epsilon _ { t }$ is estimated by

$$
\widehat {\boldsymbol {D}} = \operatorname {d i a g} \left(\widehat {\boldsymbol {E}} ^ {\prime} \widehat {\boldsymbol {E}} / (T - m - 1)\right),
$$

where diag(A) means a diagonal matrix consisting of the diagonal elements of the matrix A. Furthermore, the R-square of the ith asset of Eq. (9.3) is

$$
\mathrm {R - s q u a r e} _ {i} = 1 - \frac {\left[ \widehat {\boldsymbol {E}} ^ {\prime} \widehat {\boldsymbol {E}} \right] _ {i , i}}{\left[ \boldsymbol {R} ^ {\prime} \boldsymbol {R} \right] _ {i , i}}, \quad i = 1, \dots , k,
$$

where $A _ { i , i }$ denotes the $( i , i )$ th element of the matrix $A$ .

Note that the prior estimation does not impose the constraint that the specific factors $\epsilon _ { i t }$ are uncorrelated with each other. Consequently, the estimates obtained are not efficient in general. However, imposing the orthogonalization constraint requires nontrivial computation and is often ignored. One can check the off-diagonal elements of the matrix $\widehat { \pmb { E } } ^ { \prime } \widehat { \pmb { E } } / ( T - m - 1 )$ to verify the adequacy of the fitted model.

# 9.2.1 A Single-Factor Model

The best known macroeconomic factor model in finance is the market model; see Sharpe (1970). This is a single-factor model and can be written as

$$
r _ {i t} = \alpha_ {i} + \beta_ {i} r _ {M t} + \epsilon_ {i t}, \quad i = 1, \dots , k; \quad t = 1, \dots , T, \tag {9.5}
$$

where $r _ { i t }$ is the excess return of the ith asset and $r _ { m t }$ is the excess return of the market. To illustrate, we consider monthly returns of 13 stocks and use the return of the S&P 500 index as the market return. The stocks used and their tick symbols are given in Table 9.1, and the sample period is from January 1990 to December 2003 so that $k = 1 3$ and $T = 1 6 8$ . We use the monthly series of three-month Treasury bill rates of the secondary market as the risk-free interest rate to obtain simple excess returns of the stock and market index. The returns are in percentages.

We use S-Plus to implement the estimation method discussed in the previous subsection. Most of the commands used apply to the free software R.

```txt
> da=matrix.scan(file='m-fac9003.txt'),14)
> x=t(da)
> xmlns=cbind(rep(1,168),x[,14])
> rtn=x[,1:13]
>xit.hat=solve(xmtx,rtn)
>beta.hat=t(xit.hat[2,])
> E.hat=rtn-xmtx%*%xit.hat
>D.hat=diag(crossprod(E.hat)/(168-2))
>r(square=1-(168-2)*D.hat/diag(var(rtn,Sum Squares=T)) 
```

Table 9.1. Stocks Used and Their Tick Symbols in the Analysis of a Single-Factor Modela   

<table><tr><td>Tick</td><td>Company</td><td>\(\overline{r}(\sigma_r)\)</td><td>Tick</td><td>Company</td><td>\(\overline{r}(\sigma_r)\)</td></tr><tr><td>AA</td><td>Alcoa</td><td>1.09(9.49)</td><td>KMB</td><td>Kimberly-Clark</td><td>0.78(6.50)</td></tr><tr><td>AGE</td><td>A.G. Edwards</td><td>1.36(10.2)</td><td>MEL</td><td>Mellon Financial</td><td>1.36(7.80)</td></tr><tr><td>CAT</td><td>Caterpillar</td><td>1.23(8.71)</td><td>NYT</td><td>New York Times</td><td>0.81(7.37)</td></tr><tr><td>F</td><td>Ford Motor</td><td>0.97(9.77)</td><td>PG</td><td>Procter &amp; Gamble</td><td>1.08(6.75)</td></tr><tr><td>FDX</td><td>FedEx</td><td>1.14(9.49)</td><td>TRB</td><td>Chicago Tribune</td><td>0.95(7.84)</td></tr><tr><td>GM</td><td>General Motors</td><td>0.64(9.28)</td><td>TXN</td><td>Texas Instrument</td><td>2.19(13.8)</td></tr><tr><td>HPQ</td><td>Hewlett-Packard</td><td>1.37(0.42)</td><td>SP5</td><td>S&amp;P 500 index</td><td>0.42(4.33)</td></tr></table>

aSample means (standard errors) of excess returns are also given. The sample period is from January 1990 to December 2003.

The estimates of $\beta _ { i }$ , $\sigma _ { i } ^ { 2 }$ , and $R ^ { 2 }$ for the $i$ th asset return are given below:

<table><tr><td colspan="4">&gt; t(rbind(beta.hat, sqrt(D.hat), r(square))</td></tr><tr><td></td><td>beta.hat</td><td>sigma(i)</td><td>r(square)</td></tr><tr><td>AA</td><td>1.292</td><td>7.694</td><td>0.347</td></tr><tr><td>AGE</td><td>1.514</td><td>7.808</td><td>0.415</td></tr><tr><td>CAT</td><td>0.941</td><td>7.725</td><td>0.219</td></tr><tr><td>F</td><td>1.219</td><td>8.241</td><td>0.292</td></tr><tr><td>FDX</td><td>0.805</td><td>8.854</td><td>0.135</td></tr><tr><td>GM</td><td>1.046</td><td>8.130</td><td>0.238</td></tr><tr><td>HPQ</td><td>1.628</td><td>9.469</td><td>0.358</td></tr><tr><td>KMB</td><td>0.550</td><td>6.070</td><td>0.134</td></tr><tr><td>MEL</td><td>1.123</td><td>6.120</td><td>0.388</td></tr><tr><td>NYT</td><td>0.771</td><td>6.590</td><td>0.205</td></tr><tr><td>PG</td><td>0.469</td><td>6.459</td><td>0.090</td></tr><tr><td>TRB</td><td>0.718</td><td>7.215</td><td>0.157</td></tr><tr><td>TXN</td><td>1.796</td><td>11.474</td><td>0.316</td></tr></table>

Figure 9.1 shows the bar plots of $\hat { \beta } _ { i }$ and $R ^ { 2 }$ of the 13 stocks. The financial stocks, AGE and MEL, and the high-tech stocks, HPQ and TXN, seem to have higher $\beta$ and $R ^ { 2 }$ . On the other hand, KMB and PG have lower $\beta$ and $R ^ { 2 }$ . The $R ^ { 2 }$ ranges from 0.09 to 0.41, indicating that the market return explains less than $50 \%$ of the variabilities of the individual stocks used.

The covariance and correlation matrices of $r _ { t }$ under the market model can be estimated using the following:

> cov. $\mathbf { \nabla } \mathbf { \mathbf { \mathbf { \mathbf { r } } } } =$ var(x[,14])*(t(beta.hat)%*%beta.hat)+diag(D.hat)   
> sd. $\mathbf { \nabla } \mathbf { \mathbf { \mathbf { \mathbf { r } } } } =$ sqrt(diag(cov.r))   
> corr. $\mathbf { \nabla } \mathbf { \mathbf { \mathbf { \mathbf { r } } } } =$ cov.r/outer(sd.r,sd.r)  
$>$ print(corr.r,digits $^ { = 1 }$ ,width $^ { - 2 }$ )

AA AGE CAT F FDX GM HPQ KMB MEL NYT PG TRB TXN AA 1.0 0.4 0.3 0.3 0.2 0.3 0.4 0.2 0.4 0.3 0.2 0.2 0.3

![](images/9fd8765f0c12d46dcdc475ad1c38eb93c334bd64653b6320934debe5d12b7442.jpg)

![](images/dc244f2291b3abd33736fc99dedcd82703417b23ce31964825ed1d788a7cb1fb.jpg)  
(b) R-square   
Figure 9.1. Bar plots of the (a) beta and (b) R-square for fitting a single-factor market model to the monthly excess returns of 13 stocks. The S&P 500 index excess return is used as the market index. The sample period is from January 1990 to December 2003.

<table><tr><td>AGE</td><td>0.4</td><td>1.0</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.2</td><td>0.4</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.4</td></tr><tr><td>CAT</td><td>0.3</td><td>0.3</td><td>1.0</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.3</td></tr><tr><td>F</td><td>0.3</td><td>0.3</td><td>0.3</td><td>1.0</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.3</td></tr><tr><td>FDX</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>1.0</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.1</td><td>0.2</td></tr><tr><td>GM</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>1.0</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.3</td></tr><tr><td>HPQ</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>1.0</td><td>0.2</td><td>0.4</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.3</td></tr><tr><td>KMB</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.2</td><td>1.0</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.1</td><td>0.2</td></tr><tr><td>MEL</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.2</td><td>1.0</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.3</td></tr><tr><td>NYT</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.3</td><td>1.0</td><td>0.1</td><td>0.2</td><td>0.3</td></tr><tr><td>PG</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.1</td><td>0.1</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.1</td><td>1.0</td><td>0.1</td><td>0.2</td></tr><tr><td>TRB</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.2</td><td>0.2</td><td>0.1</td><td>1.0</td><td>0.2</td></tr><tr><td>TXN</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.2</td><td>1.0</td></tr></table>

We can compare these estimated correlations with the sample correlations of the excess returns.

<table><tr><td colspan="14">&gt; print(cor(rtn),digits=1,height=2)</td></tr><tr><td></td><td>AA</td><td>AGE</td><td>CAT</td><td>F</td><td>FDX</td><td>GM</td><td>HPQ</td><td>KMB</td><td>MEL</td><td>NYT</td><td>PG</td><td>TRB</td><td>TXN</td></tr><tr><td>AA</td><td>1.0</td><td>0.3</td><td>0.6</td><td>0.5</td><td>0.2</td><td>0.4</td><td>0.5</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.1</td><td>0.3</td><td>0.5</td></tr><tr><td>AGE</td><td>0.3</td><td>1.0</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.2</td><td>0.2</td><td>0.3</td></tr><tr><td>CAT</td><td>0.6</td><td>0.3</td><td>1.0</td><td>0.4</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.1</td><td>0.4</td><td>0.3</td></tr><tr><td>F</td><td>0.5</td><td>0.3</td><td>0.4</td><td>1.0</td><td>0.3</td><td>0.6</td><td>0.3</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.1</td><td>0.3</td><td>0.3</td></tr><tr><td>FDX</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.3</td><td>1.0</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.1</td><td>0.3</td><td>0.2</td></tr><tr><td>GM</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.6</td><td>0.2</td><td>1.0</td><td>0.3</td><td>0.3</td><td>0.4</td><td>0.2</td><td>0.1</td><td>0.3</td><td>0.3</td></tr><tr><td>HPQ</td><td>0.5</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.3</td><td>1.0</td><td>0.1</td><td>0.3</td><td>0.3</td><td>0.1</td><td>0.2</td><td>0.6</td></tr><tr><td>KMB</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.1</td><td>1.0</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.1</td></tr><tr><td>MEL</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.2</td><td>0.4</td><td>0.3</td><td>0.4</td><td>1.0</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.3</td></tr><tr><td>NYT</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>0.3</td><td>1.0</td><td>0.2</td><td>0.5</td><td>0.2</td></tr><tr><td>PG</td><td>0.1</td><td>0.2</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.3</td><td>0.4</td><td>0.2</td><td>1.0</td><td>0.3</td><td>0.1</td></tr><tr><td>TRB</td><td>0.3</td><td>0.2</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.5</td><td>0.3</td><td>1.0</td><td>0.2</td></tr><tr><td>TXN</td><td>0.5</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.6</td><td>0.1</td><td>0.3</td><td>0.2</td><td>0.1</td><td>0.2</td><td>1.0</td></tr></table>

In finance, one can use the concept of the global minimum variance portfolio (GMVP) to compare the covariance matrix implied by a fitted factor model with the sample covariance matrix of the returns. For a given covariance matrix $\pmb { \Sigma }$ , the global minimum variance portfolio is the portfolio $\omega$ that solves

$$
\min  _ {\boldsymbol {\omega}} \sigma_ {p, \boldsymbol {\omega}} ^ {2} = \boldsymbol {\omega} ^ {\prime} \boldsymbol {\Sigma} \boldsymbol {\omega} \quad \text {s u c h t h a t} \quad \boldsymbol {\omega} ^ {\prime} \mathbf {1} = 1
$$

and is given by

$$
\omega = \frac {\boldsymbol {\Sigma} ^ {- 1} \mathbf {1}}{\mathbf {1} ^ {\prime} \boldsymbol {\Sigma} ^ {- 1} \mathbf {1}},
$$

where 1 is the $k$ -dimensional vector of ones.

For the market model considered, the GMVP for the fitted model and the data are as follows:

<table><tr><td colspan="7">&gt; w.gmin.model=solve Cov.r) %*%rep(1,nrow Cov.r)</td></tr><tr><td colspan="7">&gt; w.gmin.model=w.gmin.model/sum(w.gmin.model)</td></tr><tr><td colspan="7">&gt; t(w.gmin.model)</td></tr><tr><td></td><td>AA</td><td>AGE</td><td>CAT</td><td>F</td><td>FDX</td><td>GM</td></tr><tr><td>[1,]</td><td>0.0117</td><td>-0.0306</td><td>0.0792</td><td>0.0225</td><td>0.0802</td><td>0.0533</td></tr><tr><td></td><td>HPQ</td><td>KMB</td><td>MEL</td><td>NYT</td><td>PG</td><td>TRB</td></tr><tr><td>[1,]</td><td>-0.0354</td><td>0.2503</td><td>0.0703</td><td>0.1539</td><td>0.2434</td><td>0.1400</td></tr><tr><td colspan="7">&gt; w.gmin.data=solve(var(rtn)) %*%rep(1,nrow Cov.r))</td></tr><tr><td colspan="7">&gt; w.gmin.data=w.gmin.data/sum(w.gmin.data)</td></tr><tr><td colspan="7">&gt; t(w.gmin.data)</td></tr><tr><td></td><td>AA</td><td>AGE</td><td>CAT</td><td>F</td><td>FDX</td><td>GM</td></tr><tr><td>[1,]</td><td>-0.0073</td><td>-0.0085</td><td>0.0866</td><td>-0.0232</td><td>0.0943</td><td>0.0916</td></tr><tr><td></td><td>HPQ</td><td>KMB</td><td>MEL</td><td>NYT</td><td>PG</td><td>TRB</td></tr><tr><td>[1,]</td><td>0.0345</td><td>0.2296</td><td>0.0495</td><td>0.1790</td><td>0.2651</td><td>0.0168</td></tr></table>

Comparing the two GMVPs, the weights assigned to TRB stock differ markedly. The two portfolios, however, have larger weights for KMB, NYT, and PG stocks.

Finally, we examine the residual covariance and correlation matrices to verify the assumption that the special factors are not correlated among the 13 stocks. The first four columns of the residual correlation matrix are given below and there exist some large values in the residual cross-correlations, for example, $\mathrm { C o r } ( \mathrm { C A T } , \mathrm { A A } ) = 0 . 4 5$ and $\mathrm { C o r } ( \mathrm { G M } , \mathrm { F } ) = 0 . 4 8$ .

```lisp
> resi.cov = t(E.hat) %**E.hat/(168-2)
> resi.sd = sqrt(diag(resi.cov)) 
```

```txt
> resi.cor=resi.cov/outer(resi.sd,resi.sd)  
> print(resi.cor,digits=1, width=2)  
AA AGE CAT F  
AA 1.00 -0.13 0.45 0.22  
AGE -0.13 1.00 -0.03 -0.01  
CAT 0.45 -0.03 1.00 0.23  
F 0.22 -0.01 0.23 1.00  
FDX 0.00 0.14 0.05 0.07  
GM 0.14 -0.09 0.15 0.48  
HPQ 0.24 -0.13 -0.07 -0.00  
KMB 0.16 0.06 0.18 0.05  
MEL -0.02 0.06 0.09 0.10  
NYT 0.13 0.10 0.07 0.19  
PG -0.15 -0.02 -0.01 -0.07  
TRB 0.12 -0.02 0.25 0.16  
TXN 0.19 -0.17 0.09 -0.02
```

# 9.2.2 Multifactor Models

Chen, Roll, and Ross (1986) consider a multifactor model for stock returns. The factors used consist of unexpected changes or surprises of macroeconomic variables. Here unexpected changes denote the residuals of the macroeconomic variables after removing their dynamic dependence. A simple way to obtain unexpected changes is to fit a VAR model of Chapter 8 to the macroeconomic variables. For illustration, we consider the following two monthly macroeconomic variables:

1. Consumer price index (CPI) for all urban consumers: all items and with index $1 9 8 2 - 1 9 8 4 = 1 0 0$ .   
2. Civilian employment numbers 16 years and over (CE16): measured in thousands.

Both CPI and CE16 series are seasonally adjusted, and the data span is from January 1975 to December 2003. We use a longer period to obtain the surprise series of the variables. For both series, we construct the growth rate series by taking the first difference of the logged data. The growth rates are in percentages.

To obtain the surprise series, we use the BIC criterion to identify a VAR(3) model. Thus, the two macroeconomic factors used in the factor model are the residuals of a VAR(3) model from 1990 to 2003. For the excess returns, we use the same 13 stocks as before. Details of the analysis are given below:

```txt
> da=matrix.scan(file='m-cpice16-dp7503.txt'),2)
> cpi=da[1,]
> cen=da[2,]
> x1=cbind(cpi,cen)
> y1=data.frame(x1)
> ord.choice=VAR(y1,max.ar=13)
> ord.choice$info 
```

```txt
ar(1) ar(2) ar(3) ar(4) ar(5) ar(6)  
BIC 36.992 38.093 28.234 46.241 60.677 75.810  
ar(7) ar(8) ar(9) ar(10) ar(11) ar(12) ar(13)  
BIC 86.23 99.294 111.27 125.46 138.01 146.71 166.92  
> var3.fit=VAR(x1~ar(3))  
> res=var3.fit\\(residuals[166:333,1:2]  
> da=matrix.scan(file='m-fac9003.txt'),14)  
> xmtx = cbind(rep(1,168),res)  
> da=t(da)  
> rtn=da[,1:13]  
>xit.hat=solve(xmtx,rtn)  
>beta.hat=t(xit.hat[2:3,])  
>E.hat=rtn - xmtx%*%xit.hat  
>D.hat=diag(crossprod(E.hat)/(168-3))  
>R(square=1-(168-3)*D.hat/diag(var(rtn,SumSquares=T)) 
```

Figure 9.2 shows the bar plots of the beta estimates and $R ^ { 2 }$ for the 13 stocks. It is interesting to see that all excess returns are negatively related to the unexpected changes of CPI growth rate. This seems reasonable. However, the $R ^ { 2 }$ of all excess

![](images/fb46915c4c49e88f0fcac8a0b78af0f80a928d49223e57394a9bf0b639eff9bc.jpg)  
Figure 9.2. Bar plots of the betas and R-square for fitting a two-factor model to the monthly excess returns of 13 stocks. The sample period is from January 1990 to December 2003.

returns are low, indicating that the two macroeconomic variables used have very little explanatory power in understanding the excess returns of the 13 stocks.

The estimated covariance and correlation matrices of the two-factor model can be obtained using the following:

> cov.rtn $. =$ beta.hat%*%var(res)%*%t(beta.hat)+diag(D.hat)   
$>$ sd.rtn $. =$ sqrt(diag(cov.rtn))   
$>$ cor.rtn $=$ cov.rtn/outer(sd.rtn,sd.rtn)  
$>$ print(cor.rtn,diits $^ { = 1 }$ ,width $^ { - 2 }$ )

The correlation matrix is very close to the identity matrix, indicating that the twofactor model used does not fit the excess returns well. Finally, the correlation matrix of the residuals of the two-factor model is given by the following:

> cov.resi=t(E.hat)%*%E.hat/(168-3)   
$>$ sd.resi $=$ sqrt(diag(cov.resi))   
$>$ cor.resi $=$ cov.resi/outer(sd.resi,sd.resi)   
$>$ print(cor.resi,digits $^ { = 1 }$ ,width $^ { - 2 }$

As expected, this correlation matrix is close to that of the original excess returns given before and is omitted.

# 9.3 FUNDAMENTAL FACTOR MODELS

Fundamental factor models use observable asset specific fundamentals such as industrial classification, market capitalization, book value, and style classification (growth or value) to construct common factors that explain the excess returns. There are two approaches to fundamental factor models available in the literature. The first approach is proposed by Bar Rosenberg, founder of BARRA Inc., and is referred to as the BARRA approach; see Grinold and Kahn (2000). In contrast to the macroeconomic factor models, this approach treats the observed asset specific fundamentals as the factor betas, $\beta _ { i }$ , and estimates the factors $\boldsymbol { f } _ { t }$ at each time index $t$ via regression methods. The betas are time-invariant, but the realizations $\boldsymbol { f } _ { t }$ evolve over time. The second approach is the Fama–French approach proposed by Fama and French (1992). In this approach, the factor realization $f _ { j t }$ for a given specific fundamental is obtained by constructing some hedge portfolio based on the observed fundamental. We briefly discuss the two approaches in the next two subsections.

# 9.3.1 BARRA Factor Model

Assume that the excess returns and, hence, the factor realizations are meancorrected. At each time index $t$ , the factor model in Eq. (9.2) reduces to

$$
\tilde {\boldsymbol {r}} _ {t} = \boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t}, \tag {9.6}
$$

where $\tilde { \boldsymbol { r } } _ { t }$ denotes the (sample) mean-corrected excess returns and, for simplicity in notation, we continue to use $\boldsymbol { f } _ { t }$ as factor realizations. Since $\beta$ is given, the model in Eq. (9.6) is a multiple linear regression with $k$ observations and $m$ unknowns. Because the number of common factors $m$ should be less than the number of assets $k$ , the regression is estimable. However, the regression is not homogeneous because the covariance matrix of $\epsilon _ { t }$ is $\pmb { { \cal D } } = \mathrm { d i a g } \{ \sigma _ { 1 } ^ { 2 } , \dots , \sigma _ { k } ^ { 2 } \}$ with $\sigma _ { i } ^ { 2 } = \mathrm { V a r } ( \epsilon _ { i t } )$ , which depends on the ith asset. Consequently, the factor realization at time index $t$ can be estimated by the weighted least squares (WLS) method using the standard errors of the specific factors as the weights. The resulting estimate is

$$
\widehat {\boldsymbol {f}} _ {t} = \left(\boldsymbol {\beta} \boldsymbol {D} ^ {- 1} \boldsymbol {\beta} ^ {\prime}\right) ^ {- 1} \left(\boldsymbol {\beta} \boldsymbol {D} ^ {- 1} \boldsymbol {\beta} ^ {\prime} \tilde {\boldsymbol {r}} _ {t}\right). \tag {9.7}
$$

In practice, the covariance matrix $\pmb { D }$ is unknown so that we use a two-step procedure to perform the estimation.

In step one, the ordinary least squares (OLS) method is used at each time index $t$ to obtain a preliminary estimate of $\boldsymbol { f } _ { t }$ as

$$
\widehat {\boldsymbol {f}} _ {t, o} = \left(\boldsymbol {\beta} ^ {\prime} \boldsymbol {\beta}\right) ^ {- 1} \left(\boldsymbol {\beta} ^ {\prime} \tilde {\boldsymbol {r}} _ {t}\right),
$$

where the second subscript $o$ is used to denote the OLS estimate. This estimate of factor realization is consistent, but not efficient. The residual of the OLS regression is

$$
\boldsymbol {\epsilon} _ {t, o} = \tilde {\boldsymbol {r}} _ {t} - \beta \widehat {\boldsymbol {f}} _ {t, o}.
$$

Since the residual covariance matrix is time-invariant, we can pool the residuals together (for $t = 1 , \dots , T$ ) to obtain an estimate of $\pmb { D }$ as

$$
\widehat {\boldsymbol {D}} _ {o} = \operatorname {d i a g} \left\{\frac {1}{T - 1} \sum_ {t = 1} ^ {T} \left(\boldsymbol {\epsilon} _ {t, o} \boldsymbol {\epsilon} _ {t, o} ^ {\prime}\right) \right\}.
$$

In step two, we plug in the estimate $\widehat { \pmb { D } } _ { o }$ to obtain a refined estimate of the factor realization

$$
\widehat {\boldsymbol {f}} _ {t, g} = \left(\boldsymbol {\beta} ^ {\prime} \widehat {\boldsymbol {D}} _ {o} ^ {- 1} \boldsymbol {\beta}\right) ^ {- 1} \left(\boldsymbol {\beta} ^ {\prime} \widehat {\boldsymbol {D}} _ {o} ^ {- 1} \boldsymbol {\beta} \tilde {\boldsymbol {r}} _ {t}\right), \tag {9.8}
$$

where the second subscript $g$ denotes the generalized least squares (GLS) estimate, which is a sample version of the WLS estimate. The residual of the refined regression is

$$
\boldsymbol {\epsilon} _ {t, g} = \tilde {\boldsymbol {r}} _ {t} - \boldsymbol {\beta} \widehat {\boldsymbol {f}} _ {t, g},
$$

from which we estimate the residual variance matrix as

$$
\widehat {\boldsymbol {D}} _ {g} = \operatorname {d i a g} \left\{\frac {1}{T - 1} \sum_ {t = 1} ^ {T} \left(\boldsymbol {\epsilon} _ {t, g} \boldsymbol {\epsilon} _ {t, g} ^ {\prime}\right) \right\}.
$$

Finally, the covariance matrix of the estimated factor realizations is

$$
\widehat {\pmb {\Sigma}} _ {f} = \frac {1}{T - 1} \sum_ {t = 1} ^ {T} (\widehat {\pmb {f}} _ {t, g} - \overline {{\pmb {f}}} _ {g}) (\widehat {\pmb {f}} _ {t, g} - \overline {{\pmb {f}}} _ {g}) ^ {\prime},
$$

where

$$
\overline {{f}} _ {g} = \frac {1}{T} \sum_ {t = 1} ^ {T} \widehat {\boldsymbol {f}} _ {t, g}.
$$

From Eq. (9.6), the covariance matrix of the excess returns under the BARRA approach is

$$
\operatorname {C o v} \left(\boldsymbol {r} _ {t}\right) = \boldsymbol {\beta} \widehat {\boldsymbol {\Sigma}} _ {f} \boldsymbol {\beta} ^ {\prime} + \widehat {\boldsymbol {D}} _ {g}.
$$

# Industry Factor Model

For illustration, we consider monthly excess returns of ten stocks and use industrial classification as the specific asset fundamental. The stocks used are given in Table 9.2 and can be classified into three industrial sectors—namely, financial services, computer and high-tech industry, and other. The sample period is again from January 1990 to December 2003. Under the BARRA framework, there are three common factors representing the three industrial sectors and the betas are indicators for the three industrial sectors; that is,

$$
\tilde {r} _ {i t} = \beta_ {i 1} f _ {1 t} + \beta_ {i 2} f _ {2 t} + \beta_ {i 3} f _ {3 t} + \epsilon_ {i t}, \quad i = 1, \dots , 1 0, \tag {9.9}
$$

with the betas being

$$
\beta_ {i j} = \left\{ \begin{array}{l l} 1 & \text {i f a s s e t} i \text {b e l o n g s t o t h e} j \text {i n d u s t r i a l s e c t o r ,} \\ 0 & \text {o t h e r w i s e ,} \end{array} \right. \tag {9.10}
$$

Table 9.2. Stocks Used and Their Tick Symbols in the Analysis of Industrial Factor Modela   

<table><tr><td>Tick</td><td>Company</td><td>r(σr)</td><td>Tick</td><td>Company</td><td>r(σr)</td></tr><tr><td>AGE</td><td>A.G. Edwards</td><td>1.36(10.2)</td><td rowspan="2">IBM</td><td rowspan="2">International Business Machines</td><td rowspan="2">1.06(9.47)</td></tr><tr><td>C</td><td>Citigroup</td><td>2.08(9.60)</td></tr><tr><td>MWD</td><td>Morgan Stanley</td><td>1.87(11.2)</td><td>AA</td><td>Alcoa</td><td>1.09(9.49)</td></tr><tr><td>MER</td><td>Merrill Lynch</td><td>2.08(10.4)</td><td>CAT</td><td>Caterpillar</td><td>1.23(8.71)</td></tr><tr><td>DELL</td><td>Dell Inc.</td><td>4.82(16.4)</td><td>PG</td><td>Procter &amp; Gamble</td><td>1.08(6.75)</td></tr><tr><td>HPQ</td><td>Hewlett-Packard</td><td>1.37(11.8)</td><td></td><td></td><td></td></tr></table>

aSample mean and standard deviation of the excess returns are also given. The sample span is from January 1990 to December 2003.

where $j = 1 , 2 , 3$ representing the financial, high-tech, and other sector, respectively. For instance, the beta vector for the IBM stock return is $\pmb { \beta } _ { i } = ( 0 , 1 , 0 ) ^ { \prime }$ and that for Alcoa stock return is $\pmb { \beta } _ { i } = ( 0 , 0 , 1 ) ^ { \prime }$ .

In Eq. (9.9), $f _ { 1 t }$ is the factor realization of the financial services sector, $f _ { 2 t }$ is that of the computer and high-tech sector, and $f _ { 3 t }$ is for the other sector. Because the $\beta _ { i j }$ are indicator variables, the OLS estimate of $\boldsymbol { f } _ { t }$ is extremely simple. Indeed, $\boldsymbol { f } _ { t }$ is the vector consisting of the averages of sector excess returns at time t. Specifically,

$$
\widehat {\boldsymbol {f}} _ {t, o} = \left[ \begin{array}{c} \frac {\mathrm {A G E} _ {t} + \mathrm {C} _ {t} + \mathrm {M D W} _ {t} + \mathrm {M E R} _ {t}}{4} \\ \frac {\mathrm {D E L L} _ {t} + \mathrm {H P Q} _ {t} + \mathrm {I B M} _ {t}}{3} \\ \frac {\mathrm {A A} _ {t} + \mathrm {C A T} _ {t} + \mathrm {P G} _ {t}}{3} \end{array} \right].
$$

The specific factor of the ith asset is simply the deviation of its excess return from its industrial sample average. One can then obtain an estimate of the residual variance matrix $\pmb { D }$ to perform the generalized least squares estimation. We use S-Plus to perform the analysis. First, load the returns into S-Plus, remove the sample means, create the industrial dummies, and compute the sample correlation matrix of the returns.

> da=matrix(scan(file=’m-barra-9003.txt’),10)   
> rm $=$ matrix(rowMeans(da),1)   
> rtn.rm $=$ da - t(rm)%*%rep(1,168)   
> fin = c(rep(1,4),rep(0,6))   
> tech $=$ c(rep(0,4),rep(1,3),rep(0,3)   
> oth = c(rep(0,7),rep(1,3))   
> ind.dum $=$ cbind(fin,tech,oth)   
> ind.dum

fin tech oth

[1,] 1 0 0   
[2,] 1 0 0   
[3,] 1 0 0   
[4,] 1 0 0   
[5,] 0 1 0   
[6,] 0 1 0   
[7,] 0 1 0   
[8,] 0 0 1   
[9,] 0 0 1

[10,] 0 0 1

> rtn=t(rtn.rm)   
> cov.rtn $=$ var(rtn)   
> sd.rtn $=$ sqrt(diag(cov.rtn))   
> corr.rtn $. =$ cov.rtn/outer(sd.rtn,sd.rtn)  
$>$ print(corr.rtn,digits $^ { = 1 }$ ,width $^ { - 2 }$ )

<table><tr><td></td><td>AGE</td><td>C</td><td>MWD</td><td>MER</td><td>DELL</td><td>HPQ</td><td>IBM</td><td>AA</td><td>CAT</td><td>PG</td></tr><tr><td>AGE</td><td>1.0</td><td>0.6</td><td>0.6</td><td>0.6</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td></tr><tr><td>C</td><td>0.6</td><td>1.0</td><td>0.7</td><td>0.7</td><td>0.2</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.3</td></tr><tr><td>MWD</td><td>0.6</td><td>0.7</td><td>1.0</td><td>0.8</td><td>0.3</td><td>0.5</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.3</td></tr><tr><td>MER</td><td>0.6</td><td>0.7</td><td>0.8</td><td>1.0</td><td>0.2</td><td>0.5</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.3</td></tr><tr><td>DELL</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.2</td><td>1.0</td><td>0.5</td><td>0.4</td><td>0.3</td><td>0.1</td><td>0.1</td></tr><tr><td>HPQ</td><td>0.3</td><td>0.4</td><td>0.5</td><td>0.5</td><td>0.4</td><td>1.0</td><td>0.5</td><td>0.5</td><td>0.2</td><td>0.1</td></tr><tr><td>IBM</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.4</td><td>0.5</td><td>1.0</td><td>0.4</td><td colspan="2">0.3-0.0</td></tr><tr><td>AA</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.5</td><td>0.4</td><td>1.0</td><td>0.6</td><td>0.1</td></tr><tr><td>CAT</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.1</td><td>0.2</td><td>0.3</td><td>0.6</td><td>1.0</td><td>0.1</td></tr><tr><td>PG</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.1</td><td>0.1-0.0</td><td>0.1</td><td>0.1</td><td>0.1</td><td>1.0</td></tr></table>

The OLS estimates, their residuals, and residual variances are estimated as below:

```txt
> F.hat.o = solve(crossprod(ind.dum))%%t(ind.dum)%%rtn.rm  
> E.hat.o = rtn.rm - ind.dum%%F.hat.o  
> diagD.hat.o=rowVars(E.hat.o) 
```

One can then obtain the generalized least squares estimates.

```txt
> Dinv.hat = diag(diagD.hat.o^(-1))  
> H1 = t(ind.dum)%*%Dinv.hat%*%ind.dum  
> Hmtx=solve(H1)%*%t(ind.dum)%*%Dinv.hat  
> F.hat.g = Hmtx%*%rtn.rm  
> F.hat.gt=t(F.hat.g)  
> E.hat.g = rtn.rm - ind.dum%*%F.hat.g  
> diagD.hat.g = rowVars(E.hat.g)  
> t(Hmtx)  
fin tech oth  
[1,] 0.1870 0.0000 0.0000  
[2,] 0.2548 0.0000 0.0000  
[3,] 0.2586 0.0000 0.0000  
[4,] 0.2995 0.0000 0.0000  
[5,] 0.0000 0.2272 0.0000  
[6,] 0.0000 0.4015 0.0000  
[7,] 0.0000 0.3713 0.0000  
[8,] 0.0000 0.0000 0.3319  
[9,] 0.0000 0.0000 0.4321  
[10,] 0.0000 0.0000 0.2360  
> cov.ind=ind.dum%*%var(F.hat.gt)%*%t(ind.dum) +  
+ diag(diagD.hat.g)  
> sd.ind=sqrt(diag(cov.ind))  
> corr.ind=cov.ind/outer(sd.ind, sd.ind)  
> print(corr.ind,digits=1,height=2)  
AGE C MWD MER DELL HPQ IBM AA CAT PG  
AGE 1.0 0.7 0.7 0.7 0.3 0.3 0.3 0.3 3  
C 0.7 1.0 0.8 0.8 0.3 0.4 0.4 0.3 3 3  
MWD 0.7 0.8 1.0 0.8 0.3 0.4 0.4 3 3 
```

<table><tr><td>MER</td><td>0.7</td><td>0.8</td><td>0.8</td><td>1.0</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.3</td><td>0.4</td><td>0.3</td></tr><tr><td>DELL</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>1.0</td><td>0.5</td><td>0.5</td><td>0.2</td><td>0.2</td><td>0.2</td></tr><tr><td>HPQ</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.5</td><td>1.0</td><td>0.7</td><td>0.3</td><td>0.3</td><td>0.2</td></tr><tr><td>IBM</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.5</td><td>0.7</td><td>1.0</td><td>0.3</td><td>0.3</td><td>0.2</td></tr><tr><td>AA</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.3</td><td>0.3</td><td>1.0</td><td>0.7</td><td>0.5</td></tr><tr><td>CAT</td><td>0.3</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.7</td><td>1.0</td><td>0.6</td></tr><tr><td>PG</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.5</td><td>0.6</td><td>1.0</td></tr></table>

The model-based correlations of stocks within an industrial sector are larger than their sample counterparts. For instance, the sample correlation between CAT and PG stock returns is only 0.1, but the correlation based on the fitted model is 0.6. Finally, Figure 9.3 shows the time plots of the factor realizations based on the generalized least squares estimation.

# Factor Mimicking Portfolio

Consider the special case of BARRA factor models with a single factor. Here the WLS estimate of $f _ { t }$ in Eq. (9.7) has a nice interpretation. Consider a portfolio

![](images/445fc0d1928047217b7c1bcc64c276be2a174283782191d99cbd6f9a066ea82f.jpg)

![](images/2b056fb655458aa3f1f1c6ed58a1aeb53c92ee801411ce81629a897d8f3d2a3c.jpg)  
(b) High-tech sector

![](images/cd090f243c0881015c4b9617d4106317343e153a6a2acbb0ac8c94d3d693edd5.jpg)  
(c) Other sector   
Figure 9.3. Estimated factor realizations of a BARRA industrial factor model for 10 monthly stock returns in three industrial sectors.

$\pmb { \omega } = ( \omega _ { 1 } , \ldots , \omega _ { k } ) ^ { \prime }$ of the $k$ assets that solves

$$
\min  _ {\boldsymbol {\omega}} \left(\frac {1}{2} \boldsymbol {\omega} ^ {\prime} D \boldsymbol {\omega}\right) \quad \text {s u c h t h a t} \quad \boldsymbol {\omega} ^ {\prime} \boldsymbol {\beta} = 1.
$$

It turns out that the solution to this portfolio problem is given by

$$
\omega^ {\prime} = (\boldsymbol {\beta} ^ {\prime} \boldsymbol {D} ^ {- 1} \boldsymbol {\beta}) ^ {- 1} (\boldsymbol {\beta} ^ {\prime} \boldsymbol {D} ^ {- 1}).
$$

Thus, the estimated factor realization is the portfolio return

$$
\hat {f} _ {t} = \omega^ {\prime} r _ {t}.
$$

If the portfolio $\omega$ is normalized such that $\textstyle \sum _ { i = 1 } ^ { k } \omega _ { i } = 1$ , it is referred to as a factor mimicking portfolio. For multiple factors, one can apply the idea to each factor individually.

Remark. In practice, the sample mean of an excess return is often not significantly different from zero. Thus, one may not need to remove the sample mean before fitting a BARRA factor model. 

# 9.3.2 Fama–French Approach

For a given asset fundamental (e.g., ratio of book-to-market value), Fama and French (1992) determined factor realizations using a two-step procedure. First, they sorted the assets based on the values of the observed fundamental. Then they formed a hedge portfolio which is long in the top quintile (1/3) of the sorted assets and short in the bottom quintile of the sorted assets. The observed return on this hedge portfolio at time $t$ is the observed factor realization for the given asset fundamental. The procedure is repeated for each asset fundamental under consideration. Finally, given the observed factor realizations $\{ f _ { t } | t = 1 , \ldots , T \}$ , the betas for each asset are estimated using a time series regression method. These authors identify three observed fundamentals that explain high percentages of variability in excess returns. The three fundamentals used by Fama and French are (a) the overall market return (market excess return), (b) the performance of small stocks relative to large stocks (SMB, small minus big), and (c) the performance of value stocks relative to growth stocks (HML, high minus low). The size sorted by market equity and the ratio of book equity to market equity is used to define value and growth stocks with value stocks having high book equity to market equity ratio.

Remark. The concepts of factor may differ between factor models. The three factors used in the Fama–French approach are three financial fundamentals. One can combine the fundamentals to create a new attribute of the stocks and refer to the resulting model as a single-factor model. This is particularly so because the model used is a linear statistical model. Thus, care needs to be exercised when one refers to the number of factors in a factor model. On the other hand, the number of factors is more well defined in statistical factor models, which we discuss next. 

# 9.4 PRINCIPAL COMPONENT ANALYSIS

An important topic in multivariate time series analysis is the study of the covariance (or correlation) structure of the series. For example, the covariance structure of a vector return series plays an important role in portfolio selection. In what follows, we discuss some statistical methods useful in studying the covariance structure of a vector time series.

Given a $k$ -dimensional random variable $\pmb { r } = ( r _ { 1 } , \ldots , r _ { k } ) ^ { \prime }$ with covariance matrix $\pmb { \Sigma } _ { r }$ , a principal component analysis (PCA) is concerned with using a few linear combinations of $r _ { i }$ to explain the structure of $\pmb { \Sigma } _ { r }$ . If $r$ denotes the monthly log returns of $k$ assets, then PCA can be used to study the source of variations of these $k$ asset returns. Here the keyword is few so that simplification can be achieved in multivariate analysis.

# 9.4.1 Theory of PCA

PCA applies to either the covariance matrix $\pmb { \Sigma } _ { r }$ or the correlation matrix ${ \pmb \rho } _ { r }$ of $r$ . Since the correlation matrix is the covariance matrix of the standardized random vector $r ^ { * } = S ^ { - 1 } r$ , where $s$ is the diagonal matrix of standard deviations of the components of $r$ , we use covariance matrix in our theoretical discussion. Let ${ \boldsymbol { w } } _ { i } =$ $( w _ { i 1 } , \ldots , w _ { i k } ) ^ { \prime }$ be a $k$ -dimensional vector, where $i = 1 , \ldots , k$ . Then

$$
y _ {i} = \boldsymbol {w} _ {i} ^ {\prime} \boldsymbol {r} = \sum_ {j = 1} ^ {k} w _ {i j} r _ {j}
$$

is a linear combination of the random vector $r$ . If $r$ consists of the simple returns of $k$ stocks, then $y _ { i }$ is the return of a portfolio that assigns weight $w _ { i j }$ to the $j$ th stock. Since multiplying a constant to ${ \pmb w } _ { i }$ does not affect the proportion of allocation assigned to the $j$ th stock, we standardize the vector ${ \pmb w } _ { i }$ so that ${ \pmb w } _ { i } ^ { \prime } { \pmb w } _ { i } =$ $\textstyle \sum _ { j = 1 } ^ { k } w _ { i j } ^ { 2 } = 1$ .

Using properties of a linear combination of random variables, we have

$$
\operatorname {V a r} \left(y _ {i}\right) = \boldsymbol {w} _ {i} ^ {\prime} \boldsymbol {\Sigma} _ {r} \boldsymbol {w} _ {i}, \quad i = 1, \dots , k, \tag {9.11}
$$

$$
\operatorname {C o v} \left(y _ {i}, y _ {j}\right) = \boldsymbol {w} _ {i} ^ {\prime} \boldsymbol {\Sigma} _ {r} \boldsymbol {w} _ {j}, \quad i, j = 1, \dots , k. \tag {9.12}
$$

The idea of PCA is to find linear combinations ${ \pmb w } _ { i }$ such that $y _ { i }$ and $y _ { j }$ are uncorrelated for $i \neq j$ and the variances of $y _ { i }$ are as large as possible. More specifically:

1. The first principal component of $r$ is the linear combination $y _ { 1 } = { \pmb w } _ { 1 } ^ { \prime } r$ that maximizes $\mathrm { V a r } ( y _ { 1 } )$ subject to the constraint $\pmb { w } _ { 1 } ^ { \prime } \pmb { w } _ { 1 } = 1$ .   
2. The second principal component of $r$ is the linear combination $y _ { 2 } = w _ { 2 } ^ { \prime } r$ that maximizes $\mathrm { V a r } ( y _ { 2 } )$ subject to the constraints $\pmb { w } _ { 2 } ^ { \prime } \pmb { w } _ { 2 } = 1$ and $\mathrm { C o v } ( y _ { 2 } , y _ { 1 } ) = 0$ .

3. The ith principal component of $r$ is the linear combination $y _ { i } = { \pmb w } _ { i } ^ { \prime } r$ that maximizes $\mathrm { V a r } ( y _ { i } )$ subject to the constraints ${ \pmb w } _ { i } ^ { \prime } { \pmb w } _ { i } = 1$ and $\mathrm { C o v } ( y _ { i } , y _ { j } ) = 0$ for $j = 1 , \ldots , i - 1$ .

Since the covariance matrix $\pmb { \Sigma } _ { r }$ is non-negative definite, it has a spectral decomposition; see Appendix A of Chapter 8. Let $( \lambda _ { 1 } , e _ { 1 } )$ , . . . , $( \lambda _ { k } , e _ { k } )$ be the eigenvalue–eigenvector pairs of $\pmb { \Sigma } _ { r }$ , where $\lambda _ { 1 } \geq \lambda _ { 2 } \geq \cdot \cdot \cdot \geq \lambda _ { k } \geq 0 .$ . We have the following statistical result.

Result 9.1. The ith principal component of $r$ is $\begin{array} { r } { y _ { i } = e _ { i } ^ { \prime } r = \sum _ { j = 1 } ^ { k } e _ { i j } r _ { j } } \end{array}$ for $i = 1 , \ldots , k$ . Moreover,

$$
\operatorname {V a r} \left(y _ {i}\right) = e _ {i} ^ {\prime} \boldsymbol {\Sigma} _ {r} e _ {i} = \lambda_ {i}, \quad i = 1, \dots , k,
$$

$$
\operatorname {C o v} \left(y _ {i}, y _ {j}\right) = \boldsymbol {e} _ {i} ^ {\prime} \boldsymbol {\Sigma} _ {r} \boldsymbol {e} _ {j} = 0, \quad i \neq j.
$$

If some eigenvalues $\lambda _ { i }$ are equal, the choices of the corresponding eigenvectors $e _ { i }$ and hence $y _ { i }$ are not unique. In addition, we have

$$
\sum_ {i = 1} ^ {k} \operatorname {V a r} \left(r _ {i}\right) = t r \left(\boldsymbol {\Sigma} _ {r}\right) = \sum_ {i = 1} ^ {k} \lambda_ {i} = \sum_ {i = 1} ^ {k} \operatorname {V a r} \left(y _ {i}\right). \tag {9.13}
$$

The result of Eq. (9.13) says that

$$
\frac {\operatorname {V a r} \left(y _ {i}\right)}{\sum_ {i = 1} ^ {k} \operatorname {V a r} \left(r _ {i}\right)} = \frac {\lambda_ {i}}{\lambda_ {1} + \cdots + \lambda_ {k}}.
$$

Consequently, the proportion of total variance in $r$ explained by the ith principal component is simply the ratio between the ith eigenvalue and the sum of all eigenvalues of ance explained $\pmb { \Sigma } _ { r }$ . One ca the first also compute the cumulati principal components (i.e., vari-). In $i$ $( \bar { \sum _ { j = 1 } ^ { i } \lambda _ { j } } ) / ( \sum _ { j = 1 } ^ { k } \lambda _ { j } )$ practice, one selects a small $i$ such that the prior cumulative proportion is large.

Since $t r ( \pmb { \rho } _ { r } ) = k$ , the proportion of variance explained by the ith principal component becomes $\lambda _ { i } / k$ when the correlation matrix is used to perform the PCA.

A by-product of the PCA is that a zero eigenvalue of $\pmb { \Sigma } _ { r }$ , or ${ \pmb \rho } _ { r }$ , indicates the existence of an exact linear relationship between the components of $r$ . For instance, if the smallest eigenvalue $\lambda _ { k } = 0$ , then by Result $9 . 1 \mathrm { V a r } ( y _ { k } ) = 0$ . Therefore, $y _ { k } =$ kj 1 ekj rj is a constant and there are only k − 1 random quantities in r. In this $\textstyle \sum _ { j = 1 } ^ { k } e _ { k j } r _ { j }$ $k - 1$ $r$ case, the dimension of $r$ can be reduced. For this reason, PCA has been used in the literature as a tool for dimension reduction.

# 9.4.2 Empirical PCA

In application, the covariance matrix $\pmb { \Sigma } _ { r }$ and the correlation matrix $\pmb { \rho } _ { r }$ of the return vector $r$ are unknown, but they can be estimated consistently by the sample

covariance and correlation matrices under some regularity conditions. Assuming that the returns are weakly stationary and the data consist of $\{ r _ { t } | t = 1 , \ldots , T \}$ , we have the following estimates:

$$
\widehat {\boldsymbol {\Sigma}} _ {r} \equiv [ \hat {\sigma} _ {i j, r} ] = \frac {1}{T - 1} \sum_ {t = 1} ^ {T} \left(\boldsymbol {r} _ {t} - \overline {{\boldsymbol {r}}}\right) \left(\boldsymbol {r} _ {t} - \overline {{\boldsymbol {r}}}\right) ^ {\prime}, \quad \overline {{\boldsymbol {r}}} = \frac {1}{T} \sum_ {t = 1} ^ {T} \boldsymbol {r} _ {t}, \tag {9.14}
$$

$$
\widehat {\rho} _ {r} = \widehat {S} ^ {- 1} \widehat {\Sigma} _ {r} \widehat {S} ^ {- 1}, \tag {9.15}
$$

where $\widehat { \mathbf { S } } = \mathrm { d i a g } \{ \sqrt { \hat { \sigma } _ { 1 1 , r } } , \ldots , \sqrt { \hat { \sigma } _ { k k , r } } \}$ is the diagonal matrix of sample standard errors of $r _ { t }$ . Methods to compute eigenvalues and eigenvectors of a symmetric matrix can then be used to perform the PCA. Most statistical packages now have the capability to perform principal component analysis. In S-Plus, the basic command of PCA is princomp, and in FinMetrics the command is mfactor.

Example 9.1. Consider the monthly log returns of International Business Machines, Hewlett-Packard, Intel Corporation, Merrill Lynch, and Morgan Stanley Dean Witter from January 1990 to December 1999. The returns are in percentages and include dividends. The data set has 120 observations. Figure 9.4 shows the time plots of these five monthly return series. As expected, returns of companies in the same industrial sector tend to exhibit similar patterns.

Denote the returns by $r ^ { \prime } =$ $\pmb { r } ^ { \prime } = ( \mathrm { I B M }$ , HPQ, INTC, MER, MWD). The sample mean vector of the returns is (1.47, 1.97, 3.05, 2.30, 2.36) and the sample covariance and correlation matrices are

$$
\widehat {\boldsymbol {\Sigma}} _ {r} = \left[ \begin{array}{c c c c c} 7 3. 1 0 & & & & \\ 3 6. 4 8 & 1 0 3. 6 0 & & & \\ 2 7. 0 8 & 4 8. 8 6 & 1 1 3. 9 6 & & \\ 1 6. 0 6 & 3 7. 5 9 & 2 7. 9 6 & 1 0 5. 5 6 & \\ 1 6. 3 3 & 4 0. 7 2 & 2 6. 8 6 & 8 5. 4 7 & 1 0 9. 9 1 \end{array} \right],
$$

$$
\widehat {\boldsymbol {\rho}} _ {r} = \left[ \begin{array}{c c c c c} 1. 0 0 & & & \\ 0. 4 2 & 1. 0 0 & & \\ 0. 3 0 & 0. 4 5 & 1. 0 0 & & \\ 0. 1 8 & 0. 3 6 & 0. 2 6 & 1. 0 0 & \\ 0. 1 8 & 0. 3 8 & 0. 2 4 & 0. 7 9 & 1. 0 0 \end{array} \right].
$$

Table 9.3 gives the results of PCA using both the covariance and correlation matrices. Also given are eigenvalues, eigenvectors, and proportions of variabilities explained by the principal components. Consider the correlation matrix and denote the sample eigenvalues and eigenvectors by $\hat { \lambda } _ { i }$ and $\widehat { \pmb { e } } _ { i }$ . We have

$$
\hat {\lambda} _ {1} = 2. 4 5 6, \quad \widehat {\boldsymbol {e}} _ {1} = (0. 3 4 2, 0. 4 7 4, 0. 3 8 7, 0. 5 0 3, 0. 5 0 5) ^ {\prime},
$$

$$
\hat {\lambda} _ {2} = 1. 1 4 5, \quad \widehat {\boldsymbol {e}} _ {2} = (0. 5 2 5, 0. 3 1 4, 0. 4 0 5, - 0. 4 8 1, - 0. 4 8 1) ^ {\prime}
$$

![](images/49d5e638467938ed0e8006d37310773299498e6d8f2382610f5c3b06177d09b8.jpg)

![](images/c6507210b3dcde655bfc686a1e73d3ddb45d1904d6fd8f15e02abbe0bc9eb61e.jpg)  
(b) HPQ

![](images/319a9c2ef7683c56b8ed9710c1e3146c707830b140cf9a2f6fa62fa5c68df83f.jpg)  
(c) INTC

![](images/699731078fd805be8a0fd732afb6b8dbabad1bdc6695a7d22463d8437739ee6c.jpg)  
(d) MER

![](images/eb40a8b3b5ea9ca31d3b73fb58cdc5d19ad83e96a025e21c1fec626ee8159191.jpg)  
(e) MWD  
Figure 9.4. Time plots of monthly log returns in percentages and including dividends for (a) International Business Machines, (b) Hewlett-Packard, (c) Intel, (d) Merrill Lynch, and (e) Morgan Stanley Dean Witter from January 1990 to December 1999.

for the first two principal components. These two components explain about $72 \%$ of the total variability of the data, and they have interesting interpretations. The first component is a roughly equally weighted linear combination of the stock returns. This component might represent the general movement of the stock market and hence is a market component. The second component represents the difference between the two industrial sectors—namely, technologies versus financial services. It might be an industrial component. Similar interpretations of principal components can also be found by using the covariance matrix of $r$ .

An informal but useful procedure to determine the number of principal components needed in an application is to examine the scree plot, which is the time plot of

Table 9.3. Results of Principal Component Analysisa for the Monthly Log Returns, Including Dividends, of Stocks of IBM, Hewlett-Packard, Intel, Merrill Lynch, and Morgan Stanley Dean Witter from January 1990 to December 1999   

<table><tr><td colspan="6">Using Sample Covariance Matrix</td></tr><tr><td>Eigenvalue</td><td>256.16</td><td>116.14</td><td>64.91</td><td>46.82</td><td>22.11</td></tr><tr><td>Proportion</td><td>0.506</td><td>0.229</td><td>0.128</td><td>0.093</td><td>0.044</td></tr><tr><td>Cumulative</td><td>0.506</td><td>0.736</td><td>0.864</td><td>0.956</td><td>1.000</td></tr><tr><td>Eigenvector</td><td>0.246</td><td>0.327</td><td>0.586</td><td>-0.700</td><td>0.018</td></tr><tr><td></td><td>0.461</td><td>0.360</td><td>0.428</td><td>0.687</td><td>-0.050</td></tr><tr><td></td><td>0.409</td><td>0.585</td><td>-0.683</td><td>-0.153</td><td>0.033</td></tr><tr><td></td><td>0.522</td><td>-0.452</td><td>-0.082</td><td>-0.115</td><td>-0.710</td></tr><tr><td></td><td>0.536</td><td>-0.467</td><td>-0.036</td><td>-0.042</td><td>0.701</td></tr><tr><td colspan="6">Using Sample Correlation Matrix</td></tr><tr><td>Eigenvalue</td><td>2.456</td><td>1.145</td><td>0.699</td><td>0.495</td><td>0.205</td></tr><tr><td>Proportion</td><td>0.491</td><td>0.229</td><td>0.140</td><td>0.099</td><td>0.041</td></tr><tr><td>Cumulative</td><td>0.491</td><td>0.720</td><td>0.860</td><td>0.959</td><td>1.000</td></tr><tr><td>Eigenvector</td><td>0.342</td><td>0.525</td><td>0.691</td><td>-0.362</td><td>-0.012</td></tr><tr><td></td><td>0.474</td><td>0.314</td><td>-0.043</td><td>0.820</td><td>0.050</td></tr><tr><td></td><td>0.387</td><td>0.405</td><td>-0.717</td><td>-0.414</td><td>-0.034</td></tr><tr><td></td><td>0.503</td><td>-0.481</td><td>0.052</td><td>-0.147</td><td>0.701</td></tr><tr><td></td><td>0.505</td><td>-0.481</td><td>0.071</td><td>-0.062</td><td>-0.711</td></tr></table>

aThe eigenvectors are in columns.

the eigenvalues $\hat { \lambda } _ { i }$ ordered from the largest to the smallest (i.e., a plot of $\hat { \lambda } _ { i }$ versus i). Figure 9.5a shows the scree plot for the five stock returns of Example 9.1. By looking for an elbow in the scree plot, indicating that the remaining eigenvalues are relatively small and all about the same size, one can determine the appropriate number of components. For both plots in Figure 9.5, two components appear to be appropriate. Finally, except for the case in which $\lambda _ { j } = 0$ for $j > i$ , selecting the first $i$ principal components only provides an approximation to the total variance of the data. If a small i can provide a good approximation, then the simplification becomes valuable.

Remark. I have extended the data of Example 9.1 to December 2003. The PCA results of the extended data provide essentially the same information as that shown in the text and, hence, are omitted. The S-Plus commands used to perform the PCA are given below. The S-Plus gives the square root of the eigenvalue and denotes it as standard deviation.

```txt
> da=matrix.scan(file='m-pca5c-9003.txt'),6)  
> rtn = t(da[1:5,])  
> pca.cov = princomp(rtn)  
> names(pca.cov) 
```

![](images/27bd241ca2d40bd4f2b1c7833fe7afdc7d7b8245766e0fa0e28708021e6faa17.jpg)  
(a) 5 stock returns

![](images/92b2f8492b1d48896a06513943d2ff5e75375790b79c83da11ea6a25d1ee14b0.jpg)  
(b) 5 bond index returns   
Figure 9.5. Scree plots for two 5-dimensional asset returns: (a) series of Example 9.1 and (b) bond index returns of Example 9.3.

> summary(pca.cov)   
$>$ pca.cov$loadings   
$>$ screeplot(pca.cov)

![](images/0ec3768aebaee9e471af82661d49a0259528461a9e5ba7f2f3fd0e462b0e6a1f.jpg)

# 9.5 STATISTICAL FACTOR ANALYSIS

We now turn to statistical factor analysis. One of the main difficulties in multivariate statistical analysis is the “curse of dimensionality.” In particular, the number of parameters of a parametric model often increase dramatically when the order of the model or the dimension of the time series is increased. Simplifying methods are often sought to overcome the curse of dimensionality. From an empirical viewpoint, multivariate data often exhibit similar patterns indicating the existence of common structure hidden in the data. Statistical factor analysis is one of those simplifying methods available in the literature. The aim of statistical factor analysis is to identify, from the observed data, a few factors that can account for most of the variations in the covariance or correlation matrix of the data.

Traditional statistical factor analysis assumes that the data have no serial correlations. This assumption is often violated by financial data taken with frequency less than or equal to a week. However, the assumption appears to be reasonable for asset returns with lower frequencies (e.g., monthly returns of stocks or market

indexes). If the assumption is violated, then one can use the parametric models discussed in this book to remove the linear dynamic dependence of the data and apply factor analysis to the residual series.

In what follows, we discuss statistical factor analysis based on the orthogonal factor model. Consider the return $\pmb { r } _ { t } = ( r _ { 1 t } , \ldots , r _ { k t } ) ^ { \prime }$ of $k$ assets at time period $t$ and assume that the return series $r _ { t }$ is weakly stationary with mean $\pmb { \mu }$ and covariance matrix $\pmb { \Sigma } _ { r }$ . The statistical factor model postulates that $r _ { t }$ is linearly dependent on a few unobservable random variables $\pmb { f } _ { t } = ( f _ { 1 t } , \ldots , f _ { m t } ) ^ { \prime }$ and $k$ additional noises $\pmb { \epsilon } _ { t } = ( \epsilon _ { 1 t } , \ldots , \epsilon _ { k t } ) ^ { \prime }$ . Here $m < k$ , $f _ { i t }$ are the common factors, and $\epsilon _ { i t }$ are the errors. Mathematically, the statistical factor model is also in the form of Eq. (9.1) except that the intercept $\pmb { \alpha }$ is replaced by the mean return $\pmb { \mu }$ . Thus, a statistical factor model is in the form

$$
\boldsymbol {r} _ {t} - \boldsymbol {\mu} = \boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t}, \tag {9.16}
$$

where $\pmb { \beta } = [ \beta _ { i j } ] _ { k \times m }$ is the matrix of factor loadings, $\beta _ { i j }$ is the loading of the ith variable on the $j$ th factor, and $\epsilon _ { i t }$ is the specific error of $r _ { i t }$ . A key feature of the statistical factor model is that the $m$ factors $f _ { i t }$ and the factor-loadings $\beta _ { i j }$ are unobservable. As such, Eq. (9.16) is not a multivariate linear regression model, even though it has a similar appearance. This special feature also distinguishes a statistical factor model from other factor models discussed earlier.

The factor model in Eq. (9.16) is an orthogonal factor model if it satisfies the following assumptions:

1. $E ( f _ { t } ) = \mathbf { 0 }$ and $\operatorname { C o v } ( f _ { t } ) = I _ { m }$ , the $m \times m$ identity matrix;   
2. $E ( \pmb { \epsilon } _ { t } ) = \mathbf { 0 }$ and $\mathrm { C o v } ( \epsilon _ { t } ) = D = { \mathrm { d i a g } } \{ \sigma _ { 1 } ^ { 2 } , \dots , \sigma _ { k } ^ { 2 } \}$ (i.e., $\pmb { D }$ is a $k \times k$ diagonal matrix); and   
3. $\boldsymbol { f } _ { t }$ and $\epsilon _ { t }$ are independent so that $\operatorname { C o v } ( \pmb { f } _ { t } , \pmb { \epsilon } _ { t } ) = E ( \pmb { f } _ { t } \pmb { \epsilon } _ { t } ^ { \prime } ) = \pmb { 0 } _ { m \times k } .$

Under the previous assumptions, it is easy to see that

$$
\begin{array}{l} \boldsymbol {\Sigma} _ {r} = \operatorname {C o v} (\boldsymbol {r} _ {t}) = E [ (\boldsymbol {r} _ {t} - \boldsymbol {\mu}) (\boldsymbol {r} _ {t} - \boldsymbol {\mu}) ^ {\prime} ] \\ = E \left[ \left(\boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t}\right) \left(\boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t}\right) ^ {\prime} \right] \\ = \boldsymbol {\beta} \boldsymbol {\beta} ^ {\prime} + D \tag {9.17} \\ \end{array}
$$

and

$$
\operatorname {C o v} \left(\boldsymbol {r} _ {t}, \boldsymbol {f} _ {t}\right) = E \left[ \left(\boldsymbol {r} _ {t} - \boldsymbol {\mu}\right) \boldsymbol {f} _ {t} ^ {\prime} \right] = \boldsymbol {\beta} E \left(\boldsymbol {f} _ {t} \boldsymbol {f} _ {t} ^ {\prime}\right) + E \left(\boldsymbol {\epsilon} _ {t} \boldsymbol {f} _ {t} ^ {\prime}\right) = \boldsymbol {\beta}. \tag {9.18}
$$

Using Eqs. (9.17) and (9.18), we see that for the orthogonal factor model in Eq. (9.16)

$$
\operatorname {V a r} \left(r _ {i t}\right) = \beta_ {i 1} ^ {2} + \dots + \beta_ {i m} ^ {2} + \sigma_ {i} ^ {2},
$$

$$
\operatorname {C o v} \left(r _ {i t}, r _ {j t}\right) = \beta_ {i 1} \beta_ {j 1} + \dots + \beta_ {i m} \beta_ {j m},
$$

$$
\operatorname {C o v} \left(r _ {i t}, f _ {j t}\right) = \beta_ {i j}.
$$

The quantity $\beta _ { i 1 } ^ { 2 } + \cdots + \beta _ { i m } ^ { 2 }$ , which is the portion of the variance of $r _ { i t }$ contributed by the m common factors, is called the communality. The remaining portion $\sigma _ { i } ^ { 2 }$ of the variance of $r _ { i t }$ is called the uniqueness or specific variance. Let $c _ { i } ^ { 2 } = \beta _ { i 1 } ^ { 2 } \dot { + }$ $\cdots + \beta _ { i m } ^ { 2 }$ be the communality, which is the sum of squares of the loadings of the ith variable on the m common factors. The variance of component $r _ { i t }$ becomes $\mathrm { V a r } ( r _ { i t } ) = c _ { i } ^ { 2 } + \sigma _ { i } ^ { 2 }$ .

In practice, not every covariance matrix has an orthogonal factor representation. In other words, there exists a random variable $r _ { t }$ that does not have any orthogonal factor representation. Furthermore, the orthogonal factor representation of a random variable is not unique. In fact, for any $m \times m$ orthogonal matrix $P$ satisfying $P P ^ { \prime } = P ^ { \prime } P = I$ , let $\beta ^ { * } = \beta P$ and $\pmb { f } _ { t } ^ { * } = \pmb { P } ^ { \prime } \pmb { f } _ { t }$ . Then

$$
\boldsymbol {r} _ {t} - \boldsymbol {\mu} = \boldsymbol {\beta} \boldsymbol {f} _ {t} + \epsilon_ {t} = \boldsymbol {\beta} \boldsymbol {P} \boldsymbol {P} ^ {\prime} \boldsymbol {f} _ {t} + \epsilon_ {t} = \boldsymbol {\beta} ^ {*} \boldsymbol {f} _ {t} ^ {*} + \epsilon_ {t}.
$$

In addition, $E ( f _ { t } ^ { * } ) = \mathbf { 0 }$ and $\operatorname { C o v } ( f _ { t } ^ { * } ) = P ^ { \prime } \mathrm { C o v } ( f _ { t } ) P = P ^ { \prime } P = I .$ . Thus, $\beta ^ { * }$ and $\boldsymbol { f } _ { t } ^ { * }$ form another orthogonal factor model for $r _ { t }$ . This nonuniqueness of orthogonal factor representation is a weakness as well as an advantage for factor analysis. It is a weakness because it makes the meaning of factor loading arbitrary. It is an advantage because it allows us to perform rotations to find common factors that have nice interpretations. Because $P$ is an orthogonal matrix, the transformation $\pmb { f } _ { t } ^ { * } = \pmb { P } ^ { \prime } \pmb { f } _ { t }$ is a rotation in the $m$ -dimensional space.

# 9.5.1 Estimation

The orthogonal factor model in Eq. (9.16) can be estimated by two methods. The first estimation method uses the principal component analysis of the previous section. This method does not require the normality assumption of the data nor the prespecification of the number of common factors. It applies to both the covariance and correlation matrices. But as mentioned in PCA, the solution is often an approximation. The second estimation method is the maximum likelihood method that uses normal density and requires a prespecification for the number of common factors.

# Principal Component Method

Again let $( \hat { \lambda } _ { 1 } , \bar { \pmb { e } } _ { 1 } )$ , . . . , $( \widehat { \lambda } _ { k } , \widehat { \pmb { e } } _ { k } )$ be pairs of the eigenvalues and eigenvectors of the sample covariance matrix $\widehat { \pmb { \Sigma } } _ { r }$ , where $\hat { \lambda } _ { 1 } \geq \hat { \lambda } _ { 2 } \geq \dots \geq \hat { \lambda } _ { k }$ . Let $m < k$ be the number of common factors. Then the matrix of factor loadings is given by

$$
\widehat {\boldsymbol {\beta}} \equiv [ \hat {\beta} _ {i j} ] = \left[ \sqrt {\hat {\lambda} _ {1}} \widehat {\boldsymbol {e}} _ {1} \left| \sqrt {\hat {\lambda} _ {2}} \widehat {\boldsymbol {e}} _ {2} \right| \dots \left| \sqrt {\hat {\lambda} _ {m}} \widehat {\boldsymbol {e}} _ {m} \right. \right]. \tag {9.19}
$$

The estimated specific variances are the diagonal elements of the matrix ${ \widehat { \pmb { \Sigma } } } _ { r } - { \widehat { \pmb { \beta } } } { \widehat { \pmb { \beta } } } ^ { \prime }$ . That is, $\widehat { \pmb { D } } = \mathrm { d i a g } \{ \hat { \sigma } _ { 1 } ^ { 2 } , \dots , \hat { \sigma } _ { k } ^ { 2 } \}$ , where $\begin{array} { r } { \hat { \sigma } _ { i } ^ { 2 } \bar { \mathbf { \sigma } } = \hat { \sigma } _ { i i , r } - \sum _ { j = 1 } ^ { m } \hat { \beta } _ { i j } ^ { 2 } } \end{array}$ , where $\hat { \sigma } _ { i i , r }$ is the $( i , i )$ th element of $\widehat { \pmb { \Sigma } } _ { r }$ . The communalities are estimated by

$$
\hat {c} _ {i} ^ {2} = \hat {\beta} _ {i 1} ^ {2} + \dots + \hat {\beta} _ {i m} ^ {2}.
$$

The error matrix caused by approximation is

$$
\widehat {\boldsymbol {\Sigma}} _ {r} - \left(\widehat {\boldsymbol {\beta}} \widehat {\boldsymbol {\beta}} ^ {\prime} + \widehat {\boldsymbol {D}}\right).
$$

Ideally, we would like this matrix to be close to zero. It can be shown that the sum of squared elements of $\widehat { \pmb { \Sigma } } _ { r } - ( \widehat { \pmb { \beta } \pmb { \beta } } ^ { \prime } + \widehat { \pmb { D } } )$ is less than or equal to $\hat { \lambda } _ { m + 1 } ^ { 2 } + \cdots +$ $\hat { \lambda } _ { k } ^ { 2 }$ . Therefore, the approximation error is bounded by the sum of squares of the neglected eigenvalues.

From the solution in Eq. (9.19), the estimated factor loadings based on the principal component method do not change as the number of common factors $m$ is increased.

# Maximum Likelihood Method

If the common factors $\boldsymbol { f } _ { t }$ and the specific factors $\epsilon _ { t }$ are jointly normal, then $r _ { t }$ is multivariate normal with mean $\pmb { \mu }$ and covariance matrix $\pmb { \Sigma } _ { r } = \pmb { \beta } \pmb { \beta } ^ { \prime } + \pmb { D }$ . The maximum likelihood method can then be used to obtain estimates of $\beta$ and $\pmb { D }$ under the constraint $\beta ^ { \prime } D ^ { - 1 } \beta = \Delta$ , which is a diagonal matrix. Here $\pmb { \mu }$ is estimated by the sample mean. For more details of this method, readers are referred to Johnson and Wichern (2002).

In using the maximum likelihood method, the number of common factors must be given a priori. In practice, one can use a modified likelihood ratio test to check the adequacy of a fitted $m$ -factor model. The test statistic is

$$
\operatorname {L R} (m) = - [ T - 1 - \frac {1}{6} (2 k + 5) - \frac {2}{3} m ] (\ln | \widehat {\boldsymbol {\Sigma}} _ {r} | - \ln | \widehat {\boldsymbol {\beta}} \widehat {\boldsymbol {\beta}} ^ {\prime} + \widehat {\boldsymbol {D}} |), \tag {9.20}
$$

which, under the null hypothesis of $m$ factors, is asymptotically distributed as a chi-squared distribution with ${ \begin{array} { l } { { \frac { 1 } { 2 } } [ ( k - m ) ^ { 2 } - k - m ] } \end{array} }$ degrees of freedom. We discuss some methods for selecting $m$ in Section 9.6.1.

# 9.5.2 Factor Rotation

As mentioned before, for any $m \times m$ orthogonal matrix $P$

$$
\boldsymbol {r} _ {t} - \boldsymbol {\mu} = \boldsymbol {\beta} \boldsymbol {f} _ {t} + \boldsymbol {\epsilon} _ {t} = \boldsymbol {\beta} ^ {*} \boldsymbol {f} _ {t} ^ {*} + \boldsymbol {\epsilon} _ {t},
$$

where $\beta ^ { * } = \beta ~ P$ and $\pmb { f } _ { t } ^ { * } = \pmb { P } ^ { \prime } \pmb { f } _ { t }$ . In addition,

$$
\beta \beta^ {\prime} + D = \beta P P ^ {\prime} \beta^ {\prime} + D = \beta^ {*} (\beta^ {*}) ^ {\prime} + D.
$$

This result indicates that the communalities and the specific variances remain unchanged under an orthogonal transformation. It is then reasonable to find an orthogonal matrix $P$ to transform the factor model so that the common factors have nice interpretations. Such a transformation is equivalent to rotating the common factors in the $m$ -dimensional space. In fact, there are infinite possible factor rotations available. Kaiser (1958) proposes a varimax criterion to select the rotation

that works well in many applications. Denote the rotated matrix of factor loadings by $\beta _ { \mathrm { ~ \scriptsize ~ - ~ } } ^ { * } = [ \beta _ { i j } ^ { * } ]$ and the ith communality by $c _ { i } ^ { 2 }$ . Define $\tilde { \beta } _ { i j } ^ { * } = \beta _ { i j } ^ { * } / c _ { i }$ to be the rotated coefficients scaled by the (positive) square root of communalities. The varimax procedure selects the orthogonal matrix $P$ that maximizes the quantity

$$
V = \frac {1}{k} \sum_ {j = 1} ^ {m} \left[ \sum_ {i = 1} ^ {k} (\tilde {\beta} _ {i j} ^ {*}) ^ {4} - \frac {1}{k} \left(\sum_ {i = 1} ^ {k} \tilde {\beta} _ {i j} ^ {* 2}\right) ^ {2} \right].
$$

This complicated expression has a simple interpretation. Maximizing V corresponds to spreading out the squares of the loadings on each factor as much as possible. Consequently, the procedure is to find groups of large and negligible coefficients in any column of the rotated matrix of factor loadings. In a real application, factor rotation is used to aid the interpretations of common factors. It may be helpful in some applications, but not informative in others. There are many criteria available for factor rotation.

# 9.5.3 Applications

Given the data $\{ r _ { t } \}$ of asset returns, the statistical factor analysis enables us to search for common factors that explain the variabilities of the returns. Since factor analysis assumes no serial correlations in the data, one should check the validity of this assumption before using factor analysis. The multivariate portmanteau statistics can be used for this purpose. If serial correlations are found, one can build a VARMA model to remove the dynamic dependence in the data and apply the factor analysis to the residual series. For many returns series, the correlation matrix of the residuals of a linear model is often very close to the correlation matrix of the original data. In this case, the effect of dynamic dependence on factor analysis is negligible.

We consider three examples in this subsection. The first two examples use the Minitab software to perform the analysis and the third example uses S-Plus. Other packages can also be used.

Example 9.2. Consider again the monthly log stock returns of IBM, Hewlett-Packard, Intel, Merrill Lynch, and Morgan Stanley Dean Witter used in Example 9.1. To check the assumption of no serial correlations, we compute the portmanteau statistics and obtain $Q _ { 5 } ( 1 ) = 3 4 . 2 8$ , $Q _ { 5 } ( 4 ) = 1 1 4 . 3 0$ , and $Q _ { 5 } ( 8 ) = 2 1 6 . 7 8$ . Compared with chi-squared distributions with 25, 100, and 200 degrees of freedom, the $p$ -values of these test statistics are 0.102, 0.156, and 0.198, respectively. Therefore, the assumption of no serial correlations cannot be rejected even at the $10 \%$ level.

Table 9.4 shows the results of factor analysis based on the correlation matrix using both the principal component and maximum likelihood methods. We assume that the number of common factors is 2, which is reasonable according to the principal component analysis of Example 9.1. From the table, the factor analysis reveals several interesting findings:

• The two factors identified by the principal component method explain more variability than those identified by the maximum likelihood method.

Table 9.4. Factor Analysis of the Monthly Log Stock Returnsa of IBM, Hewlett-Packard, Intel, Merrill Lynch, and Morgan Stanley Dean Witter   

<table><tr><td rowspan="2">Variable</td><td colspan="2">Estimates of Factor Loadings</td><td colspan="2">Rotated Factor Loadings</td><td rowspan="2">Communalities 1 - σi2</td></tr><tr><td>f1</td><td>f2</td><td>f1*</td><td>f2*</td></tr><tr><td colspan="6">Principal Component Method</td></tr><tr><td>IBM</td><td>0.536</td><td>0.561</td><td>0.011</td><td>0.776</td><td>0.602</td></tr><tr><td>HPQ</td><td>0.744</td><td>0.335</td><td>0.317</td><td>0.752</td><td>0.665</td></tr><tr><td>INTC</td><td>0.607</td><td>0.433</td><td>0.151</td><td>0.730</td><td>0.556</td></tr><tr><td>MER</td><td>0.788</td><td>-0.515</td><td>0.928</td><td>0.158</td><td>0.887</td></tr><tr><td>MWD</td><td>0.791</td><td>-0.514</td><td>0.930</td><td>0.161</td><td>0.891</td></tr><tr><td>Variance</td><td>2.456</td><td>1.145</td><td>1.850</td><td>1.751</td><td>3.601</td></tr><tr><td>Proportion</td><td>0.491</td><td>0.229</td><td>0.370</td><td>0.350</td><td>0.720</td></tr><tr><td colspan="6">Maximum Likelihood Method</td></tr><tr><td>IBM</td><td>0.191</td><td>0.496</td><td>0.087</td><td>0.524</td><td>0.282</td></tr><tr><td>HPQ</td><td>0.394</td><td>0.689</td><td>0.247</td><td>0.755</td><td>0.630</td></tr><tr><td>INTC</td><td>0.250</td><td>0.511</td><td>0.141</td><td>0.551</td><td>0.323</td></tr><tr><td>MER</td><td>0.800</td><td>0.072</td><td>0.769</td><td>0.232</td><td>0.645</td></tr><tr><td>MWD</td><td>0.994</td><td>-0.015</td><td>0.976</td><td>0.186</td><td>0.988</td></tr><tr><td>Variance</td><td>1.881</td><td>0.987</td><td>1.632</td><td>1.236</td><td>2.868</td></tr><tr><td>Proportion</td><td>0.376</td><td>0.197</td><td>0.326</td><td>0.247</td><td>0.574</td></tr></table>

aThe returns include dividends and are from January 1990 to December 1999. The analysis is based on the sample cross-correlation matrix and assumes two common factors.

• Based on the rotated factor loadings, the two estimation methods identify essentially the same two common factors for the data. The financial stocks (Merrill Lynch and Morgan Stanley Dean Witter) load heavily on the first factor, whereas the technology stocks (IBM, Hewlett-Packard, and Intel) load highly on the second factor. These two rotated factors jointly differentiate the industrial sectors.   
• In this particular instance, the varimax rotation does not change much the two factors identified by the maximum likelihood method. Yet the first unrotated factor identified by the principal component method was destroyed by the rotation. This is not surprising in view of the idea behind the varimax criterion.   
• The specific variances of IBM and Intel stock returns are relatively large based on the maximum likelihood method, indicating that these two stocks have their own features that are worth further investigation.

Example 9.3. In this example, we consider the monthly log returns of U.S. bond indexes with maturities in 30 years, 20 years, 10 years, 5 years, and 1 year.

The data are described in Example 9.2 but have been transformed into log returns. There are 696 observations. As shown in Example 9.2, there is serial dependence in the data. However, removing serial dependence by fitting a VARMA(2,1) model has hardly any effects on the concurrent correlation matrix. As a matter of fact, the correlation matrices before and after fitting a VARMA(2,1) model are

$$
\widehat {\boldsymbol {\rho}} _ {o} = \left[ \begin{array}{c c c c c} 1. 0 & & & & \\ 0. 9 8 & 1. 0 & & & \\ 0. 9 2 & 0. 9 1 & 1. 0 & & \\ 0. 8 5 & 0. 8 6 & 0. 9 0 & 1. 0 & \\ 0. 6 3 & 0. 6 4 & 0. 6 7 & 0. 8 1 & 1. 0 \end{array} \right], \quad \widehat {\boldsymbol {\rho}} = \left[ \begin{array}{c c c c c} 1. 0 & & & & \\ 0. 9 8 & 1. 0 & & & \\ 0. 9 2 & 0. 9 2 & 1. 0 & & \\ 0. 8 5 & 0. 8 6 & 0. 9 0 & 1. 0 & \\ 0. 6 6 & 0. 6 7 & 0. 7 1 & 0. 8 4 & 1. 0 \end{array} \right],
$$

where $\widehat { \pmb { \rho } } _ { o }$ is the correlation matrix of the original log returns. Therefore, we apply factor analysis directly to the return series.

Table 9.5 shows the results of statistical factor analysis of the data. For both estimation methods, the first two common factors explain more than $90 \%$ of the total variability of the data. Indeed, the high communalities indicate that the specific

Table 9.5. Factor Analysis of the Monthly Log Returns of U.S. Bond Indexes with Maturities in 30 Years, 20 Years, 10 Years, 5 Years, and 1 Yeara   

<table><tr><td rowspan="2">Variable</td><td colspan="2">Estimates of Factor Loadings</td><td colspan="2">Rotated Factor Loadings</td><td rowspan="2">Communalities 1 - σi2</td></tr><tr><td>f1</td><td>f2</td><td>f1*</td><td>f2*</td></tr><tr><td colspan="6">Principal Component Method</td></tr><tr><td>30 years</td><td>0.952</td><td>0.253</td><td>0.927</td><td>0.333</td><td>0.970</td></tr><tr><td>20 years</td><td>0.954</td><td>0.240</td><td>0.922</td><td>0.345</td><td>0.968</td></tr><tr><td>10 years</td><td>0.956</td><td>0.140</td><td>0.866</td><td>0.429</td><td>0.934</td></tr><tr><td>5 years</td><td>0.955</td><td>-0.142</td><td>0.704</td><td>0.660</td><td>0.931</td></tr><tr><td>1 year</td><td>0.800</td><td>-0.585</td><td>0.325</td><td>0.936</td><td>0.982</td></tr><tr><td>Variance</td><td>4.281</td><td>0.504</td><td>3.059</td><td>1.726</td><td>4.785</td></tr><tr><td>Proportion</td><td>0.856</td><td>0.101</td><td>0.612</td><td>0.345</td><td>0.957</td></tr><tr><td colspan="6">Maximum Likelihood Method</td></tr><tr><td>30 years</td><td>0.849</td><td>-0.513</td><td>0.895</td><td>0.430</td><td>0.985</td></tr><tr><td>20 years</td><td>0.857</td><td>-0.486</td><td>0.876</td><td>0.451</td><td>0.970</td></tr><tr><td>10 years</td><td>0.896</td><td>-0.303</td><td>0.744</td><td>0.584</td><td>0.895</td></tr><tr><td>5 years</td><td>1.000</td><td>0.000</td><td>0.547</td><td>0.837</td><td>1.000</td></tr><tr><td>1 year</td><td>0.813</td><td>0.123</td><td>0.342</td><td>0.747</td><td>0.675</td></tr><tr><td>Variance</td><td>3.918</td><td>0.607</td><td>2.538</td><td>1.987</td><td>4.525</td></tr><tr><td>Proportion</td><td>0.784</td><td>0.121</td><td>0.508</td><td>0.397</td><td>0.905</td></tr></table>

aThe data are from January 1942 to December 1999. The analysis is based on the sample crosscorrelation matrix and assumes two common factors.

variances are very small for the five bond index returns. Because the results of the two methods are close, we only discuss that of the principal component method. The unrotated factor loadings indicate that (a) all five return series load roughly equally on the first factor, and (b) the loadings on the second factor are positively correlated with the time to maturity. Therefore, the first common factor represents the general U.S. bond returns, and the second factor shows the “time-to-maturity” effect. Furthermore, the loadings of the second factor sum approximately to zero. Therefore, this common factor can also be interpreted as the contrast between long-term and short-term bonds. Here a long-term bond means one with maturity 10 years or longer. For the rotated factors, the loadings are also interesting. The loadings for the first rotated factor are proportional to the time to maturity, whereas the loadings of the second factor are inversely proportional to the time to maturity.

Example 9.4. Again, consider the monthly excess returns of the ten stocks in Table 9.2. The sample span is from January 1990 to December 2003 and the returns are in percentages. Our goal here is to demonstrate the use of statistical factor models using the S-Plus command factanal. We started with a two-factor model, but it is rejected by the likelihood ratio test of Eq. (9.20). The test statistic is $\mathrm { L R } ( 2 ) = 7 2 . 9 6$ . Based on the asymptotic $\chi _ { 2 6 } ^ { 2 }$ distribution, $p$ -value of the test statistic is close to zero.

>da $\equiv$ matrix.scan(file $=$ m-barra-9003.txt'），10)   
>rtn $\equiv$ t(da)   
>stat.fac $\equiv$ factanal(rtn,factors $= 2$ ,method $=$ 'mle')   
>stat.fac   
Sums of squares of loadings: Factor1Factor2 2.696479 2.19149

```txt
Component names: "loadings" "uniquenesses" "correlation" "criteria" "factors" "dof" "method" "center" "scale" "n. obs" "scores" "call" 
```

We then applied a three-factor model that appears to be reasonable at the $5 \%$ significance level. The $p$ -value of the LR(3) statistic is 0.0892.

```txt
> stat.fac=factanal(rtn, factor=3, method='mle')
> stat.fac
Test of the hypothesis that 3 factors are sufficient
versus the alternative that more are required:
The chi square statistic is 26.48 on 18 degrees of freedom.
The p-value is 0.0892
> summary(stat.fac)
Importance of factors: 
```

<table><tr><td></td><td>Factor1</td><td>Factor2</td><td>Factor3</td></tr><tr><td>SS loadings</td><td>2.635</td><td>1.825</td><td>1.326</td></tr><tr><td>Proportion Var</td><td>0.264</td><td>0.183</td><td>0.133</td></tr><tr><td>Cumulative Var</td><td>0.264</td><td>0.446</td><td>0.579</td></tr></table>

<table><tr><td colspan="7">Uniquenesses:</td></tr><tr><td>AGE</td><td>C</td><td>MWD</td><td>MER</td><td>DELL</td><td>HPQ</td><td>IBM</td></tr><tr><td>0.479</td><td>0.341</td><td>0.201</td><td>0.216</td><td>0.690</td><td>0.346</td><td>0.638</td></tr><tr><td>AA</td><td>CAT</td><td>PG</td><td></td><td></td><td></td><td></td></tr><tr><td>0.417</td><td>0.000</td><td>0.885</td><td></td><td></td><td></td><td></td></tr></table>

<table><tr><td colspan="4">Loadings:</td></tr><tr><td></td><td>Factor1</td><td>Factor2</td><td>Factor3</td></tr><tr><td>AGE</td><td>0.678</td><td>0.217</td><td>0.121</td></tr><tr><td>C</td><td>0.739</td><td>0.259</td><td>0.213</td></tr><tr><td>MWD</td><td>0.817</td><td>0.356</td><td></td></tr><tr><td>MER</td><td>0.819</td><td>0.329</td><td></td></tr><tr><td>DELL</td><td>0.102</td><td>0.547</td><td></td></tr><tr><td>HPQ</td><td>0.230</td><td>0.771</td><td></td></tr><tr><td>IBM</td><td>0.200</td><td>0.515</td><td>0.238</td></tr><tr><td>AA</td><td>0.194</td><td>0.546</td><td>0.497</td></tr><tr><td>CAT</td><td>0.198</td><td>0.138</td><td>0.970</td></tr><tr><td>PG</td><td>0.331</td><td></td><td></td></tr></table>

The factor loadings can also be shown graphically using

> plot(loadings(stat.fac))

and the plots are in Figure 9.6. From the plots, factor 1 represents essentially the financial service sector, and factor 2 mainly consists of the excess returns from the high-tech stocks and the Alcoa stock. Factor 3 depends heavily on excess returns of CAT and AA stocks and, hence, represents the remaining industrial sector.

Factor rotation can be obtained using the command rotate, which allows for many rotation methods, and factor realizations are available from the command predict.

<table><tr><td colspan="4">&gt; stat.fac2 = rotate(stat.fac,rotation=&#x27;quartimax&#x27;)</td></tr><tr><td colspan="4">&gt; loadings(stat.fac2)</td></tr><tr><td></td><td>Factor1</td><td>Factor2</td><td>Factor3</td></tr><tr><td>AGE</td><td>0.700</td><td>0.171</td><td></td></tr><tr><td>C</td><td>0.772</td><td>0.216</td><td>0.124</td></tr><tr><td>MWD</td><td>0.844</td><td>0.291</td><td></td></tr><tr><td>MER</td><td>0.844</td><td>0.264</td><td></td></tr><tr><td>DELL</td><td>0.144</td><td>0.536</td><td></td></tr><tr><td>HPQ</td><td>0.294</td><td>0.753</td><td></td></tr><tr><td>IBM</td><td>0.258</td><td>0.518</td><td>0.164</td></tr><tr><td>AA</td><td>0.278</td><td>0.575</td><td>0.418</td></tr><tr><td>CAT</td><td>0.293</td><td>0.219</td><td>0.931</td></tr></table>

![](images/fba7a7ff62df329f69afb540f83ba46abcd5f6a33f2a1bcf63e871724c89898b.jpg)

![](images/6f1ae1bfd287b14e1ff1bebb55c0ae038fc85530a015a609e38b75bfbf55f560.jpg)

![](images/b145dfc0c8bac8da5d978542aa35ca7ba5e7f6575d21c88e09826a9f42caa240.jpg)  
Figure 9.6. Plots of factor loadings when a three-factor statistical factor model is fitted to the ten monthly excess stock returns in Table 9.2.

```txt
PG 0.334  
> factor.real=predict(stat.fac,type='weighted.ps') 
```

Finally, we obtained the correlation matrix of the ten excess returns based on the fitted three-factor statistical factor model. As expected, the correlations are closer to their sample counterparts than those of the industrial factor model in Section 9.3.1. One can also use GMVP to compare the covariance matrices of the returns and the statistical factor model.

```txt
> corr.fit=fitted(stat.fac)  
> print(corr.fit, digits=1, width=2)  
AGE C MWD MER DELL HPQ IBM AA CAT PG  
AGE 1.0 0.6 0.6 0.6 0.19 0.3 0.3 0.3 0.3 0.2  
C 0.6 1.0 0.7 0.7 0.22 0.4 0.3 0.4 0.4 0.3  
MWD 0.6 0.7 1.0 0.8 0.28 0.5 0.4 0.4 0.3 0.3  
MER 0.6 0.7 0.8 1.0 0.26 0.5 0.4 0.4 0.3 0.3  
DELL 0.2 0.2 0.3 0.3 1.00 0.5 0.3 0.3 0.1 0.0  
HPQ 0.3 0.4 0.5 0.4 0.45 1.0 0.5 0.5 0.2 0.1 
```

<table><tr><td>IBM</td><td>0.3</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.31</td><td>0.5</td><td>1.0</td><td>0.4</td><td>0.3</td><td>0.1</td></tr><tr><td>AA</td><td>0.3</td><td>0.4</td><td>0.4</td><td>0.4</td><td>0.33</td><td>0.5</td><td>0.4</td><td>1.0</td><td>0.6</td><td>0.1</td></tr><tr><td>CAT</td><td>0.3</td><td>0.4</td><td>0.3</td><td>0.3</td><td>0.11</td><td>0.2</td><td>0.3</td><td>0.6</td><td>1.0</td><td>0.1</td></tr><tr><td>PG</td><td>0.2</td><td>0.3</td><td>0.3</td><td>0.3</td><td>0.03</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>1.0</td></tr></table>

# 9.6 ASYMPTOTIC PRINCIPAL COMPONENT ANALYSIS

So far, our discussion of PCA assumes that the number of assets is smaller than the number of time periods, that is, $k < T$ . To deal with situations of a small $T$ and large $k$ , Conner and Korajczyk (1986, 1988) developed the concept of asymptotic principal component analysis (APCA), which is similar to the traditional PCA but relies on the asymptotic results as the number of assets $k$ increases to infinity. Thus, the APCA is based on eigenvalue–eigenvector analysis of the $T \times T$ matrix

$$
\widehat {\boldsymbol {\Omega}} _ {T} = \frac {1}{k - 1} \sum_ {i = 1} ^ {k} (\boldsymbol {R} _ {i} - \overline {{\boldsymbol {R}}}) (\boldsymbol {R} _ {i} - \overline {{\boldsymbol {R}}}) ^ {\prime},
$$

where $\pmb { R } _ { i }$ is the time series of ith asset as defined in Eq. (9.3), and $\overline { { \pmb { R } } } = ( 1 / k ) \times$ $\textstyle \sum _ { i = 1 } ^ { k } R _ { i }$ . In other words, $\overline { { R } }$ is the time series of the average returns of all stocks used. Alternatively, using the notation in Eq. (9.4), we have

$$
\widehat {\boldsymbol {\Omega}} _ {T} = \frac {1}{k - 1} (\boldsymbol {R} - \overline {{\boldsymbol {R}}} \otimes \mathbf {1} _ {k} ^ {\prime}) (\boldsymbol {R} - \overline {{\boldsymbol {R}}} \otimes \mathbf {1} _ {k} ^ {\prime}) ^ {\prime},
$$

where $\mathbf { 1 } _ { k }$ is the $k$ -dimensional vector of ones. Conner and Korajczyk showed that as $k  \infty$ eigenvalue–eigenvector analysis of $\widehat { \pmb { \Omega } } _ { T }$ is equivalent to the traditional statistical factor analysis. In other words, the APCA estimates of the factors $\boldsymbol { f } _ { t }$ are the first $m$ eigenvectors of $\widehat { \pmb { \Omega } } _ { T }$ . Let $\widehat { F } _ { t }$ be the $m \times T$ matrix consisting of the first m eigenvectors of $\widehat { \pmb { \Omega } } _ { T }$ . Then $\widehat { \pmb f } _ { t }$ is the t th column of $\widehat { \boldsymbol { F } } _ { t }$ . Using an idea similar to the estimation of BARRA factor models, Connor and Korajczyk (1988) propose refining the estimation of $\widehat { \pmb f } _ { t }$ as follows:

1. Use the sample covariance matrix $\widehat { \pmb { \Omega } } _ { T }$ to obtain an initial estimate of $\widehat { \pmb f } _ { t }$ for $t = 1 , \dots , T$ .   
2. For each asset, perform the OLS estimation of the model

$$
r _ {i t} = \alpha_ {i} + \boldsymbol {\beta} _ {i} ^ {\prime} \widehat {\boldsymbol {f}} _ {t} + \epsilon_ {i t}, \quad t = 1, \dots , T,
$$

and compute the residual variance $\hat { \sigma } _ { i } ^ { 2 }$ .

3. Form the diagonal matrix $\widehat { \pmb { D } } = \mathrm { d i a g } \{ \hat { \sigma } _ { 1 } ^ { 2 } , \dots , \hat { \sigma } _ { k } ^ { 2 } \}$ and rescale the returns as

$$
\boldsymbol {R} _ {*} = \boldsymbol {R} \widehat {\boldsymbol {D}} ^ {- 1 / 2}.
$$

4. Compute the $T \times T$ covariance matrix using $\pmb { R } _ { * }$ as

$$
\widehat {\pmb {\Omega}} _ {*} = \frac {1}{k - 1} (\pmb {R} _ {*} - \overline {{\pmb {R}}} _ {*} \otimes \mathbf {1} _ {k} ^ {\prime}) (\pmb {R} _ {*} - \overline {{\pmb {R}}} _ {*} \otimes \mathbf {1} _ {k} ^ {\prime}) ^ {\prime},
$$

where $\overline { { R } } _ { * }$ is the vector of row averages of $\pmb { R } _ { * }$ , and perform eigenvalue– eigenvector analysis of $\widehat { \pmb { \Omega } } _ { \ast }$ to obtain a refined estimate of $\pmb { f } _ { t }$ .

# 9.6.1 Selecting the Number of Factors

Two methods are available in the literature to help select the number of factors in factor analysis. The first method proposed by Connor and Korajczyk (1993) makes use of the idea that if $m$ is the proper number of common factors, then there should be no significant decrease in the cross-sectional variance of the asset specific error $\epsilon _ { i t }$ when the number of factors moves from $m$ to $m + 1$ . The second method proposed by Bai and Ng (2002) adopts some information criteria to select the number of factors. This latter method is based on the observation that the eigenvalue–eigenvector analysis of $\widehat { \pmb { \Omega } } _ { T }$ solves the least squares problem

$$
\min  _ {\alpha , \boldsymbol {\beta}, \boldsymbol {f} _ {t}} \frac {1}{k T} \sum_ {i = 1} ^ {k} \sum_ {t = 1} ^ {T} \left(r _ {i t} - \alpha_ {i} - \boldsymbol {\beta} _ {i} ^ {\prime} \boldsymbol {f} _ {t}\right) ^ {2}.
$$

Assume that there are m factors so that $\boldsymbol { f } _ { t }$ is $m$ -dimensional. Let $\hat { \sigma } _ { i } ^ { 2 } ( m )$ be the residual variance of the inner regression of the prior least squares problem for asset i. This is done by using $\widehat { \pmb f } _ { t } ^ { - }$ obtained from the APCA analysis. Define the cross-sectional average of the residual variances as

$$
\hat {\sigma} ^ {2} (m) = \frac {1}{k} \sum_ {i = 1} ^ {k} \hat {\sigma} _ {i} ^ {2} (m).
$$

The criteria proposed by Bai and Ng (2002) are

$$
C _ {p 1} (m) = \hat {\sigma} ^ {2} (m) + m \hat {\sigma} ^ {2} (M) \left(\frac {k + T}{k T}\right) \ln \left(\frac {k T}{k + T}\right),
$$

$$
C _ {p 2} (m) = \hat {\sigma} ^ {2} (m) + m \hat {\sigma} ^ {2} (M) \left(\frac {k + T}{k T}\right) \ln \left(P _ {k T} ^ {2}\right),
$$

where $M$ is a prespecified positive integer denoting the maximum number of factors and $P _ { k T } = \operatorname* { m i n } ( \sqrt { k } , \sqrt { T } )$ . One selects $m$ that minimizes either $C _ { p 1 } ( m )$ or $C _ { p 2 } ( m )$ for $0 \leq m \leq M$ . In practice, the two criteria may select different numbers of factors.

# 9.6.2 An Example

To demonstrate asymptotic principal component analysis, we consider monthly simple returns of 40 stocks from January 2001 to December 2003 for 36 observations.

Table 9.6. Tick Symbols of Stocks Used in Asymptotic Principal Component Analysis for Sample Period from January 2001 to December 2003   

<table><tr><td>Market</td><td colspan="5">Tick Symbol</td></tr><tr><td rowspan="4">NASDAQ</td><td>INTC</td><td>MSFT</td><td>SUNW</td><td>CSCO</td><td>AMAT</td></tr><tr><td>ORCL</td><td>SIRI</td><td>COCO</td><td>CORV</td><td>SUPG</td></tr><tr><td>YHOO</td><td>JDSU</td><td>QCOM</td><td>CIEN</td><td>DELL</td></tr><tr><td>ERTS</td><td>EBAY</td><td>ADCT</td><td>AAPL</td><td>JNPR</td></tr><tr><td rowspan="4">NYSE</td><td>LU</td><td>PFE</td><td>NT</td><td>BAC</td><td>BSX</td></tr><tr><td>GE</td><td>TXN</td><td>XOM</td><td>FRX</td><td>Q</td></tr><tr><td>F</td><td>TWX</td><td>C</td><td>MOT</td><td>JPM</td></tr><tr><td>TYC</td><td>HPQ</td><td>NOK</td><td>WMT</td><td>AMD</td></tr></table>

Thus, we have $k = 4 0$ and $T = 3 6$ . The tick symbols of stocks used are given in Table 9.6. These stocks are among those heavily traded on NASDAQ and the NYSE on a particular day of September 2004. The main S-Plus command used is mfactor.

To select the number of factors, we used the two methods discussed earlier. The Connor–Korajczyk method selects $m = 1$ whereas the Bai–Ng method uses $m = 6$ . For the latter method, the two criteria provide different results.

```txt
>dim(rtn) % rtn is the return data.  
[1] 36 40  
>nf.ck=mfactor(rtn,k='ck',max.k=10,sig=0.05)  
>nf.ck  
Call:  
mfactor(x = rtn, k = "ck", max.k = 10, sig = 0.05)  
Factor Model:  
Factors Variables Periods  
1 40 36  
Factor Loadings:  
Min. 1st Qu. Median Mean 3rd Qu. Max.  
F.1 0.069 0.432 0.629 0.688 1.071 1.612 
```

```txt
Regression R-squared: Min. 1st Qu. Median Mean 3rd Qu. Max. 0.090 0.287 0.487 0.456 0.574 0.831 >nf.bn=mfactor(rtn,k='bn',max.k=10,sig=0.05) Warning messages: Cp1 & Cp2 did not yield same result.The smaller one is used. >nf.bn\$k [1] 6 
```

Using $m = 6$ , we apply APCA to the returns. The scree plot and estimated factor returns can also be obtained.

```txt
> apca = mfactor(rtn, k=6)  
> apca  
Call:  
mfactor(x = rtn, k = 6)  
Factor Model:  
Factors Variables Periods  
6 40 36  
Factor Loadings:  
Min 1st Qu. Median Mean 3rd Qu. Max.  
F.1 0.048 0.349 0.561 0.643 0.952 2.222  
F.2 -1.737 0.084 0.216 0.214 0.323 1.046  
F.3 -1.512 0.002 0.076 0.102 0.255 1.093  
F.4 -0.965 -0.035 0.078 0.048 0.202 0.585  
F.5 -0.722 -0.008 0.056 0.066 0.214 0.729  
F.6 -0.840 -0.088 0.003 0.003 0.071 0.635  
Regression R-squared:  
Min. 1st Qu. Median Mean 3rd Qu. Max.  
0.219 0.480 0.695 0.651 0.801 0.999  
> screeplot.mfactor(apca)  
> fplot(factors(apca)) 
```

Figure 9.7 shows the scree plot of the APCA for the 40 stock returns. The six common factors used explain about $8 9 . 4 \%$ of the variability. Figure 9.8 gives the time plots of the returns of the six estimated factors.

![](images/37f49ec497fb0b8b5caca27836687a58a48627d7c757bb3f3c65fbd252f79e7e.jpg)  
Figure 9.7. Scree plot of asymptotic principal component analysis applied to monthly simple returns of 40 stocks. The sample period is from January 2001 to December 2003.

![](images/f41476d546eb207fc0c6c3db8d8a11d21f4be36d87c694a291cdc4fe4c02a72e.jpg)  
Figure 9.8. Time plots of factor returns derived from applying the asymptotic principal component analysis to monthly simple returns of 40 stocks. The sample period is from January 2001 to December 2003.

# EXERCISES

9.1. Consider the monthly log stock returns, in percentages and including dividends, of Merck & Company, Johnson & Johnson, General Electric, General Motors, Ford Motor Company, and value-weighted index from January 1960 to December 1999; see the file m-mrk2vw.txt, which has six columns in the order listed before.

(a) Perform a principal component analysis of the data using the sample covariance matrix.   
(b) Perform a principal component analysis of the data using the sample correlation matrix.   
(c) Perform a statistical factor analysis on the data. Identify the number of common factors. Obtain estimates of factor loadings using both the principal component and maximum likelihood methods.

9.2. The file m-excess-c10sp-9003.txt contains the monthly simple excess returns of ten stocks and the S&P 500 index. The three-month Treasury bill rate on the secondary market is used to compute the excess returns. The sample period is from January 1990 to December 2003 for 168 observations. The 11 columns in the file contain the returns for ABT, LLY, MRK, PFE, F, GM, BP,

CVX, RD, XOM, and SP5, respectively. Analyze the ten stock excess returns using the single-factor market model. Plot the beta estimate and R-square for each stock, and use the global minimum variance portfolio to compare the covariance matrices of the fitted model and the data.

9.3. Again, consider the ten stock returns in m-excess-c10sp-9003.txt. The stocks are from companies in three industrial sectors. ABT, LLY, MRK, and PFE are major drug companies, F and GM are automobile companies, and the rest are big oil companies. Analyze the excess returns using the BARRA industrial factor model. Plot the three-factor realizations and comment on the adequacy of the fitted model.   
9.4. Again, consider the ten excess stock returns in the file m-excess-c10sp-9003.txt. Perform a principal component analysis on the returns and obtain the scree plot. How many common factors are there? Why? Interpret the common factors.   
9.5. Again, consider the ten excess stock returns in the file m-excess-c10sp-9003.txt. Perform a statistical factor analysis. How many common factors are there if the $5 \%$ significance level is used? Plot the estimated factor loadings of the fitted model. Are the common factors meaningful?   
9.6. The file m-fedip.txt contains year, month, effective federal funds rate, and the industrial production index from July 1954 to December 2003. The industrial production index is seasonally adjusted. Use the federal funds rate and the industrial production index as the macroeconomic variables. Fit a macroeconomic factor model to the ten excess returns in m-excess-c10sp-9003.txt. You can use a VAR model to obtain the surprise series of the macroeconomic variables. Comment on the fitted factor model.

# REFERENCES

Alexander, C. (2001). Market Models: A Guide to Financial Data Analysis. Wiley, Hoboken, NJ.   
Bai, J. and Ng, S. (2002). Determining the number of factors in approximate factor models. Econometrica 70: 191–221.   
Campbell, J. Y., Lo, A. W., and MacKinlay, A. C. (1997). The Econometrics of Financial Markets. Princeton University Press, Princeton, NJ.   
Chen, N. F., Roll, R., and Ross, S. A. (1986). Economic forces and the stock market. The Journal of Business 59: 383–404.   
Connor, G. (1995). The three types of factor models: A comparison of their explanatory power. Financial Analysts Journal 51: 42–46.   
Connor, G. and Korajczyk, R. A. (1986). Performance measurement with the arbitrage pricing theory: A new framework for analysis. Journal of Financial Econometrics 15: 373–394.

Connor, G. and Korajczyk, R. A. (1988). Risk and return in an equilibrium APT: Application of a new test methodology. Journal of Financial Econometrics 21: 255–289.   
Connor, G. and Korajczyk, R. A. (1993). A test for the number of factors in an approximate factor model. Journal of Finance 48: 1263–1292.   
Fama, E. and French, K. R. (1992). The cross-section of expected stock returns. Journal of Finance 47: 427–465.   
Grinold, R. C. and Kahn, R. N. (2000). Active Portfolio Management: A Quantitative Approach for Producing Superior Returns and Controlling Risk, 2nd edition. McGraw-Hill, New York.   
Johnson, R. A. and Wichern, D. W. (2002). Applied Multivariate Statistical Analysis, 5th edition. Prentice Hall, Upper Saddle River, NJ.   
Kaiser, H. F. (1958). The varimax criterion for analytic rotation in factor analysis. Psychometrika 23: 187–200.   
Sharpe, W. (1970). Portfolio Theory and Capital Markets. McGraw-Hill, New York.   
Zivot, E. and Wang, J. (2003). Modeling Financial Time Series with S-Plus. Springer-Verlag, New York.

# Multivariate Volatility Models and Their Applications

In this chapter, we generalize the univariate volatility models of Chapter 3 to the multivariate case and discuss some methods for simplifying the dynamic relationships between volatility processes of multiple asset returns. Multivariate volatilities have many important financial applications. They play an important role in portfolio selection and asset allocation, and they can be used to compute the value at risk of a financial position consisting of multiple assets.

Consider a multivariate return series $\{ \boldsymbol { r } _ { t } \}$ . We adopt the same approach as the univariate case by rewriting the series as

$$
\boldsymbol {r} _ {t} = \boldsymbol {\mu} _ {t} + \boldsymbol {a} _ {t},
$$

where $\pmb { \mu } _ { t } = E ( \pmb { r } _ { t } | \pmb { F } _ { t - 1 } )$ is the conditional expectation of $r _ { t }$ given the past information $\boldsymbol { F } _ { t - 1 }$ , and ${ \pmb a } _ { t } = ( a _ { 1 t } , \ldots , a _ { k t } ) ^ { \prime }$ is the shock, or innovation, of the series at time $t$ . The ${ \pmb { \mu } } _ { t }$ process is assumed to follow the conditional expectation of a multivariate time series model of Chapter 8. For most return series, it suffices to employ a simple vector ARMA structure with exogenous variables for ${ \pmb { \mu } } _ { t }$ — that is,

$$
\boldsymbol {\mu} _ {t} = \boldsymbol {\Upsilon} \boldsymbol {x} _ {t} + \sum_ {i = 1} ^ {p} \Phi_ {i} \boldsymbol {r} _ {t - i} - \sum_ {i = 1} ^ {q} \Theta_ {i} \boldsymbol {a} _ {t - i}, \tag {10.1}
$$

where $\boldsymbol { x } _ { t }$ denotes an $m$ -dimensional vector of exogenous (or explanatory) variables with $x _ { 1 t } = 1$ , $\boldsymbol { \Upsilon }$ is a $k \times m$ matrix, and $p$ and $q$ are non-negative integers. We refer to Eq. (10.1) as the mean equation of $r _ { t }$ .

The conditional covariance matrix of $\pmb { a } _ { t }$ given $\boldsymbol { F } _ { t - 1 }$ is a $k \times k$ positive-definite matrix $\Sigma _ { t }$ defined by $\Sigma _ { t } = \mathrm { C o v } ( { \pmb a } _ { t } | { \pmb F } _ { t - 1 } )$ . Multivariate volatility modeling is concerned with the time evolution of $\Sigma _ { t }$ . We refer to a model for the $\{ \pmb { \Sigma } _ { t } \}$ process as a volatility model for the return series $r _ { t }$ .

There are many ways to generalize univariate volatility models to the multivariate case, but the curse of dimensionality quickly becomes a major obstacle in applications because there are $k ( k + 1 ) / 2$ quantities in $\Sigma _ { t }$ for a $k$ -dimensional return series. To illustrate, there are 15 conditional variances and covariances in $\Sigma _ { t }$ for a five-dimensional return series. The goal of this chapter is to introduce some relatively simple multivariate volatility models that are useful, yet remain manageable in real application. In particular, we discuss some models that allow for time-varying correlation coefficients between asset returns. Time-varying correlations are useful in finance. For example, they can be used to estimate the time-varying beta of the market model for a return series.

We begin by using an exponentially weighted approach to estimate the covariance matrix in Section 10.1. This estimated covariance matrix can serve as a benchmark for multivariate volatility estimation. Section 10.2 discusses some generalizations of univariate GARCH models that are available in the literature. We then introduce two methods to reparameterize $\Sigma _ { t }$ for volatility modeling in Section 10.3. The reparameterization based on the Cholesky decomposition is found to be useful. We study some volatility models for bivariate returns in Section 10.4, using the GARCH model as an example. In this particular case, the volatility model can be bivariate or three-dimensional. Section 10.5 is concerned with volatility models for higher dimensional returns and Section 10.6 addresses the issue of dimension reduction. We demonstrate some applications of multivariate volatility models in Section 10.7. Finally, Section 10.8 gives a multivariate Student-t distribution useful for volatility modeling.

# 10.1 EXPONENTIALLY WEIGHTED ESTIMATE

Given the innovations $F _ { t - 1 } = \{ \pmb { a } _ { 1 } , \dots , \pmb { a } _ { t - 1 } \}$ , the (unconditional) covariance matrix of the innovation can be estimated by

$$
\widehat {\boldsymbol {\Sigma}} = \frac {1}{t - 1} \sum_ {j = 1} ^ {t - 1} \boldsymbol {a} _ {j} \boldsymbol {a} _ {j} ^ {\prime},
$$

where it is understood that the mean of ${ \pmb a } _ { j }$ is zero. This estimate assigns equal weight $1 / ( t - 1 )$ to each term in the summation. To allow for a time-varying covariance matrix and to emphasize that recent innovations are more relevant, one can use the idea of exponential smoothing and estimate the covariance matrix of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ by

$$
\widehat {\boldsymbol {\Sigma}} _ {t} = \frac {1 - \lambda}{1 - \lambda^ {t - 1}} \sum_ {j = 1} ^ {t - 1} \lambda^ {j - 1} \boldsymbol {a} _ {t - j} \boldsymbol {a} _ {t - j} ^ {\prime}, \tag {10.2}
$$

where $0 < \lambda < 1$ and the weights $( 1 - \lambda ) \lambda ^ { j - 1 } / ( 1 - \lambda ^ { t - 1 } )$ sum to one. For a sufficiently large $t$ such that $\lambda ^ { t - 1 } \approx 0$ , the prior equation can be rewritten as

$$
\widehat {\boldsymbol {\Sigma}} _ {t} = (1 - \lambda) \boldsymbol {a} _ {t - 1} \boldsymbol {a} _ {t - 1} ^ {\prime} + \lambda \widehat {\boldsymbol {\Sigma}} _ {t - 1}.
$$

Therefore, the covariance estimate in Eq. (10.2) is referred to as the exponentially weighted moving-average (EWMA) estimate of the covariance matrix.

Suppose that the return data are $\{ \boldsymbol { r } _ { 1 } , \ldots , \boldsymbol { r } _ { T } \}$ . For a given $\lambda$ and initial estimate $\widehat { \pmb { \Sigma } } _ { 1 }$ , $\widehat { \pmb { \Sigma } } _ { t } ^ { }$ can be computed recursively. If one assumes that $\pmb { a } _ { t } = \pmb { r } _ { t } - \pmb { \mu } _ { t }$ follows a multivariate normal distribution with mean zero and covariance matrix $\Sigma _ { t }$ , where ${ \pmb { \mu } } _ { t }$ is a function of parameter $\mathbf { \Theta } _ { \Theta }$ , then $\lambda$ and $\mathbf { \Theta } _ { \Theta }$ can be estimated jointly by the maximum likelihood method, because the log likelihood function of the data is

$$
\ln L (\boldsymbol {\Theta}, \lambda) \propto - \frac {1}{2} \sum_ {t = 1} ^ {T} \ln (| \boldsymbol {\Sigma} _ {t} |) - \frac {1}{2} \sum_ {t = 1} ^ {T} (\boldsymbol {r} _ {t} - \boldsymbol {\mu} _ {t}) \boldsymbol {\Sigma} _ {t} ^ {- 1} (\boldsymbol {r} _ {t} - \boldsymbol {\mu} _ {t}) ^ {\prime},
$$

which can be evaluated recursively by substituting $\widehat { \pmb { \Sigma } } _ { t }$ for $\Sigma _ { t }$ .

Example 10.1. To illustrate, consider the daily log returns of the stock market indexes for Hong Kong and Japan from January 1, 1996 to October 16, 1997 for 469 observations. The indexes are dollar denominated and the returns are in percentages. We select the sample period to avoid the effect of an Asian financial crisis, which hit the Hong Kong market on October 17, 1997. The data are obtained from Datastream. Figure 10.1 shows the time plots of the two index

![](images/d8b2f2323df7405566ea9bfaf7110acc779ca682bb6ebf807f7fb31dd773cc8d.jpg)

![](images/d75f7ba417d0b4891b239c8a20f3d91a470d90bc6edb26969d1620cd8f56f4f5.jpg)  
Figure 10.1. Time plots of daily log returns in percentages of stock market indexes for Hong Kong and Japan from January 1, 1996 to October 16, 1997: (a) the Hong Kong market and (b) the Japanese market.

returns. Let $r _ { 1 t }$ and $r _ { 2 t }$ be the log returns of the Hong Kong and Japanese markets, respectively. If univariate GARCH models are entertained, we obtain the models

$$
r _ {1 t} = 0. 0 9 0 - 0. 0 9 4 r _ {1, t - 6} + a _ {1 t}, \quad a _ {1 t} = \sigma_ {1 t} \epsilon_ {1 t}, \tag {10.3}
$$

$$
\sigma_ {1 t} ^ {2} = 0. 1 2 6 + 0. 1 0 3 a _ {1, t - 1} ^ {2} + 0. 8 1 8 \sigma_ {1, t - 1} ^ {2}
$$

and

$$
r _ {2 t} = - 0. 0 4 6 + a _ {2 t}, \quad a _ {2 t} = \sigma_ {2 t} \epsilon_ {2 t}, \tag {10.4}
$$

$$
\sigma_ {2 t} ^ {2} = 0. 0 0 7 + 0. 0 5 4 a _ {2, t - 1} ^ {2} + 0. 9 4 2 \sigma_ {2, t - 1} ^ {2},
$$

where all of the parameter estimates are significant at the $5 \%$ level except for the constant terms of the returns and $\alpha _ { 0 }$ of the Japanese market returns. The Ljung–Box statistics of the standardized residuals and their squared series of the two univariate models fail to indicate any model inadequacy. Figure 10.2 shows the estimated volatilities of the two univariate GARCH(1,1) models. The Hong Kong stock market appears to be more volatile than the Japanese stock market, but the Japanese market shows increased volatilities in the second half of the sample. The model-based asymptotic standard errors of the index returns are 1.259 and 1.393, respectively, for the Hong Kong and Japanese markets. The sample

![](images/d167d971225cdb5f965e472bc8be1e9da617a31fbf3075058cf1a230744f2856.jpg)  
(a) Hong Kong

![](images/9c3b54813b0bf2dc2c5546e35cd733e62e27ccf05d2205c665a1fa842f8acb4a.jpg)  
(b) Japan   
Figure 10.2. Estimated volatilities (standard error) for daily log returns in percentages of stock market indexes for Hong Kong and Japan from January 1, 1996 to October 16, 1997: (a) the Hong Kong market and (b) the Japanese market. Univariate models are used.

standard errors of the data are 1.296 and 1.067. Thus, the univariate model for the Japanese market index returns overestimates its unconditional volatility. This might be caused by the IGARCH feature of Eq. (10.4), which in turn may be caused by the observed jump in volatility in the second half of the data.

Turn to bivariate modeling. For simplicity, we ignore the minor lag-6 serial correlation of the Hong Kong returns and apply the EWMA approach to obtain volatility estimates, using the command mgarch in S-Plus FinMetrics:

>hkja ewma $\equiv$ mgarch 1, formula.var $= \sim$ ewmal, trace $= F$ Mean Equation: rtn \~ 1

Conditional Variance Equation: ~ ewma1

Coefficients:

C(1) 0.06394 % Expected perc. return of Hong Kong market   
C(2) -0.05478 % Expected perc. return of Japanese market ALPHA 0.03711

The estimate of $\lambda$ is $1 - { \hat { \alpha } } = 1 - 0 . 0 3 7 1 1 \approx 0 . 9 6 3$ , which is in the typical range commonly seen in practice. Figure 10.3 shows the estimated volatility series by the EWMA approach. Compared with those in Figure 10.2, the EWMA approach produces smoother volatility series, even though the two plots show similar volatility patterns.

# 10.2 SOME MULTIVARIATE GARCH MODELS

Many authors have generalized univariate volatility models to the multivariate case. In this section, we discuss some of the generalizations. For more details, readers are referred to a recent survey article by Bauwens, Laurent, and Rombouts (2004).

# 10.2.1 Diagonal VEC Model

Bollerslev, Engle, and Wooldridge (1988) generalize the exponentially weighted moving-average approach to propose the model

$$
\boldsymbol {\Sigma} _ {t} = \boldsymbol {A} _ {0} + \sum_ {i = 1} ^ {m} \boldsymbol {A} _ {i} \odot \left(\boldsymbol {a} _ {t - i} \boldsymbol {a} _ {t - i} ^ {\prime}\right) + \sum_ {j = 1} ^ {s} \boldsymbol {B} _ {j} \odot \boldsymbol {\Sigma} _ {t - j}, \tag {10.5}
$$

where m and $s$ are non-negative integers, $A _ { i }$ and $B _ { j }$ are symmetric matrices, and $\odot$ denotes Hadamard product; that is, element-by-element multiplication. This is referred to as the diagonal ${ \mathrm { V E C } } ( m , s )$ model or $\mathrm { D V E C } ( m , s )$ model. To appreciate

![](images/cc3c5ceab48686ee60083e64700f32c5a977188b303e0c399fe0dcd97a1aff96.jpg)  
(a) Hong Kong

![](images/7e68ad45acfd74cf8a41e3d5040c045e3a28e39f1677c85c207c4bbe34523e2e.jpg)  
(b) Japan   
Figure 10.3. Estimated volatilities (standard error) for daily log returns in percentages of stock market indices for Hong Kong and Japan from January 1, 1996 to October 16, 1997: (a) the Hong Kong market and (b) the Japanese market. The exponentially weighted moving-average approach is used.

the model, consider the bivariate DVEC(1,1) case satisfying

$$
\begin{array}{l} \left[ \begin{array}{c c} \sigma_ {1 1, t} & \\ \sigma_ {2 1, t} & \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c c} A _ {1 1, 0} & \\ A _ {2 1, 0} & A _ {2 2, 0} \end{array} \right] \\ + \left[ \begin{array}{c c} A _ {1 1, 1} & \\ A _ {2 1, 1} & A _ {2 2, 1} \end{array} \right] \odot \left[ \begin{array}{c c} a _ {1, t - 1} ^ {2} & \\ a _ {1, t - 1} a _ {2, t - 1} & a _ {2, t - 1} ^ {2} \end{array} \right] \\ + \left[ \begin{array}{c c} B _ {1 1, 1} & \\ B _ {2 1, 1} & B _ {2 2, 1} \end{array} \right] \odot \left[ \begin{array}{c c} \sigma_ {1 1, t - 1} & \\ \sigma_ {2 1, t - 1} & \sigma_ {2 2, t - 1} \end{array} \right], \\ \end{array}
$$

where only the lower triangular part of the model is given. Specifically, the model is

$$
\sigma_ {1 1, t} = A _ {1 1, 0} + A _ {1 1, 1} a _ {1, t - 1} ^ {2} + B _ {1 1, 1} \sigma_ {1 1, t - 1},
$$

$$
\sigma_ {2 1, t} = A _ {2 1, 0} + A _ {2 1, 1} a _ {1, t - 1} a _ {2, t - 1} + B _ {2 1, 1} \sigma_ {2 1, t - 1},
$$

$$
\sigma_ {2 2, t} = A _ {2 2, 0} + A _ {2 2, 1} a _ {2, t - 1} ^ {2} + B _ {2 2, 1} \sigma_ {2 2, t - 1},
$$

where each element of $\Sigma _ { t }$ depends only on its own past value and the corresponding product term in $\pmb { a } _ { t - 1 } \pmb { a } _ { t - 1 } ^ { \prime }$ . That is, each element of a DVEC model follows a GARCH(1,1) type model. The model is, therefore, simple. However, it may not

![](images/e839d39a733b39af0ba37491f958ebd7864e4f50631ea60b0c5f7dfc81ff3797.jpg)

![](images/5e5a29c3480ded7c961b9e282ece91899044d091c11d0de87ce52b5079fedd3e.jpg)  
Figure 10.4. Time plot of monthly simple returns, including dividends, for Pfizer and Merck stocks from January 1965 to December 2003: (a) Pfizer stock and (b) Merck stock.

produce a positive-definite covariance matrix. Furthermore, the model does not allow for dynamic dependence between volatility series.

Example 10.2. For illustration, consider the monthly simple returns, including dividends, of two major drug companies from January 1965 to December 2003 for 468 observations. Let $r _ { 1 t }$ be the return series of Pfizer stock and $r _ { 2 t }$ the return of Merck stock. The bivariate return series $\pmb { r } _ { t } = ( r _ { 1 t } , r _ { 2 t } ) ^ { \prime }$ , shown in Figure 10.4, has no significant serial correlations. Therefore, the mean equation of $r _ { t }$ consists of a constant term only. We fit a DVEC(1,1) model to the series using the command mgarch in FinMetrics of S-Plus:

```matlab
> rtn=cbind(pfe,mrk) % Output edited.  
> drug.dvec=mgarch(rtn~1,~dvec(1,1))  
> summary(drug.dvec)  
Call:  
mgarch(formula.mean = rtn ~ 1, formula.var = ~ dvec(1, 1))  
Mean Equation: rtn ~ 1  
Conditional Variance Equation: ~ dvec(1, 1)  
Conditional Distribution: gaussian  
Estimated Coefficients:  
Value Std.Error t value Pr(>|t|) 
```

<table><tr><td></td><td>C(1)</td><td>0.0164424</td><td>3.422e-03</td><td>4.805</td><td>1.047e-06</td></tr><tr><td></td><td>C(2)</td><td>0.0150987</td><td>3.139e-03</td><td>4.810</td><td>1.025e-06</td></tr><tr><td></td><td>A(1, 1)</td><td>0.0008181</td><td>4.348e-04</td><td>1.881</td><td>3.027e-02</td></tr><tr><td></td><td>A(2, 1)</td><td>0.0001021</td><td>4.979e-05</td><td>2.050</td><td>2.048e-02</td></tr><tr><td></td><td>A(2, 2)</td><td>0.0001408</td><td>7.067e-05</td><td>1.992</td><td>2.348e-02</td></tr><tr><td colspan="2">ARCH (1; 1, 1)</td><td>0.0727734</td><td>2.973e-02</td><td>2.448</td><td>7.363e-03</td></tr><tr><td colspan="2">ARCH (1; 2, 1)</td><td>0.0259816</td><td>9.537e-03</td><td>2.724</td><td>3.343e-03</td></tr><tr><td colspan="2">ARCH (1; 2, 2)</td><td>0.0518917</td><td>1.753e-02</td><td>2.961</td><td>1.614e-03</td></tr><tr><td colspan="2">GARCH (1; 1, 1)</td><td>0.7777585</td><td>9.525e-02</td><td>8.165</td><td>1.554e-15</td></tr><tr><td colspan="2">GARCH (1; 2, 1)</td><td>0.9407037</td><td>2.191e-02</td><td>42.928</td><td>0.000e+00</td></tr><tr><td colspan="2">GARCH (1; 2, 2)</td><td>0.9203388</td><td>2.684e-02</td><td>34.296</td><td>0.000e+00</td></tr></table>

<table><tr><td colspan="4">Ljung-Box test for standardized residuals:</td></tr><tr><td>Statistic</td><td>P-value</td><td>Chi^2-d.f.</td><td></td></tr><tr><td>pfe</td><td>10.07</td><td>0.6096</td><td>12</td></tr><tr><td>mrk</td><td>14.91</td><td>0.2461</td><td>12</td></tr></table>

<table><tr><td colspan="5">Ljung-Box test for squared standardized residuals: 
Statistic P-value Chi^2-d.f.</td></tr><tr><td>pfe</td><td>18.30</td><td>0.1068</td><td>12</td><td></td></tr><tr><td>mrk</td><td>5.04</td><td>0.9566</td><td>12</td><td></td></tr><tr><td colspan="5">&gt; names(drug.dvec)</td></tr><tr><td>[1]</td><td>&quot;residuals&quot;</td><td>&quot;sigma.t&quot;</td><td>&quot;df.residual&quot;</td><td>&quot;coef&quot;</td></tr><tr><td>[5]</td><td>&quot;model&quot;</td><td>&quot;cond.dist&quot;</td><td>&quot;likelihood&quot;</td><td>&quot;opt.index&quot;</td></tr><tr><td>[9]</td><td>&quot;cov&quot;</td><td>&quot;std.residuals&quot;</td><td>&quot;R.t&quot;</td><td>&quot;S.t&quot;</td></tr><tr><td>[13]</td><td>&quot;prediction&quot;</td><td>&quot;call&quot;</td><td>&quot;series&quot;</td><td></td></tr></table>

From the output, all parameter estimates are significant at the $5 \%$ level, and the fitted volatility model is

$$
\sigma_ {1 1, t} = 0. 0 0 0 8 2 + 0. 0 7 3 a _ {1, t - 1} ^ {2} + 0. 7 7 8 \sigma_ {1 1, t - 1},
$$

$$
\sigma_ {2 1, t} = 0. 0 0 0 1 0 + 0. 0 2 6 a _ {1, t - 1} a _ {2, t - 1} + 0. 9 4 1 \sigma_ {2 1, t - 1},
$$

$$
\sigma_ {2 2, t} = 0. 0 0 0 1 4 + 0. 0 5 2 a _ {2, t - 1} ^ {2} + 0. 9 2 0 \sigma_ {2 2, t - 1}.
$$

The output also provides some model checking statistics for individual stock returns. For instance, the Ljung–Box statistics for the standardized residual series and its squared series of Pfizer stock returns give $Q ( 1 2 ) = 1 0 . 0 7 ( 0 . 6 1 )$ and $Q ( 1 2 ) =$ 18.30(0.11), respectively, where the number in parentheses denotes $p$ -value. Thus, checking the fitted model individually, one cannot reject the DVEC(1,1) model. A more informative model checking approach is to apply the multivariate $Q$ -statistics to the bivariate standardized residual series and its squared process. For this particular DVEC(1,1) model, we have $Q _ { 2 } ( 1 0 ) = 4 2 . 0 4 ( 0 . 3 8 )$ and $Q _ { 2 } ^ { * } ( 1 0 ) = 6 7 . 3 3 ( 0 . 0 0 4 )$ , respectively, where $Q _ { 2 } ^ { * }$ denotes the $Q$ -statistics for the bivariate squared residual series. Based on bivariate statistics, the mean equation is adequate at the $5 \%$ significance level, but the DVEC(1,1) model is rejected for the volatility at the $1 \%$ level. Figure 10.5 shows the fitted volatility and correlation series. These series are stored

![](images/0aebb5fce20f819279f9b4a8111ee5925fd77a9ee379b0d5aca9737bc8260867.jpg)

![](images/07c5631d6672b6bad53668672c6f63ee95bee601d0a4a2b7c165822f86707870.jpg)

![](images/873e6afa2bfa76c6d66ed10dc9c44630c816a84599ffefb547ab353bc1fe4bec.jpg)  
Figure 10.5. Estimated volatilities (standard error) and time-varying correlations of a DVEC(1,1) model for monthly simple returns of two major drug companies from January 1965 to December 2003: (a) Pfizer stock volatility, (b) Merck stock volatility, and (c) time-varying correlations.

in ‘‘sigma.t’’ and ‘‘R.t’’, respectively. The correlations range from 0.42 to 0.84.

# 10.2.2 BEKK Model

To guarantee the positive-definite constraint, Engle and Kroner (1995) propose the BEKK model,

$$
\boldsymbol {\Sigma} _ {t} = \boldsymbol {A} \boldsymbol {A} ^ {\prime} + \sum_ {i = 1} ^ {m} \boldsymbol {A} _ {i} \left(\boldsymbol {a} _ {t - i} \boldsymbol {a} _ {t - i} ^ {\prime}\right) \boldsymbol {A} _ {i} ^ {\prime} + \sum_ {j = 1} ^ {s} \boldsymbol {B} _ {j} \boldsymbol {\Sigma} _ {t - j} \boldsymbol {B} _ {j} ^ {\prime}, \tag {10.6}
$$

where $A$ is a lower triangular matrix and $A _ { i }$ and $B _ { j }$ are $k \times k$ matrices. Based on the symmetric parameterization of the model, $\Sigma _ { t }$ is almost surely positive definite provided that $A A ^ { \prime }$ is positive definite. This model also allows for dynamic

dependence between the volatility series. On the other hand, the model has several disadvantages. First, the parameters in $A _ { i }$ and $B _ { j }$ do not have direct interpretations concerning lagged values of volatilities or shocks. Second, the number of parameters employed is $k ^ { 2 } ( m + s ) + k ( k + 1 ) / 2$ , which increases rapidly with m and $s$ . Limited experience shows that many of the estimated parameters are statistically insignificant, introducing additional complications in modeling.

Example 10.3. To illustrate, we consider the monthly simple returns of Pfizer and Merck stocks of Example 10.2 and employ a BEKK(1,1) model. Again, S-Plus is used to perform the estimation:

```txt
> drug.bekk=mgarch(rtn~1,~bekk(1,1))  
> summary(drug.bekk)  
Call:  
mgarch(formula.mean = rtn ~ 1, formula.var = ~bekk(1, 1))  
Mean Equation: rtn ~ 1  
Conditional Variance Equation: ~bekk(1, 1)  
Conditional Distribution: gaussian 
```

```csv
Estimated Coefficients:  
Value Std.Error t value Pr(>|t|)  
C(1) 0.0164770 0.003470 4.749e+00 1.369e-06  
C(2) 0.0142816 0.003172 4.503e+00 4.255e-06  
A(1, 1) 0.0245803 0.008837 2.782e+00 2.815e-03  
A(2, 1) 0.0116134 0.005953 1.951e+00 2.584e-02  
A(2, 2) 0.0002018 0.267625 7.541e-04 4.997e-01  
ARCH(1; 1, 1) 0.2994052 0.093304 3.209e+00 7.125e-04  
ARCH(1; 2, 1) 0.1952856 0.075092 2.601e+00 4.802e-03  
ARCH(1; 1, 2) -0.0818745 0.097810 -8.371e-01 2.015e-01  
ARCH(1; 2, 2) 0.0929540 0.082626 1.125e+00 1.306e-01  
GARCH(1; 1, 1) 0.8987843 0.074407 1.208e+01 0.000e+00  
GARCH(1; 2, 1) -0.0674587 0.059595 -1.132e+00 1.291e-01  
GARCH(1; 1, 2) 0.0163848 0.046402 3.531e-01 3.621e-01  
GARCH(1; 2, 2) 0.9889547 0.040158 2.463e+01 0.000e+00
```

```txt
Ljung-Box test for standardized residuals: Statistic P-value Chi^2-d.f.  
pfe 10.13 0.6044 12  
mrk 15.25 0.2278 12 
```

```txt
Ljung-Box test for squared standardized residuals: Statistic P-value Chi^2-d.f.  
pfe 18.314 0.1065 12  
mrk 7.174 0.8459 12 
```

Model checking statistics based on the individual residual series and provided by S-Plus fail to suggest any model inadequacy of the fitted BEKK(1,1) model. Using the bivariate standardized residuals, we have $Q _ { 2 } ( 1 0 ) = 4 1 . 5 7 ( 0 . 4 0 )$ and

![](images/11d7f33608f5875e444cef4eacb324a57426131ea04107195d91b1db60222239.jpg)

![](images/b59efad1b4889f63dadbfb49937fda3e5a5664dbd6e4fe647e4a1df20238ca81.jpg)

![](images/f8882fc0d413f2b1033abf8196af8666dd51967df4ccf054007bd624cb92b8ab.jpg)  
Figure 10.6. Estimated volatilities (standard error) and time-varying correlations of a BEKK(1,1) model for monthly simple returns of two major drug companies from January 1965 to December 2003: (a) Pfizer stock volatility, (b) Merck stock volatility, and (c) time-varying correlations.

$Q _ { 2 } ^ { * } ( 1 0 ) = 6 5 . 7 1 ( 0 . 0 0 6 )$ . Thus, similar to the DVEC(1,1) case, the Ljung–Box statistics also reject the volatility model at the $1 \%$ significance level. Figure 10.6 shows the fitted volatilities and the time-varying correlations of the BEKK(1,1) model. Compared with Figure 10.5, there are some differences between the two fitted volatility models. For instance, the time-varying correlations of the BEKK(1,1) model appear to be more volatile.

The volatility equation of the fitted BEKK(1,1) model is

$$
\begin{array}{l} \left[ \begin{array}{l l} \sigma_ {1 1, t} & \sigma_ {1 2, t} \\ \sigma_ {2 1, t} & \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{l l} 0. 0 2 5 & 0 \\ 0. 0 1 2 & 0. 0 0 0 2 \end{array} \right] \left[ \begin{array}{l l} 0. 0 2 5 & 0. 0 1 2 \\ 0 & 0. 0 0 0 2 \end{array} \right] \\ + \left[ \begin{array}{l l} 0. 2 9 9 & - 0. 0 8 2 \\ 0. 1 9 5 & 0. 0 9 3 \end{array} \right] \left[ \begin{array}{l l} a _ {1, t - 1} ^ {2} & a _ {1, t - 1} a _ {2, t - 1} \\ a _ {2, t - 1} a _ {1, t - 1} & a _ {2, t - 1} ^ {2} \end{array} \right] \left[ \begin{array}{l l} 0. 2 9 9 & 0. 1 9 5 \\ - 0. 0 8 2 & 0. 0 9 3 \end{array} \right] \\ + \left[ \begin{array}{c c} 0. 8 9 9 & 0. 0 1 6 \\ - 0. 0 6 7 & 0. 9 8 9 \end{array} \right] \left[ \begin{array}{c c} \sigma_ {1 1, t - 1} & \sigma_ {1 2, t - 1} \\ \sigma_ {2 1, t - 1} & \sigma_ {2 2, t - 1} \end{array} \right] \left[ \begin{array}{c c} 0. 8 9 9 & - 0. 0 6 7 \\ 0. 0 1 6 & 0. 9 8 9 \end{array} \right], \\ \end{array}
$$

where six estimates are insignificant at the $5 \%$ level. In particular, the constant matrix A contains only a single significant parameter. Furthermore, one needs to perform matrix multiplication to decipher the fitted model.

# 10.3 REPARAMETERIZATION

A useful step in multivariate volatility modeling is to reparameterize $\Sigma _ { t }$ by making use of its symmetric property. We consider two reparameterizations.

# 10.3.1 Use of Correlations

The first reparameterization of $\Sigma _ { t }$ is to use the conditional correlation coefficients and variances of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ . Specifically, we write $\Sigma _ { t }$ as

$$
\boldsymbol {\Sigma} _ {t} \equiv \left[ \sigma_ {i j, t} \right] = \boldsymbol {D} _ {t} \boldsymbol {\rho} _ {t} \boldsymbol {D} _ {t}, \tag {10.7}
$$

where $\pmb { \rho } _ { t }$ is the conditional correlation matrix of $\pmb { a } _ { t }$ , and $\mathbf { } D _ { t }$ is a $k \times k$ diagonal matrix consisting of the conditional standard deviations of elements of $\pmb { a } _ { t }$ (i.e., ${ \pmb { D } } _ { t } = \mathrm { d i a g } \{ \sqrt { \sigma _ { 1 1 , t } } , . . . , \sqrt { \sigma _ { k k , t } } \} )$ .

Because $\pmb { \rho } _ { t }$ is symmetric with unit diagonal elements, the time evolution of $\Sigma _ { t }$ is governed by that of the conditional variances $\sigma _ { i i , t }$ and the elements $\rho _ { i j , t }$ of $\pmb { \rho } _ { t }$ , where $j < i$ and $1 \leq i \leq k$ . Therefore, to model the volatility of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi$ , it suffices to consider the conditional variances and correlation coefficients of $a _ { i t }$ . Define the $k ( k + 1 ) / 2$ -dimensional vector

$$
\Xi_ {t} = \left(\sigma_ {1 1, t}, \dots , \sigma_ {k k, t}, \varrho_ {t} ^ {\prime}\right) ^ {\prime}, \tag {10.8}
$$

where $\varrho _ { t }$ is a $k ( k - 1 ) / 2$ -dimensional vector obtained by stacking columns of the correlation matrix $\pmb { \rho } _ { t }$ , but using only elements below the main diagonal. Specifically, for a $k$ -dimensional return series,

$$
\varrho_ {t} = \left(\rho_ {2 1, t}, \dots , \rho_ {k 1, t} \mid \rho_ {3 2, t}, \dots , \rho_ {k 2, t} \mid \dots \mid \rho_ {k, k - 1, t}\right) ^ {\prime}.
$$

To illustrate, for $k = 2$ , we have $\varrho _ { t } = \rho _ { 2 1 , t }$ and

$$
\Xi_ {t} = \left(\sigma_ {1 1, t}, \sigma_ {2 2, t}, \rho_ {2 1, t}\right) ^ {\prime}, \tag {10.9}
$$

which is a three-dimensional vector, and for $k = 3$ , we have $\pmb { \varrho } _ { t } = ( \rho _ { 2 1 , t } , \rho _ { 3 1 , t } , \rho _ { 3 2 , t } ) ^ { \prime }$ and

$$
\Xi_ {t} = \left(\sigma_ {1 1, t}, \sigma_ {2 2, t}, \sigma_ {3 3, t}, \rho_ {2 1, t}, \rho_ {3 1, t}, \rho_ {3 2, t}\right) ^ {\prime}, \tag {10.10}
$$

which is a six-dimensional random vector.

If $\pmb { a } _ { t }$ is a bivariate normal random variable, then $\Xi _ { t }$ is given in Eq. (10.9) and the conditional density function of $\pmb { a } _ { t }$ given $\boldsymbol { F } _ { t - 1 }$ is

$$
f \left(a _ {1 t}, a _ {2 t} \mid \overline {{\boldsymbol {\Xi}}} _ {t}\right) = \frac {1}{2 \pi \sqrt {\sigma_ {1 1 , t} \sigma_ {2 2 , t} \left(1 - \rho_ {2 1 , t} ^ {2}\right)}} \exp \left(- \frac {Q \left(a _ {1 t} , a _ {2 t} , \overline {{\boldsymbol {\Xi}}} _ {t}\right)}{2 \left(1 - \rho_ {2 1 , t} ^ {2}\right)}\right),
$$

where

$$
Q \left(a _ {1 t}, a _ {2 t}, \vec {\Xi} _ {t}\right) = \frac {a _ {1 t} ^ {2}}{\sigma_ {1 1 , t}} + \frac {a _ {2 t} ^ {2}}{\sigma_ {2 2 , t}} - \frac {2 \rho_ {2 1 , t} a _ {1 t} a _ {2 t}}{\sqrt {\sigma_ {1 1 , t} \sigma_ {2 2 , t}}}.
$$

The log probability density function of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ relevant to the maximum likelihood estimation is

$$
\begin{array}{l} \ell \left(a _ {1 t}, a _ {2 t}, \boldsymbol {\Xi} _ {t}\right) \\ = - \frac {1}{2} \left\{\ln \left[ \sigma_ {1 1, t} \sigma_ {2 2, t} \left(1 - \rho_ {2 1, t} ^ {2}\right) \right] + \frac {1}{1 - \rho_ {2 1 , t} ^ {2}} \left(\frac {a _ {1 t} ^ {2}}{\sigma_ {1 1 , t}} + \frac {a _ {2 t} ^ {2}}{\sigma_ {2 2 , t}} - \frac {2 \rho_ {2 1 , t} a _ {1 t} a _ {2 t}}{\sqrt {\sigma_ {1 1 , t} \sigma_ {2 2 , t}}}\right) \right\}. \tag {10.11} \\ \end{array}
$$

This reparameterization is useful because it models covariances and correlations directly. Yet the approach has several weaknesses. First, the likelihood function becomes complicated when $k \geq 3$ . Second, the approach requires a constrained maximization in estimation to ensure the positive definiteness of $\Sigma _ { t }$ . The constraint becomes complicated when $k$ is large.

# 10.3.2 Cholesky Decomposition

The second reparameterization of $\Sigma _ { t }$ is to use the Cholesky decomposition; see Appendix A of Chapter 8. This approach has some advantages in estimation as it requires no parameter constraints for the positive definiteness of $\Sigma _ { t }$ ; see Pourahmadi (1999). In addition, the reparameterization is an orthogonal transformation so that the resulting likelihood function is extremely simple. Details of the transformation are given next.

Because $\Sigma _ { t }$ is positive definite, there exist a lower triangular matrix $\mathbf { } L _ { t }$ with unit diagonal elements and a diagonal matrix $\mathbf { } G _ { t }$ with positive diagonal elements such that

$$
\boldsymbol {\Sigma} _ {t} = \boldsymbol {L} _ {t} \boldsymbol {G} _ {t} \boldsymbol {L} _ {t} ^ {\prime}. \tag {10.12}
$$

This is the well-known Cholesky decomposition of $\Sigma _ { t }$ . A feature of the decomposition is that the lower off-diagonal elements of $\scriptstyle { L _ { t } }$ and the diagonal elements of $\mathbf { } G _ { t }$ have nice interpretations. We demonstrate the decomposition by studying carefully the bivariate and three-dimensional cases. For the bivariate case, we have

$$
\boldsymbol {\Sigma} _ {t} = \left[ \begin{array}{c c} \sigma_ {1 1, t} & \sigma_ {2 1, t} \\ \sigma_ {2 1, t} & \sigma_ {2 2, t} \end{array} \right], \quad \boldsymbol {L} _ {t} = \left[ \begin{array}{c c} 1 & 0 \\ q _ {2 1, t} & 1 \end{array} \right], \quad \boldsymbol {G} _ {t} = \left[ \begin{array}{c c} g _ {1 1, t} & 0 \\ 0 & g _ {2 2, t} \end{array} \right],
$$

where $g _ { i i , t } > 0$ for $i = 1$ and 2. Using Eq. (10.12), we have

$$
\boldsymbol {\Sigma} _ {t} = \left[ \begin{array}{c c} \sigma_ {1 1, t} & \sigma_ {1 2, t} \\ \sigma_ {1 2, t} & \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c c} g _ {1 1, t} & q _ {2 1, t} g _ {1 1, t} \\ q _ {2 1, t} g _ {1 1, t} & g _ {2 2, t} + q _ {2 1, t} ^ {2} g _ {1 1, t} \end{array} \right].
$$

Equating elements of the prior matrix equation, we obtain

$$
\sigma_ {1 1, t} = g _ {1 1, t}, \quad \sigma_ {2 1, t} = q _ {2 1, t} g _ {1 1, t}, \quad \sigma_ {2 2, t} = g _ {2 2, t} + q _ {2 1, t} ^ {2} g _ {1 1, t}. \tag {10.13}
$$

Solving the prior equations, we have

$$
g _ {1 1, t} = \sigma_ {1 1, t}, \quad q _ {2 1, t} = \frac {\sigma_ {2 1 , t}}{\sigma_ {1 1 , t}}, \quad g _ {2 2, t} = \sigma_ {2 2, t} - \frac {\sigma_ {2 1 , t} ^ {2}}{\sigma_ {1 1 , t}}. \tag {10.14}
$$

However, consider the simple linear regression

$$
a _ {2 t} = \beta a _ {1 t} + b _ {2 t}, \tag {10.15}
$$

where $b _ { 2 t }$ denotes the error term. From the well-known least squares theory, we have

$$
\beta = \frac {\operatorname {C o v} (a _ {1 t} , a _ {2 t})}{\operatorname {V a r} (a _ {1 t})} = \frac {\sigma_ {2 1 , t}}{\sigma_ {1 1 , t}},
$$

$$
\operatorname {V a r} \left(b _ {2 t}\right) = \operatorname {V a r} \left(a _ {2 t}\right) - \beta^ {2} \operatorname {V a r} \left(a _ {1 t}\right) = \sigma_ {2 2, t} - \frac {\sigma_ {2 1 , t} ^ {2}}{\sigma_ {1 1 , t}}.
$$

Furthermore, the error term $b _ { 2 t }$ is uncorrelated with the regressor $a _ { 1 t }$ . Consequently, using Eq. (10.14), we obtain

$$
g _ {1 1, t} = \sigma_ {1 1, t}, \quad q _ {2 1, t} = \beta , \quad g _ {2 2, t} = \operatorname {V a r} (b _ {2 t}), \quad b _ {2 t} \perp a _ {1 t},
$$

where $\perp$ denotes no correlation. In summary, the Cholesky decomposition of the $2 \times 2$ matrix $\Sigma _ { t }$ amounts to performing an orthogonal transformation from $\pmb { a } _ { t }$ to $\pmb { b } _ { t } = ( b _ { 1 t } , b _ { 2 t } ) ^ { \prime }$ such that

$$
b _ {1 t} = a _ {1 t} \quad \text {a n d} \quad b _ {2 t} = a _ {2 t} - q _ {2 1, t} a _ {1 t},
$$

where $q _ { 2 1 , t } = \beta$ is obtained by the linear regression (10.15) and $\operatorname { C o v } ( \pmb { b } _ { t } )$ is a diagonal matrix with diagonal elements $g _ { i i , t }$ . The transformed quantities $q _ { 2 1 , t }$ and $g _ { i i , t }$ can be interpreted as follows:

1. The first diagonal element of $\mathbf { } G _ { t }$ is simply the variance of $a _ { 1 t }$   
2. The second diagonal element of $\mathbf { } G _ { t }$ is the residual variance of the simple linear regression in Eq. (10.15).

3. The element $q _ { 2 1 , t }$ of the lower triangular matrix $\mathbf { } L _ { t }$ is the coefficient $\beta$ of the regression in Eq. (10.15).

The prior properties continue to hold for the higher dimensional case. For example, consider the three-dimensional case in which

$$
\boldsymbol {L} _ {t} = \left[ \begin{array}{c c c} 1 & 0 & 0 \\ q _ {2 1, t} & 1 & 0 \\ q _ {3 1, t} & q _ {3 2, t} & 1 \end{array} \right], \quad \boldsymbol {G} _ {t} = \left[ \begin{array}{c c c} g _ {1 1, t} & 0 & 0 \\ 0 & g _ {2 2, t} & 0 \\ 0 & 0 & g _ {3, t} \end{array} \right].
$$

From the decomposition in Eq. (10.12), we have

$$
\begin{array}{l} \left[ \begin{array}{c c c} \sigma_ {1 1, t} & \sigma_ {2 1, t} & \sigma_ {3 1, t} \\ \sigma_ {2 1, t} & \sigma_ {2 2, t} & \sigma_ {3 2, t} \\ \sigma_ {3 1, t} & \sigma_ {3 2, t} & \sigma_ {3 3, t} \end{array} \right] = \\ \left[ \begin{array}{c c c} g _ {1 1, t} & q _ {2 1, t} g _ {1 1, t} & q _ {3 1, t} g _ {1 1, t} \\ q _ {2 1, t} g _ {1 1, t} & q _ {2 1, t} ^ {2} g _ {1 1, t} + g _ {2 2, t} & q _ {3 1, t} q _ {2 1, t} g _ {1 1, t} + q _ {3 2, t} g _ {2 2, t} \\ q _ {3 1, t} g _ {1 1, t} & q _ {3 1, t} q _ {2 1, t} g _ {1 1, t} + q _ {3 2, t} g _ {2 2, t} & q _ {3 1, t} ^ {2} g _ {1 1, t} + q _ {3 2, t} ^ {2} g _ {2 2, t} + g _ {3 3, t} \end{array} \right]. \\ \end{array}
$$

Equating elements of the prior matrix equation, we obtain

$$
\begin{array}{l} \sigma_ {1 1, t} = g _ {1 1, t}, \quad \sigma_ {2 1, t} = q _ {2 1, t} g _ {1 1, t}, \quad \sigma_ {2 2, t} = q _ {2 1, t} ^ {2} g _ {1 1, t} + g _ {2 2, t}, \quad \sigma_ {3 1, t} = q _ {3 1, t} g _ {1 1, t}, \\ \sigma_ {3 2, t} = q _ {3 1, t} q _ {2 1, t} g _ {1 1, t} + q _ {3 2, t} g _ {2 2, t}, \quad \sigma_ {3 3, t} = q _ {3 1, t} ^ {2} g _ {1 1, t} + q _ {3 2, t} ^ {2} g _ {2 2, t} + g _ {3 3, t} \\ \end{array}
$$

or, equivalently,

$$
\begin{array}{l} g _ {1 1, t} = \sigma_ {1 1, t}, \quad q _ {2 1, t} = \frac {\sigma_ {2 1 , t}}{\sigma_ {1 1 , t}}, \quad g _ {2 2, t} = \sigma_ {2 2, t} - q _ {2 1, t} ^ {2} g _ {1 1, t}, \\ q _ {3 1, t} = \frac {\sigma_ {3 1 , t}}{\sigma_ {1 1 , t}}, \quad q _ {3 2, t} = \frac {1}{g _ {2 2 , t}} \left(\sigma_ {3 2, t} - \frac {\sigma_ {3 1 , t} \sigma_ {2 1 , t}}{\sigma_ {1 1 , t}}\right), \\ g _ {3 3, t} = \sigma_ {3 3, t} - q _ {3 1, t} ^ {2} g _ {1 1, t} - q _ {3 2, t} ^ {2} g _ {2 2, t}. \\ \end{array}
$$

These quantities look complicated, but they are simply the coefficients and residual variances of the orthogonal transformation

$$
b _ {1 t} = a _ {1 t},
$$

$$
b _ {2 t} = a _ {2 t} - \beta_ {2 1} b _ {1 t},
$$

$$
b _ {3 t} = a _ {3 t} - \beta_ {3 1} b _ {1 t} - \beta_ {3 2} b _ {2 t},
$$

where $\beta _ { i j }$ are the coefficients of least squares regressions

$$
a _ {2 t} = \beta_ {2 1} b _ {1 t} + b _ {2 t},
$$

$$
a _ {3 t} = \beta_ {3 1} b _ {1 t} + \beta_ {3 2} b _ {2 t} + b _ {3 t}.
$$

In other words, we have $q _ { i j , t } = \beta _ { i j }$ , $g _ { i i , t } = \mathrm { V a r } ( b _ { i t } )$ and $b _ { i t } \bot b _ { j t }$ for $i \neq j$

Based on the prior discussion, using Cholesky decomposition amounts to doing an orthogonal transformation from $\pmb { a } _ { t }$ to $\mathbf { } _ { \pmb { b } _ { t } }$ , where $b _ { 1 t } = a _ { 1 t }$ , and $b _ { i t }$ , for $1 < i \leq k$ , is defined recursively by the least squares regression

$$
a _ {i t} = q _ {i 1, t} b _ {1 t} + q _ {i 2, t} b _ {2 t} + \dots + q _ {i (i - 1), t} b _ {(i - 1) t} + b _ {i t}, \tag {10.16}
$$

where $q _ { i j , t }$ is the $( i , j ) \mathrm { t h }$ element of the lower triangular matrix $\mathbf { } L _ { t }$ for $1 \le j < i$ . We can write this transformation as

$$
\boldsymbol {b} _ {t} = \boldsymbol {L} _ {t} ^ {- 1} \boldsymbol {a} _ {t}, \quad \text {o r} \quad \boldsymbol {a} _ {t} = \boldsymbol {L} _ {t} \boldsymbol {b} _ {t}, \tag {10.17}
$$

where, as mentioned before, $L _ { t } ^ { - 1 }$ is also a lower triangular matrix with unit diagonal elements. The covariance matrix of $\mathbf { } _ { \pmb { b } _ { t } }$ is the diagonal matrix $\mathbf { } G _ { t }$ of the Cholesky decomposition because

$$
\operatorname {C o v} \left(\boldsymbol {b} _ {t}\right) = \boldsymbol {L} _ {t} ^ {- 1} \boldsymbol {\Sigma} _ {t} \left(\boldsymbol {L} _ {t} ^ {- 1}\right) ^ {\prime} = \boldsymbol {G} _ {t}.
$$

The parameter vector relevant to volatility modeling under such a transformation becomes

$$
\Xi_ {t} = \left(g _ {1 1, t}, \dots , g _ {k k, t}, q _ {2 1, t}, q _ {3 1, t}, q _ {3 2, t}, \dots , q _ {k 1, t}, \dots , q _ {k (k - 1), t}\right) ^ {\prime}, \tag {10.18}
$$

which is also a $k ( k + 1 ) / 2$ -dimensional vector.

The previous orthogonal transformation also dramatically simplifies the likelihood function of the data. Using the fact that $| { \cal L } _ { t } | = 1$ , we have

$$
\left| \boldsymbol {\Sigma} _ {t} \right| = \left| \boldsymbol {L} _ {t} \boldsymbol {G} _ {t} \boldsymbol {L} _ {t} ^ {\prime} \right| = \left| \boldsymbol {G} _ {t} \right| = \prod_ {i = 1} ^ {k} g _ {i i, t}. \tag {10.19}
$$

If the conditional distribution of $\pmb { a } _ { t }$ given the past information is multivariate normal $N ( \mathbf { 0 } , \pmb { \Sigma } _ { t } )$ , then the conditional distribution of the transformed series $\mathbf { } _ { \pmb { b } _ { t } }$ is multivariate normal $N ( \mathbf { 0 } , G _ { t } )$ , and the log likelihood function of the data becomes extremely simple. Indeed, we have the log probability density of $\pmb { a } _ { t }$ as

$$
\ell \left(\boldsymbol {a} _ {t}, \boldsymbol {\Sigma} _ {t}\right) = \ell \left(\boldsymbol {b} _ {t}, \boldsymbol {\Xi} _ {t}\right) = - \frac {1}{2} \sum_ {i = 1} ^ {k} \left(\ln \left(g _ {i i, t}\right) + \frac {b _ {i t} ^ {2}}{g _ {i i , t}}\right), \tag {10.20}
$$

where for simplicity the constant term is omitted and $g _ { i i , t }$ is the variance of $b _ { i t }$ .

Using the Cholesky decomposition to reparameterize $\Sigma _ { t }$ has several advantages. First, from Eq. (10.19), $\Sigma _ { t }$ is positive-definite if $g _ { i i , t } > 0$ for all i. Consequently, the positive-definite constraint of $\Sigma _ { t }$ can easily be achieved by modeling $\ln ( g _ { i i , t } )$ instead of $g _ { i i , t }$ . Second, elements of the parameter vector $\Xi _ { t }$ in Eq. (10.18) have nice interpretations. They are the coefficients and residual variances of multiple

linear regressions that orthogonalize the shocks to the returns. Third, the correlation coefficient between $a _ { 1 t }$ and $a _ { 2 t }$ is

$$
\rho_ {2 1, t} = \frac {\sigma_ {2 1 , t}}{\sqrt {\sigma_ {1 1 , t} \sigma_ {2 2 , t}}} = q _ {2 1, t} \times \frac {\sqrt {\sigma_ {1 1 , t}}}{\sqrt {\sigma_ {2 2 , t}}},
$$

which is time-varying if $q _ { 2 1 , t } \neq 0$ . In particular, if $q _ { 2 1 , t } = c \neq 0$ , then $\rho _ { 2 1 , t } =$ $c \sqrt { \sigma _ { 1 1 , t } } / \sqrt { \sigma _ { 2 2 , t } }$ , which continues to be time-varying provided that the variance ratio $\sigma _ { 1 1 , t } / \sigma _ { 2 2 , t }$ is not a constant. This time-varying property applies to other correlation coefficients when the dimension of $r _ { t }$ is greater than 2 and is a major difference between the two approaches for reparameterizing $\Sigma _ { t }$ .

Using Eq. (10.16) and the orthogonality among the transformed shocks $b _ { i t }$ , we obtain

$$
\sigma_ {i i, t} = \operatorname {V a r} \left(a _ {i t} \mid F _ {t - 1}\right) = \sum_ {v = 1} ^ {i} q _ {i v, t} ^ {2} g _ {v v, t}, \quad i = 1, \dots , k,
$$

$$
\sigma_ {i j, t} = \mathrm {C o v} (a _ {i t}, a _ {j t} | F _ {t - 1}) = \sum_ {v = 1} ^ {j} q _ {i v, t} q _ {j v, t} g _ {v v, t}, \quad j <   i, \quad i = 2, \ldots , k,
$$

where $q _ { v v , t } = 1$ for $v = 1 , \ldots , k$ . These equations show the parameterization of $\Sigma _ { t }$ under the Cholesky decomposition.

# 10.4 GARCH MODELS FOR BIVARIATE RETURNS

Since the same techniques can be used to generalize many univariate volatility models to the multivariate case, we focus our discussion on the multivariate GARCH model. Other multivariate volatility models can also be used.

For a $k$ -dimensional return series $r _ { t }$ , a multivariate GARCH model uses “exact equations” to describe the evolution of the $k ( k + 1 ) / 2$ -dimensional vector $\Xi _ { t }$ over time. By exact equation, we mean that the equation does not contain any stochastic shock. However, the exact equation may become complicated even in the simplest case of $k = 2$ for which $\Xi _ { t }$ is three-dimensional. To keep the model simple, some restrictions are often imposed on the equations.

# 10.4.1 Constant-Correlation Models

To keep the number of volatility equations low, Bollerslev (1990) considers the special case in which the correlation coefficient $\rho _ { 2 1 , t } = \rho _ { 2 1 }$ is time-invariant, where $| \rho _ { 2 1 } | < 1$ . Under such an assumption, $\rho _ { 2 1 }$ is a constant parameter and the volatility model consists of two equations for $\Xi _ { t } ^ { * }$ , which is defined as $\Xi _ { t } ^ { * } = ( \sigma _ { 1 1 , t } , \sigma _ { 2 2 , t } ) ^ { \prime }$ . A GARCH(1,1) model for $\Xi _ { t } ^ { * }$ becomes

$$
\boldsymbol {\Xi} _ {t} ^ {*} = \boldsymbol {\alpha} _ {0} + \boldsymbol {\alpha} _ {1} \boldsymbol {a} _ {t - 1} ^ {2} + \boldsymbol {\beta} _ {1} \boldsymbol {\Xi} _ {t - 1} ^ {*}, \tag {10.21}
$$

where ${ \pmb a } _ { t - 1 } ^ { 2 } = ( a _ { 1 , t - 1 } ^ { 2 } , a _ { 2 , t - 1 } ^ { 2 } ) ^ { \prime }$ , ${ \pmb { \alpha } } _ { 0 }$ is a two-dimensional positive vector, and ${ \pmb { \alpha } } _ { 1 }$ and $\beta _ { 1 }$ are $2 \times 2$ non-negative definite matrices. More specifically, the model can be

expressed in detail as

$$
\left[ \begin{array}{l} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{l} \alpha_ {1 0} \\ \alpha_ {2 0} \end{array} \right] + \left[ \begin{array}{l l} \alpha_ {1 1} & \alpha_ {1 2} \\ \alpha_ {2 1} & \alpha_ {2 2} \end{array} \right] \left[ \begin{array}{l} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] + \left[ \begin{array}{l l} \beta_ {1 1} & \beta_ {1 2} \\ \beta_ {2 1} & \beta_ {2 2} \end{array} \right] \left[ \begin{array}{l} \sigma_ {1 1, t - 1} \\ \sigma_ {2 2, t - 1} \end{array} \right], \tag {10.22}
$$

where $\alpha _ { i 0 } > 0$ for $i = 1$ and 2. Defining $\pmb { \eta } _ { t } = \pmb { a } _ { t } ^ { 2 } - \pmb { \Xi } _ { t } ^ { * }$ , we can rewrite the prior model as

$$
\boldsymbol {a} _ {t} ^ {2} = \alpha_ {0} + (\alpha_ {1} + \beta_ {1}) \boldsymbol {a} _ {t - 1} ^ {2} + \eta_ {t} - \beta_ {1} \eta_ {t - 1},
$$

which is a bivariate ARMA(1,1) model for the ${ \pmb a } _ { t } ^ { 2 }$ process. This result is a direct generalization of the univariate GARCH(1,1) model of Chapter 3. Consequently, some properties of model (10.22) are readily available from those of the bivariate ARMA(1,1) model of Chapter 8. In particular, we have the following results:

1. If all of the eigenvalues of ${ \pmb { \alpha } } _ { 1 } + { \pmb { \beta } } _ { 1 }$ are positive, but less than 1, then the bivariate ARMA(1,1) model for ${ \pmb a } _ { t } ^ { 2 }$ is weakly stationary and, hence, $E ( \pmb { a } _ { t } ^ { 2 } )$ exists. This implies that the shock process $\pmb { a } _ { t }$ of the returns has a positivedefinite unconditional covariance matrix. The unconditional variances of the elements of $\pmb { a } _ { t }$ are $( \sigma _ { 1 } ^ { 2 } , \sigma _ { 2 } ^ { 2 } ) ^ { \prime } = ( I - \alpha _ { 1 } - \beta _ { 1 } ) ^ { - 1 } \pmb { \phi } _ { 0 }$ , and the unconditional covariance between $a _ { 1 t }$ and $a _ { 2 t }$ is $\rho _ { 2 1 } \sigma _ { 1 } \sigma _ { 2 }$ .   
2. If $\alpha _ { 1 2 } = \beta _ { 1 2 } = 0$ , then the volatility of $a _ { 1 t }$ does not depend on the past volatility of $a _ { 2 t }$ . Similarly, if $\alpha _ { 2 1 } = \beta _ { 2 1 } = 0$ , then the volatility of $a _ { 2 t }$ does not depend on the past volatility of $a _ { 1 t }$ .   
3. If both ${ \pmb { \alpha } } _ { 1 }$ and $\beta _ { 1 }$ are diagonal, then the model reduces to two univariate GARCH(1,1) models. In this case, the two volatility processes are not dynamically related.   
4. Volatility forecasts of the model can be obtained by using forecasting methods similar to those of a vector ARMA(1,1) model; see the univariate case in Chapter 3. The 1-step ahead volatility forecast at the forecast origin $h$ is

$$
\Xi_ {h} ^ {*} (1) = \alpha_ {0} + \alpha_ {1} a _ {h} ^ {2} + \beta_ {1} \Xi_ {h} ^ {*}.
$$

For the $\ell$ -step ahead forecast, we have

$$
\Xi_ {h} ^ {*} (\ell) = \boldsymbol {\alpha} _ {0} + (\boldsymbol {\alpha} _ {1} + \boldsymbol {\beta} _ {1}) \Xi_ {h} ^ {*} (\ell - 1), \quad \ell > 1.
$$

These forecasts are for the marginal volatilities of $a _ { i t }$ . The $\ell$ -step ahead forecast of the covariance between $a _ { 1 t }$ and $a _ { 2 t }$ is $\hat { \rho } _ { 2 1 } [ \sigma _ { 1 1 , h } ( \ell ) \sigma _ { 2 2 , h } ( \ell ) ] ^ { 0 . 5 }$ , where $\hat { \rho } _ { 2 1 }$ is the estimate of $\rho _ { 2 1 }$ and $\sigma _ { i i , h } ( { \boldsymbol { \ell } } )$ are the elements of $\Xi _ { h } ^ { * } ( \ell )$ .

Example 10.4. Again, consider the daily log returns of Hong Kong and Japanese markets of Example 10.1. Using bivariate GARCH models, we obtain

two models that fit the data well. The mean equations of the first bivariate model are

$$
r _ {1 t} = - 0. 1 1 8 r _ {1, t - 6} + a _ {1 t},
$$

$$
r _ {2 t} = a _ {2 t},
$$

where the standard error of the AR(6) coefficient is 0.044. The volatility equations of the first model are

$$
\begin{array}{l} \left[ \begin{array}{c} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c} 0. 2 7 5 \\ (0. 0 7 9) \\ 0. 0 5 1 \\ (0. 0 1 4) \end{array} \right] + \left[ \begin{array}{c c} 0. 1 1 2 & \cdot \\ (0. 0 3 2) & \\ \cdot & 0. 0 9 1 \\ & (0. 0 2 6) \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] \\ + \left[ \begin{array}{c c} 0. 7 1 1 & \cdot \\ (0. 0 6 8) & \\ \cdot & 0. 8 6 9 \\ & (0. 0 2 8) \end{array} \right] \left[ \begin{array}{l} \sigma_ {1 1, t - 1} \\ \sigma_ {2 2, t - 1} \end{array} \right], \tag {10.23} \\ \end{array}
$$

where the numbers in parentheses are standard errors. The estimated correlation coefficient between $a _ { 1 t }$ and $a _ { 2 t }$ is 0.226 with standard error 0.047.

Let $\tilde { \pmb { a } } _ { t } = ( \tilde { a } _ { 1 t } , \tilde { a } _ { 2 t } ) ^ { \prime }$ be the standardized residuals, where $\tilde { a } _ { i t } = a _ { i t } / \sqrt { \sigma _ { i i , t } }$ . The Ljung–Box statistics of $\tilde { \pmb { a } } _ { t }$ give $Q _ { 2 } ( 4 ) = 2 2 . 2 9 ( 0 . 1 0 )$ and $Q _ { 2 } ( 8 ) = 3 4 . 8 3 ( 0 . 2 9 )$ , where the number in parentheses denotes $p$ -value. Here the $p$ -values are based on chi-squared distributions with 15 and 31 degrees of freedom, respectively, because an AR(6) coefficient is used in the mean equation. The Ljung–Box statistics for the $\tilde { \mathbf { \Gamma } } _ { t } ^ { 2 }$ process give $\mathcal { Q } _ { 2 } ^ { * } ( 4 ) = 9 . 5 4 ( 0 . 8 5 )$ and $\mathcal { Q } _ { 2 } ^ { * } ( 8 ) = 1 8 . 5 8 ( 0 . 9 6 )$ . Consequently, there are no serial correlations or conditional heteroscedasticities in the bivariate standardized residuals of model (10.23). The unconditional innovational variances of the two residuals are 1.55 and 1.28, respectively, for the Hong Kong and Japanese markets.

The model in Eq. (10.23) shows two uncoupled volatility equations, indicating that the volatilities of the two markets are not dynamically related, but they are contemporaneously correlated. We refer to the model as a bivariate diagonal constant-correlation model. If the minor lag-6 serial correlation of Hong Kong market returns is omitted, then the constant-correlation models can easily be estimated using S-Plus:

$$
\begin{array}{l} > h k j a. c c c = m g a r c h (r t n \sim 1, \sim c c c (1, 1), t r a c e = F) \\ > \text {s u m m a r y} (\text {h k j a . c c c}) \\ \end{array}
$$

The mean equations of the second bivariate GARCH model are

$$
\begin{array}{l} r _ {1 t} = - 0. 1 4 3 r _ {1, t - 6} + a _ {1 t}, \\ r _ {2 t} = a _ {2 t}, \\ \end{array}
$$

where the standard error of the AR(6) coefficient is 0.042, and the volatility equations of the second model are

$$
\begin{array}{l} \left[ \begin{array}{c} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c} 0. 3 7 8 \\ (0. 1 0 3) \\ \cdot \end{array} \right] + \left[ \begin{array}{c c} 0. 1 0 8 & \cdot \\ (0. 0 3 0) \\ \cdot & 0. 1 7 2 \\ & (0. 0 3 5) \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] \\ + \left[ \begin{array}{c c} \cdot & 0. 8 6 5 \\ & (0. 1 0 9) \\ 0. 3 2 1 & 0. 8 6 9 \\ (0. 1 3 5) & (0. 0 2 8) \end{array} \right] \left[ \begin{array}{l} \sigma_ {1 1, t - 1} \\ \sigma_ {2 2, t - 1} \end{array} \right], \tag {10.24} \\ \end{array}
$$

where the numbers in parentheses are standard errors. The estimated correlation coefficient between $a _ { 1 t }$ and $a _ { 2 t }$ is 0.236 with standard error 0.045. Defining the standardized residuals as before, we obtain $Q _ { 2 } ( 4 ) = 2 4 . 2 2 ( 0 . 0 6 )$ and $Q _ { 2 } ( 8 ) = 3 5 . 5 2 ( 0 . 2 6 )$ for the standardized residuals of the prior model and $Q _ { 2 } ^ { * } ( 4 ) =$ 17.45(0.29) and $Q _ { 2 } ^ { * } ( 8 ) = 2 4 . 5 5 ( 0 . 7 9 )$ for the squared standardized residuals. These Ljung–Box statistics are not significant at the $5 \%$ level, and hence the model in Eq. (10.24) is also adequate. The unconditional innovational variances of the prior model are 1.71 and 1.32, respectively, for the Hong Kong and Japanese markets.

In contrast with model (10.23), this second bivariate GARCH(1,1) model shows a feedback relationship between the two markets. It is then interesting to compare the two volatility models. First, the unconditional innovational variances of model (10.24) are closer to those of the univariate models in Eqs. (10.3) and (10.4). Second, Figure 10.7 shows the fitted volatility processes of model (10.23), whereas Figure 10.8 shows those of model (10.24). Because model (10.23) implies no dynamic volatility dependence between the two markets, Figure 10.7 is similar to that of Figure 10.2. In contrast, Figure 10.8 shows evidence of mutual impacts between the two markets. Third, the maximized log likelihood function for model (10.23) is $- 5 3 5 . 1 3$ for $t = 8 , \ldots , 4 6 9$ , whereas that of model (10.24) is $- 5 4 0 . 3 2$ ; see the log probability density function in Eq. (10.11). Therefore, model (10.23) is preferred if one uses the likelihood principle. Finally, because practical implications of the two bivariate volatility models differ dramatically, further investigation is needed to separate them. Such an investigation may use a longer sample period or include more variables (e.g., using some U.S. market returns).

Example 10.5. As a second illustration, consider the monthly log returns, in percentages, of IBM stock and the S&P 500 index from January 1926 to December 1999 used in Chapter 8. Let $r _ { 1 t }$ and $r _ { 2 t }$ be the monthly log returns for IBM stock and the S&P 500 index, respectively. If a constant-correlation GARCH(1,1) model is entertained, we obtain the mean equations

$$
\begin{array}{l} r _ {1 t} = 1. 3 5 1 + 0. 0 7 2 r _ {1, t - 1} + 0. 0 5 5 r _ {1, t - 2} - 0. 1 1 9 r _ {2, t - 2} + a _ {1 t}, \\ r _ {2 t} = 0. 7 0 3 + a _ {2 t}, \\ \end{array}
$$

![](images/56b4d4afd2a455e90835326d1a4ef541539d0f6fcfdec6af4ed4274441fc27f7.jpg)  
(a) Hong Kong

![](images/580fd333ab65bed58fc7bf249b1e525e46fd8600841513ef2cf1b83f7cda6b30.jpg)  
(b) Japan   
Figure 10.7. Estimated volatilities for daily log returns in percentages of stock market indexes for Hong Kong and Japan from January 1, 1996 to October 16, 1997: (a) the Hong Kong market and (b) the Japanese market. The model used is Eq. (10.23).

where standard errors of the parameters in the first equation are 0.225, 0.029, 0.034, and 0.044, respectively, and standard error of the parameter in the second equation is 0.155. The volatility equations are

$$
\begin{array}{l} \left[ \begin{array}{c} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c} 2. 9 8 \\ (0. 5 9) \\ 2. 0 9 \\ (0. 4 7) \end{array} \right] + \left[ \begin{array}{c c} 0. 0 7 9 & \cdot \\ (0. 0 1 3) \\ 0. 0 4 2 & 0. 0 4 5 \\ (0. 0 0 9) & (0. 0 1 0) \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] \\ + \left[ \begin{array}{c c} 0. 8 7 3 & - 0. 0 3 1 \\ (0. 0 2 0) & (0. 0 0 9) \\ - 0. 0 6 6 & 0. 9 1 3 \\ (0. 0 1 5) & (0. 0 1 4) \end{array} \right] \left[ \begin{array}{l} \sigma_ {1 1, t - 1} \\ \sigma_ {2 2, t - 1} \end{array} \right], \tag {10.25} \\ \end{array}
$$

where the numbers in parentheses are standard errors. The constant correlation coefficient is 0.614 with standard error 0.020. Using the standardized residuals, we obtain the Ljung–Box statistics $Q _ { 2 } ( 4 ) = 1 6 . 7 7 ( 0 . 2 1 )$ and $Q _ { 2 } ( 8 ) = 3 2 . 4 0 ( 0 . 3 0 )$ , where the $p$ -values shown in parentheses are obtained from chi-squared distributions with 13 and 29 degrees of freedom, respectively. Here the degrees of

![](images/78473aa9d0fd22dadecde6bd2c8a7f408b7b9fe852f9d72a64edf87ab84e5eba.jpg)

![](images/d403a89f8448e3613ca129520f41774c1fc7a394ccd20604c08d9f769c174f55.jpg)  
Figure 10.8. Estimated volatilities for daily log returns in percentages of stock market indices for Hong Kong and Japan from January 1, 1996 to October 16, 1997: (a) the Hong Kong market and (b) the Japanese market. The model used is Eq. (10.24).

freedom have been adjusted because the mean equations contain three lagged predictors. For the squared standardized residuals, we have $\mathcal { Q } _ { 2 } ^ { * } ( 4 ) = 1 8 . 0 0 ( 0 . 1 6 )$ and $Q _ { 2 } ^ { * } ( 8 ) = 3 9 . 0 9 ( 0 . 1 0 )$ . Therefore, at the $5 \%$ significance level, the standardized residuals $\tilde { \pmb { a } } _ { t }$ have no serial correlations or conditional heteroscedasticities. This bivariate GARCH(1,1) model shows a feedback relationship between the volatilities of the two monthly log returns.

# 10.4.2 Time-Varying Correlation Models

A major drawback of the constant-correlation volatility models is that the correlation coefficient tends to change over time in a real application. Consider the monthly log returns of IBM stock and the S&P 500 index used in Example 10.5. It is hard to justify that the S&P 500 index return, which is a weighted average, can maintain a constant-correlation coefficient with IBM return over the past 70 years. Figure 10.9 shows the sample correlation coefficient between the two monthly log return series using a moving window of 120 observations (i.e., 10 years). The correlation changes over time and appears to be decreasing in recent years. The decreasing trend in correlation is not surprising because the ranking of

![](images/9edac4b25e80d8c361a5cb6c2c3dd5da6cc5aeeb456ce447bf3ab1245bbe5b7a.jpg)  
Figure 10.9. The sample correlation coefficient between monthly log returns of IBM stock and the S&P 500 index. The correlation is computed by a moving window of 120 observations. The sample period is from January 1926 to December 1999.

IBM market capitalization among large U.S. industrial companies has changed in recent years. A Lagrange multiplier statistic was proposed recently by Tse (2000) to test constant-correlation coefficients in a multivariate GARCH model.

A simple way to relax the constant-correlation constraint within the GARCH framework is to specify an exact equation for the conditional correlation coefficient. This can be done by two methods using the two reparameterizations of $\Sigma _ { t }$ discussed in Section 10.3. First, we use the correlation coefficient directly. Because the correlation coefficient between the returns of IBM stock and S&P 500 index is positive and must be in the interval [0, 1], we employ the equation

$$
\rho_ {2 1, t} = \frac {\exp \left(q _ {t}\right)}{1 + \exp \left(q _ {t}\right)}, \tag {10.26}
$$

where

$$
q _ {t} = \varpi_ {0} + \varpi_ {1} \rho_ {2 1, t - 1} + \varpi_ {2} \frac {a _ {1 , t - 1} a _ {2 , t - 1}}{\sqrt {\sigma_ {1 1 , t - 1} \sigma_ {2 2 , t - 1}}},
$$

where $\sigma _ { i i , t - 1 }$ is the conditional variance of the shock $a _ { i , t - 1 }$ . We refer to this equation as a GARCH(1,1) model for the correlation coefficient because it uses the lag-1 cross-correlation and the lag-1 cross-product of the two shocks. If $\varpi _ { 1 } = \varpi _ { 2 } = 0$ , then model (10.26) reduces to the case of constant correlation.

In summary, a time-varying correlation bivariate GARCH(1,1) model consists of two sets of equations. The first set of equations consists of a bivariate GARCH(1,1) model for the conditional variances and the second set of equation is a GARCH(1,1) model for the correlation in Eq. (10.26). In practice, a negative sign can be added to Eq. (10.26) if the correlation coefficient is negative. In general, when the sign of correlation is unknown, we can use the Fisher transformation for correlation

$$
q _ {t} = \ln \left(\frac {1 + \rho_ {2 1 , t}}{1 - \rho_ {2 1 , t}}\right) \quad \text {o r} \quad \rho_ {2 1, t} = \frac {\exp (q _ {t}) - 1}{\exp (q _ {t}) + 1}
$$

and employ a GARCH model for $q _ { t }$ to model the time-varying correlation between two returns.

Example 10.5 (Continued). Augmenting Eq. (10.26) to the GARCH(1,1) model in Eq. (10.25) for the monthly log returns of IBM stock and the S&P 500 index and performing a joint estimation, we obtain the following model for the two series:

$$
\begin{array}{l} r _ {1 t} = 1. 3 1 8 + 0. 0 7 6 r _ {1, t - 1} - 0. 0 6 8 r _ {2, t - 2} + a _ {1 t}, \\ r _ {2 t} = 0. 6 7 3 + a _ {2 t}, \\ \end{array}
$$

where standard errors of the three parameters in the first equation are 0.215, 0.026, and 0.034, respectively, and standard error of the parameter in the second equation is 0.151. The volatility equations are

$$
\begin{array}{l} \left[ \begin{array}{l} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{l} 2. 8 0 \\ (0. 5 8) \\ 1. 7 1 \\ (0. 4 0) \end{array} \right] + \left[ \begin{array}{c c} 0. 0 8 4 & \cdot \\ (0. 0 1 3) & \\ 0. 0 3 7 & 0. 0 5 4 \\ (0. 0 0 9) & (0. 0 1 0) \end{array} \right] \left[ \begin{array}{l} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] \\ + \left[ \begin{array}{c c} 0. 8 6 4 & - 0. 0 2 0 \\ (0. 0 2 1) & (0. 0 0 9) \\ - 0. 0 5 8 & 0. 9 1 4 \\ (0. 0 1 4) & (0. 0 1 3) \end{array} \right] \left[ \begin{array}{l} \sigma_ {1 1, t - 1} \\ \sigma_ {2 2, t - 1} \end{array} \right], \tag {10.27} \\ \end{array}
$$

where, as before, standard errors are in parentheses. The conditional correlation equation is

$$
\rho_ {t} = \frac {\exp \left(q _ {t}\right)}{1 + \exp \left(q _ {t}\right)}, \quad q _ {t} = - 2. 0 2 4 + 3. 9 8 3 \rho_ {t - 1} + 0. 0 8 8 \frac {a _ {1 , t - 1} a _ {2 , t - 1}}{\sqrt {\sigma_ {1 1 , t - 1} \sigma_ {2 2 , t - 1}}}, \tag {10.28}
$$

where standard errors of the estimates are 0.050, 0.090, and 0.019, respectively. The parameters of the prior correlation equation are highly significant. Applying the Ljung–Box statistics to the standardized residuals $\tilde { \pmb { a } } _ { t }$ , we have $Q _ { 2 } ( 4 ) =$ 20.57(0.11) and $Q _ { 2 } ( 8 ) = 3 6 . 0 8 ( 0 . 2 1 )$ . For the squared standardized residuals, we have $Q _ { 2 } ^ { * } ( 4 ) = 1 6 . 6 9 ( 0 . 2 7 )$ and $Q _ { 2 } ^ { * } ( 8 ) = 3 6 . 7 1 ( 0 . 1 9 )$ . Therefore, the standardized

residuals of the model have no significant serial correlations or conditional heteroscedasticities.

It is interesting to compare this time-varying correlation GARCH(1,1) model with the constant-correlation GARCH(1,1) model in Eq. (10.25). First, the mean and volatility equations of the two models are close. Second, Figure 10.10 shows the fitted conditional-correlation coefficient between the monthly log returns of IBM stock and the S&P 500 index based on model (10.28). The plot shows that the correlation coefficient fluctuated over time and became smaller in recent years. This latter characteristic is in agreement with that of Figure 10.9. Third, the average of the fitted correlation coefficients is 0.612, which is essentially the estimate 0.614 of the constant-correlation model in Eq. (10.25). Fourth, using the sample variances of $r _ { i t }$ as the starting values for the conditional variances and the observations from $t = 4$ to $t = 8 8 8$ , the maximized log likelihood function is $- 3 6 9 1 . 2 1 $ for the constant-correlation GARCH(1,1) model and $- 3 6 7 9 . 6 4$ for the time-varying correlation GARCH(1,1) model. Thus, the time-varying correlation model shows some significant improvement over the constant-correlation model. Finally, consider the 1-step ahead volatility forecasts of the two models at the forecast origin $h = 8 8 8$ . For the constant-correlation model in Eq. (10.25), we have $a _ { 1 , 8 8 8 } = 3 . 0 7 5$ , $a _ { 2 , 8 8 8 } = 4 . 9 3 1$ , $\sigma _ { ^ { 1 1 , 8 8 8 } } = 7 7 . 9 1$ , and $\sigma _ { ^ { 2 2 , 8 8 8 } } = 2 1 . 1 9$ . Therefore, the 1-step ahead forecast for the conditional covariance matrix is

$$
\widehat {\Sigma} _ {8 8 8} (1) = \left[ \begin{array}{c c} 7 1. 0 9 & 2 1. 8 3 \\ 2 1. 8 3 & 1 7. 7 9 \end{array} \right],
$$

![](images/ea9063ccd8acba689e06cbd56f4a97520227167eb3ef81e21c41199f187bdab4.jpg)  
Figure 10.10. The fitted conditional correlation coefficient between monthly log returns of IBM stock and the S&P 500 index using the time-varying correlation GARCH(1,1) model of Example 10.5. The horizontal line denotes the average 0.612 of the correlation coefficients.

where the covariance is obtained by using the constant-correlation coefficient 0.614. For the time-varying correlation model in Eqs. (10.27) and (10.28), we have $a _ { 1 , 8 8 8 } = 3 . 2 8 7$ , $a _ { 2 , 8 8 8 } = 4 . 9 5 0$ , $\sigma _ { 1 1 , 8 8 8 } = 8 3 . 3 5$ , $\sigma _ { 2 2 , 8 8 8 } = 2 8 . 5 6$ , and $\rho _ { 8 8 8 } = 0 . 5 4 6$ . The 1-step ahead forecast for the covariance matrix is

$$
\widehat {\boldsymbol {\Sigma}} _ {8 8 8} (1) = \left[ \begin{array}{l l} 7 5. 1 5 & 2 3. 4 8 \\ 2 3. 4 8 & 2 4. 7 0 \end{array} \right],
$$

where the forecast of the correlation coefficient is 0.545.

In the second method, we use the Cholesky decomposition of $\Sigma _ { t }$ to model time-varying correlations. For the bivariate case, the parameter vector is $\Xi _ { t } =$ $( g _ { 1 1 , t } , g _ { 2 2 , t } , q _ { 2 1 , t } ) ^ { \prime }$ ; see Eq. (10.18). A simple GARCH(1,1) type model for $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ is

$$
g _ {1 1, t} = \alpha_ {1 0} + \alpha_ {1 1} b _ {1, t - 1} ^ {2} + \beta_ {1 1} g _ {1 1, t - 1},
$$

$$
q _ {2 1, t} = \gamma_ {0} + \gamma_ {1} q _ {2 1, t - 1} + \gamma_ {2} a _ {2, t - 1}, \tag {10.29}
$$

$$
g _ {2 2, t} = \alpha_ {2 0} + \alpha_ {2 1} b _ {1, t - 1} ^ {2} + \alpha_ {2 2} b _ {2, t - 1} ^ {2} + \beta_ {2 1} g _ {1 1, t - 1} + \beta_ {2 2} g _ {2 2, t - 1},
$$

where $b _ { 1 t } = a _ { 1 t }$ and $b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } a _ { 1 t }$ . Thus, $b _ { 1 t }$ assumes a univariate GARCH(1,1) model, $b _ { 2 t }$ uses a bivariate GARCH(1,1) model, and $q _ { 2 1 , t }$ is autocorrelated and uses $_ { a _ { 2 , t - 1 } }$ as an additional explanatory variable. The probability density function relevant to maximum likelihood estimation is given in Eq. (10.20) with $k = 2$ .

Example 10.5 (Continued). Again we use the monthly log returns of IBM stock and the S&P 500 index to demonstrate the volatility model in Eq. (10.29). Using the same specification as before, we obtain the fitted mean equations as

$$
r _ {1 t} = 1. 3 6 4 + 0. 0 7 5 r _ {1, t - 1} - 0. 0 5 8 r _ {2, t - 2} + a _ {1 t},
$$

$$
r _ {2 t} = 0. 6 4 3 + a _ {2 t},
$$

where standard errors of the parameters in the first equation are 0.219, 0.027, and 0.032, respectively, and the standard error of the parameter in the second equation is 0.154. These two mean equations are close to what we obtained before. The fitted volatility model is

$$
g _ {1 1, t} = 3. 7 1 4 + 0. 1 1 3 b _ {1, t - 1} ^ {2} + 0. 8 0 4 g _ {1 1, t - 1},
$$

$$
q _ {2 1, t} = 0. 0 0 2 9 + 0. 9 9 1 5 q _ {2 1, t - 1} - 0. 0 0 4 1 a _ {2, t - 1}, \tag {10.30}
$$

$$
g _ {2 2, t} = 1. 0 2 3 + 0. 0 2 1 b _ {1, t - 1} ^ {2} + 0. 0 5 2 b _ {2, t - 1} ^ {2} - 0. 0 4 0 g _ {1 1, t - 1} + 0. 9 3 7 g _ {2 2, t - 1},
$$

where $b _ { 1 t } = a _ { 1 t }$ and $b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } b _ { 1 t }$ . Standard errors of the parameters in the equation of $g _ { 1 1 , t }$ are 1.033, 0.022, and 0.037, respectively; those of the parameters

in the equation of $q _ { 2 1 , t }$ are 0.001, 0.002, and 0.0004; and those of the parameters in the equation of $g _ { 2 2 , t }$ are 0.344, 0.007, 0.013, and 0.015, respectively. All estimates are statistically significant at the $1 \%$ level.

The conditional covariance matrix $\Sigma _ { t }$ can be obtained from model (10.30) by using the Cholesky decomposition in Eq. (10.12). For the bivariate case, the relationship is given specifically in Eq. (10.13). Consequently, we obtain the timevarying correlation coefficient as

$$
\rho_ {t} = \frac {\sigma_ {2 1 , t}}{\sqrt {\sigma_ {1 1 , t} \sigma_ {2 2 , t}}} = \frac {q _ {2 1 , t} \sqrt {g _ {1 1 , t}}}{\sqrt {g _ {2 2 , t} + q _ {2 1 , t} ^ {2} g _ {1 1 , t}}}. \tag {10.31}
$$

Using the fitted values of $\sigma _ { 1 1 , t }$ and $\sigma _ { 2 2 , t }$ , we can compute the standardized residuals to perform model checking. The Ljung–Box statistics for the standardized residuals of model (10.30) give $Q _ { 2 } ( 4 ) = 1 9 . 7 7 ( 0 . 1 4 )$ and $Q _ { 2 } ( 8 ) = 3 4 . 2 2 ( 0 . 2 7 )$ . For the squared standardized residuals, we have $Q _ { 2 } ^ { * } ( 4 ) = 1 5 . 3 4 ( 0 . 3 6 )$ and $Q _ { 2 } ^ { * } ( 8 ) =$ 31.87(0.37). Thus, the fitted model is adequate in describing the conditional mean and volatility. The model shows a strong dynamic dependence in the correlation; see the coefficient 0.9915 in Eq. (10.30).

Figure 10.11 shows the fitted time-varying correlation coefficient in Eq. (10.31). It shows a smoother correlation pattern than that of Figure 10.10 and confirms the decreasing trend of the correlation coefficient. In particular, the fitted correlation coefficients in recent years are smaller than those of the other models. The two time-varying correlation models for the monthly log returns of IBM stock and the S&P 500 index have comparable maximized likelihood functions of about −3672, indicating the fits are similar. However, the approach based on the Cholesky decomposition may have some advantages. First, it does not require any parameter constraint in estimation to ensure the positive definiteness of $\Sigma _ { t }$ . If one also uses log transformation for $g _ { i i , t }$ , then no constraints are needed for the entire volatility model. Second, the log likelihood function becomes simple under the transformation. Third, the time-varying parameters $q _ { i j , t }$ and $g _ { i i , t }$ have nice interpretations. However, the transformation makes inference a bit more complicated because the fitted model may depend on the ordering of elements in $\pmb { a } _ { t }$ ; recall that $a _ { 1 t }$ is not transformed. In theory, the ordering of elements in $\pmb { a } _ { t }$ should have no impact on volatility.

Finally, the 1-step ahead forecast of the conditional covariance matrix at the forecast origin $t = 8 8 8$ for the new time-varying correlation model is

$$
\widehat {\Sigma} _ {8 8 8} (1) = \left[ \begin{array}{c c} 7 3. 4 5 & 7. 3 4 \\ 7. 3 4 & 1 7. 8 7 \end{array} \right].
$$

The correlation coefficient of the prior forecast is 0.203, which is substantially smaller than those of the previous two models. However, forecasts of the conditional variances are similar as before.

![](images/d9719355ec3fde9b5adb8dc8fd00612738b679067b0e5011fb00f07eed015fd4.jpg)  
Figure 10.11. The fitted conditional correlation coefficient between monthly log returns of IBM stock and the S&P 500 index using the time-varying correlation GARCH(1,1) model of Example 10.5 with Cholesky decomposition. The horizontal line denotes the average 0.612 of the estimated coefficients.

# 10.4.3 Some Recent Developments

Using the parameterization in Eq. (10.7), several authors have proposed parsimonious models for $\pmb { \rho } _ { t }$ to describe the time-varying correlations. We discuss two such developments.

For $k$ -dimensional returns, Tse and Tsui (2002) assume that the conditional correlation matrix $\pmb { \rho } _ { t }$ follows the model

$$
\boldsymbol {\rho} _ {t} = (1 - \theta_ {1} - \theta_ {2}) \boldsymbol {\rho} + \theta_ {1} \boldsymbol {\rho} _ {t - 1} + \theta_ {2} \boldsymbol {\psi} _ {t - 1},
$$

where $\theta _ { 1 }$ and $\theta _ { 2 }$ are scalar parameters, $\pmb { \rho }$ is a $k \times k$ positive-definite matrix with unit diagonal elements, and $\psi _ { t - 1 }$ is the $k \times k$ sample correlation matrix using shocks from $t - m , \ldots , t - 1$ for a prespecified $m$ . Estimation of the two scalar parameters $\theta _ { 1 }$ and $\theta _ { 2 }$ requires special constraints to ensure positive definiteness of the correlation matrix. This is a parsimonious model, but it might be hard to implement in real application. The choice of $\pmb { \rho }$ and $m$ deserves a careful investigation.

Engle (2002) proposes the model

$$
\boldsymbol {\rho} _ {t} = \boldsymbol {J} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {J} _ {t},
$$

where $\pmb { { Q } } _ { t } = ( q _ { i j , t } ) _ { k \times k }$ is a positive-definite matrix, $\pmb { J } _ { t } = \mathrm { d i a g } \{ q _ { 1 1 , t } ^ { - 1 / 2 } , \dots , q _ { k k , t } ^ { - 1 / 2 } \}$ , and $\boldsymbol { Q } _ { t }$ satisfies

$$
\boldsymbol {Q} _ {t} = (1 - \theta_ {1} - \theta_ {2}) \overline {{\boldsymbol {Q}}} + \theta_ {1} \boldsymbol {\epsilon} _ {t - 1} \boldsymbol {\epsilon} _ {t - 1} ^ {\prime} + \theta_ {2} \boldsymbol {Q} _ {t - 1},
$$

where $\epsilon _ { t }$ is the standardized innovation vector with elements $\epsilon _ { i t } = a _ { i t } / \sqrt { \sigma _ { i i , t } }$ , $\overline { { \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \ell } } \boldsymbol { \mathbf { \Lambda } } } }$ is the unconditional covariance matrix of $\epsilon _ { t }$ , and $\theta _ { 1 }$ and $\theta _ { 2 }$ are non-negative scalar parameters satisfying $0 < \theta _ { 1 } + \theta _ { 2 } < 1 .$ . The $\boldsymbol { J } _ { t }$ matrix is a normalization matrix to guarantee that $\pmb { R } _ { t }$ is a correlation matrix.

An obvious drawback of the prior two models is that $\theta _ { 1 }$ and $\theta _ { 2 }$ are scalar so that all the conditional correlations have the same dynamics. This might be hard to justify in real applications, especially when the dimension $k$ is large.

# 10.5 HIGHER DIMENSIONAL VOLATILITY MODELS

In this section, we make use of the sequential nature of Cholesky decomposition to suggest a strategy for building a high-dimensional volatility model. Again write the vector return series as $\pmb { r } _ { t } = \pmb { \mu } _ { t } + \pmb { a } _ { t }$ . The mean equations for $r _ { t }$ can be specified by using the methods of Chapter 8. A simple vector AR model is often sufficient. Here we focus on building a volatility model using the shock process $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf$ .

Based on the discussion of Cholesky decomposition in Section 10.3, the orthogonal transformation from $a _ { i t }$ to $b _ { i t }$ only involves $b _ { j t }$ for $j < i$ . In addition, the time-varying volatility models built in Section 10.4 appear to be nested in the sense that the model for $g _ { i i , t }$ depends only on quantities related to $b _ { j t }$ for $j < i$ . Consequently, we consider the following sequential procedure to build a multivariate volatility model:

1. Select a market index or a stock return that is of major interest. Build a univariate volatility model for the selected return series.   
2. Augment a second return series to the system, perform the orthogonal transformation on the shock process of this new return series, and build a bivariate volatility model for the system. The parameter estimates of the univariate model in step 1 can be used as the starting values in bivariate estimation.   
3. Augment a third return series to the system, perform the orthogonal transformation on this newly added shock process, and build a three-dimensional volatility model. Again parameter estimates of the bivariate model can be used as the starting values in the three-dimensional estimation.   
4. Continue the augmentation until a joint volatility model is built for all the return series of interest.

Finally, model checking should be performed in each step to ensure the adequacy of the fitted model. Experience shows that this sequential procedure can simplify

substantially the complexity involved in building a high-dimensional volatility model. In particular, it can markedly reduce the computing time in estimation.

Example 10.6. We demonstrate the proposed sequential procedure by building a volatility model for the daily log returns of the S&P 500 index and the stocks of Cisco Systems and Intel Corporation. The data span is from January 2, 1991 to December 31, 1999 with 2275 observations. The log returns are in percentages and shown in Figure 10.12. Components of the return series are ordered as $r _ { t } =$ $\mathrm { S P } 5 _ { t }$ , $\mathbf { C S C O } _ { t }$ , INTCt ). The sample means, standard errors, and correlation matrix of the data are

$$
\widehat {\boldsymbol {\mu}} = \left[ \begin{array}{l} 0. 0 6 6 \\ 0. 2 5 7 \\ 0. 1 5 6 \end{array} \right], \quad \left[ \begin{array}{l} \hat {\sigma} _ {1} \\ \hat {\sigma} _ {2} \\ \hat {\sigma} _ {3} \end{array} \right] = \left[ \begin{array}{l} 0. 8 7 5 \\ 2. 8 5 3 \\ 2. 4 6 4 \end{array} \right], \quad \widehat {\boldsymbol {\rho}} = \left[ \begin{array}{l l l} 1. 0 0 & 0. 5 2 & 0. 5 0 \\ 0. 5 2 & 1. 0 0 & 0. 4 7 \\ 0. 5 0 & 0. 4 7 & 1. 0 0 \end{array} \right].
$$

Using the Ljung–Box statistics to detect any serial dependence in the return series, we obtain $Q _ { 3 } ( 1 ) = 2 6 . 2 0$ , $Q _ { 3 } ( 4 ) = 7 9 . 7 3$ , and $\begin{array} { r } { Q _ { 3 } ( 8 ) = 1 2 3 . 6 8 . } \end{array}$ These test

![](images/2c667ec68b293b2cd3493bc9187602631fc28b501911e894685343e1e55a1af6.jpg)  
(a) S&P 500 index

![](images/dd4be64cd20832a335078570c5d3a25f2b47d910be07f298ea15515e163eec33.jpg)  
(b) Cisco systems

![](images/3b721fc87086cb79a17ba50b314017fa81b8f6feee6f4fa816f6b822f4da2907.jpg)  
(c) Intel corp   
Figure 10.12. Time plots of daily log returns in percentages of (a) the S&P 500 index and stocks of (b) Cisco Systems and (c) Intel Corporation from January 2, 1991 to December 31, 1999.

Table 10.1. Sample Cross-Correlation Matrices of Daily Log Returns of the S&P 500 Index and the Stocks of Cisco Systems and Intel Corporation from January 2, 1991 to December 31, 1999   

<table><tr><td colspan="8">Lag</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td></td><td></td></tr><tr><td>. . .</td><td>. . .</td><td>- . . .</td><td>. . .</td><td>- . . .</td><td>. . .</td><td></td><td></td></tr><tr><td>. . .</td><td>. - . .</td><td>. . .</td><td>. . .</td><td>- . . .</td><td>. - .</td><td></td><td></td></tr><tr><td>- . . .</td><td>. . .</td><td>. . .</td><td>. . .</td><td>- . . .</td><td>. . .</td><td></td><td></td></tr></table>

statistics are highly significant with $p$ -values close to zero as compared with chisquared distributions with degrees of freedom 9, 36, and 72, respectively. There is indeed some serial dependence in the data. Table 10.1 gives the first five lags of sample cross-correlation matrices shown in the simplified notation of Chapter 8. An examination of the table shows that (a) the daily log returns of the S&P 500 index does not depend on the past returns of Cisco or Intel, (b) the log return of Cisco stock has some serial correlations and depends on the past returns of the S&P 500 index (see lags 2 and 5), and (c) the log return of Intel stock depends on the past returns of the S&P 500 index (see lags 1 and 5). These observations are similar to those between the returns of IBM stock and the S&P 500 index analyzed in Chapter 8. They suggest that returns of individual large-cap companies tend to be affected by the past behavior of the market. However, the market return is not significantly affected by the past returns of individual companies.

Turning to volatility modeling and following the suggested procedure, we start with the log returns of the S&P 500 index and obtain the model

$$
\begin{array}{l} r _ {1 t} = 0. 0 7 8 + 0. 0 4 2 r _ {1, t - 1} - 0. 0 6 2 r _ {1, t - 3} - 0. 0 4 8 r _ {1, t - 4} - 0. 0 5 2 r _ {1, t - 5} + a _ {1 t}, \\ \sigma_ {1 1, t} = 0. 0 1 3 + 0. 0 9 2 a _ {1, t - 1} ^ {2} + 0. 8 9 4 \sigma_ {1 1, t - 1}, \tag {10.32} \\ \end{array}
$$

where standard errors of the parameters in the mean equation are 0.016, 0.023, 0.020, 0.022, and 0.020, respectively, and those of the parameters in the volatility equation are 0.002, 0.006, and 0.007, respectively. Univariate Ljung–Box statistics of the standardized residuals and their squared series fail to detect any remaining serial correlation or conditional heteroscedasticity in the data. Indeed, we have $Q ( 1 0 ) = 7 . 3 8 ( 0 . 6 9 )$ for the standardized residuals and $Q ( 1 0 ) = 3 . 1 4 ( 0 . 9 8 )$ for the squared series.

Augmenting the daily log returns of Cisco stock to the system, we build a bivariate model with mean equations given by

$$
\begin{array}{l} r _ {1 t} = 0. 0 6 5 - 0. 0 4 6 r _ {1, t - 3} + a _ {1 t}, \tag {10.33} \\ r _ {2 t} = 0. 3 2 5 + 0. 1 9 5 r _ {1, t - 2} - 0. 0 9 1 r _ {2, t - 2} + a _ {2 t}, \\ \end{array}
$$

where all of the estimates are statistically significant at the $1 \%$ level. Using the notation of Cholesky decomposition, we obtain the volatility equations as

$$
g _ {1 1, t} = 0. 0 0 6 + 0. 0 5 1 b _ {1, t - 1} ^ {2} + 0. 9 4 3 g _ {1 1, t - 1},
$$

$$
q _ {2 1, t} = 0. 3 3 1 + 0. 7 9 0 q _ {2 1, t - 1} - 0. 0 4 1 a _ {2, t - 1}, \tag {10.34}
$$

$$
g _ {2 2, t} = 0. 1 7 7 + 0. 0 8 2 b _ {2, t - 1} ^ {2} + 0. 8 9 0 g _ {2 2, t - 1},
$$

where $b _ { 1 t } = a _ { 1 t } , \ b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } b _ { 1 t }$ $b _ { 1 t } = a _ { 1 t }$ , standard errors of the parameters in the equation of $g _ { 1 1 , t }$ are 0.001, 0.005, and 0.006, those of the parameters in the equation of $q _ { 2 1 , t }$ are 0.156, 0.099, and 0.011, and those of the parameters in the equation of $g _ { 2 2 , t }$ are 0.029, 0.008, and 0.011, respectively. The bivariate Ljung–Box statistics of the standardized residuals fail to detect any remaining serial dependence or conditional heteroscedasticity. The bivariate model is adequate. Comparing with Eq. (10.32), we see that the difference between the marginal and univariate models of $r _ { 1 t }$ is small.

The next and final step is to augment the daily log returns of Intel stock to the system. The mean equations become

$$
r _ {1 t} = 0. 0 6 5 - 0. 0 4 3 r _ {1, t - 3} + a _ {1 t},
$$

$$
r _ {2 t} = 0. 3 2 6 + 0. 2 0 1 r _ {1, t - 2} - 0. 0 8 9 r _ {2, t - 1} + a _ {2 t}, \tag {10.35}
$$

$$
r _ {3 t} = 0. 1 9 2 - 0. 2 6 4 r _ {1, t - 1} + 0. 0 5 9 r _ {3, t - 1} + a _ {3 t},
$$

where standard errors of the parameters in the first equation are 0.016 and 0.017, those of the parameters in the second equation are 0.052, 0.059, and 0.021, and those of the parameters in the third equation are 0.050, 0.057, and 0.022, respectively. All estimates are statistically significant at about the $1 \%$ level. As expected, the mean equations for $r _ { 1 t }$ and $r _ { 2 t }$ are essentially the same as those in the bivariate case.

The three-dimensional time-varying volatility model becomes a bit more complicated, but it remains manageable as

$$
g _ {1 1, t} = 0. 0 0 6 + 0. 0 5 0 b _ {1, t - 1} ^ {2} + 0. 9 4 3 g _ {1 1, t - 1},
$$

$$
q _ {2 1, t} = 0. 2 7 7 + 0. 8 2 4 q _ {2 1, t - 1} - 0. 0 3 5 a _ {2, t - 1},
$$

$$
g _ {2 2, t} = 0. 1 7 8 + 0. 0 8 2 b _ {2, t - 1} ^ {2} + 0. 8 8 9 g _ {2 2, t - 1}, \tag {10.36}
$$

$$
q _ {3 1, t} = 0. 0 3 9 + 0. 9 7 3 q _ {3 1, t - 1} + 0. 0 1 0 a _ {3, t - 1},
$$

$$
q _ {3 2, t} = 0. 0 0 6 + 0. 9 8 1 q _ {3 2, t - 1} + 0. 0 0 4 a _ {2, t - 1},
$$

$$
g _ {3 3, t} = 1. 1 8 8 + 0. 0 5 3 b _ {3, t - 1} ^ {2} + 0. 6 8 7 g _ {3 3, t - 1} - 0. 0 1 9 g _ {2 2, t - 1},
$$

where $b _ { 1 t } = a _ { 1 t }$ , $b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } b _ { 1 t }$ , $b _ { 3 t } = a _ { 3 t } - q _ { 3 1 , t } b _ { 1 t } - q _ { 3 2 , t } b _ { 2 t }$ , and standard errors of the parameters are given in Table 10.2. Except for the constant term of the $q _ { 3 2 , t }$ equation, all estimates are significant at the $5 \%$ level. Let $\tilde { \pmb { a } } _ { t } =$

Table 10.2. Standard Errors of Parametera Estimates of a Three-Dimensional Volatility Model for the Daily Log Returns in Percentages of the S&P 500 Index and Stocks of Cisco Systems and Intel Corporation from January 2, 1991 to December 31, 1999   

<table><tr><td>Equation</td><td colspan="4">Standard Error</td><td>Equation</td><td colspan="3">Standard Error</td></tr><tr><td>g11,t</td><td>0.001</td><td>0.005</td><td>0.006</td><td></td><td>q21,t</td><td>0.135</td><td>0.086</td><td>0.010</td></tr><tr><td>g22,t</td><td>0.029</td><td>0.009</td><td>0.011</td><td></td><td>q31,t</td><td>0.017</td><td>0.012</td><td>0.004</td></tr><tr><td>g33,t</td><td>0.407</td><td>0.015</td><td>0.100</td><td>0.008</td><td>q32,t</td><td>0.004</td><td>0.013</td><td>0.001</td></tr></table>

aThe ordering of the parameter is the same as appears in Eq. (10.36).

$( a _ { 1 t } / \hat { \sigma } _ { 1 t } , a _ { 2 t } / \hat { \sigma } _ { 2 t } , a _ { 3 t } / \hat { \sigma } _ { 3 t } ) ^ { \prime }$ $( a _ { 1 t } / \hat { \sigma } _ { 1 t }$ be the standardized residual series, where $\hat { \sigma } _ { i t } = \sqrt { \hat { \sigma } _ { i i , t } }$ is the fitted conditional standard error of the ith return. The Ljung–Box statistics of $\tilde { \pmb { a } } _ { t }$ give $Q _ { 3 } ( 4 ) = 3 4 . 4 8 ( 0 . 3 1 )$ and $Q _ { 3 } ( 8 ) = 6 0 . 4 2 ( 0 . 7 0 )$ , where the degrees of freedom of the chi-squared distributions are 31 and 67, respectively, after adjusting for the number of parameters used in the mean equations. For the squared standardized residual series $\tilde { \mathbf { \Gamma } } _ { t } ^ { 2 }$ , we have $Q _ { 3 } ^ { * } ( 4 ) = 2 8 . 7 1 ( 0 . 5 8 )$ and $Q _ { 3 } ^ { * } ( 8 ) = 5 2 . 0 0 ( 0 . 9 1 )$ . Therefore, the fitted model appears to be adequate in modeling the conditional means and volatilities.

The three-dimensional volatility model in Eq. (10.36) shows some interesting features. First, it is essentially a time-varying correlation GARCH(1,1) model because only lag-1 variables are used in the equations. Second, the volatility of the daily log returns of the S&P 500 index does not depend on the past volatilities of Cisco or Intel stock returns. Third, by taking the inverse transformation of the Cholesky decomposition, the volatilities of daily log returns of Cisco and Intel stocks depend on the past volatility of the market return; see the relationships between elements of $\Sigma _ { t }$ , $\scriptstyle { L _ { t } }$ , and $\mathbf { } G _ { t }$ given in Section 10.3. Fourth, the correlation quantities $q _ { i j , t }$ have high persistence with large AR(1) coefficients.

Figure 10.13 shows the fitted volatility processes of the model (i.e., $\hat { \sigma } _ { i i , t }$ ) for the data. The volatility of the index return is much smaller than those of the two individual stock returns. The plots also show that the volatility of the index return has increased in recent years, but this is not the case for the return of Cisco Systems. Figure 10.14 shows the time-varying correlation coefficients between the three return series. Of particular interest is to compare Figures 10.13 and 10.14. They show that the correlation coefficient between two return series increases when the returns are volatile. This is in agreement with the empirical study of relationships between international stock market indexes for which the correlation between two markets tends to increase during a financial crisis.

The volatility model in Eq. (10.36) consists of two sets of equations. The first set of equations describes the time evolution of conditional variances (i.e., $g _ { i i , t }$ ), and the second set of equations deals with correlation coefficients (i.e., $q _ { i j , t }$ with $i > j ,$ ). For this particular data set, an AR(1) model might be sufficient for the correlation equations. Similarly, a simple AR model might also be sufficient for the conditional variances. Define $\pmb { v } _ { t } = ( v _ { 1 1 , t } , v _ { 2 2 , t } , v _ { 3 3 , t } ) ^ { \prime }$ , where $v _ { i i , t } = \ln ( g _ { i i , t } )$ ,

![](images/5f6fb953b5bcd8392f2818247fe8d6a841de9f6b9711a27cc8a64fb1e01082bd.jpg)

![](images/c22b083cd40955697d65647eab91b1f477ca1fab8f6b59ec52e9d0a25eddf63f.jpg)

![](images/071e285a4e5e135400783ba6ef75f8dd4b536fc6b09fe5144d1d52cbfbd5e5bf.jpg)  
Figure 10.13. Time plots of fitted volatilities for daily log returns, in percentages, of (a) the S&P 500 index and stocks of (b) Cisco Systems and (c) Intel Corporation from January 2, 1991 to December 31, 1999.

and $\pmb q _ { t } = ( q _ { 2 1 , t } , q _ { 3 1 , t } , q _ { 3 2 , t } ) ^ { \prime }$ . The previous discussion suggests that we can use the simple lag-1 models

$$
\boldsymbol {v} _ {t} = \boldsymbol {c} _ {1} + \boldsymbol {\beta} _ {1} \boldsymbol {v} _ {t - 1}, \quad \boldsymbol {q} _ {t} = \boldsymbol {c} _ {2} + \boldsymbol {\beta} _ {2} \boldsymbol {q} _ {t - 1}
$$

as exact functions to model the volatility of asset returns, where $c _ { i }$ are constant vectors and $\beta _ { i }$ are $3 \times 3$ real-valued matrices. If a noise term is also included in the above equations, then the models become

$$
\boldsymbol {v} _ {t} = \boldsymbol {c} _ {1} + \boldsymbol {\beta} _ {1} \boldsymbol {v} _ {t - 1} + \boldsymbol {e} _ {1 t}, \quad \boldsymbol {q} _ {t} = \boldsymbol {c} _ {2} + \boldsymbol {\beta} _ {2} \boldsymbol {q} _ {t - 1} + \boldsymbol {e} _ {2 t},
$$

where $e _ { i t }$ are random shocks with mean zero and a positive-definite covariance matrix, and we have a simple multivariate stochastic volatility model. In a recent manuscript, Chib, Nardari, and Shephard (1999) use Markov chain Monte Carlo (MCMC) methods to study high-dimensional stochastic volatility models. The

![](images/4de666c94b7bba43133b9c1386f5ca8b4789833c19019292058e750364c7862c.jpg)

![](images/5a1965539d24d8afed6ac55c3d272b968b23e6a381dee11197f4b9036130d76b.jpg)

![](images/a8a42a0d03adfb1658d020704e9ba9bc781d5329a1ecec5f3cbf9c8d43cfb44b.jpg)  
Figure 10.14. Time plots of fitted time-varying correlation coefficients between daily log returns of the S&P 500 index and stocks of Cisco Systems and Intel Corporation from January 2, 1991 to December 31, 1999.

model considered there allows for time-varying correlations, but in a relatively restrictive manner. Additional references of multivariate volatility model include Harvey, Ruiz, and Shephard (1995). We discuss MCMC methods in volatility modeling in Chapter 12.

# 10.6 FACTOR–VOLATILITY MODELS

Another approach to simplifying the dynamic structure of a multivariate volatility process is to use factor models. In practice, the “common factors” can be determined a priori by substantive matter or empirical methods. As an illustration, we use the factor analysis of Chapter 8 to discuss factor–volatility models. Because volatility models are concerned with the evolution over time of the conditional covariance matrix of $\pmb { a } _ { t }$ , where $\pmb { a } _ { t } = \pmb { r } _ { t } - \pmb { \mu } _ { t }$ , a simple way to identify the “common factors” in volatility is to perform a principal component analysis (PCA) on $\pmb { a } _ { t }$ ; see the

PCA of Chapter 8. Building a factor–volatility model thus involves a three-step procedure:

• Select the first few principal components that explain a high percentage of variability in $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \mathbf $ .   
• Build a volatility model for the selected principal components.   
• Relate the volatility of each $a _ { i t }$ series to the volatilities of the selected principal components.

The objective of such a procedure is to reduce the dimension but maintain an accurate approximation of the multivariate volatility.

Example 10.7. Consider again the monthly log returns, in percentages, of IBM stock and the S&P 500 index of Example 10.5. Using the bivariate AR(3) model of Example 8.4, we obtain an innovational series $\pmb { a } _ { t }$ . Performing a PCA on $\pmb { a } _ { t }$ based on its covariance matrix, we obtained eigenvalues 63.373 and 13.489. The first eigenvalue explains $8 2 . 2 \%$ of the generalized variance of $\pmb { a } _ { t }$ . Therefore, we may choose the first principal component $x _ { t } = 0 . 7 9 7 a _ { 1 t } + 0 . 6 0 4 a _ { 2 t }$ as the common factor. Alternatively, as shown by the model in Example 8.4, the serial dependence in $r _ { t }$ is weak and, hence, one can perform the PCA on $r _ { t }$ directly. For this particular instance, the two eigenvalues of the sample covariance matrix of $r _ { t }$ are 63.625 and 13.513, which are essentially the same as those based on $\pmb { a } _ { t }$ . The first principal component explains approximately $8 2 . 5 \%$ of the generalized variance of $r _ { t }$ , and the corresponding common factor is $x _ { t } = 0 . 7 9 6 r _ { 1 t } + 0 . 6 0 5 r _ { 2 t }$ . Consequently, for the two monthly log return series considered, the effect of the conditional mean equations on PCA is negligible.

Based on the prior discussion and for simplicity, we use $x _ { t } = 0 . 7 9 6 r _ { 1 t } + 0 . 6 0 5 r _ { 2 t }$ as a common factor for the two monthly return series. Figure 10.15a shows the time plot of this common factor. If univariate Gaussian GARCH models are entertained, we obtain the following model for $x _ { t }$ :

$$
\begin{array}{l} x _ {t} = 1. 3 1 7 + 0. 0 9 6 x _ {t - 1} + a _ {t}, \quad a _ {t} = \sigma_ {t} \epsilon_ {t}, \\ \sigma_ {t} ^ {2} = 3. 8 3 4 + 0. 1 1 0 a _ {t - 1} ^ {2} + 0. 8 2 5 \sigma_ {t - 1} ^ {2}. \tag {10.37} \\ \end{array}
$$

All parameter estimates of the previous model are highly significant at the $1 \%$ level, and the Ljung–Box statistics of the standardized residuals and their squared series fail to detect any model inadequacy. Figure 10.15b shows the fitted volatility of $x _ { t }$ (i.e., the sample $\sigma _ { t } ^ { 2 }$ series in Eq. (10.37)).

Using $\sigma _ { t } ^ { 2 }$ of model (10.37) as a common volatility factor, we obtain the following model for the original monthly log returns. The mean equations are

$$
\begin{array}{l} r _ {1 t} = 1. 1 4 0 + 0. 0 7 9 r _ {1, t - 1} + 0. 0 6 7 r _ {1, t - 2} - 0. 1 2 2 r _ {2, t - 2} + a _ {1 t}, \\ r _ {2 t} = 0. 5 3 7 + a _ {2 t}, \\ \end{array}
$$

![](images/0b118fb1810db2a0c5f67e53edeaf52f1fd48459640a05e2fa3553aedd24ab6d.jpg)  
(a) The first principal component

![](images/ba1f43d20a3e86d30480d9b155d88329dcbaa3bdb94e1a4af1ca2a2ef371c63b.jpg)  
(b) A fitted volatility process   
Figure 10.15. (a) Time plot of the first principal component of the monthly log returns of IBM stock and the S&P 500 index. (b) The fitted volatility process based on a GARCH(1,1) model.

where standard errors of the parameters in the first equation are 0.211, 0.030, 0.031, and 0.043, respectively, and standard error of the parameter in the second equation is 0.165. The conditional variance equation is

$$
\left[ \begin{array}{c} \sigma_ {1 1, t} \\ \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c} 1 9. 0 8 \\ (3. 7 0) \\ - 5. 6 2 \\ (2. 3 6) \end{array} \right] + \left[ \begin{array}{c c} 0. 0 9 8 & \cdot \\ (0. 0 4 4) & \\ \cdot & \cdot \end{array} \right] \left[ \begin{array}{c} a _ {1, t - 1} ^ {2} \\ a _ {2, t - 1} ^ {2} \end{array} \right] + \left[ \begin{array}{c} 0. 3 3 3 \\ (0. 0 7 6) \\ 0. 5 9 6 \\ (0. 0 5 0) \end{array} \right] \sigma_ {t} ^ {2}, \tag {10.38}
$$

where, as before, standard errors are in parentheses, and $\sigma _ { t } ^ { 2 }$ is obtained from model (10.37). The conditional correlation equation is

$$
\rho_ {t} = \frac {\exp \left(q _ {t}\right)}{1 + \exp \left(q _ {t}\right)}, \quad q _ {t} = - 2. 0 9 8 + 4. 1 2 0 \rho_ {t - 1} + 0. 0 7 8 \frac {a _ {1 , t - 1} a _ {2 , t - 1}}{\sqrt {\sigma_ {1 1 , t - 1} \sigma_ {2 2 , t - 1}}}, \tag {10.39}
$$

where standard errors of the three parameters are 0.025, 0.038, and 0.015, respectively. Defining the standardized residuals as before, we obtain $Q _ { 2 } ( 4 ) = 1 5 . 3 7 ( 0 . 2 9 )$ ) and $Q _ { 2 } ( 8 ) = 3 4 . 2 4 ( 0 . 2 3 )$ , where the number in parentheses denotes $p$ -value. Therefore, the standardized residuals have no serial correlations. Yet we have $Q _ { 2 } ^ { * } ( 4 ) =$ 20.25(0.09) and $Q _ { 2 } ^ { * } ( 8 ) = 6 1 . 9 5 ( 0 . 0 0 0 4 )$ for the squared standardized residuals.

The volatility model in Eq. (10.38) does not adequately handle the conditional heteroscedasticity of the data especially at higher lags. This is not surprising as the single common factor only explains about $8 2 . 5 \%$ of the generalized variance of the data.

Comparing the factor model in Eqs. (10.38) and (10.39) with the time-varying correlation model in Eqs. (10.27) and (10.28), we see that (a) the correlation equations of the two models are essentially the same, (b) as expected the factor model uses fewer parameters in the volatility equation, and (c) the commonfactor model provides a reasonable approximation to the volatility process of the data.

Remark. In Example 10.7, we used a two-step estimation procedure. In the first step, a volatility model is built for the common factor. The estimated volatility is treated as given in the second step to estimate the multivariate volatility model. Such an estimation procedure is simple but may not be efficient. A more efficient estimation procedure is to perform a joint estimation. This can be done relatively easily provided that the common factors are known. For example, for the monthly log returns of Example 10.7, a joint estimation of Eqs. (10.37)–(10.39) can be performed if the common factor $x _ { t } = 0 . 7 6 9 r _ { 1 t } + 0 . 6 0 5 r _ { 2 t }$ is treated as given. 

# 10.7 APPLICATION

We illustrate the application of multivariate volatility models by considering the value at risk (VaR) of a financial position with multiple assets. Suppose that an investor holds a long position in the stocks of Cisco Systems and Intel Corporation each worth $\$ 1$ million. We use the daily log returns for the two stocks from January 2, 1991 to December 31, 1999 to build volatility models. The VaR is computed using the 1-step ahead forecasts at the end of data span and $5 \%$ critical values.

Let $\operatorname { V a R } _ { 1 }$ be the value at risk for holding the position on Cisco Systems stock and $\operatorname { V a R } _ { 2 }$ for holding Intel stock. Results of Chapter 7 show that the overall daily VaR for the investor is

$$
\mathrm {V a R} = \sqrt {\mathrm {V a R} _ {1} ^ {2} + \mathrm {V a R} _ {2} ^ {2} + 2 \rho \mathrm {V a R} _ {1} \mathrm {V a R} _ {2}}.
$$

In this illustration, we consider three approaches to volatility modeling for calculating VaR. For simplicity, we do not report standard errors for the parameters involved or model checking statistics. Yet all of the estimates are statistically significant at the $5 \%$ level and the models are adequate based on the Ljung–Box statistics of the standardized residual series and their squared series. The log returns are in percentages so that the quantiles are divided by 100 in VaR calculation. Let $r _ { 1 t }$ be the return of Cisco stock and $r _ { 2 t }$ the return of Intel stock.

# Univariate Models

This approach uses a univariate volatility model for each stock return and uses the sample correlation coefficient of the stock returns to estimate $\rho$ . The univariate volatility models for the two stock returns are

$$
r _ {1 t} = 0. 3 8 0 + 0. 0 3 4 r _ {1, t - 1} - 0. 0 6 1 r _ {1, t - 2} - 0. 0 5 5 r _ {1, t - 3} + a _ {1 t},
$$

$$
\sigma_ {1 t} ^ {2} = 0. 5 9 9 + 0. 1 1 7 a _ {1, t - 1} ^ {2} + 0. 8 1 4 \sigma_ {1, t - 1} ^ {2}
$$

and

$$
r _ {2 t} = 0. 1 8 7 + a _ {2 t},
$$

$$
\sigma_ {2 t} ^ {2} = 0. 3 1 0 + 0. 0 3 2 a _ {2, t - 1} ^ {2} + 0. 9 1 8 \sigma_ {2, t - 1} ^ {2}.
$$

The sample correlation coefficient is 0.473. The 1-step ahead forecasts needed in VaR calculation at the forecast origin $t = 2 2 7 5$ are

$$
\hat {r} _ {1} = 0. 6 2 6, \quad \hat {\sigma} _ {1} ^ {2} = 4. 1 5 2, \quad \hat {r} _ {2} = 0. 1 8 7, \quad \hat {\sigma} _ {2} ^ {2} = 6. 0 8 7, \quad \hat {\rho} = 0. 4 7 3.
$$

The $5 \%$ quantiles for both daily returns are

$$
q _ {1} = 0. 6 2 6 - 1. 6 5 \sqrt {4 . 1 5 2} = - 2. 7 3 6, \quad q _ {2} = 0. 1 8 7 - 1. 6 5 \sqrt {6 . 0 8 7} = - 3. 8 8 4,
$$

where the negative sign denotes loss. For the individual stocks, $\mathrm { { V a R } _ { 1 } = }$ $\$ 10000000 q _ { 1 } /100 = \ S 2 7 ,360$ and $\mathrm { V a R } _ { 2 } = \mathbb { S } 1 0 0 0 0 0 q _ { 2 } / 1 0 0 = \ S 3 8 , 8 4 0$ . Consequently, the overall VaR for the investor is $\mathrm { V a R } = \$ 57,117$ .

# Constant-Correlation Bivariate Model

This approach employs a bivariate GARCH(1,1) model for the stock returns. The correlation coefficient is assumed to be constant over time, but it is estimated jointly with other parameters. The model is

$$
r _ {1 t} = 0. 3 8 5 + 0. 0 3 8 r _ {1, t - 1} - 0. 0 6 0 r _ {1, t - 2} - 0. 0 4 7 r _ {1, t - 3} + a _ {1 t},
$$

$$
r _ {2 t} = 0. 2 2 2 + a _ {2 t},
$$

$$
\sigma_ {1 1, t} = 0. 6 2 4 + 0. 1 1 0 a _ {1, t - 1} ^ {2} + 0. 8 1 6 \sigma_ {1 1, t - 1},
$$

$$
\sigma_ {2 2, t} = 0. 6 6 4 + 0. 0 3 8 a _ {2, t - 1} ^ {2} + 0. 8 5 3 \sigma_ {2 2, t - 1},
$$

and $\hat { \rho } = 0 . 4 7 5$ . This is a diagonal bivariate GARCH(1,1) model. The 1-step ahead forecasts for VaR calculation at the forecast origin $t = 2 2 7 5$ are

$$
\hat {r} _ {1} = 0. 3 7 3, \quad \hat {\sigma} _ {1} ^ {2} = 4. 2 8 7, \quad \hat {r} _ {2} = 0. 2 2 2, \quad \hat {\sigma} _ {2} ^ {2} = 5. 7 0 6, \quad \hat {\rho} = 0. 4 7 5.
$$

Consequently, we have $\mathrm { V a R } _ { 1 } = \$ 30,432$ and $\mathrm { V a R } _ { 2 } = \$ 37 ,195$ . The overall $5 \%$ VaR for the investor is $\mathrm { V a R } = \$ 58,180$ .

# Time-Varying Correlation Model

Finally, we allow the correlation coefficient to evolve over time by using the Cholesky decomposition. The fitted model is

$$
r _ {1 t} = 0. 3 5 5 + 0. 0 3 9 r _ {1, t - 1} - 0. 0 5 7 r _ {1, t - 2} - 0. 0 3 8 r _ {1, t - 3} + a _ {1 t},
$$

$$
r _ {2 t} = 0. 2 0 6 + a _ {2 t},
$$

$$
g _ {1 1, t} = 0. 4 2 0 + 0. 0 9 1 b _ {1, t - 1} ^ {2} + 0. 8 5 8 g _ {1 1, t - 1},
$$

$$
q _ {2 1, t} = 0. 1 2 3 + 0. 6 8 9 q _ {2 1, t - 1} - 0. 0 1 4 a _ {2, t - 1},
$$

$$
g _ {2 2, t} = 0. 0 8 0 + 0. 0 1 3 b _ {2, t - 1} ^ {2} + 0. 9 7 1 g _ {2 2, t - 1},
$$

where $b _ { 1 t } = a _ { 1 t }$ and $b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } a _ { 1 t }$ . The 1-step ahead forecasts for VaR calculation at the forecast origin $t = 2 2 7 5$ are

$$
\hat {r} _ {1} = 0. 3 5 2, \quad \hat {r} _ {2} = 0. 2 0 6, \quad \hat {g} _ {1 1} = 4. 2 5 2, \quad \hat {q} _ {2 1} = 0. 4 2 1, \quad \hat {g} _ {2 2} = 5. 5 9 4.
$$

Therefore, we have $\hat { \sigma } _ { 1 } ^ { 2 } = 4 . 2 5 2$ , $\hat { \sigma } _ { 2 1 } = 1 . 7 9 1$ , and $\hat { \sigma } _ { 2 } ^ { 2 } = 6 . 3 4 8$ . The correlation coefficient is $\hat { \rho } = 0 . 3 4 \bar { 5 }$ . Using these forecasts, we have $\mathrm { V a R } _ { 1 } = \ S 3 0 { , } 5 0 4$ , ${ \mathrm { V a R } } _ { 2 } = $ $\$ 39,512$ , and the overall value at risk $\mathrm { V a R } = \$ 57,648$ .

The estimated VaR values of the three approaches are similar. The univariate models give the lowest VaR, whereas the constant-correlation model produces the highest VaR. The range of the difference is about $\$ 100$ . The time-varying volatility model seems to produce a compromise between the two extreme models.

# 10.8 MULTIVARIATE t DISTRIBUTION

Empirical analysis indicates that the multivariate Gaussian innovations used in the previous sections may fail to capture the kurtosis of asset returns. In this situation, a multivariate Student-t distribution might be useful. There are many versions of the multivariate Student-t distribution. We give a simple version here for volatility modeling.

A $k$ -dimensional random vector ${ \pmb x } = ( x _ { 1 } , \dots , x _ { k } ) ^ { \prime }$ has a multivariate Student- $\cdot t$ distribution with $v$ degrees of freedom and parameters $\pmb { \mu } = \pmb { 0 }$ and $\Sigma = I$ (the identity matrix) if its probability density function (pdf) is

$$
f (\boldsymbol {x} | v) = \frac {\Gamma ((v + k) / 2)}{(\pi v) ^ {k / 2} \Gamma (v / 2)} \left(1 + v ^ {- 1} \boldsymbol {x} ^ {\prime} \boldsymbol {x}\right) ^ {- (v + k) / 2}, \tag {10.40}
$$

where $\Gamma ( y )$ is the gamma function; see Mardia, Kent, and Bibby (1979, p. 57). The variance of each component $x _ { i }$ in Eq. (10.40) is $v / ( v - 2 )$ and hence we define $\epsilon _ { t } = \sqrt { ( v - 2 ) / v } x$ as the standardized multivariate Student- $\cdot t$ distribution with $v$ degrees of freedom. By transformation, the pdf of $\epsilon _ { t }$ is

$$
f \left(\epsilon_ {t} | v\right) = \frac {\Gamma \left((v + k) / 2\right)}{\left[ \pi (v - 2) \right] ^ {k / 2} \Gamma (v / 2)} \left[ 1 + (v - 2) ^ {- 1} \epsilon_ {t} ^ {\prime} \epsilon_ {t} \right] ^ {- (v + k) / 2}. \tag {10.41}
$$

For volatility modeling, we write ${ \pmb a } _ { t } = { \pmb \Sigma } _ { t } ^ { 1 / 2 } { \pmb \epsilon } _ { t }$ and assume that $\epsilon _ { t }$ follows the multivariate Student- $\cdot t$ distribution in Eq. (10.41). By transformation, the pdf of $\pmb { a } _ { t }$ is

$$
f \left(\boldsymbol {a} _ {t} | v, \boldsymbol {\Sigma} _ {t}\right) = \frac {\Gamma ((v + k) / 2)}{[ \pi (v - 2) ] ^ {k / 2} \Gamma (v / 2) | \boldsymbol {\Sigma} _ {t} | ^ {1 / 2}} \left(1 + (v - 2) ^ {- 1} \boldsymbol {a} _ {t} ^ {\prime} \boldsymbol {\Sigma} _ {t} ^ {- 1} \boldsymbol {a} _ {t}\right) ^ {- (v + k) / 2}.
$$

Furthermore, if we use the Cholesky decomposition of $\Sigma _ { t }$ , then the pdf of the transformed shock $\mathbf { } _ { \pmb { b } _ { t } }$ becomes

$$
\begin{array}{l} f \left(\boldsymbol {b} _ {t} | v, \boldsymbol {L} _ {t}, \boldsymbol {G} _ {t}\right) \\ = \frac {\Gamma ((v + k) / 2)}{[ \pi (v - 2) ] ^ {k / 2} \Gamma (v / 2) \prod_ {j = 1} ^ {k} g _ {j j , t} ^ {1 / 2}} \left(1 + (v - 2) ^ {- 1} \sum_ {j = 1} ^ {k} \frac {b _ {j t} ^ {2}}{g _ {j j , t}}\right) ^ {(v + k) / 2}, \\ \end{array}
$$

where ${ \pmb a } _ { t } = { \pmb L } _ { t } { \pmb b } _ { t }$ and $g _ { j j , t }$ is the conditional variance of $b _ { j t }$ . Because this pdf does not involve any matrix inversion, the conditional likelihood function of the data is easy to evaluate.

# APPENDIX: SOME REMARKS ON ESTIMATION

The estimation of multivariate ARMA models in this chapter is done by using the time series program SCA of Scientific Computing Associates. The estimation of multivariate volatility models is done by using either the S-Plus package with FinMetrics or the Regression Analysis for Time Series (RATS) program. Below are some run streams for estimating multivariate volatility models using the RATS program. A line starting with * means “comment” only.

# Estimation of the Diagonal Constant-Correlation AR(2)–GARCH(1,1) Model for Example 10.5

The program includes some Ljung–Box statistics for each component and some fitted values for the last few observations. The data file is m-ibmspln.txt, which has two columns, and there are 888 observations.

```txt
all 0 888:1
open data m-ibmspln.txt
data(org=obs) / r1 r2
set h1 = 0.0
set h2 = 0.0
nonlin a0 a1 b1 a00 a11 b11 rho c1 c2 p1
frml a1t = r1(t) -c1-p1*r2(t-1)
frml a2t = r2(t)-c2
frml gvar1 = a0+a1*a1t(t-1)**2+b1*h1(t-1)
frml gvar2 = a00+a11*a2t(t-1)**2+b11*h2(t-1)
frml gdet = -0.5*(log(h1(t)=gvar1(t))+log(h2(t)=gvar2(t)) $ +log(1.0-rho**2)) 
```

```txt
frml gln = gdet(t) -0.5/(1.0-rho**2)*( (alt(t) **2/h1(t)) $ + (a2t(t) **2/h2(t)) -2*rho*a1t(t) * a2t(t)/sqrt(h1(t) * h2(t)))  
spl 3 888  
compute c1 = 1.22, c2 = 0.57, p1 = 0.1, rho = 0.1  
compute a0 = 3.27, a1 = 0.1, b1 = 0.6  
compute a00 = 1.17, all1 = 0.13, b11 = 0.8  
maximize(method=bhhh, recursive, iterations=150) gln  
set fv1 = gvar1(t)  
set resil = alt(t)/sqrt(fv1(t))  
set residsq = resil(t) * resil(t)  
* Checking standardized residuals *  
cor(qstats, number=12, span=4) resil  
* Checking squared standardized residuals *  
cor(qstats, number=12, span=4) residsq  
set fv2 = gvar2(t)  
set resi2 = a2t(t)/sqrt(fv2(t))  
set residsq = resi2(t) * resi2(t)  
* Checking standardized residuals *  
cor(qstats, number=12, span=4) resi2  
* Checking squared standardized residuals *  
cor(qstats, number=12, span=4) residsq  
* Last few observations needed for computing forecasts *  
set shock1 = alt(t)  
set shock2 = a2t(t)  
print 885 888 shock1 shock2 fv1 fv2 
```

Estimation of the Time-Varying Coefficient Model in Example 10.5   
```txt
all 0 888:1
open data m-ibmspln.txt
data(org=obs) / r1 r2
set h1 = 45.0
set h2 = 31.0
set rho = 0.8
nonlin a0 a1 b1 f1 a00 a11 b11 d11 f11 c1 c2 p1 p3 q0 q1 q2
frml a1t = r1(t)-c1-p1*r1(t-1)-p3*r2(t-2)
frml a2t = r2(t)-c2
frml gvar1 = a0+a1*a1t(t-1)**2+b1*h1(t-1)+f1*h2(t-1)
frml gvar2 = a00+a11*a2t(t-1)**2+b11*h2(t-1)+f11*h1(t-1) $
+d11*a1t(t-1)**2
frml rh1 = q0 + q1*rho(t-1) $
	+ q2*a1t(t-1)*a2t(t-1)/sqrt(h1(t-1)*h2(t-1))
frml rh = exp(rh1(t)) / (1+exp(rh1(t)))
frml gdet = -0.5*(log(h1(t)=gvar1(t))+log(h2(t)=gvar2(t)) $
	+ log(1.0-(rho(t)=rh(t))**2))
frml gln = gdet(t)-0.5/(1.0-rho(t)**2)*( (alt(t)**2/h1(t)) $
	+(a2t(t)**2/h2(t))-2*rho(t)*alt(t)*a2t(t)/sqrt(h1(t)*h2(t)))'
smp1 4 888
compute c1 = 1.4, c2 = 0.7, p1 = 0.1, p3 = -0.1 
```

```txt
compute a0 = 2.95, a1 = 0.08, b1 = 0.87, f1 = -.03  
compute a00 = 2.05, a11 = 0.05  
compute b11 = 0.92, f11=-.06, d11=.04, q0 = -2.0  
compute q1 = 3.0, q2 = 0.1  
nlpar(criterion=value, cvcrit=0.00001)  
maximize(method=bhhh, recursive, iterations=150) gln  
set fv1 = gvar1(t)  
set resil = a1t(t)/sqrt(fv1(t))  
set residsq = resil(t)*resil(t)  
* Checking standardized residuals *  
cor(qstats, number=16, span=4) resil  
* Checking squared standardized residuals *  
cor(qstats, number=16, span=4) residsq  
set fv2 = gvar2(t)  
set resi2 = a2t(t)/sqrt(fv2(t))  
set residsq = resi2(t)*resi2(t)  
* Checking standardized residuals *  
cor(qstats, number=16, span=4) resi2  
* Checking squared standardized residuals *  
cor(qstats, number=16, span=4) residsq  
* Last few observations needed for computing forecasts *  
set rhohat = rho(t)  
set shock1 = a1t(t)  
set shock2 = a2t(t)  
print 885 888 shock1 shock2 fv1 fv2 rhohat 
```

# Estimation of the Time-Varying Coefficient Model in Example 10.5 Using Cholesky Decomposition

```txt
all 0 888:1
open data m-ibmspln.txt
data(org=obs) / r1 r2
set h1 = 45.0
set h2 = 20.0
set q = 0.8
nonlin a0 a1 b1 a00 a11 b11 d11 f11 c1 c2 p1 p3 t0 t1 t2
frml a1t = r1(t) -c1-p1*r1(t-1) -p3*r2(t-2)
frml a2t = r2(t) -c2
frml v1 = a0+a1*a1t(t-1) **2+b1*h1(t-1)
frml qt = t0 + t1*q(t-1) + t2*a2t(t-1)
frml bt = a2t(t) - (q(t)=qt(t)) *alt(t)
frml v2 = a00+a11*b1(t-1) **2+b11*h2(t-1) +f11*h1(t-1) $
+d11*a1t(t-1) **2
frml gdet = -0.5*(log(h1(t) = v1(t)) + log(h2(t)=v2(t)))
frml garchln = gdet-0.5*(a1t(t) **2/h1(t) +bt(t) **2/h2(t))
mpl 5 888
compute c1 = 1.4, c2 = 0.7, p1 = 0.1, p3 = -0.1
compute a0 = 1.0, a1 = 0.08, b1 = 0.87
compute a00 = 2.0, a11 = 0.05, b11 = 0.8
compute d11=.04, f11=-.06, t0 =0.2, t1 = 0.1, t2 = 0.1 
```

```txt
nlpar(criterion=value, cvcrit=0.00001)  
maximize(method=bhhh, recursive, iterations=150) garchln  
set fv1 = v1(t)  
set resil = a1t(t)/sqrt(fv1(t))  
set residsq = resil(t)*resil(t)  
* Checking standardized residuals *  
cor(qstats, number=16, span=4) resil  
* Checking squared standardized residuals *  
cor(qstats, number=16, span=4) residsq  
set fv2 = v2(t)+qt(t)**2*v1(t)  
set resi2 = a2t(t)/sqrt(fv2(t))  
set residsq = resi2(t)*resi2(t)  
* Checking standardized residuals *  
cor(qstats, number=16, span=4) resi2  
* Checking squared standardized residuals *  
cor(qstats, number=16, span=4) residsq  
* Last few observations needed for forecasts *  
set rhohat = qt(t)*sqrt(v1(t)/fv2(t))  
set shock1 = a1t(t)  
set shock2 = a2t(t)  
set g22 = v2(t)  
set q21 = qt(t)  
set b2t = bt(t)  
print 885 888 shock1 shock2 fv1 fv2 rhohat g22 q21 b2t 
```

# Estimation of the Three-Dimensional Time-Varying Correlation Volatility Model in Example 10.6 Using Cholesky Decomposition

Initial estimates are obtained by a sequential modeling procedure.

```txt
all 0 2275:1
open data d-cscointc.txt
data(org=obs) / r1 r2 r3
set h1 = 1.0
set h2 = 4.0
set h3 = 3.0
set q21 = 0.8
set q31 = 0.3
set q32 = 0.3
nonlin c1 c2 c3 p3 p21 p22 p31 p33 a0 a1 a2 t0 t1 t2 b0 b1 $
b2 u0 u1 u2 w0 w1 w2 d0 d1 d2 d5
frml a1t = r1(t) -c1-p3*r1(t-3)
frml a2t = r2(t) -c2-p21*r1(t-2) -p22*r2(t-2)
frml a3t = r3(t) -c3-p31*r1(t-1) -p33*r3(t-1)
frml v1 = a0+a1*a1t(t-1) **2+a2*h1(t-1)
frml q1t = t0 + t1*q21(t-1) + t2*a2t(t-1)
frml bt = a2t(t) - (q21(t)=q1t(t)) *a1t(t)
frml v2 = b0+b1*bt(t-1) **2+b2*h2(t-1) 
```

```csv
frml q2t = u0 + u1*q31(t-1) + u2*a3t(t-1)
frml q3t = w0 + w1*q32(t-1) + w2*a2t(t-1)
frml b1t = a3t(t)-(q31(t)=q2t(t))*a1t(t)-(q32(t)=q3t(t))*bt(t)
frml v3 = d0+d1*b1t(t-1)**2+d2*h3(t-1)+d5*h2(t-1)
frml gdet = -0.5*(log(h1(t) = v1(t))+ log(h2(t)=v2(t)) $ +log(h3(t)=v3(t)))
frml garchln = gdet-0.5*(a1t(t)**2/h1(t)+bt(t)**2/h2(t) $ +b1t(t)**2/h3(t))
simpl 8 2275
compute c1 = 0.07, c2 = 0.33, c3 = 0.19, p1 = 0.1, p3 = -0.04
compute p21 =0.2, p22 = -0.1, p31 = -0.26, p33 = 0.06
compute a0 = .01, a1 = 0.05, a2 = 0.94
compute t0 = 0.28, t1 =0.82, t2 = -0.035
compute b0 = .17, b1 = 0.08, b2 = 0.89
compute u0= 0.04, u1 = 0.97, u2 = 0.01
compute w0 =0.006, w1=0.98, w2=0.004
compute d0 =1.38, d1 = 0.06, d2 = 0.64, d5 = -0.027
nlpar(criterion=value,cvcrit=0.00001)
maximize(method=bhhh,recursive,iterations=250) garchln
set fv1 = v1(t)
set resil = a1t(t)/sqrt(fv1(t))
set residsq = resil(t)*resil(t)
* Checking standardized residuals *
cor(qstats,number=12 span=4) resil
* Checking squared standardized residuals *
cor(qstats,number=12 span=4) residsq
set fv2 = v2(t)+q1t(t)**2*v1(t)
set resi2 = a2t(t)/sqrt(fv2(t))
set residsq = resi2(t)*resi2(t)
* Checking standardized residuals *
cor(qstats,number=12 span=4) resi2
* Checking squared standardized residuals *
cor(qstats,number=12 span=4) residsq
set fv3 = v3(t)+q2t(t)**2*v1(t)+q3t(t)**2*v2(t)
set resi3 = a3t(t)/sqrt(fv3(t))
set residsq = resi3(t)*resi3(t)
* Checking standardized residuals *
cor(qstats,number=12 span=4) resi3
* Checking squared standardized residuals *
cor(qstats,number=12 span=4) residsq
* print standardized residuals and correlation-coefficients
set rho21 = q1t(t)*sqrt(v1(t)/fv2(t))
set rho31 = q2t(t)*sqrt(v1(t)/fv3(t))
set rho32 = (q2t(t)*q1t(t)*v1(t) $
+q3t(t)*v2(t))/sqrt(fv2(t)*fv3(t))
print 10 2275 resil(resi3)
print 10 2275 rho21 rho31 rho32
print 10 2275 fv1 fv2 fv3 
```

# EXERCISES

10.1. Consider the monthly log returns of the S&P composite index, IBM stock, and Hewlett-Packard (HPQ) stock from January 1962 to December 2003 for 504 observations. The log returns are in the file m-spibmhpq6203.txt. Use the exponentially weighted moving-average method to obtain a multivariate volatility series for the three return series. What is the estimated λ? Plot the three volatility series.   
10.2. Focus on the monthly log returns of IBM and HPQ stocks from January 1962 to December 2003. Fit a DVEC(1,1) model to the bivariate return series. Is the model adequate? Plot the fitted volatility series and the time-varying correlations.   
10.3. Focus on the monthly log returns of the S&P composite index and HPQ stock. Build a BEKK model for the bivariate series. What is the fitted model? Plot the fitted volatility series and the time-varying correlations.   
10.4. Build a constant-correlation volatility model for the three monthly log returns of the S&P composite index, IBM stock, and HPQ stock. Write down the fitted model. Is the model adequate? Why?   
10.5. The file m-spibmge.txt contains the monthly log returns in percentages of the S&P 500 index, IBM stock, and General Electric stock from January 1926 to December 1999. The returns include dividends. Focus on the monthly log returns in percentages of GE stock and the S&P 500 index. Build a constantcorrelation GARCH model for the bivariate series. Check the adequacy of the fitted model, and obtain the 1-step ahead forecast of the covariance matrix at the forecast origin December 1999.   
10.6. Focus on the monthly log returns in percentages of GE stock and the S&P 500 index. Build a time-varying correlation GARCH model for the bivariate series using a logistic function for the correlation coefficient. Check the adequacy of the fitted model, and obtain the 1-step ahead forecast of the covariance matrix at the forecast origin December 1999.   
10.7. Focus on the monthly log returns in percentages of GE stock and the S&P 500 index. Build a time-varying correlation GARCH model for the bivariate series using the Cholesky decomposition. Check the adequacy of the fitted model, and obtain the 1-step ahead forecast of the covariance matrix at the forecast origin December 1999. Compare the model with the other two models built in the previous exercises.   
10.8. Consider the three-dimensional return series jointly. Build a multivariate time-varying volatility model for the data, using the Cholesky decomposition. Discuss the implications of the model and compute the 1-step ahead volatility forecast at the forecast origin $t = 8 8 8$ .

10.9. An investor is interested in daily value at risk of his position on holding long $\$ 0.5$ million of Dell stock and $\$ 1$ million of Cisco Systems stock. Use $5 \%$ critical values and the daily log returns from February 20, 1990 to December 31, 1999 to do the calculation. The data are in the file d-dellcsco9099.txt. Apply the three approaches to volatility modeling in Section 10.7 and compare the results.

# REFERENCES

Bauwens, L., Laurent, S. and Rombouts, J. V. K. (2004). Multivariate GARCH models: a survey. Journal of Applied Econometrics (to appear).   
Bollerslev, T. (1990). Modeling the coherence in short-term nominal exchange rates: A multivariate generalized ARCH approach. Review of Economics and Statistics 72: 498–505.   
Bollerslev, T., Engle, R. F., and Wooldridge, J. M. (1988). A capital-asset pricing model with time-varying covariances. Journal of Political Economy 96: 116–131.   
Chib, S., Nardari, F. and Shephard, N. (1999). Analysis of high dimensional multivariate stochastic volatility models. Working paper, Washington University, St. Louis.   
Engle, R. F. (2002). Dynamic conditional correlation: a simple class of multivariate GARCH models. Journal of Business and Economic Statistics 20: 339–350.   
Engle, R. F. and Kroner, K. F. (1995). Multivariate simultaneous generalized ARCH. Econometric Theory 11: 122–150.   
McCulloch, R.E., Polson, N., and Tsay, R. S. (2000), “Multivariate volatility models,” Working paper, Graduate School of Business, University of Chicago.   
Mardia, K. V., Kent, J. T., and Bibby, J. M. (1979). Multivariate Analysis. Academic Press, New York.   
Pourahmadi, M. (1999). Joint mean-covariance models with applications to longitudinal data: Unconstrained parameterization. Biometrika 86: 677–690.   
Tse, Y. K. (2000). A test for constant correlations in a multivariate GARCH model. Journal of Econometrics 98: 107–127.   
Tse, Y. K. and Tsui, A. K. C. (2002). A multivariate GARCH model with time-varying correlations. Journal of Business & Economic Statistics 20: 351–362.

# State-Space Models and Kalman Filter

The state-space model provides a flexible approach to time series analysis, especially for simplifying maximum likelihood estimation and handling missing values. In this chapter, we discuss the relationship between the state-space model and the ARIMA model, the Kalman filter algorithm, various smoothing methods, and some applications. We begin with a simple model that shows the basic ideas of the statespace approach to time series analysis before introducing the general state-space model. For demonstrations, we use the model to analyze realized volatility series of asset returns, the time-varying coefficient market models, and the quarterly earnings per share of a company.

There are many books on statistical analysis using the state-space model. Durbin and Koopman (2001) provide a recent treatment of the approach, Kim and Nelson (1999) focus on economic applications and regime switching, and Anderson and Moore (1979) give a nice summary of theory and applications of the approach for engineering and optimal control. Many time series textbooks include the Kalman filter and state-space model. For example, Chan (2002), Shumway and Stoffer (2000), Hamilton (1994), and Harvey (1993) all have chapters on the topic. West and Harrison (1997) provide a Bayesian treatment with emphasis on forecasting, and Kitagawa and Gersch (1996) use a smoothing prior approach.

The derivation of Kalman filter and smoothing algorithms necessarily involves heavy notation. Therefore, Section 11.4 could be dry for readers who are interested mainly in the concept and applications of state-space models and can be skipped on the first read.

# 11.1 LOCAL TREND MODEL

Consider the univariate time series $y _ { t }$ satisfying

$$
y _ {t} = \mu_ {t} + e _ {t}, \quad e _ {t} \sim N \left(0, \sigma_ {e} ^ {2}\right), \tag {11.1}
$$

$$
\mu_ {t + 1} = \mu_ {t} + \eta_ {t}, \quad \eta_ {t} \sim N \left(0, \sigma_ {\eta} ^ {2}\right), \tag {11.2}
$$

where $\{ e _ { t } \}$ and $\{ \eta _ { t } \}$ are two independent Gaussian white noise series and $t =$ $1 , \ldots , T$ . The initial value $\mu _ { 1 }$ is either given or follows a known distribution, and it is independent of $\{ e _ { t } \}$ and $\{ \eta _ { t } \}$ for $t > 0$ . Here $\mu _ { t }$ is a pure random walk of Chapter 2 with initial value $\mu _ { 1 }$ and $y _ { t }$ is an observed version of $\mu _ { t }$ with added noise $a _ { t }$ . In the literature, $\mu _ { t }$ is referred to as the trend of the series, which is not directly observable, and $y _ { t }$ is the observed data with observational noise $e _ { t }$ . The dynamic dependence of $y _ { t }$ is governed by that of $\mu _ { t }$ because $\left\{ \boldsymbol { e } _ { t } \right\}$ is not serially correlated.

The model in Eqs. (11.1) and (11.2) can readily be used to analyze realized volatility of an asset price; see Example 11.1 below. Here $\mu _ { t }$ represents the underlying log volatility of the asset price and $y _ { t }$ is the logarithm of realized volatility. The true log volatility is not directly observed but evolves over time according to a random-walk model. On the other hand, $y _ { t }$ is constructed from high-frequency transactions data and subjected to the influence of market microstructure. The standard deviation of $e _ { t }$ denotes the scale used to measure the impact of market microstructure.

The model in Eqs. (11.1) and (11.2) is a special linear Gaussian state-space model. The variable $\mu _ { t }$ is called the state of the system at time $t$ and is not directly observed. Equation (11.1) provides the link between the data $y _ { t }$ and the state $\mu _ { t }$ and is called the observation equation with measurement error $e _ { t }$ . Equation (11.2) governs the time evolution of the state variable and is the state equation (or state transition equation) with innovation $\eta _ { t }$ . The model is also called a local level model in Durbin and Koopman (2001, Chapter 2), which is a simple case of the structural time series model of Harvey (1993).

# Relationship to ARIMA Model

If there is no measurement error in Eq. (11.1), that is, $\sigma _ { e } = 0$ , then $y _ { t } = \mu _ { t }$ , which is an ARIMA(0,1,0) model. If $\sigma _ { e } > 0$ , that is, there exist measurement errors, then $y _ { t }$ is an ARIMA(0,1,1) model satisfying

$$
(1 - B) y _ {t} = (1 - \theta B) a _ {t}, \tag {11.3}
$$

where $\{ a _ { t } \}$ is a Gaussian white noise with mean zero and variance $\sigma _ { a } ^ { 2 }$ . The values of $\theta$ and $\sigma _ { a } ^ { 2 }$ are determined by $\sigma _ { e }$ and $\sigma _ { \eta }$ . This result can be derived as follows.

From Eq. (11.2), we have

$$
(1 - B) \mu_ {t + 1} = \eta_ {t}, \quad \text {o r} \quad \mu_ {t + 1} = \frac {1}{1 - B} \eta_ {t}.
$$

Using this result, Eq. (11.1) can be written as

$$
y _ {t} = \frac {1}{1 - B} \eta_ {t - 1} + e _ {t}.
$$

Multiplying by $( 1 - B )$ , we have

$$
(1 - B) y _ {t} = \eta_ {t - 1} + e _ {t} - e _ {t - 1}.
$$

Let $( 1 - B ) y _ { t } = w _ { t }$ . We have $w _ { t } = \eta _ { t - 1 } + e _ { t } - e _ { t - 1 }$ . Under the assumptions, it is easy to see that (a) $w _ { t }$ is Gaussian, (b) $\mathrm { V a r } ( w _ { t } ) = 2 \sigma _ { e } ^ { 2 } + \sigma _ { \eta } ^ { 2 }$ , (c) $\mathrm { C o v } ( w _ { t } , w _ { t - 1 } ) =$ $- \sigma _ { e } ^ { 2 }$ , and (d) $\mathrm { C o v } ( w _ { t } , w _ { t - j } ) = 0$ for $j > 1$ . Consequently, $w _ { t }$ follows an MA(1) model and can be written as $w _ { t } = ( 1 - \theta B ) a _ { t }$ . By equating the variance and lag-1 autocovariance of $w _ { t } = ( 1 - \theta B ) a _ { t } = \eta _ { t - 1 } + e _ { t } - e _ { t - 1 }$ , we have

$$
(1 + \theta^ {2}) \sigma_ {a} ^ {2} = 2 \sigma_ {e} ^ {2} + \sigma_ {\eta} ^ {2},
$$

$$
\theta \sigma_ {a} ^ {2} = \sigma_ {e} ^ {2}.
$$

For given $\sigma _ { e } ^ { 2 }$ and $\sigma _ { \eta } ^ { 2 }$ , one considers the ratio of the prior two equations to form a quadratic function of $\theta$ . This quadratic form has two solutions so one should select the one that satisfies $| \theta | < 1$ . The value of $\sigma _ { a } ^ { 2 }$ can then be easily obtained. Thus, the state-space model in Eqs. (11.1) and (11.2) is also an ARIMA(0,1,1) model, which is the simple exponential smoothing model of Chapter 2.

On the other hand, for an ARIMA(0,1,1) model with positive $\theta$ , one can use the prior two identities to solve for $\sigma _ { e } ^ { 2 }$ and $\sigma _ { \eta } ^ { 2 }$ , and obtain a local trend model. If $\theta$ is negative, then the model can still be put in a state-space form without the observational error, that is, $\sigma _ { e } = 0$ . In fact, as will be seen later, an ARIMA model can be transformed into state-space models in many ways. Thus, the linear state-space model is closely related to the ARIMA model.

In practice, what one observes is the $y _ { t }$ series. Thus, based on the data alone, the decision of using ARIMA models or linear state-space models is not critical. Both model representations have pros and cons. The objective of data analysis, substantive issues, and experience all play a role in choosing a statistical model.

Example 11.1. To illustrate the ideas of the state-space model and Kalman filter, we consider the intradaily realized volatility of Alcoa stock from January 2, 2003 to May 7, 2004 for 340 observations. The daily realized volatility used is the sum of squares of intraday 10-minute log returns measured in percentage. No overnight returns or the first 10-minute intraday returns are used. See Chapter 3 for more information about realized volatility. The series used in the demonstration is the logarithm of the daily realized volatility.

Figure 11.1 shows the time plot of the logarithms of the realized volatility of Alcoa stock from January 2, 2003 to May 7, 2004. The transactions data are obtained from the TAQ database of the NYSE. If ARIMA models are entertained, we obtain an ARIMA(0,1,1) model

$$
(1 - B) y _ {t} = (1 - 0. 8 5 5 B) a _ {t}, \quad \hat {\sigma} _ {a} = 0. 5 1 8 4, \tag {11.4}
$$

where $y _ { t }$ is the log realized volatility, and the standard error of $\hat { \theta }$ is 0.029. The residuals show $Q ( 1 2 ) = 1 2 . 4 $ with $p$ -value 0.33, indicating that there is no significant

![](images/0c3fc8b4ee7400362cd550388b0b6f8a4cc6adabde45ce48bf1559f5a8d7e943.jpg)  
Figure 11.1. Time plot of the logarithms of intradaily realized volatility of Alcoa stock from January 2, 2003 to May 7, 2004. The realized volatility is computed from the intraday 10-minute log returns measured in percentage.

serial correlation in the residuals. Similarly, the squared residuals give $Q ( 1 2 ) = 8 . 2 $ with $p$ -value 0.77, suggesting no ARCH effects in the series.

Since $\hat { \theta }$ is positive, we can transform the ARIMA(0,1,1) model into a local trend model in Eqs. (11.1) and (11.2). The maximum likelihood estimates of the two parameters are $\hat { \sigma } _ { \eta } = 0 . 0 7 3 5$ and $\hat { \sigma } _ { e } = 0 . 4 8 0 3$ . The measurement errors have a larger variance than the state innovations, confirming that intraday high-frequency returns are subject to measurement errors. Details of estimation will be discussed in Section 11.1.7. Here we treat the two estimates as given and use the model to demonstrate application of the Kalman filter.

# 11.1.1 Statistical Inference

Return to the state-space model in Eqs. (11.1) and (11.2). The aim of the analysis is to infer properties of the state $\mu _ { t }$ from the data $\{ y _ { t } | t = 1 , \ldots , T \}$ and the model. Three types of inference are commonly discussed in the literature. They are filtering, prediction, and smoothing. Let $F _ { t } = \{ y _ { 1 } , . . . , y _ { t } \}$ be the information available at time t (inclusive) and assume that the model is known, including all parameters. The three types of inference can briefly be described as follows:

• Filtering. Filtering means to recover the state variable $\mu _ { t }$ given $F _ { t }$ , that is, to remove the measurement errors from the data.

• Prediction. Prediction means to forecast $\mu _ { t + h }$ or $y _ { t + h }$ for $h > 0$ given $F _ { t }$ , where $t$ is the forecast origin.   
• Smoothing. Smoothing is to estimate $\mu _ { t }$ given $F _ { T }$ , where $T > t$ .

A simple analogy of the three types of inference is reading a handwritten note. Filtering is figuring out the word you are reading based on knowledge accumulated from the beginning of the note, predicting is to guess the next word, and smoothing is deciphering a particular word once you have read through the note.

To describe the inference more precisely, we introduce some notation. Let $\mu _ { t | j } = E ( \mu _ { t } | F _ { j } )$ and $\begin{array} { r } { \Sigma _ { t | j } = \mathrm { V a r } ( \mu _ { t } | F _ { j } ) } \end{array}$ be, respectively, the conditional mean and variance of $\mu _ { t }$ given $F _ { j }$ . Similarly, $y _ { t \mid j }$ denotes the conditional mean of $y _ { t }$ given $F _ { j }$ . Furthermore, let $\upsilon _ { t } = y _ { t } - y _ { t | t - 1 }$ and $V _ { t } = \mathrm { V a r } ( v _ { t } | F _ { t - 1 } )$ be the 1-step ahead forecast error and its variance of $y _ { t }$ given $F _ { t - 1 }$ . Note that the forecast error $v _ { t }$ is independent of $F _ { t - 1 }$ so that the conditional variance is the same as the unconditional variance; that is, $\operatorname { V a r } ( v _ { t } | F _ { t - 1 } ) = \operatorname { V a r } ( v _ { t } )$ . From Eq. (11.1),

$$
y _ {t | t - 1} = E (y _ {t} | F _ {t - 1}) = E (\mu_ {t} + e _ {t} | F _ {t - 1}) = E (\mu_ {t} | F _ {t - 1}) = \mu_ {t | t - 1}.
$$

Consequently,

$$
v _ {t} = y _ {t} - y _ {t \mid t - 1} = y _ {t} - \mu_ {t \mid t - 1} \tag {11.5}
$$

and

$$
\begin{array}{l} V _ {t} = \operatorname {V a r} \left(y _ {t} - \mu_ {t | t - 1} \mid F _ {t - 1}\right) = \operatorname {V a r} \left(\mu_ {t} + e _ {t} - \mu_ {t | t - 1} \mid F _ {t - 1}\right) \\ = \operatorname {V a r} \left(\mu_ {t} - \mu_ {t | t - 1} \mid F _ {t - 1}\right) + \operatorname {V a r} \left(e _ {t} \mid F _ {t - 1}\right) = \Sigma_ {t | t - 1} + \sigma_ {e} ^ {2}. \tag {11.6} \\ \end{array}
$$

It is also easy to see that

$$
E (v _ {t}) = E [ E (v _ {t} | F _ {t - 1}) ] = E [ E (y _ {t} - y _ {t | t - 1} | F _ {t - 1}) ] = E [ y _ {t | t - 1} - y _ {t | t - 1} ] = 0,
$$

$$
\operatorname {C o v} \left(v _ {t}, y _ {j}\right) = E \left(v _ {t} y _ {j}\right) = E \left[ E \left(v _ {t} y _ {j} \mid F _ {t - 1}\right) \right] = E \left[ y _ {j} E \left(v _ {t} \mid F _ {t - 1}\right) \right] = 0, \quad j <   t.
$$

Thus, as expected, the 1-step ahead forecast error is uncorrelated (hence, independent) with $y _ { j }$ for $j < t$ . Furthermore, for the linear model in Eqs. (11.1) and (11.2), $\mu _ { t | t } = E ( \mu _ { t } | F _ { t } ) = E ( \mu _ { t } | F _ { t - 1 } , v _ { t } )$ and $\Sigma _ { t \mid t } = { \mathrm { V a r } } ( \mu _ { t } \vert F _ { t } ) = { \mathrm { V a r } } ( \mu _ { t } \vert F _ { t - 1 } , v _ { t } )$ . In other words, the information set $F _ { t }$ can be written as $F _ { t } = \{ F _ { t - 1 } , y _ { t } \} = \{ F _ { t - 1 } , v _ { t } \}$ .

The following properties of multivariate normal distribution are useful in studying the Kalman filter under normality. They can be shown via the multivariate linear regression method or factorization of the joint density. See, also, Appendix B of Chapter 8. For random vectors $\pmb { w }$ and $\mathbf { \nabla } m$ , denote the mean vectors and covariance matrix as $E ( \pmb { w } ) = \pmb { \mu } _ { w }$ , $E ( \pmb { m } ) = \pmb { \mu } _ { m }$ , and $\mathrm { C o v } ( \pmb { m } , \pmb { w } ) = \pmb { \Sigma } _ { m w }$ , respectively.

Theorem 11.1. Suppose that $x , y$ , and z are three random vectors such that their joint distribution is multivariate normal. In addition, assume that the diagonal block covariance matrix $\pmb { \Sigma } _ { w w }$ is nonsingular for $w = x , y , z$ , and $\pmb { \Sigma } _ { y z } = \pmb { 0 }$ . Then,

1. $E ( \pmb { x } | \pmb { y } ) = \pmb { \mu _ { x } } + \pmb { \Sigma } _ { x y } \pmb { \Sigma } _ { y y } ^ { - 1 } ( \pmb { y } - \pmb { \mu } _ { y } ) .$   
2. $\mathrm { V a r } ( { \pmb x } | { \pmb y } ) = \pmb { \Sigma } _ { x x } - \pmb { \Sigma } _ { x x } \pmb { \Sigma } _ { y y } ^ { - 1 } \pmb { \Sigma } _ { y x }$ .

3. $E ( { \pmb x } | { \pmb y } , z ) = E ( { \pmb x } | { \pmb y } ) + \pmb { \Sigma } _ { x z } \pmb { \Sigma } _ { z z } ^ { - 1 } ( z - \pmb { \mu } _ { z } ) .$   
4. $\operatorname { V a r } ( { \pmb x } | { \pmb y } , { \pmb z } ) = \operatorname { V a r } ( { \pmb x } | { \pmb y } ) - \pmb { \Sigma } _ { { \pmb x } { \pmb z } } \pmb { \Sigma } _ { { \pmb z } { \pmb z } } ^ { - 1 } \pmb { \Sigma } _ { { \pmb z } { \pmb x } } .$ .

# 11.1.2 Kalman Filter

The goal of the Kalman filter is to update knowledge of the state variable recursively when a new data point becomes available. That is, knowing the conditional distribution of $\mu _ { t }$ given $F _ { t - 1 }$ and the new data $y _ { t }$ , we would like to obtain the conditional distribution of $\mu _ { t }$ given $F _ { t }$ , where, as before, $F _ { j } = \{ y _ { 1 } , \ldots , y _ { j } \}$ . Since $F _ { t } = \{ F _ { t - 1 } , v _ { t } \}$ , giving $y _ { t }$ and $F _ { t - 1 }$ is equivalent to giving $v _ { t }$ and $F _ { t - 1 }$ . Consequently, to derive the Kalman filter, it suffices to consider the joint conditional distribution of $( \mu _ { t } , v _ { t } ) ^ { \prime }$ given $F _ { t - 1 }$ before applying Theorem 11.1.

The conditional distribution of $v _ { t }$ given $F _ { t - 1 }$ is normal with mean zero and variance given in Eq. (11.6), and that of $\mu _ { t }$ given $F _ { t - 1 }$ is also normal with mean $\mu _ { t \mid t - 1 }$ and variance $\Sigma _ { t \left. t - 1 \right. }$ . Furthermore, the joint distribution of $( \mu _ { t } , v _ { t } ) ^ { \prime }$ given $F _ { t - 1 }$ is also normal. Thus, what remains to be solved is the conditional covariance between $\mu _ { t }$ and $v _ { t }$ given $F _ { t - 1 }$ . From the definition,

$$
\begin{array}{l} \operatorname {C o v} \left(\mu_ {t}, v _ {t} \mid F _ {t - 1}\right) = E \left(\mu_ {t} v _ {t} \mid F _ {t - 1}\right) = E \left[ \mu_ {t} \left(y _ {t} - \mu_ {t \mid t - 1}\right) \mid F _ {t - 1} \right] \quad (\text {b y}) \\ = E \left[ \mu_ {t} \left(\mu_ {t} + e _ {t} - \mu_ {t \mid t - 1}\right) \mid F _ {t - 1} \right] \\ = E \left[ \mu_ {t} \left(\mu_ {t} - \mu_ {t \mid t - 1}\right) \mid F _ {t - 1} \right] + E \left(\mu_ {t} e _ {t} \mid F _ {t - 1}\right) \\ = E \left[ \left(\mu_ {t} - \mu_ {t | t - 1}\right) ^ {2} \mid F _ {t - 1} \right] = \operatorname {V a r} \left(\mu_ {t} \mid F _ {t - 1}\right) = \Sigma_ {t | t - 1}, \tag {11.7} \\ \end{array}
$$

where we have used the fact that $E [ \mu _ { t | t - 1 } ( \mu _ { t } - \mu _ { t | t - 1 } ) | F _ { t - 1 } ] = 0$ . Putting the results together, we have

$$
\left[ \begin{array}{c} \mu_ {t} \\ v _ {t} \end{array} \right] _ {F _ {t - 1}} \sim N \left(\left[ \begin{array}{c} \mu_ {t | t - 1} \\ 0 \end{array} \right], \left[ \begin{array}{c c} \Sigma_ {t | t - 1} & \Sigma_ {t | t - 1} \\ \Sigma_ {t | t - 1} & V _ {t} \end{array} \right]\right).
$$

By Theorem 11.1, the conditional distribution of $\mu _ { t }$ given $F _ { t }$ is normal with mean and variance

$$
\mu_ {t \mid t} = \mu_ {t \mid t - 1} + \frac {\sum_ {t \mid t - 1} v _ {t}}{V _ {t}} = \mu_ {t \mid t - 1} + K _ {t} v _ {t}, \tag {11.8}
$$

$$
\Sigma_ {t | t} = \Sigma_ {t | t - 1} - \frac {\Sigma_ {t | t - 1} ^ {2}}{V _ {t}} = \Sigma_ {t | t - 1} \left(1 - K _ {t}\right), \tag {11.9}
$$

where $K _ { t } = \Sigma _ { t \mid t - 1 } / V _ { t }$ is commonly referred to as the Kalman gain, which is the regression coefficient of $\mu _ { t }$ on $v _ { t }$ . From Eq. (11.8), Kalman gain is the factor that governs the contribution of the new shock $v _ { t }$ to the state variable $\mu _ { t }$ .

Next, one can make use of the knowledge of $\mu _ { t }$ given $F _ { t }$ to predict $\mu _ { t + 1 }$ via Eq. (11.2). Specifically, we have

$$
\mu_ {t + 1 \mid t} = E \left(\mu_ {t} + \eta_ {t} \mid F _ {t}\right) = E \left(\mu_ {t} \mid F _ {t}\right) = \mu_ {t \mid t}, \tag {11.10}
$$

$$
\Sigma_ {t + 1 | t} = \operatorname {V a r} \left(\mu_ {t + 1} \mid F _ {t}\right) = \operatorname {V a r} \left(\mu_ {t} \mid F _ {t}\right) + \operatorname {V a r} \left(\eta_ {t}\right) = \Sigma_ {t | t} + \sigma_ {\eta} ^ {2}. \tag {11.11}
$$

Once the new data $y _ { t + 1 }$ is observed, one can repeat the above procedure to update knowledge of $\mu _ { t + 1 }$ . This is the famous Kalman filter algorithm proposed by Kalman (1960).

In summary, putting Eqs. (11.5)–(11.11) together and conditioning on the initial assumption that $\mu _ { 1 }$ is distributed as $N ( \mu _ { 1 | 0 } , \Sigma _ { 1 | 0 } )$ , the Kalman filter for the local trend model is as follows:

$$
v _ {t} = y _ {t} - \mu_ {t | t - 1},
$$

$$
V _ {t} = \Sigma_ {t | t - 1} + \sigma_ {e} ^ {2},
$$

$$
K _ {t} = \Sigma_ {t | t - 1} / V _ {t}, \tag {11.12}
$$

$$
\mu_ {t + 1 | t} = \mu_ {t | t - 1} + K _ {t} v _ {t},
$$

$$
\Sigma_ {t + 1 | t} = \Sigma_ {t | t - 1} (1 - K _ {t}) + \sigma_ {\eta} ^ {2}, \quad t = 1, \dots , T.
$$

There are many ways to derive the Kalman filter. We use Theorem 11.1, which describes some properties of multivariate normal distribution, for its simplicity. In practice, the choice of initial values $\Sigma _ { 1 | 0 }$ and $\mu _ { 1 | 0 }$ requires some attention and we shall discuss it later in Section 11.1.6. For the local trend model in Eqs. (11.1) and (11.2), the two parameters $\sigma _ { e }$ and $\sigma _ { \eta }$ can be estimated via the maximum likelihood method. Again, the Kalman filter is useful in evaluating the likelihood function of the data in estimation. We shall discuss estimation in Section 11.1.7.

Example 11.1 (Continued). To illustrate application of the Kalman filter, we use the fitted state-space model for daily realized volatility of Alcoa stock returns and apply the Kalman filter algorithm to the data with $\Sigma _ { 1 | 0 } = \infty$ and $\mu _ { 1 | 0 } = 0$ . The choice of these initial values will be discussed in Section 11.1.6. Figure 11.2a shows the time plot of the filtered state variable $\mu _ { t | t }$ and Figure 11.2b is the time plot of the 1-step ahead forecast error $v _ { t }$ . Compared with Figure 11.1, the filtered states are smoother. The forecast errors appear to be stable and center around zero. These forecast errors are out-of-sample 1-step ahead prediction errors.

# 11.1.3 Properties of Forecast Error

The one-step ahead forecast errors $\{ v _ { t } \}$ are useful in many applications, hence it pays to study carefully their properties. Given the initial values $\Sigma _ { 1 | 0 }$ and $\mu _ { 1 | 0 }$ , which are independent of $y _ { t }$ , the Kalman filter enables us to compute $v _ { t }$ recursively as a linear function of $\{ y _ { 1 } , \ldots , y _ { t } \}$ . Specifically, by repeated substitutions,

$$
v _ {1} = y _ {1} - \mu_ {1 | 0},
$$

$$
v _ {2} = y _ {2} - \mu_ {2 | 1} = y _ {2} - \mu_ {1 | 0} - K _ {1} (y _ {1} - \mu_ {1 | 0}),
$$

$$
v _ {3} = y _ {3} - \mu_ {3 | 2} = y _ {3} - \mu_ {1 | 0} - K _ {2} (y _ {2} - \mu_ {1 | 0}) - K _ {1} (1 - K _ {2}) (y _ {1} - \mu_ {1 | 0}),
$$

and so on. This transformation can be written in matrix form as

$$
\boldsymbol {v} = \boldsymbol {K} (\boldsymbol {y} - \mu_ {1 | 0} \mathbf {1} _ {T}), \tag {11.13}
$$

![](images/d4784b1c1b288de18f5f2e71565e8a6ec179cde912e1cf55d23cc4625bf2a61b.jpg)  
(a) Filtered state variable

![](images/64b2fc11b8e37ea6cb9d3c860b0351f1cea13e662ae6ef163ae2720d4e44b61a.jpg)  
(b) Prediction error   
Figure 11.2. Time plots of output of the Kalman filter applied to the daily realized log volatility of Alcoa stock based on the local trend state-space model: (a) the filtered state $\mu _ { t \mid t }$ and (b) the one-step ahead forecast error $v _ { t }$ .

where $\pmb { v } = ( v _ { 1 } , \dots , v _ { T } ) ^ { \prime }$ $\pmb { v } = ( v _ { 1 } , \ldots , v _ { T } ) ^ { \prime } , \ \pmb { y } = ( y _ { 1 } , \ldots , y _ { T } ) ^ { \prime }$ , ${ \bf 1 } _ { T }$ is the $T$ -dimensional vector of ones, and $\pmb { K }$ is a lower triangular matrix defined as

$$
\boldsymbol {K} = \left[ \begin{array}{c c c c c} 1 & 0 & 0 & \dots & 0 \\ k _ {2 1} & 1 & 0 & \dots & 0 \\ k _ {3 1} & k _ {3 2} & 1 & & 0 \\ \vdots & \vdots & & & \vdots \\ k _ {T 1} & k _ {T 2} & k _ {T 3} & \dots & 1 \end{array} \right],
$$

where $k _ { i , i - 1 } = - K _ { i - 1 }$ and $k _ { i j } = - ( 1 - K _ { i - 1 } ) ( 1 - K _ { i - 2 } ) \cdot \cdot \cdot ( 1 - K _ { j + 1 } ) K _ { j }$ for $i =$ $2 , \ldots , T$ and $j = 1 , \dots , i - 2$ . It should be noted that, from the definition, the Kalman gain $K _ { t }$ does not depend on $\mu _ { 1 | 0 }$ or the data $\{ y _ { 1 } , \ldots , y _ { t } \}$ ; it depends on $\Sigma _ { 1 | 0 }$ and $\sigma _ { e } ^ { 2 }$ and $\sigma _ { \eta } ^ { 2 }$ .

The transformation in Eq. (11.13) has several important implications. First, $\{ v _ { t } \}$ are mutually independent under the normality assumption. To show this, consider the joint probability density function of the data

$$
p (y _ {1}, \dots , y _ {T}) = p (y _ {1}) \prod_ {j = 2} ^ {T} p (y _ {j} | F _ {j - 1}).
$$

Equation (11.13) indicates that the transformation from $y _ { t }$ to $v _ { t }$ has a unit Jacobian so that $p ( \pmb { v } ) = p ( \pmb { y } )$ . Furthermore, since $\mu _ { 1 | 0 }$ is given, $p ( v _ { 1 } ) = p ( y _ { 1 } )$ . Consequently, the joint probability density function of $v$ is

$$
p (\boldsymbol {v}) = p (\boldsymbol {y}) = p (y _ {1}) \prod_ {j = 2} ^ {T} p (y _ {j} | F _ {j - 1}) = p (v _ {1}) \prod_ {j} ^ {T} p (v _ {j}) = \prod_ {j = 1} ^ {T} p (v _ {j}).
$$

This shows that $\{ v _ { t } \}$ are mutually independent.

Second, the Kalman filter provides a Cholesky decomposition of the covariance matrix of $\textbf { y }$ . To see this, let $\pmb { \Omega } = \mathbf { C } \mathbf { o v } ( \pmb { y } )$ . Equation (11.13) shows that $\mathrm { C o v } ( \pmb { v } ) =$ ${ \pmb K } \pmb { \Omega } { \pmb K } ^ { \prime }$ . On the other hand, $\{ v _ { t } \}$ are mutually independent with $\mathrm { V a r } ( v _ { t } ) = V _ { t }$ . Therefore, $K \Omega K ^ { \prime } = \operatorname { d i a g } \{ V _ { 1 } , . . . , V _ { T } \}$ , which is precisely a Cholesky decomposition of $\pmb { \Omega }$ . The elements $k _ { i j }$ of the matrix $\pmb { K }$ thus have some nice interpretations; see Chapter 10.

# State Error Recursion

Turn to the estimation error of the state variable $\mu _ { t }$ . Define

$$
x _ {t} = \mu_ {t} - \mu_ {t | t - 1}
$$

as the forecast error of the state variable $\mu _ { t }$ given data $F _ { t - 1 }$ . From Section 11.1.1, $\operatorname { V a r } ( x _ { t } | F _ { t - 1 } ) = \Sigma _ { t | t - 1 }$ . From the Kalman filter in Eq. (11.12),

$$
v _ {t} = y _ {t} - \mu_ {t | t - 1} = \mu_ {t} + e _ {t} - \mu_ {t | t - 1} = x _ {t} + e _ {t},
$$

and

$$
\begin{array}{l} x _ {t + 1} = \mu_ {t + 1} - \mu_ {t + 1 | t} = \mu_ {t} + \eta_ {t} - \left(\mu_ {t | t - 1} + K _ {t} v _ {t}\right) \\ = x _ {t} + \eta_ {t} - K _ {t} v _ {t} = x _ {t} + \eta_ {t} - K _ {t} \left(x _ {t} + e _ {t}\right) = L _ {t} x _ {t} + \eta_ {t} - K _ {t} e _ {t}, \\ \end{array}
$$

where $L _ { t } = 1 - K _ { t } = 1 - \Sigma _ { t | t - 1 } / V _ { t } = ( V _ { t } - \Sigma _ { t | t - 1 } ) / V _ { t } = \sigma _ { e } ^ { 2 } / V _ { t }$ . Consequently, for the state errors, we have

$$
v _ {t} = x _ {t} + e _ {t}, \quad x _ {t + 1} = L _ {t} x _ {t} + \eta_ {t} - K _ {t} e _ {t}, \quad t = 1, \dots , T, \tag {11.14}
$$

where $x _ { 1 } = \mu _ { 1 } - \mu _ { 1 | 0 }$ . Equation (11.14) is in the form of a time-varying state-space model with $x _ { t }$ being the state variable and $v _ { t }$ the observation.

# 11.1.4 State Smoothing

Next we consider the estimation of the state variables $\{ \mu _ { 1 } , \ldots , \mu _ { T } \}$ given the data $F _ { T }$ and the model. That is, given the state-space model in Eqs. (11.1) and (11.2), we wish to obtain the conditional distribution $\mu _ { t } | F _ { T }$ for all $t$ . To this end, we first recall some facts available about the model:

• All distributions involved are normal so that we can write the conditional distribution of $\mu _ { t }$ given $F _ { T }$ as $N ( \mu _ { t \mid T } , \Sigma _ { t \mid T } )$ , where $t \leq T$ . We refer to $\mu _ { t | T }$ as the smoothed state at time $t$ and $\Sigma _ { t \mid T }$ as the smoothed state variance.

• Based on the properties of $\{ v _ { t } \}$ shown in Section 11.1.3, $\{ v _ { 1 } , \ldots , v _ { T } \}$ are mutually independent and are linear functions of $\{ y _ { 1 } , . . . , y _ { T } \}$ .   
• If $y _ { 1 } , \ldots , y _ { T }$ are fixed, then $F _ { t - 1 }$ and $\{ v _ { t } , \ldots , v _ { T } \}$ are fixed, and vice versa.   
• $\{ v _ { t } , \ldots , v _ { T } \}$ are independent of $F _ { t - 1 }$ with mean zero and variance ${ \mathrm { V a r } } ( v _ { j } ) =$ $V _ { j }$ for $j \geq t$ .

Applying Theorem 11.1(3) to the conditional joint distribution of $( \mu _ { t } , v _ { t } , \ldots$ $v _ { T } )$ given $F _ { t - 1 }$ , we have

$$
\begin{array}{l} \mu_ {t \mid T} = E \left(\mu_ {t} \mid F _ {T}\right) = E \left(\mu_ {t} \mid F _ {t - 1}, v _ {t}, \dots , v _ {T}\right) \\ = E \left(\mu_ {t} \mid F _ {t - 1}\right) + \operatorname {C o v} \left[ \mu_ {t}, \left(v _ {t}, \dots , v _ {T}\right) ^ {\prime} \right] \operatorname {C o v} \left[ \left(v _ {t}, \dots , v _ {T}\right) ^ {\prime} \right] ^ {- 1} \left(v _ {t}, \dots , v _ {T}\right) ^ {\prime} \\ = \mu_ {t | t - 1} + \left[ \begin{array}{c} \operatorname {C o v} \left(\mu_ {t}, v _ {t}\right) \\ \operatorname {C o v} \left(\mu_ {t}, v _ {t + 1}\right) \\ \vdots \\ \operatorname {C o v} \left(\mu_ {t}, v _ {T}\right) \end{array} \right] ^ {\prime} \left[ \begin{array}{c c c c} V _ {t} & 0 & \dots & 0 \\ 0 & V _ {t + 1} & \dots & 0 \\ \vdots & \vdots & & \vdots \\ 0 & 0 & \dots & V _ {T} \end{array} \right] ^ {- 1} \left[ \begin{array}{c} v _ {t} \\ v _ {t + 1} \\ \vdots \\ v _ {T} \end{array} \right] \\ = \mu_ {t | t - 1} + \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\mu_ {t}, v _ {j}\right) V _ {j} ^ {- 1} v _ {j}. \tag {11.15} \\ \end{array}
$$

From the definition and independence of {vt $\} , \mathrm { C o v } ( \mu _ { t } , \upsilon _ { j } ) = \mathrm { C o v } ( x _ { t } , \upsilon _ { j } )$ for $j =$ $t , \ldots , T$ , and

$$
\operatorname {C o v} \left(x _ {t}, v _ {t}\right) = E \left[ x _ {t} \left(x _ {t} + e _ {t}\right) \right] = \operatorname {V a r} \left(x _ {t}\right) = \Sigma_ {t | t - 1},
$$

$$
\operatorname {C o v} \left(x _ {t}, v _ {t + 1}\right) = E \left[ x _ {t} \left(x _ {t + 1} + e _ {t + 1}\right) \right] = E \left[ x _ {t} \left(L _ {t} x _ {t} + \eta_ {t} - K _ {t} e _ {t}\right) \right] = \Sigma_ {t | t - 1} L _ {t}.
$$

Similarly, we have

$$
\operatorname {C o v} \left(x _ {t}, v _ {t + 2}\right) = E \left[ x _ {t} \left(x _ {t + 2} + e _ {t + 2}\right) \right] = \dots = \Sigma_ {t | t - 1} L _ {t} L _ {t + 1},
$$

$$
\begin{array}{c} \vdots = \vdots \end{array}
$$

$$
\operatorname {C o v} \left(x _ {t}, v _ {T}\right) = E \left[ x _ {t} \left(x _ {T} + e _ {T}\right) \right] = \dots = \Sigma_ {t | t - 1} \prod_ {j = t} ^ {T - 1} L _ {j}.
$$

Consequently, Eq. (11.15) becomes

$$
\begin{array}{l} \mu_ {t | T} = \mu_ {t | t - 1} + \Sigma_ {t | t - 1} \frac {v _ {t}}{V _ {t}} + \Sigma_ {t | t - 1} L _ {t} \frac {v _ {t + 1}}{V _ {t + 1}} + \Sigma_ {t | t - 1} L _ {t} L _ {t + 1} \frac {v _ {t + 2}}{V _ {t + 2}} + \dots \\ \equiv \mu_ {t | t - 1} + \Sigma_ {t | t - 1} q _ {t - 1}, \\ \end{array}
$$

where

$$
q _ {t - 1} = \frac {v _ {t}}{V _ {t}} + L _ {t} \frac {v _ {t + 1}}{V _ {t + 1}} + L _ {t} L _ {t + 1} \frac {v _ {t + 2}}{V _ {t + 2}} + \dots + \left(\prod_ {j = t} ^ {T - 1} L _ {j}\right) \frac {v _ {T}}{V _ {T}} \tag {11.16}
$$

is a weighted linear combination of the innovations $\{ v _ { t } , \ldots , v _ { T } \}$ . This weighted sum satisfies

$$
\begin{array}{l} q _ {t - 1} = \frac {v _ {t}}{V _ {t}} + L _ {t} \left[ \frac {v _ {t + 1}}{V _ {t + 1}} + L _ {t + 1} \frac {v _ {t + 2}}{V _ {t + 2}} + \dots + \left(\prod_ {j = t + 1} ^ {T - 1} L _ {j}\right) \frac {v _ {T}}{V _ {T}} \right] \\ = \frac {v _ {t}}{V _ {t}} + L _ {t} q _ {t}. \\ \end{array}
$$

Therefore, using the initial value $q _ { T } = 0$ , we have the backward recursion

$$
q _ {t - 1} = \frac {v _ {t}}{V _ {t}} + L _ {t} q _ {t}, \quad t = T, T - 1, \dots , 1. \tag {11.17}
$$

Putting Eqs. (11.15)–(11.17) together, we have a backward recursive algorithm to compute the smoothed state variables:

$$
q _ {t - 1} = V _ {t} ^ {- 1} v _ {t} + L _ {t} q _ {t}, \quad \mu_ {t | T} = \mu_ {t | t - 1} + \Sigma_ {t | t - 1} q _ {t - 1}, \quad t = T, \dots , 1, \tag {11.18}
$$

where $q _ { T } = 0$ , and $\mu _ { t \mid t - 1 }$ , $\Sigma _ { t \left. t - 1 \right. }$ and $L _ { t }$ are available from the Kalman filter in Eq. (11.12).

# Smoothed State Variance

The variance of the smoothed state variable $\mu _ { t | T }$ can be derived in a similar manner via Theorem 11.1(4). Specifically, letting $\pmb { v } _ { t } ^ { T } = ( v _ { t } , \dots , v _ { T } ) ^ { \prime }$ , we have

$$
\begin{array}{l} \Sigma_ {t \mid T} = \operatorname {V a r} \left(\mu_ {t} \mid F _ {T}\right) = \operatorname {V a r} \left(\mu_ {t} \mid F _ {t - 1}, v _ {t}, \dots , v _ {T}\right) \\ = \operatorname {V a r} (\mu_ {t} | F _ {t - 1}) - \operatorname {C o v} [ \mu_ {t}, (\pmb {v} _ {t} ^ {T}) ^ {\prime} ] \operatorname {C o v} [ (\pmb {v} _ {t} ^ {T}) ] ^ {- 1} \operatorname {C o v} [ \mu_ {t}, (\pmb {v} _ {t} ^ {T}) ] \\ = \Sigma_ {t | t - 1} - \sum_ {j = t} ^ {T} \left[ \operatorname {C o v} \left(\mu_ {t}, v _ {j}\right) \right] ^ {2} V _ {j} ^ {- 1}, \tag {11.19} \\ \end{array}
$$

where $\mathrm { C o v } ( \mu _ { t } , v _ { j } ) = \mathrm { C o v } ( x _ { t } , v _ { j } )$ are given earlier after Eq. (11.15). Thus,

$$
\begin{array}{l} \Sigma_ {t | T} = \Sigma_ {t | t - 1} - \Sigma_ {t | t - 1} ^ {2} \frac {1}{V _ {t}} - \Sigma_ {t | t - 1} ^ {2} L _ {t} ^ {2} \frac {1}{V _ {t + 1}} - \dots - \Sigma_ {t | t - 1} ^ {2} \left(\prod_ {j = t} ^ {T - 1} L _ {j} ^ {2}\right) \frac {1}{V _ {T}} \\ \equiv \Sigma_ {t | t - 1} - \Sigma_ {t | t - 1} ^ {2} M _ {t - 1}, \tag {11.20} \\ \end{array}
$$

where

$$
M _ {t - 1} = \frac {1}{V _ {t}} + L _ {t} ^ {2} \frac {1}{V _ {t + 1}} + L _ {t} ^ {2} L _ {t + 1} ^ {2} \frac {1}{V _ {t + 2}} + \dots + \left(\prod_ {j = t} ^ {T - 1} L _ {j} ^ {2}\right) \frac {1}{V _ {T}}
$$

is a weighted linear combination of the inverses of variances of the 1-step ahead forecast errors after time $t - 1$ . Let $M _ { T } = 0$ because no 1-step ahead forecast error

is available after time index $T$ . The statistic $M _ { t - 1 }$ can be written as

$$
\begin{array}{l} M _ {t - 1} = \frac {1}{V _ {t}} + L _ {t} ^ {2} \left[ \frac {1}{V _ {t + 1}} + L _ {t + 1} ^ {2} \frac {1}{V _ {t + 2}} + \dots + \left(\prod_ {j = t + 1} ^ {T - 1} L _ {j} ^ {2}\right) \frac {1}{V _ {T}} \right] \\ = \frac {1}{V _ {t}} + L _ {t} ^ {2} M _ {t}, \quad t = T, T - 1, \dots , 1. \\ \end{array}
$$

Note that from the independence of $\{ v _ { t } \}$ and Eq. (11.16), we have

$$
\operatorname {V a r} \left(q _ {t - 1}\right) = \frac {1}{V _ {t}} + L _ {t} ^ {2} \frac {1}{V _ {t + 1}} + \dots + \left(\prod_ {j = t} ^ {T - 1} L _ {j} ^ {2}\right) \frac {1}{V _ {T}} = M _ {t - 1}.
$$

Combining the results, variances of the smoothed state variables can be computed efficiently via the backward recursion

$$
M _ {t - 1} = V _ {t} ^ {- 1} + L _ {t} ^ {2} M _ {t}, \quad \Sigma_ {t | T} = \Sigma_ {t | t - 1} - \Sigma_ {t | t - 1} ^ {2} M _ {t - 1}, \quad t = T, \dots , 1, \tag {11.21}
$$

where $M _ { T } = 0$

Example 11.1 (Continued). Applying the Kalman filter and state-smoothing algorithms in Eqs. (11.18) and (11.21) to the daily realized volatility of Alcoa stock using the fitted state-space model, we can easily compute the filtered state $\mu _ { t | t }$ and the smoothed state $\mu _ { t | T }$ and their variances. Figure 11.3 shows the filtered state variable and its $9 5 \%$ pointwise confidence interval, whereas Figure 11.4 provides the time plot of smoothed state variable and its $9 5 \%$ pointwise confidence interval. As expected, the smoothed state variables are smoother than the filtered state variables. The confidence intervals for the smoothed state variables are also narrower than those of the filtered state variables. Note that the width of the $9 5 \%$ confidence interval of $\mu _ { 1 | 1 }$ depends on the initial value $\Sigma _ { 1 | 0 }$ .

# 11.1.5 Missing Values

An advantage of thethat the observations $\{ y _ { t } \} _ { t = \ell + 1 } ^ { \ell + \bar { h } }$ ce model is in handare missing, where $h \geq 1$ issin and $1 \leq \ell < T$ uppose. There discuss a method that keeps the original time scale and model form. For $t \in \{ \ell +$ $1 , \ldots , \ell + h \}$ , we can use Eq. (11.2) to express $\mu _ { t }$ as a linear combination of $\mu _ { \ell + 1 }$ and $\{ \eta _ { j } \} _ { j = \ell + 1 } ^ { t - 1 }$ . Specifically,

$$
\mu_ {t} = \mu_ {t - 1} + \eta_ {t - 1} = \dots = \mu_ {\ell + 1} + \sum_ {j = \ell + 1} ^ {t - 1} \eta_ {j},
$$

![](images/ac04544fffb6bd8175c71897b27f34f8319d43167785bd3f484d20fc7359c734.jpg)  
Figure 11.3. Filtered state variable $\mu _ { t \mid t }$ and its $9 5 \%$ pointwise confidence interval for the daily log realized volatility of Alcoa stock returns based on the fitted local trend state-space model.

![](images/73b07999e15397823cea4ec9b85add1469f3e77e673afc10181fa88c007ddd3d.jpg)  
Figure 11.4. Smoothed state variable $\mu _ { t | T }$ and its $9 5 \%$ pointwise confidence interval for the daily log realized volatility of Alcoa stock returns based on the fitted local trend state-space model.

where it is understood that the summation term is zero if its lower limit is greater than its upper limit. Therefore, for $t \in \{ \ell + 1 , \ldots , \ell + h \}$ ,

$$
E \left(\mu_ {t} \mid F _ {t - 1}\right) = E \left(\mu_ {t} \mid F _ {\ell}\right) = \mu_ {\ell + 1 \mid \ell},
$$

$$
\operatorname {V a r} \left(\mu_ {t} \mid F _ {t - 1}\right) = \operatorname {V a r} \left(\mu_ {t} \mid F _ {\ell}\right) = \Sigma_ {\ell + 1 \mid \ell} + (t - \ell - 1) \sigma_ {\eta} ^ {2}.
$$

Consequently, we have

$$
\mu_ {t | t - 1} = \mu_ {t - 1 | t - 2}, \quad \Sigma_ {t | t - 1} = \Sigma_ {t - 1 | t - 2} + \sigma_ {\eta} ^ {2}, \tag {11.22}
$$

for $t = \ell + 2 , \ldots , \ell + h$ . These results show that we can continue to apply the Kalman filter algorithm in Eq. (11.12) by taking $\boldsymbol { v } _ { t } = 0$ and $K _ { t } = 0$ for $t = \ell +$ $1 , \ldots , \ell + h$ . This is rather natural because when $y _ { t }$ is missing, there is no new innovation or new Kalman gain so that $\boldsymbol v _ { t } = 0$ and $K _ { t } = 0$ .

# 11.1.6 Effect of Initialization

In this subsection, we consider the effects of initial condition $\mu _ { 1 } \sim N ( \mu _ { 1 | 0 } , \Sigma _ { 1 | 0 } )$ on the Kalman filter and state smoothing. From the Kalman filter in Eq. (11.12),

$$
v _ {1} = y _ {1} - \mu_ {1 | 0}, \quad V _ {1} = \Sigma_ {1 | 0} + \sigma_ {e} ^ {2},
$$

and, by Eqs. (11.8)–(11.11),

$$
\mu_ {2 | 1} = \mu_ {1 | 0} + \frac {\Sigma_ {1 | 0}}{V _ {1}} v _ {1} = \mu_ {1 | 0} + \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}} (y _ {1} - \mu_ {1 | 0}),
$$

$$
\Sigma_ {2 | 1} = \Sigma_ {1 | 0} \left(1 - \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) + \sigma_ {\eta} ^ {2} = \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}} \sigma_ {e} ^ {2} + \sigma_ {\eta} ^ {2}.
$$

Therefore, letting $\Sigma _ { 1 | 0 }$ increase to infinity, we have $\mu _ { 2 | 1 } = y _ { 1 }$ and $\Sigma _ { 2 | 1 } = \sigma _ { e } ^ { 2 } + \sigma _ { \eta } ^ { 2 }$ This is equivalent to treating $y _ { 1 }$ as fixed and assuming $\mu _ { 1 } \sim N ( y _ { 1 } , \sigma _ { e } ^ { 2 } )$ . In the literature, this approach to initializing the Kalman filter is called diffuse initialization because a very large $\Sigma _ { 1 | 0 }$ means one is uncertain about the initial condition.

Next, turn to the effect of diffuse initialization on state smoothing. It is obvious that based on the results of Kalman filtering, state smoothing is not affected by = Eq. (11.18) and the definition of the diffuse initialization for $t = T , \ldots , 2 .$ $L _ { 1 } = 1 - K _ { 1 } = V _ { 1 } ^ { - 1 } \sigma _ { e } ^ { 2 }$ . Thus, we focus on , $\mu _ { 1 }$ given $F _ { T }$ . From

$$
\begin{array}{l} \mu_ {1 | T} = \mu_ {1 | 0} + \Sigma_ {1 | 0} q _ {0} \\ = \mu_ {1 | 0} + \Sigma_ {1 | 0} \left[ \frac {1}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}} v _ {1} + \left(1 - \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) q _ {1} \right] \\ = \mu_ {1 | 0} + \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}} (v _ {1} + \sigma_ {e} ^ {2} q _ {1}). \\ \end{array}
$$

Letting $\Sigma _ { 1 | 0 }  \infty$ , we have $\mu _ { 1 | T } = \mu _ { 1 | 0 } + v _ { 1 } + \sigma _ { e } ^ { 2 } q _ { 1 } = y _ { 1 } + \sigma _ { e } ^ { 2 } q _ { 1 }$ . Furthermore, from Eq. (11.21) and using $V _ { 1 } = \Sigma _ { 1 | 0 } + \sigma _ { e } ^ { 2 }$ , we have

$$
\begin{array}{l} \Sigma_ {1 | T} = \Sigma_ {1 | 0} - \Sigma_ {1 | 0} ^ {2} \left[ \frac {1}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}} + \left(1 - \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) ^ {2} M _ {1} \right] \\ = \Sigma_ {1 | 0} \left(1 - \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) - \left(1 - \frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) ^ {2} \Sigma_ {1 | 0} ^ {2} M _ {1} \\ = \left(\frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) \sigma_ {e} ^ {2} - \left(\frac {\Sigma_ {1 | 0}}{\Sigma_ {1 | 0} + \sigma_ {e} ^ {2}}\right) ^ {2} \sigma_ {e} ^ {4} M _ {1}. \\ \end{array}
$$

Thus, letting $\Sigma _ { 1 | 0 }  \infty$ , we obtain $\Sigma _ { 1 | T } = \sigma _ { e } ^ { 2 } - \sigma _ { e } ^ { 4 } M _ { 1 }$

Based on the prior discussion, we suggest using diffuse initialization when little is known about the initial value $\mu _ { 1 }$ . However, it might be hard to justify the use of a random variable with infinite variance in real applications. If necessary, one can treat $\mu _ { 1 }$ as an additional parameter of the state-space model and estimate it jointly with other parameters. This latter approach is closely related to the exact maximum likelihood estimation of Chapters 2 and 8.

# 11.1.7 Estimation

In this subsection, we consider the estimation of $\sigma _ { e }$ and $\sigma _ { \eta }$ of the local trend model in Eqs. (11.1) and (11.2). Based on properties of forecast errors discussed in Section 11.1.3, the Kalman filter provides an efficient way to evaluate the likelihood function of the data for estimation. Specifically, the likelihood function under normality is

$$
\begin{array}{l} p \left(y _ {1}, \dots , y _ {T} \mid \sigma_ {e}, \sigma_ {\eta}\right) = p \left(y _ {1} \mid \sigma_ {e}, \sigma_ {\eta}\right) \prod_ {t = 2} ^ {T} \left(y _ {t} \mid F _ {t - 1}, \sigma_ {e}, \sigma_ {\eta}\right) \\ = p (y _ {1} | \sigma_ {e}, \sigma_ {\eta}) \prod_ {t = 2} ^ {T} (v _ {t} | F _ {t - 1}, \sigma_ {e}, \sigma_ {\eta}), \\ \end{array}
$$

where $y _ { 1 } \sim N ( \mu _ { 1 | 0 } , V _ { 1 } )$ and $v _ { t } = ( y _ { t } - \mu _ { t \left| t - 1 \right. } ) \sim N ( 0 , V _ { t } )$ . Consequently, assuming $\mu _ { 1 | 0 }$ and $\Sigma _ { 1 | 0 }$ are known, and taking the logarithms, we have

$$
\ln \left[ L \left(\sigma_ {e}, \sigma_ {\eta}\right) \right] = - \frac {T}{2} \ln (2 \pi) - \frac {1}{2} \sum_ {t = 1} ^ {T} \left(\ln \left(V _ {t}\right) + \frac {v _ {t} ^ {2}}{V _ {t}}\right), \tag {11.23}
$$

which involves $v _ { t }$ and $V _ { t }$ . Therefore, the log likelihood function, including cases with missing values, can be evaluated recursively via the Kalman filter. Many software packages perform state-space model estimation via a Kalman filter algorithm such as Matlab, RATS, and S-Plus. In this chapter, we use the SsfPack program developed by Koopman, Shephard, and Doornik (1999) and available in S-Plus and OX. Both SsfPack and OX are free and can be downloaded from their Web sites.

Table 11.1. State-Space Form and Notation in S-Plus   

<table><tr><td>State-Space Parameter</td><td>S-Plus Name</td></tr><tr><td>δ</td><td>mDelta</td></tr><tr><td>Φ</td><td>mPhi</td></tr><tr><td>Ω</td><td>mOmega</td></tr><tr><td>Σ</td><td>mSigma</td></tr></table>

Table 11.2. Some Commands of SsfPack Package   

<table><tr><td>Command</td><td>Function</td></tr><tr><td>SsfFit</td><td>Maximum likelihood estimation</td></tr><tr><td>CheckSsf</td><td>Create ‘‘Ssf’’ object in S-Plus</td></tr><tr><td>KalmanFil</td><td>Perform Kalman filtering</td></tr><tr><td>KalmanSmo</td><td>Perform state smoothing</td></tr><tr><td>SsfMomentEst with task ‘‘STFIL’’</td><td>Compute filtered state and variance</td></tr><tr><td>SsfMomentEst with task ‘‘STSMO’’</td><td>Compute smoothed state and variance</td></tr><tr><td>SsfCondDens with task ‘‘STSMO’’</td><td>Compute smoothed state without variance</td></tr></table>

# 11.1.8 S-Plus Commands Used

We provide here the SsfPack commands used to perform analysis of the daily realized volatility of Alcoa stock returns. Only brief explanations are given. For further details of the commands used, see Durbin and Koopman (2001, Section 6.6). S-Plus uses specific notation to specify a state-space model; see Table 11.1. The notation must be followed closely. In Table 11.2, we give some commands and their functions.

In our analysis, we first perform maximum likelihood estimation of the statespace model in Eqs. (11.1) and (11.2) to obtain estimates of $\sigma _ { e }$ and $\sigma _ { \eta }$ . The initial values used are $\Sigma _ { 1 | 0 } = - 1$ and $\mu _ { 1 | 0 } = 0$ , where “−1” signifies diffuse initialization, that is, $\Sigma _ { 1 | 0 }$ is very large. We then treat the fitted model as given to perform Kalman filtering and state smoothing.

# SsfPack and S-Plus Commands for State-Space Model

>da $=$ matrix.scan(file $\coloneqq$ 'aa-rv-0304.txt'),2）%loaddata >y $=$ log(da[1,]) %log(RV)

```matlab
> ltm.start=c(3,1) % Initial parameter values
> P1 = -1 % Initialization of Kalman filter
> a1 = 0 
```

```javascript
> ltm.m=function(param){ % Specify a function for the + sigmaEta=param[1] % local trend model. + sigma.e=param[2] 
```

```txt
+ssf.m=list(mPhi=as.matrix(c(1,1)),  
+ mOmega=diag(c(sigmaEta^2,sigma.e^2)),  
+ mSigma=as.matrix(c(P1,a1)))  
+ CheckSsf(ssf.m)  
+ }  
% perform estimation  
> ltm.mle=SssfFit(ltm.start,y,"ltm.m",lower=c(0,0),  
+ upper=c(100,100))  
> ltm.mle$parameters  
[1] 0.07350827 0.48026284  
> sigma eta=ltm.mle$parameter[1]  
> sigma eta  
[1] 0.07350827  
> sigma.e=ltm.mle$parameters[2]  
> sigma.e  
[1] 0.4802628  
% Specify a state-space model in S-Plus.  
>ssf.ltm.list=list(mPhi=as.matrix(c(1,1)),  
+ mOmega=diag(c(sigma eta^2,sigma.e^2)),  
+ mSigma=as.matrix(c(P1,a1)))  
% check validity of the specified model.  
>ssf.ltm=CheckSsf(ssf.ltm.list)  
>ssf.ltm  
$mPhi:  
[.,1]  
[1,] 1  
[2,] 1  
$mOmega:  
[.,1] [.,2]  
[1,] 0.0054035 0.0000000  
[2,] 0.0000000 0.2306524  
$mSigma:  
[.,1]  
[1,] -1  
[2,] 0  
$mDelta:  
[.,1]  
[1,] 0  
[2,] 0  
$mJPhi:  
[1] 0  
$mJOmega:  
[1] 0  
$mJDelta:  
[1] 0  
$mX:  
[1] 0  
$cT:  
[1] 0 
```

```txt
$C:  
[1] 0  
$cY:  
[1] 1  
$cSt:  
[1] 1  
attr(, "class"):  
[1] "ssf"  
% Apply Kalman filter  
> KalmanFil.ltm=KalmanFil(y,ssf.ltm, task="STFIL")  
> names (KalmanFil.ltm)  
[1] "mOut" "innov" "std.innov" "mGain" "loglike"  
[6] "loglikeconc" "dVar" "mEst" "mOffP" "task"  
[11] "err" "call"  
> par(mfcol=c(2,1)) % Obtain plot  
> plot(1:340, KalmanFil.ltm$mEst[,1], xlab='day', + ylab='filtered state', type='l')  
> title(main=' (a) Filtered state variable')  
> plot(1:340, KalmanFil.ltm$mOut[,1], xlab='day', + ylab='v(t)', type='l')  
> title(main=' (b) Prediction error')  
% Obtain residuals and their variances  
> KalmanSmo.ltm=KalmanSmo(KalmanFil.ltm,ssf.ltm)  
> names (KalmanSmo.ltm)  
[1] "state.residuals" "response.residuals" "state.variance"  
[4] "response.variance" "aux.residuals" "scores"  
[7] "call"  
% Next, filtered states  
> FiledEst.ltm=SsfMomentEst(y,ssf.ltm, task="STFIL")  
> names (FiledEst.ltm)  
[1] "state.moment" "state.variance" "responsemoment"  
[4] "response.variance" "task"  
% Smoothen states  
> SmoedEst.ltm=SsfMomentEst(y,ssf.ltm, task="STSMO")  
> names (SmoedEst.ltm)  
[1] "state.moment" "state.variance" "responsemoment"  
[4] "response.variance" "task"  
% Obtain plots of filtered and smoothed states with 95% C.I.  
> up=FiledEst.ltm$state.moment + 2*sqrt(FiledEst.ltm$state.variance)  
> lw=FiledEst.ltm$state.moment - 2*sqrt(FiledEst.ltm$state.variance)  
> par(mfcol=c(1,1))  
> plot(1:340, FiledEst.ltm$state.moment, type='l', xlab='day', + ylab='value', ylim=c(-0.1,2.5))  
> lines(1:340, up, lty=2)  
> lines(1:340, lw, lty=2)  
> title(main='Filed state variable')  
> up=SmoedEst.ltm$state.moment + 
```

```matlab
+ 2*sqrt(SmoedEst.ltm$state.variance)
> lw=SmoedEst.ltm$state.moment -
+ 2*sqrt(SmoedEst.ltm$state.variance)
> plot(1:340,SmoedEst.ltm$state.moment,type='l',xlab='day',
+ ylab='value',ylim=c(-0.1,2.5))
> lines(1:340,up,lty=2)
> lines(1:340,lw,lty=2)
> title(main='Smoothed state variable')
% Model checking
> resi=KalmanFil.ltm$mOut[,1]*sqrt(KalmanFil.ltm$mOut[,3])
> archTest(resi)
> autocorTest(resi) 
```

For the daily realized volatility of Alcoa stock returns, the fitted local trend model is adequate based on residual analysis. Specifically, given the parameter estimates, we use the Kalman filter to obtain the 1-step ahead forecast error $v _ { t }$ and its variance $V _ { t }$ . We then compute the standardized forecast error $\tilde { v } _ { t } =$ $v _ { t } / \sqrt { V _ { t } }$ and check the serial correlations and ARCH effects of $\{ \tilde { v } _ { t } \}$ . We found that $Q ( 2 5 ) = 2 3 . 3 7 ( 0 . 5 6 )$ for the standardized forecast errors and the LM test statistic for ARCH effect is 18.48(0.82) for 25 lags, where the number in parentheses denotes $p$ -value.

# 11.2 LINEAR STATE-SPACE MODELS

We now consider the general state-space model. Many dynamic time series models in economics and finance can be represented in state-space form. Examples include the ARIMA models, dynamic linear models with unobserved components, timevarying regression models, and stochastic volatility models. A general Gaussian linear state-space model assumes the form

$$
\boldsymbol {s} _ {t + 1} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t} + \boldsymbol {R} _ {t} \eta_ {t}, \tag {11.24}
$$

$$
\mathbf {y} _ {t} = \mathbf {c} _ {t} + \mathbf {Z} _ {t} \mathbf {s} _ {t} + \mathbf {e} _ {t}, \tag {11.25}
$$

where $\pmb { s } _ { t } = ( s _ { 1 t } , \ldots , s _ { m t } ) ^ { \prime }$ is an $m$ -dimensional state vector, $\pmb { y } _ { t } = ( y _ { 1 t } , \ldots , y _ { k t } ) ^ { \prime }$ is a $k$ -dimensional observation vector, $\mathbf { \delta } \mathbf { d } _ { t }$ and $c _ { t }$ are $m$ - and $k$ -dimensional deterministic vectors, $\boldsymbol { T } _ { t }$ and $\mathbf { } Z _ { t }$ are $m \times m$ and $k \times m$ coefficient matrices, $\pmb { R } _ { t }$ is an $m \times n$ matrix often consisting of a subset of columns of the $m \times m$ identity matrix, and $\{ \eta _ { t } \}$ and $\{ e _ { t } \}$ are $n$ - and $k$ -dimensional Gaussian white noise series such that

$$
\boldsymbol {\eta} _ {t} \sim N (\mathbf {0}, \boldsymbol {Q} _ {t}), \quad \boldsymbol {e} _ {t} \sim N (\mathbf {0}, \boldsymbol {H} _ {t}),
$$

where $\boldsymbol { Q } _ { t }$ and $\pmb { H } _ { t }$ are positive-definite matrices. We assume that $\{ e _ { t } \}$ and $\{ \eta _ { t } \}$ are independent, but this condition can be relaxed if necessary. The initial state $\mathbf { s } _ { 1 }$ is

$N ( { \pmb \mu } _ { 1 | 0 } , { \pmb \Sigma } _ { 1 | 0 } )$ , where ${ \pmb { \mu } } _ { 1 | 0 }$ and $\pmb { \Sigma } _ { 1 | 0 }$ are given, and is independent of $e _ { t }$ and $\pmb { \eta } _ { t }$ for $t > 0$ .

Equation (11.25) is the measurement or observation equation that relates the vector of observations $\mathbf { } y _ { t }$ to the state vector $\mathbf { } _ { \pmb { S } _ { t } }$ , the explanatory variable $c _ { t }$ , and the measurement error $e _ { t }$ . Equation (11.24) is the state or transition equation that describes a first-order Markov chain to govern the state transition with innovation $\pmb { \eta } _ { t }$ . The matrices $\boldsymbol { T } _ { t }$ , $\pmb { R } _ { t }$ , $\boldsymbol { Q } _ { t }$ , $\mathbf { } Z _ { t }$ , and $\pmb { H } _ { t }$ are known and referred to as system matrices. These matrices are often sparse, and they can be functions of some parameters $\pmb \theta$ , which can be estimated by the maximum likelihood method.

The state-space model in Eqs. (11.24) and (11.25) can be rewritten in a compact form as

$$
\left[ \begin{array}{c} s _ {t + 1} \\ y _ {t} \end{array} \right] = \delta_ {t} + \Phi_ {t} s _ {t} + u _ {t}, \tag {11.26}
$$

where

$$
\boldsymbol {\delta} _ {t} = \left[ \begin{array}{c} \boldsymbol {d} _ {t} \\ \boldsymbol {c} _ {t} \end{array} \right], \quad \boldsymbol {\Phi} _ {t} = \left[ \begin{array}{c} \boldsymbol {T} _ {t} \\ \boldsymbol {Z} _ {t} \end{array} \right], \quad \boldsymbol {u} _ {t} = \left[ \begin{array}{c} \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} \\ \boldsymbol {e} _ {t} \end{array} \right],
$$

and $\left\{ { \pmb u } _ { t } \right\}$ is a sequence of Gaussian white noises with mean zero and covariance matrix

$$
\boldsymbol {\Omega} _ {t} = \operatorname {C o v} (\boldsymbol {u} _ {t}) = \left[ \begin{array}{c c} \boldsymbol {R} _ {t}   \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime} & \boldsymbol {0} \\ \boldsymbol {0} & \boldsymbol {H} _ {t} \end{array} \right].
$$

The case of diffuse initialization is achieved by using

$$
\boldsymbol {\Sigma} _ {1 | 0} = \boldsymbol {\Sigma} _ {*} + \lambda \boldsymbol {\Sigma} _ {\infty},
$$

where $\pmb { \Sigma } _ { * }$ and $\pmb { \Sigma } _ { \infty }$ are $m \times m$ symmetric positive-definite matrices and λ is a large real number, which can approach infinity. In S-Plus and SsfPack, the notation

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c} \boldsymbol {\Sigma} _ {1 | 0} \\ \boldsymbol {\mu} _ {1 | 0} ^ {\prime} \end{array} \right] _ {(m + 1) \times m}
$$

is used; see the notation in Table 11.1.

In many applications, the system matrices are time-invariant. However, these matrices can be time-varying, making the state-space model flexible.

# 11.3 MODEL TRANSFORMATION

To appreciate the flexibility of the state-space model, we rewrite some well-known econometric and financial models in state-space form.

# 11.3.1 CAPM with Time-Varying Coefficients

First, consider the capital asset pricing model (CAPM) with time-varying intercept and slope. The model is

$$
r _ {t} = \alpha_ {t} + \beta_ {t} r _ {M, t} + e _ {t}, \quad e _ {t} \sim N (0, \sigma_ {e} ^ {2}),
$$

$$
\alpha_ {t + 1} = \alpha_ {t} + \eta_ {t}, \quad \eta_ {t} \sim N \left(0, \sigma_ {\eta} ^ {2}\right), \tag {11.27}
$$

$$
\beta_ {t + 1} = \beta_ {t} + \epsilon_ {t}, \quad \epsilon_ {t} \sim N (0, \sigma_ {\epsilon} ^ {2}),
$$

where $r _ { t }$ is the excess return of an asset, $r _ { M , t }$ is the excess return of the market, and the innovations $\{ e _ { t } , \eta _ { t } , \epsilon _ { t } \}$ are mutually independent. This CAPM allows for time-varying $\alpha$ and $\beta$ that evolve as a random walk over time. We can easily rewrite the model as

$$
\left[ \begin{array}{c} \alpha_ {t + 1} \\ \beta_ {t + 1} \end{array} \right] = \left[ \begin{array}{c c} 1 & 0 \\ 0 & 1 \end{array} \right] \left[ \begin{array}{c} \alpha_ {t} \\ \beta_ {t} \end{array} \right] + \left[ \begin{array}{c} \eta_ {t} \\ \epsilon_ {t} \end{array} \right],
$$

$$
r _ {t} = [ 1, r _ {M, t} ] \left[ \begin{array}{c} \alpha_ {t} \\ \beta_ {t} \end{array} \right] + e _ {t}.
$$

Thus, the time-varying CAPM is a special case of the state-space model with $s _ { t } =$ $( \alpha _ { t } , \beta _ { t } ) ^ { \prime }$ , $\pmb { T } _ { t } = \pmb { R } _ { t } = \pmb { I } _ { 2 }$ , the $2 \times 2$ identity matrix, $\mathbf { \nabla } \mathbf { d } _ { t } = \mathbf { 0 }$ , $c _ { t } = 0$ , $\mathbf { Z } _ { t } = ( 1 , r _ { M , t } )$ , $\pmb { H } _ { t } = \sigma _ { e } ^ { 2 }$ , and $\pmb { \mathcal { Q } } _ { t } = \mathrm { d i a g } \{ \sigma _ { \eta } ^ { 2 } , \sigma _ { \epsilon } ^ { 2 } \}$ . Furthermore, in the form of Eq. (11.26), we have $\delta _ { t } = \mathbf { 0 }$ , $\pmb { u } _ { t } = ( \eta _ { t } , \epsilon _ { t } , e _ { t } ) ^ { \prime }$ ,

$$
\boldsymbol {\Phi} _ {t} = \left[ \begin{array}{c c} 1 & 0 \\ 0 & 1 \\ 1 & r _ {M, t} \end{array} \right], \quad \boldsymbol {\Omega} _ {t} = \left[ \begin{array}{c c c} \sigma_ {\eta} ^ {2} & 0 & 0 \\ 0 & \sigma_ {\epsilon} ^ {2} & 0 \\ 0 & 0 & \sigma_ {e} ^ {2} \end{array} \right].
$$

If diffuse initialization is used, then

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c c} - 1 & 0 \\ 0 & - 1 \\ 0 & 0 \end{array} \right].
$$

# SsfPack/S-Plus Specification of Time-Varying Models

For the CAPM in Eq. (11.27), $\Phi _ { t }$ contains $r _ { M , t }$ , which is time-varying. Some special input is required to specify such a model in SsfPack. Basically, it requires two additional variables: (a) a data matrix $X$ that stores $\mathbf { } Z _ { t }$ and (b) an index matrix for $\Phi _ { t }$ that identifies $\mathbf { } Z _ { t }$ from the data matrix. The notation for index matrices of the state-space model in Eq. (11.26) is given in Table 11.3. Note that the matrix $J _ { \Phi }$ must have the same dimension as $\Phi _ { t }$ . The elements of $J _ { \Phi }$ are all set to “ 1” except the elements for which the corresponding elements of $\Phi _ { t }$ are time-varying. The non-negative index value of $J _ { \Phi }$ indicates the column of the data matrix $X$ , which contains the time-varying values.

Table 11.3. Notation and Name Used in SsfPack/S-Plus for Time-Varying State-Space Model   

<table><tr><td>Index Matrix</td><td>Name Used in SsfPack/S-Plus</td></tr><tr><td>Jδ</td><td>mJDelta</td></tr><tr><td>JΦ</td><td>mJPhi</td></tr><tr><td>JΩ</td><td>mJOmega</td></tr><tr><td>Time-Varying Data Matrix</td><td>Name Used in SsfPack/S-Plus</td></tr><tr><td>X</td><td>mX</td></tr></table>

To illustrate, consider the monthly simple excess returns of General Motors stock from January 1990 to December 2003 used in Chapter 9. The monthly simple excess return of the S&P 500 composite index is used as the market return. The specification of a time-varying CAPM requires values of the variances $\sigma _ { \eta } ^ { 2 }$ , $\sigma _ { \epsilon } ^ { 2 }$ , and $\sigma _ { e } ^ { 2 }$ . Suppose that $( \sigma _ { \eta } , \sigma _ { \epsilon } , \sigma _ { e } ) = ( 0 . 0 2 , 0 . 0 4 , 0 . 1 )$ . The state-space specification for the CAPM under SsfPack/S-Plus is given below:

```txt
> X.mtx=cbind(1,sp) % Here 'sp' is the market excess returns.
> Phi.t = rbind(diag(2),rep(0,2))
> Sigma=-Phi.t
> sigma eta=.02
> sigma.ep=.04
> sigma.e=.1
> Omega=diag(c(sigma.eta^2,sigma.ep^2,sigma.e^2))
> JPhi = matrix(-1,3,2) % Create a 3-by-2 matrix of -1.
> JPhi[3,1]=1
> JPhi[3,2]=2
>ssf.tv.capm=list(mPhi=Phi.t,
+ mOmega=Omega,
+ mJPhi=JPhi,
+ mSigma=Sigma,
+ mX=X.mtx)
>ssf.tv.capm
$mPhi:
[.,1] [,2]
[1,] 1 0
[2,] 0 1
[3,] 0 0
$mOmega:
[.,1] [,2] [,3]
[1,] 4e-04 0.0000 0.00
[2,] 0e+00 0.0016 0.00
[3,] 0e+00 0.0000 0.01
$mJPhi:
[.,1] [,2] 
```

[1,] -1 -1  
[2,] -1 -1  
[3,] 1 2  
\(mSigma:  
\begin{bmatrix} ,1 \end{bmatrix} [,2]  
[1,] -1 0  
[2,] 0 -1  
[3,] 0 0  
\)mX:  
numeric matrix: 168 rows, 2 columns.  
sp  
[1,] 1 -0.075187  
...  
[168,] 1 0.05002

# 11.3.2 ARMA Models

Consider a zero-mean ARMA $( p , q )$ process $y _ { t }$ of Chapter 2,

$$
\phi (B) y _ {t} = \theta (B) a _ {t}, \quad a _ {t} \sim N \left(0, \sigma_ {a} ^ {2}\right), \tag {11.28}
$$

where $\begin{array} { r } { \phi ( B ) = 1 - \sum _ { i = 1 } ^ { p } \phi _ { i } B ^ { i } } \end{array}$ and $\begin{array} { r } { \theta ( B ) = 1 - \sum _ { j = 1 } ^ { q } \theta _ { j } B ^ { j } } \end{array}$ , and $p$ and $q$ are nonnegative integers. There are many ways to transform such an ARMA model into a state-space form. We discuss three methods available in the literature. Let $m =$ $\operatorname* { m a x } ( p , q + 1 )$ and rewrite the ARMA model in Eq. (11.28) as

$$
y _ {t} = \sum_ {i = 1} ^ {m} \phi_ {i} y _ {t - i} + a _ {t} - \sum_ {j = 1} ^ {m - 1} \theta_ {j} a _ {t - j}, \tag {11.29}
$$

where $\phi _ { i } = 0$ for $i > p$ and $\theta _ { j } = 0$ for $j > q .$ In particular, $\theta _ { m } = 0$ because $m > q$ .

# Akaike’s Approach

Akaike (1975) defines the state vector $\mathbf { } _ { \pmb { S } _ { t } }$ as the minimum collection of variables that contains all the information needed to produce forecasts at the forecast origin t . It turns out that, for the ARMA process in Eq. (11.28) with $m = \operatorname* { m a x } ( p , q + 1 )$ , $\pmb { s } _ { t } = ( y _ { t | t } , y _ { t + 1 | t } , \dots , y _ { t + m - 1 | t } ) ^ { \prime }$ , where $y _ { t + j | t } = E ( y _ { t + j } | F _ { t } )$ is the conditional expectation of $y _ { t + j }$ given $F _ { t } = \{ y _ { 1 } , . . . , y _ { t } \}$ . Since $y _ { t \mid t } = y _ { t }$ , the first element of $\mathbf { } _ { \pmb { S } _ { t } }$ is $y _ { t }$ . Thus, the observation equation is

$$
y _ {t} = \mathbf {Z} s _ {t}, \tag {11.30}
$$

where $\pmb { Z } = ( 1 , 0 , \dots , 0 ) _ { 1 \times m }$ . We derive the transition equation in several steps. First, from the definition,

$$
s _ {1, t + 1} = y _ {t + 1} = y _ {t + 1 | t} + \left(y _ {t + 1} - y _ {t + 1 | t}\right) = s _ {2 t} + a _ {t + 1}, \tag {11.31}
$$

where $s _ { i t }$ is the ith element of $\mathbf { } _ { \pmb { S } _ { t } }$ . Next, consider the MA representation of ARMA models given in Chapter 2. That is,

$$
y _ {t} = a _ {t} + \psi_ {1} a _ {t - 1} + \psi_ {2} a _ {t - 2} + \dots = \sum_ {i = 0} ^ {\infty} \psi_ {i} a _ {t - i},
$$

where $\psi _ { 0 } = 1$ and other $\psi$ -weights can be obtained by equating coefficients of $B ^ { i }$ in $\begin{array} { r } { 1 + \sum _ { i = 1 } ^ { \infty } \psi _ { i } B ^ { i } = \theta ( B ) / \phi ( B ) } \end{array}$ . In particular, we have

$$
\psi_ {1} = \phi_ {1} - \theta_ {1},
$$

$$
\psi_ {2} = \phi_ {1} \psi_ {1} + \phi_ {2} - \theta_ {2},
$$

$$
\begin{array}{c} \vdots = \vdots \\ \hline \end{array}
$$

$$
\begin{array}{l} \psi_ {m - 1} = \phi_ {1} \psi_ {m - 2} + \phi_ {2} \psi_ {m - 3} + \dots + \phi_ {m - 2} \psi_ {1} + \phi_ {m - 1} - \theta_ {m - 1} \\ = \sum_ {i = 1} ^ {m - 1} \phi_ {i} \psi_ {m - 1 - i} - \theta_ {m - 1}. \tag {11.32} \\ \end{array}
$$

Using the MA representation, we have, for $j > 0$ ,

$$
\begin{array}{l} y _ {t + j \mid t} = E \left(y _ {t + j} \mid F _ {t}\right) = E \left(\sum_ {i = 0} ^ {\infty} \psi_ {i} a _ {t + j - i} \mid F _ {t}\right) \\ = \psi_ {j} a _ {t} + \psi_ {j + 1} a _ {t - 1} + \psi_ {j + 2} a _ {t - 2} + \dots \\ \end{array}
$$

and

$$
\begin{array}{l} y _ {t + j \mid t + 1} = E \left(y _ {t + j} \mid F _ {t + 1}\right) = \psi_ {j - 1} a _ {t + 1} + \psi_ {j} a _ {t} + \psi_ {j + 1} a _ {t - 1} + \dots \\ = \psi_ {j - 1} a _ {t + 1} + y _ {t + j | t}. \\ \end{array}
$$

Thus, for $j > 0$ , we have

$$
y _ {t + j \mid t + 1} = y _ {t + j \mid t} + \psi_ {j - 1} a _ {t + 1}. \tag {11.33}
$$

This result is referred to as the forecast updating formula of ARMA models. It provides a simple way to update the forecast from origin $t$ to origin $t + 1$ when $y _ { t + 1 }$ becomes available. The new information of $y _ { t + 1 }$ is contained in the innovation $a _ { t + 1 }$ , and the time-t forecast is revised based on this new information with weight $\psi _ { j - 1 }$ to compute the time- $( t + 1 )$ forecast.

Finally, from Eq. (11.29) and using $E ( a _ { t + j } | F _ { t + 1 } ) = 0$ for $j > 1$ , we have

$$
y _ {t + m \mid t + 1} = \sum_ {i = 1} ^ {m} \phi_ {i} y _ {t + m - i \mid t + 1} - \theta_ {m - 1} a _ {t + 1}.
$$

Taking Eq. (11.33), the prior equation becomes

$$
\begin{array}{l} y _ {t + m | t + 1} = \sum_ {i = 1} ^ {m - 1} \phi_ {i} \left(y _ {t + m - i | t} + \psi_ {m - i - 1} a _ {t + 1}\right) + \psi_ {m} y _ {t | t} - \theta_ {m - 1} a _ {t + 1} \\ = \sum_ {i = 1} ^ {m} \phi_ {i} y _ {t + m - i | t} + \left(\sum_ {i = 1} ^ {m - 1} \phi_ {i} \psi_ {m - 1 - i} - \theta_ {m - 1}\right) a _ {t + 1} \\ = \sum_ {i = 1} ^ {m} \phi_ {i} y _ {t + m - i | t} + \psi_ {m - 1} a _ {t + 1}, \tag {11.34} \\ \end{array}
$$

where the last equality uses Eq. (11.32). Combining Eqs. (11.31), (11.33) for $j =$ $2 , \ldots , m - 1$ , and (11.34) together, we have

$$
\left[ \begin{array}{c} y _ {t + 1} \\ y _ {t + 2 | t + 1} \\ \vdots \\ y _ {t + m - 1 | t + 1} \\ y _ {t + m | t + 1} \end{array} \right] = \left[ \begin{array}{c c c c c} 0 & 1 & 0 & \cdot & 0 \\ 0 & 0 & 1 & & 0 \\ \vdots & & & & \vdots \\ 0 & 0 & 0 & \cdot & 1 \\ \phi_ {m} & \phi_ {m - 1} & \phi_ {m - 2} & \cdot & \phi_ {1} \end{array} \right] \left[ \begin{array}{c} y _ {t} \\ y _ {t + 1 | t} \\ \vdots \\ y _ {t + m - 2 | t} \\ y _ {t + m - 1 | t} \end{array} \right] + \left[ \begin{array}{c} 1 \\ \psi_ {1} \\ \vdots \\ \psi_ {m - 2} \\ \psi_ {m - 1} \end{array} \right] a _ {t + 1}. \tag {11.35}
$$

Thus, the transition equation of Akaike’s approach is

$$
\boldsymbol {s} _ {t + 1} = \boldsymbol {T} \boldsymbol {s} _ {t} + \boldsymbol {R} \eta_ {t}, \quad \eta_ {t} \sim N \left(0, \sigma_ {a} ^ {2}\right), \tag {11.36}
$$

where $\eta _ { t } = a _ { t + 1 }$ , and $T$ and $\pmb { R }$ are the coefficient matrices in Eq. (11.35).

# Harvey’s Approach

Harvey (1993, Section 4.4) provides a state-space form with an $m$ -dimensional state vector $\mathbf { } _ { \pmb { S } _ { t } }$ , the first element of which is $y _ { t }$ , that is, $s _ { 1 t } = y _ { t }$ . The other elements of $\mathbf { } _ { \pmb { S } _ { t } }$ are obtained recursively. From the $\mathrm { A R M A } ( m , m - 1 )$ model, we have

$$
\begin{array}{l} y _ {t + 1} = \phi_ {1} y _ {t} + \sum_ {i = 2} ^ {m} \phi_ {i} y _ {t + 1 - i} - \sum_ {j = 1} ^ {m - 1} \theta_ {j} a _ {t + 1 - j} + a _ {t + 1} \\ \equiv \phi_ {1} s _ {1 t} + s _ {2 t} + \eta_ {t}, \\ \end{array}
$$

where $\begin{array} { r } { s _ { 2 t } = \sum _ { i = 2 } ^ { m } \phi _ { i } y _ { t + 1 - i } - \sum _ { j = 1 } ^ { m - 1 } \theta _ { j } a _ { t + 1 - j } } \end{array}$ , $\eta _ { t } = a _ { t + 1 }$ , and as defined earlier $s _ { 1 t } = y _ { t }$ . Focusing on $s _ { 2 , t + 1 }$ , we have

$$
\begin{array}{l} s _ {2, t + 1} = \sum_ {i = 2} ^ {m} \phi_ {i} y _ {t + 2 - i} - \sum_ {j = 1} ^ {m - 1} \theta_ {j} a _ {t + 2 - j} \\ = \phi_ {2} y _ {t} + \sum_ {i = 3} ^ {m} \phi_ {i} y _ {t + 2 - i} - \sum_ {j = 2} ^ {m - 1} \theta_ {j} a _ {t + 2 - j} - \theta_ {1} a _ {t + 1} \\ \equiv \phi_ {2} s _ {1 t} + s _ {3 t} + (- \theta_ {1}) \eta_ {t}, \\ \end{array}
$$

where $\begin{array} { r } { s _ { 3 t } = \sum _ { i = 3 } ^ { m } \phi _ { i } y _ { t + 2 - i } - \sum _ { j = 2 } ^ { m - 1 } \theta _ { j } a _ { t + 2 - j } . } \end{array}$ . Next, considering $s _ { 3 , t + 1 }$ , we have

$$
\begin{array}{l} s _ {3, t + 1} = \sum_ {i = 3} ^ {m} \phi_ {i} y _ {t + 3 - i} - \sum_ {j = 2} ^ {m - 1} \theta_ {j} a _ {t + 3 - j} \\ = \phi_ {3} y _ {t} + \sum_ {i = 4} ^ {m} \phi_ {i} y _ {t + 3 - i} - \sum_ {j = 3} ^ {m - 1} \theta_ {j} a _ {t + 3 - j} + (- \theta_ {2}) a _ {t + 1} \\ \equiv \phi_ {3} s _ {1 t} + s _ {4 t} + (- \theta_ {2}) \eta_ {t}, \\ \end{array}
$$

$\begin{array} { r } { s _ { 4 t } = \sum _ { i = 4 } ^ { m } \phi _ { i } y _ { t + 3 - i } - \sum _ { j = 3 } ^ { m - 1 } \theta _ { j } a _ { t + 3 - j } } \end{array}$ m−1 dure, we have. Finally, $\begin{array} { r } { s _ { m t } = \sum _ { i = m } ^ { m } \phi _ { i } y _ { t + m - 1 - i } - \sum _ { j = m - 1 } ^ { m - 1 } \theta _ { j } a _ { t + m - 1 - j } = \phi _ { m } y _ { t - 1 } - \theta _ { m - 1 } a _ { t } } \end{array}$

$$
\begin{array}{l} s _ {m, t + 1} = \phi_ {m} y _ {t} - \theta_ {m - 1} a _ {t + 1} \\ = \phi_ {m} s _ {1 t} + (- \theta_ {m - 1}) \eta_ {t}. \\ \end{array}
$$

Putting the prior equations together, we have a state-space form

$$
\boldsymbol {s} _ {t + 1} = \boldsymbol {T} \boldsymbol {s} _ {t} + \boldsymbol {R} \eta_ {t}, \quad \eta_ {t} \sim N \left(0, \sigma_ {a} ^ {2}\right), \tag {11.37}
$$

$$
y _ {t} = \mathbf {Z} s _ {t}, \tag {11.38}
$$

where the system matrices are time-invariant defined as $\mathbf { Z } = ( 1 , 0 , \ldots , 0 ) _ { 1 \times m }$ ,

$$
\boldsymbol {T} = \left[ \begin{array}{c c c c c} \phi_ {1} & 1 & 0 & \dots & 0 \\ \phi_ {2} & 0 & 1 & & 0 \\ \vdots & & & & \vdots \\ \phi_ {m - 1} & 0 & 0 & \dots & 1 \\ \phi_ {m} & 0 & 0 & \dots & 0 \end{array} \right], \quad \boldsymbol {R} = \left[ \begin{array}{c} 1 \\ - \theta_ {1} \\ \vdots \\ - \theta_ {m - 1} \end{array} \right],
$$

and $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Xi \mathbf { } \mathbf { } \mathbf \Lambda \Lambda \mathbf { } \mathbf { } \Lambda \mathbf \Lambda \Lambda \mathbf { } \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf { } \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf { } \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \mathbf \Lambda \Lambda \mathbf $ , $c _ { t }$ , and $\pmb { H } _ { t }$ are all zero. The model in Eqs. (11.37) and (11.38) has no measurement errors. It has an advantage that the AR and MA coefficients are directly used in the system matrices.

# Aoki’s Approach

Aoki (1987, Chapter 4) discusses several ways to convert an ARMA model into a state-space form. First, consider the MA model, that is, $y _ { t } = \theta ( B ) a _ { t }$ . In this case, we can simply define $\pmb { s } _ { t } = ( a _ { t - q } , a _ { t - q + 2 } , \ldots , a _ { t - 1 } ) ^ { \prime }$ and obtain the state-space form

$$
\left[ \begin{array}{c} a _ {t - q + 1} \\ a _ {t - q + 2} \\ \vdots \\ a _ {t - 1} \\ a _ {t} \end{array} \right] = \left[ \begin{array}{c c c c c} 0 & 1 & 0 & \dots & 0 \\ 0 & 0 & 1 & & 0 \\ \vdots & & & & \vdots \\ 0 & 0 & 0 & & 1 \\ 0 & 0 & 0 & \dots & 0 \end{array} \right] \left[ \begin{array}{c} a _ {t - q} \\ a _ {t - q + 1} \\ \vdots \\ a _ {t - 2} \\ a _ {t - 1} \end{array} \right] + \left[ \begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array} \right] a _ {t},
$$

$$
y _ {t} = \left(- \theta_ {q}, - \theta_ {q - 1}, \dots , - \theta_ {1}\right) s _ {t} + a _ {t}, \tag {11.39}
$$

Note that, in this particular case, $a _ { t }$ appears in both state and measurement equations.

Next, consider the AR model, that is, $\phi ( B ) z _ { t } = a _ { t }$ . Aoki (1987) introduces two methods. The first method is a straightforward one by defining $\boldsymbol { s } _ { t } = ( z _ { t - p + 1 } , \ldots , z _ { t } ) ^ { \prime }$ to obtain

$$
\begin{array}{l} \left[ \begin{array}{c} z _ {t - p + 2} \\ z _ {t - p + 3} \\ \vdots \\ z _ {t + 2} \\ z _ {t + 1} \end{array} \right] = \left[ \begin{array}{c c c c c} 0 & 1 & 0 & \dots & 0 \\ 0 & 0 & 1 & & 0 \\ \vdots & & & & \vdots \\ 0 & 0 & 0 & & 1 \\ \phi_ {p} & \phi_ {p - 1} & \phi_ {p - 2} & \dots & \phi_ {1} \end{array} \right] \left[ \begin{array}{c} z _ {t - p + 1} \\ z _ {t - p + 2} \\ \vdots \\ z _ {t + 1} \\ z _ {t} \end{array} \right] + \left[ \begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{array} \right] a _ {t + 1}, \\ z _ {t} = (0, 0, \dots , 0, 1) s _ {t}. \tag {11.40} \\ \end{array}
$$

The second method defines the state vector in the same way as the first method except that $a _ { t }$ is removed from the last element; that is, $s _ { t } = z _ { t } - a _ { t }$ if $p = 1$ and $\pmb { s } _ { t } = ( z _ { t - p + 1 } , \dots , z _ { t - 1 } , z _ { t } - a _ { t } ) ^ { \prime }$ if $p > 1$ . Simple algebra shows that

$$
\begin{array}{l} \left[ \begin{array}{c} z _ {t - p + 2} \\ z _ {t - p + 3} \\ \vdots \\ z _ {t} \\ z _ {t + 1} - a _ {t + 1} \end{array} \right] = \left[ \begin{array}{c c c c c} 0 & 1 & 0 & \cdot & 0 \\ 0 & 0 & 1 & & 0 \\ \vdots & & & & \vdots \\ 0 & 0 & 0 & 1 \\ \phi_ {p} & \phi_ {p - 1} & \phi_ {p - 2} & \cdot & \phi_ {1} \end{array} \right] \left[ \begin{array}{c} z _ {t - p + 1} \\ z _ {t - p + 2} \\ \vdots \\ z _ {t - 1} \\ z _ {t} - a _ {t} \end{array} \right] + \left[ \begin{array}{c} 0 \\ 0 \\ \vdots \\ 1 \\ \phi_ {1} \end{array} \right] a _ {t}, \\ z _ {t} = (0, 0, \dots , 0, 1) s _ {t} + a _ {t}. \tag {11.41} \\ \end{array}
$$

Again, $a _ { t }$ appears in both transition and measurement equations.

Turn to the $\mathbf { A R M A } ( p , q )$ model $\phi ( B ) y _ { t } = \theta ( B ) a _ { t }$ . For simplicity, we assume $q < p$ and introduce an auxiliary variable $z _ { t } = [ 1 / \phi ( B ) ] a _ { t }$ . Then, we have

$$
\phi (B) z _ {t} = a _ {t}, \quad y _ {t} = \theta (B) z _ {t}.
$$

Since $z _ { t }$ is an $\operatorname { A R } ( p )$ model, we can use the transition equation in Eq. (11.40) or Eq. (11.41). If Eq. (11.40) is used, we can use $y _ { t } = \theta ( B ) z _ { t }$ to construct the measurement equation as

$$
y _ {t} = (- \theta_ {p - 1}, - \theta_ {p - 2}, \dots , - \theta_ {1}, 1) s _ {t}, \tag {11.42}
$$

where it is understood that $p > q$ and $\theta _ { j } = 0$ for $j > q$ . On the other hand, if Eq. (11.41) is used as the transition equation, we construct the measurement equation as

$$
y _ {t} = \left(- \theta_ {p - 1}, - \theta_ {p - 2}, \dots , - \theta_ {1}, 1\right) s _ {t} + a _ {t}. \tag {11.43}
$$

In summary, there are many state-space representations for an ARMA model. Each representation has its pros and cons. For estimation and forecasting purposes, one can choose any one of those representations. On the other hand, for a timeinvariant coefficient state-space model in Eqs. (11.24) and (11.25), one can use the Cayley–Hamilton theorem to show that the observation $y _ { t }$ follows an ARMA(m, m) model, where $m$ is the dimension of the state vector.

# SsfPack Command

In SsfPack/S-Plus, a command GetSsfArma can be used to transform an ARMA model into a state-space form. Harvey’s approach is used. To illustrate, consider the AR(1) model

$$
y _ {t} = 0. 6 y _ {t - 1} + a _ {t}, \quad a _ {t} \sim N (0, 0. 4 ^ {2}).
$$

The state-space form of the model is

```csv
>ssf.ar1 = GetSsfArma(ar=0.6,sigma=0.4)
>ssf.ar1
$mPhi:
[.,1]
[1,] 0.6
[2,] 1.0
$mOmega:
[.,1] [,2]
[1,] 0.16 0
[2,] 0.00 0
$mSigma:
[.,1]
[1,] 0.25
[2,] 0.00 
```

Since the AR(1) model is stationary, the program uses $\Sigma _ { 1 | 0 } = \mathrm { V a r } ( y _ { t } ) = ( 0 . 4 ) ^ { 2 } /$ $( 1 - 0 . 6 ^ { 2 } ) = 0 . 2 5$ and $\mu _ { 1 | 0 } = 0$ . These values appear in the matrix mSigma.

As a second example, consider the ARMA(2,1) model

$$
y _ {t} = 1. 2 y _ {t - 1} - 0. 3 5 y _ {t - 2} + a _ {t} - 0. 2 5 a _ {t - 1}, \quad a _ {t} \sim N (0, 1. 1 ^ {2}).
$$

The state-space form of the model is

```html
>arma21.m = list(ar=c(1.2,-0.35),ma=c(-0.25),sigma=1.1)
>ssf.arma21= GetSsfArma(model=arma21.m)
>ssf.arma21
$mPhi:
[.,1] [,2]
[1,] 1.20 1
[2,] -0.35 0
[3,] 1.00 0
$mOmega:
[.,1] [,2] [,3]
[1,] 1.2100 -0.302500 0
[2,] -0.3025 0.075625 0
[3,] 0.0000 0.000000 0
$mSigma:
[.,1] [,2] 
```

[1,] 4.060709 -1.4874057   
[2,] -1.487406 0.5730618   
[3,] 0.000000 0.0000000

As expected, the output shows that

$$
\boldsymbol {T} = \left[ \begin{array}{c c} 1. 2 & 1 \\ - 0. 3 5 & 0 \end{array} \right], \quad \boldsymbol {Z} = (1, 0),
$$

and mPhi and mOmega follow the format of Eq. (11.26), and the covariance matrix of $( y _ { t } , y _ { t - 1 } ) ^ { \prime }$ is used in mSigma. Note that in SsfPack, the MA polynomial of an ARMA model assumes the form $\theta ( B ) = 1 + \theta _ { 1 } B + \cdot \cdot \cdot + \theta _ { q } B ^ { q }$ , not the form $\theta ( B ) = 1 - \theta _ { 1 } B - \cdot \cdot \cdot - \theta _ { q } B ^ { q }$ commonly used in the literature.

# 11.3.3 Linear Regression Model

Multiple linear regression models can also be represented in state-space form. Consider the model

$$
y _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + e _ {t}, \quad e _ {t} \sim N (0, \sigma_ {e} ^ {2}),
$$

where $\scriptstyle { \boldsymbol { x } } _ { t }$ is a $p$ -dimensional explanatory variable and $\beta$ is a $p$ -dimensional parameter vector. Let $s _ { t } = \beta$ for all $t$ . Then the model can be written as

$$
\left[ \begin{array}{c} \boldsymbol {s} _ {t + 1} \\ y _ {t} \end{array} \right] = \left[ \begin{array}{l} \boldsymbol {I} _ {p} \\ \boldsymbol {x} _ {t} ^ {\prime} \end{array} \right] \boldsymbol {s} _ {t} + \left[ \begin{array}{l} \boldsymbol {0} _ {p} \\ e _ {t} \end{array} \right]. \tag {11.44}
$$

Thus, the system matrices are $\pmb { T } _ { t } = \pmb { I } _ { p }$ $\pmb { T } _ { t } = \pmb { I } _ { p } , \ \pmb { Z } _ { t } = \pmb { x } _ { t } ^ { \prime } , \ \pmb { d } _ { t } = \pmb { 0 } , \ c _ { t } = 0 , \ \pmb { H } _ { t } = \pmb { 0 }$ $\mathbf { Z } _ { t } = \mathbf { \mathcal { x } } _ { t } ^ { \prime }$ , and $Q _ { t } = \sigma _ { e } ^ { 2 }$ . Since the state vector is fixed, a diffuse initialization should be used.

One can extend the regression model so that $\beta _ { t }$ is random, say,

$$
\boldsymbol {\beta} _ {t + 1} = \boldsymbol {\beta} _ {t} + \boldsymbol {R} _ {t} \eta_ {t}, \quad \eta_ {t} \sim N (0, 1),
$$

and $\pmb { R } _ { t } = ( \sigma _ { 1 } , \ldots , \sigma _ { p } ) ^ { \prime }$ with $\sigma _ { i } \geq 0$ . If $\sigma _ { i } = 0$ , then $\beta _ { i }$ is time-invariant.

# SsfPack Command

In SsfPack, the command GetSsfReg creates a state-space form for the multiple linear regression model. The command has an input argument that contains the data matrix of explanatory variables. To illustrate, consider the simple market model

$$
r _ {t} = \beta_ {0} + \beta_ {1} r _ {M, t} + e _ {t}, \quad t = 1, \dots , 1 6 8,
$$

where $r _ { t }$ is the return of an asset and $r _ { M , t }$ is the market return, for example, the S&P 500 composite index return. The state-space form can be obtained as

> ssf.reg=GetSsfReg(cbind(1,sp)) % ‘sp’ is market return.

> ssf.reg

$mPhi: [,1] [,2]

[1,] 1 0   
0 1   
[3,] 0 0

$mOmega: [,1] [,2] [,3]

[1,] 0 0 0   
[2,] 0 0 0   
[3,] 0 0 1

$mSigma:

[,1] [,2]

[1,] -1 0   
[2,] 0 -1   
[3,] 0 0

$mJPhi:

[,1] [,2]

[1,] -1 -1   
[2,] -1 -1   
[3,] 1 2

$\$ 123$

numeric matrix: 168 rows, 2 columns. sp   
[1,] 1 -0.075187   
  
[168,] 1 0.05002

# 11.3.4 Linear Regression Models with ARMA Errors

Consider the regression model with ARMA $( p , q )$ errors,

$$
y _ {t} = x _ {t} ^ {\prime} \boldsymbol {\beta} + z _ {t}, \quad \phi (B) z _ {t} = \theta (B) a _ {t}, \tag {11.45}
$$

where $a _ { t } \sim N ( 0 , \sigma _ { a } ^ { 2 } )$ and $\scriptstyle { \boldsymbol { x } } _ { t }$ is a $k$ -dimensional vector of explanatory variables. A special case of this model is the nonzero mean $\mathbf { A R M A } ( p , q )$ model in which $\boldsymbol { x } _ { t } = 1$ for all $t$ and $\beta$ becomes a scalar parameter. Let $\mathbf { } _ { \pmb { S } _ { t } }$ be a state vector for the $z _ { t }$ series, for example, that defined in Eq. (11.37). We can define a state vector $s _ { t } ^ { * }$ for $y _ { t }$ as

$$
\mathbf {s} _ {t} ^ {*} = \left[ \begin{array}{l} s _ {t} \\ \boldsymbol {\beta} _ {t} \end{array} \right], \tag {11.46}
$$

where $\beta _ { t } = \beta$ for all $t$ . Then, a state-space form for $y _ { t }$ is

$$
\begin{array}{l} s _ {t + 1} ^ {*} = \boldsymbol {T} ^ {*} s _ {t} ^ {*} + \boldsymbol {R} ^ {*} \eta_ {t}, (11.47) \\ y _ {t} = \mathbf {Z} _ {t} ^ {*} s _ {t} ^ {*}, (11.48) \\ \end{array}
$$

where $\pmb { Z } _ { t } ^ { * } = ( 1 , 0 , \ldots , 0 , \pmb { x } _ { t } ^ { \prime } ) _ { 1 \times ( m + k ) }$ , $m = \operatorname* { m a x } ( p , q + 1 )$ , and

$$
\boldsymbol {T} ^ {*} = \left[ \begin{array}{c c} \boldsymbol {T} & \boldsymbol {0} \\ \boldsymbol {0} & \boldsymbol {I} _ {k} \end{array} \right], \quad \boldsymbol {R} ^ {*} = \left[ \begin{array}{c} \boldsymbol {R} \\ \boldsymbol {0} \end{array} \right],
$$

where $T$ and $\pmb { R }$ are defined in Eq. (11.37). In a compact form, we have the statespace model

$$
\left[ \begin{array}{c} s _ {t + 1} ^ {*} \\ y _ {t} \end{array} \right] = \left[ \begin{array}{c} \boldsymbol {T} ^ {*} \\ \boldsymbol {Z} _ {t} ^ {*} \end{array} \right] s _ {t} ^ {*} + \left[ \begin{array}{c} \boldsymbol {R} ^ {*} \eta_ {t} \\ 0 \end{array} \right].
$$

# SsfPack Command

SsfPack uses the command GetSsfRegArma to construct a state-space form for linear regression models with ARMA errors. The arguments of the command can be found using the command args(GetSsfRegArma). They consist of a data matrix for the explanatory variables and ARMA model specification. To illustrate, consider the model

$$
\begin{array}{l} y _ {t} = \beta_ {0} + \beta_ {1} x _ {t} + z _ {t}, \quad t = 1, \dots , 1 6 8, \\ z _ {t} = 1. 2 z _ {t - 1} - 0. 3 5 z _ {t - 2} + a _ {t} - 0. 2 5 a _ {t - 1}, \quad a _ {t} \sim N (0, \sigma_ {a} ^ {2}). \\ \end{array}
$$

We use the notation X to denote the $T \times 2$ matrix of regressors $( 1 , x _ { t } )$ . A state-space form for the prior model can be obtained as

$$
> \text {s s f . r e g . a r m a 2 1} = \text {G e t S s f R e g A r m a} (X, \operatorname {a r} = c (1. 2, - 0. 3 5),
$$

$$
+ \mathrm {m a} = \mathrm {c} (- 0. 2 5))
$$

$$
> \text {s s f . r e g . a r m a 2 1}
$$

$mPhi:

$$
[ , 1 ] \quad [ , 2 ] \quad [ , 3 ] \quad [ , 4 ]
$$

$$
[ 1, ] \quad 1. 2 0 \quad 1 \quad 0 \quad 0
$$

$$
[ 2, ] - 0. 3 5 \quad 0 \quad 0 \quad 0
$$

$$
[ 3, ] \quad 0. 0 0 \quad 0 \quad 1 \quad 0
$$

$$
[ 4, ] \quad 0. 0 0 \quad 0 \quad 0 \quad 1
$$

$$
[ 5, ] \quad 1. 0 0 \quad 0 \quad 0 \quad 0
$$

$mOmega:

$$
[ \cdot , 1 ] \quad [ \cdot , 2 ] \quad [ \cdot , 3 ] \quad [ \cdot , 4 ] \quad [ \cdot , 5 ]
$$

$$
[ 1, ] \quad 1. 0 0 - 0. 2 5 0 0 \quad 0 \quad 0 \quad 0
$$

$$
[ 2, ] - 0. 2 5 0. 0 6 2 5 \quad 0 \quad 0 \quad 0
$$

$$
[ 3, ] \quad 0. 0 0 \quad 0. 0 0 0 0 \quad 0 \quad 0 \quad 0
$$

$$
[ 4, ] \quad 0. 0 0 \quad 0. 0 0 0 0 \quad 0 \quad 0 \quad 0
$$

$$
[ 5, ] \quad 0. 0 0 \quad 0. 0 0 0 0 \quad 0 \quad 0 \quad 0
$$

$mSigma:

$$
[ \cdot , 1 ] \quad [ \cdot , 2 ] \quad [ \cdot , 3 ] \quad [ \cdot , 4 ]
$$

$$
[ 1, ] \quad 3. 3 5 5 9 5 - 1. 2 2 9 2 6 0 \quad 0 \quad 0
$$

$$
[ 2, ] - 1. 2 2 9 2 6 \quad 0. 4 7 3 6 0 4 \quad 0 \quad 0
$$

$$
[ 3, ] \quad 0. 0 0 0 0 0 \quad 0. 0 0 0 0 0 0 \quad - 1 \quad 0
$$

$$
[ 4, ] \quad 0. 0 0 0 0 0 \quad 0. 0 0 0 0 0 0 \quad 0 \quad - 1
$$

[5,] 0.00000 0.000000 0 0
$mJPhi:
[.,1] [,2] [,3] [,4]
[1,] -1 -1 -1 -1
[2,] -1 -1 -1 -1
[3,] -1 -1 -1 -1
[4,] -1 -1 -1 -1
[5,] -1 -1 1 2
$mX:
numeric matrix: 168 rows, 2 columns.
xt
[1,] 1 0.4993
...
[168,] 1 0.7561

# 11.3.5 Scalar Unobserved Component Model

The basic univariate unobserved component model, or the structural time series model (STSM), assumes the form

$$
y _ {t} = \mu_ {t} + \gamma_ {t} + \varpi_ {t} + e _ {t}, \tag {11.49}
$$

where $\mu _ { t } , \gamma _ { t }$ , and $\varpi _ { t }$ represent the unobserved trend, seasonal, and cycle components, respectively, and $e _ { t }$ is the unobserved irregular component. In the literature, a nonstationary (possibly double-unit-root) model is commonly used for the trend component:

$$
\mu_ {t + 1} = \mu_ {t} + \beta_ {t} + \eta_ {t}, \quad \eta_ {t} \sim N \left(0, \sigma_ {\eta} ^ {2}\right), \tag {11.50}
$$

$$
\beta_ {t} = \beta_ {t - 1} + \varsigma_ {t}, \quad \varsigma_ {t} \sim N (0, \sigma_ {\varsigma} ^ {2}),
$$

where $\mu _ { 1 } \sim N ( 0 , \xi )$ and $\beta _ { 1 } \sim N ( 0 , \xi )$ with $\xi$ a large real number, for example, $\xi = 1 0 ^ { 8 }$ . See, for instance, Kitagawa and Gersch (1996). If $\sigma _ { \varsigma } = 0$ , then $\mu _ { t }$ follows a random walk with drift $\beta _ { 1 }$ . If $\sigma _ { \varsigma } = \sigma _ { \eta } = 0$ , then $\mu _ { t }$ represents a linear deterministic trend.

The seasonal component $\gamma _ { t }$ assumes the form

$$
(1 + B + \dots + B ^ {s - 1}) \gamma_ {t} = \omega_ {t}, \quad \omega_ {t} \sim N (0, \sigma_ {\omega} ^ {2}), \tag {11.51}
$$

where $s$ is the number of seasons in a year, that is, the period of the seasonality. If $\sigma _ { \omega } = 0$ , then the seasonal pattern is deterministic. The cycle component is postulated as

$$
\left[ \begin{array}{c} \varpi_ {t + 1} \\ \varpi_ {t + 1} ^ {*} \end{array} \right] = \delta \left[ \begin{array}{c c} \cos \left(\lambda_ {c}\right) & \sin \left(\lambda_ {c}\right) \\ - \sin \left(\lambda_ {c}\right) & \cos \left(\lambda_ {c}\right) \end{array} \right] \left[ \begin{array}{c} \varpi_ {t} \\ \varpi_ {t} ^ {*} \end{array} \right] + \left[ \begin{array}{c} \varepsilon_ {t} \\ \varepsilon_ {t} ^ {*} \end{array} \right], \tag {11.52}
$$

Table 11.4. Arguments of the Command GetSsfStsm in SsfPack/S-Plus   

<table><tr><td>Argument</td><td>STSM Parameter</td></tr><tr><td>irregular</td><td>σe</td></tr><tr><td>level</td><td>ση</td></tr><tr><td>slope</td><td>σs</td></tr><tr><td>seasonalDummy</td><td>σω, s</td></tr><tr><td>seasonalTrig</td><td>σω, s</td></tr><tr><td>seasonalHS</td><td>σω, s</td></tr><tr><td>Cycle0</td><td>σε, λc, δ</td></tr><tr><td>·</td><td>·</td></tr><tr><td>Cycle9</td><td>σε, λc, δ</td></tr></table>

where

$$
\left[ \begin{array}{c} \varepsilon_ {t} \\ \varepsilon_ {t} ^ {*} \end{array} \right] \sim N \left(\left[ \begin{array}{c} 0 \\ 0 \end{array} \right], \sigma_ {\varepsilon} ^ {2} (1 - \delta^ {2}) I _ {2}\right),
$$

$\varpi _ { 0 } \sim N ( 0 , \sigma _ { \varepsilon } ^ { 2 } )$ $\varpi _ { 0 } \sim N ( 0 , \sigma _ { \varepsilon } ^ { 2 } ) , \varpi _ { 0 } ^ { * } \sim N ( 0 , \sigma _ { \varepsilon } ^ { 2 } )$ , and $\mathrm { C o v } ( \varpi _ { 0 } , \varpi _ { 0 } ^ { * } ) = 0 , \ \delta \in ( 0 , 1 ]$ is called a damping factor, and the frequency of the cycle is $\lambda _ { c } = 2 \pi / q$ with $q$ being the period. If $\delta = 1$ , then the cycle becomes a deterministic sine–cosine wave.

# SsfPack/S-Plus Command

The command GetSsfStsm constructs a state-space form for the structural time series model. It allows for 10 cycle components; see the output of the command args(GetSsfStsm). Table 11.4 provides a summary of the arguments and their corresponding symbols of the model. To illustrate, consider the local trend model in Eqs. (11.1) and (11.2) with $\sigma _ { e } = 0 . 4$ and $\sigma _ { \eta } = 0 . 2$ . This is a special case of the scalar unobserved component model. One can obtain a state-space form as

```csv
>ssf.stsm=GetSsfStsm(irregular=0.4,level=0.2)
>ssf.stsm
$mPhi:
[.,1]
[1,] 1
[2,] 1
$mOmega:
[.,1] [,2]
[1,] 0.04 0.00
[2,] 0.00 0.16
$mSigma:
[.,1]
[1,] -1
[2,] 0 
```

# 11.4 KALMAN FILTER AND SMOOTHING

In this section, we study the Kalman filter and various smoothing methods for the general state-space model in Eqs. (11.24) and (11.25). The derivation follows closely the steps taken in Section 11.1. For readers interested in applications, this section can be skipped at the first read. A good reference for this section is Durbin and Koopman (2001, Chapter 4).

# 11.4.1 Kalman Filter

Recall that the aim of the Kalman filter is to obtain recursively the conditional distribution of $\pmb { S } _ { t + 1 }$ given the data $F _ { t } = \{ { \bf y } _ { 1 } , \ldots , { \bf y } _ { t } \}$ and the model. Since the conditional distribution involved is normal, it suffices to study the conditional mean and covariance matrix. Let $\mathbf { \Delta } _ { s _ { j \vert i } }$ and $\pmb { \Sigma } _ { j | i }$ be the conditional mean and covariance matrix of $s _ { j }$ given $F _ { i }$ , that is, $s _ { j } | F _ { i } \sim N ( s _ { j | i } , \pmb { \Sigma } _ { j | i } )$ . From Eq. (11.24),

$$
s _ {t + 1 | t} = E \left(\boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} s _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} \mid F _ {t}\right) = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} s _ {t | t}, \tag {11.53}
$$

$$
\boldsymbol {\Sigma} _ {t + 1 \mid t} = \operatorname {V a r} \left(\boldsymbol {T} _ {t} \boldsymbol {s} _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} \mid F _ {t}\right) = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t \mid t} \boldsymbol {T} _ {t} ^ {\prime} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime}. \tag {11.54}
$$

Similarly to that of Section 11.1, let $\boldsymbol { y } _ { t \left. t - \right. }$ be the conditional mean of $y _ { t }$ given $F _ { t - 1 }$ . From Eq. (11.25),

$$
\mathbf {y} _ {t \mid t - 1} = \mathbf {c} _ {t} + \mathbf {Z} _ {t} \mathbf {s} _ {t \mid t - 1}.
$$

Let

$$
\boldsymbol {v} _ {t} = \boldsymbol {y} _ {t} - \boldsymbol {y} _ {t | t - 1} = \boldsymbol {y} _ {t} - \left(\boldsymbol {c} _ {t} + \boldsymbol {Z} _ {t} s _ {t | t - 1}\right) = \boldsymbol {Z} _ {t} \left(s _ {t} - s _ {t | t - 1}\right) + \boldsymbol {e} _ {t}, \tag {11.55}
$$

be the 1-step ahead forecast error of $\boldsymbol { y } _ { t }$ given $F _ { t - 1 }$ . It is easy to see that (a) $E ( \pmb { v } _ { t } | F _ { t - 1 } ) = \pmb { 0 }$ ; (b) ${ \boldsymbol { v } } _ { t }$ is independent of $F _ { t - 1 }$ , that is, $\mathrm { C o v } ( { \pmb v } _ { t } , { \pmb y } _ { j } ) = { \pmb 0 }$ for $1 \le j < t$ ; and (c) $\{ \pmb { v } _ { t } \}$ is a sequence of independent normal random vectors. Also, let $V _ { t } = \operatorname { V a r } ( \pmb { v } _ { t } | \boldsymbol { F } _ { t - 1 } ) = \operatorname { V a r } ( \pmb { v } _ { t } )$ be the covariance matrix of the 1-step ahead forecast error. From Eq. (11.55), we have

$$
\boldsymbol {V} _ {t} = \operatorname {V a r} \left[ \boldsymbol {Z} _ {t} \left(\boldsymbol {s} _ {t} - \boldsymbol {s} _ {t | t - 1}\right) + \boldsymbol {e} _ {t} \right] = \boldsymbol {Z} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime} + \boldsymbol {H} _ {t}. \tag {11.56}
$$

Since $F _ { t } = \{ F _ { t - 1 } , \mathbf { y } _ { t } \} = \{ F _ { t - 1 } , \pmb { v } _ { t } \}$ , we can apply Theorem 11.1 to obtain

$$
\begin{array}{l} \boldsymbol {s} _ {t \mid t} = E (\boldsymbol {s} _ {t} \mid F _ {t}) = E (\boldsymbol {s} _ {t} \mid F _ {t - 1}, \boldsymbol {v} _ {t}) \\ = E \left(\boldsymbol {s} _ {t} \mid F _ {t - 1}\right) + \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {t}\right) [ \operatorname {V a r} (\boldsymbol {v} _ {t}) ] ^ {- 1} \boldsymbol {v} _ {t} \\ = \boldsymbol {s} _ {t | t - 1} + \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t}, \tag {11.57} \\ \end{array}
$$

where $\begin{array} { r } { \pmb { C } _ { t } = \mathbf { C } \mathrm { o v } ( \pmb { s } _ { t } , \pmb { v } _ { t } | \boldsymbol { F } _ { t - 1 } ) } \end{array}$ given by

$$
\begin{array}{l} \boldsymbol {C} _ {t} = \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {t} \mid F _ {t - 1}\right) = \operatorname {C o v} \left[ \boldsymbol {s} _ {t}, \boldsymbol {Z} _ {t} \left(\boldsymbol {s} _ {t} - \boldsymbol {s} _ {t \mid t - 1}\right) + \boldsymbol {e} _ {t} \mid F _ {t - 1} \right] \\ = \operatorname {C o v} \left[ s _ {t}, \mathbf {Z} _ {t} \left(s _ {t} - s _ {t \mid t - 1}\right) \mid F _ {t - 1} \right] = \boldsymbol {\Sigma} _ {t \mid t - 1} \mathbf {Z} _ {t} ^ {\prime}. \\ \end{array}
$$

Here we assume that $\mathbf { } _ { \mathbf { } } { V } _ { t }$ is invertible, because $\pmb { H } _ { t }$ is. Using Eqs. (11.53) and (11.57), we obtain

$$
\boldsymbol {s} _ {t + 1 | t} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t | t - 1} + \boldsymbol {T} _ {t} \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t | t - 1} + \boldsymbol {K} _ {t} \boldsymbol {v} _ {t}, \tag {11.58}
$$

where

$$
\boldsymbol {K} _ {t} = \boldsymbol {T} _ {t} \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1}, \tag {11.59}
$$

which is the Kalman gain at time t. Applying Theorem 11.1(2), we have

$$
\begin{array}{l} \boldsymbol {\Sigma} _ {t \mid t} = \operatorname {V a r} \left(\boldsymbol {s} _ {t} \mid F _ {t - 1}\right) \\ = \operatorname {V a r} \left(s _ {t} \mid F _ {t - 1}\right) - \operatorname {C o v} \left(s _ {t}, v _ {t}\right) \left[ \operatorname {V a r} \left(v _ {t}\right) \right] ^ {- 1} \operatorname {C o v} \left(s _ {t}, v _ {t}\right) ^ {\prime} \\ = \boldsymbol {\Sigma} _ {t | t - 1} - \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {C} _ {t} ^ {\prime} \\ = \boldsymbol {\Sigma} _ {t | t - 1} - \boldsymbol {\Sigma} _ {t | t - 1} \mathbf {Z} _ {t} ^ {\prime} V _ {t} ^ {- 1} \mathbf {Z} _ {t} \boldsymbol {\Sigma} _ {t | t - 1}. \tag {11.60} \\ \end{array}
$$

Plugging Eq. (11.60) into Eq. (11.54) and using Eq. (11.59), we obtain

$$
\boldsymbol {\Sigma} _ {t + 1 \mid t} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {L} _ {t} ^ {\prime} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime}, \tag {11.61}
$$

where

$$
\boldsymbol {L} _ {t} = \boldsymbol {T} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {Z} _ {t}.
$$

Putting the prior equations together, we obtain the celebrated Kalman filter for the state-space model in Eqs. (11.24) and (11.25). Given the starting values $\pmb { s } _ { 1 | 0 }$ and $\pmb { \Sigma } _ { 1 | 0 }$ , the Kalman filter algorithm is

$$
\boldsymbol {v} _ {t} = \boldsymbol {y} _ {t} - \boldsymbol {c} _ {t} - \boldsymbol {Z} _ {t} s _ {t | t - 1},
$$

$$
\boldsymbol {V} _ {t} = \boldsymbol {Z} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime} + \boldsymbol {H} _ {t},
$$

$$
\boldsymbol {K} _ {t} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime} V _ {t} ^ {- 1}, \tag {11.62}
$$

$$
\boldsymbol {L} _ {t} = \boldsymbol {T} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {Z} _ {t},
$$

$$
\boldsymbol {s} _ {t + 1 \mid t} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t \mid t - 1} + \boldsymbol {K} _ {t} \boldsymbol {v} _ {t},
$$

$$
\boldsymbol {\Sigma} _ {t + 1 | t} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime}, \quad t = 1, \dots , T.
$$

If the filtered quantities $\boldsymbol { s } _ { t \left| t \right. }$ and $\pmb { \Sigma } _ { t \mid t }$ are also of interest, then we modify the filter to include the contemporaneous filtering equations in Eqs. (11.57) and (11.60). The resulting algorithm is

$$
\boldsymbol {v} _ {t} = \boldsymbol {y} _ {t} - \boldsymbol {c} _ {t} - \boldsymbol {Z} _ {t} s _ {t | t - 1},
$$

$$
\boldsymbol {C} _ {t} = \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime},
$$

$$
\boldsymbol {V} _ {t} = \boldsymbol {Z} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {Z} _ {t} ^ {\prime} + \boldsymbol {H} _ {t} = \boldsymbol {Z} _ {t} \boldsymbol {C} _ {t} + \boldsymbol {H} _ {t},
$$

$$
\boldsymbol {s} _ {t \mid t} = \boldsymbol {s} _ {t \mid t - 1} + \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t},
$$

$$
\boldsymbol {\Sigma} _ {t \mid t} = \boldsymbol {\Sigma} _ {t \mid t - 1} - \boldsymbol {C} _ {t} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {C} _ {t} ^ {\prime},
$$

$$
\boldsymbol {s} _ {t + 1 | t} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t | t},
$$

$$
\boldsymbol {\Sigma} _ {t + 1 \mid t} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t \mid t} \boldsymbol {T} _ {t} ^ {\prime} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime}.
$$

# Steady State

If the state-space model is time-invariant, that is, all system matrices are timeinvariant, then the matrices $\pmb { \Sigma } _ { t \mid t - 1 }$ converge to a constant matrix $\pmb { \Sigma } _ { * }$ , which is a solution of the matrix equation

$$
\boldsymbol {\Sigma} _ {*} = \boldsymbol {T} \boldsymbol {\Sigma} _ {*} \boldsymbol {T} ^ {\prime} - \boldsymbol {T} \boldsymbol {\Sigma} _ {*} \boldsymbol {Z} \boldsymbol {V} ^ {- 1} \boldsymbol {Z} \boldsymbol {\Sigma} _ {*} \boldsymbol {T} ^ {\prime} + \boldsymbol {R} \boldsymbol {Q} \boldsymbol {R} ^ {\prime},
$$

where $V = Z \Sigma _ { * } Z ^ { \prime } + H$ . The solution that is reached after convergence to $\pmb { \Sigma } _ { * }$ is referred to as the steady-state solution of the Kalman filter. Once the steady state is reached, $\mathbf { } _ { \mathbf { } } { V } _ { t }$ , $\pmb { K } _ { t }$ , and $\pmb { \Sigma } _ { t + 1 | t }$ are all constant. This can lead to considerable saving in computing time.

# 11.4.2 State Estimation Error and Forecast Error

Define the state prediction error as

$$
\boldsymbol {x} _ {t} = \boldsymbol {s} _ {t} - \boldsymbol {s} _ {t | t - 1}.
$$

From the definition, the covariance matrix of $\boldsymbol { x } _ { t }$ is $\operatorname { V a r } ( x _ { t } | F _ { t - 1 } ) = \operatorname { V a r } ( s _ { t } | F _ { t - 1 } ) =$ $\pmb { \Sigma } _ { t \mid t - 1 }$ . Following Section 11.1, we investigate properties of $\mathbf { \boldsymbol { x } } _ { t }$ . First, from Eq. (11.55),

$$
\boldsymbol {v} _ {t} = \boldsymbol {Z} _ {t} \left(\boldsymbol {s} _ {t} - \boldsymbol {s} _ {t | t - 1}\right) + \boldsymbol {e} _ {t} = \boldsymbol {Z} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {e} _ {t}.
$$

Second, from Eqs. (11.62) and (11.24), and the prior equation, we have

$$
\begin{array}{l} x _ {t + 1} = s _ {t + 1} - s _ {t + 1 \mid t} \\ = \boldsymbol {T} _ {t} \left(\boldsymbol {s} _ {t} - \boldsymbol {s} _ {t | t - 1}\right) + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {v} _ {t} \\ = \boldsymbol {T} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} - \boldsymbol {K} _ {t} (\boldsymbol {Z} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {e} _ {t}) \\ = \boldsymbol {L} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {e} _ {t}, \\ \end{array}
$$

where, as before, $L _ { t } = T _ { t } - K _ { t } \mathbf { Z } _ { t }$ . Consequently, we obtain a state-space form for ${ \boldsymbol { v } } _ { t }$ as

$$
\boldsymbol {v} _ {t} = \boldsymbol {Z} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {e} _ {t}, \quad \boldsymbol {x} _ {t + 1} = \boldsymbol {L} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {e} _ {t}, \tag {11.63}
$$

with ${ \pmb x } _ { 1 } = { \pmb s } _ { 1 } - { \pmb s } _ { 1 | 0 }$ for $t = 1 , \dots , T$

Finally, similar to the local trend model in Section 11.1, we can show that the 1-step ahead forecast errors $\{ \pmb { v } _ { t } \}$ are independent of each other and $\big \{ \pmb { v } _ { t } , \dots , \pmb { v } _ { T } \big \}$ is independent of $F _ { t - 1 }$ .

# 11.4.3 State Smoothing

State smoothing focuses on the conditional distribution of $\mathbf { } _ { \pmb { S } _ { t } }$ given $F _ { T }$ . Notice that (a) $F _ { t - 1 }$ and $\{ \pmb { v } _ { t } , \dotsc , \pmb { v } _ { T } \}$ are independent and (b) ${ \pmb v } _ { t }$ are serially independent. We can apply Theorem 11.1 to the joint distribution of $\mathbf { } _ { \pmb { S } _ { t } }$ and $\big \{ \pmb { v } _ { t } , \dots , \pmb { v } _ { T } \big \}$ given $F _ { t - 1 }$ and obtain

$$
\begin{array}{l} \boldsymbol {s} _ {t \mid T} = E (\boldsymbol {s} _ {t} \mid F _ {T}) = E (\boldsymbol {s} _ {t} \mid F _ {t - 1}, \boldsymbol {v} _ {t}, \dots , \boldsymbol {v} _ {T}) \\ = E \left(\boldsymbol {s} _ {t} \mid F _ {t - 1}\right) + \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {j}\right) \left[ \operatorname {V a r} \left(\boldsymbol {v} _ {t}\right) \right] ^ {- 1} \boldsymbol {v} _ {t} \\ = \boldsymbol {s} _ {t | t - 1} + \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {j}\right) \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t}, \tag {11.64} \\ \end{array}
$$

where the covariance matrices are conditional on $F _ { t - 1 }$ . The covariance matrices $\mathbf { C o v } ( \pmb { s } _ { t } , \pmb { v } _ { j } )$ for $j = t , \ldots , T$ can by derived as follows. By Eq. (11.63),

$$
\begin{array}{l} \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {j}\right) = E \left(\boldsymbol {s} _ {t} \boldsymbol {v} _ {j} ^ {\prime}\right) \\ = E \left[ s _ {t} \left(\mathbf {Z} _ {j} \mathbf {x} _ {j} + \mathbf {e} _ {j}\right) ^ {\prime} \right] = E \left(s _ {t} \mathbf {x} _ {j} ^ {\prime}\right) \mathbf {Z} _ {j} ^ {\prime}, \quad j = t, \dots , T. \tag {11.65} \\ \end{array}
$$

Furthermore,

$$
E \left(s _ {t} x _ {t} ^ {\prime}\right) = E \left[ s _ {t} \left(s _ {t} - s _ {t | t - 1}\right) ^ {\prime} \right] = \operatorname {V a r} \left(s _ {t}\right) = \boldsymbol {\Sigma} _ {t | t - 1},
$$

$$
E \left(s _ {t} \boldsymbol {x} _ {t + 1} ^ {\prime}\right) = E \left[ s _ {t} \left(\boldsymbol {L} _ {t} \boldsymbol {x} _ {t} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t} - \boldsymbol {K} _ {t} \boldsymbol {e} _ {t}\right) ^ {\prime} \right] = \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime},
$$

$$
E \left(s _ {t} x _ {t + 2} ^ {\prime}\right) = \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime}, \tag {11.66}
$$

$$
\begin{array}{c} \vdots = \vdots \\ \vdots = \vdots \end{array}
$$

$$
E \left(\boldsymbol {s} _ {t} \boldsymbol {x} _ {T} ^ {\prime}\right) = \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime}.
$$

Plugging the prior two equations into Eq. (11.64), we have

$$
\boldsymbol {s} _ {T \mid T} = \boldsymbol {s} _ {T \mid T - 1} + \boldsymbol {\Sigma} _ {T \mid T - 1} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {v} _ {T},
$$

$$
s _ {T - 1 | T} = s _ {T - 1 | T - 2} + \boldsymbol {\Sigma} _ {T | T - 1} \boldsymbol {Z} _ {T - 1} ^ {\prime} \boldsymbol {V} _ {T - 1} ^ {- 1} \boldsymbol {v} _ {T - 1} + \boldsymbol {\Sigma} _ {T | T - 1} \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {v} _ {T},
$$

$$
\begin{array}{l} s _ {t \mid T} = s _ {t \mid t - 1} + \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t - 1} ^ {- 1} \boldsymbol {v} _ {t + 1} \\ + \dots + \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {v} _ {T}, \\ \end{array}
$$

for $t = T - 2 , T - 3 , \ldots , 1$ , where it is understood that $\pmb { L } _ { t } ^ { \prime } \cdot \cdot \cdot \pmb { L } _ { T - 1 } ^ { \prime } = \pmb { I } _ { m }$ when $t = T$ . These smoothed state vectors can be expressed as

$$
\boldsymbol {s} _ {t} | T = \boldsymbol {s} _ {t | t - 1} + \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {q} _ {t - 1}, \tag {11.67}
$$

where ${ \pmb q } _ { T - 1 } = { \pmb Z } _ { T } ^ { \prime } { \pmb V } _ { T } ^ { - 1 } { \pmb v } _ { T }$ , ${ \pmb q } _ { T - 2 } = { \pmb Z } _ { T - 1 } ^ { \prime } V _ { T - 1 } ^ { - 1 } { \pmb v } _ { T - 1 } + { \pmb L } _ { T - 1 } ^ { \prime } { \pmb Z } _ { T } ^ { \prime } V _ { T } ^ { - 1 } { \pmb v } _ { T }$ , and

$$
\boldsymbol {q} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t + 1} ^ {- 1} \boldsymbol {v} _ {t + 1} + \dots + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {v} _ {T},
$$

for $t = T - 2 , T - 3 , \ldots , 1 .$ . The quantity $\pmb q _ { t - 1 }$ is a weighted sum of the 1-step ahead forecast errors $v _ { j }$ occurring after time $t - 1$ . From the definition in the prior equation, $\pmb q _ { t }$ can be computed recursively backward as

$$
\boldsymbol {q} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} V _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \quad t = T, \dots , 1, \tag {11.68}
$$

with $\pmb q _ { T } = \pmb 0$ . Putting the equations together, we have a backward recursion for the smoothed state vectors as

$$
\boldsymbol {q} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \quad s _ {t | T} = s _ {t | t - 1} + \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {q} _ {t - 1}, \quad t = T, \dots , 1, \tag {11.69}
$$

starting with $\pmb q _ { T } = \pmb 0$ , where $\mathbf { \boldsymbol { s } } _ { t \left. t - 1 \right. }$ , $\pmb { \Sigma } _ { t \mid t - 1 }$ , Lt , and $\mathbf { } _ { \mathbf { } } { V } _ { t }$ are available from the Kalman filter. This algorithm is referred to as the fixed interval smoother in the literature; see de Jong (1989) and the references therein.

# Covariance Matrix of Smoothed State Vector

Next, we derive the covariance matrices of the smoothed state vectors. Applying Theorem 11.1(4) to the conditional joint distribution of $\mathbf { } _ { \pmb { s } _ { t } }$ and $\{ \pmb { v } _ { t } , \dotsc , \pmb { v } _ { T } \}$ given $F _ { t - 1 }$ , we have

$$
\boldsymbol {\Sigma} _ {t \mid T} = \boldsymbol {\Sigma} _ {t \mid t - 1} - \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {j}\right) \left[ \operatorname {V a r} \left(\boldsymbol {v} _ {j}\right) \right] ^ {- 1} \left[ \operatorname {C o v} \left(\boldsymbol {s} _ {t}, \boldsymbol {v} _ {j}\right) \right] ^ {\prime}.
$$

Using the covariance matrices in Eqs. (11.65) and (11.66), we further obtain

$$
\begin{array}{l} \boldsymbol {\Sigma} _ {t \mid T} = \boldsymbol {\Sigma} _ {t \mid t - 1} - \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t} \boldsymbol {\Sigma} _ {t \mid t - 1} - \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t + 1} ^ {- 1} \boldsymbol {Z} _ {t + 1} \boldsymbol {L} _ {t} \boldsymbol {\Sigma} _ {t \mid t - 1} \\ - \dots - \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {L} _ {t} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {Z} _ {T} \boldsymbol {L} _ {T - 1} \dots \boldsymbol {L} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \\ = \boldsymbol {\Sigma} _ {t | t - 1} - \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {M} _ {t - 1} \boldsymbol {\Sigma} _ {t | t - 1}, \\ \end{array}
$$

where

$$
\begin{array}{l} \boldsymbol {M} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t + 1} ^ {- 1} \boldsymbol {Z} _ {t + 1} \boldsymbol {L} _ {t} \\ + \dots + \boldsymbol {L} _ {t} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {Z} _ {T} \boldsymbol {L} _ {T - 1} \dots \boldsymbol {L} _ {t}. \\ \end{array}
$$

Again, $\pmb { L } _ { t } ^ { \prime } \cdot \cdot \cdot \pmb { L } _ { T - 1 } = \pmb { I } _ { m }$ when $t = T$ . From its definition, the $M _ { t - 1 }$ matrix satisfies

$$
\boldsymbol {M} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {L} _ {t}, \quad t = T, \dots , 1, \tag {11.70}
$$

with the starting value ${ { M } _ { T } } = \mathbf { 0 }$ . Collecting the results, we obtain a backward recursion to compute $\pmb { \Sigma } _ { t \mid T }$ as

$$
\boldsymbol {M} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t}, + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {L} _ {t}, \quad \boldsymbol {\Sigma} _ {t | T} = \boldsymbol {\Sigma} _ {t | t - 1} - \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {M} _ {t - 1} \boldsymbol {\Sigma} _ {t | t - 1}, \tag {11.71}
$$

for $t = T , \dots , 1$ with ${ M } _ { T } = \mathbf { 0 }$ . Note that, like that of the local trend model in Section 11.1, $\pmb { M } _ { t } = \mathrm { V a r } ( \pmb { q } _ { t } )$ .

Combining the two backward recursions of smoothed state vectors, we have

$$
\begin{array}{l} \boldsymbol {q} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \\ \boldsymbol {s} _ {t \mid T} = \boldsymbol {s} _ {t \mid t - 1} + \boldsymbol {\Sigma} _ {t \mid t - 1} \boldsymbol {q} _ {t - 1}, \tag {11.72} \\ \boldsymbol {M} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {L} _ {t}, \\ \boldsymbol {\Sigma} _ {t | T} = \boldsymbol {\Sigma} _ {t | t - 1} - \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {M} _ {t - 1} \boldsymbol {\Sigma} _ {t | t - 1}, \quad t = T, \dots , 1, \\ \end{array}
$$

with $\pmb q _ { T } = \pmb 0$ and ${ M } _ { T } = \mathbf { 0 }$ .

Suppose that the state-space model in Eqs. (11.24) and (11.25) is known. Application of the Kalman filter and state smoothing can proceed in two steps. First, the Kalman filter in Eq. (11.62) is used for $t = 1 , \dots , T$ and the quantities $\mathbf { } _ { v _ { t } , V _ { t } }$ , $\pmb { K } _ { t }$ , $\mathbf { \boldsymbol { s } } _ { t \left. t - 1 \right. }$ , and $\pmb { \Sigma } _ { t \mid t - 1 }$ are stored. Second, the state smoothing algorithm in Eq. (11.72) is applied for $t = T , T - 1 , \dots , 1$ $t = T$ to obtain $\mathbf { \boldsymbol { s } } _ { t \mid T }$ and $\pmb { \Sigma } _ { t \mid T }$ .

# 11.4.4 Disturbance Smoothing

Let ${ \pmb e } _ { t | T } = E ( { \pmb e } _ { t } | F _ { T } )$ and $\pmb { \eta } _ { t | T } = E ( \pmb { \eta } _ { t } | F _ { T } )$ be the smoothed disturbances of the observation and transition equation, respectively. These smoothed disturbances are useful in many applications, for example, in model checking. In this subsection, we study recursive algorithms to compute smoothed disturbances and their covariance matrices. Again, applying Theorem 11.1 to the conditional joint distribution of $e _ { t }$ and $\{ \pmb { v } _ { t } , \dotsc , \pmb { v } _ { T } \}$ given $F _ { t - 1 }$ , we obtain

$$
\boldsymbol {e} _ {t \mid T} = E \left(\boldsymbol {e} _ {t} \mid F _ {t - 1}, \boldsymbol {v} _ {t}, \dots , \boldsymbol {v} _ {T}\right) = \sum_ {j = t} ^ {T} E \left(\boldsymbol {e} _ {t} \boldsymbol {v} _ {j} ^ {\prime}\right) \boldsymbol {V} _ {j} ^ {- 1} \boldsymbol {v} _ {j}, \tag {11.73}
$$

where $E ( e _ { t } | F _ { t - 1 } ) = \mathbf { 0 }$ is used. Using Eq. (11.63),

$$
E \left(\boldsymbol {e} _ {t} \boldsymbol {v} _ {j} ^ {\prime}\right) = E \left(\boldsymbol {e} _ {t} \boldsymbol {x} _ {j} ^ {\prime}\right) \boldsymbol {Z} _ {j} ^ {\prime} + E \left(\boldsymbol {e} _ {t} \boldsymbol {e} _ {j} ^ {\prime}\right).
$$

Since $E ( e _ { t } \pmb { x } _ { t } ^ { \prime } ) = \pmb { 0 }$ , we have

$$
E \left(\boldsymbol {e} _ {t} \boldsymbol {v} _ {j} ^ {\prime}\right) = \left\{ \begin{array}{l l} \boldsymbol {H} _ {t}, & \text {i f} j = t, \\ E \left(\boldsymbol {e} _ {t} \boldsymbol {x} _ {j} ^ {\prime}\right) \boldsymbol {Z} _ {j} ^ {\prime}, & \text {f o r} j = t + 1, \dots , T. \end{array} \right. \tag {11.74}
$$

Using Eq. (11.63) repeatedly and the independence between $\{ e _ { t } \}$ and $\{ \eta _ { t } \}$ , we obtain

$$
E \left(\boldsymbol {e} _ {t} \boldsymbol {x} _ {t + 1} ^ {\prime}\right) = - \boldsymbol {H} _ {t} \boldsymbol {K} _ {t} ^ {\prime},
$$

$$
E \left(\boldsymbol {e} _ {t} \boldsymbol {x} _ {t + 2} ^ {\prime}\right) = - \boldsymbol {H} _ {t} \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime},
$$

$$
\dot {\vdots} = \dot {\vdots} \tag {11.75}
$$

$$
E \left(\boldsymbol {e} _ {t} \boldsymbol {x} _ {T} ^ {\prime}\right) = - \boldsymbol {H} _ {t} \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime},
$$

where it is understood that $\pmb { L } _ { t + 1 } ^ { \prime } \cdot \cdot \cdot \pmb { L } _ { T - 1 } ^ { \prime } = \pmb { I } _ { m }$ if $t = T - 1$ . Based on Eqs. (11.74) and (11.75),

$$
\begin{array}{l} \boldsymbol {e} _ {t \mid T} = \boldsymbol {H} _ {t} \left(\boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} - \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t + 1} ^ {- 1} \boldsymbol {v} _ {t + 1} - \dots - \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime} \boldsymbol {Z} _ {T} ^ {\prime} \boldsymbol {V} _ {T} ^ {- 1} \boldsymbol {v} _ {T}\right) \\ = \boldsymbol {H} _ {t} \left(\boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} - \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {q} _ {t}\right) \\ = \boldsymbol {H} _ {t} \boldsymbol {o} _ {t}, \quad t = T, \dots , 1, \tag {11.76} \\ \end{array}
$$

where $\pmb q _ { t }$ is defined in Eq. (11.67) and ${ \pmb { \sigma } } _ { t } = { \pmb { V } } _ { t } ^ { - 1 } { \pmb { v } } _ { t } - { \pmb { K } } _ { t } ^ { \prime } { \pmb { q } } _ { t }$ . We refer to $\mathbf { \delta } _ { \pmb { o } _ { t } }$ as the smoothing measurement error.

The smoothed disturbance $\pmb { \eta } _ { t \vert T }$ can be derived analogously and we have

$$
\boldsymbol {\eta} _ {t \mid T} = \sum_ {j = t} ^ {T} E \left(\boldsymbol {\eta} _ {t} \boldsymbol {v} _ {j} ^ {\prime}\right) \boldsymbol {V} _ {j} ^ {- 1} \boldsymbol {v} _ {j}. \tag {11.77}
$$

The state-space form in Eq. (11.67) gives

$$
E (\eta_ {t} \boldsymbol {v} _ {j} ^ {\prime}) = \left\{ \begin{array}{l l} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime}, & \text {i f} j = t + 1, \\ E (\eta_ {t} \boldsymbol {x} _ {j} ^ {\prime}) \boldsymbol {Z} _ {j} ^ {\prime}, & \text {i f} j = t + 2, \ldots , T, \end{array} \right.
$$

where

$$
E \left(\eta_ {t} x _ {t + 2} ^ {\prime}\right) = Q _ {t} R _ {t} ^ {\prime} L _ {t + 1} ^ {\prime},
$$

$$
E \left(\eta_ {t} x _ {t + 3} ^ {\prime}\right) = Q _ {t} R _ {t} ^ {\prime} L _ {t + 1} ^ {\prime} L _ {t + 2} ^ {\prime},
$$

$$
\vdots = \vdots
$$

$$
E \left(\boldsymbol {\eta} _ {t} \boldsymbol {x} _ {T} ^ {\prime}\right) = \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime} \boldsymbol {L} _ {t + 1} ^ {\prime} \dots \boldsymbol {L} _ {T - 1} ^ {\prime},
$$

for $t = 1 , \dots , T$ . Consequently, Eq. (11.77) implies

$$
\begin{array}{l} \eta_ {t \mid T} = Q _ {t} R _ {t} ^ {\prime} \left(Z _ {t + 1} ^ {\prime} V _ {t + 1} ^ {- 1} v _ {t + 1} + L _ {t + 1} ^ {\prime} Z _ {t + 2} ^ {\prime} V _ {t + 2} ^ {- 1} v _ {t + 2} \right. \\ + \dots + L _ {t + 1} ^ {\prime} \dots L _ {T - 1} ^ {\prime} Z _ {T} V _ {T} ^ {- 1} v _ {T}) \\ = \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \quad t = T, \dots , 1, \tag {11.78} \\ \end{array}
$$

where $\pmb q _ { t }$ is defined earlier in Eq. (11.68).

Koopman (1993) uses the smoothed disturbance $\pmb { \eta } _ { t \vert T }$ to derive a new recursion for computing $\pmb { S } _ { t \vert T }$ . From the transition equation in Eq. (11.24),

$$
\boldsymbol {s} _ {t + 1 | T} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t | T} + \boldsymbol {R} _ {t} \boldsymbol {\eta} _ {t | T}.
$$

Using Eq. (11.78), we have

$$
\boldsymbol {s} _ {t + 1 | T} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} \boldsymbol {s} _ {t | T} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \quad t = 1, \dots , T, \tag {11.79}
$$

where the initial value is ${ \pmb S } _ { 1 | T } = { \pmb S } _ { 1 | 0 } + { \pmb \Sigma } _ { 1 | 0 } { \pmb q } _ { 0 }$ with $\pmb q _ { 0 }$ obtained from the recursion in Eq. (11.68).

# Covariance Matrices of Smoothed Disturbances

The covariance matrix of the smoothed disturbance can also be obtained using Theorem 11.1. Specifically,

$$
\begin{array}{l} \operatorname {V a r} \left(\boldsymbol {e} _ {t} \mid F _ {T}\right) = \operatorname {V a r} \left(\boldsymbol {e} _ {t} \mid F _ {t - 1}, \boldsymbol {v} _ {t}, \dots , \boldsymbol {v} _ {T}\right) \\ = \operatorname {V a r} \left(\boldsymbol {e} _ {t} \mid F _ {t - 1}\right) - \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\boldsymbol {e} _ {t}, \boldsymbol {v} _ {j}\right) V _ {j} ^ {- 1} \left[ \operatorname {C o v} \left(\boldsymbol {e} _ {t}, \boldsymbol {v} _ {j}\right) \right] ^ {\prime}. \\ \end{array}
$$

Note that $\mathrm { C o v } ( e _ { t } , \pmb { v } _ { j } ) = E ( e _ { t } \pmb { v } _ { j } ^ { \prime } )$ , which is given in Eq. (11.74). Thus, we have

$$
\begin{array}{l} \operatorname {V a r} (\boldsymbol {e} _ {t} | F _ {T}) = \boldsymbol {H} _ {t} - \boldsymbol {H} _ {t} (\boldsymbol {V} _ {t} ^ {- 1} + \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {Z} _ {t + 1} ^ {\prime} \boldsymbol {V} _ {t + 1} ^ {- 1} \boldsymbol {Z} _ {t + 1} \boldsymbol {K} _ {t} \\ + K _ {t} ^ {\prime} L _ {t + 1} ^ {\prime} Z _ {t + 2} ^ {\prime} V _ {t + 2} ^ {- 1} Z _ {t + 2} L _ {t + 1} K _ {t} \\ + \dots + K _ {t} ^ {\prime} L _ {t + 1} ^ {\prime} \dots L _ {T - 1} ^ {\prime} Z _ {T} ^ {\prime} V _ {T} ^ {- 1} Z _ {T} L _ {T - 1} \dots L _ {t + 1} K _ {t}) H _ {t} \\ = \boldsymbol {H} _ {t} - \boldsymbol {H} _ {t} \left(\boldsymbol {V} _ {t} ^ {- 1} + \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {K} _ {t}\right) \boldsymbol {H} _ {t} \\ = \boldsymbol {H} _ {t} - \boldsymbol {H} _ {t} \boldsymbol {N} _ {t} \boldsymbol {H} _ {t}, \\ \end{array}
$$

where $N _ { t } = V _ { t } ^ { - 1 } + K _ { t } ^ { \prime } M _ { t } K _ { t }$ , where $M _ { t }$ is given in Eq. (11.70). Similarly,

$$
\operatorname {V a r} \left(\boldsymbol {\eta} _ {t} \mid F _ {T}\right) = \operatorname {V a r} \left(\boldsymbol {\eta} _ {t}\right) - \sum_ {j = t} ^ {T} \operatorname {C o v} \left(\boldsymbol {\eta} _ {t}, \boldsymbol {v} _ {t}\right) \boldsymbol {V} _ {t} ^ {- 1} \left[ \operatorname {C o v} \left(\boldsymbol {\eta} _ {t}, \boldsymbol {v} _ {t}\right) \right] ^ {- 1},
$$

where $\mathrm { C o v } ( \pmb { \eta } _ { t } , \pmb { v } _ { j } ) = E ( \pmb { \eta } _ { t } \pmb { v } _ { j } ^ { \prime } )$ , which is given before when we derived the formula for $\pmb { \eta } _ { t \vert T }$ . Consequently,

$$
\begin{array}{l} \operatorname {V a r} \left(\eta_ {t} \mid F _ {T}\right) = Q _ {t} - Q _ {t} R _ {t} ^ {\prime} \left(Z _ {t + 1} ^ {\prime} V _ {t + 1} ^ {- 1} Z _ {t + 1} + L _ {t + 1} ^ {\prime} Z _ {t + 2} ^ {\prime} V _ {t + 2} ^ {- 1} Z _ {t + 2} L _ {t + 1} \right. \\ + \dots + L _ {t + 1} ^ {\prime} \dots L _ {T - 1} ^ {\prime} Z _ {T} ^ {\prime} V _ {T} ^ {- 1} Z _ {T} L _ {T - 1} \dots L _ {t + 1}) R _ {t} Q _ {t} \\ = Q _ {t} - Q _ {t} R _ {t} ^ {\prime} M _ {t} R _ {t} Q _ {t}. \\ \end{array}
$$

In summary, the disturbance smoothing algorithm is as follows:

$$
\begin{array}{l} \boldsymbol {e} _ {t \mid T} = \boldsymbol {H} _ {t} \left(\boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} - \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {q} _ {t}\right), \\ \eta_ {t \mid T} = Q _ {t} R _ {t} ^ {\prime} q _ {t}, \\ \boldsymbol {q} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {v} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \tag {11.80} \\ \end{array}
$$

$$
\begin{array}{l} \operatorname {V a r} \left(\boldsymbol {e} _ {t} \mid F _ {T}\right) = \boldsymbol {H} _ {t} - \boldsymbol {H} _ {t} \left(\boldsymbol {V} _ {t} ^ {- 1} + \boldsymbol {K} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {K} _ {t}\right) \boldsymbol {H} _ {t}, \\ \operatorname {V a r} \left(\eta_ {t} \mid F _ {T}\right) = Q _ {t} - Q _ {t} R _ {t} ^ {\prime} M _ {t} R _ {t} Q _ {t}, \\ \boldsymbol {M} _ {t - 1} = \boldsymbol {Z} _ {t} ^ {\prime} \boldsymbol {V} _ {t} ^ {- 1} \boldsymbol {Z} _ {t} + \boldsymbol {L} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {L} _ {t}, \quad t = T, \dots , 1, \\ \end{array}
$$

where $\pmb q _ { T } = \pmb 0$ and ${ M } _ { T } = \mathbf { 0 }$ .

# 11.5 MISSING VALUES

For the general state-space model in Eqs. (11.24) and (11.25), we consider two cases of missing values. First, suppose that similar to the local trend model in Section 11.1 the observations $\boldsymbol { y } _ { t }$ at $t = \ell + 1 , \ldots , \ell + h$ are missing. In this case, there is no new information available at these time points and we set

$$
\boldsymbol {v} _ {t} = \mathbf {0}, \quad \boldsymbol {K} _ {t} = \mathbf {0}, \quad \text {f o r} \quad t = \ell + 1, \dots , \ell + h.
$$

The Kalman filter in Eq. (11.62) can then proceed as usual. That is,

$$
s _ {t + 1 | t} = \boldsymbol {d} _ {t} + \boldsymbol {T} _ {t} s _ {t | t - 1}, \quad \boldsymbol {\Sigma} _ {t + 1 | t} = \boldsymbol {T} _ {t} \boldsymbol {\Sigma} _ {t | t - 1} \boldsymbol {T} _ {t} ^ {\prime} + \boldsymbol {R} _ {t} \boldsymbol {Q} _ {t} \boldsymbol {R} _ {t} ^ {\prime},
$$

for $t = \ell + 1 , \ldots , \ell + h$ . Similarly, the smoothed state vectors can be computed as usual via Eq. (11.72) with

$$
\boldsymbol {q} _ {t - 1} = \boldsymbol {T} _ {t} ^ {\prime} \boldsymbol {q} _ {t}, \quad \boldsymbol {M} _ {t - 1} = \boldsymbol {T} _ {t} ^ {\prime} \boldsymbol {M} _ {t} \boldsymbol {T} _ {t},
$$

for $t = \ell + 1 , \ldots , \ell + h$ .

In the second case, some components of $\mathbf { } y _ { t }$ are missing. Let $\mathbf { y } _ { t } ^ { * } = J \mathbf { y } _ { t }$ be the vector of observed data at time $t$ , where $J$ is an indicator matrix identifying the observed data. More specifically, rows of $J$ are a subset of the rows of the $k \times k$ identity matrix. In this case, the observation equation (11.25) of the model can be transformed as

$$
\boldsymbol {y} _ {t} ^ {*} = \boldsymbol {c} _ {t} ^ {*} + \boldsymbol {Z} _ {t} ^ {*} \boldsymbol {s} _ {t} + \boldsymbol {e} _ {t} ^ {*},
$$

where $\pmb { c } _ { t } ^ { * } = \pmb { J } \pmb { c } _ { t }$ , ${ \bf Z } _ { t } ^ { * } = { \bf J } { \bf Z } _ { t }$ , and $e _ { t } ^ { * } = J e _ { t }$ with covariance matrix $\mathrm { V a r } ( e _ { t } ^ { * } ) = H _ { t } ^ { * } =$ $J H _ { t } J ^ { \prime }$ . The Kalman filter and state-smoothing recursion continue to apply except that the modified observation equation is used at time t. Consequently, the ease in handling missing values is a nice feature of the state-space model.

# 11.6 FORECASTING

Suppose that the forecast origin is $t$ and we are interested in predicting $y _ { t + j }$ for $j = 1 , \dots , h$ , where $h > 0$ . Also, we adopt the minimum mean squared error forecasts. Similar to the ARMA models, the $j$ -step ahead forecast ${ \bf y } _ { t } ( j )$ turns out to be the expected value of $y _ { t + j }$ given $F _ { t }$ and the model. That is, $\begin{array} { r } { \mathbf { y } _ { t } ( j ) = E ( \mathbf { y } _ { t + j } \vert F _ { t } ) } \end{array}$ . In what follows, we show that these forecasts and the covariance matrices of the associated forecast errors can be obtained via the Kalman filter in Eq. (11.62) by treating $\{ \boldsymbol { y } _ { t + 1 } , \ldots , \boldsymbol { y } _ { t + h } \}$ as missing values, that is, case one of Section 11.5.

Consider the 1-step ahead forecast. From Eq. (11.25),

$$
\mathbf {y} _ {t} (1) = E \left(\mathbf {y} _ {t + 1} \mid F _ {t}\right) = \mathbf {c} _ {t + 1} + \mathbf {Z} _ {t + 1} s _ {t + 1 \mid t},
$$

where $\pm 1 | t$ is available via the Kalman filter at the forecast origin t. The associated forecast error is

$$
\boldsymbol {e} _ {t} (1) = \boldsymbol {y} _ {t + 1} - \boldsymbol {y} _ {t} (1) = \boldsymbol {Z} _ {t + 1} \left(\boldsymbol {s} _ {t + 1} - \boldsymbol {s} _ {t + 1 | t}\right) + \boldsymbol {e} _ {t + 1}.
$$

Therefore, the covariance matrix of the 1-step ahead forecast error is

$$
\operatorname {V a r} \left[ e _ {t} (1) \right] = Z _ {t + 1} \Sigma_ {t + 1 | t} Z _ {t + 1} ^ {\prime} + H _ {t + 1}.
$$

This is precisely the covariance matrix $\boldsymbol { V } _ { t + 1 }$ of the Kalman filter in Eq. (11.62). Thus, we have showed the case for $h = 1$ .

Now, for $h > 1$ , we consider 1-step to $h$ -step ahead forecasts sequentially. From Eq. (11.25), the $j$ -step ahead forecast is

$$
\mathbf {y} _ {t} (j) = \mathbf {c} _ {t + j} + \mathbf {Z} _ {t + j} s _ {t + j | t}, \tag {11.81}
$$

and the associated forecast error is

$$
\boldsymbol {e} _ {t} (j) = \mathbf {Z} _ {t + j} \left(\boldsymbol {s} _ {t + j} - \boldsymbol {s} _ {t + j | t}\right) + \boldsymbol {e} _ {t + j}.
$$

Recall that $\mathbf { } s _ { t + j | t }$ and $\Sigma _ { t + j | t }$ are, respectively, the conditional mean and covariance matrix of $\mathbf { \boldsymbol { s } } _ { t + j }$ given $F _ { t }$ . The prior equation says that

$$
\operatorname {V a r} \left[ e _ {t} (j) \right] = \mathbf {Z} _ {t + j} \boldsymbol {\Sigma} _ {t + j \mid t} \mathbf {Z} _ {t + j} ^ {\prime} + \mathbf {H} _ {t + j}. \tag {11.82}
$$

Furthermore, from Eq. (11.24),

$$
\boldsymbol {s} _ {t + j + 1 | t} = \boldsymbol {d} _ {t + j} + \boldsymbol {T} _ {t + j} \boldsymbol {s} _ {t + j | t},
$$

which in turn implies that

$$
\boldsymbol {s} _ {t + j + 1} - \boldsymbol {s} _ {t + j + 1 | t} = \boldsymbol {T} _ {t + j} \left(\boldsymbol {s} _ {t + j} - \boldsymbol {s} _ {t + j | t}\right) + \boldsymbol {R} _ {t + j} \boldsymbol {\eta} _ {t + j}.
$$

Consequently,

$$
\boldsymbol {\Sigma} _ {t + j + 1 \mid t} = \boldsymbol {T} _ {t + j} \boldsymbol {\Sigma} _ {t + j \mid t} \boldsymbol {T} _ {t + j} ^ {\prime} + \boldsymbol {R} _ {t + j} \boldsymbol {Q} _ {t + j} \boldsymbol {R} _ {t + j} ^ {\prime}. \tag {11.83}
$$

Note that $\mathrm { V a r } [ e _ { t } ( j ) ] = V _ { t + j }$ and Eqs. (11.81)–(11.83) are the recursion of the Kalman filter in Eq. (11.62) for $t + j$ with $j = 1 , \dots , h$ when $\pmb { v } _ { t + j } = \mathbf { 0 }$ and $\pmb { K } _ { t + j } = \mathbf { 0 }$ . Thus, the forecast ${ \bf y } _ { t } ( j )$ and the covariance matrix of its forecast error ${ e _ { t } } ( j )$ can be obtained via the Kalman filter with missing values.

Finally, the prediction error series $\{ \pmb { v } _ { t } \}$ can be used to evaluate the likelihood function for estimation and the standardized prediction errors ${ \pmb { D } } _ { t } ^ { - 1 / 2 } { \pmb v } _ { t }$ can be used for model checking, where $D _ { t } = \mathrm { d i a g } \{ V _ { t } ( 1 , 1 ) , \ldots , V _ { t } ( k , k ) \}$ with $V _ { t } ( i , i )$ being the $( i , i )$ th element of $\mathbf { } _ { \mathbf { } } { V } _ { t }$ .

# 11.7 APPLICATION

In this section, we consider some applications of the state-space model in finance and business. Our objectives are to highlight the applicability of the model and to demonstrate the practical implementation of the analysis in S-Plus with SsfPack.

Example 11.2. Consider the CAPM for the monthly simple excess returns of General Motors (GM) stock from January 1990 to December 2003; see Chapter 9. We use the simple excess returns of the S&P 500 composite index as the market returns. Our illustration starts with a simple market model

$$
r _ {t} = \alpha + \beta r _ {M, t} + e _ {t}, \quad e _ {t} \sim N \left(0, \sigma_ {e} ^ {2}\right) \tag {11.84}
$$

for $t = 1 , \ldots , 1 6 8$ . This is a fixed-coefficient model and can easily be estimated by the ordinary least squares (OLS) method. Denote the GM stock return and the market return by gm and sp, respectively. The result is given below.

>fit $\equiv$ OLS(gm\~sp)   
>summary(fit)   
Call:   
OLS(formula $=$ gm\~ sp)   
Coefficients: Value Std.Error t value Pr(>|t|) (Intercept) 0.0020 0.0063 0.3151 0.7531 sp 1.0457 0.1453 7.1964 0.0000   
Regression Diagnostics: R-Squared 0.238   
Adjusted R-Squared 0.233   
Durbin-Watson Stat 2.029   
Residual Diagnostics: Stat P-Value

```txt
Jarque-Bera 2.537 0.281  
Ljung-Box 24.207 0.337 
```

Residual standard error: 0.0813

Thus, the fitted model is

$$
r _ {t} = 0. 0 2 + 1. 0 4 5 7 r _ {M, t} + e _ {t}, \quad \hat {\sigma} _ {e} = 0. 0 8 1 3.
$$

Based on the residual diagnostics, the model appears to be adequate for the GM stock returns with adjusted $R ^ { 2 } = 2 3 . 3 \%$ .

As shown in Section 11.3, model (11.84) is a special case of the state-space model. We then estimate the model using SsfPack. The result is as follows:

```csv
> reg.m=function(param,mX=NULL) {
+ param=exp(param) % log(sigma.e) used to ensure positiveness.
+ssf.reg=GetssfReg(mX)
+ssf.reg$mOmega[3,3]=param[1]
+ CheckSSF(ssf.reg)
}
> c.start=c(0.1)
> reg.fit=SssfFit(c.start,gm,"reg.m",mX=X.mtx)
RELATIVE FUNCTION CONVERGENCE
> sqrt(exp(reg.fit$parameters))
[1] 0.08129934
>
% Next, perform smoothing
>ssf.reg$mOmega[3,3]=exp(reg.fit$parameters)
> reg.s=SssfMomentEst(gm,ssf.reg,task="STSMO")
> reg.s,statemoment[10, % use 10th row to avoid impact
state.1 state.2 % of the starting value.
[10,] 0.001985928 1.045712
% Next, obtain standard errors of estimates
> sqrt(reg.s/state.variance[10,])
state.1 state.2
0.006301927 0.1453096 
```

As expected, the result is in total agreement with that of the OLS method.

Finally, we entertain the time-varying CAPM of Section 11.3.1. The estimation result, including time plot of the smoothed response variable, is given below. The command SsfCondDens is used to compute the smoothed estimates of the state vector and observation without variance estimation.

```txt
> tv.capm = function(param, mX=NULL) { % Setup the model
+ param=exp(param) %parameterize in log for positiveness.
+ Phi.t = rbind(diag(2), rep(0, 2))
+ Omega=diag(param) 
```

```txt
+ JPhi=matrix(-1,3,2)
+ JPhi[3,1]=1
+ JPhi[3,2]=2
+ Sigma=-Phi.t
+ssf.tv=list(mPhi=Phi.t,
+mOmega=Omega,
+mJPhi=JPhi,
+mSigma=Sigma,
+mX=mX)
+ CheckSsf(ssf(tv)
}
> tv.start=c(0,0,0) %starting values
> tv.mle=SsfFit(tv.start,gm,"tv.capm",mX=X.mtx) %estimation
> sigma.mle=sqrt(exp(tv.mle\$parameters))
> sigma.mle
1.168806e-05 0.0007428207 0.08129916
% Smoothing
> smoEst.tv=SsfCondDens(gm, tv.capm(tv.mle\$parameters,
+mX=X.mtx),task="STSMO")
> names(smoEst(tv)
[1] "state" "response" "task"
> par(mfcol=c(2,2)) %plotting
> plot(gm,type='l',ylab='excess return')
> title(main=' (a) Monthly simple excess returns')
> plot(smoEst.tv\$response,type='l',ylab='rtn')
> title(main=' (b) Expected returns')
> plot(smoEst.tv\$state[,1],type='l',ylab='value')
> title(main=' (c) Alpha(t)')
> plot(smoEst.tv\$state[,2],type='l',ylab='value')
> title(main=' (d) Beta(t)') 
```

Note that estimates of $\sigma _ { \eta }$ and $\sigma _ { \varepsilon }$ are $1 . 1 7 \times 1 0 ^ { - 5 }$ and $0 . 7 4 \times 1 0 ^ { - 3 }$ , respectively. These estimates are close to zero, indicating that $\alpha _ { t }$ and $\beta _ { t }$ of the time-varying market model are essentially constant for the GM stock returns. This is in agreement with the fact that the fixed-coefficient market model fits the data well. Figure 11.5 shows some plots for the time-varying CAPM fit. Part (a) is the monthly simple excess returns of GM stock from January 1990 to December 2003. Part (b) is the expected returns of GM stock, that is, $r _ { t \mid T }$ , where $T = 1 6 8$ is the sample size. Parts (c) and (d) are the time plots of the estimates of $\alpha _ { t }$ and $\beta _ { t }$ . Given the tightness in the vertical scale, these two time plots confirm the assertion that a fixed-coefficient market model is adequate for the monthly GM stock return.

Example 11.3. In this example we reanalyze the series of quarterly earnings per share of Johnson and Johnson from 1960 to 1980 using the unobserved component model; see Chapter 2 for details of the data. The model considered is

$$
y _ {t} = \mu_ {t} + \gamma_ {t} + e _ {t}, \quad e _ {t} \sim N \left(0, \sigma_ {e} ^ {2}\right), \tag {11.85}
$$

![](images/7c536b8091d1f50b9a6f251810c9423012d023dd0fd8800759d3db3a380c8b75.jpg)

![](images/b5759abd5b1d2c0bc86985b2e7116277c5140652c160df5391f34fe52c0b3a1a.jpg)

![](images/42ac034a9349724bd411d62c5e173c49e3dcfef35fa68d0e020cd67f470d8c65.jpg)

![](images/225e1a73f73793c81c4581a4b48bfb73afc33cbb251d133f266a666389bad1f9.jpg)  
Figure 11.5. Time plots of some statistics for a time-varying CAPM applied to the monthly simple excess returns of General Motors stock. The S&P 500 composite index return is used as the market return: (a) monthly simple excess return, (b) expected returns $r _ { t \mid T }$ , (c) $\alpha _ { t }$ estimate, and (d) $\beta _ { t }$ estimate.

where $y _ { t }$ is the logarithm of the observed earnings per share, $\mu _ { t }$ is the local trend component satisfying

$$
\mu_ {t + 1} = \mu_ {t} + \eta_ {t}, \quad \eta_ {t} \sim N (0, \sigma_ {\eta} ^ {2}),
$$

and $\gamma _ { t }$ is the seasonal component that satisfies

$$
(1 + B + B ^ {2} + B ^ {3}) \gamma_ {t} = \omega_ {t}, \quad \omega_ {t} \sim N (0, \sigma_ {\omega} ^ {2}),
$$

that is, and is a $\begin{array} { r } { \gamma _ { t } = - \sum _ { j = 1 } ^ { 3 } \gamma _ { t - j } + \omega _ { t } } \end{array}$ . This model has three parameters ponent model. It can be put in a stat $\sigma _ { e }$ $\sigma _ { \eta }$ , and e form $\sigma _ { \omega }$

$$
\left[ \begin{array}{c} \mu_ {t + 1} \\ \gamma_ {t + 1} \\ \gamma_ {t} \\ \gamma_ {t - 1} \end{array} \right] = \left[ \begin{array}{c c c c} 1 & 0 & 0 & 0 \\ 0 & - 1 & - 1 & - 1 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \end{array} \right] \left[ \begin{array}{c} \mu_ {t} \\ \gamma_ {t} \\ \gamma_ {t - 1} \\ \gamma_ {t - 2} \end{array} \right] + \left[ \begin{array}{c c} 1 & 0 \\ 0 & 1 \\ 0 & 0 \\ 0 & 0 \end{array} \right] \left[ \begin{array}{c} \eta_ {t} \\ \omega_ {t} \end{array} \right],
$$

where the covariance matrix of $( \eta _ { t } , \omega _ { t } ) ^ { \prime }$ is $\mathrm { d i a g } \{ \sigma _ { \eta } ^ { 2 } , \sigma _ { \omega } ^ { 2 } \}$ , and $y _ { t } = [ 1 , 1 , 0 , 0 ] s _ { t } + e _ { t }$ ; see Section 11.3. This is a special case of the structural time series in SsfPack and can easily be specified using the command GetSsfStsm. Performing the maximum likelihood estimation, we obtain $( \hat { \sigma } _ { e } , \hat { \sigma } _ { \eta } , \hat { \sigma } _ { \omega } ) = ( 0 . 0 0 1 4 3 , 0 . 2 6 9 6 , 0 . 1 7 1 2 )$ .

```txt
> jnj = scan(file='q-jnj.txt')
> y = log(jnj)
% Estimation
> jnj.m = function(param) {
+ param = exp(param)
+ jnj.sea = GetSsfStsm(arregular = param[1], level = param[2],
+ seasonalDummy = c(param[3], 4))
+ CheckSsf(jnj.sea)
}
>
> c.start = c(0,0,0) % Starting values
> jnj.est = SsfFit(c.start, y, "jnj.m")
> names (jnj.est)
[1] "parameters" "objective" "message" "grad(norm"
[5] "iterations" "f.eval" "g.eval" "hessian"
[9] "scale" "aux" "call"
> jnjest = sqrt(exp(jnj.est\$parameters))
> jnjest
[1] 0.001429867 0.269622976 0.171221806 % Estimates
% Next, specify the model with estimates
> jnj.ssf = GetSsfStsm(arregular = jnjest[1], level = jnjest[2],
+ seasonalDummy = c(jnjest[3], 4))
> CheckSsf(jnj.ssf)
$mPhi:
[.,1] [,2] [,3] [,4]
[1,] 1 0 0 0
[2,] 0 -1 -1 -1
[3,] 0 1 0 0
[4,] 0 0 1 0
[5,] 1 1 0 0
$mOmega:
[.,1] [,2] [,3] [,4] [,5]
[1,] 0.07270 0.00000 0 0 0
[2,] 0.00000 0.02932 0 0 0
[3,] 0.00000 0.00000 0 0 0
[4,] 0.00000 0.00000 0 0 0
[5,] 0.00000 0.00000 0 0 2.044e-06
$mSigma:
[.,1] [,2] [,3] [,4]
[1,] -1 0 0 0
[2,] 0 -1 0 0
[3,] 0 0 -1 0
[4,] 0 0 0 -1
[5,] 0 0 0 0
$mDelta:
[.,1]
[1,] 0
[2,] 0
[3,] 0 
```

```matlab
[4,] 0
[5,] 0
$mjPhi:
[1] 0
$mjOmega:
[1] 0
$mjDelta:
[1] 0
$mx:
[1] 0
$cT:
[1] 0
$cX:
[1] 0
$cY:
[1] 1
$cSt:
[1] 4
attr(,"class"): [1]"ssf" %below: smoothed components
> jnj.smo=SsfMomentEst(y,jnjssf,task="STSMO")
> up1=jnj.smo$statemoment[,1]+
+ 2*sqrt(jnj.smo$state.variance[,1])
> lw1=jnj.smo$statemoment[,1]-
+ 2*sqrt(jnj.smo$state.variance[,1])
> max(up1)%obtain range for plotting
[1] 3.067664
> min(lw1)
[1] -1.063997
> up=jnj.smo$statemoment[,2]+
+ 2*sqrt(jnj.smo$state.variance[,2])
> lw=jnj.smo$statemoment[,2]-
+ 2*sqrt(jnj.smo$state.variance[,2])
> max(up)
[1] 0.5909587
> min(lw)
[1] -0.6157968
> par(mfcol=c(2,1)) %plotting
> plot(tdx,jnj.smo$statemoment[,1],type='l',xlab='year',
+ylab='value',ylim=c(-1.1,3.1))
> lines(tdx,up1,lty=2)
> lines(tdx,lw1,lty=2)
> title(main=' (a) Trend component')
> plot(tdx,jnj.smo$statemoment[,2],type='l',xlab='year',
+ylab='value',ylim=c(-.62,0.6))
> lines(tdx,up,lty=2)
> lines(tdx,lw,lty=2)
> title(main=' (b) Seasonal component')
% Filtering and smoothing 
```

```txt
> jnj.fil=KalmanFil(y, jnj.ssf, task="STFIL")
> jnj.sm0=KalmanSm0(jnj.fil, jnj.ssf)
> plot(tdx, jnj.fil$mOut[,1], type='l', xlab='year',
+ ylab='resi')
> title(main=' (a) 1-Step forecast error')
> plot(tdx, jnj.sm0$response.residuals[2:85], type='l',
+ xlab='year', ylab='resi')
> title(main=' (b) Smoothing residual') 
```

Figure 11.6 shows the smoothed estimates of the trend and seasonal components, that is, $\mu _ { t | T }$ and $\gamma _ { t \mid T }$ with $T = 8 4$ , of the data. Of particular interest is that the seasonal pattern seems to evolve over time. Also shown are $9 5 \%$ pointwise confidence regions of the unobserved components. Figure 11.7 shows the residual plots, where part (a) gives the 1-step ahead forecast errors computed by Kalman filter and part (b) is the smoothed response residuals of the fitted model. Thus, state-space modeling provides an alternative approach for analyzing seasonal time series. It should be noted that the estimated components in Figure 11.6 are not unique. They depend on the model specified and constraints used. In fact, there are infinitely many ways to decompose an observed time series into unobserved components. For instance, one can use a different specification for the seasonal component,

![](images/e05c959a58b4a5345082d94bbf099ef46df22b9eb469e33552e148b74d68a525.jpg)

![](images/08b5dd2619f847fb9d3b311cc0ff9c9ab544fd1a42ef1a81da6238f4ec64b20c.jpg)  
Figure 11.6. Smoothed components of fitting model (11.85) to the logarithm of quarterly earnings per share of Johnson and Johnson Company from 1960 to 1980: (a) trend component and (b) seasonal component. Dotted lines indicate pointwise $9 5 \%$ confidence regions.

![](images/4a01bf843ffddebf32a52e481db1346b290fbde2a2f844eadd442b4d37a8be8f.jpg)

![](images/d35f4682c29699df3edf3c8d480dbb3cdd523dc16f4d15c346fd24bff9c5eba8.jpg)  
Figure 11.7. Residual series of fitting model (11.85) to the logarithm of quarterly earnings per share of Johnson and Johnson Company from 1960 to 1980: (a) 1-step ahead forecast error $v _ { t }$ and (b) smoothed residuals of response variable.

for example, seasonalTrig in SsfPack, to obtain another decomposition for the earnings series of Johnson and Johnson. Thus, care must be exercised in interpreting the estimated components. However, for forecasting purposes, the choice of decomposition does not matter provided that the chosen one is a valid decomposition.

# EXERCISES

11.1. Consider the ARMA(1,1) model $y _ { t } - 0 . 8 y _ { t - 1 } = a _ { t } + 0 . 4 a _ { t - 1 }$ with $a _ { t } \sim$ $N ( 0 , 0 . 4 9 )$ . Convert the model into a state-space form using (a) Akaike’s method, (b) Harvey’s approach, and (c) Aoki’s approach.

11.2. The file aa-rv-20m.txt contains the realized daily volatility series of Alcoa stock returns from January 2, 2003 to May 7, 2004; see the example in Section 11.1. The volatility series is constructed using 20-minute intradaily log returns.

(a) Fit an ARIMA(0,1,1) model to the log volatility series and write down the model.   
(b) Estimate the local trend model in Eqs. (11.1) and (11.2) for the log volatility series. What are the estimates of $\sigma _ { e }$ and $\sigma _ { \eta } ?$ Obtain time plots

for the filtered and smoothed state variables with pointwise $9 5 \%$ confidence interval.

11.3. Consider the monthly simple excess returns of Pfizer stock and the S&P 500 composite index from January 1990 to December 2003. The excess returns are in m-pfesp-ex9003.txt with Pfizer stock returns in the first column.

(a) Fit a fixed-coefficient market model to the Pfizer stock return. Write down the fitted model.   
(b) Fit a time-varying CAPM to the Pfizer stock return. What are the estimated standard errors of the innovations to the $\alpha _ { t }$ and $\beta _ { t }$ series? Obtain time plots of the smoothed estimates of $\alpha _ { t }$ and $\beta _ { t }$ .

11.4. Consider the AR(3) model

$$
x _ {t} = \phi_ {1} x _ {t - 1} + \phi_ {2} x _ {t - 2} + \phi_ {3} x _ {t - 3} + a _ {t}, \quad a _ {t} \sim N (0, \sigma_ {a} ^ {2}),
$$

and suppose that the observed data are

$$
y _ {t} = x _ {t} + e _ {t}, \quad e _ {t} \sim N (0, \sigma_ {e} ^ {2}),
$$

where $\{ e _ { t } \}$ and $\{ a _ { t } \}$ are independent and the initial values of $x _ { j }$ with $j \le 0$ are independent of $e _ { t }$ and $a _ { t }$ for $t > 0$ .

(a) Convert the model into a state-space form.   
(b) If $E ( e _ { t } ) = c$ , which is not zero, what is the corresponding state-space form for the system?

11.5. The file m-ppiaco.txt contains year, month, day, and U.S. Producer Price Index (PPI) from January 1947 to August 2004. The index is for all commodities and not seasonally adjusted. Let $z _ { t } = \ln ( Z _ { t } ) - \ln ( Z _ { t - 1 } )$ , where $Z _ { t }$ is the observed monthly PPI. It turns out that an AR(3) model is adequate for $y _ { t }$ if the minor seasonal dependence is ignored. Let $y _ { t }$ be the sample-mean corrected series of $z _ { t }$ .

(a) Fit an AR(3) model to $y _ { t }$ and write down the fitted model.   
(b) Suppose that $y _ { t }$ has independent measurement errors so that $y _ { t } = x _ { t } + e _ { t }$ where $x _ { t }$ is an AR(3) process and $\mathrm { V a r } ( e _ { t } ) = \sigma _ { e } ^ { 2 }$ . Use a state-space form to estimate parameters, including the innovational variances to the state and $\sigma _ { e } ^ { 2 }$ . Write down the fitted model and obtain a time plot of the smoothed estimate of $x _ { t }$ . Also, show the time plot of filtered response residuals of the fitted state-space model.

# REFERENCES

Akaike, H. (1975). Markovian representation of stochastic processes by canonical variables.

SIAM Journal on Control 13: 162–173.

Aoki, M. (1987). State Space Modeling of Time Series. Springer-Verlag, New York.   
Anderson, B. D. O. and Moore, J. B. (1979). Optimal Filtering. Prentice Hall, Englewood Cliffs, NJ.   
Chan, N. H. (2002). Time Series: Applications to Finance. Wiley, Hoboken, NJ.   
de Jong, P. (1989). Smoothing and interpolation with the state space model. Journal of the American Statistical Association 84: 1085–1088.   
Durbin, J. and Koopman, S. J. (2001). Time Series Analysis by State Space Methods. Oxford University Press, Oxford, UK.   
Hamilton, J. (1994). Time Series Analysis. Princeton University Press, Princeton, NJ.   
Harvey, A. C. (1993). Time Series Models, 2nd edition. Harvester Wheatsheaf, Hemel Hempstead, UK.   
Kalman, R. E. (1960). A new approach to linear filtering and prediction problems. Journal of Basic Engineering, Transactions ASMA Series D 82: 35–45.   
Kim, C. J. and Nelson, C. R. (1999). State Space Models with Regime Switching. Academic Press, New York.   
Kitagawa, G. and Gersch, W. (1996). Smoothness Priors Analysis of Time Series. Springer-Verlag, New York.   
Koopman, S. J. (1993). Disturbance smoother for state space models. Biometrika 80: 117–126.   
Koopman, S. J., Shephard, N. and Doornik, J. A. (1999). Statistical algorithms for models in state-space form using SsfPack 2.2. Econometrics Journal 2: 113–166. Also, http://www.ssfpack.com/.   
Shumway, R. H. and Stoffer, D. S. (2000). Time Series Analysis and Its Applications. Springer-Verlag, New York.   
West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models, 2nd edition. Springer-Verlag, New York.

# Markov Chain Monte Carlo Methods with Applications

Advances in computing facilities and computational methods have dramatically increased our ability to solve complicated problems. The advances also extend the applicability of many existing econometric and statistical methods. Examples of such achievements in statistics include the Markov chain Monte Carlo (MCMC) method and data augmentation. These techniques enable us to make some statistical inference that was not feasible just a few years ago. In this chapter, we introduce the ideas of MCMC methods and data augmentation that are widely applicable in finance. In particular, we discuss Bayesian inference via Gibbs sampling and demonstrate various applications of MCMC methods. Rapid developments in the MCMC methodology make it impossible to cover all the new methods available in the literature. Interested readers are referred to some recent books on Bayesian and empirical Bayesian statistics (e.g., Carlin and Louis, 2000; Gelman, Carlin, Stern, and Rubin, 2003).

For applications, we focus on issues related to financial econometrics. The demonstrations shown in this chapter represent only a small fraction of all possible applications of the techniques in finance. As a matter of fact, it is fair to say that Bayesian inference and the MCMC methods discussed here are applicable to most, if not all, of the studies in financial econometrics.

We begin the chapter by reviewing the concept of a Markov process. Consider a stochastic process $\{ X _ { t } \}$ , where each $X _ { t }$ assumes a value in the space $\mathbf { \Theta } _ { \Theta }$ . The process $\{ X _ { t } \}$ is a Markov process if it has the property that, given the value of $X _ { t }$ , the values of $X _ { h }$ , $h > t$ , do not depend on the values $X _ { s }$ , $s < t$ . In other words, $\{ X _ { t } \}$ is a Markov process if its conditional distribution function satisfies

$$
P \left(X _ {h} \mid X _ {s}, s \leq t\right) = P \left(X _ {h} \mid X _ {t}\right), \quad h > t.
$$

If $\{ X _ { t } \}$ is a discrete-time stochastic process, then the prior property becomes

$$
P \left(X _ {h} \mid X _ {t}, X _ {t - 1}, \dots\right) = P \left(X _ {h} \mid X _ {t}\right), \quad h > t.
$$

Let $\pmb { A }$ be a subset of $\mathbf { \Theta } _ { \Theta }$ . The function

$$
P _ {t} (\boldsymbol {\theta}, h, \boldsymbol {A}) = P (X _ {h} \in \boldsymbol {A} | X _ {t} = \boldsymbol {\theta}), \quad h > t
$$

is called the transition probability function of the Markov process. If the transition probability depends on $h - t$ , but not on $t$ , then the process has a stationary transition distribution.

# 12.1 MARKOV CHAIN SIMULATION

Consider an inference problem with parameter vector $\pmb \theta$ and data $X$ , where $\pmb { \theta } \in \mathbf { \Theta } \Theta$ . To make inference, we need to know the distribution $P ( \pmb \theta | X )$ . The idea of Markov chain simulation is to simulate a Markov process on $\mathbf { \Theta } _ { \Theta }$ , which converges to a stationary transition distribution that is $P ( \pmb \theta | X )$ .

The key to Markov chain simulation is to create a Markov process whose stationary transition distribution is a specified $P ( \pmb \theta | X )$ and run the simulation sufficiently long so that the distribution of the current values of the process is close enough to the stationary transition distribution. It turns out that, for a given $P ( \pmb \theta | X )$ , many Markov chains with the desired property can be constructed. We refer to methods that use Markov chain simulation to obtain the distribution $P ( \pmb \theta | X )$ as Markov chain Monte Carlo (MCMC) methods.

The development of MCMC methods took place in various forms in the statistical literature. Consider the problem of “missing value” in data analysis. Most statistical methods discussed in this book were developed under the assumption of “complete data” (i.e., there is no missing value). For example, in modeling daily volatility of an asset return, we assume that the return data are available for all trading days in the sample period. What should we do if there is a missing value?

Dempster, Laird, and Rubin (1977) suggest an iterative method called the EM algorithm to solve the problem. The method consists of two steps. First, if the missing value were available, then we could use methods of complete-data analysis to build a volatility model. Second, given the available data and the fitted model, we can derive the statistical distribution of the missing value. A simple way to fill in the missing value is to use the conditional expectation of the derived distribution of the missing value. In practice, one can start the method with an arbitrary value for the missing value and iterate the procedure for many times until convergence. The first step of the prior procedure involves performing the maximum likelihood estimation of a specified model and is called the M-step. The second step is to compute the conditional expectation of the missing value and is called the E-step.

Tanner and Wong (1987) generalize the EM algorithm in two ways. First, they introduce the idea of iterative simulation. For instance, instead of using the conditional expectation, one can simply replace the missing value by a random draw from its derived conditional distribution. Second, they extend the applicability of EM algorithm by using the concept of data augmentation. By data augmentation, we mean adding auxiliary variables to the problem under study. It turns out that many of the simulation methods can often be simplified or speeded up by data augmentation; see the application sections of this chapter.

# 12.2 GIBBS SAMPLING

Gibbs sampling (or Gibbs sampler) of Geman and Geman (1984) and Gelfand and Smith (1990) is perhaps the most popular MCMC method. We introduce the idea of Gibbs sampling by using a simple problem with three parameters. Here the word parameter is used in a very general sense. A missing data point can be regarded as a parameter under the MCMC framework. Similarly, an unobservable variable such as the “true” price of an asset can be regarded as $N$ parameters when there are $N$ transaction prices available. This concept of parameter is related to data augmentation and becomes apparent when we discuss applications of the MCMC methods.

Denote the three parameters by $\theta _ { 1 } , \theta _ { 2 }$ , and $\theta _ { 3 }$ . Let $X$ be the collection of available data and $M$ the entertained model. The goal here is to estimate the parameters so that the fitted model can be used to make inference. Suppose that the likelihood function of the model is hard to obtain, but the three conditional distributions of a single parameter given the others are available. In other words, we assume that the following three conditional distributions are known:

$$
f _ {1} \left(\theta_ {1} \mid \theta_ {2}, \theta_ {3}, X, M\right), \quad f _ {2} \left(\theta_ {2} \mid \theta_ {3}, \theta_ {1}, X, M\right), \quad f _ {3} \left(\theta_ {3} \mid \theta_ {1}, \theta_ {2}, X, M\right), \tag {12.1}
$$

where $f _ { i } ( \theta _ { i } | \theta _ { j \neq i } , X , M )$ denotes the conditional distribution of the parameter $\theta _ { i }$ given the data, the model, and the other two parameters. In application, we do not need to know the exact forms of the conditional distributions. What is needed is the ability to draw a random number from each of the three conditional distributions.

Let $\theta _ { 2 , 0 }$ and $\theta _ { 3 , 0 }$ be two arbitrary starting values of $\theta _ { 2 }$ and $\theta _ { 3 }$ . The Gibbs sampler proceeds as follows:

1. Draw a random sample from $f _ { 1 } ( \theta _ { 1 } | \theta _ { 2 , 0 } , \theta _ { 3 , 0 } , X , M )$ . Denote the random draw by $\theta _ { 1 , 1 }$ .   
2. Draw a random sample from $f _ { 2 } ( \theta _ { 2 } | \theta _ { 3 , 0 } , \theta _ { 1 , 1 } , X , M )$ . Denote the random draw by $\theta _ { 2 , 1 }$ .   
3. Draw a random sample from $f _ { 3 } ( \theta _ { 3 } | \theta _ { 1 , 1 } , \theta _ { 2 , 1 } , X , M ) .$ . Denote the random draw by $\theta _ { 3 , 1 }$ .

This completes a Gibbs iteration and the parameters become $\theta _ { 1 , 1 } , \theta _ { 2 , 1 }$ , and $\theta _ { 3 , 1 }$ .

Next, using the new parameters as starting values and repeating the prior iteration of random draws, we complete another Gibbs iteration to obtain the updated parameters $\theta _ { 1 , 2 }$ , $\theta _ { 2 , 2 }$ , and $\theta _ { 3 , 2 }$ . We can repeat the previous iterations for $m$ times to obtain a sequence of random draws:

$$
(\theta_ {1, 1}, \theta_ {2, 1}, \theta_ {3, 1}), \dots , (\theta_ {1, m}, \theta_ {2, m}, \theta_ {3, m}).
$$

Under some regularity conditions, it can be shown that, for a sufficiently large m, $( \theta _ { 1 , m } , \theta _ { 2 , m } , \theta _ { 3 , m } )$ is approximately equivalent to a random draw from the joint distribution $f ( \theta _ { 1 } , \theta _ { 2 } , \theta _ { 3 } | X , M )$ of the three parameters. The regularity conditions

are weak; they essentially require that for an arbitrary starting value $( \theta _ { 1 , 0 } , \theta _ { 2 , 0 } , \theta _ { 3 , 0 } )$ , the prior Gibbs iterations have a chance to visit the full parameter space. The actual convergence theorem involves using the Markov chain theory; see Tierney (1994).

In practice, we use a sufficiently large $n$ and discard the first $m$ random draws of the Gibbs iterations to form a Gibbs sample, say,

$$
\left(\theta_ {1, m + 1}, \theta_ {2, m + 1}, \theta_ {3, m + 1}\right), \dots , \left(\theta_ {1, n}, \theta_ {2, n}, \theta_ {3, n}\right). \tag {12.2}
$$

Since the previous realizations form a random sample from the joint distribution $f ( \theta _ { 1 } , \theta _ { 2 } , \theta _ { 3 } | X , M )$ , they can be used to make inference. For example, a point estimate of $\theta _ { i }$ and its variance are

$$
\widehat {\theta} _ {i} = \frac {1}{n - m} \sum_ {j = m + 1} ^ {n} \theta_ {i, j}, \quad \widehat {\sigma} _ {i} ^ {2} = \frac {1}{n - m - 1} \sum_ {j = m + 1} ^ {n} \left(\theta_ {i, j} - \widehat {\theta} _ {i}\right) ^ {2}. \tag {12.3}
$$

The Gibbs sample in Eq. (12.2) can be used in many ways. For example, if we are interested in testing the null hypothesis $H _ { o } : \theta _ { 1 } = \theta _ { 2 }$ versus the alternative hypothesis $H _ { a } : \theta _ { 1 } \neq \theta _ { 2 }$ , then we can simply obtain the point estimate of $\theta =$ $\theta _ { 1 } - \theta _ { 2 }$ and its variance as

$$
\widehat {\theta} = \frac {1}{n - m} \sum_ {j = m + 1} ^ {n} \left(\theta_ {1, j} - \theta_ {2, j}\right), \quad \widehat {\sigma} ^ {2} = \frac {1}{n - m - 1} \sum_ {j = m + 1} ^ {n} \left(\theta_ {1, j} - \theta_ {2, j} - \widehat {\theta}\right) ^ {2}.
$$

The null hypothesis can then be tested by using the conventional $t$ -ratio statistic $t = { \widehat { \theta } } / { \widehat { \sigma } }$ .

Remark. The first $m$ random draws of a Gibbs sampling, which are discarded, are commonly referred to as the burn-in sample. The burn-ins are used to ensure that the Gibbs sample in Eq. (12.2) is indeed close enough to a random sample from the joint distribution $f ( \theta _ { 1 } , \theta _ { 2 } , \theta _ { 3 } | X , M )$ . 

Remark. The method discussed before consists of running a single long chain and keeping all random draws after the burn-ins to obtain a Gibbs sample. Alternatively, one can run many relatively short chains using different starting values and a relatively small $n$ . The random draw of the last Gibbs iteration in each chain is then used to form a Gibbs sample. 

From the prior introduction, Gibbs sampling has the advantage of decomposing a high-dimensional estimation problem into several lower dimensional ones via full conditional distributions of the parameters. At the extreme, a high-dimensional problem with $N$ parameters can be solved iteratively by using $N$ univariate conditional distributions. This property makes the Gibbs sampling simple and widely applicable. However, it is often not efficient to reduce all the Gibbs draws into a univariate problem. When parameters are highly correlated, it pays to draw them jointly. Consider the three-parameter illustrative example. If $\theta _ { 1 }$ and $\theta _ { 2 }$ are highly correlated, then one should employ the conditional distributions $f ( \theta _ { 1 } , \theta _ { 2 } | \theta _ { 3 } , X , M )$

and $f _ { 3 } ( \theta _ { 3 } | \theta _ { 1 } , \theta _ { 2 } , X , M )$ whenever possible. A Gibbs iteration then consists of (a) drawing jointly $( \theta _ { 1 } , \theta _ { 2 } )$ given $\theta _ { 3 }$ and (b) drawing $\theta _ { 3 }$ given $( \theta _ { 1 } , \theta _ { 2 } )$ . For more information on the impact of parameter correlations on the convergence rate of a Gibbs sampler, see Liu, Wong, and Kong (1994).

In practice, convergence of a Gibbs sample is an important issue. The theory only states that the convergence occurs when the number of iterations $m$ is sufficiently large. It provides no specific guidance for choosing m. Many methods have been devised in the literature for checking the convergence of a Gibbs sample. But there is no consensus on which method performs best. In fact, none of the available methods can guarantee $100 \%$ that the Gibbs sample under study has converged for all applications. Performance of a checking method often depends on the problem at hand. Care must be exercised in a real application to ensure that there is no obvious violation of the convergence requirement; see Carlin and Louis (2000) and Gelman et al. (2003) for convergence checking methods. In application, it is important to repeat the Gibbs sampling several times with different starting values to ensure that the algorithm has converged.

# 12.3 BAYESIAN INFERENCE

Conditional distributions play a key role in Gibbs sampling. In the statistical literature, these conditional distributions are referred to as conditional posterior distributions because they are distributions of parameters given the data, other parameter values, and the entertained model. In this section, we review some wellknown posterior distributions that are useful in using MCMC methods.

# 12.3.1 Posterior Distributions

There are two approaches to statistical inference. The first approach is the classical approach based on the maximum likelihood principle. Here a model is estimated by maximizing the likelihood function of the data, and the fitted model is used to make inference. The other approach is Bayesian inference that combines prior belief with data to obtain posterior distributions on which statistical inference is based. Historically, there were heated debates between the two schools of statistical inference. Yet both approaches have proved to be useful and are now widely accepted. The methods discussed so far in this book belong to the classical approach. However, Bayesian solutions exist for all of the problems considered. This is particularly so in recent years with the advances in MCMC methods, which greatly improve the feasibility of Bayesian analysis. Readers can revisit the previous chapters and derive MCMC solutions for the problems considered. In most cases, the Bayesian solutions are similar to what we had before. In some cases, the Bayesian solutions might be advantageous. For example, consider the calculation of value at risk in Chapter 7. A Bayesian solution can easily take into consideration the parameter uncertainty in VaR calculation. However, the approach requires intensive computation.

Let $\pmb \theta$ be the vector of unknown parameters of an entertained model and $X$ be the data. Bayesian analysis seeks to combine knowledge about the parameters with the data to make inference. Knowledge of the parameters is expressed by specifying a

prior distribution for the parameters, which is denoted by $P ( \pmb \theta )$ . For a given model, denote the likelihood function of the data by $f ( X | \pmb \theta )$ . Then by the definition of conditional probability,

$$
f (\boldsymbol {\theta} | \boldsymbol {X}) = \frac {f (\boldsymbol {\theta} , \boldsymbol {X})}{f (\boldsymbol {X})} = \frac {f (\boldsymbol {X} | \boldsymbol {\theta}) P (\boldsymbol {\theta})}{f (\boldsymbol {X})}, \tag {12.4}
$$

where the marginal distribution $f ( X )$ can be obtained by

$$
f (X) = \int f (X, \boldsymbol {\theta}) d \boldsymbol {\theta} = \int f (X | \boldsymbol {\theta}) P (\boldsymbol {\theta}) d \boldsymbol {\theta}.
$$

The distribution $f ( \pmb \theta | X )$ in Eq. (12.4) is called the posterior distribution of $\pmb \theta$ . In general, we can use Bayes’ rule to obtain

$$
f (\boldsymbol {\theta} | X) \propto f (X | \boldsymbol {\theta}) P (\boldsymbol {\theta}), \tag {12.5}
$$

where $P ( \pmb \theta )$ is the prior distribution and $f ( X | \pmb \theta )$ is the likelihood function. From Eq. (12.5), making statistical inference based on the likelihood function $f ( X | \pmb \theta )$ amounts to using a Bayesian approach with a constant prior distribution.

# 12.3.2 Conjugate Prior Distributions

Obtaining the posterior distribution in Eq. (12.4) is not simple in general, but there are cases in which the prior and posterior distributions belong to the same family of distributions. Such a prior distribution is called a conjugate prior distribution. For MCMC methods, use of conjugate priors means that a closed-form solution for the conditional posterior distributions is available. Random draws of the Gibbs sampler can then be obtained by using the commonly available computer routines of probability distributions. In what follows, we review some well-known conjugate priors. For more information, readers are referred to textbooks on Bayesian statistics (e.g., DeGroot 1990, Chapter 9).

Result 1. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a normal distribution with mean $\mu$ , which is unknown, and variance $\sigma ^ { 2 }$ , which is known and positive. Suppose that the prior distribution of $\mu$ is a normal distribution with mean $\mu _ { o }$ and variance $\sigma _ { o } ^ { 2 }$ . Then the posterior distribution of $\mu$ given the data and prior is normal with mean $\mu _ { * }$ and variance $\sigma _ { * } ^ { 2 }$ given by

$$
\mu_ {*} = \frac {\sigma^ {2} \mu_ {o} + n \sigma_ {o} ^ {2} \overline {{x}}}{\sigma^ {2} + n \sigma_ {o} ^ {2}} \quad \mathrm {a n d} \quad \sigma_ {*} ^ {2} = \frac {\sigma^ {2} \sigma_ {o} ^ {2}}{\sigma^ {2} + n \sigma_ {o} ^ {2}},
$$

where $\textstyle { \overline { { x } } } = \sum _ { i = 1 } ^ { n } x _ { i } / n$ is the sample mean.

In Bayesian analysis, it is often convenient to use the precision parameter $\eta =$ $1 / \sigma ^ { 2 }$ (i.e., the inverse of the variance $\sigma ^ { 2 }$ ). Denote the precision parameter of the prior distribution by $\eta _ { o } = 1 / \sigma _ { o } ^ { 2 }$ and that of the posterior distribution by $\eta _ { * } = 1 / \sigma _ { * } ^ { 2 }$ . Then Result 1 can be rewritten as

$$
\eta_ {*} = \eta_ {o} + n \eta \quad \text {a n d} \quad \mu_ {*} = \frac {\eta_ {o}}{\eta_ {*}} \times \mu_ {o} + \frac {n \eta}{\eta_ {*}} \times \overline {{x}}.
$$

For the normal random sample considered, data information about $\mu$ is contained in the sample mean $\overline { { x } }$ , which is the sufficient statistic of $\mu$ . The precision of $\overline { { x } }$ is $n / \sigma ^ { 2 } = n \eta$ . Consequently, Result 1 says that (a) precision of the posterior distribution is the sum of the precisions of the prior and the data, and (b) the posterior mean is a weighted average of the prior mean and sample mean with weight proportional to the precision. The two formulas also show that the contribution of the prior distribution is diminishing as the sample size $n$ increases.

A multivariate version of Result 1 is particularly useful in MCMC methods when linear regression models are involved; see Box and Tiao (1973).

Result 1a. Suppose that $\pmb { x } _ { 1 } , \ldots , \pmb { x } _ { n }$ form a random sample from a multivariate normal distribution with mean vector $\pmb { \mu }$ and a known covariance matrix $\pmb { \Sigma }$ . Suppose also that the prior distribution of $\pmb { \mu }$ is multivariate normal with mean vector ${ \pmb \mu } _ { o }$ and covariance matrix $\Sigma _ { o }$ . Then the posterior distribution of $\pmb { \mu }$ is also multivariate normal with mean vector $\pmb { \mu } _ { \ast }$ and covariance matrix $\pmb { \Sigma } _ { * }$ , where

$$
\boldsymbol {\Sigma} _ {*} ^ {- 1} = \boldsymbol {\Sigma} _ {o} ^ {- 1} + n \boldsymbol {\Sigma} ^ {- 1} \quad \text {a n d} \quad \boldsymbol {\mu} _ {*} = \boldsymbol {\Sigma} _ {*} (\boldsymbol {\Sigma} _ {o} ^ {- 1} \boldsymbol {\mu} _ {o} + n \boldsymbol {\Sigma} ^ {- 1} \overline {{\boldsymbol {x}}}),
$$

where ${ \overline { { \pmb { x } } } } = { \bigl ( } \sum _ { i = 1 } ^ { n } { \pmb { x } } _ { i } { \bigr ) } / n$ is the sample mean, which is distributed as a multivariate normal with mean $\pmb { \mu }$ and covariance matrix $\pmb { \Sigma } / n$ . Note that $n { \pmb \Sigma } ^ { - 1 }$ is the precision matrix of $\overline { { x } }$ and $\pmb { \Sigma } _ { o } ^ { - 1 }$ is the precision matrix of the prior distribution.

A random variable $\eta$ has a gamma distribution with positive parameters $\alpha$ and $\beta$ if its probability density function is

$$
f (\eta | \alpha , \beta) = \frac {\beta^ {\alpha}}{\Gamma (\alpha)} \eta^ {\alpha - 1} e ^ {- \beta \eta}, \quad \eta > 0,
$$

where $\Gamma ( \alpha )$ is a gamma function. For this distribution, $E ( \eta ) = \alpha / \beta$ and $\mathrm { V a r } ( \eta ) = \alpha / \beta ^ { 2 }$ .

Result 2. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a normal distribution with a given mean $\mu$ and an unknown precision $\eta$ . If the prior distribution of $\eta$ is a gamma distribution with positive parameters $\alpha$ and $\beta$ , then the posterior distribution of $\eta$ is a gamma distribution with parameters $\alpha + ( n / 2 )$ and $\textstyle { \beta + \sum _ { i = 1 } ^ { n } ( x _ { i } - \mu ) ^ { 2 } / 2 }$ .

A random variable $\theta$ has a beta distribution with positive parameters $\alpha$ and $\beta$ if its probability density function is

$$
f (\theta | \alpha , \beta) = \frac {\Gamma (\alpha + \beta)}{\Gamma (\alpha) \Gamma (\beta)} \theta^ {\alpha - 1} (1 - \theta) ^ {\beta - 1}, \quad 0 <   \theta <   1.
$$

The mean and variance of $\theta$ are $E ( \theta ) = \alpha / ( \alpha + \beta )$ and $\mathrm { V a r } ( \theta ) = \alpha \beta / [ ( \alpha +$ $\beta ) ^ { 2 } ( \alpha + \beta + 1 ) ]$ .

Result 3. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a Bernoulli distribution with parameter $\theta$ . If the prior distribution of $\theta$ is a beta distribution

with given positive parameters $\alpha$ and $\beta$ , then the posterior of $\theta$ is a beta distribution with parameters $\textstyle { \alpha + \sum _ { i = 1 } ^ { n } x _ { i } }$ and $\begin{array} { r } { \beta + n - \sum _ { i = 1 } ^ { n } x _ { i } } \end{array}$ .

Result 4. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a Poisson distribution with parameter $\lambda$ . Suppose also that the prior distribution of $\lambda$ is a gamma distribution with given positive parameters $\alpha$ and $\beta$ . Then the posterior distribution of $\lambda$ is a gamma distribution with parameters $\textstyle { \alpha + \sum _ { i = 1 } ^ { n } x _ { i } }$ and $\beta + n$ .

Result 5. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from an exponential distribution with parameter λ. If the prior distribution of $\lambda$ is a gamma distribution with given positive parameters $\alpha$ and $\beta$ , then the posterior distribution of $\lambda$ is a gamma distribution with parameters $\alpha + n$ and $\beta + \textstyle \sum _ { i = 1 } ^ { n } x _ { i }$ .

A random variable $X$ has a negative binomial distribution with parameters $m$ and $\lambda$ , where $m > 0$ and $0 < \lambda < 1$ , if $X$ has a probability mass function

$$
p (n | m, \lambda) = \left\{ \begin{array}{c c} \binom {m + n - 1} {n} \lambda^ {m} (1 - \lambda) ^ {n} & \text {i f} n = 0, 1, \ldots , \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

A simple example of negative binomial distribution in finance is how many MBA graduates a firm must interview before finding exactly m “right candidates” for its $m$ openings, assuming that the applicants are independent and each applicant has a probability $\lambda$ of being a perfect fit. Denote the total number of interviews by Y . Then $X = Y - m$ is distributed as a negative binomial with parameters $m$ and $\lambda$ .

Result 6. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a negative binomial distribution with parameters $m$ and $\lambda$ , where $m$ is positive and fixed. If the prior distribution of $\lambda$ is a beta distribution with positive parameters $\alpha$ and $\beta$ , then the posterior distribution of $\lambda$ is a beta distribution with parameters $\alpha + m n$ and $\beta + \textstyle \sum _ { i = 1 } ^ { n } x _ { i }$ .

Next, we consider the case of a normal distribution with an unknown mean $\mu$ and an unknown precision $\eta$ . The two-dimensional prior distribution is partitioned as $P ( \mu , \eta ) = P ( \mu | \eta ) P ( \eta )$ .

Result 7. Suppose that $x _ { 1 } , \ldots , x _ { n }$ form a random sample from a normal distribution with an unknown mean $\mu$ and an unknown precision $\eta$ . Suppose also that the conditional distribution of $\mu$ given $\eta = \eta _ { o }$ is a normal distribution with mean $\mu _ { o }$ and precision $\tau _ { o } \eta _ { o }$ and the marginal distribution of $\eta$ is a gamma distribution with positive parameters $\alpha$ and $\beta$ . Then the conditional posterior distribution of $\mu$ given $\eta = \eta _ { o }$ is a normal distribution with mean $\mu _ { * }$ and precision $\eta _ { * }$ ,

$$
\mu_ {*} = \frac {\tau_ {o} \mu_ {o} + n \overline {{x}}}{\tau_ {o} + n} \quad \mathrm {a n d} \quad \eta_ {*} = (\tau_ {o} + n) \eta_ {o},
$$

where $\textstyle { \overline { { x } } } = { \bigl ( } \sum _ { i = 1 } ^ { n } x _ { i } { \bigr ) } / n$ is the sample mean, and the marginal posterior distribution of $\eta$ is a gamma distribution with parameters $\alpha + ( n / 2 )$ and $\beta _ { * }$ , where

$$
\beta_ {*} = \beta + \frac {1}{2} \sum_ {i = 1} ^ {n} (x _ {i} - \overline {{x}}) ^ {2} + \frac {\tau_ {o} n (\overline {{x}} - \mu_ {o}) ^ {2}}{2 (\tau_ {o} + n)}.
$$

When the conditional variance of a random variable is of interest, an inverted chi-squared distribution (or inverse chi-squared) is often used. A random variable $Y$ has an inverted chi-squared distribution with $v$ degrees of freedom if $1 / Y$ follows a chi-squared distribution with the same degrees of freedom. The probability density function of $Y$ is

$$
f (y | v) = \frac {2 ^ {- v / 2}}{\Gamma (v / 2)} y ^ {- (v / 2 + 1)} e ^ {- 1 / (2 y)}, \quad y > 0.
$$

For this distribution, we have $E ( Y ) = 1 / ( v - 2 )$ if $v > 2$ and $\operatorname { V a r } ( Y ) = 2 / [ ( v -$ $2 ) ^ { 2 } ( v - 4 ) ]$ if $v > 4$ .

Result 8. Suppose that $a _ { 1 } , \ldots , a _ { n }$ form a random sample from a normal distribution with mean zero and variance $\sigma ^ { 2 }$ . Suppose also that the prior distribution of $\sigma ^ { 2 }$ is an inverted chi-squared distribution with $v$ degrees of freedom (i.e., $( v \lambda ) / \sigma ^ { 2 } \sim \chi _ { v } ^ { 2 }$ , where $\lambda > 0$ ). Then the posterior distribution of $\sigma ^ { 2 }$ is also an inverted chi-squared distribution with $v + n$ degrees of freedom—that is, $\textstyle \left( v \lambda + \sum _ { i = 1 } ^ { n } a _ { i } ^ { 2 } \right) / \sigma ^ { 2 } \sim \mathop { \chi _ { v + n } ^ { 2 } }$ .

# 12.4 ALTERNATIVE ALGORITHMS

In many applications, there are no closed-form solutions for the conditional posterior distributions. But many clever alternative algorithms have been devised in the statistical literature to overcome this difficulty. In this section, we discuss some of these algorithms.

# 12.4.1 Metropolis Algorithm

This algorithm is applicable when the conditional posterior distribution is known except for a normalization constant; see Metropolis and Ulam (1949) and Metropolis et al. (1953). Suppose that we want to draw a random sample from the distribution $f ( \pmb \theta | X )$ , which contains a complicated normalization constant so that a direct draw is either too time-consuming or infeasible. But there exists an approximate distribution for which random draws are easily available. The Metropolis algorithm generates a sequence of random draws from the approximate distribution whose distributions converge to $f ( \pmb \theta | X )$ . The algorithm proceeds as follows:

1. Draw a random starting value $\pmb { \theta } _ { 0 }$ such that $f ( \pmb \theta _ { 0 } | \pmb X ) > 0$

2. For $t = 1 , 2 , \ldots$

(a) Draw a candidate sample $\pmb { \theta } _ { \ast }$ from a known distribution at iteration $t$ given the previous draw $\pmb { \theta } _ { t - 1 }$ . Denote the known distribution by $J _ { t } ( \pmb \theta _ { t } | \pmb \theta _ { t - 1 } )$

which is called a jumping distribution in Gelman et al. (2003). It is also referred to as a proposal distribution. The jumping distribution must be symmetric—that is, $J _ { t } ( \pmb { \theta } _ { i } | \pmb { \theta } _ { j } ) = J _ { t } ( \pmb { \theta } _ { j } | \pmb { \theta } _ { i } )$ for all $\pmb { \theta } _ { i } , \pmb { \theta } _ { j }$ , and $t$ .

(b) Calculate the ratio

$$
r = \frac {f (\boldsymbol {\theta} _ {*} | \boldsymbol {X})}{f (\boldsymbol {\theta} _ {t - 1} | \boldsymbol {X})}.
$$

(c) Set

$$
\boldsymbol {\theta} _ {t} = \left\{ \begin{array}{l l} \boldsymbol {\theta} _ {*} & \text {w i t h p r o b a b i l i t y m i n} (r, 1), \\ \boldsymbol {\theta} _ {t - 1} & \text {o t h e r w i s e}. \end{array} \right.
$$

Under some regularity conditions, the sequence $\{ \pmb \theta _ { t } \}$ converges in distribution to $f ( \pmb \theta | X )$ ; see Gelman et al. (2003).

Implementation of the algorithm requires the ability to calculate the ratio $r$ for all $\pmb { \theta } _ { \ast }$ and $\pmb \theta _ { t - 1 }$ , to draw $\pmb { \theta } _ { \ast }$ from the jumping distribution, and to draw a random realization from a uniform distribution to determine the acceptance or rejection of $\pmb { \theta } _ { \ast }$ . The normalization constant of $f ( \pmb \theta | X )$ is not needed because only a ratio is used.

The acceptance and rejection rule of the algorithm can be stated as follows: (i) if the jump from $\pmb { \theta } _ { t - 1 }$ to $\pmb { \theta } _ { \ast }$ increases the conditional posterior density, then accept $\pmb { \theta } _ { \ast }$ as $\pmb { \theta } _ { t }$ ; (ii) if the jump decreases the posterior density, then set $\pmb { \theta } _ { t } = \pmb { \theta } _ { \ast }$ with probability equal to the density ratio $r$ , and set $\pmb \theta _ { t } = \pmb \theta _ { t - 1 }$ otherwise. Such a procedure seems reasonable.

Examples of symmetric jumping distributions include the normal and Student-$t$ distributions for the mean parameter. For a given covariance matrix, we have $f ( \pmb { \theta } _ { i } | \pmb { \theta } _ { j } ) = f ( \pmb { \theta } _ { j } | \pmb { \theta } _ { i } )$ , where $f ( \pmb \theta | \pmb \theta _ { o } )$ denotes a multivariate normal density function with mean vector $\theta _ { o }$ .

# 12.4.2 Metropolis–Hasting Algorithm

Hasting (1970) generalizes the Metropolis algorithm in two ways. First, the jumping distribution does not have to be symmetric. Second, the jumping rule is modified to

$$
r = \frac {f (\pmb {\theta} _ {*} | \boldsymbol {X}) / J _ {t} (\pmb {\theta} _ {*} | \pmb {\theta} _ {t - 1})}{f (\pmb {\theta} _ {t - 1} | \boldsymbol {X}) / J _ {t} (\pmb {\theta} _ {t - 1} | \pmb {\theta} _ {*})} = \frac {f (\pmb {\theta} _ {*} | \boldsymbol {X}) J _ {t} (\pmb {\theta} _ {t - 1} | \pmb {\theta} _ {*})}{f (\pmb {\theta} _ {t - 1} | \boldsymbol {X}) J _ {t} (\pmb {\theta} _ {*} | \pmb {\theta} _ {t - 1})}.
$$

This modified algorithm is referred to as the Metropolis–Hasting algorithm. Tierney (1994) discusses methods to improve computational efficiency of the algorithm.

# 12.4.3 Griddy Gibbs

In financial applications, an entertained model may contain some nonlinear parameters (e.g., the moving-average parameters in an ARMA model or the GARCH parameters in a volatility model). Since conditional posterior distributions of nonlinear parameters do not have a closed-form expression, implementing a Gibbs sampler in this situation may become complicated even with the Metropolis–Hasting algorithm. Tanner (1996) describes a simple procedure to obtain random draws in a Gibbs sampling when the conditional posterior distribution is

univariate. The method is called the Griddy Gibbs sampler and is widely applicable. However, the method could be inefficient in a real application.

Let $\theta _ { i }$ be a scalar parameter with conditional posterior distribution $f ( \theta _ { i } | X , \pmb \theta _ { - i } )$ , where $\pmb { \theta } _ { - i }$ is the parameter vector after removing $\theta _ { i }$ . For instance, if $\pmb \theta =$ $( \theta _ { 1 } , \theta _ { 2 } , \theta _ { 3 } ) ^ { \prime }$ , then $\pmb { \theta } _ { - 1 } = ( \theta _ { 2 } , \theta _ { 3 } ) ^ { \prime } .$ . The Griddy Gibbs proceeds as follows:

1. Select a grid of points from a properly selected interval of $\theta _ { i }$ , say, $\theta _ { i 1 } \leq$ $\theta _ { i 2 } \le \cdots \le \theta _ { i m }$ . Evaluate the conditional posterior density function to obtain $w _ { j } = f ( \theta _ { i j } | X , \pmb \theta _ { - i } )$ for $j = 1 , \ldots , m$ .   
2. Use $w _ { 1 } , \ldots , w _ { m }$ to obtain an approximation to the inverse cumulative distribution function (CDF) of $f ( \theta _ { i } | X , \pmb \theta _ { - i } )$ .   
3. Draw a uniform (0,1) random variate and transform the observation via the approximate inverse CDF to obtain a random draw for $\theta _ { i }$ .

Some remarks on the Griddy Gibbs are in order. First, the normalization constant of the conditional posterior distribution $f ( \theta _ { i } | X , \pmb \theta _ { - i } )$ is not needed because the inverse CDF can be obtained from $\{ w _ { j } \} _ { j = 1 } ^ { m }$ directly. Second, a simple approx-= imation to the inverse CDF is a discrete distribution for $\{ \theta _ { i j } \} _ { j = 1 } ^ { m }$ with probability $\begin{array} { r } { p ( \theta _ { i j } ) = w _ { j } / \sum _ { v = 1 } ^ { m } w _ { v } } \end{array}$ . Third, in a real application, selection of the interval $[ \theta _ { i 1 } , \theta _ { i m } ]$ for the parameter $\theta _ { i }$ must be checked carefully. A simple checking procedure is to consider the histogram of the Gibbs draws of $\theta _ { i }$ . If the histogram indicates substantial probability around $\theta _ { i 1 }$ or $\theta _ { i m }$ , then the interval must be expanded. However, if the histogram shows a concentration of probability inside the interval $[ \theta _ { i 1 } , \theta _ { i m } ]$ , then the interval is too wide and can be shortened. If the interval is too wide, then the Griddy Gibbs becomes inefficient because most of $w _ { j }$ would be zero. Finally, the Griddy Gibbs or Metropolis–Hasting algorithm can be used in a Gibbs sampling to obtain random draws of some parameters.

# 12.5 LINEAR REGRESSION WITH TIME SERIES ERRORS

We are ready to consider some specific applications of MCMC methods. Examples discussed in the next few sections are for illustrative purposes only. The goal here is to highlight the applicability and usefulness of the methods. Understanding these examples can help readers gain insights into applications of MCMC methods in finance.

The first example is to estimate a regression model with serially correlated errors. This is a topic discussed in Chapter 2, where we use SCA to perform the estimation. A simple version of the model is

$$
\begin{array}{l} y _ {t} = \beta_ {0} + \beta_ {1} x _ {1 t} + \dots + \beta_ {k} x _ {k t} + z _ {t}, \\ z _ {t} = \phi z _ {t - 1} + a _ {t}, \\ \end{array}
$$

where $y _ { t }$ is the dependent variable, $x _ { i t }$ are explanatory variables that may contain lagged values of $y _ { t }$ , and $z _ { t }$ follows a simple AR(1) model with $\{ a _ { t } \}$ being a sequence of independent and identically distributed normal random variables with mean zero

and variance $\sigma ^ { 2 }$ . Denote the parameters of the model by $\pmb \theta = ( \pmb \beta ^ { \prime } , \phi , \sigma ^ { 2 } ) ^ { \prime }$ , where $\beta = ( \beta _ { 0 } , \beta _ { 1 } , \dots , \beta _ { k } ) ^ { \prime }$ , and let $\pmb { x } _ { t } = ( 1 , x _ { 1 t } , \ldots , x _ { k t } ) ^ { \prime }$ be the vector of all regressors at time $t$ , including a constant of unity. The model becomes

$$
y _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + z _ {t}, \quad z _ {t} = \phi z _ {t - 1} + a _ {t}, \quad t = 1, \dots , n, \tag {12.6}
$$

where $n$ is the sample size.

A natural way to implement Gibbs sampling in this case is to iterate between regression estimation and time series estimation. If the time series model is known, we can estimate the regression model easily by using the least squares method. However, if the regression model is known, we can obtain the time series $z _ { t }$ by using $z _ { t } = y _ { t } - x _ { t } ^ { \prime } \beta$ and use the series to estimate the AR(1) model. Therefore, we need the following conditional posterior distributions:

$$
f (\boldsymbol {\beta} | \boldsymbol {Y}, \boldsymbol {X}, \phi , \sigma^ {2}), \quad f (\phi | \boldsymbol {Y}, \boldsymbol {X}, \boldsymbol {\beta}, \sigma^ {2}), \quad f (\sigma^ {2} | \boldsymbol {Y}, \boldsymbol {X}, \boldsymbol {\beta}, \phi),
$$

where $Y = ( y _ { 1 } , \dots , y _ { n } ) ^ { \prime }$ and $X$ denotes the collection of all observations of explanatory variables.

We use conjugate prior distributions to obtain closed-form expressions for the conditional posterior distributions. The prior distributions are

$$
\boldsymbol {\beta} \sim N \left(\boldsymbol {\beta} _ {o}, \boldsymbol {\Sigma} _ {o}\right), \quad \phi \sim N \left(\phi_ {o}, \sigma_ {o} ^ {2}\right), \quad \frac {v \lambda}{\sigma^ {2}} \sim \chi_ {v} ^ {2}, \tag {12.7}
$$

where again $\sim$ denotes distribution, and $\beta _ { o }$ , $\Sigma _ { o }$ , λ, v, φo, and $\sigma _ { o } ^ { 2 }$ are known quantities. These quantities are referred to as hyperparameters in Bayesian inference. Their exact values depend on the problem at hand. Typically, we assume that ${ \boldsymbol { \beta } } _ { o } = \mathbf { 0 }$ , φo 0, and $\Sigma _ { o }$ is a diagonal matrix with large diagonal elements. The prior distributions in Eq. (12.7) are assumed to be independent of each other. Thus, we use independent priors based on the partition of the parameter vector $\pmb \theta$ .

The conditional posterior distribution $f ( \beta | Y , X , \phi , \sigma ^ { 2 } )$ can be obtained by using Result 1a of Section 12.3. Specifically, given $\phi$ , we define

$$
y _ {o, t} = y _ {t} - \phi y _ {t - 1}, \quad \boldsymbol {x} _ {o, t} = \boldsymbol {x} _ {t} - \phi \boldsymbol {x} _ {t - 1}.
$$

Using Eq. (12.6), we have

$$
y _ {o, t} = \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {o, t} + a _ {t}, \quad t = 2, \dots , n. \tag {12.8}
$$

Under the assumption of $\{ a _ { t } \}$ , Eq. (12.8) is a multiple linear regression. Therefore, information of the data about the parameter vector $\beta$ is contained in its least squares estimate

$$
\widehat {\boldsymbol {\beta}} = \left(\sum_ {t = 2} ^ {n} \boldsymbol {x} _ {o, t} \boldsymbol {x} _ {o, t} ^ {\prime}\right) ^ {- 1} \left(\sum_ {t = 2} ^ {n} \boldsymbol {x} _ {o, t} \boldsymbol {y} _ {o, t}\right),
$$

which has a multivariate normal distribution

$$
\widehat {\boldsymbol {\beta}} \sim N \left[ \boldsymbol {\beta}, \quad \sigma^ {2} \left(\sum_ {t = 2} ^ {n} \boldsymbol {x} _ {o, t} \boldsymbol {x} _ {o, t} ^ {\prime}\right) ^ {- 1} \right].
$$

Using Result 1a, the posterior distribution of $\beta$ , given the data, $\phi$ , and $\sigma ^ { 2 }$ , is multivariate normal. We write the result as

$$
(\boldsymbol {\beta} | Y, X, \phi , \sigma) \sim N \left(\boldsymbol {\beta} _ {*}, \boldsymbol {\Sigma} _ {*}\right), \tag {12.9}
$$

where the parameters are given by

$$
\pmb {\Sigma} _ {*} ^ {- 1} = \frac {\sum_ {t = 2} ^ {n} \pmb {x} _ {o , t} \pmb {x} _ {o , t} ^ {\prime}}{\sigma^ {2}} + \pmb {\Sigma} _ {o} ^ {- 1}, \quad \pmb {\beta} _ {*} = \pmb {\Sigma} _ {*} \left(\frac {\sum_ {t = 2} ^ {n} \pmb {x} _ {o , t} \pmb {x} _ {o , t} ^ {\prime}}{\sigma^ {2}} \widehat {\pmb {\beta}} + \pmb {\Sigma} _ {o} ^ {- 1} \pmb {\beta} _ {o}\right).
$$

Next, consider the conditional posterior distribution of $\phi$ given $\beta , \sigma ^ { 2 }$ , and the data. Because $\beta$ is given, we can calculate $z _ { t } = y _ { t } - \beta ^ { \prime } x _ { t }$ for all $t$ and consider the AR(1) model

$$
z _ {t} = \phi z _ {t - 1} + a _ {t}, \quad t = 2, \dots , n.
$$

The information of the likelihood function about $\phi$ is contained in the least squares estimate

$$
\widehat {\phi} = \left(\sum_ {t = 2} ^ {n} z _ {t - 1} ^ {2}\right) ^ {- 1} \left(\sum_ {t = 2} ^ {n} z _ {t - 1} z _ {t}\right),
$$

which is normally distributed with mean $\phi$ and variance $\scriptstyle \sigma ^ { 2 } ( \sum _ { t = 2 } ^ { n } z _ { t - 1 } ^ { 2 } ) ^ { - 1 }$ . Based on Result 1, the posterior distribution of $\phi$ is also normal with mean $\phi _ { * }$ and variance $\sigma _ { * } ^ { 2 }$ , where

$$
\sigma_ {*} ^ {- 2} = \frac {\sum_ {t = 2} ^ {n} z _ {t - 1} ^ {2}}{\sigma^ {2}} + \sigma_ {o} ^ {- 2}, \quad \phi_ {*} = \sigma_ {*} ^ {2} \left(\frac {\sum_ {t = 2} ^ {n} z _ {t - 1} ^ {2}}{\sigma^ {2}} \widehat {\phi} + \sigma_ {o} ^ {- 2} \phi_ {o}\right). \tag {12.10}
$$

Finally, turn to the posterior distribution of $\sigma ^ { 2 }$ given $\beta , \phi$ , and the data. Because $\beta$ and $\phi$ are known, we can calculate

$$
a _ {t} = z _ {t} - \phi z _ {t - 1}, \quad z _ {t} = y _ {t} - \boldsymbol {\beta} ^ {\prime} \boldsymbol {x} _ {t}, \quad t = 2, \dots , n.
$$

By Result 8 of Section 12.3, the posterior distribution of $\sigma ^ { 2 }$ is an inverted chisquared distribution—that is,

$$
\frac {v \lambda + \sum_ {t = 2} ^ {n} a _ {t} ^ {2}}{\sigma^ {2}} \sim \chi_ {v + (n - 1)} ^ {2}, \tag {12.11}
$$

where $\chi _ { k } ^ { 2 }$ denotes a chi-squared distribution with $k$ degrees of freedom.

Using the three conditional posterior distributions in Eqs. (12.9)– (12.11), we can estimate Eq. (12.6) via Gibbs sampling as follows:

1. Specify the hyperparameter values of the priors in Eq. (12.7).   
2. Specify arbitrary starting values for β, $\phi$ , and $\sigma ^ { 2 }$ (e.g., the ordinary least squares estimate of $\beta$ without time series errors).   
3. Use the multivariate normal distribution in Eq. (12.9) to draw a random realization for $\beta$ .

4. Use the univariate normal distribution in Eq. (12.10) to draw a random realization for $\phi$ .   
5. Use the chi-squared distribution in Eq. (12.11) to draw a random realization for $\sigma ^ { 2 }$ .

Repeat steps 3–5 for many iterations to obtain a Gibbs sample. The sample means are then used as point estimates of the parameters of model (12.6).

Example 12.1. As an illustration, we revisit the example of U.S. weekly interest rates of Chapter 2. The data are the 1-year and 3-year Treasury constant maturity rates from January 5, 1962 to September 10, 1999 and are obtained from the Federal Reserve Bank of St. Louis. Because of unit-root nonstationarity, the dependent and independent variables are:

1. $c _ { 3 t } = r _ { 3 t } - r _ { 3 , t - 1 }$ , which is the weekly change in 3-year maturity rate,   
2. $c _ { 1 t } = r _ { 1 t } - r _ { 1 , t - 1 }$ , which is the weekly change in 1-year maturity rate,

where the original interest rates $r _ { i t }$ are measured in percentages. In Chapter 2, we employed a linear regression model with an MA(1) error for the data. Here we consider an AR(2) model for the error process. Using the traditional approach, we obtain the model

$$
c _ {3 t} = 0. 0 0 0 2 + 0. 7 8 2 c _ {1 t} + z _ {t}, \quad z _ {t} = 0. 2 0 5 z _ {t - 1} - 0. 0 6 8 z _ {t - 2} + a _ {t}, \tag {12.12}
$$

where $\widehat { \sigma } _ { a } = 0 . 0 6 7$ . Standard errors of the coefficient estimates of Eq. (12.12) are 0.0017, 0.008, 0.023, and 0.023, respectively. Except for a marginally significant residual ACF at lag 6, the prior model seems adequate.

Writing the model as

$$
c _ {3 t} = \beta_ {0} + \beta_ {1} c _ {1 t} + z _ {t}, \quad z _ {t} = \phi_ {1} z _ {t - 1} + \phi_ {2} z _ {t - 2} + a _ {t}, \tag {12.13}
$$

where $\{ a _ { t } \}$ is an independent sequence of $N ( 0 , \sigma ^ { 2 } )$ random variables, we estimate the parameters by Gibbs sampling. The prior distributions used are

$$
\pmb {\beta} \sim N (\mathbf {0}, 4 \pmb {I} _ {2}), \quad \pmb {\phi} \sim N [ \mathbf {0}, \mathrm {d i a g} (0. 2 5, 0. 1 6) ], \quad (v \lambda) / \sigma^ {2} = (1 0 \times 0. 1) / \sigma^ {2} \sim \chi_ {1 0} ^ {2},
$$

where $I _ { 2 }$ is the $2 \times 2$ identity matrix. The initial parameter estimates are obtained by the ordinary least squares method (i.e., by using a two-step procedure of fitting the linear regression model first, then fitting an AR(2) model to the regression residuals). Since the sample size 1966 is large, the initial estimates are close to those given in Eq. (12.12). We iterated the Gibbs sampling for 2100 iterations but discard results of the first 100 iterations. Table 12.1 gives the posterior means and standard errors of the parameters. Figure 12.1 shows the histogram of the marginal posterior distribution of each parameter.

![](images/87e80c32d0fd4635246fa386b277030e0f6e16ba1cc4b42a5eabcf3d4526ecb8.jpg)

![](images/74560c051119e2842823bfa1132747a237a3cc1237e68c02432f8d566dd3af75.jpg)

![](images/a646a1eba06a45f1e6158283fc1b6420295208fc16dd4b8b639aec2ae0179f78.jpg)

![](images/2ebe2bcf0f651e72cb10c6e252628807d2a72203d3e9090b372b90b08753636f.jpg)

![](images/c35a151222301fabaf3e6c87fea79d8f9c173ac4ad38ce7e9d20f7d558fa65c5.jpg)  
Figure 12.1. Histograms of Gibbs draws for the model in Eq. (12.13) with 2100 iterations. The results are based on the last 2000 draws. Prior distributions and starting parameter values are given in the text.

Table 12.1. Posterior Means and Standard Errors of Model (12.13) Estimated by a Gibbs Sampling with 2100 Iterationsa   

<table><tr><td>Parameter</td><td>β0</td><td>β1</td><td>φ1</td><td>φ2</td><td>σ</td></tr><tr><td>Mean</td><td>0.025</td><td>0.784</td><td>0.305</td><td>0.032</td><td>0.074</td></tr><tr><td>Standard error</td><td>0.024</td><td>0.009</td><td>0.089</td><td>0.087</td><td>0.003</td></tr></table>

aThe results are based on the last 2000 iterations, and the prior distributions are given in the text.

We repeated the Gibbs sampling with different initial values but obtained similar results. The Gibbs sampling appears to have converged. From Table 12.1, the posterior means are close to the estimates of Eq. (12.12) except for the coefficient of $z _ { t - 2 }$ . However, the posterior standard errors of $\phi _ { 1 }$ and $\phi _ { 2 }$ are relatively large, indicating uncertainty in these two estimates. The histograms of Figure 12.1 are informative. In particular, they show that the distributions of $\widehat { \phi } _ { 1 }$ and $\widehat { \phi } _ { 2 }$ have not converged to the asymptotic normality; the distributions are skewed to the right. However, the asymptotic normality of $\widehat { \beta } _ { 0 }$ and ${ \widehat { \beta } } _ { 1 }$ seems reasonable.

# 12.6 MISSING VALUES AND OUTLIERS

In this section, we discuss MCMC methods for handling missing values and detecting additive outliers. Let $\{ y _ { t } \} _ { t = 1 } ^ { n }$ be an observed time series. A data point $y _ { h }$ is an additive outlier if

$$
y _ {t} = \left\{ \begin{array}{l l} x _ {h} + \omega & \text {i f} t = h, \\ x _ {t} & \text {o t h e r w i s e}, \end{array} \right. \tag {12.14}
$$

where $\omega$ is the magnitude of the outlier and $x _ { t }$ is an outlier-free time series. Examples of additive outliers include recording errors (e.g., typos and measurement errors). Outliers can seriously affect time series analysis because they may induce substantial biases in parameter estimation and lead to model misspecification.

Consider a time series $x _ { t }$ and a fixed time index $h$ . We can learn a lot about $x _ { h }$ by treating it as a missing value. If the model of $x _ { t }$ were known, then we could derive the conditional distribution of $x _ { h }$ given the other values of the series. By comparing the observed value $y _ { h }$ with the derived distribution of $x _ { h }$ , we can determine whether $y _ { h }$ can be classified as an additive outlier. Specifically, if $y _ { h }$ is a value that is likely to occur under the derived distribution, then $y _ { h }$ is not an additive outlier. However, if the chance to observe $y _ { h }$ is very small under the derived distribution, then $y _ { h }$ can be classified as an additive outlier. Therefore, detection of additive outliers and treatment of missing values in time series analysis are based on the same idea.

In the literature, missing values in a time series can be handled by using either the Kalman filter or MCMC methods; see Jones (1980), Chapter 11, and McCulloch and Tsay (1994a). Outlier detection has also been carefully investigated; see Chang, Tiao, and Chen (1988), Tsay (1988), Tsay, Pena, and Pankratz (2000) and ˜

the references therein. The outliers are classified into four categories depending on the nature of their impacts on the time series. Here we focus on additive outliers.

# 12.6.1 Missing Values

For ease in presentation, consider an $\operatorname { A R } ( p )$ time series

$$
x _ {t} = \phi_ {1} x _ {t - 1} + \dots + \phi_ {p} x _ {t - p} + a _ {t}, \tag {12.15}
$$

where $\{ a _ { t } \}$ is a Gaussian white noise series with mean zero and variance $\sigma ^ { 2 }$ . Suppose that the sampling period is from $t = 1$ to $t = n$ , but the observation $x _ { h }$ is missing, where $1 < h < n$ . Our goal is to estimate the model in the presence of a missing value.

In this particular instance, the parameters are $\pmb \theta = ( \pmb \phi ^ { \prime } , x _ { h } , \sigma ^ { 2 } ) ^ { \prime }$ , where $\phi =$ $( \phi _ { 1 } , \ldots , \phi _ { p } ) ^ { \prime }$ . Thus, we treat the missing value $x _ { h }$ as an unknown parameter. If we assume that the prior distributions are

$$
\pmb {\phi} \sim N (\pmb {\phi} _ {o}, \pmb {\Sigma} _ {o}), x _ {h} \sim N (\mu_ {o}, \sigma_ {o} ^ {2}), \frac {v \lambda}{\sigma^ {2}} \sim \chi_ {v} ^ {2},
$$

where the hyperparameters are known, then the conditional posterior distributions $f ( \phi | X , x _ { h } , \sigma ^ { 2 } )$ and $f ( \sigma ^ { 2 } | \boldsymbol { X } , \boldsymbol { x } _ { h } , \boldsymbol { \phi } )$ are exactly as those given in the previous section, where $X$ denotes the observed data. The conditional posterior distribution $f ( x _ { h } | X , \phi , \sigma ^ { 2 } )$ is univariate normal with mean $\mu _ { * }$ and variance $\sigma _ { h } ^ { 2 }$ . These two parameters can be obtained by using a linear regression model. Specifically, given the model and the data, $x _ { h }$ is only related to $\{ x _ { h - p } , \ldots , x _ { h - 1 } , x _ { h + 1 } , \ldots , x _ { h + p } \}$ . Keeping in mind that $x _ { h }$ is an unknown parameter, we can write the relationship as follows:

1. For $t = h$ , the model says

$$
x _ {h} = \phi_ {1} x _ {h - 1} + \dots + \phi_ {p} x _ {h - p} + a _ {h}.
$$

Letting $y _ { h } = \phi _ { 1 } x _ { h - 1 } + \cdot \cdot \cdot + \phi _ { p } x _ { h - p }$ and $b _ { h } = - a _ { h }$ , the prior equation can be written as

$$
y _ {h} = x _ {h} + b _ {h} = \phi_ {0} x _ {h} + b _ {h},
$$

where $\phi _ { 0 } = 1$

2. For $t = h + 1$ , we have

$$
x _ {h + 1} = \phi_ {1} x _ {h} + \phi_ {2} x _ {h - 1} + \dots + \phi_ {p} x _ {h + 1 - p} + a _ {h + 1}.
$$

Letting $y _ { h + 1 } = x _ { h + 1 } - \phi _ { 2 } x _ { h - 1 } - \cdot \cdot \cdot - \phi _ { p } x _ { h + 1 - p }$ and $b _ { h + 1 } = a _ { h + 1 }$ , the prior equation can be written as

$$
y _ {h + 1} = \phi_ {1} x _ {h} + b _ {h + 1}.
$$

3. In general, for $t = h + j$ with $j = 1 , \dotsc , p$ , we have

$$
x _ {h + j} = \phi_ {1} x _ {h + j - 1} + \dots + \phi_ {j} x _ {h} + \phi_ {j + 1} x _ {h - 1} + \dots + \phi_ {p} x _ {h + j - p} + a _ {h + j}.
$$

Let $y _ { h + j } = x _ { h + j } - \phi _ { 1 } x _ { h + j - 1 } - \cdot \cdot \cdot - \phi _ { j - 1 } x _ { h + 1 } - \phi _ { j + 1 } x _ { h - 1 } - \cdot \cdot \cdot - \phi _ { p } x _ { h + j - p }$ and $b _ { h + j } = a _ { h + j }$ . The prior equation reduces to

$$
y _ {h + j} = \phi_ {j} x _ {h} + b _ {h + j}.
$$

Consequently, for an $\operatorname { A R } ( p )$ model, the missing value $x _ { h }$ is related to the model, and the data in $p + 1$ equations

$$
y _ {h + j} = \phi_ {j} x _ {h} + b _ {h + j}, \quad j = 0, \dots , p, \tag {12.16}
$$

where $\phi _ { 0 } = 1$ . Since a normal distribution is symmetric with respect to its mean, $a _ { h }$ and $- \boldsymbol { a } _ { h }$ have the same distribution. Consequently, Eq. (12.16) is a special simple linear regression model with $p + 1$ data points. The least squares estimate of $x _ { h }$ and its variance are

$$
\widehat {x} _ {h} = \frac {\sum_ {j = 0} ^ {p} \phi_ {j} y _ {h + j}}{\sum_ {j = 0} ^ {p} \phi_ {j} ^ {2}}, \quad \mathrm {V a r} (\widehat {x} _ {h}) = \frac {\sigma^ {2}}{\sum_ {j = 0} ^ {p} \phi_ {j} ^ {2}}.
$$

For instance, when $p = 1$ , we have $\widehat { x } _ { h } = [ \phi _ { 1 } / ( 1 + \phi _ { 1 } ^ { 2 } ) ] ( x _ { h - 1 } + x _ { h + 1 } )$ , which is referred to as the filtered value of $x _ { h }$ . Because a Gaussian AR(1) model is time reversible, equal weights are applied to the two neighboring observations of $x _ { h }$ to obtain the filtered value.

Finally, using Result 1 of Section 12.3, we obtain that the posterior distribution of $x _ { h }$ is normal with mean $\mu _ { * }$ and variance $\sigma _ { * } ^ { 2 }$ , where

$$
\mu_ {*} = \frac {\sigma^ {2} \mu_ {o} + \sigma_ {o} ^ {2} \left(\sum_ {j = 0} ^ {p} \phi_ {j} ^ {2}\right) \widehat {x} _ {h}}{\sigma^ {2} + \sigma_ {o} ^ {2} \left(\sum_ {j = 0} ^ {p} \phi_ {j} ^ {2}\right)}, \quad \sigma_ {*} ^ {2} = \frac {\sigma^ {2} \sigma_ {o} ^ {2}}{\sigma^ {2} + \sigma_ {o} ^ {2} \sum_ {j = 0} ^ {p} \phi_ {j} ^ {2}}. \tag {12.17}
$$

Missing values may occur in patches, resulting in the situation of multiple consecutive missing values. These missing values can be handled in two ways. First, we can generalize the prior method directly to obtain a solution for multiple filtered values. Consider, for instance, the case that $x _ { h }$ and $x _ { h + 1 }$ are missing. These missing values are related to $\{ x _ { h - p } , \ldots , x _ { h - 1 } ; x _ { h + 2 } , \ldots , x _ { h + p + 1 } \}$ . We can define a dependent variable $y _ { h + j }$ in a similar manner as before to set up a multiple linear regression with parameters $x _ { h }$ and $x _ { h + 1 }$ . The least squares method is then used to obtain estimates of $x _ { h }$ and $x _ { h + 1 }$ . Combining with the specified prior distributions, we have a bivariate normal posterior distribution for $( x _ { h } , x _ { h + 1 } ) ^ { \prime }$ . In Gibbs sampling, this approach draws the consecutive missing values jointly. Second, we can apply the result of a single missing value in Eq. (12.17) multiple times within a Gibbs iteration. Again consider the case of missing $x _ { h }$ and $x _ { h + 1 }$ . We can employ the conditional posterior distributions $f ( x _ { h } | X , x _ { h + 1 } , \phi , \sigma ^ { 2 } )$ and $f ( x _ { h + 1 } | X , x _ { h } , \phi , \sigma ^ { 2 } )$

separately. In Gibbs sampling, this means that we draw the missing value one at a time.

Because $x _ { h }$ and $x _ { h + 1 }$ are correlated in a time series, drawing them jointly is preferred in a Gibbs sampling. This is particularly so if the number of consecutive missing values is large. Drawing one missing value at a time works well if the number of missing values is small.

Remark. In the previous discussion, we assumed $h - p \geq 1$ and $h + p \leq n$ If $h$ is close to the end points of the sample period, the number of data points available in the linear regression model must be adjusted. 

# 12.6.2 Outlier Detection

Detection of additive outliers in Eq. (12.14) becomes straightforward under the MCMC framework. Except for the case of a patch of additive outliers with similar magnitudes, the simple Gibbs sampler of McCulloch and Tsay (1994a) seems to work well; see Justel, Pena, and Tsay (2001). Again we use an AR model to ˜ illustrate the problem. The method applies equally well to other time series models when the Metropolis–Hasting algorithm or the Griddy Gibbs is used to draw values of nonlinear parameters.

Assume that the observed time series is $y _ { t }$ , which may contain some additive outliers whose locations and magnitudes are unknown. We write the model for $y _ { t }$ as

$$
y _ {t} = \delta_ {t} \beta_ {t} + x _ {t}, \quad t = 1, \dots , n, \tag {12.18}
$$

where $\{ \delta _ { t } \}$ is a sequence of independent Bernoulli random variables such that $P ( \delta _ { t } = 1 ) = \epsilon$ and $P ( \delta _ { t } = 0 ) = 1 - \epsilon , \epsilon$ is a constant between 0 and 1, $\{ \beta _ { t } \}$ is a sequence of independent random variables from a given distribution, and $x _ { t }$ is an outlier-free $\operatorname { A R } ( p )$ time series,

$$
x _ {t} = \phi_ {0} + \phi_ {1} x _ {t - 1} + \dots + \phi_ {p} x _ {t - p} + a _ {t},
$$

where $\{ a _ { t } \}$ is a Gaussian white noise with mean zero and variance $\sigma ^ { 2 }$ . This model seems complicated, but it allows additive outliers to occur at every time point. The chance of being an outlier for each observation is $\epsilon$ .

Under the model in Eq. (12.18), we have $n$ data points, but there are $2 n + p + 3$ parameters—namely, $\pmb { \phi } = ( \phi _ { 0 } , \ldots , \phi _ { p } ) ^ { \prime }$ , $\boldsymbol { \delta } = ( \delta _ { 1 } , \ldots , \delta _ { n } ) ^ { \prime }$ , $\beta = ( \beta _ { 1 } , \ldots , \beta _ { n } ) ^ { \prime } , \sigma ^ { 2 }$ and $\epsilon$ . The binary parameters $\delta _ { t }$ are governed by $\epsilon$ and the $\beta _ { t }$ are determined by the specified distribution. The parameters $\delta$ and $\beta$ are introduced by using the idea of data augmentation with $\delta _ { t }$ denoting the presence or absence of an additive outlier at time $t$ , and $\beta _ { t }$ is the magnitude of the outlier at time $t$ when it is present.

Assume that the prior distributions are

$$
\boldsymbol {\phi} \sim N (\boldsymbol {\phi} _ {o}, \boldsymbol {\Sigma} _ {o}), \quad \frac {v \lambda}{\sigma^ {2}} \sim \chi_ {v} ^ {2}, \quad \epsilon \sim \operatorname {B e t a} (\gamma_ {1}, \gamma_ {2}), \quad \beta_ {t} \sim N (0, \xi^ {2}),
$$

where the hyperparameters are known. These are conjugate prior distributions. To implement Gibbs sampling for model estimation with outlier detection, we need to consider the conditional posterior distributions of

$$
\begin{array}{l} f (\boldsymbol {\phi} | \boldsymbol {Y}, \boldsymbol {\delta}, \boldsymbol {\beta}, \sigma^ {2}), \quad f (\delta_ {h} | \boldsymbol {Y}, \boldsymbol {\delta} _ {- h}, \boldsymbol {\beta}, \boldsymbol {\phi}, \sigma^ {2}), \quad f (\beta_ {h} | \boldsymbol {Y}, \boldsymbol {\delta}, \boldsymbol {\beta} _ {- h}, \boldsymbol {\phi}, \sigma^ {2}), \\ f (\epsilon | Y, \delta), \quad f (\sigma^ {2} | Y, \phi , \delta , \beta), \\ \end{array}
$$

where $1 \leq h \leq n$ , $Y$ denotes the data and $\pmb { \theta } _ { - i }$ denotes that the $i$ th element of $\pmb \theta$ is removed.

Conditioned on δ and $\beta$ , the outlier-free time series $x _ { t }$ can be obtained by $x _ { t } = y _ { t } - \delta _ { t } \beta _ { t }$ . Information of the data about $\phi$ is then contained in the least squares estimate

$$
\widehat {\boldsymbol {\phi}} = \left(\sum_ {t = p + 1} ^ {n} \boldsymbol {x} _ {t - 1} \boldsymbol {x} _ {t - 1} ^ {\prime}\right) ^ {- 1} \left(\sum_ {t = p + 1} ^ {n} \boldsymbol {x} _ {t - 1} x _ {t}\right),
$$

where $\pmb { x } _ { t - 1 } = ( 1 , x _ { t - 1 } , \ldots , x _ { t - p } ) ^ { \prime }$ , which is normally distributed with mean $\phi$ and covariance matrix

$$
\widehat {\boldsymbol {\Sigma}} = \sigma^ {2} \left(\sum_ {t = p + 1} ^ {n} \boldsymbol {x} _ {t - 1} \boldsymbol {x} _ {t - 1} ^ {\prime}\right) ^ {- 1}.
$$

The conditional posterior distribution of $\phi$ is therefore multivariate normal with mean $\phi _ { * }$ and covariance matrix $\pmb { \Sigma } _ { * }$ , which are given in Eq. (12.9) with $\beta$ being replaced by $\phi$ and $\boldsymbol { x } _ { o , t }$ by $x _ { t - 1 }$ . Similarly, the conditional posterior distribution of $\sigma ^ { 2 }$ is an inverted chi-squared distribution—that is,

$$
\frac {v \lambda + \sum_ {t = p + 1} ^ {n} a _ {t} ^ {2}}{\sigma^ {2}} \sim \chi_ {v + (n - p)} ^ {2},
$$

where $a _ { t } = x _ { t } - \phi ^ { \prime } x _ { t - 1 }$ and $x _ { t } = y _ { t } - \delta _ { t } \beta _ { t }$ .

only related to The conditional posterior distribution of $\{ y _ { j } , \dot { \beta } _ { j } \} _ { j = h - p } ^ { h + p }$ , $\{ \delta _ { j } \} _ { j = h - p } ^ { h + p }$ h with $\delta _ { h }$ can be obtained as follows. First, $j \neq h , \phi$ , and $\sigma ^ { 2 }$ h . More specifically, $\delta _ { h }$ is we have

$$
x _ {j} = y _ {j} - \delta_ {j} \beta_ {j}, \quad j \neq h.
$$

Second, $x _ { h }$ can assume two possible values: $x _ { h } = y _ { h } - \beta _ { h }$ if $\delta _ { h } = 1$ and $x _ { h } = y _ { h }$ otherwise. Define

$$
w _ {j} = x _ {j} ^ {*} - \phi_ {0} - \phi_ {1} x _ {j - 1} ^ {*} - \dots - \phi_ {p} x _ {j - p} ^ {*}, \quad j = h, \ldots , h + p,
$$

where $x _ { j } ^ { * } = x _ { j }$ if $j \neq h$ and $x _ { h } ^ { * } = y _ { h }$ . The two possible values of $x _ { h }$ give rise to two situations:

• Case I: $\delta _ { h } = 0$ . Here the hth observation is not an outlier and $x _ { h } ^ { * } = y _ { h } = x _ { h }$ . Hence, $w _ { j } = a _ { j }$ for $j = h , \ldots , h + p$ . In other words, we have

$$
w _ {j} \sim N (0, \sigma^ {2}), \quad j = h, \dots , h + p.
$$

• Case II: $\delta _ { h } = 1$ . Now the hth observation is an outlier and $x _ { h } ^ { * } = y _ { h } = x _ { h } + \beta _ { h }$ The $w _ { j }$ defined before is contaminated by $\beta _ { h }$ . In fact, we have

$$
w _ {h} \sim N \left(\beta_ {h}, \sigma^ {2}\right) \quad \text {a n d} \quad w _ {j} \sim N \left(- \phi_ {j - h} \beta_ {h}, \sigma^ {2}\right), \quad j = h + 1, \dots , h + p.
$$

If we define $\psi _ { 0 } = - 1$ and $\psi _ { i } = \phi _ { i }$ for $i = 1 , \ldots , p$ , then we have $w _ { j } \sim$ $N ( - \psi _ { j - h } \beta _ { h } , \sigma ^ { 2 } )$ for $j = h , \ldots , h + p$ .

Based on the prior discussion, we can summarize the situation as follows:

1. Case I: $\delta _ { h } = 0$ with probability $1 - \epsilon$ . In this case, $w _ { j } \sim N ( 0 , \sigma ^ { 2 } )$ for $j =$ $h , \ldots , h + p$ .   
2. Case II: $\delta _ { h } = 1$ with probability $\epsilon$ . Here $w _ { j } \sim N ( - \psi _ { j - h } \beta _ { h } , \sigma ^ { 2 } )$ for $j =$ $h , \ldots , h + p$ .

Since there are $n$ data points, $j$ cannot be greater than $n$ . Let $m = \operatorname* { m i n } ( n , h + p )$ . The posterior distribution of $\delta _ { h }$ is therefore

$$
\begin{array}{l} P \left(\delta_ {h} = 1 \mid Y, \delta_ {- h}, \boldsymbol {\beta}, \phi , \sigma^ {2}\right) \\ = \frac {\epsilon \exp \left[ - \sum_ {j = h} ^ {m} \left(w _ {j} + \psi_ {j - h} \beta_ {h}\right) ^ {2} / \left(2 \sigma^ {2}\right) \right]}{\epsilon \exp \left[ - \sum_ {j = h} ^ {m} \left(w _ {j} + \psi_ {j - h} \beta_ {h}\right) ^ {2} / \left(2 \sigma^ {2}\right) \right] + (1 - \epsilon) \exp \left[ - \sum_ {j = h} ^ {m} w _ {j} ^ {2} / \left(2 \sigma^ {2}\right) \right]}. \tag {12.19} \\ \end{array}
$$

This posterior distribution is simply to compare the weighted values of the likelihood function under the two situations with weight being the probability of each situation.

Finally, the posterior distribution of $\beta _ { h }$ is as follows.

• If $\delta _ { h } = 0$ , then $y _ { h }$ is not an outlier and $\beta _ { h } \sim N ( 0 , \xi ^ { 2 } )$ .   
• If $\delta _ { h } = 1$ , then $y _ { h }$ is contaminated by an outlier with magnitude $\beta _ { h }$ . The variable $w _ { j }$ defined before contains information of $\beta _ { h }$ for $j = h$ , $h + 1 , \ldots , \operatorname* { m i n } ( h + p , n )$ . Specifically, we have $w _ { j } \sim N ( - \psi _ { j - h } \beta _ { h } , \sigma ^ { 2 } )$ for $j = h , h + 1 , \ldots , \operatorname* { m i n } ( h + p , n )$ . The information can be put in a linear regression framework as

$$
w _ {j} = - \psi_ {j - h} \beta_ {h} + a _ {j}, \quad j = h, h + 1, \dots , \min  (h + p, n).
$$

Consequently, the information is embedded in the least squares estimate

$$
\widehat {\beta} _ {h} = \frac {\sum_ {j = h} ^ {m} - \psi_ {j - h} w _ {j}}{\sum_ {j = h} ^ {m} \psi_ {j - h} ^ {2}}, \quad m = \min (h + p, n),
$$

which is normally distributed with mean $\beta _ { h }$ and variance $\sigma ^ { 2 } / \bigl ( \sum _ { j = h } ^ { m } \psi _ { j - h } ^ { 2 } \bigr )$ By Result 1, the posterior distribution of $\beta _ { h }$ =is normal with mean $\beta _ { h } ^ { * }$ −and variance $\sigma _ { h * } ^ { 2 }$ , where

$$
\beta_ {h} ^ {*} = \frac {- \left(\sum_ {j = h} ^ {m} \psi_ {j - h} w _ {j}\right) \xi^ {2}}{\sigma^ {2} + \left(\sum_ {j = h} ^ {m} \psi_ {j - h} ^ {2}\right) \xi^ {2}}, \quad \sigma_ {h *} ^ {2} = \frac {\sigma^ {2} \xi^ {2}}{\sigma^ {2} + \left(\sum_ {j = h} ^ {m} \psi_ {j - h} ^ {2}\right) \xi^ {2}}.
$$

Example 12.2. Consider the weekly change series of U.S. 3-year Treasury constant maturity interest rate from March 18, 1988 to September 10, 1999 for 600 observations. The interest rate is in percentage and is a subseries of the dependent variable $c _ { 3 t }$ of Example 12.1. The time series is shown in Figure 12.2a. If AR models are entertained for the series, the partial autocorrelation function suggests an AR(3) model and we obtain

$$
c _ {3 t} = 0. 2 2 7 c _ {3, t - 1} + 0. 0 0 6 c _ {3, t - 2} + 0. 1 1 4 c _ {3, t - 2} + a _ {t}, \quad \widehat {\sigma} ^ {2} = 0. 0 1 2 8,
$$

where standard errors of the coefficients are 0.041, 0.042, and 0.041, respectively. The Ljung–Box statistics of the residuals show $Q ( 1 2 ) = 1 1 . 4 $ , which is insignificant at the $5 \%$ level.

Next, we apply the Gibbs sampling to estimate the AR(3) model and to detect simultaneously possible additive outliers. The prior distributions used are

$$
\boldsymbol {\phi} \sim N (\mathbf {0}, 0. 2 5 \boldsymbol {I} _ {3}), \quad \frac {v \lambda}{\sigma^ {2}} = \frac {5 \times 0 . 0 0 2 5 6}{\sigma^ {2}} \sim \chi_ {5} ^ {2}, \quad \gamma_ {1} = 5, \quad \gamma_ {2} = 9 5, \quad \xi^ {2} = 0. 1,
$$

where $0 . 0 0 2 5 6 \approx \widehat { \sigma } ^ { 2 } / 5$ and $\xi ^ { 2 } \approx 9 \widehat { \sigma } ^ { 2 }$ . The expected number of additive outliers is $5 \%$ . Using initial values $\epsilon = 0 . 0 5$ , $\sigma ^ { 2 } = 0 . 0 1 2$ , $\phi _ { 1 } = 0 . 2$ , $\phi _ { 2 } = 0 . 0 2$ , and $\phi _ { 3 } = 0 . 1$ , we run the Gibbs sampling for 1050 iterations but discard results of the first 50 iterations. Using posterior means of the coefficients as parameter estimates, we obtain the fitted model

$$
c _ {3 t} = 0. 2 5 2 c _ {3, t - 1} + 0. 0 0 3 c _ {3, t - 2} + 0. 1 1 0 c _ {3, t - 2} + a _ {t}, \quad \widehat {\sigma} ^ {2} = 0. 0 1 1 8,
$$

where posterior standard deviations of the parameters are 0.046, 0.045, 0.046, and 0.0008, respectively. Thus, the Gibbs sampling produces results similar to that of the maximum likelihood method. Figure 12.2b shows the time plot of posterior probability of each observation being an additive outlier, and Figure 12.2c plots the posterior mean of outlier magnitude. From the probability plot, some observations have high probabilities of being an outlier. In particular, $t = 3 2 3$ has a probability of 0.83 and the associated posterior mean of outlier magnitude is $- 0 . 3 0 4$ . This point corresponds to May 20, 1994 when the $c _ { 3 t }$ changed from 0.24 to $- 0 . 3 4$ (i.e., about a $0 . 6 \%$ drop in the weekly interest rate within two weeks). The point with second highest posterior probability of being an outlier is $t = 2 0 1$ , which is January 17, 1992. The outlying posterior probability is 0.58 and the estimated outlier size is 0.176. At this particular time point, $c _ { 3 t }$ changed from $- 0 . 0 2$ to 0.33, corresponding to a jump of about $0 . 3 5 \%$ in the weekly interest rate.

Remark. Outlier detection via Gibbs sampling requires intensive computation, but the approach performs a joint estimation of model parameters and outliers. Yet the traditional approach to outlier detection separates estimation from detection. It is much faster in computation but may produce spurious detections when multiple outliers are present. For the data in Example 12.2, the SCA program also identifies $t = 3 2 3$ and $t = 2 0 1$ as the two most significant additive outliers. The estimated outlier sizes are $- 0 . 3 9$ and 0.36, respectively. 

![](images/a6fc1ca795153234d6e0d31263a75af00355a040643e7b42de444ad49e3e7733.jpg)

![](images/bc848e2069a5e86f4eba0f677f695593ba5a7e0c72d55bee10c31e68d13357dd.jpg)

![](images/402d89149334f8b2a6877b35f22c2649584ae433b46342a1882cb6c62054c274.jpg)  
Figure 12.2. Time plots of weekly change series of U.S. 3-year Treasury constant maturity interest rate from March 18, 1988 to September 10, 1999: (a) the data, (b) the posterior probability of being an outlier, and (c) the posterior mean of outlier size. The estimation is based on a Gibbs sampling with 1050 iterations with the first 50 iterations as burn-ins.

# 12.7 STOCHASTIC VOLATILITY MODELS

An important financial application of MCMC methods is the estimation of stochastic volatility models; see Jacquier, Polson, and Rossi (1994) and the references therein. We start with a univariate stochastic volatility model. The mean and volatility equations of an asset return $r _ { t }$ are

$$
r _ {t} = \beta_ {0} + \beta_ {1} x _ {1 t} + \dots + \beta_ {p} x _ {p t} + a _ {t}, \quad a _ {t} = \sqrt {h _ {t}} \epsilon_ {t}, \tag {12.20}
$$

$$
\ln h _ {t} = \alpha_ {0} + \alpha_ {1} \ln h _ {t - 1} + v _ {t}, \tag {12.21}
$$

where $\{ x _ { i t } | i = 1 , \ldots , p \}$ are explanatory variables available at time $t - 1$ , the $\beta _ { j }$ are parameters, $\{ \epsilon _ { t } \}$ is a Gaussian white noise sequence with mean 0 and variance 1, $\{ v _ { t } \}$ is also a Gaussian white noise sequence with mean 0 and variance $\sigma _ { v } ^ { 2 }$ , and $\left\{ \epsilon _ { t } \right\}$ and $\{ v _ { t } \}$ are independent. The log transformation is used to ensure that $h _ { t }$ is

positive for all t. The explanatory variables $x _ { i t }$ may include lagged values of the return (e.g., $x _ { i t } = r _ { t - i }$ ). In Eq. (12.21), we assume that $| \alpha _ { 1 } | < 1$ so that the log volatility process $\ln h _ { t }$ is stationary. If necessary, a higher order $\operatorname { A R } ( p )$ model can be used for $\ln h _ { t }$ .

Denote the coefficient vector of the mean equation by $\beta = ( \beta _ { 0 } , \beta _ { 1 } , . . . , \beta _ { p } ) ^ { \prime }$ and the parameter vector of the volatility equation by ${ \pmb \omega } = ( \alpha _ { 0 } , \alpha _ { 1 } , \sigma _ { v } ^ { 2 } ) ^ { \prime }$ . Suppose that $\pmb { R } = ( r _ { 1 } , \ldots , r _ { n } ) ^ { \prime }$ is the collection of observed returns and $X$ is the collection of explanatory variables. Let $\pmb { H } = ( h _ { 1 } , \ldots , h _ { n } ) ^ { \prime }$ be the vector of unobservable volatilities. Here $\beta$ and $\omega$ are the “traditional” parameters of the model and $\pmb { H }$ is an auxiliary variable. Estimation of the model would be complicated via the maximum likelihood method because the likelihood function is a mixture over the $n$ -dimensional $\pmb { H }$ distribution as

$$
f (\boldsymbol {R} | \boldsymbol {X}, \boldsymbol {\beta}, \omega) = \int f (\boldsymbol {R} | \boldsymbol {X}, \boldsymbol {\beta}, \boldsymbol {H}) f (\boldsymbol {H} | \omega) d \boldsymbol {H}.
$$

However, under the Bayesian framework, the volatility vector $\pmb { H }$ consists of augmented parameters. Conditioning on $\pmb { H }$ , we can focus on the probability distribution functions $f ( R | H , \beta )$ and $f ( H | \omega )$ and the prior distribution $p ( \beta , \omega )$ . We assume that the prior distribution can be partitioned as $p ( \beta , \omega ) = p ( \beta ) p ( \omega )$ ; that is, prior distributions for the mean and volatility equations are independent. A Gibbs sampling approach to estimating the stochastic volatility in Eqs. (12.20) and (12.21) then involves drawing random samples from the following conditional posterior distributions:

$$
f (\boldsymbol {\beta} | \boldsymbol {R}, \boldsymbol {X}, \boldsymbol {H}, \omega), \quad f (\boldsymbol {H} | \boldsymbol {R}, \boldsymbol {X}, \boldsymbol {\beta}, \omega), \quad f (\omega | \boldsymbol {R}, \boldsymbol {X}, \boldsymbol {\beta}, \boldsymbol {H}).
$$

In what follows, we give details of practical implementation of the Gibbs sampling used.

# 12.7.1 Estimation of Univariate Models

Given $\pmb { H }$ , the mean equation in (12.20) is a nonhomogeneous linear regression. Dividing the equation by $\sqrt { h } _ { t }$ , we can write the model as

$$
r _ {o, t} = \boldsymbol {x} _ {o, t} ^ {\prime} \boldsymbol {\beta} + \epsilon_ {t}, \quad t = 1, \dots , n, \tag {12.22}
$$

where $r _ { o , t } = r _ { t } / \sqrt { h } _ { t }$ and $\pmb { x } _ { o , t } = \pmb { x } _ { t } / \sqrt { h _ { t } }$ , with $\pmb { x } _ { t } = ( 1 , x _ { 1 t } , \ldots , x _ { p t } ) ^ { \prime }$ being the vector of explanatory variables. Suppose that the prior distribution of $\beta$ is multivariate normal with mean $\beta _ { o }$ and covariance matrix $A _ { o }$ . Then the posterior distribution of $\beta$ is also multivariate normal with mean $\beta _ { * }$ and covariance matrix $A _ { * }$ . These two quantities can be obtained as before via Result 1a and they are

$$
A _ {*} ^ {- 1} = \sum_ {t = 1} ^ {n} \boldsymbol {x} _ {o, t} \boldsymbol {x} _ {o, t} ^ {\prime} + A _ {o} ^ {- 1}, \quad \boldsymbol {\beta} _ {*} = A _ {*} \left(\sum_ {t = 1} ^ {n} \boldsymbol {x} _ {o, t} r _ {o, t} + A _ {o} ^ {- 1} \boldsymbol {\beta} _ {o}\right),
$$

where it is understood that the summation starts with $p + 1$ if $r _ { t - p }$ is the highest lagged return used in the explanatory variables.

The volatility vector $\pmb { H }$ is drawn element by element. The necessary conditional posterior distribution is $f ( h _ { t } | R , X , H _ { - t } , \beta , \omega )$ , which is produced by the normal distribution of $a _ { t }$ and the lognormal distribution of the volatility,

$$
\begin{array}{l} f (h _ {t} | \boldsymbol {R}, \boldsymbol {X}, \boldsymbol {\beta}, \boldsymbol {H} _ {- t}, \boldsymbol {\omega}) \\ \propto f \left(a _ {t} \mid h _ {t}, r _ {t}, \boldsymbol {x} _ {t}, \boldsymbol {\beta}\right) f \left(h _ {t} \mid h _ {t - 1}, \omega\right) f \left(h _ {t + 1} \mid h _ {t}, \omega\right) \\ \propto h _ {t} ^ {- 0. 5} \exp \left[ - \left(r _ {t} - x _ {t} ^ {\prime} \boldsymbol {\beta}\right) ^ {2} / \left(2 h _ {t}\right) \right] h _ {t} ^ {- 1} \exp \left[ - \left(\ln h _ {t} - \mu_ {t}\right) ^ {2} / \left(2 \sigma^ {2}\right) \right] \\ \propto h _ {t} ^ {- 1. 5} \exp \left[ - \left(r _ {t} - \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta}\right) ^ {2} / \left(2 h _ {t}\right) - \left(\ln h _ {t} - \mu_ {t}\right) ^ {2} / \left(2 \sigma^ {2}\right) \right], \tag {12.23} \\ \end{array}
$$

where $\mu _ { t } = [ \alpha _ { 0 } ( 1 - \alpha _ { 1 } ) + \alpha _ { 1 } ( \ln h _ { t + 1 } + \ln h _ { t - 1 } ) ] / ( 1 + \alpha _ { 1 } ^ { 2 } )$ and $\sigma ^ { 2 } = \sigma _ { v } ^ { 2 } / ( 1 + \alpha _ { 1 } ^ { 2 } )$ Here we have used the following properties: (a) $a _ { t } | h _ { t } \sim N ( 0 , h _ { t } )$ ; (b) $\ln h _ { t } | \ln h _ { t - 1 } \sim N ( \alpha _ { 0 } + \alpha _ { 1 } \ln h _ { t - 1 } , \sigma _ { v } ^ { 2 } )$ ; (c) $\ln h _ { t + 1 } | \ln h _ { t } \sim N ( \alpha _ { 0 } + \alpha _ { 1 } \ln h _ { t } , \sigma _ { v } ^ { 2 } )$ (d) $d \ln h _ { t } = h _ { t } ^ { - 1 } d h _ { t }$ , where $d$ denotes differentiation; and (e) the equality

$$
(x - a) ^ {2} A + (x - b) ^ {2} C = (x - c) ^ {2} (A + C) + (a - b) ^ {2} A C / (A + C),
$$

where $c = ( A a + C b ) / ( A + C )$ provided that $A + C \ne 0$ . This equality is a scalar version of Lemma 1 of Box and Tiao (1973, p. 418). In our application, $A = 1$ , $a = \alpha _ { 0 } + \ln h _ { t - 1 }$ , $C = \alpha _ { 1 } ^ { 2 }$ , and $b = ( \ln h _ { t + 1 } - \alpha _ { 0 } ) / \alpha _ { 1 }$ . The term $( a - b ) ^ { 2 } A C / ( A +$ C) does not contain the random variable $h _ { t }$ and, hence, is integrated out in the derivation of the conditional posterior distribution. Jacquier, Polson, and Rossi (1994) use the Metropolis algorithm to draw $h _ { t }$ . We use Griddy Gibbs in this section, and the range of $h _ { t }$ is chosen to be a multiple of the unconditional sample variance of $r _ { t }$ .

To draw random samples of $\omega$ , we partition the parameters as ${ \pmb { \alpha } } = ( \alpha _ { 0 } , \alpha _ { 1 } ) ^ { \prime }$ and $\sigma _ { v } ^ { 2 }$ . The prior distribution of $\omega$ is also partitioned accordingly (i.e., $p ( \omega ) =$ $p ( \pmb { \alpha } ) p ( \sigma _ { v } ^ { 2 } ) )$ . The conditional posterior distributions needed are

• $f ( \alpha | Y , X , H , \beta , \sigma _ { v } ^ { 2 } ) = f ( \alpha | H , \sigma _ { v } ^ { 2 } )$ : Given H , $\ln h _ { t }$ follows an AR(1) model. Therefore, the result of AR models discussed in the previous two sections applies. Specifically, if the prior distribution of $\pmb { \alpha }$ is multivariate normal with mean $\pmb { \alpha } _ { o }$ and covariance matrix $C _ { o }$ , then $f ( \alpha | H , \sigma _ { v } ^ { 2 } )$ is multivariate normal with mean $\pmb { \alpha } _ { \ast }$ and covariance matrix $c _ { * }$ , where

$$
\boldsymbol {C} _ {*} ^ {- 1} = \frac {\sum_ {t = 2} ^ {n} z _ {t} \boldsymbol {z} _ {t} ^ {\prime}}{\sigma_ {v} ^ {2}} + \boldsymbol {C} _ {o} ^ {- 1}, \quad \boldsymbol {\alpha} _ {*} = \boldsymbol {C} _ {*} \left(\frac {\sum_ {t = 2} ^ {n} z _ {t} \ln h _ {t}}{\sigma_ {v} ^ {2}} + \boldsymbol {C} _ {o} ^ {- 1} \boldsymbol {\alpha} _ {o}\right),
$$

where $z _ { t } = ( 1 , \ln h _ { t - 1 } ) ^ { \prime }$

• $f ( \sigma _ { v } ^ { 2 } | Y , X , H , \beta , \alpha ) = f ( \sigma _ { v } ^ { 2 } | H , \alpha )$ : Given $\pmb { H }$ and $\pmb { \alpha }$ , we can calculate $v _ { t } =$ $\ln h _ { t } - \alpha _ { 0 } - \alpha _ { 1 } \ln h _ { t - 1 }$ for $t = 2 , \ldots , n$ . Therefore, if the prior distribution of $\sigma _ { v } ^ { 2 }$ is $( m \lambda ) / \sigma _ { v } ^ { 2 } \sim \chi _ { m } ^ { 2 }$ , then the conditional posterior distribution of $\sigma _ { v } ^ { 2 }$ is an inverted chi-squared distribution with $m + n - 1$ degrees of freedom; that is,

$$
\frac {m \lambda + \sum_ {t = 2} ^ {n} v _ {t} ^ {2}}{\sigma_ {v} ^ {2}} \sim \chi_ {m + n - 1} ^ {2}.
$$

Remark. Formula (12.23) is for $1 < t < n$ , where $n$ is the sample size. For the two end data points $h _ { 1 }$ and $h _ { n }$ , some modifications are needed. A simple approach is to assume that $h _ { 1 }$ is fixed so that the drawing of $h _ { t }$ starts with $t = 2$ . For $t = n$ , one uses the result $\ln h _ { n } \sim ( \alpha _ { 0 } + \alpha _ { 1 } \ln h _ { n - 1 } , \sigma _ { v } ^ { 2 } )$ . Alternatively, one can employ a forecast of $h _ { n + 1 }$ and a backward prediction of $h _ { 0 }$ and continue to apply the formula. Since $h _ { n }$ is the variable of interest, we forecast $h _ { n + 1 }$ by using a 2-step ahead forecast at the forecast origin $n - 1$ . For the model in Eq. (12.21), the forecast of $h _ { n + 1 }$ is

$$
\widehat {h} _ {n - 1} (2) = \alpha_ {0} + \alpha_ {1} (\alpha_ {0} + \alpha_ {1} \ln h _ {n - 1}).
$$

The backward prediction of $h _ { 0 }$ is based on the time reversibility of the model

$$
\left(\ln h _ {t} - \eta\right) = \alpha_ {1} \left(\ln h _ {t - 1} - \eta\right) + v _ {t},
$$

where $\eta = \alpha _ { 0 } / ( 1 - \alpha _ { 1 } )$ and $| \alpha _ { 1 } | < 1$ . The model of the reversed series is

$$
\left(\ln h _ {t} - \eta\right) = \alpha_ {1} \left(\ln h _ {t + 1} - \eta\right) + v _ {t} ^ {*},
$$

where $\{ v _ { t } ^ { * } \}$ is also a Gaussian white noise series with mean zero and variance $\sigma _ { v } ^ { 2 }$ . Consequently, the 2-step backward prediction of $h _ { 0 }$ at time $t = 2$ is

$$
\widehat {h} _ {2} (- 2) = \alpha_ {1} ^ {2} (\ln h _ {2} - \eta).
$$

Remark. Formula (12.23) can also be obtained by using results of a missing value in an AR(1) model; see Section 12.6.1. Specifically, assume that $\ln h _ { t }$ is missing. For the AR(1) model in Eq. (12.21), this missing value is related to $\ln h _ { t - 1 }$ and $\ln h _ { t + 1 }$ for $1 < t < n$ . From the model, we have

$$
\ln h _ {t} = \alpha_ {0} + \alpha_ {1} \ln h _ {t - 1} + a _ {t}.
$$

Define $y _ { t } = \alpha _ { 0 } + \alpha _ { 1 } y _ { t - 1 }$ , $x _ { t } = 1$ , and $b _ { t } = - a _ { t }$ . Then we obtain

$$
y _ {t} = x _ {t} \ln h _ {t} + b _ {t}. \tag {12.24}
$$

Next, from

$$
\ln h _ {t + 1} = \alpha_ {0} + \alpha_ {1} \ln h _ {t} + a _ {t + 1},
$$

we define $y _ { t + 1 } = \ln h _ { t + 1 } - \alpha _ { 0 }$ , $x _ { t + 1 } = \alpha _ { 1 }$ , and $b _ { t + 1 } = a _ { t + 1 }$ and obtain

$$
y _ {t + 1} = x _ {t + 1} \ln h _ {t + 1} + b _ {t + 1}. \tag {12.25}
$$

Now Eqs. (12.24) and (12.25) form a special simple linear regression with two observations and an unknown parameter $\ln h _ { t }$ . Note that $b _ { t }$ and $b _ { t + 1 }$ have the same distribution because $- { a } _ { t }$ is also $N ( 0 , \sigma _ { v } ^ { 2 } )$ . The least squares estimate of $\ln h _ { t }$ is then

$$
\widehat {\ln h _ {t}} = \frac {x _ {t} y _ {t} + x _ {t + 1} y _ {t + 1}}{x _ {t} ^ {2} + x _ {t + 1} ^ {2}} = \frac {\alpha_ {0} (1 - \alpha_ {1}) + \alpha_ {1} (\ln h _ {t + 1} + \ln h _ {t - 1})}{1 + \alpha_ {1} ^ {2}},
$$

which is precisely the conditional mean of $\ln h _ { t }$ given in Eq. (12.23). In addition, this estimate is normally distributed with mean $\ln h _ { t }$ and variance $\sigma _ { v } ^ { 2 } / ( 1 + \alpha _ { 1 } ^ { 2 } )$ . Formula (12.23) is simply the product of $a _ { t } \sim N ( 0 , h _ { t } )$ and $\widehat { \ln h _ { t } } \sim \dot { N } [ \ln h _ { t }$ , $\sigma _ { v } ^ { 2 } / ( 1 +$ $\alpha _ { 1 } ^ { 2 } ) ]$ with the transformation $d \ln h _ { t } = h _ { t } ^ { - 1 } d h _ { t }$ . This regression approach generalizes easily to other $\operatorname { A R } ( p )$ models for $\ln h _ { t }$ . We use this approach and assume that $\{ h _ { t } \} _ { t = 1 } ^ { p }$ are fixed for a stochastic volatility $\operatorname { A R } ( p )$ model. 

Remark. Starting value of $h _ { t }$ can be obtained by fitting a volatility model of Chapter 3 to the return series. 

Example 12.3. Consider the monthly log returns of the S&P 500 index from January 1962 to December 1999 for 456 observations. Figure 12.3 shows the time plot of the return measured in percentage. If GARCH models are entertained for the series, we obtain a Gaussian GARCH(1,1) model

$$
r _ {t} = 0. 6 5 8 + a _ {t}, \quad a _ {t} = \sqrt {h _ {t}} \epsilon_ {t},
$$

$$
h _ {t} = 3. 3 4 9 + 0. 0 8 6 a _ {t - 1} ^ {2} + 0. 7 3 5 h _ {t - 1}, \tag {12.26}
$$

where $t$ -ratios of the coefficients are all greater than 2.52. The Ljung–Box statistics of the standardized residuals and their squared series fail to indicate any model inadequacy.

![](images/b584afaf2d8fd2b52d5259f725ccf6626c95a5a69466f151647663c4586f5d31.jpg)  
Figure 12.3. Time plot of monthly log returns of the S&P 500 index from 1962 to 1999.

Next, consider the stochastic volatility model

$$
r _ {t} = \mu + a _ {t}, \quad a _ {t} = \sqrt {h _ {t}} \epsilon_ {t},
$$

$$
\ln h _ {t} = \alpha_ {0} + \alpha_ {1} \ln h _ {t - 1} + v _ {t}, \tag {12.27}
$$

where the $v _ { t }$ are iid $N ( 0 , \sigma _ { v } ^ { 2 } )$ . To implement the Gibbs sampling, we use the prior distributions

$$
\mu \sim N (0, 9), \quad \boldsymbol {\alpha} \sim N [ \boldsymbol {\alpha} _ {o}, \operatorname {d i a g} (0. 0 9, 0. 0 4) ], \quad \frac {5 \times 0 . 2}{\sigma_ {v} ^ {2}} \sim \chi_ {5} ^ {2},
$$

where $\pmb { \alpha } _ { o } = ( 0 . 4 , 0 . 8 ) ^ { \prime } .$ For initial parameter values, we use the fitted values of the GARCH(1,1) model in Eq. (12.26) for $\{ h _ { t } \}$ and set $\sigma _ { v } ^ { 2 } = 0 . 5$ and $\mu = 0 . 6 6$ , which is the sample mean. In addition, $h _ { t }$ is drawn by using the Griddy Gibbs with 500 grid points and the range of $h _ { t }$ is $( 0 , 1 . 5 s ^ { 2 } )$ , where $s ^ { 2 }$ is the sample variance of the log return $r _ { t }$ .

We ran the Gibbs sampling for 5100 iterations but discarded results of the first 100 iterations. Figure 12.4 shows the density functions of the prior and posterior distributions of the four coefficient parameters. The prior distributions used are relatively noninformative. The posterior distributions are concentrated especially for $\mu$ and $\sigma _ { v } ^ { 2 }$ . Figure 12.5 shows the time plots of fitted volatilities. The upper panel shows the posterior mean of $h _ { t }$ over the 5000 iterations for each time point

![](images/8821e160ce69cbb5b5bfbc6adf002fc9b1ebd5c1f308432846feab8b06b2d5a0.jpg)

![](images/9af419a3329902d3b3ab300ddfc1000f1f695fc7f81b18d24f21df092d335789.jpg)

![](images/c89d8783e792488d69d04e75d99ef5c5bda1db9c879c344ff3c9a9489e925c78.jpg)

![](images/6c9b0b606a22a17c1831ded3ce602cf676ebab8abae8e4b1370f0e8b07f97061.jpg)  
Figure 12.4. Density functions of prior and posterior distributions of parameters in a stochastic volatility model for the monthly log returns of the S&P 500 index. The dashed line denotes prior density and the solid line the posterior density, which is based on results of Gibbs sampling with 5000 iterations. See the text for more details.

![](images/f48acb3a6b12dfc359d8ea93809490b7557f92cb0d2a6302dcfc24e4cdfc3df8.jpg)

![](images/7d9d7d1179c6f8fe5419e9f6240b416bda328d620a027d987f61111f5fec56d5.jpg)  
Figure 12.5. Time plots of fitted volatilities for monthly log returns of the S&P 500 index from 1962 to 1999. The upper panel shows the posterior means of a Gibbs sampler with 5000 iterations. The lower panel shows the results of a GARCH(1,1) model.

whereas the lower panel shows the fitted values of the GARCH(1,1) model in Eq. (12.26). The two plots exhibit a similar pattern.

The posterior mean and standard error of the four coefficients are as follows:

<table><tr><td>Parameter</td><td>μ</td><td>α0</td><td>α1</td><td>σv2</td></tr><tr><td>Mean</td><td>0.836</td><td>0.831</td><td>0.685</td><td>0.265</td></tr><tr><td>Standard error</td><td>0.177</td><td>0.183</td><td>0.069</td><td>0.056</td></tr></table>

The posterior mean of $\alpha _ { 1 }$ is 0.685, which is smaller than that obtained by Jacquier, Polson, and Rossi (1994) who used daily returns of the S&P 500 index. But it confirms the strong serial dependence in the volatility series. Finally, we have used different initial values and 3100 iterations for another Gibbs sampler; the posterior means of the parameters change slightly, but the series of posterior means of $h _ { t }$ are stable.

# 12.7.2 Multivariate Stochastic Volatility Models

In this subsection, we study multivariate stochastic volatility models using the Cholesky decomposition of Chapter 10. We focus on the bivariate case, but the methods discussed also apply to the higher dimensional case. Based on the Cholesky decomposition, the innovation $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \mathbf \Psi \Psi \mathbf \Psi $ of a return series $r _ { t }$ is transformed into $\mathbf { } _ { \pmb { b } _ { t } }$ such that

$$
b _ {1 t} = a _ {1 t}, \quad b _ {2 t} = a _ {2 t} - q _ {2 1, t} b _ {1 t},
$$

where $b _ { 2 t }$ and $q _ { 2 1 , t }$ can be interpreted as the residual and least squares estimate of the linear regression

$$
a _ {2 t} = q _ {2 1, t} a _ {1 t} + b _ {2 t}.
$$

The conditional covariance matrix of $\pmb { a } _ { t }$ is parameterized by $\{ g _ { 1 1 , t } , g _ { 2 2 , t } \}$ and $\{ q _ { 2 1 , t } \}$ as

$$
\left[ \begin{array}{l l} \sigma_ {1 1, t} & \sigma_ {1 2, t} \\ \sigma_ {2 1, t} & \sigma_ {2 2, t} \end{array} \right] = \left[ \begin{array}{c c} 1 & 0 \\ q _ {2 1, t} & 1 \end{array} \right] \left[ \begin{array}{c c} g _ {1 1, t} & 0 \\ 0 & g _ {2 2, t} \end{array} \right] \left[ \begin{array}{l l} 1 & q _ {2 1, t} \\ 0 & 1 \end{array} \right], \tag {12.28}
$$

where $g _ { i i , t } = \mathrm { V a r } ( b _ { i t } | F _ { t - 1 } )$ and $b _ { 1 t } \perp b _ { 2 t }$ . Thus, the quantities of interest are $g _ { 1 1 , t }$ , $g _ { 2 2 , t }$ , and $q _ { 2 1 , t }$ .

A simple bivariate stochastic volatility model for the return $\pmb { r } _ { t } = ( r _ { 1 t } , r _ { 2 t } ) ^ { \prime }$ is as follows:

$$
\boldsymbol {r} _ {t} = \boldsymbol {\beta} _ {0} + \boldsymbol {\beta} _ {1} \boldsymbol {x} _ {t} + \boldsymbol {a} _ {t}, \tag {12.29}
$$

$$
\ln g _ {i i, t} = \alpha_ {i 0} + \alpha_ {i 1} \ln g _ {i i, t - 1} + v _ {i t}, \quad i = 1, 2, \tag {12.30}
$$

$$
q _ {2 1, t} = \gamma_ {0} + \gamma_ {1} q _ {2 1, t - 1} + u _ {t}, \tag {12.31}
$$

where $\left\{ \pmb { a } _ { t } \right\}$ is a sequence of serially uncorrelated Gaussian random vectors with mean zero and conditional covariance matrix $\Sigma _ { t }$ given by Eq. (12.28), $\beta _ { 0 }$ is a two-dimensional constant vector, $\boldsymbol { x } _ { t }$ denotes the explanatory variables, and $\{ v _ { 1 t } \}$ , $\{ v _ { 2 t } \}$ , and $\left\{ u _ { t } \right\}$ are three independent Gaussian white noise series such that $\mathrm { V a r } ( v _ { i t } )$ $= \sigma _ { i v } ^ { 2 }$ and $\mathrm { V a r } ( u _ { t } ) = \sigma _ { u } ^ { 2 }$ . Again log transformation is used in Eq. (12.30) to ensure the positiveness of $g _ { i i , t }$ .

Let $\begin{array} { r } { \pmb { G } _ { i } = ( g _ { i i , 1 } , \ldots , g _ { i i , n } ) ^ { \prime } , \ \pmb { G } = [ \pmb { G } _ { 1 } , \pmb { G } _ { 2 } ] , } \end{array}$ $\pmb { G } = [ \pmb { G } _ { 1 } , \pmb { G } _ { 2 } ]$ , and $\pmb { \mathcal { Q } } = ( q _ { 2 1 , 1 } , \dotsc , q _ { 2 1 , n } ) ^ { \prime }$ . The “traditional” parameters of the model in Eqs. (12.29)– (12.31) are $\pmb { \beta } = ( \pmb { \beta } _ { 0 } , \pmb { \beta } _ { 1 } )$ , $\pmb { \omega } _ { i } = ( \alpha _ { i 0 } , \alpha _ { i 1 } , \sigma _ { i v } ^ { 2 } )$ for i = 1, 2, and $\gamma = ( \gamma _ { 0 } , \gamma _ { 1 } , \sigma _ { u } ^ { 2 } )$ . The augmented parameters are $\varrho$ , $G _ { 1 }$ , and $G _ { 2 }$ . To estimate such a bivariate stochastic volatility model via Gibbs sampling, we use results of the univariate model in the previous subsection and two additional conditional posterior distributions. Specifically, we can draw random samples of:

1. $\beta _ { 0 }$ and $\beta _ { 1 }$ row by row using the result (12.22);   
2. $g _ { 1 1 , t }$ using Eq. (12.23) with $a _ { t }$ being replaced by $a _ { 1 t }$   
3. $\omega _ { \mathrm { l } }$ using exactly the same methods as those of the univariate case with $a _ { t }$ replaced by $a _ { 1 t }$ .

To draw random samples of $\omega _ { 2 }$ and $g _ { 2 2 , t }$ , we need to compute $b _ { 2 t }$ . But this is easy because $b _ { 2 t } = a _ { 2 t } - q _ { 2 1 , t } a _ { 1 t }$ given the augmented parameter vector $\varrho$ . Furthermore, $b _ { 2 t }$ is normally distributed with mean 0 and conditional variance $g _ { 2 2 , t }$ .

It remains to consider the conditional posterior distributions

$$
f (\varpi | \boldsymbol {Q}, \sigma_ {u} ^ {2}), \quad f (\sigma_ {u} ^ {2} | \boldsymbol {Q}, \varpi), \quad f (q _ {2 1, t} | \boldsymbol {A}, \boldsymbol {G}, \boldsymbol {Q} _ {- t}, \boldsymbol {\gamma}),
$$

where $\pmb { \varpi } = ( \gamma _ { 0 } , \gamma _ { 1 } ) ^ { \prime }$ is the coefficient vector of Eq. (12.31) and $A$ denotes the collection of $\mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf { } \mathbf \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \Psi \mathbf \Psi \mathbf \Psi \Psi \mathbf \mathbf \Psi \Psi \mathbf \Psi $ , which is known if $R , X , \beta _ { 0 }$ , and $\beta _ { 1 }$ are given. Given $\varrho$ and $\sigma _ { u } ^ { 2 }$ , model

(12.31) is a simple Gaussian AR(1) model. Therefore, if the prior distribution of $\mathbf { \omega } _ { \varpi }$ is bivariate normal with mean $\varpi _ { o }$ and covariance matrix $\scriptstyle D _ { o }$ , then the conditional posterior distribution of $\mathbf { \omega } _ { \varpi }$ is also bivariate normal with mean $\varpi _ { * }$ and covariance matrix $\pmb { { D } } _ { \ast }$ , where

$$
\pmb {D} _ {*} ^ {- 1} = \frac {\sum_ {t = 2} ^ {n} z _ {t} z _ {t} ^ {\prime}}{\sigma_ {u} ^ {2}} + \pmb {D} _ {o} ^ {- 1}, \quad \pmb {\varpi} _ {*} = \pmb {D} _ {*} \left(\frac {\sum_ {t = 2} ^ {n} z _ {t} q _ {2 1 , t}}{\sigma_ {u} ^ {2}} + \pmb {D} _ {o} ^ {- 1} \pmb {\varpi} _ {o}\right),
$$

where $z _ { t } = ( 1 , q _ { 2 1 , t - 1 } ) ^ { \prime }$ . Similarly, if the prior distribution of $\sigma _ { u } ^ { 2 }$ is $( m \lambda ) / \sigma _ { u } ^ { 2 } \sim \chi _ { m } ^ { 2 }$ then the conditional posterior distribution of $\sigma _ { u } ^ { 2 }$ is

$$
\frac {m \lambda + \sum_ {t = 2} ^ {n} u _ {t} ^ {2}}{\sigma_ {u} ^ {2}} \sim \chi_ {m + n - 1} ^ {2},
$$

where $u _ { t } = q _ { 2 1 , t } - \gamma _ { 0 } - \gamma _ { 1 } q _ { 2 1 , t - 1 }$ . Finally,

$$
\begin{array}{l} f (q _ {2 1, t} | \boldsymbol {A}, \boldsymbol {G}, \boldsymbol {Q} _ {- t}, \sigma_ {u} ^ {2}, \varpi) \\ \propto f \left(\boldsymbol {b} _ {2 t} \mid g _ {2 2, t}\right) f \left(q _ {2 1, t} \mid q _ {2 1, t - 1}, \varpi , \sigma_ {u} ^ {2}\right) f \left(q _ {2 1, t + 1} \mid q _ {2 1, t}, \varpi , \sigma_ {u} ^ {2}\right) \\ \propto g _ {2 2, t} ^ {- 0. 5} \exp \left[ - \left(a _ {2 t} - q _ {2 1, t} a _ {1 t}\right) ^ {2} / \left(2 g _ {2 2, t}\right) \right] \exp \left[ - \left(q _ {2 1, t} - \mu_ {t}\right) ^ {2} \left(2 \sigma^ {2}\right) \right], \tag {12.32} \\ \end{array}
$$

where $\mu _ { t } = [ \gamma _ { 0 } ( 1 - \gamma _ { 1 } ) + \gamma _ { 1 } ( q _ { 2 1 , t - 1 } + q _ { 2 1 , t + 1 } ) ] / ( 1 + \gamma _ { 1 } ^ { 2 } )$ and $\sigma ^ { 2 } = \sigma _ { u } ^ { 2 } / ( 1 + \gamma _ { 1 } ^ { 2 } )$ . In general, $\mu _ { t }$ and $\sigma ^ { 2 }$ can be obtained by using the results of a missing value in an $\operatorname { A R } ( p )$ process. It turns out that Eq. (12.32) has a closed-form distribution for $q _ { 2 1 , t }$ . Specifically, the first term of Eq. (12.32), which is the conditional distribution of $q _ { 2 1 , t }$ given $g _ { 2 2 , t }$ and $\pmb { a } _ { t }$ , is normal with mean $a _ { 2 t } / a _ { 1 t }$ and variance $g _ { 2 2 , t } / ( a _ { 1 t } ) ^ { 2 }$ . The second term of the equation is also normal with mean $\mu _ { t }$ and variance $\sigma ^ { 2 }$ . Consequently, by Result 1 of Section 12.3, the conditional posterior distribution of $q _ { 2 1 , t }$ is normal with mean $\mu _ { * }$ and variance $\sigma _ { * } ^ { 2 }$ , where

$$
\frac {1}{\sigma_ {*} ^ {2}} = \frac {a _ {1 t} ^ {2}}{g _ {2 2 , t}} + \frac {1 + \gamma_ {1} ^ {2}}{\sigma_ {u} ^ {2}}, \quad \mu_ {*} = \sigma_ {*} ^ {2} \left(\frac {1 + \gamma_ {1} ^ {2}}{\sigma_ {u} ^ {2}} \times \mu_ {t} + \frac {a _ {1 t} ^ {2}}{g _ {2 2 , t}} \times \frac {a _ {2 t}}{a _ {1 t}}\right)
$$

where $\mu _ { t }$ is defined in Eq. (12.32).

Example 12.4. In this example, we study bivariate volatility models for the monthly log returns of IBM stock and the S&P 500 index from January 1962 to December 1999. This is an expanded version of Example 12.3 by adding the IBM returns. Figure 12.6 shows the time plots of the two return series. Let $r _ { t } =$ $( \mathbf { I B M } _ { t } , \mathbf { S P } _ { t } ) ^ { \prime }$ . If time-varying correlation GARCH models with Cholesky decomposition of Chapter 10 are entertained, we obtain the model

$$
\boldsymbol {r} _ {t} = \boldsymbol {\beta} _ {0} + \boldsymbol {a} _ {t}, \tag {12.33}
$$

$$
g _ {1 1, t} = \alpha_ {1 0} + \alpha_ {1 1} g _ {1 1, t - 1} + \alpha_ {1 2} a _ {1, t - 1} ^ {2}, \tag {12.34}
$$

$$
g _ {2 2, t} = \alpha_ {2 0} + \alpha_ {2 1} a _ {1, t - 1} ^ {2}, \tag {12.35}
$$

$$
q _ {2 1, t} = \gamma_ {0}, \tag {12.36}
$$

![](images/5d2bec3cf7d742fa7b7c9b262c107de49dd97caca023fca20508d061dce0e717.jpg)

![](images/7f639e2426041e9e0618e4c620f14dd67c6bf09a806bd24d85ae555edfc386d7.jpg)  
(b) S&P 500 index   
Figure 12.6. Time plots of monthly log returns of (a) IBM stock and (b) the S&P 500 index from 1962 to 1999.

where the estimates and their standard errors are given in Table 12.2(a). For comparison purpose, we employ the same mean equation in Eq. (12.33) and a stochastic volatility model similar to that in Eqs. (12.34) – (12.36). The volatility equations are

$$
\ln g _ {1 1, t} = \alpha_ {1 0} + \alpha_ {1 1} \ln g _ {1 1, t - 1} + v _ {1 t}, \quad \operatorname {V a r} \left(v _ {1 t}\right) = \sigma_ {1 v} ^ {2}, \tag {12.37}
$$

$$
\ln g _ {2 2, t} = \alpha_ {2 0} + v _ {2 t}, \quad \operatorname {V a r} \left(v _ {2 t}\right) = \sigma_ {2 v} ^ {2}, \tag {12.38}
$$

$$
q _ {2 1, t} = \gamma_ {0} + u _ {t}, \quad \operatorname {V a r} \left(u _ {t}\right) = \sigma_ {u} ^ {2}. \tag {12.39}
$$

The prior distributions used are

$$
\beta_ {i 0} \sim N (0. 8, 4), \quad \alpha_ {1} \sim N [ (0. 4, 0. 8) ^ {\prime}, \operatorname {d i a g} (0. 1 6, 0. 0 4) ], \quad \alpha_ {2 0} \sim N (5, 2 5),
$$

$$
\gamma_ {0} \sim N (0. 4,.. 0 4), \quad \frac {1 0 \times 0 . 1}{\sigma_ {1 v} ^ {2}} \sim \chi_ {1 0} ^ {2}, \quad \frac {5 \times 0 . 2}{\sigma_ {2 v} ^ {2}} \sim \chi_ {5} ^ {2}, \quad \frac {5 \times 0 . 2}{\sigma_ {u} ^ {2}} \sim \chi_ {5} ^ {2}.
$$

These prior distributions are relatively noninformative. We ran the Gibbs sampling for 1300 iterations but discarded results of the first 300 iterations. The random samples of $g _ { i i , t }$ were drawn by Griddy Gibbs with 400 grid points in the intervals $[ 0 , 1 . 5 s _ { i } ^ { 2 } ]$ , where $s _ { i } ^ { 2 }$ is the sample variance of the log return $r _ { i t }$ . Posterior means and

Table 12.2. Estimation of Bivariate Volatility Models for Monthly Log Returns of IBM Stock and the S&P 500 Index from January 1962 to December 1999   

<table><tr><td colspan="9">(a) Bivariate GARCH(1,1) Model with Time-Varying Correlations</td></tr><tr><td>Parameter</td><td>β01</td><td>β02</td><td>α10</td><td>α11</td><td>α12</td><td>α20</td><td>α21</td><td>γ0</td></tr><tr><td>Estimate</td><td>1.04</td><td>0.79</td><td>3.16</td><td>0.83</td><td>0.10</td><td>10.59</td><td>0.04</td><td>0.35</td></tr><tr><td>Standard error</td><td>0.31</td><td>0.20</td><td>1.67</td><td>0.08</td><td>0.03</td><td>0.93</td><td>0.02</td><td>0.02</td></tr><tr><td colspan="9">(b) Stochastic Volatility Model</td></tr><tr><td>Parameter</td><td>β01</td><td>β02</td><td>α10</td><td>α11</td><td>σ21v</td><td>α20</td><td>σ22v</td><td>γ0</td></tr><tr><td>Posterior mean</td><td>0.86</td><td>0.84</td><td>0.52</td><td>0.86</td><td>0.08</td><td>1.81</td><td>0.39</td><td>0.39</td></tr><tr><td>Standard error</td><td>0.30</td><td>0.18</td><td>0.18</td><td>0.05</td><td>0.03</td><td>0.11</td><td>0.06</td><td>0.03</td></tr></table>

aThe stochastic volatility models are based on the last 1000 iterations of a Gibbs sampling with 1300 total iterations.

standard errors of the “traditional” parameters of the bivariate stochastic volatility model are given in Table 12.2(b).

To check for convergence of the Gibbs sampling, we ran the procedure several times with different starting values and numbers of iterations. The results are stable. For illustration, Figure 12.7 shows the scatterplots of various quantities for two different Gibbs samples. The first Gibbs sample is based on $3 0 0 + 1 0 0 0$ iterations, and the second Gibbs sample is based on $5 0 0 + 3 0 0 0$ iterations, where $M + N$ denotes that the total number of Gibbs iterations is $M + N$ , but results of the first $M$ iterations are discarded. The scatterplots shown are posterior means of $g _ { 1 1 , t }$ , $g _ { 2 2 , t }$ , $g _ { 2 1 , t }$ , $\sigma _ { 2 2 , t }$ , $\sigma _ { 2 1 , t }$ , and the correlation $\rho _ { 2 1 , t }$ . The line $y = x$ is added to each plot to show the closeness of the posterior means. The stability of the Gibbs sampling results is clearly seen.

It is informative to compare the GARCH model with time-varying correlations in Eqs. (12.33)– (12.36) with the stochastic volatility model. First, as expected, the mean equations of the two models are essentially identical. Second, Figure 12.8 shows the time plots of fitted volatilities for IBM stock return. Figure 12.8a is for the GARCH model, and Figure 12.8b shows the posterior mean of the stochastic volatility model. The two models show similar volatility characteristics; they exhibit volatility clusterings and indicate an increasing trend in volatility. However, the GARCH model produces higher peak volatility values. Third, Figure 12.9 shows the time plots of fitted volatilities for the S&P 500 index return. The GARCH model produces an extra volatility peak around 1993. This additional peak does not appear in the univariate analysis shown in Figure 12.5. It seems that for this particular instance the bivariate GARCH model produces a spurious volatility peak. This spurious peak is induced by its dependence on IBM returns and does not appear in the stochastic volatility model. Indeed, the fitted volatilities of the S&P 500 index return by the bivariate stochastic volatility model are similar to that of the univariate analysis. Fourth, Figure 12.10 shows the time plots of fitted

![](images/647e5e21e5800d203207afd084bb312d5aff7b630a3868b025a5df93ba4d6ce6.jpg)

![](images/f4048fe1b0bce4991096f3166489d4bfc876827feb8744d3e148cce0bc29e28d.jpg)

![](images/c5b46495712d495a96c6cd287da69d8f18e2c9e9341d8f6cb272277084ac3530.jpg)

![](images/69a1d0ff004230630da976d5ca13d8fb693936b4661456a6c8e01c8c47279e43.jpg)

![](images/0c0491c6aad1545501e013245c7281ad05d92e82769dd02f13019dc09c61228c.jpg)

![](images/de78223b01866a44d8f536c30916f7d1870e3bf1b7faf962d752f402f6621515.jpg)  
Figure 12.7. Scatterplots of posterior means of various statistics of two different Gibbs samples for the bivariate stochastic volatility model for monthly log returns of IBM stock and the S&P 500 index. The $x$ -axis denotes results based on $5 0 0 + 3 0 0 0$ iterations and the $y$ -axis denotes results based on $3 0 0 + 1 0 0 0$ iterations. The notation is defined in the text.

![](images/615c91bca7ef3d59281047a7960b9bdeb1a95f742d8afa025d01165580f7a040.jpg)

![](images/86b54d65f7d5902e32bf0a161962db066a198d8ed54fcf0e18726a0166f5ef3d.jpg)  
(b) Stochastic volatility   
Figure 12.8. Time plots of fitted volatilities for monthly log returns of IBM stock from 1962 to 1999: (a) a GARCH model with time-varying correlations and (b) a bivariate stochastic volatility model estimated by Gibbs sampling with $3 0 0 + 1 0 0 0$ iterations.

![](images/cbba7d05a9eb5611260d017d4fd1add7de1a08d14eaadf4c65c2f122ebcfa4d7.jpg)

![](images/3822265dfd8d787299cc6737976eb888ea25f7894ef5d48978c51b364d8ce756.jpg)  
Figure 12.9. Time plots of fitted volatilities for monthly log returns of the S&P 500 index from 1962 to 1999: (a) a GARCH model with time-varying correlations and (b) a bivariate stochastic volatility model estimated by Gibbs sampling with $3 0 0 + 1 0 0 0$ iterations.

![](images/27287bdf9629f75666e3b0a6d5a3e8997a9afd976a567a6cdc2567bdf8a62c7c.jpg)

![](images/71d6a28d0beb834b5b485582dfcccd405c40638fb8ec6cc8a20e8ca27d9a0d63.jpg)  
Figure 12.10. Time plots of fitted correlation coefficients between monthly log returns of IBM stock and the S&P 500 index from 1962 to 1999: (a) a GARCH model with time-varying correlations and (b) a bivariate stochastic volatility model estimated by Gibbs sampling with $3 0 0 + 1 0 0 0$ iterations.

conditional correlations. Here the two models differ substantially. The correlations of the GARCH model are relatively smooth and positive with mean value 0.55 and standard deviation 0.11. However, the correlations produced by the stochastic volatility model vary markedly from one month to another with mean value 0.57 and standard deviation 0.17. Furthermore, there are isolated occasions on which the correlation is negative. The difference is understandable because $q _ { 2 1 , t }$ contains the random shock $u _ { t }$ in the stochastic volatility model.

Remark. The Gibbs sampling estimation applies to other bivariate stochastic volatility models. The conditional posterior distributions needed require some extensions of those discussed in this section, but they are based on the same ideas. 

# 12.8 A NEW APPROACH TO SV ESTIMATION

In this section, we discuss an alternative procedure to estimate stochastic volatility models. This approach makes use of the technique of forward filtering and backward sampling (FFBS) within the Kalman filter framework to improve the efficiency of Gibbs sampling. It can dramatically reduce the computing time by drawing the

volatility process jointly with the help of a mixture of normal distributions. In fact, the approach can be used to estimate many stochastic diffusion models with leverage effects and jumps.

For ease in presentation, we reparameterize the univariate stochastic volatility model in Eqs. (12.20) and (12.21) as

$$
r _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + \sigma_ {0} \exp \left(\frac {z _ {t}}{2}\right) \epsilon_ {t}, \tag {12.40}
$$

$$
z _ {t + 1} = \alpha z _ {t} + \eta_ {t}, \tag {12.41}
$$

where $\pmb { x } _ { t } = ( 1 , x _ { 1 t } , \ldots , x _ { p t } ) ^ { \prime }$ , $\beta = ( \beta _ { 0 } , \beta _ { 1 } , . . . , \beta _ { p } ) ^ { \prime }$ , $\sigma _ { 0 } > 0$ , $\{ z _ { t } \}$ is a zero-mean log volatility series, and $\left\{ \epsilon _ { t } \right\}$ and $\{ \eta _ { t } \}$ are bivariate normal distributions with mean zero and covariance matrix

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c c} 1 & \rho \sigma_ {\eta} \\ \rho \sigma_ {\eta} & \sigma_ {\eta} ^ {2} \end{array} \right].
$$

The parameter $\rho$ is the correlation between $\epsilon _ { t }$ and $\eta _ { t }$ and represents the leverage effect of the asset return $r _ { t }$ . Typically, $\rho$ is negative signifying that a negative return tends to increase the volatility of an asset price.

Compared with the model in Eqs. (12.20) and (12.21), we have $z _ { t } = \ln ( h _ { t } ) -$ $\ln ( \sigma _ { 0 } ^ { 2 } )$ and $\sigma _ { 0 } ^ { 2 } = \exp \{ E [ \ln ( h _ { t } ) ] \}$ . That is, $z _ { t }$ is a mean-adjusted log volatility series. This new parameterization has some nice characteristics. For example, the volatility series is $\sigma _ { 0 } \exp ( z _ { t } / 2 )$ , which is always positive. More importantly, $\eta _ { t }$ is the innovation of $z _ { t + 1 }$ and is independent of $z _ { t }$ . This simple time shift enables us to handle the leverage effect. If one postulates $z _ { t } = \alpha z _ { t - 1 } + \eta _ { t }$ for Eq. (12.41), then $\eta _ { t }$ and $\epsilon _ { t }$ cannot be correlated, because a nonzero correlation implies that $z _ { t }$ and $\epsilon _ { t }$ are correlated in Eq. (12.40), which would lead to some identifiability issues.

Remark. Alternatively, one can write the stochastic volatility model as

$$
r _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + \sigma_ {0} \exp \left(\frac {z _ {t - 1}}{2}\right) \epsilon_ {t},
$$

$$
z _ {t} = \alpha z _ {t - 1} + \eta_ {t},
$$

where $( \epsilon _ { t } , \eta _ { t } ) ^ { \prime }$ is a bivariate normal distribution as before. Yet another equivalent parameterization is

$$
r _ {t} = \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta} + \exp \left(\frac {z _ {t - 1} ^ {*}}{2}\right) \epsilon_ {t},
$$

$$
z _ {t} ^ {*} = \alpha_ {0} + \alpha z _ {t - 1} ^ {*} + \eta_ {t},
$$

where $E ( z _ { t } ^ { * } ) = \alpha _ { 0 } / ( 1 - \alpha )$ is not zero.



Parameters of the stochastic volatility model in Eqs. (12.40) and (12.41) are $\beta , \sigma _ { 0 } , \alpha , \rho , \sigma _ { \eta }$ , and $z = ( z _ { 1 } , \ldots , z _ { n } ) ^ { \prime }$ , where $n$ is the sample size. For simplicity, we assume $z _ { 1 }$ is known. To estimate these parameters via MCMC methods, we need

their conditional posterior distributions. In what follows, we discuss the needed conditional posterior distributions.

1. Given z and $\sigma _ { 0 }$ and a normal prior distribution, $\beta$ has the same conditional posterior distribution as that in Section 12.7.1 with $\sqrt { h _ { t } }$ replaced by $\sigma _ { 0 } \exp ( z _ { t } / 2 )$ ; see Eq. (12.22).   
2. Given z and $\sigma _ { \eta } ^ { 2 }$ , $\alpha$ is a simple AR(1) coefficient. Thus, with an approximate normal prior, the conditional posterior distribution of $\alpha$ is readily available; see Section 12.7.1.   
3. Given $\beta$ and z, we define $v _ { t } = ( r _ { t } - x _ { t } ^ { \prime } \beta ) \exp ( - z _ { t } / 2 ) = \sigma _ { 0 } \epsilon _ { t }$ . Thus, $\{ v _ { t } \}$ is a sequence of iid normal random variables with mean zero and variance $\sigma _ { 0 } ^ { 2 }$ . If the prior distribution of $\sigma _ { 0 } ^ { 2 }$ is $( m \lambda ) / \sigma _ { 0 } ^ { 2 } \sim \chi _ { m } ^ { 2 }$ , then the conditional posterior distribution of $\sigma _ { 0 } ^ { 2 }$ is an inverted chi-squared distribution with $m + n$ degrees of freedom; that is,

$$
\frac {m \lambda + \sum_ {t = 1} ^ {n} v _ {t} ^ {2}}{\sigma_ {0} ^ {2}} \sim \chi_ {m + n} ^ {2}.
$$

4. Given $\beta$ , σ0, z, and $\alpha$ , we can easily obtain the bivariate innovation $\pmb { b } _ { t } = ( \epsilon _ { t } , \eta _ { t } ) ^ { \prime }$ for $t = 2 , \ldots , n$ . The likelihood function of $( \rho , \sigma _ { \eta } ^ { 2 } )$ is readily available as

$$
\begin{array}{l} \ell (\rho , \sigma_ {\eta} ^ {2}) = \prod_ {t = 2} ^ {n} f (\boldsymbol {b} _ {t} | \boldsymbol {\Sigma}) \propto | \boldsymbol {\Sigma} | ^ {- (n - 1) / 2} \exp \left(- \frac {1}{2} \sum_ {t = 2} ^ {n} \boldsymbol {b} _ {t} ^ {\prime} \boldsymbol {\Sigma} ^ {- 1} \boldsymbol {b} _ {t}\right) \\ \propto | \boldsymbol {\Sigma} | ^ {- (n - 1) / 2} \exp \left[ - \frac {1}{2} t r \left(\boldsymbol {\Sigma} ^ {- 1} \sum_ {t = 2} ^ {n} \boldsymbol {b} _ {t} \boldsymbol {b} _ {t} ^ {\prime}\right) \right], \\ \end{array}
$$

where $t r ( A )$ denotes trace of the matrix $A$ . However, this joint distribution is complicated because one cannot separate $\rho$ and $\sigma _ { \eta } ^ { 2 }$ . We adopt the technique of Jacquier, Polson, and Rossi (2004) and reparameterize the covariance matrix as

$$
\boldsymbol {\Sigma} = \left[ \begin{array}{c c} 1 & \rho \sigma_ {\eta} \\ \rho \sigma_ {\eta} & \sigma_ {\eta} ^ {2} \end{array} \right] = \left[ \begin{array}{c c} 1 & \varphi \\ \varphi & \omega + \varphi^ {2} \end{array} \right],
$$

where $\omega = \sigma _ { \eta } ^ { 2 } ( 1 - \rho ^ { 2 } )$ . It is easy to see that $| { \pmb { \Sigma } } | = \omega$ and

$$
\boldsymbol {\Sigma} ^ {- 1} = \frac {1}{\omega} \left[ \begin{array}{c c} \varphi^ {2} & - \varphi \\ - \varphi & 1 \end{array} \right] + \left[ \begin{array}{c c} 1 & 0 \\ 0 & 0 \end{array} \right] \equiv \frac {1}{\omega} \boldsymbol {S} + \left[ \begin{array}{c c} 1 & 0 \\ 0 & 0 \end{array} \right],
$$

where $s$ contains $\varphi$ only. Let $\pmb { e } = ( \epsilon _ { 2 } , \ldots , \epsilon _ { n } ) ^ { \prime }$ and $\pmb { \eta } = ( \eta _ { 2 } , \dots , \eta _ { n } ) ^ { \prime }$ be the innovations of the model in Eqs. (12.40) and (12.41). The likelihood function then becomes (keeping terms related to parameters only)

$$
\ell (\varphi , \omega) \propto \omega^ {- (n - 1) / 2} \exp \left(- \frac {1}{2 \omega} t r (\boldsymbol {S R})\right),
$$

where $\begin{array} { r } { \pmb { R } = \sum _ { t = 2 } ^ { n } b _ { t } \pmb { b } _ { t } ^ { \prime } = ( e , \pmb { \eta } ) ^ { \prime } ( e , \pmb { \eta } ) } \end{array}$ , which is the $2 \times 2$ cross-product matrix of the innovations. For simplicity, we use conjugate priors such that $\omega$ is inverse

gamma (IG) with hyperparameters $( \gamma _ { 0 } / 2 , \gamma _ { 1 } / 2 )$ : that is, $\omega \sim \mathrm { I G } ( \gamma _ { 0 } / 2 , \gamma _ { 1 } / 2 )$ and $\varphi | \omega \sim N ( 0 , \omega / 2 )$ . Then, after some algebraic manipulation, the joint posterior distribution of $( \varphi , \omega )$ can be decomposed into a normal and an inverse gamma distribution. Specifically,

$$
\varphi \sim N [ \tilde {\varphi}, \omega / (2 + e ^ {\prime} e) ],
$$

where $\tilde { \varphi } = e ^ { \prime } \eta / ( 2 + e ^ { \prime } e )$ , and

$$
\omega \sim \operatorname {I G} [ (n + 1 + \gamma_ {0}) / 2, \left\{\gamma_ {1} + \boldsymbol {\eta} ^ {\prime} \boldsymbol {\eta} - (\boldsymbol {e} ^ {\prime} \boldsymbol {\eta}) ^ {2} / (2 + \boldsymbol {e} ^ {\prime} \boldsymbol {e}) \right\} / 2 ].
$$

In Gibbs sampling, once $\varphi$ and $\omega$ are available, we can obtain $\rho$ and $\sigma _ { \eta } ^ { 2 }$ easily because $\sigma _ { \eta } ^ { 2 } = \omega + \varphi ^ { 2 }$ and $\rho = \varphi / \sigma _ { \eta }$ . Note that the probability density function of an $\operatorname { I G } ( \alpha , \beta )$ random variable $\omega$ is

$$
f (\omega | \alpha , \beta) = \frac {\beta^ {\alpha}}{\Gamma (\alpha)} \omega^ {- (\alpha + 1)} \exp \left(- \frac {\beta}{\omega}\right), \quad \text {f o r} \omega > 0,
$$

where $\alpha > 2$ and $\beta > 0$ .

5. Finally, we consider the joint distribution of the log volatility z given the data and other parameters. From Eq. (12.40), we have

$$
\frac {\left(r _ {t} - \boldsymbol {x} _ {t} ^ {\prime} \boldsymbol {\beta}\right) ^ {2}}{\sigma_ {0} ^ {2}} = \exp (z _ {t}) \epsilon_ {t} ^ {2}.
$$

Therefore, letting $y _ { t } = \ln [ ( r _ { t } - x _ { t } ^ { \prime } \pmb { \beta } ) ^ { 2 } / \sigma _ { 0 } ^ { 2 } ]$ , we obtain

$$
y _ {t} = z _ {t} + \epsilon_ {t} ^ {*}, \tag {12.42}
$$

where $\epsilon _ { t } ^ { * } = \ln ( \epsilon _ { t } ^ { 2 } )$ . Since $\epsilon _ { t } ^ { 2 } \sim \chi _ { 1 } ^ { 2 }$ , $\boldsymbol { \epsilon } _ { t } ^ { * }$ is not normally distributed. Treating Eq. (12.42) as an observation equation and Eq. (12.41) as the state equation, we have the form of a state-space model except that $\boldsymbol { \epsilon } _ { t } ^ { * }$ is not Gaussian; see Eqs. (11.25) and (11.24) of Chapter 11. To overcome the difficulty associated with non-normality, Kim, Shephard, and Chib (1998) use a mixture of seven normal distributions to approximate the distribution of $\boldsymbol { \epsilon } _ { t } ^ { * }$ . Specifically, we have

$$
f \left(\epsilon_ {t} ^ {*}\right) \approx \sum_ {i = 1} ^ {7} p _ {i} N \left(\mu_ {i}, \varpi_ {i} ^ {2}\right),
$$

where $p _ { i } , \mu _ { i }$ , and $\varpi _ { i } ^ { 2 }$ are given in Table 12.3. See also, Chib, Nardari, and Shephard (2002).

To demonstrate the adequacy of the approximation, Figure 12.11 shows the density function of $\boldsymbol { \epsilon } _ { t } ^ { * }$ (solid line) and that of the mixture of seven normals (dashed line) in Table 12.3. These densities are obtained using simulations with 100,000 observations. From the plot, the approximation by the mixture of seven normals is very good.

Why is it important to have a Gaussian state-space model? The answer is that such a Gaussian model enables us to draw the log volatility series z jointly and

Table 12.3. Seven Components of Normal Distributions   

<table><tr><td>Component i</td><td>Probability pi</td><td>Mean μi</td><td>Variable ωi2</td></tr><tr><td>1</td><td>0.00730</td><td>-11.4004</td><td>5.7960</td></tr><tr><td>2</td><td>0.10556</td><td>-5.2432</td><td>2.6137</td></tr><tr><td>3</td><td>0.00002</td><td>-9.8373</td><td>5.1795</td></tr><tr><td>4</td><td>0.04395</td><td>1.5075</td><td>0.1674</td></tr><tr><td>5</td><td>0.34001</td><td>-0.6510</td><td>0.6401</td></tr><tr><td>6</td><td>0.24566</td><td>0.5248</td><td>0.3402</td></tr><tr><td>7</td><td>0.25750</td><td>-2.3586</td><td>1.2626</td></tr></table>

![](images/95f46d8b63744ba79e7ac18f5e4235ef1804182aeba09abbcbd1d39a702bd9f8.jpg)  
Figure 12.11. Density functions of $\log ( \chi _ { 1 } ^ { 2 } )$ , solid line, and that of a mixture of seven normal distributions, dashed line. Results are based on 100,000 observations.

efficiently. To see this, consider the following special Gaussian state-space model, where $\eta _ { t }$ and $e _ { t }$ are uncorrelated (i.e., no leverage effects):

$$
z _ {t + 1} = \alpha z _ {t} + \eta_ {t}, \quad \eta_ {t} \sim_ {\mathrm {i i d}} N \left(0, \sigma_ {\eta} ^ {2}\right), \tag {12.43}
$$

$$
y _ {t} = c _ {t} + z _ {t} + e _ {t}, \quad e _ {t} \sim_ {\text {i n d .}} N (0, H _ {t}) \tag {12.44}
$$

where, as will be seen later, $( c _ { t } , H _ { t } )$ assumes the value $( \mu _ { i } , \varpi _ { i } ^ { 2 } )$ of Table 12.3 for some i. For this special state-space model, we have the Kalman filter algorithm

$$
v _ {t} = y _ {t} - y _ {t \mid t - 1} = y _ {t} - c _ {t} - z _ {t \mid t - 1},
$$

$$
V _ {t} = \Sigma_ {t | t - 1} + H _ {t},
$$

$$
z _ {t | t} = z _ {t | t - 1} + \Sigma_ {t | t - 1} V _ {t} ^ {- 1} v _ {t}, \tag {12.45}
$$

$$
\Sigma_ {t | t} = \Sigma_ {t | t - 1} - \Sigma_ {t | t - 1} V _ {t} ^ {- 1} \Sigma_ {t | t - 1},
$$

$$
z _ {t + 1 | t} = \alpha z _ {t | t},
$$

$$
\Sigma_ {t + 1 | t} = \alpha^ {2} \Sigma_ {t | t} + \sigma_ {\eta} ^ {2},
$$

where $V _ { t } = \mathrm { V a r } ( v _ { t } )$ is the variance of the 1-step ahead prediction error $v _ { t }$ of $y _ { t }$ given $F _ { t - 1 } = ( y _ { 1 } , \dots , y _ { t - 1 } )$ , and $z _ { j \mid i }$ and $\Sigma _ { j \vert i }$ are, respectively, the conditional expectation and variance of the state variable $z _ { j }$ given $F _ { i }$ . See the Kalman filter discussion of Chaper 11.

# Forward Filtering and Backward Sampling (FFBS)

Let $p ( z | F _ { n } )$ be the joint conditional posterior distribution of z given the return data and other parameters, where for simplicity the parameters are omitted from the condition set. We can partition the distribution as

$$
\begin{array}{l} p (z \mid F _ {n}) = P (z _ {2}, z _ {3}, \dots , z _ {n} \mid F _ {n}) \\ = p \left(z _ {n} \mid F _ {n}\right) p \left(z _ {n - 1} \mid z _ {n}, F _ {n}\right) p \left(z _ {n - 2} \mid z _ {n - 1}, z _ {n}, F _ {n}\right) \dots p \left(z _ {2} \mid z _ {3}, \dots , z _ {n}, F _ {n}\right) \\ = p \left(z _ {n} \mid F _ {n}\right) p \left(z _ {n - 1} \mid z _ {n}, F _ {n}\right) p \left(z _ {n - 2} \mid z _ {n - 1}, F _ {n}\right) \dots p \left(z _ {2} \mid z _ {3}, F _ {n}\right), \tag {12.46} \\ \end{array}
$$

where the last equality holds because $z _ { t }$ in Eq. (12.43) is a Markov process so that conditioned on $z _ { t + 1 }$ , $z _ { t }$ is independent of $z _ { t + j }$ for $j > 1$ .

From the Kalman filter in Eq. (12.45), we obtain that $p ( z _ { n } | F _ { n } )$ is normal with mean $z _ { n | n }$ and variance $\Sigma _ { n | n }$ . Next, consider the second term $p ( z _ { n - 1 } | z _ { n } , F _ { n } )$ of Eq. (12.46). We have

$$
p \left(z _ {n - 1} \mid z _ {n}, F _ {n}\right) = p \left(z _ {n - 1} \mid z _ {n}, F _ {n - 1}, y _ {n}\right) = p \left(z _ {n - 1} \mid z _ {n}, F _ {n - 1}, v _ {n}\right), \tag {12.47}
$$

where $\upsilon _ { n } = y _ { n } - y _ { n | n - 1 }$ is the 1-step ahead prediction error of $y _ { n }$ . From the statespace model in Eqs. (12.43) and (12.44), $z _ { n - 1 }$ is independent of $v _ { n }$ . Therefore,

$$
p \left(z _ {n - 1} \mid z _ {n}, F _ {n}\right) = p \left(z _ {n - 1} \mid z _ {n}, F _ {n - 1}\right). \tag {12.48}
$$

This is an important property because it implies that we can derive the posterior distribution $p ( z _ { n - 1 } | z _ { n } , F _ { n } )$ from the joint distribution of $( z _ { n - 1 } , z _ { n } )$ given $F _ { n - 1 }$ via Theorem 11.1 of Chapter 11. First, the joint distribution is bivariate normal under the Gaussian assumption. Second, the conditional mean and covariance matrix of $\left( z _ { n - 1 } , z _ { n } \right)$ given $F _ { n - 1 }$ are readily available from the Kalman filter algorithm in Eq. (12.45). Specifically, we have

$$
\left[ \begin{array}{c} z _ {n - 1} \\ z _ {n} \end{array} \right] _ {F _ {n - 1}} \sim N \left(\left[ \begin{array}{c} z _ {n - 1 | n - 1} \\ z _ {n | n - 1} \end{array} \right], \left[ \begin{array}{c c} \sum_ {n - 1 | n - 1} & \alpha \sum_ {n - 1 | n - 1} \\ \alpha \sum_ {n - 1 | n - 1} & \sum_ {n | n - 1} \end{array} \right]\right), \tag {12.49}
$$

where the covariance is obtained by (i) multiplying $z _ { n - 1 }$ by Eq. (12.43) and (ii) taking conditional expectation. Note that all quantities involved in Eq. (12.49) are

available from the Kalman filter. Consequently, by Theorem 11.1, we have

$$
p \left(z _ {n - 1} \mid z _ {n}, F _ {n}\right) \sim N \left(\mu_ {n - 1} ^ {*}, \Sigma_ {n - 1} ^ {*}\right), \tag {12.50}
$$

where

$$
\mu_ {n - 1} ^ {*} = z _ {n - 1 | n - 1} + \alpha \Sigma_ {n - 1 | n - 1} \Sigma_ {n | n - 1} ^ {- 1} (z _ {n} - z _ {n | n - 1}),
$$

$$
\Sigma_ {n - 1} ^ {*} = \Sigma_ {n - 1 | n - 1} - \alpha^ {2} \Sigma_ {n - 1 | n - 1} ^ {2} \Sigma_ {n | n - 1} ^ {- 1}.
$$

Next, for the conditional posterior distribution $p ( z _ { n - 2 } | z _ { n - 1 } , F _ { n } )$ , we have

$$
\begin{array}{l} p \left(z _ {n - 2} \mid z _ {n - 1}, F _ {n}\right) = p \left(z _ {n - 2} \mid z _ {n - 1}, F _ {n - 2}, y _ {n - 1}, y _ {n}\right) \\ = p \left(z _ {n - 2} \mid z _ {n - 1}, F _ {n - 2}, v _ {n - 1}, v _ {n}\right) \\ = p \left(z _ {n - 2} \mid z _ {n - 1}, F _ {n - 2}\right). \\ \end{array}
$$

Consequently, we can obtain $p ( z _ { n - 2 } | z _ { n - 1 } , F _ { n } )$ from the bivariate normal distribution of $p ( z _ { n - 2 } , z _ { n - 1 } | F _ { n - 2 } )$ as before. In general, we have

$$
p \left(z _ {t} \mid z _ {t + 1}, F _ {n}\right) = p \left(z _ {t} \mid z _ {t + 1}, F _ {t}\right), \quad \text {f o r} 1 <   t <   n.
$$

Furthermore, from the Kalman filter, $p ( z _ { t } , z _ { t + 1 } | F _ { t } )$ is bivariate normal as

$$
\left[ \begin{array}{c} z _ {t} \\ z _ {t + 1} \end{array} \right] _ {F _ {t}} \sim N \left(\left[ \begin{array}{c} z _ {t | t} \\ z _ {t + 1 | t} \end{array} \right], \left[ \begin{array}{c c} \Sigma_ {t | t} & \alpha \Sigma_ {t | t} \\ \alpha \Sigma_ {t | t} & \Sigma_ {t + 1 | t} \end{array} \right]\right). \tag {12.51}
$$

Consequently,

$$
p \left(z _ {t} \mid z _ {t + 1}, F _ {t}\right) \sim N \left(\mu_ {t} ^ {*}, \Sigma_ {t} ^ {*}\right),
$$

where

$$
\begin{array}{l} \mu_ {t} ^ {*} = z _ {t | t} + \alpha \Sigma_ {t | t} \Sigma_ {t + 1 | t} ^ {- 1} \left(z _ {t + 1} - z _ {t + 1 | t}\right), \\ \Sigma_ {t} ^ {*} = \Sigma_ {t | t} - \alpha^ {2} \Sigma_ {t | t} ^ {2} \Sigma_ {t + 1 | t}. \\ \end{array}
$$

The prior derivation implies that we can draw the volatility series $z$ jointly by a recursive method using quantities readily available from the Kalman filter algorithm. That is, given the initial values $z _ { 1 \vert 0 }$ and $\Sigma _ { 1 | 0 }$ , one uses the Kalman filter in Eq. (12.45) to process the return data forward, then applies the recursive backward method to draw a realization of the volatility series z. This scheme is referred to as forward filtering and backward sampling (FFBS); see Carter and Kohn (1994) and Fruhwirth-Schnatter (1994). Because the volatility ¨ $\{ z _ { t } \}$ is serially correlated, drawing the series jointly is more efficient.

Remark. The FFBS procedure applies to general linear Gaussian state-space models. The main idea is to make use of the Markov property of the model and the structure of the state-transition equation so that

$$
p \left(S _ {t} \mid S _ {t + 1}, F _ {n}\right) = p \left(S _ {t} \mid S _ {t + 1}, F _ {t}, v _ {t + 1}, \dots , v _ {n}\right) = p \left(S _ {t} \mid S _ {t + 1}, F _ {t}\right),
$$

where $S _ { t }$ denotes the state variable at time $t$ and $v _ { j }$ is the 1-step ahead prediction error. This identity enables us to apply Theorem 11.1 to derive a recursive method to draw the state vectors jointly. 

Return to the estimation of the SV model. As in Eq. (12.42), let $y _ { t } = \ln [ ( r _ { t } -$ $x _ { t } ^ { \prime } \beta ) ^ { 2 } / \sigma _ { 0 } ^ { 2 } ]$ . To implement FFBS, one must determine $c _ { t }$ and $H _ { t }$ of Eq. (12.44) so that the mixture of normals provides a good approximation to the distribution of $\epsilon _ { t } ^ { * }$ . To this end, we augment the model with a series of independent indicator with variables $\textstyle \sum _ { i = 1 } ^ { 7 } p _ { i t } = 1$ $\{ I _ { t } \}$ , where t { }  for each t . In practice, conditioned on $I _ { t }$ assumes a value in $\{ 1 , . . . , 7 \}$ such that $\{ z _ { t } \}$ t =  = it, we can determine $P ( I _ { t } = i ) = p _ { i t }$ $c _ { t }$ and $H _ { t }$ as follows. Let

$$
q _ {i t} = \Phi \left[ \left(y _ {t} - z _ {t} - \mu_ {i}\right) / \varpi_ {i} \right], \quad \text {f o r} i = 1, \dots , 7,
$$

where $\mu _ { i }$ and $\varpi _ { i }$ are the mean and standard error of the normal distributions given in Table 12.3 and $\Phi ( . )$ denotes the cumulative distribution function of the standard normal random variable. These probabilities $q _ { i t }$ are the likelihood function of $I _ { t }$ given $y _ { t }$ and $z _ { t }$ . The probabilities $p _ { i }$ of Table 12.3 form a prior distribution of $I _ { t }$ . Therefore, the posterior distribution of $I _ { t }$ is

$$
p _ {i t} = \frac {p _ {i} q _ {i t}}{\sum_ {j = 1} ^ {7} p _ {j} q _ {j t}}, \quad i = 1, \dots , 7.
$$

We can draw a realization of $I _ { t }$ using this posterior distribution. If the random draw is $I _ { t } = j$ , then we define $c _ { t } = \mu _ { j }$ and $H _ { t } = \varpi _ { j } ^ { 2 }$ . In summary, conditioned on the return data and other parameters of the model, we employ the approximate linear Gaussian state-space model in Eqs. (12.43) and (12.44) to draw jointly the log volatility series z. It turns out that the resulting Gibbs sampling is efficient in estimating univariate stochastic volatility models.

On the other hand, the square transformation involved in Eq. (12.42) fails to retain the correlation between $\eta _ { t }$ and $\epsilon _ { t }$ if it exists, making the approximate statespace model in Eqs. (12.43) and (12.44) incapable of estimating the leverage effect. To overcome this inadequacy, Artigas and Tsay (2004) propose using a time-varying state-space model that maintains the leverage effect. Specifically, when $\rho \neq 0$ , we have

$$
\eta_ {t} = \rho \sigma_ {\eta} \epsilon_ {t} + \eta_ {t} ^ {*},
$$

where $\boldsymbol { \eta } _ { t } ^ { * }$ is a normal random variable independent of $\epsilon _ { t }$ and $\mathrm { V a r } ( \eta _ { t } ^ { * } ) = \sigma _ { \eta } ^ { 2 } ( 1 - \rho ^ { 2 } )$ . The state-transition equation of Eq. (12.43) then becomes

$$
z _ {t + 1} = \alpha z _ {t} + \rho \sigma_ {\eta} \epsilon_ {t} + \eta_ {t} ^ {*}.
$$

Substituting $\epsilon _ { t } = ( 1 / \sigma _ { 0 } ) ( r _ { t } - x _ { t } ^ { \prime } \beta ) \exp ( - z _ { t } / 2 )$ , we obtain

$$
\begin{array}{l} z _ {t + 1} = \alpha z _ {t} + \frac {\rho \sigma_ {\eta} \left(r _ {t} - x _ {t} ^ {\prime} \boldsymbol {\beta}\right)}{\sigma_ {0}} \exp \left(- z _ {t} / 2\right) + \eta_ {t} ^ {*} \tag {12.52} \\ = G \left(z _ {t}\right) + \eta_ {t} ^ {*} \\ \end{array}
$$

where $G ( z _ { t } ) = \alpha z _ { t } + \rho \sigma _ { \eta } ( r _ { t } - x _ { t } ^ { \prime } \beta ) \exp ( - z _ { t } / 2 ) / \sigma _ { 0 }$ . This is a nonlinear transition equation for the state variable $z _ { t }$ . The Kalman filter in Eq. (12.45) is no longer applicable. To overcome this difficulty, Artigas and Tsay (2004) use a time-varying linear Kalman filter to approximate the system. Specifically, the last two equations of Eq. (12.45) are modified as

$$
z _ {t + 1 \mid t} = G \left(z _ {t \mid t}\right), \tag {12.53}
$$

$$
\Sigma_ {t + 1 | t} = g (z _ {t | t}) ^ {2} \Sigma_ {t | t} + \sigma_ {\eta} ^ {2} (1 - \rho^ {2}),
$$

where $g ( z _ { t | t } ) = \partial G ( x ) / \partial x | _ { x = z _ { t | t } }$ is the first-order derivative of $G ( z _ { t } )$ evaluated at the smoothed state $z _ { t \mid t }$ .

Example 12.5. To demonstrate the FFBS procedure, we consider the monthly log returns of the S&P 500 index from January 1962 to November 2004 for 515 observations. Figure 12.12 shows the time plots of the logged S&P 500 index and the log return series. The original data were obtained from Yahoo Finance Web site. Let $r _ { t }$ be the monthly log return series. We consider two stochastic volatility models in the form:

$$
r _ {t} = \mu + \sigma_ {o} \exp \left(z _ {t} / 2\right) \epsilon_ {t}, \quad \epsilon_ {t} \sim_ {\mathrm {i i d}} N (0, 1), \tag {12.54}
$$

$$
z _ {t + 1} = \alpha z _ {t} + \eta_ {t}, \quad \eta_ {t} \sim_ {\mathrm {i i d}} N (0, \sigma_ {\eta} ^ {2}).
$$

![](images/898e139da8fde2f945a7cb9c2f6db5cd0bf77c88b977cee4f219391da6bdf851.jpg)  
(a) ln(SP 500 index)

![](images/16289268989f818e2087d4f4b8fba99ec9272e7e660ad2586eb0d9b71a32cedb.jpg)  
(b) log-return   
Figure 12.12. Time plots of monthly S&P 500 index from January 1962 to November 2004: (a) log index series and (b) log return series.

Table 12.4. Estimation of Stochastic Volatility Model in Eq. (12.54) for the Monthly Log Returns of the S&P 500 Index from January 1962 to November 2004 Using Gibbs Sampling with the FFBS Algorithma   

<table><tr><td>Parameter</td><td>μ</td><td>σo</td><td>α</td><td>ση</td><td>ρ</td></tr><tr><td colspan="6">With Leverage Effect</td></tr><tr><td>Estimate</td><td>0.0081</td><td>0.0764</td><td>-0.0616</td><td>2.5639</td><td>-0.3892</td></tr><tr><td>Standard error</td><td>0.0274</td><td>0.0255</td><td>0.1186</td><td>0.3924</td><td>0.0292</td></tr><tr><td colspan="6">Without Leverage Effect</td></tr><tr><td>Estimate</td><td>0.0080</td><td>0.0775</td><td>-0.0613</td><td>2.5827</td><td></td></tr><tr><td>Standard error</td><td>0.0279</td><td>0.0266</td><td>0.1164</td><td>0.3783</td><td></td></tr></table>

aThe results are based on $2 0 0 0 + 8 0 0 0$ iterations with the first 2000 iterations as burn-ins.

![](images/bd4713172b18d992d57d04ef1477b7d50c7b44131019c4c6e3a43eb3a8294a90.jpg)  
(a) Volatility series with leverage effect

![](images/1b7fbf529412f90a3b6d41609b71d508db4377160300647ee94c8713d31d1892.jpg)  
(b) Volatility series without leverage effect   
Figure 12.13. Estimated volatility of monthly log returns of the S&P 500 index from January 1962 to November 2004 using stochastic volatility models: (a) with leverage effect (b) without leverage effect.

In model 1, $\{ \epsilon _ { t } \}$ and $\{ \eta _ { t } \}$ are two independent Gaussian white noise series. That is, there is no leverage effect in the model. In model 2, we assume that $\mathrm { c o r r } ( \epsilon _ { t } , e _ { t } ) = \rho$ , which denotes the leverage effect.

We estimate the models via the FFBS procedure using a program written in Matlab. The Gibbs sampling was run for $2 0 0 0 + 8 0 0 0$ iterations with the first 2000 iterations as burn-ins. Table 12.4 gives the posterior means and standard errors of

the parameter estimates. In particular, we have $\hat { \rho } = - 0 . 3 9$ , which is close to the value commonly seen in the literature. Figure 12.13 shows the time plots of the posterior means of the estimated volatility. As expected, the two volatility series are very close. Compared with the results of Example 12.3, which uses a shorter series, the estimated volatility series exhibit similar patterns and are in the same magnitude. Note that the volatility shown in Figure 12.5 is conditional variance of percentage log returns whereas the volatility in Figure 12.13 is the conditional standard error of log returns.

# 12.9 MARKOV SWITCHING MODELS

The Markov switching model is another econometric model for which MCMC methods enjoy many advantages over the traditional likelihood method. McCulloch and Tsay (1994b) discuss a Gibbs sampling procedure to estimate such a model when the volatility in each state is constant over time. These authors applied the procedure to estimate a Markov switching model with different dynamics and mean levels for different states to the quarterly growth rate of U.S. real gross national product, seasonally adjusted, and obtained some interesting results. For instance, the dynamics of the growth rate are significantly different between periods of economic “contraction” and “expansion.” Since this chapter is concerned with asset returns, we focus on models with volatility switching.

Suppose that an asset return $r _ { t }$ follows a simple two-state Markov switching model with different risk premiums and different GARCH dynamics:

$$
r _ {t} = \left\{ \begin{array}{l l} \beta_ {1} \sqrt {h _ {t}} + \sqrt {h} _ {t} \epsilon_ {t}, & h _ {t} = \alpha_ {1 0} + \alpha_ {1 1} h _ {t - 1} + \alpha_ {1 2} a _ {t - 1} ^ {2} \text {i f} s _ {t} = 1, \\ \beta_ {2} \sqrt {h _ {t}} + \sqrt {h} _ {t} \epsilon_ {t}, & h _ {t} = \alpha_ {2 0} + \alpha_ {2 1} h _ {t - 1} + \alpha_ {2 2} a _ {t - 1} ^ {2} \text {i f} s _ {t} = 2, \end{array} \right. \tag {12.55}
$$

where $a _ { t } = \sqrt { h _ { t } } \epsilon _ { t }$ , $\left\{ \epsilon _ { t } \right\}$ is a sequence of Gaussian white noises with mean zero and variance 1, and the parameters $\alpha _ { i j }$ satisfy some regularity conditions so that the unconditional variance of $a _ { t }$ exists. The probability transition from one state to another is governed by

$$
P \left(s _ {t} = 2 \mid s _ {t - 1} = 1\right) = e _ {1}, \quad P \left(s _ {t} = 1 \mid s _ {t - 1} = 2\right) = e _ {2}, \tag {12.56}
$$

where $0 < e _ { i } < 1$ . A small $e _ { i }$ means that the return series has a tendency to stay in the $i$ th state with expected duration $1 / e _ { i }$ . For the model in Eq. (12.55) to be identifiable, we assume that $\beta _ { 2 } > \beta _ { 1 }$ so that state 2 is associated with higher risk premium. This is not a critical restriction because it is used to achieve uniqueness in labeling the states. A special case of the model results if $\alpha _ { 1 j } = \alpha _ { 2 j }$ for all $j$ so that the model assumes a GARCH model for all states. However, if $\beta _ { i } \sqrt { h _ { t } }$ is replaced by $\beta _ { i }$ , then model (12.55) reduces to a simple Markov switching GARCH model.

Model (12.55) is a Markov switching GARCH-M model. For simplicity, we assume that the initial volatility $h _ { 1 }$ is given with value equal to the sample variance

of $r _ { t }$ . A more sophisticated analysis is to treat $h _ { 1 }$ as a parameter and estimate it jointly with other parameters. We expect the effect of fixing $h _ { 1 }$ will be negligible in most applications, especially when the sample size is large. The “traditional” parameters of the Markov switching GARCH-M model are $\pmb { \beta } = ( \beta _ { 1 } , \beta _ { 2 } ) ^ { \prime }$ , ${ \pmb { \alpha } } _ { i } =$ $( \alpha _ { i 0 } , \alpha _ { i 1 } , \alpha _ { i 2 } ) ^ { \prime }$ for $i = 1$ and 2, and the transition probabilities $\boldsymbol { e } = ( e _ { 1 } , e _ { 2 } ) ^ { \prime }$ . The state vector $\pmb { S } = ( s _ { 1 } , s _ { 2 } , \ldots , s _ { n } ) ^ { \prime }$ contains the augmented parameters. The volatility vector $\pmb { H } = ( h _ { 2 } , \ldots , h _ { n } ) ^ { \prime }$ can be computed recursively if $h _ { 1 }$ , ${ \pmb { \alpha } } _ { i }$ , and the state vector $s$ are given.

Dependence of the return on volatility in model (12.55) implies that the return is also serially correlated. The model thus has some predictivity in the return. However, states of the future returns are unknown and a prediction produced by the model is necessarily a mixture of those over possible state configurations. This often results in high uncertainty in point prediction of future returns.

Turn to estimation. The likelihood function of model (12.55) is complicated as it is a mixture over all possible state configurations. Yet the Gibbs sampling approach only requires the following conditional posterior distributions:

$$
\begin{array}{l} f (\boldsymbol {\beta} | \boldsymbol {R}, \boldsymbol {S}, \boldsymbol {H}, \alpha_ {1}, \alpha_ {2}), \quad f (\alpha_ {i} | \boldsymbol {R}, \boldsymbol {S}, \boldsymbol {H}, \alpha_ {j \neq i}), \\ P (S | \boldsymbol {R}, h _ {1}, \alpha_ {1}, \alpha_ {2}), \quad f (e _ {i} | S), \quad i = 1, 2, \\ \end{array}
$$

where $\pmb { R }$ is the collection of observed returns. For simplicity, we use conjugate prior distributions discussed in Section 12.3—that is,

$$
\beta_ {i} \sim N \left(\beta_ {i o}, \sigma_ {i o} ^ {2}\right), \quad e _ {i} \sim \operatorname {B e t a} \left(\gamma_ {i 1}, \gamma_ {i 2}\right).
$$

The prior distribution of parameter $\alpha _ { i j }$ is uniform over a properly specified interval. Since $\alpha _ { i j }$ is a nonlinear parameter of the likelihood function, we use the Griddy Gibbs to draw its random realizations. A uniform prior distribution simplifies the computation involved. Details of the prior conditional posterior distributions are given below:

1. The posterior distribution of $\beta _ { i }$ only depends on the data in state i. Define

$$
r _ {i t} = \left\{ \begin{array}{l l} r _ {t} / \sqrt {h _ {t}} & \text {i f} s _ {t} = i, \\ 0 & \text {o t h e r w i s e}. \end{array} \right.
$$

Then we have

$$
r _ {i t} = \beta_ {i} + \epsilon_ {t}, \quad \text {f o r} \quad s _ {t} = i.
$$

Therefore, information of the data on $\beta _ { i }$ is contained in the sample mean of $r _ { i t }$ . Let $\textstyle { \overline { { r } } } _ { i } = { \bigl ( } \sum _ { s _ { t } = i } r _ { i t } { \bigr ) } / n _ { i }$ , where the summation is over all data points in state $i$ and $n _ { i }$ =is the number of data points in state $i$ . Then the conditional posterior distribution of $\beta _ { i }$ is normal with mean $\beta _ { i } ^ { * }$ and variance $\sigma _ { i * } ^ { 2 }$ , where

$$
\frac {1}{\sigma_ {i *} ^ {2}} = n _ {i} + \frac {1}{\sigma_ {i o} ^ {2}}, \quad \beta_ {i} ^ {*} = \sigma_ {i *} ^ {2} \left(n _ {i} \overline {{r}} _ {i} + \beta_ {i o} / \sigma_ {i o} ^ {2}\right), \quad i = 1, 2.
$$

2. Next, the parameters $\alpha _ { i j }$ can be drawn one by one using the Griddy Gibbs method. Given $h _ { 1 }$ , S, $\pmb { \alpha } _ { v \neq i }$ , and $\alpha _ { i v }$ with $v \neq j$ , the conditional posterior distribution function of $\alpha _ { i j }$ does not correspond to a well-known distribution, but it can be evaluated easily as

$$
f (\alpha_ {i j} |.) \propto - \frac {1}{2} \left(\ln h _ {t} + \frac {(r _ {t} - \beta_ {i} \sqrt {h _ {t}}) ^ {2}}{h _ {t}}\right), \quad \mathrm {i f} \quad s _ {t} = i,
$$

where $h _ { t }$ contains $\alpha _ { i j }$ . We evaluate this function at a grid of points for $\alpha _ { i j }$ over a properly specified interval. For example, $0 \leq \alpha _ { 1 1 } < 1 - \alpha _ { 1 2 }$ .

3. The conditional posterior distribution of $e _ { i }$ only involves S. Let $\ell _ { 1 }$ be the number of switches from state 1 to state 2 and $\ell _ { 2 }$ be the number of switches from state 2 to state 1 in S. Also, let $n _ { i }$ be the number of data points in state i. Then by Result 3 of conjugate prior distributions, the posterior distribution of $e _ { i }$ is $\mathrm { \Phi } _ { \mathsf { } } \mathrm { e t a } ( \gamma _ { i 1 } + \ell _ { i }$ , $\gamma _ { i 2 } + n _ { i } - \ell _ { i } )$ .

4. Finally, elements of $s$ can be drawn one by one. Let $S _ { - j }$ be the vector obtained by removing $s _ { j }$ from S. Given $S _ { - j }$ and other information, $s _ { j }$ can assume two possibilities (i.e., $s _ { j } = 1$ or $s _ { j } = 2$ ), and its conditional posterior distribution is

$$
P (s _ {j} |.) \propto \prod_ {t = j} ^ {n} f (a _ {t} | \boldsymbol {H}) P (s _ {j} | \boldsymbol {S} _ {- j}).
$$

The probability

$$
P (s _ {j} = i \mid S _ {- j}) = P (s _ {j} = i \mid s _ {j - 1}, s _ {j + 1}), \quad i = 1, 2
$$

can be computed by the Markov transition probabilities in Eq. (12.56). In addition, assuming $s _ { j } = i$ , one can compute $h _ { t }$ for $t \geq j$ recursively. The relevant likelihood function, denoted by $L ( s _ { j } )$ , is given by

$$
L (s _ {j} = i) \equiv \prod_ {t = j} ^ {n} f (a _ {t} | \boldsymbol {H}) \propto \exp (f _ {j i}), \quad f _ {j i} = \sum_ {t = j} ^ {n} - \frac {1}{2} \left(\ln (h _ {t}) + \frac {a _ {t} ^ {2}}{h _ {t}}\right),
$$

for $i = 1$ and 2, where $a _ { t } = r _ { t } - \beta _ { 1 } \sqrt { h _ { t } }$ if $s _ { t } = 1$ and $a _ { t } = r _ { t } - \beta _ { 2 } \sqrt { h _ { t } }$ otherwise. Consequently, the conditional posterior probability of $s _ { j } = 1$ is

$$
\begin{array}{l} P (s _ {j} = 1 |.) \\ = \frac {P (s _ {j} = 1 | s _ {j - 1} , s _ {j + 1}) L (s _ {j} = 1)}{P (s _ {j} = 1 | s _ {j - 1} , s _ {j + 1}) L (s _ {j} = 1) + P (s _ {j} = 2 | s _ {j - 1} , s _ {j + 1}) L (s _ {j} = 2)}. \\ \end{array}
$$

The state $s _ { j }$ can then be drawn easily using a uniform distribution on the unit interval [0, 1].

Remark. Since $s _ { j }$ and $s _ { j + 1 }$ are highly correlated when $e _ { 1 }$ and $e _ { 2 }$ are small, it is more efficient to draw several $s _ { j }$ jointly. However, the computation involved in enumerating the possible state configurations increases quickly with the number of states drawn jointly. 

![](images/c7b20b76b1f7696e9e937bbfcfcc7d25bcf56ff3e5d22a97b97e347d40897c80.jpg)

![](images/fce378cf38d5b9e434b19fd4cfac0b0b085ac712c862549d06dfd07659e2338e.jpg)  
Figure 12.14. (a) Time plot of the monthly log returns, in percentages, of GE stock from 1926 to 1999. (b) Time plot of the posterior probability of being in state 2 based on results of the last 2000 iterations of a Gibbs sampling with $5 0 0 0 + 2 0 0 0$ total iterations. The model used is a two-state Markov switching GARCH-M model.

Example 12.6. In this example, we consider the monthly log stock returns of General Electric Company from January 1926 to December 1999 for 888 observations. The returns are in percentages and shown in Figure 12.14a. For comparison purposes, we start with a GARCH-M model for the series and obtain

$$
r _ {t} = 0. 1 8 2 \sqrt {h _ {t}} + a _ {t}, \quad a _ {t} = \sqrt {h _ {t}} \epsilon_ {t},
$$

$$
h _ {t} = 0. 5 4 6 + 1. 7 4 0 h _ {t - 1} - 0. 7 7 5 h _ {t - 2} + 0. 0 2 5 a _ {t - 1} ^ {2}, \tag {12.57}
$$

where $r _ { t }$ is the monthly log return and $\left\{ \epsilon _ { t } \right\}$ is a sequence of independent Gaussian white noises with mean zero and variance 1. All parameter estimates are highly significant with $p$ -values less than 0.0006. The Ljung–Box statistics of the standardized residuals and their squared series fail to suggest any model inadequacy. It is reassuring to see that the risk premium is positive and significant. The GARCH model in Eq. (12.57) can be written as

$$
(1 - 1. 7 6 5 B + 0. 7 7 5 B ^ {2}) a _ {t} ^ {2} = 0. 5 4 6 + (1 - 0. 0 2 5 B) \eta_ {t},
$$

where $\eta _ { t } = a _ { t } ^ { 2 } - h _ { t }$ and $B$ is the back-shift operator such that $B a _ { t } ^ { 2 } = a _ { t - 1 } ^ { 2 }$ . As discussed in Chapter 3, the prior equation can be regarded as an ARMA(2,1) model with nonhomogeneous innovations for the squared series $a _ { t } ^ { 2 }$ . The AR polynomial can be factorized as $( 1 - 0 . 9 4 5 B ) ( 1 - 0 . 8 2 0 B )$ , indicating two real characteristic

roots with magnitudes less than 1. Consequently, the unconditional variance of $r _ { t }$ is finite and equal to $0 . 5 4 6 / ( 1 - 1 . 7 6 5 + 0 . 7 7 5 ) \approx 4 9 . 6 4$ .

Turn to Markov switching models. We use the following prior distributions:

$$
\beta_ {1} \sim N (0. 3, 0. 0 9), \quad \beta_ {2} \sim N (1. 3, 0. 0 9), \quad \epsilon_ {i} \sim \operatorname {B e t a} (5, 9 5).
$$

The initial parameter values used are (a) $e _ { i } = 0 . 1$ , (b) $s _ { 1 }$ is a Bernoulli trial with equal probabilities and $s _ { t }$ is generated sequentially using the initial transition probabilities, and (c) $\pmb { \alpha } _ { 1 } = ( 1 . 0 , 0 . 6 , 0 . 2 ) ^ { \prime }$ and $\pmb { \alpha } _ { 2 } = ( 2 , 0 . 7 , 0 . 1 ) ^ { \prime }$ . Gibbs samples of $\alpha _ { i j }$ are drawn using the Griddy Gibbs with 400 grid points, equally spaced over the following ranges: $\alpha _ { i 0 } \in [ 0 , 6 . 0 ]$ , $\alpha _ { i 1 } \in [ 0 , 1 ]$ , and $\alpha _ { i 2 } \in [ 0 , 0 . 5 ]$ . In addition, we implement the constraints $\alpha _ { i 1 } + \alpha _ { i 2 } < 1$ for $i = 1$ , 2. The Gibbs sampler is run for $5 0 0 0 + 2 0 0 0$ iterations but only results of the last 2000 iterations are used to make inference.

Table 12.5 shows the posterior means and standard deviations of parameters of the Markov switching GARCH-M model in Eq. (12.55). In particular, it also contains some statistics showing the difference between the two states such as $\theta = \beta _ { 2 } - \beta _ { 1 }$ . The difference between the risk premiums is statistically significant at the $5 \%$ level. The differences in posterior means of the volatility parameters between the two states appear to be insignificant. Yet the posterior distributions of volatility parameters show some different characteristics. Figures 12.15 and 12.16 show the histograms of all parameters in the Markov switching GARCH-M model.

Table 12.5. A Fitted Markov Switching GARCH-M Model for the Monthly Log Returns of GE Stock from January 1926 to December 1999a   

<table><tr><td colspan="6">State 1</td></tr><tr><td>Parameter</td><td>β1</td><td>e1</td><td>α10</td><td>α11</td><td>α12</td></tr><tr><td>Posterior mean</td><td>0.111</td><td>0.089</td><td>2.070</td><td>0.844</td><td>0.033</td></tr><tr><td>Posterior standard error</td><td>0.043</td><td>0.012</td><td>1.001</td><td>0.038</td><td>0.033</td></tr><tr><td colspan="6">State 2</td></tr><tr><td>Parameter</td><td>β2</td><td>e2</td><td>α20</td><td>α21</td><td>α22</td></tr><tr><td>Posterior mean</td><td>0.247</td><td>0.112</td><td>2.740</td><td>0.869</td><td>0.068</td></tr><tr><td>Posterior standard error</td><td>0.050</td><td>0.014</td><td>1.073</td><td>0.031</td><td>0.024</td></tr><tr><td colspan="6">Difference Between States</td></tr><tr><td>Parameter</td><td>β2-β1</td><td>e2-e1</td><td>α20-α10</td><td>α21-α11</td><td>α22-α12</td></tr><tr><td>Posterior mean</td><td>0.135</td><td>0.023</td><td>0.670</td><td>0.026</td><td>-0.064</td></tr><tr><td>Posterior standard error</td><td>0.063</td><td>0.019</td><td>1.608</td><td>0.050</td><td>0.043</td></tr></table>

aThe numbers shown are the posterior means and standard deviations based on a Gibbs sampling with $5 0 0 0 + 2 0 0 0$ iterations. Results of the first 5000 iterations are discarded. The prior distributions and initial parameter estimates are given in the text.

![](images/fe49fc97b33153d615c1b7f88f3d9869f22d0de8edaf07deebe8e0c23f92b805.jpg)

![](images/ee25f95e28c0d321fd94feaa0da51227395b54218b69fc1844afd130cc14340c.jpg)

![](images/54a1c61355ba91cfa665d8013bac27a11bac70346a1920831f5ff21156db0134.jpg)

![](images/71e4cb208bddec6fc89c74b27d4b5df5fe8a6a2c3e55d907e8764311ef2aafbe.jpg)  
Figure 12.15. Histograms of the risk premium and transition probabilities of a two-state Markov switching GARCH-M model for the monthly log returns of GE stock from 1926 to 1999. The results are based on the last 2000 iterations of a Gibbs sampling with $5 0 0 0 + 2 0 0 0$ total iterations.

![](images/1330f4920410ac5a49221b18594c536a86172b1bdc531a648d9af52ebbd0c262.jpg)

![](images/fb008d216c2798d95e1e43391c7125ac80b441ad67fc344d057b9c5d68fd3f13.jpg)

![](images/66588e277e89802203e94a1d9241996fa71c3d44d17e000f29ab265205b0b57f.jpg)

![](images/bebdd9ffe76d0c2959b6ec6af0d2ec5efb08c08f50a2c59749a44411d89b3f39.jpg)

![](images/0d40e4880b7335d49fe51cdedf13332a2b9f59c80408e596dca66b4998fb7b19.jpg)

![](images/b1652542271e11ff20b255ed2a999d8c72da77a8ded4fa1b4a47178e7e451477.jpg)  
Figure 12.16. Histograms of volatility parameters of a two-state Markov switching GARCH-M model for the monthly log returns of GE stock from 1926 to 1999. The results are based on the last 2000 iterations of a Gibbs sampling with $5 0 0 0 + 2 0 0 0$ total iterations.

![](images/cf2255c75f0eaabc27dbf0e4b3e7074c0325c414c5131d70dbcb57f2074b1c4e.jpg)

![](images/af034cf7d99b410e500096ec3422676a38786c57971d0c8c2b8495f8718aeb7d.jpg)  
Figure 12.17. Time plots of the persistent parameter $\alpha _ { i 1 } + \alpha _ { i 2 }$ of a two-state Markov switching GARCH-M model for the monthly log returns of GE stock from 1926 to 1999. The results are based on the last 2000 iterations of a Gibbs sampling with $5 0 0 0 + 2 0 0 0$ total iterations.

They exhibit some differences between the two states. Figure 12.17 shows the time plot of the persistent parameter $\alpha _ { i 1 } + \alpha _ { i 2 }$ for the two states. It shows that the persistent parameter of state 1 reaches the boundary 1.0 frequently, but that of state 2 does not. The expected durations of the two states are about 11 and 9 months, respectively. Figure 12.14b shows the posterior probability of being in state 2 for each observation.

Finally, we compare the fitted volatility series of the simple GARCH-M model in Eq. (12.57) and the Markov switching GARCH-M model in Eq. (12.55). The two fitted volatility series (Figure 12.18) show similar patterns and are consistent with the behavior of the squared log returns. The simple GARCH-M model produces a smoother volatility series with lower estimated volatilities.

# 12.10 FORECASTING

Forecasting under the MCMC framework can be done easily. The procedure is simply to use the fitted model in each Gibbs iteration to generate samples for the forecasting period. In a sense, forecasting here is done by using the fitted model to simulate realizations for the forecasting period. We use the univariate

![](images/66edfd378dba9c382452b1c074a6c067f186bb28a307a4cf7ba7345c3ad4df3e.jpg)

![](images/a5b2e3a3cdd6b23457ebbdcddfd18eb127551472d907a7e4928289c4dab88605.jpg)

![](images/27fc7a735d25a686bdb2a3bc36a8a42be76e8d8fcde77c60a33b5823d2f0f2e1.jpg)  
Figure 12.18. Fitted volatility series for the monthly log returns of GE stock from 1926 to 1999: (a) the squared log returns, (b) the GARCH-M model in Eq. (12.57), and (c) the two-state Markov switching GARCH-M model in Eq. (12.55).

stochastic volatility model to illustrate the procedure; forecasts of other models can be obtained by the same method.

Consider the stochastic volatility model in Eqs. (12.20) and (12.21). Suppose that there are $n$ returns available and we are interested in predicting the return $r _ { n + i }$ and volatility $h _ { n + i }$ for $i = 1 , \ldots , \ell$ , where $\ell > 0$ . Assume that the explanatory variables $x _ { j t }$ in Eq. (12.20) are either available or can be predicted sequentially during the forecasting period. Recall that estimation of the model under the MCMC framework is done by Gibbs sampling, which draws parameter values from their conditional posterior distributions iteratively. Denote the parameters by $\beta _ { j } = ( \beta _ { 0 , j } , \ldots , \beta _ { p , j } ) ^ { \prime }$ , ${ \pmb { \alpha } } _ { j } = ( \alpha _ { 0 , j } , \alpha _ { 1 , j } ) ^ { \prime }$ , and $\sigma _ { v , j } ^ { 2 }$ for the $j$ th Gibbs iteration. In other words, at the $j$ th Gibbs iteration, the model is

$$
r _ {t} = \beta_ {0, j} + \beta_ {1, j} x _ {1 t} + \dots + \beta_ {p, j} x _ {p t} + a _ {t}, \tag {12.58}
$$

$$
\ln h _ {t} = \alpha_ {0, j} + \alpha_ {1, j} \ln h _ {t - 1} + v _ {t}, \quad \operatorname {V a r} (v _ {t}) = \sigma_ {v, j} ^ {2}. \tag {12.59}
$$

We can use this model to generate a realization of $r _ { n + i }$ and $h _ { n + i }$ for $i = 1 , \ldots , \ell$ . Denote the simulated realizations by $r _ { n + i , j }$ and $h _ { n + i , j }$ , respectively. These realizations are generated as follows:

• Draw a random sample $v _ { n + 1 }$ from $N ( 0 , \sigma _ { v , j } ^ { 2 } )$ and use Eq. (12.59) to compute $h _ { n + 1 , j }$ .   
• Draw a random sample $\epsilon _ { n + 1 }$ from $N ( 0 , 1 )$ to obtain $a _ { n + 1 , j } = \sqrt { h _ { n + 1 , j } } \epsilon _ { n + 1 }$ and use Eq. (12.58) to compute $r _ { n + 1 , j }$ .   
• Repeat the prior two steps sequentially for $n + i$ with $i = 2 , \ldots , \ell$

If we run a Gibbs sampling for $M + N$ iterations in model estimation, we only need to compute the forecasts for the last $N$ iterations. This results in a random sample for $r _ { n + i }$ and $h _ { n + i }$ . More specifically, we obtain

$$
\{r _ {n + 1, j}, \ldots , r _ {n + \ell , j} \} _ {j = 1} ^ {N}, \quad \{h _ {n + 1, j}, \ldots , h _ {n + \ell , j} \} _ {j = 1} ^ {N}.
$$

These two random samples can be used to make inference. For example, point forecasts of the return $r _ { n + i }$ and volatility $h _ { n + i }$ are simply the sample means of the two random samples. Similarly, the sample standard deviations can be used as the standard deviations of forecast errors. To improve the computational efficiency in volatility forecast, importance sampling can be used; see Gelman, Carlin, Stern, and Rubin (2003).

Example 12.7 (Example 12.3 Continued). As a demonstration, we consider the monthly log return series of the S&P 500 index from 1962 to 1999. Table 12.6 gives the point forecasts of the return and its volatility for five forecast horizons starting with December 1999. Both the GARCH model in Eq. (12.26) and the stochastic volatility model in Eq. (12.27) are used in the forecasting. The volatility forecasts of the GARCH(1,1) model increase gradually with the forecast horizon to the unconditional variance $3 . 3 4 9 / ( 1 - 0 . 0 8 6 - 0 . 7 3 5 ) = 1 8 . 7 8$ . The volatility

Table 12.6. Volatility Forecasts for the Monthly Log Return of the S&P 500 Index   

<table><tr><td>Horizon</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td colspan="6">Log Return</td></tr><tr><td>GARCH</td><td>0.66</td><td>0.66</td><td>0.66</td><td>0.66</td><td>0.66</td></tr><tr><td>SVM</td><td>0.53</td><td>0.78</td><td>0.92</td><td>0.88</td><td>0.84</td></tr><tr><td colspan="6">Volatility</td></tr><tr><td>GARCH</td><td>17.98</td><td>18.12</td><td>18.24</td><td>18.34</td><td>18.42</td></tr><tr><td>SVM</td><td>19.31</td><td>19.36</td><td>19.35</td><td>19.65</td><td>20.13</td></tr></table>

aThe data span is from January 1962 to December 1999 and the forecast origin is December 1999. Forecasts of the stochastic volatility model are obtained by a Gibbs sampling with $2 0 0 0 +$ 2000 iterations.

forecasts of the stochastic volatility model are higher than those of the GARCH model. This is understandable because the stochastic volatility model takes into consideration the parameter uncertainty in producing forecasts. In contrast, the GARCH model assumes that the parameters are fixed and given in Eq. (12.26). This is an important difference and is one of the reasons that GARCH models tend to underestimate the volatility in comparison with the implied volatility obtained from derivative pricing.

Remark. Besides the advantage of taking into consideration parameter uncertainty in forecast, the MCMC method produces in effect a predictive distribution of the volatility of interest. The predictive distribution is more informative than a simple point forecast. It can be used, for instance, to obtain the quantiles needed in value at risk calculation. 

# 12.11 OTHER APPLICATIONS

The MCMC method is applicable to many other financial problems. For example, Zhang, Russell, and Tsay (2000) use it to analyze information determinants of bid and ask quotes, McCulloch and Tsay (2001) use the method to estimate a hierarchical model for IBM transaction data, and Eraker (2001) and Elerian, Chib, and Shephard (2001) use it to estimate diffusion equations. The method is also useful in value at risk calculation because it provides a natural way to evaluate predictive distributions. The main question is not whether the methods can be used in most financial applications, but how efficient the methods can become. Only time and experience can provide an adequate answer to the question.

# EXERCISES

12.1. Suppose that $x$ is normally distributed with mean $\mu$ and variance 4. Assume that the prior distribution of $\mu$ is also normal with mean 0 and variance 25. What is the posterior distribution of $\mu$ given the data point $x$ ?

12.2. Consider the linear regression model with time series errors in Section 12.5. Assume that $z _ { t }$ is an $\operatorname { A R } ( p )$ process (i.e., $z _ { t } = \phi _ { 1 } z _ { t - 1 } + \cdot \cdot \cdot + \phi _ { p } z _ { t - p } + a _ { t } )$ . Let $\pmb { \phi } = ( \phi _ { 1 } , \ldots , \phi _ { p } ) ^ { \prime }$ be the vector of AR parameters. Derive the conditional posterior distributions of $f ( \beta | Y , X , \phi , \sigma ^ { 2 } )$ , $f ( \phi | Y , X , \beta , \sigma ^ { 2 } )$ , and $f ( \sigma ^ { 2 } | Y , X , \beta , \phi )$ assuming that conjugate prior distributions are used: that is,

$$
\boldsymbol {\beta} \sim N (\boldsymbol {\beta} _ {o}, \boldsymbol {\Sigma} _ {o}), \quad \boldsymbol {\phi} \sim N (\boldsymbol {\phi} _ {o}, \boldsymbol {A} _ {o}), \quad (v \lambda) / \sigma^ {2} \sim \chi_ {v} ^ {2}.
$$

12.3. Consider the linear $\operatorname { A R } ( p )$ model in Section 12.6.1. Suppose that $x _ { h }$ and $x _ { h + 1 }$ are two missing values with a joint prior distribution being multivariate normal with mean ${ \pmb \mu } _ { o }$ and covariance matrix $\Sigma _ { o }$ . Other prior distributions are the same as that in the text. What is the conditional posterior distribution of the two missing values?

12.4. Consider the monthly log returns of General Motors stock from 1950 to 1999 with 600 observations: (a) build a GARCH model for the series, (b) build a stochastic volatility model for the series, and (c) compare and discuss the two volatility models.   
12.5. Build a stochastic volatility model for the daily log return of Cisco Systems stock from January 1991 to December 1999. You may download the data from the CRSP database or the file d-csco9199.txt. Use the model to obtain a predictive distribution for 1-step ahead volatility forecast at the forecast origin December 1999. Finally, use the predictive distribution to compute the value at risk of a long position worth $\$ 1$ million with probability 0.01 for the next trading day.   
12.6. Build a bivariate stochastic volatility model for the monthly log returns of General Motors stock and the S&P 500 index for the sample period from January 1950 to December 1999. Discuss the relationship between the two volatility processes and compute the time-varying beta for GM stock.

# REFERENCES

Artigas, J. C. and Tsay, R. S. (2004). Effective estimation of stochastic diffusion models with leverage effects and jumps. Working paper, Graduate School of Business, University of Chicago.   
Box, G. E. P. and Tiao, G. C. (1973). Bayesian Inference in Statistical Analysis. Addison-Wesley, Reading, MA.   
Carter, C. K. and Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika 81: 541–553.   
Chang, I., Tiao, G. C., and Chen, C. (1988). Estimation of time series parameters in the presence of outliers. Technometrics 30: 193–204.   
Carlin, B. P. and Louis, T. A. (2000). Bayes and Empirical Bayes Methods for Data Analysis, 2nd edition. Chapman and Hall, London.   
Chib, S., Nardari, F., and Shephard, N. (2002). Markov chain Monte Carlo methods for stochastic volatility models. Journal of Econometrics 108: 281–316.   
DeGroot, M. H. (1990). Optimal Statistical Decisions. McGraw-Hill, New York.   
Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm (with discussion). Journal of the Royal Statistical Society Series B 39: 1–38.   
Elerian, O., Chib, S. and Shephard, N. (2001). Likelihood inference for discretely observed nonlinear diffusions. Econometrica 69: 959–993.   
Eraker, B. (2001). Markov chain Monte Carlo analysis of diffusion with application to finance. Journal of Business & Economic Statistics 19: 177–191.   
Fruhwirth-Schnatter, S. (1994). Data augmentation and dynam ¨ ic linear models. Journal of Time Series Analysis 15: 183–202.

Gelfand, A. E. and Smith, A. F. M. (1990). Sampling-based approaches to calculating marginal densities. Journal of the American Statistical Association 85: 398–409.   
Gelfand, A. E., Hills, S. E., Racine-Poon, A., and Smith, A. F. M. (1990). Illustration of Bayesian inference in normal data models using Gibbs sampling, Journal of the American Statistical Association 85: 972–985.   
Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. B. (2003). Bayesian Data Analysis, 2nd edition. Chapman and Hall/CRC Press, London.   
Geman, S. and Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence 6: 721–741.   
Hasting, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika 57: 97–109.   
Jacquier, E., Polson, N. G., and Rossi, P. E. (1994). Bayesian analysis of stochastic volatility models (with discussion). Journal of Business & Economic Statistics 12: 371–417.   
Jacquier, E., Polson, N. G., and Rossi, P. E. (2004). Bayesian analysis of stochastic volatility models with fat-tails and correlated errors. Journal of Econometrics 122: 185–212.   
Jones, R. H.(1980). Maximum likelihood fitting of ARMA models to time series with missing observations. Technometrics 22: 389–395.   
Justel, A., Pena, D., and Tsay, R. S. (2001). Detection of outlier patches i ˜ n autoregressive time series. Statistica Sinica 11: 651–673.   
Kim, S., Shephard, N., and Chib, S. (1998). Stochastic volatility: Likelihood inference and comparison with ARCH models. Review of Economic Studies 65: 361–393.   
Liu, J., Wong, W. H., and Kong, A. (1994). Correlation structure and convergence rate of the Gibbs samplers I: Applications to the comparison of estimators and augmentation schemes. Biometrika 81: 27–40.   
McCulloch, R. E. and Tsay, R. S. (1994a), Bayesian analysis of autoregressive time series via the Gibbs sampler. Journal of Time Series Analysis 15: 235–250.   
McCulloch, R. E. and Tsay, R. S. (1994b). Statistical analysis of economic time series via Markov switching models. Journal of Time Series Analysis 15: 523–539.   
McCulloch, R. E. and Tsay, R. S. (2001). Nonlinearity in high-frequency financial data and hierarchical models. Studies in Nonlinear Dynamics and Econometrics 5: 1–17.   
Metropolis, N. and Ulam, S. (1949). The Monte Carlo method. Journal of the American Statistical Association 44: 335–341.   
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. (1953). Equation of state calculations by fast computing machines. Journal of Chemical Physics 21: 1087–1092.   
Tanner, M. A. (1996). Tools for Statistical Inference: Methods for the Exploration of Posterior Distributions and Likelihood Functions, 3rd edition. Springer-Verlag, New York.   
Tanner, M. A. and Wong, W. H. (1987). The calculation of posterior distributions by data augmentation (with discussion). Journal of the American Statistical Association 82: 528–550.   
Tierney, L. (1994). Markov chains for exploring posterior distributions (with discussion). Annals of Statistics 22: 1701–1762.   
Tsay, R. S. (1988). Outliers, level shifts, and variance changes in time series. Journal of Forecasting 7: 1–20.

Tsay, R. S., Pena, D., and Pankratz, A. (2000). Outliers in multivariate ti˜ me series. Biometrika 87: 789–804.   
Zhang, M. Y., Russell, J. R., and Tsay, R. S. (2000). Determinants of bid and ask quotes and implications for the cost of trading. Working paper, Statistics Research Center, Graduate School of Business, University of Chicago.

# Index

ACD, see Autoregressive conditional duration

Activation function, see Neural network

Airline model, 75

Akaike information criterion (AIC), 41, 356

Arbitrage, 391

Autoregressive conditional hetereoscedastic (ARCH) effect, 101

Autoregressive conditional hetereoscedastic (ARCH) model, 102

estimation, 107

t distribution, 108

GED innovation, 108 normal, 107

Arranged autoregression, 189

Augmented Dickey−Fuller test, 69

Autocorrelation function (ACF), 26

Autoregressive conditional duration (ACD) model, 227

exponential, 228

generalized Gamma, 229

threshold, 236

Weibull, 228

Autoregressive integrated moving-average (ARIMA) model, 67

Autoregressive model, 32

estimation, 43

forecasting, 47

order, 41

stationarity, 40

Autoregressive moving-average (ARMA) model, 56

forecasting, 61

Back propagation (BP) neural network, 180

Back-shift operator, 36

Bartlett’s formula, 27

Bayesian information criterion (BIC), 42

Bid–ask bounce, 211

Bid–ask spread, 211

Bilinear model, 156

Black−Scholes differential equation, 263

Black−Scholes formula European call option, 97, 265 European put option, 265

Brownian motion, 255 geometric, 258 standard, 253

Business cycle, 37

Canonical correlation analysis, 385

Characteristic equation, 40

Characteristic root, 36, 40

Cholesky decomposition, 350, 397, 455

Co-integration, 82, 376

Co-integration test maximum eigenvalue, 385 trace, 385

Common factor, 477

Common trend, 378

Companion matrix, 354

Compounding, 4

Conditional distribution, 8

Conditional forecast, 48

Conditional heteroscedasticity, 86 HAC covariance estimator, 86

Conditional heteroscedasticity ARMA (CHARMA) model, 131

Conditional likelihood method, 53

Conjugate prior, see Distribution

Correlation

coefficient, 25

constant, 459

time-varying, 464

Cost-of-carry model, 390

Covariance matrix, 340

Cross-correlation matrix, 340, 341

Cross-validation, 170

Data

3M stock return, 19, 59, 66, 164

Cisco stock return, 260, 472, 480

Citi-Group stock return, 19

Civilian employment number, 412

consumer price index, 412

equal-weighted index, 19, 52, 54, 91, 157, 190

GE stock return, 591

Hewlett-Packard stock return, 423

Hong Kong market index, 445

IBM stock return, 19, 28, 126, 135, 136, 161, 180, 190, 259, 292, 295, 298, 300, 307, 313, 323, 343, 423, 462, 478, 573

IBM transactions, 213, 215, 219, 223, 234, 240

Intel stock return, 19, 100, 109, 299, 423, 472, 480

Japan market index, 445

Johnson and Johnson’s earning, 72

Mark/Dollar exchange rate, 104

Merrill Lynch stock return, 423

Microsoft stock return, 19

Morgan Stanley Dean Witter stock return, 423

SP 500 excess return, 116, 132

SP 500 index futures, 390, 392

SP 500 index return, 135, 138, 141, 343, 462, 472, 478, 569, 573, 586

SP 500 spot price, 392

U.S. 3-month treasury bill rate, 173

U.S. government bond, 21, 345, 431

U.S. interest rate, 21, 80, 556, 564

U.S. monthly unemployment rate, 159

U.S. real GNP, 38, 165

U.S. unemployment rate, 194

value-weighted index, 19, 28, 41, 91, 126, 190

Data augmentation, 544

Decomposition model, 221

Descriptive statistics, 19

Diagonal VEC model, 447

Dickey−Fuller test, 68

Differencing, 68 seasonal, 74

Distribution beta, 549

conjugate prior, 548

double exponential, 276

Frechet family, 303

gamma, 243, 549

generalized error, 108

generalized extreme value, 302

generalized Gamma, 245

generalized Pareto, 320, 330

inverted chi-squared, 551

Laplacian, 275

multivariate t, 482

multivariate normal, 399, 549

negative binomial, 550

Poisson, 550

posterior, 548

prior, 548

Weibull, 244

Diurnal pattern, 212

Donsker’s theorem, 254

Duration

between trades, 215

model, 225

Durbin−Watson statistic, 85

EGARCH model, 124

forecasting, 128

Eigenvalue, 396

Eigenvector, 396

EM algorithm, 544

Error-correction model, 380

Estimation, extreme value parameter, 304

Exact likelihood method, 53

Exceedance, 318

Exceeding times, 318

Excess return, 5

Extended autocorrelation function, 59

Extreme value theory, 301

Factor analysis, 426

Factor mimicking portfolio, 420

Factor model

common factor, 406

estimation, 428

factor loading, 406

specific factor, 406

Factor rotation, varimax, 429

Filtering, 493

Forecast

horizon, 47

origin, 47

Forecast updating formula, 513

Forecasting, see Markov chain Monte Carlo method

Forward filtering and backward sampling, 583

Fractional differencing, 89

GARCH model, 114

Cholesky decomposition, 468

diagonal multivariate

multivariate, 459

time-varying correlation, 466

GARCH-M model, 123, 588

Generalized least squares, 415

Generalized Pareto distribution, 320

Geometric ergodicity, 158

Gibbs sampling, 545

Global minimum variance portfolio, 411

Griddy Gibbs, 553

Hazard function, 245

Hh function, 281

Hill estimator, 306

Hyperparameter, 554

Identifiability, 371

IGARCH model, 122, 290

Implied volatility, 98

Impulse response function, 63, 362

Innovation, 31

Inverted yield curve, 82

Invertibility, 52, 379

Invertible ARMA model, 62

Ito’s lemma, 258

multivariate, 273

Ito process, 256

Joint distribution function, 7

Jump diffusion, 275

Kalman filter, 496, 524

Kalman gain, 495, 524

Kernel, 168

bandwidth, 169

Epanechnikov, 169

Gaussian, 169

Kernel regression, 168

Kurtosis, 9

excess, 9

Lag operator, 36

Lead-lag relationship, 341

Leptokurtic, 9

Leverage effect, 99, 125, 579

Likelihood function, 17

Linear time series, 31

Liquidity, 210

Ljung−Box statistic, 27, 101

multivariate, 346

Local linear regression, 173

Local trend model, 491

Log return, 5

Logit model, 239

Long position, 6

Long-memory

stochastic volatility, 135

time series, 89

Marginal distribution, 7

Market model, 408

Markov chain Monte Carlo method (MCMC), 177, 594

Markov process, 543

Markov property, 32

Markov switching model, 164, 588

Martingale difference, 114

Maximum likelihood estimate (MLE),

exact, 368

Mean equation, 101

Mean excess function, 321

Mean excess plot, 321

Mean reversion, 49, 63

half-life, 49

Metropolis algorithm, 551

Metropolis−Hasting algorithm, 552

Missing value, 531, 558

Model checking, 44

Moment of a random variable, 8

Moving-average model, 50

Nadaraya−Watson estimator, 169

Neural network, 177

activation function, 178

feed-forward, 177

skip layer, 179

Neuron, see Neural network

Node, see Neural network

Nonlinearity test, 183

Brock-Dechert-Scheinkman (BDS), 185

bispectral, 184

F-test, 188

Keenan, 187

RESET, 186

Tar-F, 190

Nonstationarity, unit-root, 64

Nonsynchronous trading, 207

Nuisance parameter, 188

American, 252

at-the-money, 252

European call, 97

in-the-money, 252

out-of-the-money, 252

stock, 252

strike price, 97, 252

Order statistics, 299

Ordered probit model, 218

Orthogonal factor model, 427

Outlier

additive, 558

detection, 561

Parametric bootstrap, 192

Partial autoregressive function (PACF), 40

Peaks over thresholds, 318

$\pi$ -weight, 62

Pickands estimator, 306

Platykurtic, 9

Poisson process, 275

inhomogeneous, 329

intensity function, 322

Portmanteau test, 27. See also Ljung–Box statistic

Positive definite matrix, 396

Prediction, 493

Present value, 4

Price change and duration (PCD) model, 238

Principal component analysis, 421, 478

$\psi$ -weight, 31

Put-call parity, 266

Quantile, 8

definition, 289

R-square, 46

adjusted, 47

Random coefficient (RCA) model, 133

Random walk, 64

with drift, 65

Realized volatility, 141, 492

Reduced form model, 349

Regression, with time series errors, 80

Return level, 317

stress period, 317

RiskMetrics, 290

Sample autocorrelation, 26

Scree plot, 425

Seasonal adjustment, 72

Seasonal model, 72

multiplicative, 75

Shape parameter of a distribution, 302

Shock, 31, 48, 101

Short position, 6

Simple return, 3

Skewness, 9

Smoothed disturbance, 528

Smoothing, 167, 493

Square root of time rule, 291

Standard Brownian motion, 69

State space model, 509 nonlinear, 176

Stationarity, 25

weak, 340

Steady state, 525

Stochastic diffusion equation, 256

Stochastic volatility model, 134, 565 multivariate, 571

Structural equation, 350

Structural form, 350

Structural time series model (STSM), 491, 521

Student-t distribution standardized, 108

Survival function, 322

Tail index, 302

TGARCH model, 130

general form, 161

Threshold, 159

Threshold autoregressive model multivariate, 392

self-exciting, 159

smooth, 163

Threshold co-integration, 392

Time plot, 17

Transactions data, 212

Trend stationary model, 67

Unit-root test, 68

Unit-root time series, 64

Unobserved component model, 521

Value at Risk (VaR), 287, 480

econometric approach, 294

homogeneous Poisson process, 324

inhomogeneous Poisson process, 328

RiskMetrics, 290

of a short position, 316

traditional extreme value, 312

Vector autoregressive (VAR) model, 349

Vector ARMA model, 371

marginal models, 375

Vector moving average model, 365

VIX Volatility Index, 98

Volatility, 97

Volatility equation, 101

Volatility model

factor, 477

Volatility smile, 274

Weighted least squares, 415

White noise, 31

Wiener process, 253

generalized, 255

Yule–Walker equation

multivariate, 354

# WILEY SERIES IN PROBABILITY AND STATISTICS ESTABLISHED BY WALTER A. SHEWHART AND SAMUEL S.WILKS

Editors: David J.Balding, Noel A.C. Cressie, Nicholas I. Fisher, lain M.Johnstone, J.B. Kadane, Geert Molenberghs.Louise M. Ryan, David W. Scott, Adrian F. M. Smith, Jozef L. Teugels Editors Emeriti:Vic Barnett,J.Stuart Hunter,David G.Kendall

The Wiley Series in Probability and Statistics iswell established and authoritative.It covers many topics of current research interest in both pure and applied statistics and probability theory.Written by leading statisticians and institutions,the titles span both state-of-the-art developments in the field and classical methods.

Reflecting the wide range of current research in statistics,the series encompasses applied, methodological and theoretical statistics,ranging from applications and new techniques made possible by advances in computerized practice to rigorous treatment of theoretical approaches.

This series provides essential and invaluable reading for all statisticians,whether in academia,industry,government,or research.

ABRAHAM and LEDOLTER $\cdot$ Statistical Methods for Forecasting

AGRESTI $\cdot$ Analysis of Ordinal Categorical Data

AGRESTI $\cdot$ An Introduction to Categorical Data Analysis

AGRESTI $\cdot$ Categorical Data Analysis,Second Edition

ALTMAN,GILL,and McDONALD $\cdot$ Numerical Issues in Statistical Computing for the Social Scientist

AMARATUNGA and CABRERA $\cdot$ Exploration and Analysis of DNA Microarray and Protein Array Data

ANDEL·Mathematics of Chance

ANDERSON $\cdot$ An Introduction to Multivariate Statistical Analysis, Third Edition

*ANDERSON $\cdot$ The Statistical Analysis of Time Series

ANDERSON,AUQUIER,HAUCK,OAKES,VANDAELE,and WEISBERG · Statistical Methods for Comparative Studies

ANDERSON and LOYNES $\cdot$ The Teaching of Practical Statistics

ARMITAGE and DAVID (editors) $\cdot$ Advances in Biometry

ARNOLD, BALAKRISHNAN, and NAGARAJA $\cdot$ Records

* ARTHANARI and DODGE $\cdot$ Mathematical Programming in Statistics

*BAILEY · The Elements of Stochastic Processes with Applications to the Natural Sciences

BALAKRISHNAN and KOUTRAS · Runs and Scans with Applications

BARNETT·Comparative Statistical Inference,Third Edition

BARNETT and LEWIS·Outliers in Statistical Data, Third Edition

BARTOSZYNSKI and NIEWIADOMSKA-BUGAJ $^ { * }$ Probability and Statistical Inference

BASILEVSKY $\cdot$ Statistical Factor Analysis and Related Methods: Theory and Applications

BASU and RIGDON $\cdot$ Statistical Methods for the Reliability of Repairable Systems

BATES and WATTS $\cdot$ Nonlinear Regression Analysis and Its Applications

BECHHOFER,SANTNER,and GOLDSMAN $\cdot$ Design and Analysis of Experiments for Statistical Selection, Screening,and Multiple Comparisons

BELSLEY $\cdot$ Conditioning Diagnostics: Collinearity and Weak Data in Regression

↑ BELSLEY, KUH,and WELH $\cdot$ Regression Diagnostics:Identifying Influential Data and Sources of Collinearity

BENDAT and PIERSOL $\ast$ Random Data: Analysis and Measurement Procedures, ThirdEdition

BERRY,CHALONER,and GEWEKE $\cdot$ Bayesian Analysis in Statistics and Econometrics: Essays in Honor of Arnold Zellner

BERNARDO and SMITH $\cdot$ Bayesian Theory

BHAT and MILLER·Elements of Applied Stochastic Processes, Third Edition

BHATTACHARYA and WAYMIRE·Stochastic Processes with Applications

BIEMER,OS,G,OWETZ,ndUN:eauretr in Surveys

BILLINGSLEY $^ { * }$ Convergence of Probability Measures, Second Edition

BILLINGSLEY $\cdot$ Probability and Measure,Third Edition

BIRKES and DODGE $\cdot$ Alternative Methods of Regression

BLISCHKE AND MURTHY (editors) $^ { * }$ Case Studies in Reliability and Maintenance

BLISCHKE AND MURTHY $\cdot$ Reliability: Modeling,Prediction,and Optimization

BLOOMFIELD $\cdot$ Fourier Analysis of Time Series: An Introduction, Second Edition

BOLLEN $\ast$ Structural Equations with Latent Variables

BOROVKOV $\cdot$ Ergodicity and Stability of Stochastic Processes

BOULEAU $\cdot$ Numerical Methods for Stochastic Processes

BOX·Bayesian Inference in Statistical Analysis

BOX $\cdot$ R.A.Fisher, the Life of a Scientist

BOX and DRAPER · Empirical Model-Building and Response Surfaces

* BOX and DRAPER $\ast$ Evolutionary Operation: A Statistical Method for Process Improvement

BOX, HUNTER,and HUNTER $\cdot$ Statistics for Experimenters: Design, Innovation, and Discovery,Second Editon

BOX and LUCENO $\cdot$ Statistical Control by Monitoring and Fedback Adjustment

BRANDIMARTE $\cdot$ Numerical Methods in Finance:A MATLAB-Based Introduction

BROWN and HOLLANDER $\cdot$ Statistics:A Biomedical Introduction

BRUNNER, DOMHOF,and LANGER · Nonparametric Analysis of Longitudinal Data in Factorial Experiments

BUCKLEW $\cdot$ Large Deviation Techniques in Decision, Simulation,and Estimation

CAIROLI and DALANG $\cdot$ Sequential Stochastic Optimization

CASTILLO, HADI, BALAKRISHNAN, and SARABIA $\cdot$ Extreme Value and Related Models with Applications in Engineering and Science

CHAN $^ { * }$ Time Series: Applications to Finance

CHARALAMBIDES $\cdot$ Combinatorial Methods in Discrete Distributions

CHATTERJEE and HADI · Sensitivity Analysis in Linear Regression

CHATTERJEE and PRICE·Regression Analysis by Example, Third Edition

CHERNICK $\cdot$ Bootstrap Methods:A Practitioner's Guide

CHERNICK and FRIIS $\cdot$ Introductory Biostatistics for the Health Sciences

CHILES and DELFINER $^ { * }$ Geostatistics: Modeling Spatial Uncertainty

CHOW and LIU $\cdot$ Design and Analysis of Clinical Trials: Concepts and Methodologies, Second Edition

CLARKE and DISNEY $\cdot$ Probability and Random Processes: A First Course with Applications,Second Edition

* COCHRAN and COX $\cdot$ Experimental Designs, Second Edition

CONGDON· Applied Bayesian Modelling

CONGDON $\dot { }$ Bayesian Statistical Modelling

CONOVER $\cdot$ Practical Nonparametric Statistics,Third Edition

COOK $\cdot$ Regression Graphics

COOK and WEISBERG $\cdot$ Applied Regression Including Computing and Graphics

COOK and WEISBERG $\cdot$ An Introduction to Regression Graphics

CORNELL·Experiments with Mixtures,Designs,Models,and the Analysis of Mixture Data,Third Edition

COVER and THOMAS $^ *$ Elements of Information Theory

COX $^ { * }$ A Handbook of Introductory Statistical Methods

*COX $\cdot$ Planning of Experiments

CRESSIE $\cdot$ Statistics for Spatial Data,Revised Edition

CSORGO and HORVATH $\cdot$ Limit Theorems in Change Point Analysis

DANIEL $\cdot$ Applications of Statistics to Industrial Experimentation

DANIEL ·Biostatistics: A Foundation for Analysis in the Health Sciences,Eighth Edition

*DANIEL $\cdot$ Fiting Equations to Data: Computer Analysis of Multifactor Data, Second Edition

DASU and JOHNSON $\cdot$ Exploratory Data Mining and Data Cleaning

DAVID and NAGARAJA $\cdot$ Order Statistics,Third Edition

*DEGROOT,FIENBERG,and KADANE· Statistics and the Law

DEL CASTILLO $\cdot$ Statistical Process Adjustment for Quality Control

DEMARIS $\cdot$ Regression with Social Data: Modeling Continuous and Limited Response Variables

DEMIDENK0 $\cdot$ Mixed Models: Theory and Applications

DENISON,HOLMES,MALLICK and $\cdot$ Bayesian Methods for Nonlinear Classification and Regression

DETTE and STUDDEN $\cdot$ The Theory of Canonical Moments with Applications in Statistics, Probability,and Analysis

DEY and MUKERJEE·Fractional Factorial Plans

DILLON and GOLDSTEIN $\cdot$ Multivariate Analysis: Methods and Applications

DODGE $\cdot$ Alternative Methods of Regression

* DODGE and ROMIG $\cdot$ Sampling Inspection Tables,Second Edition

*DOOB $^ { \ast }$ Stochastic Processes

DOWDY,WEARDEN,and CHILKO $\cdot$ Statistics for Research,Third Edition

DRAPER and SMITH $^ { * }$ Applied Regression Analysis, Third Edition

DRYDEN and MARDIA $\cdot$ Statistical Shape Analysis

DUDEWICZ and MISHRA $\cdot$ Modern Mathematical Statistics

DUNN and CLARK $\cdot$ Basic Statistics: A Primer for the Biomedical Sciences, Third Edition

DUPUIS and ELLIS $\cdot$ A Weak Convergence Approach to the Theory of Large Deviations

* ELANDT-JOHNSON and JOHNSON $\cdot$ Survival Models and Data Analysis ，ENDERS·Applied Econometric Time Series

ETHIER and KURTZ·Markov Processs: Characterization and Convergence $\cdot$

EVANS, HASTINGS,and PEACOCK $^ { * }$ Statistical Distributions,Third Edition

FELLER·An Introduction to Probability Theory and Its Applications, Volume I, Third Edition,Revised; Volume II, Second Edition

FISHER and VAN BELLE $\cdot$ Biostatistics:A Methodology for the Health Sciences

FITZMAURICE, LAIRD,and WARE·Applied Longitudinal Analysis

*FLEISS · The Design and Analysis of Clinical Experiments

FLEISS $*$ Statistical Methods for Rates and Proportions,Third Edition

↑FLEMING and HARRINGTON: Counting Processes and Survival Analysis

FULLER $\cdot$ Introduction to Statistical Time Series,Second Edition

FULLER $\cdot$ Measurement Error Models

GALLANT $\cdot$ Nonlinear Statistical Models

GEISSER $\cdot$ Modes of Parametric Statistical Inference

GEWEKE $\cdot$ Contemporary Bayesian Econometrics and Statistics

GHOSH, MUKHOPADHYAY,and SEN · Sequential Estimation

GIESBRECHT and GUMPERTZ $\cdot$ Planning, Construction,and Statistical Analysis of Comparative Experiments

GIFI $\cdot$ Nonlinear Multivariate Analysis

GIVENS and HOETING $^ *$ Computational Statistics

GLASSERMAN and YAO $\cdot$ Monotone Structure in Discrete-Event Systems

GNANADESIKAN $\cdot$ Methods for Statistical Data Analysis of Multivariate Observations, Second Edition

GOLDSTEIN and LEWIS $\cdot$ Assessment: Problems,Development,and Statistical Issues

GREENWOOD and NIKULIN $^ { * }$ A Guide to Chi-Squared Testing

GROSS and HARRIS $\cdot$ Fundamentalsof Queueing Theory,Third Edition

1 GROVES $\cdot$ Survey Errors and Survey Costs

* HAHN and SHAPIRO $\cdot$ Statistical Models in Engineering

HAHN and MEEKER $\cdot$ Statistical Intervals:A Guide for Practitioners

HALD ·A History of Probability and Statistics and their Applications Before 1750

HALD $\cdot$ A History of Mathematical Statistics from 1750 to i930

HAMPEL  Robust Statistics: The Approach Based on Influence Functions

HANNAN and DEISTLER $\cdot$ The Statistical Theory of Linear Systems

HEIBERGER $\cdot$ Computation for the Analysis of Designed Experiments

HEDAYAT and SINHA $\cdot$ Design and Inference in Finite Population Sampling

HELLER $^ { \ast }$ MACSYMA for Statisticians

HINKELMANN and KEMPTHORNE $\cdot$ Design and Analysis of Experiments,Volume 1: Introduction to Experimental Design

HINKELMANN and KEMPTHORNE $\cdot$ Design and Analysis of Experiments, Volume 2: Advanced Experimental Design

HOAGLIN,MOSTELLER,and TUKEY $\cdot$ Exploratory Approach to Analysis of Variance

HOAGLIN, MOSTELLER,and TUKEY $\cdot$ Exploring Data Tables,Trends and Shapes

* HOAGLIN,MOSTELLER,and TUKEY $\cdot$ Understanding Robust and Exploratory Data Analysis

HOCHBERG and TAMHANE $\cdot$ Multiple Comparison Procedures

HOCKING $\cdot$ Methods and Applications of Linear Models: Regression and the Analysis of Variance,Second Edition

HOEL $\ast$ Introduction to Mathematical Statistics,Fifth Edition

HOGG and KLUGMAN $\cdot$ Loss Distributions

HOLLANDER and WOLFE $^ { * }$ Nonparametric Statistical Methods, Second Edition

HOSMER and LEMESHOW $\cdot$ Applied Logistic Regression,Second Edition

HOSMER and LEMESHOW $\cdot$ Applied Survival Analysis: Regression Modeling of Time to Event Data

† HUBER · Robust Statistics $\cdot$

HUBERTY·Applied Discriminant Analysis

HUNT and KENNEDY $\cdot$ Financial Derivatives in Theory and Practice

HUSKOVA, BERAN,and DUPAC·Collected Works of Jaroslav Hajekwith Commentary

HUZURBAZAR $\cdot$ Flowgraph Models for Multistate Time-to-Event Data

IMAN and CONOVER·A Modern Approach to Statistics

1 JACKSON $\cdot$ A User'sGuide to PrincipleComponents

JOHN $\cdot$ Statistical Methods in Engineering and Quality Assurance

JOHNSON $\cdot$ Multivariate Statistical Simulation

JOHNSON and BALAKRISHNAN $\cdot$ Advances in the Theory and Practice of Statistics: A Volume in Honor of Samuel Kotz

JOHNSON and BHATTACHARYYA $\cdot$ Statistics:Principles and Methods,Fifth Edition

JOHNSON and KOTZ $^ { * }$ Distributions in Statistics

*Now available in a lower priced paperback edition in the Wiley Classics Library.

tNow available in a lower priced paperback edition in the Wiley-Interscience Paperback Series.

JOHNSON and KOTZ (editors) $\ast$ Leading Personalities in Statistical Sciences: From the Seventeenth Century to the Present

JOHNSON, KOTZ, and BALAKRISHNAN $\cdot$ Continuous Univariate Distributions, Volume 1, Second Edition

JOHNSON, KOTZ,and BALAKRISHNAN $\cdot$ Continuous Univariate Distributions, Volume2,Second Edition

JOHNSON, KOTZ,and BALAKRISHNAN $\cdot$ Discrete Multivariate Distributions

JOHNSON,KOTZ,and KEMP :Univariate Discrete Distributions,Third Edition

JUDGE,GRIFFITHS, HILL,LUTKEPOHL,and LEE $\cdot$ The Theory and Practice of Econometrics,Second Edition

JURECKOVA and SEN $\cdot$ Robust Statistical Procedures: Aymptotics and Interrelations

JUREK and MASON $\cdot$ Operator-Limit Distributions in Probability Theory

KADANE·Bayesian Methods and Ethics in a Clinical Trial Design

KADANE AND SCHUM $\cdot$ A Probabilistic Analysis of the Sacco and Vanzeti Evidence

KALBFLEISCHand PRENTICE $\ast$ The Statistical Analysis of Failure Time Data, Second Edition

KASS and VOS $\cdot$ Geometrical Foundations of Asymptotic Inference

KAUFMAN and ROUSSEEUW $\cdot$ Finding Groups in Data: An Introduction to Cluster Analysis

KEDEM and FOKIANOS $\cdot$ Regression Models for Time Series Analysis

KENDALL, BARDEN, CARNE,and LE·Shape and Shape Theory

KHURI $\cdot$ Advanced Calculus with Applications in Statistics,Second Edition

KHURI, MATHEW,and SINHA ·Statistical Tests for Mixed Linear Models

*KISH $\cdot$ Statistical Design for Research

KLEIBER and KOTZ·Statistical Size Distributions in Economics and Actuarial Sciences

KLUGMAN,PANJER,and WILLMOT $\cdot$ Loss Models: From Data to Decisions, Second Edition

KLUGMAN,PANJER,and WILLMOT $\cdot$ Solutions Manual to Accompany Loss Models: From Data to Decisions,Second Edition

KOTZ, BALAKRISHNAN, and JOHNSON $\cdot$ Continuous Multivariate Distributions, Volume1,Second Edition

KOTZ and JOHNSON (editors) $\ast$ Encyclopedia of Statistical Sciences: Volumes 1 to 9 with Index

KOTZ and JOHNSON (editors) $\cdot$ Encyclopedia of Statistical Sciences: Supplement Volume

KOTZ, READ, and BANKS (editors) : Encyclopedia of Statistical Sciences: Update Volume 1

KOTZ, READ,and BANKS (editors) : Encyclopedia of Statistical Sciences: Update Volume 2

KOVALENKO, KUZNETZOV,and PEGG $^ { * }$ Mathematical Theory of Reliability of Time-Dependent Systems with Practical Applications

LACHIN ·Biostatistical Methods: The Assessment of Relative Risks

LAD $\cdot$ Operational Subjective Statistical Methods: A Mathematical, Philosophical, and Historical Introduction

LAMPERTI Probability: A Survey of the Mathematical Theory, Second Edition

LANGE,RYAN,BILLARD,BRILLINGER,CONQUEST,and GREENHOUSE· Case Studies in Biometry

LARSON $\cdot$ Introduction to Probability Theory and Statistical Inference,Third Edition

LAWLESS $^ *$ Statistical Models and Methods for Lifetime Data,Second Edition

LAWSON $^ { * }$ Statistical MethodsinSpatial Epidemiology

LE·Applied Categorical Data Analysis

LE $\cdot$ Applied Survival Analysis

LEE and WANG $\cdot$ Statistical Methods for Survival Data Analysis,Third Edition

LEPAGE and BILLARD $\cdot$ Exploring the Limits of Bootstrap

LEYLAND and GOLDSTEIN (editors) $\cdot$ Multilevel Modelling of Health Statistics

LIAO $\cdot$ Statistical Group Comparison

LINDVALL $^ *$ Lectures on the Coupling Method

LINHART and ZUCCHINI $\cdot$ Model Selection

LITTLE and RUBIN $\cdot$ Statistical Analysis with Missing Data,Second Edition

LLOYD $\cdot$ The Statistical Analysis of Categorical Data

LOWEN and TEICH·Fractal-Based Point Processes

MAGNUS and NEUDECKER $\cdot$ Matrix Differential Calculus with Applications in Statistics and Econometrics,Revised Edition

MALLER and ZHOU $*$ Survival Analysis with Long Term Survivors

MALLOWS ·Design, Data,and Analysis by Some Friends of Cuthbert Daniel

MANN,SCHAFER,and SINGPURWALLA $\cdot$ Methods for Statistical Analysis of Reliabilityand Life Data

MANTON,WOODBURY,and TOLLEY $^ { * }$ Statistical Applications Using Fuzzy Sets

MARCHETTE $\cdot$ Random Graphs for Statistical Pattern Recognition

MARDIA and JUPP $\cdot$ Directional Statistics

MASON,GUNST,and HESS $\cdot$ Statistical Design and Analysis of Experiments with Applications to Engineering and Science, Second Edition

McCULLOCH and SEARLE·Generalized,Linear,and Mixed Models

McFADDEN·Management of Data in Clinical Trials

* McLACHLAN $\cdot$ Discriminant Analysis and Statistical Pattern Recognition

McLACHLAN, DO,and AMBROISE·Analyzing Microarray Gene Expression Data

McLACHLAN and KRISHNAN· The EM Algorithm and Extensions

McLACHLAN and PEEL $\cdot$ Finite Mixture Models

McNEIL $\cdot$ Epidemiological Research Methods

MEEKER and ESCOBAR·Statistical Methods for Reliability Data

MEERSCHAERT and SCHEFFLER $\cdot$ Limit Distributions for Sums of Independent Random Vectors: Heavy Tails in Theory and Practice

MICKEY,UNN,and C $\cdot$ Applied Statistics: Analysis of Variance and Regression,Third Edition

* MILLER· Survival Analysis, Second Edition

MONTGOERY,CK,ndG $\cdot$ Introduction to Linear Regression Analysis, Third Edition

MORGENTHALER and TUKEY $\cdot$ Configural Polysampling: A Route to Practical Robustness

MUIRHEAD $\cdot$ Aspects of Multivariate Statistical Theory

MULLER and STOYAN·Comparison Methods for Stochastic Models and Risks

MURRAY $\cdot$ X-STAT 2.0 Statistical Experimentation, Design Data Analysis, and Nonlinear Optimization

MURTHY,XIE,and JIANG $\cdot$ WeibullModels

MYERS and MONTGOMERY $^ { * }$ Response Surface Methodology: Process and Product Optimization Using Designed Experiments,Second Edition

MYERS,MONTGOMERY,and VINING·Generalized Linear Models.With Applications in Engineering and the Sciences

NELSON·Accelerated Testing,Statistical Models,Test Plans,and Data Analyses

NELSON $\cdot$ Applied Life Data Analysis

NEWMAN $*$ Biostatistical Methods in Epidemiology

OCHI $\cdot$ Applied Probability and Stochastic Processes in Engineering and Physical Sciences

OKABE, BOOTS, SUGIHARA, and CHIU $\cdot$ Spatial Tesselations: Concepts and Applications of Voronoi Diagrams, Second Edition

OLIVER and SMITH $\cdot$ Influence Diagrams, Belief Nets and Decision Analysis

PALTA·Quantitative Methods in Population Health: Extensions of Ordinary Regressions

*Now available in a lower priced paperback edition in the Wiley Classics Library.

tNow available in a lower priced paperback edition in the Wiley-Interscience Paperback Series.

PANKRATZ $\cdot$ Forecasting with Dynamic Regression Models

PANKRATZ $\cdot$ Forecasting with Univariate Box-Jenkins Models: Concepts and Cases

*PARZEN $\cdot$ Modern Probability Theory and Its Applications

PENA,TIAO, and TSAY $\cdot$ A Course in Time Series Analysis

PIANTADOSI $\ast$ Clinical Trials: A Methodologic Perspective

PORT·Theoretical Probability for Applications

POURAHMADI $\cdot$ Foundations of Time Series Analysis and Prediction Theory

PRESS·Bayesian Statistics: Principles,Models,and Applications

PRESS $\cdot$ Subjective and Objective Bayesian Statistics, Second Edition

PRESS and TANUR $\cdot$ The Subjectivity of Scientists and the Bayesian Approach

PUKELSHEIM $\cdot$ Optimal Experimental Design

PURI, VILAPLANA,and WERTZ $\cdot$ New Perspectives in Theoretical and Applied Statistics

fPUTERMAN : Markov Decision Processes: Discrete Stochastic Dynamic Programming QIU $^ { * }$ Image Processing and Jump Regression Analysis

*RAO $\cdot$ Linear Statistical Inference and Its Applications, Second Edition

RAUSAND and HOYLAND $\cdot$ System Reliability Theory:Models,Statistical Methods, and Applications, Second Edition

RENCHER $\cdot$ Linear Models in Statistics

RENCHER · Methods of Multivariate Analysis, Second Edition

RENCHER $\cdot$ Multivariate Statistical Inference with Applications

*RIPLEY $\cdot$ Spatial Statistics

RIPLEY $\cdot$ Stochastic Simulation

ROBINSON· Practical Strategies for Experimenting

ROHATGI and SALEH $\cdot$ An Introduction to Probability and Statistics,Second Edition

ROLSKI, SCHMIDLI, SCHMIDT,and TEUGELS : Stochastic Processes for Insurance and Finance

ROSENBERGER and LACHIN $\cdot$ Randomization in Clinical Trials: Theory and Practice

ROSS $\cdot$ Introduction to Probability and Statistics for Engineers and Scientists

ROUSSEEUW and LEROY $\cdot$ Robust Regression and Outlier Detection

*RUBIN $\cdot$ Multiple Imputation for Nonresponse in Surveys

RUBINSTEIN $\cdot$ Simulation and the Monte Carlo Method

RUBINSTEIN and MELAMED $\cdot$ Modern Simulation and Modeling

RYAN $^ *$ Modern Regression Methods

RYAN $\cdot$ Statistical Methods for Quality Improvement, Second Edition

SALTELLI, CHAN, and SCOTT (editors) $\cdot$ Sensitivity Analysis

* SCHEFFE·The Analysis of Variance

SCHIMEK $\cdot$ Smoothing and Regression: Approaches, Computation,and Application

SCHOTT $\cdot$ Matrix Analysis for Statistics,Second Edition

SCHOUTENS $^ { * }$ Levy Processes in Finance: Pricing Financial Derivatives

SCHUSS $\cdot$ Theory and Applications of Stochastic Differential Equations

SCOTT $\cdot$ Multivariate Density Estimation: Theory,Practice,and Visualization

*SEARLE $\ast$ Linear Models

SEARLE·Linear Models for Unbalanced Data

SEARLE $\cdot$ Matrix Algebra Useful for Statistics

SEARLE, CASELLA,and McCULLOCH $\cdot$ Variance Components

SEARLE and WILLETT $\cdot$ Matrix Algebra for Applied Economics

SEBER and LEE $\cdot$ Linear Regression Analysis, Second Edition

SEBER $\cdot$ Multivariate Observations

SEBER and WILD $\cdot$ Nonlinear Regression

SENNOTT · Stochastic Dynamic Programming and the Control of Queueing Systems

* SERFLING $\cdot$ Approximation Theorems of Mathematical Statistics

SHAFER and VOVK $\cdot$ Probability and Finance: It's Only a Game!

*Now available in a lower priced paperback edition in the Wiley Clasics Library.

†Now available in a lower priced paperback edition in the Wiley-Interscience Paperback Series.

SILVAPULLE and SEN $\cdot$ Constrained Statistical Inference: Inequality,Order,and Shape Restrictions

SMALL and McLEISH $\cdot$ Hilbert Space Methods in Probability and Statistical Inference

SRIVASTAVA $\cdot$ Methods of Multivariate Statistics

STAPLETON $\cdot$ Linear Statistical Models

STAUDTE and SHEATHER $\cdot$ Robust Estimation and Testing

STOYAN, KENDALL,and MECKE ·Stochastic Geometry and Its Applications, Second Edition

STOYAN and STOYAN $^ { * }$ Fractals,Random Shapes and Point Fields:Methods of Geometrical Statistics

STYAN $\cdot$ The Collected Papers of T.W. Anderson: 1943-1985

SUTTON,ABRAMS, JONES, SHELDON, and SONG $\cdot$ Methods for Meta-Analysis in Medical Research

TANAKA $\cdot$ Time Series Analysis: Nonstationary and Noninvertible Distribution Theory

THOMPSON $^ { * }$ Empirical Model Building

THOMPSON $\cdot$ Sampling,Second Edition

THOMPSON $\cdot$ Simulation: A Modeler's Approach

THOMPSON and SEBER $\cdot$ Adaptive Sampling

THOMPSON,WILLIAMS,and FINDLAY $\cdot$ Models for Investors in Real World Markets

TIAO, BISGAARD, HILL, PENA,and STIGLER (editors $\cdot$ Box on Quality and Discovery:with Design,Control,and Robustness

TIERNEY $\cdot$ LISP-STAT: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics

TSAY $\cdot$ Analysis of Financial Time Series,Second Edition

UPTON and FINGLETON $\cdot$ Spatial Data Analysis by Example,Volume II: Categorical and Directional Data

VAN BELLE·Statistical Rules of Thumb

VAN BELLE,FISHER, HEAGERTY,and LUMLEY $\cdot$ Biostatistics: A Methodology for the Health Sciences,Second Edition

VESTRUP ·The Theory of Measures and Integration

VIDAKOVIC·Statistical Modeling by Wavelets

VINOD and REAGLE · Preparing for the Worst: Incorporating Downside Risk in Stock Market Investments

WALLER and GOTWAY $\cdot$ Applied Spatial Statistics for Public Health Data

WEERAHANDI $\cdot$ Generalized Inference in Repeated Measures: Exact Methods in MANOVA and MixedModels

WEISBERG $\cdot$ Applied Linear Regression, Third Edition

WELSH $^ *$ Aspects of Statistical Inference

WESTFALL and YOUNG $\cdot$ Resampling-Based Multiple Testing: Examples and Methods for $p .$ -Value Adjustment

WHITTAKER · Graphical Models in Applied Multivariate Statistics

WINKER $\cdot$ Optimization Heuristics in Economics: Applications of Threshold Accepting

WONNACOTT and WONNACOTT $\cdot$ Econometrics,econd ition

WOODING $\cdot$ Planning Pharmaceutical Clinical Trials: Basic Statistical Principles

WOODWORTH $\cdot$ Biostatistics: A Bayesian Introduction

WOOLSON and CLARKE· Statistical Methods for the Analysis of Biomedical Data, Second Edition

WU and HAMADA $\ast$ Experiments: Planning, Analysis,and Parameter Design Optimization

YANG $\cdot$ The Construction Theory of Denumerable Markov Processes

*ZELLNER $\cdot$ An Introduction to Bayesian Inference in Econometrics

ZHOU,OBUCHOWSKI,and McCIH $\cdot$ Statistical Methods in Diagnostic Medicine

# Time Series Analysis

Lecture Notes for 475.726

Ross Ihaka

Statistics Department

University of Auckland

April 14, 2005

# Contents

# 1 Introduction 1

1.1 Time Series . . 1   
1.2 Stationarity and Non-Stationarity 1   
1.3 Some Examples . . . 2

1.3.1 Annual Auckland Rainfall . . . 2   
1.3.2 Nile River Flow . . . 2   
1.3.3 Yield on British Government Securities . . 2   
1.3.4 Ground Displacement in an Earthquake . . . . . . 3   
1.3.5 United States Housing Starts . . . . 3   
1.3.6 Iowa City Bus Ridership . . . 3

# 2 Vector Space Theory 7

2.1 Vectors In Two Dimensions . . 7

2.1.1 Scalar Multiplication and Addition . . . 7   
2.1.2 Norms and Inner Products 8

2.2 General Vector Spaces . . . 9

2.2.1 Vector Spaces and Inner Products . . 9   
2.2.2 Some Examples . . . . 11

2.3 Hilbert Spaces 12

2.3.1 Subspaces . . . 13   
2.3.2 Projections . . 13

2.4 Hilbert Spaces and Prediction . . 14

2.4.1 Linear Prediction . . 14   
2.4.2 General Prediction . . . 15

# 3 Time Series Theory 17

3.1 Time Series . . 17   
3.2 Hilbert Spaces and Stationary Time Series . . . . 18   
3.3 The Lag and Differencing Operators . . . 19   
3.4 Linear Processes 20   
3.5 Autoregressive Series . . 21

3.5.1 The AR(1) Series . . . . 21   
3.5.2 The AR(2) Series . . . . 23   
3.5.3 Computations . . . . 26

3.6 Moving Average Series . . . . 29

3.6.1 The MA(1) Series 29   
3.6.2 Invertibility . . . 29   
3.6.3 Computation . . . 30

3.7 Autoregressive Moving Average Series . . . . . 30

3.7.1 The ARMA(1,1) Series 31   
3.7.2 The ARMA(p,q) Model . . 32   
3.7.3 Computation . . 32   
3.7.4 Common Factors . . 34

3.8 The Partial Autocorrelation Function . . . 34

3.8.1 Computing the PACF 36   
3.8.2 Computation . . 37

4 Identifying Time Series Models 39

4.1 ACF Estimation 39   
4.2 PACF Estimation . . 42   
4.3 System Identification . . 43   
4.4 Model Generalisation . . . 45

4.4.1 Non-Zero Means . . . 45   
4.4.2 Deterministic Trends . . . . 47   
4.4.3 Models With Non-stationary AR Components . . . . . . . 47   
4.4.4 The Effect of Differencing . . . 48

4.5 ARIMA Models . . 49

5 Fitting and Forecasting 51

5.1 Model Fitting . . 51   
5.1.1 Computations . . . . 51

5.2 Assessing Quality of Fit . . 54   
5.3 Residual Correlations 58

5.4 Forecasting . . 59

5.4.1 Computation . . 59

5.5 Seasonal Models 61

5.5.1 Purely Seasonal Models . . . 61   
5.5.2 Models with Short-Term and Seasonal Components . . . 63   
5.5.3 A More Complex Example . . 66

6 Frequency Domain Analysis 75

6.1 Some Background 75

6.1.1 Complex Exponentials, Sines and Cosines . . . . . . . . . 75   
6.1.2 Properties of Cosinusoids . . . 76   
6.1.3 Frequency and Angular Frequency . . . . 77   
6.1.4 Invariance and Complex Exponentials . . . 77

6.2 Filters and Filtering 78

6.2.1 Filters . . 78   
6.2.2 Transfer Functions . . . 79   
6.2.3 Filtering Sines and Cosines 80   
6.2.4 Filtering General Series . . . 80   
6.2.5 Computing Transfer Functions . . . 81   
6.2.6 Sequential Filtering . . . 81

6.3 Spectral Theory . . . 82

6.3.1 The Power Spectrum . . . 82   
6.3.2 The Cram´er Representation . . . 83   
6.3.3 Using The Cram´er Representation . . . 85   
6.3.4 Power Spectrum Examples . . 86

# Contents

v

6.4 Statistical Inference . . 88

6.4.1 Some Distribution Theory . . . 88   
6.4.2 The Periodogram and its Distribution . . 90   
6.4.3 An Example – Sunspot Numbers . . . . 91   
6.4.4 Estimating The Power Spectrum . . . 92   
6.4.5 Tapering and Prewhitening . . . 95   
6.4.6 Cross Spectral Analysis . . . 96

6.5 Computation 99

6.5.1 A Simple Spectral Analysis Package for R . . . . . . . . . 99   
6.5.2 Power Spectrum Estimation . . . . 99   
6.5.3 Cross-Spectral Analysis . . . . 100

6.6 Examples 100

# Chapter 1

# Introduction

# 1.1 Time Series

Time series arise as recordings of processes which vary over time. A recording can either be a continuous trace or a set of discrete observations. We will concentrate on the case where observations are made at discrete equally spaced times. By appropriate choice of origin and scale we can take the observation times to be 1, 2, . . . T and we can denote the observations by $Y _ { 1 }$ , $Y _ { 2 }$ , . . . , $Y _ { T }$ .

There are a number of things which are of interest in time series analysis. The most important of these are:

Smoothing: The observed $Y _ { t }$ are assumed to be the result of “noise” values $\varepsilon _ { t }$ additively contaminating a smooth signal $\eta _ { t }$ .

$$
Y _ {t} = \eta_ {t} + \varepsilon_ {t}
$$

We may wish to recover the values of the underlying $\eta _ { t }$

Modelling: We may wish to develop a simple mathematical model which explains the observed pattern of $Y _ { 1 }$ , $Y _ { 2 }$ , . . . , $Y _ { T }$ . This model may depend on unknown parameters and these will need to be estimated.

Forecasting: On the basis of observations $Y _ { 1 }$ , $Y _ { 2 }$ , . . . , $Y _ { T }$ , we may wish to predict what the value of $Y _ { T + L }$ will be ( $L \geq 1$ ), and possibly to give an indication of what the uncetainty is in the prediction.

Control: We may wish to intervene with the process which is producing the $Y _ { t }$ values in such a way that the future values are altered to produce a favourable outcome.

# 1.2 Stationarity and Non-Stationarity

A key idea in time series is that of stationarity. Roughly speaking, a time series is stationary if its behaviour does not change over time. This means, for example, that the values always tend to vary about the same level and that their variability is constant over time. Stationary series have a rich theory and

their behaviour is well understood. This means that they play a fundamental role in the study of time series.

Obviously, not all time series that we encouter are stationary. Indeed, nonstationary series tend to be the rule rather than the exception. However, many time series are related in simple ways to series which are stationary. Two important examples of this are:

Trend models : The series we observe is the sum of a determinstic trend series and a stationary noise series. A simple example is the linear trend model:

$$
Y _ {t} = \beta_ {0} + \beta_ {1} t + \varepsilon_ {t}.
$$

Another common trend model assumes that the series is the sum of a periodic “seasonal” effect and stationary noise. There are many other variations.

Integrated models : The time series we observe satisfies

$$
Y _ {t + 1} - Y _ {t} = \varepsilon_ {t + 1}
$$

where $\varepsilon _ { t }$ is a stationary series. A particularly important model of this kind is the random walk. In that case, the $\varepsilon _ { t }$ values are independent “shocks” which perturb the current state $Y _ { t }$ by an amount $\varepsilon _ { t + 1 }$ to produce a new state $Y _ { t + 1 }$ .

# 1.3 Some Examples

# 1.3.1 Annual Auckland Rainfall

Figure 1.1 shows the annual amount of rainfall in Auckland for the years from 1949 to 2000. The general pattern of rainfall looks similar throughout the record, so this series could be regarded as being stationary. (There is a hint that rainfall amounts are declining over time, but this type of effect can occur over shortish time spans for stationary series.)

# 1.3.2 Nile River Flow

Figure 1.2 shows the flow volume of the Nile at Aswan from 1871 to 1970. These are yearly values. The general pattern of this data does not change over time so it can be regarded as stationary (at least over this time period).

# 1.3.3 Yield on British Government Securities

Figure 1.3 shows the percentage yield on British Government securities, monthly over a 21 year period. There is a steady long-term increase in the yields. Over the period of observation a trend-plus-stationary series model looks like it might be appropriate. An integrated stationary series is another possibility.

# 1.3.4 Ground Displacement in an Earthquake

Figure 1.4 shows one component of the horizontal ground motion resulting from an earthquake. The initial motion (a little after 4 seconds) corresponds to the arrival of the $p$ -wave and the large spike just before six seconds corresponds to the arrival of the $s$ -wave. Later features correspond to the arrival of surface waves. This is an example of a transient signal and cannot have techniques appropriate for stationary series applied to it.

# 1.3.5 United States Housing Starts

Figure 1.5 shows the monthly number of housing starts in the Unites States (in thousands). Housing starts are a leading economic indicator. This means that an increase in the number of housing starts indicates that economic growth is likely to follow and a decline in housing starts indicates that a recession may be on the way.

# 1.3.6 Iowa City Bus Ridership

Figure 1.6 shows the monthly average weekday bus ridership for Iowa City over the period from September 1971 to December 1982. There is clearly a strong seasonal effect suprimposed on top of a general upward trend.

![](images/e80e860a45ccb54417ddc8e1b3b6e5799bcfeafc2ae03b5e2dc26391d6904466.jpg)

![](images/b3b84da7e48597ebbfe71f43f14256c46c8a24c54fd1a7eff307da3830388753.jpg)  
Figure 1.1: Annual Auckland rainfall (in cm) from 1949 to 2000 (from Paul Cowpertwait).   
Figure 1.2: Flow volume of the Nile at Aswan from 1871 to 1970 (from Durbin and Koopman).

![](images/f2a03637753082463e008252d02dfb975c83e77a4a4a451912f88c38c2ba1769.jpg)  
Figure 1.3: Monthly percentage yield on British Government securities over a 21 year period (from Chatfield).

![](images/7293625376a2cdab40d0ef8e9cc5b4df0dbb05f3f46bea47dca7d39417062fd9.jpg)  
Figure 1.4: Horizontal ground displacement during a small Nevada earthquake (from Bill Peppin).

![](images/0dcc3de8139dce70bf6ded0bb127ffa7be5c96e89af6cc984c6de348d702df4d.jpg)  
Figure 1.5: Housing starts in the United States (000s) (from S-Plus).

![](images/4c59a24f2eae1d28466e16fee196c441b4b83662d65d25d3dd609e6c9fd29b9e.jpg)  
Figure 1.6: Average weekday bus ridership, Iowa City (monthly ave) Sep 1971 - Dec 1982.

# Chapter 2

# Vector Space Theory

# 2.1 Vectors In Two Dimensions

The theory which underlies time series analysis is quite technical in nature. In spite of this, a good deal of intuition can be developed by approaching the subject geometrically. The geometric approach is based on the ideas of vectors and vector spaces.

# 2.1.1 Scalar Multiplication and Addition

A good deal can be learnt about the theory of vectors by considering the twodimensional case. You can think of two dimensional vectors as being little arrows which have a length and a direction. Individual vectors can be stretched (altering their length but not their direction) and pairs of vectors can be added by placing them head to tail.

To get more precise, we’ll suppose that a vector $_ { v }$ extends for a distance $x$ in the horizontal direction and a distance $y$ in the vertical direction. This gives us a representation of the vector as a pair of numbers and we can write it as

$$
\boldsymbol {v} = (x, y).
$$

Doubling the length of the vector doubles the $x$ and $y$ values. In a similar way we can scale the length of the vector by any value, and this results in a similar scaling of the $x$ and $y$ values. This gives us a natural way of defining multiplication of a vector by a number.

$$
c \boldsymbol {v} = (c x, c y)
$$

A negative value for $c$ produces a reversal of direction as well as change of length of magnitude $| c |$ .

Adding two vectors amounts to placing them head to tail and taking the sum to be the arrow which extends from the base of the first to the head of the second. This corresponds to adding the $x$ and $y$ values corresponding to the vectors. For two vectors $\pmb { v } _ { 1 } = ( x _ { 1 } , y _ { 1 } )$ and $\pmb { v } _ { 2 } = ( x _ { 2 } , y _ { 2 } )$ the result is $( x _ { 1 } + x _ { 2 } , y _ { 1 } + y _ { 2 } )$ . This corresponds to a natural definition of addition for vectors.

$$
\boldsymbol {v} _ {1} + \boldsymbol {v} _ {2} = (x _ {1} + x _ {2}, y _ {1} + y _ {2})
$$

# 2.1.2 Norms and Inner Products

While coordinates give a complete description of vectors, it is often more useful to describe them in terms of the lengths of individual vectors and the angles between pairs of vectors. If we denote the length of a vector by $\lVert u \rVert$ , then by Pythagoras’ theorem we know

$$
\| \boldsymbol {u} \| = \sqrt {x ^ {2} + y ^ {2}}.
$$

Vector length has a number of simple properties:

Positivity: For every vector $\mathbf { \Delta } _ { \mathbf { u } }$ , we must have $\| \mathbf { \boldsymbol { u } } \| \geqslant 0$ , with equality if and only if ${ \pmb u } = { \bf 0 }$ .

Linearity: For every scalar $c$ and vector $\textbf { \em u }$ we have $\| c \pmb { u } \| = | c | \| \pmb { u } \|$

The Triangle Inequality: If $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { v }$ are vectors, then $\| u + v \| \leqslant \| u \| + \| v \|$ .

The first and second of these properties are obvious, and the third is simply a statement that the shortest distance between two points is a straight line. The technical mathematical name for the length of a vector is the norm of the vector.

Although the length of an individual vector gives some information about it, it is also important to consider the angles between pairs of vectors. Suppose that we have vectors $\pmb { v } _ { 1 } = ( x _ { 1 } , y _ { 1 } )$ and $\pmb { v } _ { 2 } = ( x _ { 2 } , y _ { 2 } )$ , and that we want to know the angle between them. If ${ \pmb v } _ { 1 }$ subtends an angle $\theta _ { 1 }$ with the $x$ axis and $\mathbf { \boldsymbol { v } } _ { 2 }$ subtends an angle $\theta _ { 2 }$ with the $x$ axis, simple geometry tells us that:

$$
\cos \theta_ {i} = \frac {x _ {i}}{\| \boldsymbol {v} _ {i} \|},
$$

$$
\sin \theta_ {i} = \frac {y _ {i}}{\| \boldsymbol {v} _ {i} \|}.
$$

The angle we are interested in is $\theta _ { 1 } - \theta _ { 2 }$ and the cosine of this can be computed using the formulae:

$$
\cos (\alpha - \beta) = \cos \alpha \cos \beta + \sin \alpha \sin \beta
$$

$$
\sin (\alpha - \beta) = \sin \alpha \cos \beta - \cos \alpha \sin \beta ,
$$

so that

$$
\cos (\theta_ {1} - \theta_ {2}) = \frac {x _ {1} x _ {2} + y _ {1} y _ {2}}{\| \boldsymbol {v} _ {1} \| \| \boldsymbol {v} _ {2} \|}
$$

$$
\sin (\theta_ {1} - \theta_ {2}) = \frac {x _ {2} y _ {1} - x _ {1} y _ {2}}{\| \boldsymbol {v} _ {1} \| \| \boldsymbol {v} _ {2} \|}.
$$

Knowledge of the sine and cosine values makes it possible to compute the angle between the vectors.

There are actually two angles between a pair of vectors; one measured clockwise and one measured counter-clockwise. Often we are interested in the smaller of these two angles. This can be determined from the cosine value (because $\cos \theta = \cos - \theta$ ). The cosine is determined by the lengths of the two vectors and the quantity $x _ { 1 } x _ { 2 } + y _ { 1 } y _ { 2 }$ . This quantity is called the inner product of the vectors ${ \pmb v } _ { 1 }$ and ${ \pmb v } _ { 2 }$ and is denoted by $\left. { \pmb v } _ { 1 } , { \pmb v } _ { 2 } \right.$ . Inner products have the following basic properties.

Positivity: For every vector $_ v$ , we must have $\langle { \pmb v } , { \pmb v } \rangle \geqslant 0$ , with $\langle { \pmb v } , { \pmb v } \rangle = 0$ only when $v = 0$ .

Linearity: For all vectors $\textbf { \em u }$ , $_ { v }$ , and $\mathbf { w }$ ; and scalars $\alpha$ and $\beta$ ; we must have $\langle \alpha \pmb { u } + \beta \pmb { v } , \pmb { w } \rangle = \alpha \langle \pmb { u } , \pmb { w } \rangle + \beta \langle \pmb { v } , \pmb { w } \rangle$ .

Symmetry: For all vectors $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { \pmb { v } }$ , we must have $\langle { \pmb u } , { \pmb v } \rangle = \langle { \pmb v } , { \pmb u } \rangle$ (or in the case of complex vector spaces $\langle { \pmb u } , { \pmb v } \rangle = \langle { \pmb v } , { \pmb u } \rangle$ , where the bar indicates a complex conjugate).

It is clear that the norm can be defined in terms of the inner product by

$$
\left\| \boldsymbol {v} \right\| ^ {2} = \langle \boldsymbol {v}, \boldsymbol {v} \rangle .
$$

It is easy to show that the properties of the norm $\lVert \boldsymbol { v } \rVert$ follow from those of the inner product.

Two vectors $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { v }$ are said to be orthogonal if $\langle { \pmb u } , { \pmb v } \rangle = 0$ . This means that the vectors are “at right angles” to each other.

# 2.2 General Vector Spaces

The theory and intuition obtained from studying two-dimensional vectors carries over into more general situations. It is not the particular representation of vectors as pairs of coordinates which is important but rather the ideas of addition, scalar multiplication and inner-product which are important.

# 2.2.1 Vector Spaces and Inner Products

The following concepts provide an abstract generalisation of vectors in two dimensions.

1. A vector space is a set of objects, called vectors, which is closed under addition and scalar multiplication. This means that when vectors are scaled or added, the result is a vector.   
2. An inner product on a vector space is a function which takes two vectors $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { \pmb { v } }$ and returns a scalar denoted by $\left. \textbf { \em u } , \pmb { v } \right.$ which has the conditions of positivity, linearity and symmetry described in section 2.1.2. A vector space with an associated inner product is called an inner product space.   
3. The norm associated with an inner product space is defined in terms of the inner product as $\| \boldsymbol { \mathbf { u } } \| = \sqrt { \langle \boldsymbol { \mathbf { u } } , \boldsymbol { \mathbf { u } } \rangle }$ .

These ideas can be applied to quite general vector spaces. Although it may seem strange to apply ideas of direction and length to some of these spaces, thinking in terms of two and three dimensional pictures can be quite useful.

Example 2.2.1 The concept of two-dimensional vectors can be generalised by looking at the set of $n$ -tuples of the form $\pmb { u } = ( u _ { 1 } , u _ { 2 } , \dots , u _ { n } )$ , where each $u _ { i }$ is a real number. With addition and scalar multiplication defined element-wise,

the set of all such $n$ -tuples forms a vector space, usually denoted by $\mathbb { R } ^ { n }$ . An inner product can be defined on the space by

$$
\langle \boldsymbol {u}, \boldsymbol {v} \rangle = \sum_ {i = 1} ^ {n} u _ {i} v _ {i},
$$

and this produces the norm

$$
\left\| \boldsymbol {u} \right\| = \left(\sum_ {i = 1} ^ {n} u _ {i} ^ {2}\right) ^ {\frac {1}{2}}.
$$

This generalisation of vector ideas to $n$ dimensions provides the basis for a good deal of statistical theory. This is especially true for linear models and multivariate analysis.

We will need a number of fundamental results on vector spaces. These follow directly from the definition of vector space, inner-product and norm, and do not rely on any special assumptions about the kind of vectors being considered.

The Cauchy-Schwarz Inequality. For any two vectors $\textbf { \em u }$ and $_ { \pmb { v } }$

$$
| \langle \boldsymbol {u}, \boldsymbol {v} \rangle | \leqslant \| \boldsymbol {u} \| \| \boldsymbol {v} \|. \tag {2.1}
$$

Proof : For any two vectors $\textbf { \em u }$ and $_ v$ and scalars $\alpha$ and $\beta$ ,

$$
0 \leqslant \| \alpha \boldsymbol {u} - \beta \boldsymbol {v} \| ^ {2} = \left\langle \alpha \boldsymbol {u} - \beta \boldsymbol {v}, \alpha \boldsymbol {u} - \beta \boldsymbol {v} \right\rangle = \alpha^ {2} \| \boldsymbol {u} \| ^ {2} - 2 \alpha \beta \left\langle \boldsymbol {u}, \boldsymbol {v} \right\rangle + \beta^ {2} \| \boldsymbol {v} \| ^ {2}
$$

Setting $\alpha = \| \pmb { v } \|$ and $\beta = \langle \pmb { u } , \pmb { v } \rangle / \| \pmb { v } \|$ yields

$$
0 \leqslant \| \boldsymbol {u} \| ^ {2} \| \boldsymbol {v} \| ^ {2} - 2 \langle \boldsymbol {u}, \boldsymbol {v} \rangle^ {2} + \langle \boldsymbol {u}, \boldsymbol {v} \rangle^ {2} = \| \boldsymbol {u} \| ^ {2} \| \boldsymbol {v} \| ^ {2} - \langle \boldsymbol {u}, \boldsymbol {v} \rangle^ {2}.
$$

This can be rewritten as

$$
| \langle \boldsymbol {u}, \boldsymbol {v} \rangle | \leqslant \| \boldsymbol {u} \| \| \boldsymbol {v} \|.
$$

The Triangle Inequality. For any two vectors $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { v }$

$$
\| \boldsymbol {u} + \boldsymbol {v} \| \leqslant \| \boldsymbol {u} \| + \| \boldsymbol {v} \|.
$$

Proof : For any $\textbf { \em u }$ and $_ { \pmb { v } }$

$$
\begin{array}{l} \left\| \boldsymbol {u} + \boldsymbol {v} \right\| ^ {2} = \langle \boldsymbol {u} + \boldsymbol {v}, \boldsymbol {u} + \boldsymbol {v} \rangle \\ = \langle \boldsymbol {u}, \boldsymbol {u} \rangle + \langle \boldsymbol {u}, \boldsymbol {v} \rangle + \langle \boldsymbol {v}, \boldsymbol {u} \rangle + \langle \boldsymbol {v}, \boldsymbol {v} \rangle \\ \leqslant \| \boldsymbol {u} \| ^ {2} + 2 \| \boldsymbol {u} \| \| \boldsymbol {v} \| + \| \boldsymbol {v} \| ^ {2} \quad (\text {C a u c h y - S c h w a r z}) \\ = \left(\left\| \boldsymbol {u} \right\| + \left\| \boldsymbol {v} \right\|\right) ^ {2} \\ \end{array}
$$

The Angle Between Vectors. The Cauchy-Schwarz inequality means that

$$
- 1 \leqslant \frac {\langle \boldsymbol {x} , \boldsymbol {y} \rangle}{\| \boldsymbol {x} \| \| \boldsymbol {y} \|} \leqslant 1.
$$

This means that just as in the 2- $d$ case we can define the angle between vectors $\mathbf { \Delta } _ { \mathbf { u } }$ and $_ { v }$ by

$$
\theta = \cos^ {- 1} \frac {\langle \boldsymbol {x} , \boldsymbol {y} \rangle}{\| \boldsymbol {x} \| \| \boldsymbol {y} \|}.
$$

# 2.2.2 Some Examples

The ideas in abstract vector space theory are derived from the concrete ideas of vectors in 2 and 3 dimensions. The real power of vector space theory is that it applies to much more general spaces. To show off the generality of the theory we’ll now look at a couple of examples of less concrete spaces.

Example 2.2.2 The set $\mathcal { F }$ of all (real-valued) random variables with $\mathrm { E } X = 0$ and $\operatorname { E } { \lvert X \rvert } ^ { 2 } < \infty$ is a vector space, because for any choice of $X _ { 1 }$ and $X _ { 2 }$ from $\mathcal { F }$ and scalars $\beta _ { 1 }$ and $\beta _ { 2 }$

$$
\operatorname {E} [ \beta_ {1} X _ {1} + \beta_ {2} X _ {2} ] = 0
$$

and

$$
\mathrm {E} \left| \beta_ {1} X _ {1} + \beta_ {2} X _ {2} \right| ^ {2} <   \infty .
$$

It is possible to define an inner product on this vector space by

$$
\langle X, Y \rangle = \operatorname {E X Y}.
$$

This in turn produces the norm

$$
\left\| X \right\| = \left(\mathrm {E} | X | ^ {2}\right) ^ {\frac {1}{2}},
$$

which is just the standard deviation of $X$ .

The cosine of the angle between random variables is defined as

$$
\frac {\operatorname {E X Y}}{\sqrt {\operatorname {E} | X | ^ {2} E | Y | ^ {2}}},
$$

which is recognisable as the correlation between the $X$ and $Y$ .

(There is a technical problem with uniqueness in this case. Any random variable which has probability 1 of being zero will have $\langle X , X \rangle = 0$ , which violates the requirement that this only happen for $X = 0$ . The workaround is to regard random variables as identical if they are the same with probability one.)

Example 2.2.3 The set of all continuous functions from $[ - 1 , 1 ]$ to $\mathbb { R }$ is a vector space because there is a natural definition of addition and scalar multiplication for such functions.

$$
(f + g) (x) = f (x) + g (x)
$$

$$
(\beta f) (x) = \beta f (x)
$$

A natural inner-product can be defined on this space by

$$
\langle f, g \rangle = \int_ {- 1} ^ {1} f (x) g (x) d x.
$$

Vector space theory immediately gets us results such as

$$
\left| \int_ {- 1} ^ {1} f (x) g (x) d x \right| \leqslant \left(\int_ {- 1} ^ {1} f (x) ^ {2} d x\right) ^ {1 / 2} \left(\int_ {- 1} ^ {1} g (x) ^ {2} d x\right) ^ {1 / 2},
$$

which is just a restatement of the Cauchy-Schwarz inequality.

There is also a technical uniqueness problem in this case. This is handled by regarding functions $f$ and $g$ as equal if

$$
\int_ {- 1} ^ {1} | f (x) - g (x) | ^ {2} d x = 0.
$$

This happens, for example, if $f$ and $g$ differ only on a finite or countably infinite set of points. Integration theory gives a characterisation in terms of sets with “measure zero.”

# 2.3 Hilbert Spaces

The vector spaces we’ve looked at so far work perfectly well for performing finite operations such as forming linear combinations. However, there can be problems when considering limits.

Consider the case of example 2.2.3. Each of the functions $f _ { n }$ defined by

$$
f _ {n} (x) = \left\{ \begin{array}{l l} 0, & x <   - \frac {1}{n}, \\ \frac {n x + 1}{2}, & - \frac {1}{n} \leqslant x \leqslant \frac {1}{n}, \\ 1, & x > \frac {1}{n}, \end{array} \right.
$$

is continuous and the sequence obviously converges to the function

$$
f (x) = \left\{ \begin{array}{l l} 0, & x <   0, \\ 1 / 2, & x = 0, \\ 1, & x > 0. \end{array} \right.
$$

This limit function is not in the space under consideration because it is not continuous.

Hilbert spaces add a requirement of completeness to those for an inner product space. In Hilbert spaces, sequences that look like they are converging will actually converge to an element of the space. To make this precise we need to define the meaning of convergence.

Convergence. Suppose that $\{ { \pmb u } _ { n } \}$ is a sequence of vectors and $\mathbf { \Delta } _ { \mathbf { u } }$ is a vector such that $\| \pmb { u } _ { n } - \pmb { u } \|  0$ , then ${ \pmb u } _ { n }$ is said to converge to $\textbf { \em u }$ and this is denoted by ${ \bf u } _ { n } \to { \bf u }$ .

If $\{ { \pmb u } _ { n } \}$ is a sequence of vectors such that the ${ \bf u } _ { n }  { \bf u }$ and $_ { v }$ is any vector then, by the Cauchy-Schwarz inequality $\langle { \pmb u } _ { n } , { \pmb v } \rangle  \langle { \pmb u } , { \pmb v } \rangle$ . In a similar way $\| u _ { n } \|  \| u \|$ . These properties are referred to as continuity of the inner product and norm.

A sequence for which $\begin{array} { r } { \operatorname* { l i m } _ { m , n \to \infty } \| u _ { m } - { \pmb u } _ { n } \| \to 0 } \end{array}$ is called a Cauchy sequence. It is easy to see that every convergent sequence is a Cauchy sequence. If conversely every Cauchy sequence converges to an element of the space, the space is said to be complete. A complete inner product space is called a Hilbert space.

Hilbert spaces preserve many of the important properties of $\mathbb { R } ^ { n }$ . In particular the notions of length and direction retain their intuitive meanings. This makes it possible to carry out mathematical arguments geometrically and even to use pictures to understand what is happening in quite complex cases.

# 2.3.1 Subspaces

A subset $\mathcal { M }$ of a Hilbert space $\mathcal { H }$ is called a linear manifold if whenever $\textbf { \em u }$ and $_ { v }$ are elements of $\mathcal { M }$ then so is $\alpha \pm \beta \pmb { v }$ . A linear manifold which contains the limit of every Cauchy sequence of its elements is called a linear subspace of $\mathcal { H }$ . A linear subspace of a Hilbert space is itself a Hilbert space.

A vector $_ v$ is orthogonal to a subspace $\mathcal { M }$ if $\langle { \pmb v } , { \pmb u } \rangle = 0$ for every $\pmb { u } \in \mathcal { M }$ . The set all vectors which are orthogonal to $\mathcal { M }$ is itself a subspace denoted by $\mathcal { M } ^ { \perp }$ and called the orthogonal complement of $\mathcal { M }$ .

A set of vectors $\{ v _ { \lambda } : \lambda \in \Lambda \}$ is said to generate a linear subspace $\mathcal { M }$ if $\mathcal { M }$ is the smallest subspace containing those vectors. It is relatively straightforward to show that the subspace consists of all linear combinations of the ${ \pmb v } _ { \lambda }$ s together with the limits of all Cauchy sequences formed from these linear combinations.

We will use the notation ${ \overline { { \operatorname { s p } } } } \{ v _ { \lambda } : \lambda \in \Lambda \}$ to indicate the subspace generated by the random variables $\{ \pmb { v } _ { \lambda } : \lambda \in \Lambda \}$ .

# 2.3.2 Projections

If $\mathcal { M }$ is a subspace of a Hilbert space $\mathcal { H }$ and $_ { \pmb { v } }$ is a vector not in $\mathcal { M }$ then the distance from $\mathcal { M }$ to $_ { \pmb { v } }$ is defined to be $\mathrm { m i n } _ { \pmb { u } \in \mathcal { M } } \| \pmb { v } - \pmb { u } \|$ . A crucial result in Hilbert space theory tells us about how this minimum is attained.

The Projection Theorem. There is a unique vector $\mathcal { P } _ { \mathcal { M } } \pmb { v } \in \mathcal { M }$ such that

$$
\left\| \boldsymbol {v} - \mathcal {P} _ {\mathcal {M}} \boldsymbol {v} \right\| = \min _ {\boldsymbol {u} \in \mathcal {M}} \left\| \boldsymbol {v} - \boldsymbol {u} \right\|.
$$

The vector $\mathcal { P } _ { \mathcal { M } } \boldsymbol { v }$ satisfies $\mathcal { P } _ { \mathcal { M } } \pmb { v } \in \mathcal { M }$ and ${ \pmb v } - \mathcal { P } _ { \mathcal { M } } { \pmb v } \in \mathcal { M } ^ { \bot }$ . It is called the orthogonal projection of $_ v$ on $\mathcal { M }$ .

When $\mathcal { M }$ is generated by a set of elements $\{ \pmb { u } _ { \lambda } : \lambda \in \Lambda \}$ , the condition $\pmb { v } - \mathcal { P } _ { \mathcal { M } } \pmb { v } \in \mathcal { M } ^ { \bot }$ is equivalent to the condition $( { \pmb v } - \mathcal { P } _ { \mathcal { M } } { \pmb v } ) \perp { \pmb u } _ { \lambda }$ for every $\lambda \in \Lambda$ . In other words, $\langle { \pmb v } - \mathcal { P } _ { \mathcal { M } } { \pmb v } , { \pmb u } _ { \lambda } \rangle = 0$ for every $\lambda \in \Lambda$ . This produces the equations

$$
\langle \mathcal {P} _ {\mathcal {M}} \boldsymbol {v}, \boldsymbol {u} _ {\lambda} \rangle = \langle \boldsymbol {v}, \boldsymbol {u} _ {\lambda} \rangle , \quad \lambda \in \Lambda ,
$$

which together with the requirement $\mathcal { P } _ { \mathcal { M } } \pmb { v } \in \mathcal { M }$ , completely determines $\mathcal { P } _ { \mathcal { M } } \boldsymbol { v }$

When a subspace of a Hilbert space is generated by a countable set of orthogonal vectors $\{ \xi _ { n } \}$ , the orthogonal projection has the form

$$
\mathcal {P} _ {\mathcal {M}} \boldsymbol {v} = \sum_ {n} \frac {\langle \boldsymbol {v} , \boldsymbol {\xi} _ {n} \rangle}{\| \boldsymbol {\xi} _ {n} \| ^ {2}} \boldsymbol {\xi} _ {n}
$$

In the case of a finite set $\{ \pmb { \xi } _ { 1 } , \dots , \pmb { \xi } _ { n } \}$ this is easy to see.

$$
\frac {\langle \pmb {v} , \pmb {\xi} _ {1} \rangle}{\| \pmb {\xi} _ {1} \| ^ {2}} \pmb {\xi} _ {1} + \dots + \frac {\langle \pmb {v} , \pmb {\xi} _ {n} \rangle}{\| \pmb {\xi} _ {n} \| ^ {2}} \pmb {\xi} _ {n}
$$

In addition, the orthogonality of $\{ \pmb { \xi } _ { 1 } , \dots , \pmb { \xi } _ { n } \}$ means

$$
\begin{array}{l} \left\langle \frac {\langle \pmb {v} , \pmb {\xi} _ {1} \rangle}{\| \pmb {\xi} _ {1} \| ^ {2}} \pmb {\xi} _ {1} + \dots + \frac {\langle \pmb {v} , \pmb {\xi} _ {n} \rangle}{\| \pmb {\xi} _ {n} \| ^ {2}} \pmb {\xi} _ {n}, \pmb {\xi} _ {i} \right\rangle = \frac {\langle \pmb {v} , \pmb {\xi} _ {i} \rangle}{\| \pmb {\xi} _ {i} \| ^ {2}} \langle \pmb {\xi} _ {i}, \pmb {\xi} _ {i} \rangle \\ = \left\langle \boldsymbol {v}, \boldsymbol {\xi} _ {i} \right\rangle \\ \end{array}
$$

so the conditions above are verified.

The general (countable) case follows from the continuity of the norm and inner product.

# 2.4 Hilbert Spaces and Prediction

Consider the Hilbert space $\mathcal { H }$ consisting of all finite-variance random variables on some probability space, with inner product defined by

$$
\langle X, Y \rangle = \operatorname {E} X Y.
$$

We will now look at the problem of predicting a variable $Y$ using zero, one or more predicting random variables $X _ { 1 } , \ldots , X _ { n }$ .

# 2.4.1 Linear Prediction

The problem can be stated as follows. Given a “response” random variable $Y$ and predictor random variables $X _ { 1 } , \ldots , X _ { n }$ , what is the best way of predicting $Y$ using a linear function of the $X \mathrm { s }$ . This amounts to finding the coefficients which minimise the mean squared error

$$
\operatorname {E} | Y - \beta_ {0} - \beta_ {1} X _ {1} - \dots - \beta_ {n} X _ {n} | ^ {2},
$$

or, in a Hilbert space setting,

$$
\left\| Y - \beta_ {0} - \beta_ {1} X _ {1} - \dots - \beta_ {n} X _ {n} \right\| ^ {2}.
$$

The variables $\{ 1 , X _ { 1 } , \ldots , X _ { n } \}$ generate a subspace $\mathcal { M }$ of $\mathcal { H }$ , and the minimisation problem above amounts to finding the projection $\mathcal { P } _ { \mathcal { M } } Y$ . We’ll approach this problem in steps, beginning with $n = 0$ .

The subspace $\boldsymbol { \mathscr { C } }$ generated by the constant random variable 1 consists of all constant random variables. Using the result above, the projection of a random variable $Y$ with mean $\mu _ { Y }$ and variance $\sigma _ { Y } ^ { 2 }$ onto this subspace is

$$
\mathcal {P} _ {\mathcal {C}} Y = \frac {\langle Y , 1 \rangle}{\| 1 \| ^ {2}} 1 = \mathrm {E} Y = \mu_ {Y}.
$$

This tells us immediately that the value of $c$ which minimises $\operatorname { E } [ Y - c ] ^ { 2 }$ is $\mu _ { Y }$

Now consider the subspace $\mathcal { L }$ generated by 1 and a single random variable $X$ with mean $\mu _ { X }$ and variance $\sigma _ { X } ^ { 2 }$ . This is clearly the same as the subspace generated by 1 and $X - \operatorname { E } X$ . Since 1 and $X - \operatorname { E } X$ are orthogonal, we can use the projection result of the previous section to compute the projection of $Y$ onto $\mathcal { L }$ .

$$
\begin{array}{l} \mathcal {P} _ {\mathcal {L}} Y = \frac {\langle Y , 1 \rangle}{\| 1 \| ^ {2}} 1 + \frac {\langle Y , X - \mathrm {E} X \rangle}{\| X - \mathrm {E} X \| ^ {2}} (X - \mathrm {E} X) \\ = \mathrm {E} Y + \frac {\langle Y - \mathrm {E} Y , X - \mathrm {E} X \rangle}{\| X - \mathrm {E} X \| ^ {2}} (X - \mathrm {E} X) + \frac {\langle \mathrm {E} Y , X - \mathrm {E} X \rangle}{\| X - \mathrm {E} X \| ^ {2}} (X - \mathrm {E} X) \\ = \mathrm {E} Y + \frac {\langle Y - \mathrm {E} Y , X - \mathrm {E} X \rangle}{\| X - \mathrm {E} X \| ^ {2}} (X - \mathrm {E} X) \\ \end{array}
$$

because $\langle \mathrm { E } Y , X - \mathrm { E } X \rangle = 0$ .

Now $\langle Y - \operatorname { E } Y , X - \operatorname { E } X \rangle = \operatorname { c o v } ( Y , X )$ which is in turn equal to $\rho _ { Y X } \sigma _ { Y } \sigma _ { X }$ where $\rho _ { Y X }$ is the correlation between $Y$ and $X$ . This means that

$$
\mathcal {P} _ {\mathcal {L}} Y = \mu_ {Y} + \rho_ {Y X} \frac {\sigma_ {Y}}{\sigma_ {X}} (X - \mu_ {X}).
$$

$\mathcal { P } _ { \mathcal { L } } Y$ is the best possible linear prediction of $Y$ based on $X$ , because among all predictions of the form $\beta _ { 0 } + \beta _ { 1 } X$ , it is the one which minimises

$$
\operatorname {E} (Y - \beta_ {0} - \beta_ {1} X) ^ {2}.
$$

The general case of $n$ predictors proceeds in exactly the same way, but is more complicated because we must use progressive orthogonalisation of the set of variables $\{ 1 , X _ { 1 } , \ldots , X _ { n } \}$ . The final result is that the best predictor of $Y$ is

$$
\mathcal {P} _ {\mathcal {L}} Y = \mu_ {Y} + \boldsymbol {\Sigma} _ {Y X} \boldsymbol {\Sigma} _ {X X} ^ {- 1} (\boldsymbol {X} - \boldsymbol {\mu} _ {X}),
$$

where $\pmb { X }$ represents the variables $X _ { 1 } , \ldots , X _ { n }$ assembled into a vector, $\pmb { \mu } _ { X }$ is the vector made up of the means of the $X$ s, $\Sigma _ { Y X }$ is the vector of covariances between $Y$ and each of the $X$ s, and $\Sigma _ { X X }$ is the variance-covariance matrix of the $X \mathrm { s }$ .

# 2.4.2 General Prediction

It is clear that linear prediction theory can be developed using Hilbert space theory. What is a little less clear is that Hilbert space theory also yields a general non-linear prediction theory.

Linear prediction theory uses only linear information about the predictors and there is much more information available. In the one variable case, the additional information can be obtained by considering all possible (Borel) functions $\phi ( X )$ . These are still just random variables and so generate a subspace $\mathcal { M }$ of $\mathcal { H }$ . The projection onto this subspace gives the best possible predictor of $Y$ based on $X _ { 1 } , \ldots , X _ { n }$ .

With some technical mathematics it is possible to show that this projection is in fact just the conditional expectation $\operatorname { E } [ Y | X ]$ . More generally, it is possible to show that the best predictor of $Y$ based on $X _ { 1 } , \ldots , X _ { n }$ is $\operatorname { E } [ Y | X _ { 1 } , \dots , X _ { n } ]$ .

Although this is theoretically simple, it requires very strong assumptions about the distribution of $Y$ and $X _ { 1 } , \ldots , X _ { n }$ to actually compute an explicit value for the prediction. The simplest assumption to make is that $Y$ and $X _ { 1 } , \ldots , X _ { n }$ have a joint normal distribution. In this case, the general predictor and the linear one are identical.

Because of this it is almost always the case that linear prediction is preferred to general prediction.

# Chapter 3

# Time Series Theory

# 3.1 Time Series

We will assume that the time series values we observe are the realisations of random variables $Y _ { 1 } , \dots , Y _ { T }$ , which are in turn part of a larger stochastic process $\{ Y _ { t } : t \in \mathbb { Z } \}$ . It is this underlying process that will be the focus for our theoretical development.

Although it is best to distinguish the observed time series from the underlying stochastic process, the distinction is usually blurred and the term time series is used to refer to both the observations and the underlying process which generates them.

The mean and the variance of random variables have a special place in the theory of statistics. In time series analysis, the analogs of these are the mean function and the autocovariance function.

Definition 3.1.1 (Mean and Autocovariance Functions): The mean function of a time series is defined to be $\mu ( t ) = \mathrm { E } Y _ { t }$ and the autocovariance function is defined to be $\gamma ( s , t ) = \mathrm { c o v } ( Y _ { s } , Y _ { t } )$ .

The mean and the autocovariance functions are fundamental parameters and it would be useful to obtain sample estimates of them. For general time series there are $2 T + T ( T - 1 ) / 2$ parameters associated with $Y _ { 1 } , \dots , Y _ { T }$ and it is not possible to estimate all these parameters from $T$ data values.

To make any progress at all we must impose constraints on the time series we are investigating. The most common constraint is that of stationarity. There are two common definitions of stationarity.

Definition 3.1.2 (Strict Stationarity): A time series $\{ Y _ { t } : t \in \mathbb { Z } \}$ is said to be strictly stationary if for any $k > 0$ and any $t _ { 1 } , \dots , t _ { k } \in \mathbb { Z }$ , the distribution of

$$
\left(Y _ {t _ {1}}, \ldots , Y _ {t _ {k}}\right)
$$

is the same as that for

$$
\left(Y _ {t _ {1} + u}, \dots , Y _ {t _ {k} + u}\right)
$$

for every value of $u$ .

This definition says that the stochastic behaviour of the process does not change through time. If $Y _ { t }$ is stationary then

$$
\mu (t) = \mu (0)
$$

and

$$
\gamma (s, t) = \gamma (s - t, 0).
$$

So for stationary series, the mean function is constant and the autocovariance function depends only on the time-lag between the two values for which the covariance is being computed.

These two restrictions on the mean and covariance functions are enough for a reasonable amount of theory to be developed. Because of this a less restrictive definition of stationarity is often used in place of strict stationarity.

Definition 3.1.3 (Weak Stationarity): A time series is said to be weakly, widesense or covariance stationary if $\mathrm { E } | Y _ { t } | ^ { 2 } < \infty$ , $\mu ( t ) = \mu$ and $\gamma ( t + u , t ) = \gamma ( u , 0 )$ for all $t$ and $u$ .

In the case of Gaussian time series, the two definitions of stationarity are equivalent. This is because the finite dimensional distributions of the time series are completely characterised by the mean and covariance functions.

When time series are stationary it is possible to simplify the parameterisation of the mean and autocovariance functions. In this case we can define the mean of the series to be $\mu = \operatorname { E } ( Y _ { t } )$ and the autocovariance function to be $\gamma ( u ) = \operatorname { c o v } ( Y _ { t + u } , Y _ { t } )$ . We will also have occasion to examine the autocorrelation function

$$
\rho (u) = \frac {\gamma (u)}{\gamma (0)} = \operatorname {c o r} (Y _ {t + u}, Y _ {t}).
$$

Example 3.1.1 (White Noise) If the random variables which make up $\{ Y _ { t } \}$ are uncorrelated, have means 0 and variance $\sigma ^ { 2 }$ , then $\{ Y _ { t } \}$ is stationary with autocovariance function

$$
\gamma (u) = \left\{ \begin{array}{l l} \sigma^ {2} & u = 0, \\ 0 & \mathrm {o t h e r w i s e .} \end{array} \right.
$$

This type of series is referred to as white noise.

# 3.2 Hilbert Spaces and Stationary Time Series

Suppose that $\{ Y _ { t } : t \in \mathbb { Z } \}$ is a stationary zero-mean time series. We can consider the Hilbert space $\mathcal { H }$ generated by the random variables $\{ Y _ { t } : t \in \mathbb { Z } \}$ with inner product

$$
\langle X, Y \rangle = E (X Y),
$$

and norm

$$
\left\| X \right\| ^ {2} = \operatorname {E} | X | ^ {2}.
$$

At a given time $t$ , we can consider the subspace $\mathcal { M }$ generated by the random variables $\{ Y _ { u } : u \leqslant t \}$ . This subspace represents the past and present of the process. Future values of the series can be predicted by projecting onto the

subspace $\mathcal { M }$ . For example, $Y _ { t + 1 }$ can be predicted by $\mathcal { P } _ { \mathcal { M } } Y _ { t + 1 }$ , $Y _ { t + 1 }$ by $\mathcal { P } _ { \mathcal { M } } Y _ { t + 2 }$ and so on.

Computing these predictions requires a knowledge of the autocovariance function of the time series and typically this is not known. We will spend a good deal of this chapter studying simple parametric models for time series. By fitting such models we will be able to determine the covariance structure of the time series and so be able to obtain predictions or forecasts of future values.

# 3.3 The Lag and Differencing Operators

The lag operator $L$ is defined for a time series $\{ Y _ { t } \}$ by

$$
L Y _ {t} = Y _ {t - 1}.
$$

The operator can be defined for linear combinations by

$$
L \left(c _ {1} Y _ {t _ {1}} + c _ {2} Y _ {t _ {2}}\right) = c _ {1} Y _ {t _ {1} - 1} + c _ {2} Y _ {t _ {2} - 1}
$$

and can be extended to all of $\mathcal { H }$ by a suitable definition for limits.

In addition to being linear, the lag operator preserves inner products.

$$
\begin{array}{l} \left\langle L Y _ {s}, L Y _ {t} \right\rangle = \operatorname {c o v} \left(Y _ {s - 1}, Y _ {t - 1}\right) \\ = \operatorname {c o v} \left(Y _ {s}, Y _ {t}\right) \\ = \left\langle Y _ {s}, Y _ {t} \right\rangle \\ \end{array}
$$

(An operator of this type is called a unitary operator.)

There is a natural calculus of operators on $\mathcal { H }$ . For example we can define powers of $L$ naturally by

$$
\begin{array}{l} L ^ {2} Y _ {t} = L L Y _ {t} = L Y _ {t - 1} = Y _ {t - 2} \\ L ^ {3} Y _ {t} = L L ^ {2} Y _ {t} = Y _ {t - 3} \\ \end{array}
$$

$$
L ^ {k} Y _ {t} = Y _ {t - k}
$$

and linear combinations by

$$
\left(\alpha L ^ {k} + \beta L ^ {l}\right) Y _ {t} = \alpha Y _ {t - k} + \beta Y _ {t - l}.
$$

Other operators can be defined in terms in terms of $L$ . The differencing operator defined by

$$
\nabla Y _ {t} = (1 - L) Y _ {t} = Y _ {t} - Y _ {t - 1}
$$

is of fundamental importance when dealing with models for non-stationary time series. Again, we can define powers of this operator

$$
\begin{array}{l} \nabla^ {2} Y _ {t} = \nabla (\nabla Y _ {t}) \\ = \nabla \left(Y _ {t} - Y _ {t - 1}\right) \\ = \left(Y _ {t} - Y _ {t - 1}\right) - \left(Y _ {t - 1} - Y _ {t - 2}\right) \\ = Y _ {t} - 2 Y _ {t - 1} + Y _ {t - 2}. \\ \end{array}
$$

We will not dwell on the rich Hilbert space theory associated with time series, but it is important to know that many of the operator manipulations which we will carry out can be placed on a rigorous footing.

# 3.4 Linear Processes

We will now turn to an examination of a large class of useful time series models. These are almost all defined in terms of the lag operator $L$ . As the simplest example, consider the autoregressive model defined by:

$$
Y _ {t} = \phi Y _ {t - 1} + \varepsilon_ {t}, \tag {3.1}
$$

where $\phi$ is a constant with $| \phi | < 1$ and $\varepsilon _ { t }$ is a sequence of uncorrelated random variables, each with with mean 0 and variance $\sigma ^ { 2 }$ . From a statistical point of view this “model” makes perfect sense, but is not clear that any $Y _ { t }$ which satisfies this equation exists.

One way to see that there is a solution is to re-arrange equation 3.1 and write it in its operator form.

$$
(1 - \phi L) Y _ {t} = \varepsilon_ {t}.
$$

Formally inverting the operator $( 1 - \phi L )$ leads to

$$
\begin{array}{l} Y _ {t} = (1 - \phi L) ^ {- 1} \varepsilon_ {t} \\ = \sum_ {u = 0} ^ {\infty} \phi^ {u} L ^ {u} \varepsilon_ {t} \\ = \sum_ {u = 0} ^ {\infty} \phi^ {u} \varepsilon_ {t - u}. \\ \end{array}
$$

The series on the right is defined as the limit as $n \longrightarrow \infty$ of

$$
\sum_ {u = 0} ^ {n} \phi^ {u} \varepsilon_ {t - u}.
$$

Loosely speaking, this limit exists if

$$
\| \sum_ {u = n + 1} ^ {\infty} \phi^ {u} \varepsilon_ {t - u} \| ^ {2} \rightarrow 0.
$$

Since

$$
\begin{array}{l} \| \sum_ {u = n + 1} ^ {\infty} \phi^ {u} \varepsilon_ {t - u} \| ^ {2} = \operatorname {v a r} \left(\sum_ {u = n + 1} ^ {\infty} \phi^ {u} \varepsilon_ {t - u}\right) \\ = \sum_ {u = n + 1} ^ {\infty} | \phi | ^ {2 u} \sigma^ {2} \\ \end{array}
$$

and $| \phi | < 1$ , there is indeed a well-defined solution of 3.1. Further, this solution can be written as an (infinite) moving average of current and earlier $\varepsilon _ { t }$ values.

This type of infinite moving average plays a special role in the theory of time series.

Definition 3.4.1 (Linear Processes) The time series $Y _ { t }$ defined by

$$
Y _ {t} = \sum_ {u = - \infty} ^ {\infty} \psi_ {u} \varepsilon_ {t - u}
$$

where $\varepsilon _ { t }$ is a white-noise series and

$$
\sum_ {u = - \infty} ^ {\infty} | \psi_ {u} | ^ {2} <   \infty
$$

is called a linear process.

The general linear process depends on both past and future values of $\varepsilon _ { t }$ . A linear process which depends only on the past and present values of $\varepsilon _ { t }$ is said to be causal. Causal processes are preferred for forecasting because they reflect the way in which we believe the real world works.

Many time series can be represented as linear processes. This provides a unifying underpinning for time series theory, but may be of limited practical interest because of the potentially infinite number of parameters required.

# 3.5 Autoregressive Series

Definition 3.5.1 (Autoregressive Series) If $Y _ { t }$ satisfies

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t}
$$

where $\varepsilon _ { t }$ is white-noise and the $\phi _ { u }$ are constants, then $Y _ { t }$ is called an autoregressive series of order $p$ , denoted by AR(p).

Autoregressive series are important because:

1. They have a natural interpretation — the next value observed is a slight perturbation of a simple function of the most recent observations.   
2. It is easy to estimate their parameters. It can be done with standard regression software.   
3. They are easy to forecast. Again standard regression software will do the job.

# 3.5.1 The AR(1) Series

The AR(1) series is defined by

$$
Y _ {t} = \phi Y _ {t - 1} + \varepsilon_ {t}. \tag {3.2}
$$

Because $Y _ { t - 1 }$ and $\varepsilon _ { t }$ are uncorrelated, the variance of this series is

$$
\operatorname {v a r} \left(Y _ {t}\right) = \phi^ {2} \operatorname {v a r} \left(Y _ {t - 1}\right) + \sigma_ {\varepsilon} ^ {2}.
$$

If $\{ Y _ { t } \}$ is stationary then $\mathrm { v a r } ( Y _ { t } ) = \mathrm { v a r } ( Y _ { t - 1 } ) = \sigma _ { Y } ^ { 2 }$ and so

$$
\sigma_ {Y} ^ {2} = \phi^ {2} \sigma_ {Y} ^ {2} + \sigma_ {\varepsilon} ^ {2}. \tag {3.3}
$$

This implies that

$$
\sigma_ {Y} ^ {2} > \phi^ {2} \sigma_ {Y} ^ {2}
$$

and hence

$$
1 > \phi^ {2}.
$$

There is an alternative view of this, using the operator formulation of equation 3.2, namely

$$
(1 - \phi L) Y _ {t} = \varepsilon_ {t}
$$

It is possible to formally invert the autoregressive operator to obtain

$$
(1 - \phi L) ^ {- 1} = \sum_ {u = 0} ^ {\infty} \phi^ {u} L ^ {u}.
$$

Applying this to the series $\left\{ \varepsilon _ { t } \right\}$ produces the representation

$$
Y _ {t} = \sum_ {u = 0} ^ {\infty} \phi^ {u} \varepsilon_ {t - u}. \tag {3.4}
$$

If $| \phi | < 1$ this series converges in mean square because $\sum | \phi | ^ { 2 u } < \infty$ . The limit series is stationary and satisfies equation 3.2. Thus, if $| \phi | < 1$ then there is a stationary solution to 3.2. An equivalent condition is that the root of the equation

$$
1 - \phi z = 0
$$

(namely $1 / \phi$ ) lies outside the unit circle in the complex plane.

If $| \phi | > 1$ the series defined by 3.4 does not converge. We can, however, rearrange the defining equation 3.2 in the form

$$
Y _ {t} = \frac {1}{\phi} Y _ {t + 1} - \frac {1}{\phi} \varepsilon_ {t + 1},
$$

and a similar argument to that above produces the representation

$$
Y _ {t} = - \sum_ {u = 0} ^ {\infty} \phi^ {- u} \varepsilon_ {t + u}.
$$

This series does converge, so there is a stationary series $Y _ { t }$ which satisfies 3.2. The resulting series is generally not regarded as satisfactory for modelling and forecasting because it is not causal, i.e. it depends on future values of $\varepsilon _ { t }$ .

If $| \phi | = 1$ there is no stationary solution to 3.2. This means that for the purposes of modelling and forecasting stationary time series, we must restrict our attention to series for which $| \phi | < 1$ or, equivalently, to series for which the root of the polynomial $1 - \phi z$ lies outside the unit circle in the complex plane.

If we multiply both sides of equation 3.2 by $Y _ { t - u }$ and take expectations we obtain

$$
\mathrm {E} \left(Y _ {t} Y _ {t - u}\right) = \phi \mathrm {E} \left(Y _ {t - 1} Y _ {t - u}\right) + \mathrm {E} \left(\varepsilon_ {t} Y _ {t - u}\right).
$$

The term on the right is zero because, from the linear process representation, $\varepsilon _ { t }$ is independent of earlier $Y _ { t }$ values. This means that the autocovariances must satisfy the recursion

$$
\gamma (u) = \phi \gamma (u - 1), \qquad u = 1, 2, 3, \dots .
$$

This is a first-order linear difference equation with solution

$$
\gamma (u) = \phi^ {u} \gamma (0), \qquad u = 0, 1, 2, \dots
$$

# 3.5. Autoregressive Series

![](images/8b6f5c44559f574abdfc13f975774e19523b045b7ec8e06f96d4cbfc6af1b60e.jpg)  
Figure 3.1: Autocorrelation functions for two of AR(1) models.

By rearranging equation 3.3 we find $\gamma ( 0 ) = \sigma _ { \varepsilon } ^ { 2 } / ( 1 - \phi ^ { 2 } )$ , and hence that

$$
\gamma (u) = \frac {\phi^ {u} \sigma_ {\varepsilon} ^ {2}}{1 - \phi^ {2}}, \qquad u = 0, 1, 2, \ldots
$$

This in turn means that the autocorrelation function is given by

$$
\rho (u) = \phi^ {u}, \qquad u = 0, 1, 2, \ldots
$$

The autocorrelation functions for the the AR(1) series with $\phi _ { 1 } = . 7$ and $\phi _ { 1 } = - . 7$ are shown in figure 3.1. Both functions show exponential decay.

# 3.5.2 The AR(2) Series

The AR(2) model is defined by

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \phi_ {2} Y _ {t - 2} + \varepsilon_ {t} \tag {3.5}
$$

or, in operator form

$$
\left(1 - \phi_ {1} L - \phi_ {2} L ^ {2}\right) Y _ {t} = \varepsilon_ {t}.
$$

As in the AR(1) case we can consider inverting the AR operator. To see whether this is possible, we can consider factorising the operator

$$
1 - \phi_ {1} L - \phi_ {2} L ^ {2}
$$

and inverting each factor separately. Suppose that

$$
1 - \phi_ {1} L - \phi_ {2} L ^ {2} = (1 - c _ {1} L) (1 - c _ {2} L),
$$

then it is clear that we can invert the operator if we can invert each factor separately. This is possible if $| c _ { 1 } | < 1$ and $| c _ { 2 } | < 1$ , or equivalently, if the roots of the polynomial

$$
1 - \phi_ {1} z - \phi_ {2} z ^ {2}
$$

lie outside the unit circle. A little algebraic manipulation shows that this is equivalent to the conditions:

$$
\phi_ {1} + \phi_ {2} <   1, \quad - \phi_ {1} + \phi_ {2} <   1, \quad \phi_ {2} > - 1.
$$

These constraints define a triangular region in the $\phi _ { 1 }$ , $\phi _ { 2 }$ plane. The region is shown as the shaded triangle in figure 3.3.

The autocovariance function for the AR(2) series can be investigated by multiplying both sides of equation 3.5 by $Y _ { t - u }$ and taking expectations.

$$
\mathrm {E} (Y _ {t} Y _ {t - u}) = \phi_ {1} \mathrm {E} (Y _ {t - 1} Y _ {t - u}) + \phi_ {2} \mathrm {E} (Y _ {t - 2} Y _ {t - u}) + \mathrm {E} (\varepsilon_ {t} Y _ {t - u}).
$$

This in turns leads to the recurrence

$$
\gamma (u) = \phi_ {1} \gamma (u - 1) + \phi_ {2} \gamma (u - 2)
$$

with initial conditions

$$
\begin{array}{l} \gamma (0) = \phi_ {1} \gamma (- 1) + \phi_ {2} \gamma (- 2) + \sigma_ {\varepsilon} ^ {2} \\ \gamma (1) = \phi_ {1} \gamma (0) + \phi_ {2} \gamma (- 1). \\ \end{array}
$$

or, using the fact that $\gamma ( - u ) = \gamma ( u )$ ,

$$
\begin{array}{l} \gamma (0) = \phi_ {1} \gamma (1) + \phi_ {2} \gamma (2) + \sigma_ {\varepsilon} ^ {2} \\ \gamma (1) = \phi_ {1} \gamma (0) + \phi_ {2} \gamma (1). \\ \end{array}
$$

The solution to these equations has the form

$$
\gamma (u) = A _ {1} G _ {1} ^ {u} + A _ {2} G _ {2} ^ {u}
$$

where $G _ { 1 } ^ { - 1 }$ and $G _ { 2 } ^ { - 1 }$ are the roots of the polynomial

$$
1 - \phi_ {1} z - \phi_ {2} z ^ {2} \tag {3.6}
$$

and $A _ { 1 }$ and $A _ { 2 }$ are constants that can be determined from the initial conditions. In the case that the roots are equal, the solution has the general form

$$
\gamma (u) = \left(A _ {1} + A _ {2} u\right) G ^ {u}
$$

These equations indicate that the autocovariance function for the AR(2) series will exhibit (exponential) decay as $u \longrightarrow \infty$ .

If $G _ { k }$ corresponds to a complex root, then

$$
G _ {k} = | G _ {k} | e ^ {i \theta_ {k}}
$$

and hence

$$
G _ {k} ^ {u} = \left| G _ {k} \right| ^ {u} e ^ {i \theta_ {k} u} = \left| G _ {k} \right| ^ {u} \left(\cos \theta_ {k} u + i \sin \theta_ {k} u\right)
$$

Complex roots will thus introduce a pattern of decaying sinusoidal variation into the covariance function (or autocorrelation function). The region of the $\phi _ { 1 }$ , $\phi _ { 2 }$ plane corresponding to complex roots is indicated by the cross-hatched region in figure 3.3.

![](images/552d69d0a3c2b721ee643157b477ffacd355baf7c4cdedff076630af667cd781.jpg)

![](images/b6fbef1fa6a0c86be4589d17e1bdff7d2184c9431d3c8be0e216bba620ae6504.jpg)  
Figure 3.2: Autocorrelation functions for a variety of AR(2) models.

![](images/410a1a478a7d37cdc8738cb7c05f642b111bf130676c58129cc6b0c2f2c260a0.jpg)  
Figure 3.3: The regions of $\phi _ { 1 } / \phi _ { 2 }$ space where the series produced by the AR(2) scheme is stationary (indicated in grey) and has complex roots (indicated by cross-hatching).

# The AR(p) Series

The AR(p) series is defined by

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t} \tag {3.7}
$$

If the roots of

$$
1 - \phi_ {1} z - \dots - \phi_ {p} z ^ {p} \tag {3.8}
$$

lie outside the unit circle, there is a stationary causal solution to 3.7.

The autocovariance function can be investigated by multiplying equation 3.7 by $Y _ { t - u }$ and taking expectations. This yields

$$
\gamma (u) = \phi_ {1} \gamma (u - 1) + \dots + \phi_ {p} \gamma (u - p).
$$

This is a linear homogeneous difference equation and has the general solution

$$
\gamma (u) = A _ {1} G _ {1} ^ {u} + \dots + A _ {p} G _ {p} ^ {u}
$$

(this is for distinct roots), where $G _ { 1 } , \ldots , G _ { p }$ are the reciprocals of the roots of equation 3.8. Note that the stationarity condition means that $\gamma ( u ) \to 0$ , exhibiting exponential decay. As in the AR(2) case, complex roots will introduce oscillatory behaviour into the autocovariance function.

# 3.5.3 Computations

R contains a good deal of time series functionality. On older versions of R (those prior to 1.7.0) you will need to type the command

> library(ts)

to ensure that this functionality is loaded.

The function polyroot can be used to find the roots of polynomials and so determine whether a proposed model is stationary. Consider the model

$$
Y _ {t} = 2. 5 Y _ {t - 1} - Y _ {t - 2} + \varepsilon_ {t}
$$

or, its equivalent operator form

$$
(1 - 2. 5 L + L ^ {2}) Y _ {t} = \varepsilon_ {t}.
$$

We can compute magnitudes of the roots of the polynomial $1 - 2 . 5 z + z ^ { 2 }$ with polyroot.

> Mod(polyroot(c(1,-2.5,1)))

[1] 0.5 2.0

The roots have magnitudes .5 and 2. Because the first of these is less than 1 in magnitude the model is thus not stationary and causal.

For the model

$$
Y _ {t} = 1. 5 Y _ {t - 1} - . 7 5 Y _ {t - 2} + \varepsilon_ {t}
$$

or its operator equivalent

$$
(1 - 1. 5 L +. 7 5 L ^ {2}) Y _ {t} = \varepsilon_ {t}
$$

we can check stationarity by examining the magnitudes of the roots of $1 - 1 . 5 z +$ . $7 5 z ^ { 2 }$ .

> Mod(polyroot(c(1,-1.5,.75)))

[1] 1.154701 1.154701

Both roots are bigger than 1 in magnitude, so the series is stationary. We can obtain the roots themselves as follows.

> polyroot(c(1,-1.5,.75))

[1] 1+0.5773503i 1-0.5773503i

Because the roots are complex we can expect to see a cosine-like ripple in the autocovariance function and the autocorrelation function.

The autocorrelation function for a given model can be computed using the ARMAacf function. The acf for the model above can be computed and plotted as follows.

> plot(0:14, ARMAacf(ar=c(1.5,-.75), lag=14), type="h",

xlab $=$ "Lag", ylab $=$ "ACF")

> abline(h = 0)

The result is shown in figure 3.4.

Finally, it may be useful to simulate a time series of a given form. We can create a time series from the model $Y _ { t } = 1 . 5 Y _ { t - 1 } - . 7 5 Y _ { t - 2 } + \varepsilon _ { t }$ and plot it with the following statements.

> x = arima.sim(model = list(ar=c(1.5,-.75)), n = 100)

> plot(x)

The result is shown in figure 3.5. Note that there is evidence that the series contains a quasi-periodic component with period about 12, as suggested by the autocorrelation function.

![](images/f87eb8fd405593627b14741133c70c8a07f8226ea36ed1a2ae8d77ed70e830e6.jpg)  
Figure 3.4: The acf for the model $Y _ { t } = 1 . 5 Y _ { t - 1 } - . 7 5 Y _ { t - 2 } + \varepsilon _ { t }$ .

![](images/5670ad723c45c47378a62ba667b0b5137cecd54ac8a47d4fbc35b9ba35341a76.jpg)  
Figure 3.5: Simulation of the model $Y _ { t } = 1 . 5 Y _ { t - 1 } - . 7 5 Y _ { t - 2 } + \varepsilon _ { t }$ .

# 3.6 Moving Average Series

A time series $\{ Y _ { t } \}$ which satisfies

$$
Y _ {t} = \varepsilon_ {t} + \theta_ {1} \varepsilon_ {t - 1} + \dots + \theta_ {q} \varepsilon_ {t - q} \tag {3.9}
$$

(with $\left\{ \varepsilon _ { t } \right\}$ white noise) is said to be a moving average process of order $q$ or $\mathrm { M A } ( q )$ process. No additional conditions are required to ensure stationarity.

The autocovariance function for the MA(q) process is

$$
\gamma (u) = \left\{ \begin{array}{l l} (1 + \theta_ {1} ^ {2} + \dots + \theta_ {q} ^ {2}) \sigma^ {2} & u = 0 \\ (\theta_ {u} + \theta_ {1} \theta_ {u + 1} + \dots + \theta_ {q - u} \theta_ {q}) \sigma^ {2} & u = 1, \ldots , q \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

which says there is only a finite span of dependence on the series.

Note that it is easy to distinguish MA and AR series by the behaviour of their autocorrelation functions. The acf for MA series “cuts off” sharply while that for an AR series decays exponentially (with a possible sinusoidal ripple superimposed).

# 3.6.1 The MA(1) Series

The MA(1) series is defined by

$$
Y _ {t} = \varepsilon_ {t} + \theta \varepsilon_ {t - 1}. \tag {3.10}
$$

It has autocovariance function

$$
\gamma (u) = \left\{ \begin{array}{l l} (1 + \theta^ {2}) \sigma^ {2} & u = 0 \\ \theta \sigma^ {2} & u = 1 \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

and autocorrelation function

$$
\rho (u) = \left\{ \begin{array}{l l} \frac {\theta}{1 + \theta^ {2}} & \text {f o r} u = 1, \\ 0 & \text {o t h e r w i s e .} \end{array} \right. \tag {3.11}
$$

# 3.6.2 Invertibility

If we replace $\theta$ by $1 / \theta$ and $\sigma ^ { 2 }$ by $\theta \sigma ^ { 2 }$ the autocorrelation function given by 3.11 is unchanged. There are thus two sets of parameter values which can explain the structure of the series.

For the general process defined by equation 3.9, there is a similar identifiability problem. The problem can be resolved by requiring that the operator

$$
1 + \theta_ {1} L + \dots + \theta_ {q} L ^ {q}
$$

be invertible – i.e. that all roots of the polynomial

$$
1 + \theta_ {1} z + \dots + \theta_ {q} z ^ {q}
$$

lie outside the unit circle.

![](images/0d8b3478eedb4498dc309e1dff6a140c71f048eb10f3f1e26691396b3ac63046.jpg)  
Figure 3.6: The acf for the model $Y _ { t } = \varepsilon _ { t } + . 9 \varepsilon _ { t - 1 }$

# 3.6.3 Computation

The function polyroot can be used to check invertibility for MA models. Remember that the invertibility requirement is only so that each MA model is only defined by one set of parameters.

The function ARMAacf can be used to compute the acf for MA series. For example, the acf of the model

$$
Y _ {t} = \varepsilon_ {t} + 0. 9 \varepsilon_ {t - 1}
$$

can be computed and plotted as follows.

```txt
> plot(0:14, ARMAacf(ma=.9, lag=14), type="h", xlab = "Lag", ylab = "ACF")  
> abline(h = 0) 
```

The result is shown in figure 3.6.

A simulation of the series can be computed and plotted as follows.

$\begin{array}{rl} & {\mathrm{\bf >x = arima.sim(model = list(ma=.9),n = 100)}}\\ & {\mathrm{\bf >plot(x)}} \end{array}$

The result of the simulation is shown in figure 3.7.

# 3.7 Autoregressive Moving Average Series

Definition 3.7.1 If a series satisfies

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t} + \theta_ {1} \varepsilon_ {t - 1} + \dots + \theta_ {q} \varepsilon_ {t - q} \tag {3.12}
$$

![](images/519f2b8d6ffe00becf90af912ebba80954fd4abe80207b8e1c8263ae8bb68f67.jpg)  
Figure 3.7: Simulation of the model $Y _ { t } = \varepsilon _ { t } + . 9 \varepsilon _ { t - 1 }$ .

(with $\left\{ \varepsilon _ { t } \right\}$ white noise), it is called an autoregressive-moving average series of order $( p , q )$ , or an ARMA $( p , q )$ series.

An ARMA $( p , q )$ series is stationary if the roots of the polynomial

$$
1 - \phi_ {1} z - \dots - \phi_ {p} z ^ {p}
$$

lie outside the unit circle.

# 3.7.1 The ARMA(1,1) Series

The ARMA(1,1) series is defined by

$$
Y _ {t} = \phi Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1}. \tag {3.13}
$$

To derive the autocovariance function for $Y _ { t }$ , note that

$$
\begin{array}{l} E \left(\varepsilon_ {t} Y _ {t}\right) = E \left[ \varepsilon_ {t} \left(\phi Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1}\right) \right] \\ = \sigma_ {\varepsilon} ^ {2} \\ \end{array}
$$

and

$$
\begin{array}{l} E \left(\varepsilon_ {t - 1} Y _ {t}\right) = E \left[ \varepsilon_ {t - 1} \left(\phi Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1}\right) \right] \\ = \phi \sigma_ {\varepsilon} ^ {2} + \theta \sigma_ {\varepsilon} ^ {2} \\ = (\phi + \theta) \sigma_ {\varepsilon} ^ {2}. \\ \end{array}
$$

Multiplying equation 3.13 by $Y _ { t - u }$ and taking expectation yields:

$$
\gamma (u) = \left\{ \begin{array}{l l} \phi \gamma (1) + (1 + \theta (\phi + \theta)) \sigma_ {\varepsilon} ^ {2} & u = 0 \\ \phi \gamma (0) + \theta \sigma_ {\varepsilon} ^ {2} & u = 1 \\ \phi \gamma (u - 1) & u \geq 2 \end{array} \right.
$$

Solving the first two equations produces

$$
\gamma (0) = \frac {(1 + 2 \theta \phi + \theta^ {2})}{1 - \phi^ {2}} \sigma_ {\varepsilon} ^ {2} = \frac {(1 + 2 \theta \phi + \theta^ {2})}{1 - \phi^ {2}} \sigma_ {\varepsilon} ^ {2}
$$

and using the last recursively shows

$$
\gamma (u) = \frac {(1 + \theta \phi) (\phi + \theta)}{1 - \phi^ {2}} \phi^ {u - 1} \sigma_ {\varepsilon} ^ {2} \qquad \text {f o r} u \geq 1.
$$

The autocorrelation function can then be computed as

$$
\rho (u) = \frac {(1 + \theta \phi) (\phi + \theta)}{(1 + 2 \theta \phi + \theta^ {2})} \phi^ {u - 1} \qquad \text {f o r} u \geq 1.
$$

The pattern here is similar to that for AR(1), except for the first term.

# 3.7.2 The ARMA(p,q) Model

It is possible to make general statements about the behaviour of general ARMA(p,q) series. When values are more than $q$ time units apart, the memory of the movingaverage part of the series is lost. The functions $\gamma ( u )$ and $\rho ( u )$ will then behave very similarly to those for the AR(p) series

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t}
$$

for large $u$ , but the first few terms will exhibit additional structure.

# 3.7.3 Computation

Stationarity can be checked by examining the roots of the characteristic polynomial of the AR operator and model parameterisation can be checked by examining the roots of the characteristic polynomial of the MA operator. Both checks can be carried out with polyroot.

The autocorrelation function for an ARMA series can be computed with ARMAacf. For the model

$$
Y _ {t} = -. 5 Y _ {t - 1} + \varepsilon_ {t} +. 3 \varepsilon_ {t - 1}
$$

this can be done as follows

```txt
> plot(0:14, ARMAacf(ar=-.5, ma=.3, lag=14), type="h", xlab = "Lag", ylab = "ACF")  
> abline(h = 0) 
```

and produces the result shown in figure 3.8.

Simulation can be carried out using arma.sim

$\begin{array}{rl} & {\mathrm{\bf >x = arima.sim(model = list(ar=-.5,ma=.3),n = 100)}}\\ & {\mathrm{\bf >plot(x)}} \end{array}$

producing the result in figure 3.9.

![](images/0e4f2ed93ac07abe5f31aeec4f05f9d10dcc0634142cf5fc8603880b99493f1c.jpg)  
Figure 3.8: The acf for the model $Y _ { t } = - . 5 Y _ { t - 1 } + \varepsilon _ { t } + . 3 \varepsilon _ { t - 1 }$ .

![](images/c666afb423fa8db2b4c5ef7b491ae50e2f88481902e98b7135eb3004c014fafb.jpg)  
Figure 3.9: Simulation of the model $Y _ { t } = - . 5 Y _ { t - 1 } + \varepsilon _ { t } + . 3 \varepsilon _ { t - 1 }$ .

# 3.7.4 Common Factors

If the AR and MA operators in an ARMA $( p , q )$ model possess common factors, then the model is over-parameterised. By dividing through by the common factors we can obtain a simpler model giving and identical description of the series. It is important to recognise common factors in an ARMA model because they will produce numerical problems in model fitting.

# 3.8 The Partial Autocorrelation Function

The autocorrelation function of an MA series exhibits different behaviour from that of AR and general ARMA series. The acf of an MA series cuts of sharply whereas those for AR and ARMA series exhibit exponential decay (with possible sinusoidal behaviour superimposed). This makes it possible to identify an ARMA series as being a purely MA one just by plotting its autocorrelation function. The partial autocorrelation function provides a similar way of identifying a series as a purely AR one.

Given a stretch of time series values

$$
\ldots , Y _ {t - u}, Y _ {t - u + 1}, \ldots , Y _ {t - 1}, Y _ {t}, \ldots
$$

the partial correlation of $Y _ { t }$ and $Y _ { t - u }$ is the correlation between these random variables which is not conveyed through the intervening values.

If the $Y$ values are normally distributed, the partial autocorrelation between $Y _ { t }$ and $Y _ { t - u }$ can be defined as

$$
\phi (u) = \operatorname {c o r} \left(Y _ {t}, Y _ {t - u} \mid Y _ {t - 1}, \dots , Y _ {t - u + 1}\right).
$$

A more general approach is based on regression theory. Consider predicting $Y _ { t }$ based on $Y _ { t - 1 } , \dots , Y _ { t - u + 1 }$ . The prediction is

$$
\widehat {Y} _ {t} = \beta_ {1} Y _ {t - 1} + \beta_ {2} Y _ {t - 2} \dots , \beta_ {u - 1} Y _ {t - u + 1}
$$

with the βs chosen to minimise

$$
\operatorname {E} (Y _ {t} - \widehat {Y} _ {t}) ^ {2}.
$$

It is also possible to “think backwards in time” and consider predicting $Y _ { t - u }$ with the same set of predictors. The best predictor will be

$$
\widehat {Y} _ {i - u} = \beta_ {1} Y _ {t - u + 1} + \beta_ {2} Y _ {t - u + 2} \dots , \beta_ {u - 1} Y _ {t - 1}.
$$

(The coefficients are the same because the correlation structure is the same whether the series is run forwards or backwards in time.

The partial correlation function at lag $u$ is the correlation between the prediction errors.

$$
\phi (u) = \mathrm {c o r} (Y _ {t} - \widehat {Y} _ {t}, Y _ {t - u} - \widehat {Y} _ {t - u})
$$

By convention we take $\phi ( 1 ) = \rho ( 1 )$ .

It is quite straightforward to compute the value of $\phi ( 2 )$ . Using the results of section 2.4.1, the best predictor of $Y _ { t }$ based on $Y _ { t - 1 }$ is just $\rho ( 1 ) Y _ { t - 1 }$ . Thus

$$
\begin{array}{l} \operatorname {c o v} \left(Y _ {t} - \rho (1) Y _ {t - 1}, Y _ {t - 2} - \rho (1) Y _ {t - 1}\right) = \sigma_ {Y} ^ {2} (\rho (2) - \rho (1) ^ {2} - \rho (1) ^ {2}) + \rho (1) ^ {2}) \\ = \sigma_ {Y} ^ {2} (\rho (2) - \rho (1) ^ {2}) \\ \end{array}
$$

and

$$
\begin{array}{l} \operatorname {v a r} \left(Y _ {t} - \rho (1) Y _ {t - 1}\right) = \sigma_ {Y} ^ {2} \left(1 + \rho (1) ^ {2} - 2 \rho (1) ^ {2}\right) \\ = \sigma_ {Y} ^ {2} (1 - \rho (1)) ^ {2} \\ \end{array}
$$

This means that

$$
\phi (2) = \frac {\rho (2) - \rho (1) ^ {2}}{1 - \rho (1) ^ {2}} \tag {3.14}
$$

Example 3.8.1 For the AR(1) series, recall that

$$
\rho (u) = \phi^ {u} \qquad (u \geq 0).
$$

Substituting this into equation 3.14 we find

$$
\phi (2) = \frac {\phi^ {2} - \phi^ {2}}{1 - \phi^ {2}} = 0.
$$

Example 3.8.2 For the MA(1) series

$$
\rho (u) = \left\{ \begin{array}{l l} \frac {\theta}{1 + \theta^ {2}} & \text {i f} u = 1, \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

Substituting this into 3.14 we find

$$
\begin{array}{l} \phi (2) = \frac {0 - (\theta / (1 + \theta^ {2})) ^ {2}}{1 - (\theta / (1 + \theta^ {2})) ^ {2}} \\ = \frac {- \theta^ {2}}{(1 + \theta^ {2}) ^ {2} - \theta^ {2}} \\ = \frac {- \theta^ {2}}{1 + \theta^ {2} + \theta^ {4}}. \\ \end{array}
$$

More generally it is possible to show

$$
\phi (u) = \frac {- \theta^ {u} (1 - \theta^ {2})}{1 - \theta^ {2 (u + 1)}} \qquad \text {f o r} u \geq 0.
$$

For the general AR(p) series, it is possible to show that $\phi ( u ) = 0$ for all $u \ > \ p$ . For such a series, the best predictor of $Y _ { t }$ using $Y _ { t - 1 } , \dots , Y _ { t - u + 1 }$ for $u > p$ is

$$
\phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p}.
$$

because

$$
Y _ {t} - \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} = \varepsilon_ {t}
$$

and $\varepsilon _ { t }$ is uncorrelated with $Y _ { t - 1 } , Y _ { t - 2 } , . . .$ , so that the “fit” cannot be improved.

The prediction error corresponding to the best linear predictor of $Y _ { t - u }$ is based on $Y _ { t - 1 } , \dots , Y _ { t - u + 1 }$ and so must be uncorrelated with $\varepsilon _ { t }$ . This shows that $\phi ( u ) = 0$ .

For the general MA(q), it is possible to show that $\phi ( u )$ decays exponentially as $u \longrightarrow \infty$ .

# 3.8.1 Computing the PACF

The definition of the partial autocorrelation function given in the previous section is conceptually simple, but it makes computations hard. In this section we’ll see that there is an equivalent form which is computationally simple.

Consider the $k$ th order autoregressive prediction of $Y _ { k + 1 }$

$$
\widehat {Y} _ {k + 1} = \phi_ {k 1} Y _ {k} + \dots + \phi_ {k k} Y _ {1} \tag {3.15}
$$

obtained by minimising $E ( Y _ { k + 1 } - \widehat { Y } _ { k + 1 } ) ^ { 2 }$ . We will show that the $k$ th partial autocorrelation values is given by $\phi ( k ) = \phi _ { k k }$ . The proof of this is a geometric one which takes places in the space $\mathcal { H }$ generated by the series $\{ Y _ { t } \}$ .

We begin by defining the subspace ${ \mathcal { H } } _ { 1 } = { \overline { { \operatorname { s p } } } } \{ Y _ { 2 } , \dots , Y _ { k } \}$ and associated projection $\mathcal { P } _ { \mathcal { H } _ { 1 } }$ , the subspace ${ \mathcal { H } } _ { 2 } = { \overline { { \operatorname { s p } } } } \{ Y _ { 1 } - { \mathcal { P } } _ { { \mathcal { H } } _ { 1 } } Y _ { 1 } \}$ and the subspace $\mathcal { H } _ { k } =$ s ${ \bar { \upsilon } } \{ Y _ { 1 } , \ldots , Y _ { k } \}$ . Any $Y \in \mathcal { H }$ ,

$$
\mathcal {P} _ {\mathcal {H} _ {k}} Y = \mathcal {P} _ {\mathcal {H} _ {1}} Y + \mathcal {P} _ {\mathcal {H} _ {2}} Y.
$$

Thus

$$
\begin{array}{l} \widehat {Y} _ {k + 1} = \mathcal {P} _ {\mathcal {H} _ {k}} Y _ {k + 1} \\ = \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {k + 1} + \mathcal {P} _ {\mathcal {H} _ {2}} Y _ {k + 1} \\ = \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {k + 1} + a \left(Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1}\right), \\ \end{array}
$$

where

$$
a = \left\langle Y _ {k + 1}, Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \right\rangle / \| Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \| ^ {2}. \tag {3.16}
$$

Rearranging, we find

$$
\widehat {Y} _ {k + 1} = \mathcal {P} _ {\mathcal {H} _ {1}} \left(Y _ {k + 1} - a Y _ {1}\right) + a Y _ {1}.
$$

The first term on the right must be a linear combination of $Y _ { 2 } , \ldots , Y _ { k }$ , so comparing with equation 3.15 we see that $a = \phi _ { k k }$ .

Now, the kth partial correlation is defined as the correlation between the residuals from the regressions of $Y _ { k + 1 }$ and $Y _ { 1 }$ on $Y _ { 2 } , \ldots , Y _ { k }$ . But this is just

$$
\begin{array}{l} \operatorname {c o r} \left(Y _ {k + 1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {k + 1}, Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1}\right) \\ = \left\langle Y _ {k + 1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {k + 1}, Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \right\rangle / \| Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \| ^ {2} \\ = \left\langle Y _ {k + 1}, Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \right\rangle / \left\| Y _ {1} - \mathcal {P} _ {\mathcal {H} _ {1}} Y _ {1} \right\| ^ {2} \\ = a \\ \end{array}
$$

by equation 3.16.

A recursive way of computing the regression coefficients in equation 3.15 from the autocorrelation function was given by Levinson (1947) and Durbin (1960). The Durbin-Levinson algorithm updates the coefficients the from $k - 1 \mathrm { s t }$ order model to those of the $k$ th order model as follows:

$$
\phi_ {k k} = \frac {\rho (k) - \sum_ {j = 1} ^ {k - 1} \phi_ {k - 1 , j} \rho_ {k - j}}{1 - \sum_ {j = 1} ^ {k - 1} \phi_ {k - 1 , j} \rho_ {j}}
$$

$$
\phi_ {k, j} = \phi_ {k - 1, j} - \phi_ {k k} \phi_ {k - 1, k - j} \quad j = 1, 2, \dots , k - 1.
$$

# 3.8.2 Computation

The R function ARMAacf can be used to obtain the partial autocorrelation function associated with a stationary ARMA series. The call to ARMAacf is identical to its use for obtaining the ordinary autocorrelation function, except it has the additional argument pacf=TRUE.

The following code computes and plots the partial autocorrelation function for the ARMA(1,1) model with $\phi = - . 5$ and $\theta = . 3$ .

```txt
> plot(1:14, ARMAacf(ar=-.5, ma=.3, lag=14, pacf=TRUE), type="h", xlab = "Lag", ylab = "ACF")  
> abline(h = 0) 
```

The resulting plot is shown in figure 3.10.

![](images/13b5cfa7f7d6abddea3c4b441e29f82cb6563df55ecc5b840b85c1a284fec5ce.jpg)  
Figure 3.10: The partial acf for the model $Y _ { t } = - . 5 Y _ { t - 1 } + \varepsilon _ { t } + . 3 \varepsilon _ { t - 1 }$ .

# Chapter 4

# Identifying Time Series Models

# 4.1 ACF Estimation

We have seen that it is possible to distinguish between AR, MA and ARMA models by the behaviour of their acf and pacf functions. In practise, we don’t know these functions and so we must estimate them.

Given a stretch of data $Y _ { 1 } , \dots , Y _ { T }$ , the usual estimate of the autocovariance function is

$$
\widehat {\gamma} (u) = \frac {1}{T} \sum_ {t = 1} ^ {T - u} \left(Y _ {t + u} - \overline {{Y}}\right) \left(Y _ {t} - \overline {{Y}}\right)
$$

Note that this estimator is biased — an unbiased estimator would have a divisor of $T - u$ in place of $T$ . There are two reasons for using this estimator.

The first of these reasons is that it produces a $\widehat { \gamma } ( u )$ which is positive definite. This means that for any constants $c _ { 1 } , \ldots , c _ { k }$ ,

$$
\sum_ {u = 1} ^ {k} \sum_ {v = 1} ^ {k} c _ {u} c _ {v} \widehat {\gamma} (u - v) \geq 0.
$$

This ensures that our estimate of the variance of

$$
\sum_ {u = 1} ^ {k} c _ {u} X _ {t - u}
$$

will be non-negative, something which might not be the case for the unbiased estimate.

The second reason is that for many time series $\gamma ( u ) \to 0$ as $u  \infty$ . For such time series, the biased estimate can have lower mean-squared error.

The estimate of $\rho ( u )$ based on $\widehat { \gamma } ( u )$ is

$$
r (u) = \frac {\widehat {\gamma} (u)}{\widehat {\gamma} (0)} = \frac {\sum_ {t} (Y _ {t + u} - \overline {{Y}}) (Y _ {t} - \overline {{Y}})}{\sum_ {t} (Y _ {t} - \overline {{Y}}) ^ {2}}
$$

(Again, this can have better mean-squared error properties than the estimate based on the unbiased estimate of $\gamma ( u )$ .)

In order to say whether an observed correlation is significantly different from zero, we need some distribution theory. Like most time series results, the theory here is asymptotic (as $T \to \infty$ ). The original results in this area were obtained by Bartlett in 1947. We will look at results due to T. W. Anderson in 1971.

Suppose that

$$
Y _ {t} = \mu + \sum_ {u = 0} ^ {\infty} \psi_ {u} \varepsilon_ {t - u}
$$

with the $\varepsilon _ { t }$ independent and identically distributed with zero mean and non-zero variance. Suppose that

$$
\sum_ {u = 0} ^ {\infty} \left| \psi_ {u} \right| <   \infty \quad \text {a n d} \quad \sum_ {u = 0} ^ {\infty} u \left| \psi_ {u} \right| ^ {2} <   \infty .
$$

(This is true for all stationary ARMA series). The last condition can be replaced by the requirement that the $\{ Y _ { t } \}$ values have a finite fourth moment.

Under these conditions, for any fixed $m$ , the joint distribution of

$$
\sqrt {T} (r (1) - \rho (1)), \sqrt {T} (r (2) - \rho (2)), \dots \sqrt {T} (r (m) - \rho (m))
$$

is asymptotically normal with zero means and covariances

$$
\begin{array}{l} c _ {u v} = \sum_ {t = 0} ^ {\infty} (\rho (t + u) \rho (t + v) + \rho (t - u) \rho (t + v) \\ - 2 \rho (u) \rho (t) \rho (t + v) - 2 \rho (v) \rho (t) \rho (t + u) \tag {4.1} \\ + 2 \rho (u) \rho (v) \rho (t) ^ {2}). \\ \end{array}
$$

I.e. for large $T$

$$
r (u) \approx N (0, c _ {u u} / T) \qquad \operatorname {c o r} \big (r (u), r (v) \big) \approx \frac {c _ {u v}}{\sqrt {c _ {u u} c _ {v v}}}.
$$

Notice that var $r ( u ) \downarrow 0$ but that the correlations stay approximately constant.

Equation 4.1 is clearly not easy to interpret in general. Let’s examine some special cases.

Example 4.1.1 White Noise.

The theory applies to the case that the $Y _ { t }$ are i.i.d.

$$
\operatorname {v a r}   r (u) \approx \frac {1}{T} \qquad \operatorname {c o r} \big (r (u), r (v) \big) \approx 0
$$

Example 4.1.2 The AR(1) Series.

In this case $\rho ( u ) ~ = ~ \phi ^ { u }$ for $u > 0$ . After a good deal of algebra (summing geometric series) one finds:

$$
\operatorname {v a r} r (u) \approx \frac {1}{T} \left(\frac {(1 + \phi^ {2}) (1 - \phi^ {2 u})}{1 - \phi^ {2}} - 2 u \phi^ {2 u}\right).
$$

In particular, for $u = 1$ ,

$$
\operatorname {v a r} r (1) \approx \frac {1 - \phi^ {2}}{T}.
$$

Table 4.1: Large Sample Results for $r _ { k }$ for an AR(1) Model.   

<table><tr><td>φ</td><td>√var r(1)</td><td>√var r(2)</td><td>cor(r(1),r(2))</td><td>√var r(10)</td></tr><tr><td>0.9</td><td>0.44/√T</td><td>0.807/√T</td><td>0.97</td><td>2.44/√T</td></tr><tr><td>0.7</td><td>0.71/√T</td><td>1.12/√T</td><td>0.89</td><td>1.70/√T</td></tr><tr><td>0.5</td><td>0.87/√T</td><td>1.15/√T</td><td>0.76</td><td>1.29/√T</td></tr><tr><td>0.3</td><td>0.95/√T</td><td>1.08/√T</td><td>0.53</td><td>1.09/√T</td></tr><tr><td>0.1</td><td>0.99/√T</td><td>1.01/√T</td><td>0.20</td><td>1.01/√T</td></tr></table>

Notice that the closer $\phi$ is to $\pm 1$ , the more accurate the estimate becomes.

As $u \longrightarrow \infty$ , $\phi ^ { 2 u } \to 0$ . In that case

$$
\operatorname {v a r} r (u) \approx \frac {1}{T} \left(\frac {1 + \phi^ {2}}{1 - \phi^ {2}}\right).
$$

For values of $\phi$ close to $\pm 1$ this produces large variances for the $r ( u )$ .

For $0 < u \leqslant v$ (after much algebra),

$$
c _ {u v} = \frac {\left(\phi^ {v - 1} - \phi^ {v + u}\right) \left(1 + \phi^ {2}\right)}{1 - \phi^ {2}} + (v - u) \phi^ {v - u} - (v + u) \phi^ {v + u}.
$$

In particular,

$$
\operatorname {c o r} \big (r (1), r (2) \big) \approx 2 \phi \left(\frac {1 - \phi^ {2}}{1 + 2 \phi^ {2} - 3 \phi^ {4}}\right) ^ {1 / 2}
$$

Using these formulae it is possible to produce the results in table 4.1.

# Example 4.1.3 The MA(1) Series

For the MA(1) series it is straightforward to show that

$$
c _ {1 1} = 1 - 3 \rho (1) ^ {2} + 4 \rho (1) ^ {4}
$$

$$
c _ {u u} = 1 - 2 \rho (1) ^ {2} \qquad u > 1
$$

$$
c _ {1 2} = 2 \rho (1) (1 - \rho (1) ^ {2})
$$

Using these results it is easy to produce the results in table 4.2.

# Example 4.1.4 The General MA(q) Series

In the case of the general MA(q) series it is easy to see that

$$
c _ {u u} = 1 + 2 \sum_ {v = 1} ^ {q} \rho (v) ^ {2}, \quad \text {f o r} u > q,
$$

and hence that

$$
\operatorname {v a r} r (u) = \frac {1}{T} \left(1 + 2 \sum_ {v = 1} ^ {q} \rho (v) ^ {2}\right), \quad \text {f o r} u > q.
$$

Table 4.2: Large Sample Results for $r _ { k }$ for an MA(1) Model.   

<table><tr><td>θ</td><td>√var r(1)</td><td>√var r(k) (k &gt; 1)</td><td>cor(r(1), r(2))</td></tr><tr><td>0.9</td><td>0.71/√T</td><td>1.22/√T</td><td>0.86</td></tr><tr><td>0.7</td><td>0.73/√T</td><td>1.20/√T</td><td>0.84</td></tr><tr><td>0.5</td><td>0.79/√T</td><td>1.15/√T</td><td>0.74</td></tr><tr><td>0.4</td><td>0.84/√T</td><td>1.11/√T</td><td>0.65</td></tr></table>

# Notes

1. In practise we don’t know the parameters of the model generating the data we might have. We can still estimate the variances and covariances of the $r ( u )$ by substituting estimates of $\rho ( u )$ into the formulae above.   
2. Note that there can be quite large correlations between the $r ( u )$ values so caution must be used when examining plots of $r ( u )$ .

# 4.2 PACF Estimation

In section 3.8.1 we saw that the theoretical pacf can be computed by solving the Durbin-Levinson recursion

$$
\phi_ {k k} = \frac {\rho (k) - \sum_ {j = 1} ^ {k - 1} \phi_ {k - 1 , j} \rho (k - j)}{1 - \sum_ {j = 1} ^ {k - 1} \phi_ {k - 1 , j} \rho (j)}
$$

$$
\phi_ {k, j} = \phi_ {k - 1, j} - \phi_ {k k} \phi_ {k - 1, k - j} \quad j = 1, 2, \dots , k - 1.
$$

and setting $\phi ( u ) = \phi _ { u u }$

In practice, the estimated autocorrelation function is used in place of the theoretical autocorrelation function to generate estimates of the partial autocorrelation function.

To decide whether partial autocorrelation values are significantly different from zero, we can use a (1949) result of Quenouille which states that if the true underlying model is $\operatorname { A R } ( p )$ , then the estimated partial autocorrelations at lags greater than $p$ are approximately independently normal with means equal to zero and variance $1 / T$ . Thus $\pm 2 / \sqrt { T }$ can be used as critical limits on $\phi ( u )$ for $u > p$ to test the hypothesis of an $\operatorname { A R } ( p )$ model.

![](images/07a27cda75109db373b8b87ee0ab0ba8beff16243fd58e404f55a4e2794ea66a.jpg)  
Figure 4.1: Monthly differences between the yield on mortgages and government loans in the Netherlands, January 1961 to March 1974.

# 4.3 System Identification

Given a set of observations $Y _ { 1 } , \dots , Y _ { T }$ we will need to decide what the appropriate model might be. The estimated acf and pacf are the tools which can be used to do this. If the acf exhibits slow decay and the pacf cuts off sharply after lag $p$ , we would identify the series as AR(p). If the pacf shows slow decay and the acf show a sharp cutoff after lag $q$ , we would identify the series as being $\mathrm { M A } ( q )$ . If both the acf and pacf show slow decay we would identify the series as being mixed ARMA. In this case the orders of the AR and MA parts are not clear, but it is reasonable to first try ARMA(1,1) and move on to higher order models if the fit of this model is not good.

# Example 4.3.1 Interest Yields

Figure 4.1 shows a plot of the Monthly differences between the yield on mortgages and government loans in the Netherlands, January 1961 to March 1974. The series appears stationary, so we can attempt to use the acf and pacf to decide whether an AR, MA or ARMA model might be appropriate.

Figures 4.2 and 4.3 show the estimated acf and pacf functions for the yield series. The horizontal lines in the plots are drawn at the $y$ values $\pm 1 . 9 6 / \sqrt { 1 5 9 }$ (the series has 159 values). These provide 95% confidence limits for what can be expected under the hypothesis of white noise. Note that these limits are point-wise so that we would expect to see roughly 5% of the values lying outside the limits.

The acf plot shows evidence of slow decay, while the pacf plot shows a “sharp

![](images/25442b59f2865e7a743c0a98975a89021c78fbec9784f096436fd092543cdde8.jpg)  
Figure 4.2: The acf for the yield data.

![](images/25147a0079c53b2c9ef41ff2d61d1f97ca09cfdafe4b31f7c23744f4dfea0cfb.jpg)  
Figure 4.3: The pacf for the yield data.

![](images/d13f04259800846efd9a5bff6beced9de374bca923ea7da5bdb0cd39ba3f6746.jpg)  
Figure 4.4: Yields from a chemical process (from Box and Jenkins).

cutoff” after lag 1. On the basis of these two plots we might hypothesise that an AR(1) model was an appropriate description of the data.

# Example 4.3.2 Box and Jenkins Chemical Yields

Figure 4.4 shows an example from the classic time series text by Box and Jenkins. This series contains consecutive yields recorded from a chemical process. Again, the series is apparently stationary so that we can consider identifying an appropriate model on the basis of the acf and pacf.

Again, the acf seems to show slow decay, this time with alternating signs. The pacf shows sudden cutoff after lag 1, suggesting that again an AR(1) model might be appropriate.

# 4.4 Model Generalisation

ARMA series provide a flexible class of models for stationary mean-zero series, with AR and MA series being special cases.

Unfortunately, many series are clearly not in this general class for models. It is worthwhile looking at some generalisation of this class.

# 4.4.1 Non-Zero Means

When a series $\{ Y _ { t } \}$ has a non-zero mean $\mu$ , the mean can be subtracted and the deviations from the mean modeled as an ARMA series.

$$
Y _ {t} - \mu = \phi_ {1} (Y _ {t - 1} - \mu) + \dots + \phi_ {p} (Y _ {t - p} - \mu) + \varepsilon_ {t} + \theta_ {1} \varepsilon_ {t - 1} + \dots + \theta_ {q} \varepsilon_ {t - q}
$$

![](images/c45120323885a0d520f7a4d65949017df5cddfb68dc4fdddd4e55788978bfc0d.jpg)  
Figure 4.5: The acf for the chemical process data.

![](images/b0889e4ef2f999f87996877d4be95ba5bd2cd8133361167ffa1025d5ce604684.jpg)  
Figure 4.6: The pacf for the chemical process data.

Alternatively, the model can be adjusted by introducing a constant directly.

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \theta_ {0} + \varepsilon_ {t} + \theta_ {1} \varepsilon_ {t - 1} + \dots + \theta_ {q} \varepsilon_ {t - q}
$$

The two characterisations are connected by

$$
\theta_ {0} = \mu - \mu \left(\phi_ {1} + \dots + \phi_ {p}\right)
$$

so that

$$
\mu = \frac {\theta_ {0}}{1 - \phi_ {1} - \cdots - \phi_ {p}}
$$

or

$$
\theta_ {0} = \mu (1 - \phi_ {1} - \dots - \phi_ {p}).
$$

# 4.4.2 Deterministic Trends

Consider the model

$$
Y _ {t} = f (t) + Z _ {t},
$$

where $Z _ { t }$ is a stationary ARMA series and $f ( t )$ is a deterministic function of $t$ . Considering $Y _ { t } - f ( t )$ reduces $Y _ { t }$ to an ARMA series. (If $f ( t )$ contains unknown parameters we can estimate them.)

# 4.4.3 Models With Non-stationary AR Components

We’ve seen that any AR model with characteristic equation roots outside the unit circle will be non-stationary.

# Example 4.4.1 Random Walks

A random walk is defined by the equation

$$
Y _ {t} = Y _ {t - 1} + \varepsilon_ {t}
$$

where $\left\{ \varepsilon _ { t } \right\}$ is a series of uncorrelated (perhaps independent) random variables. In operator form this equation is

$$
(1 - L) Y _ {t} = \varepsilon_ {t}.
$$

The equation $1 - z = 0$ has a root at 1 so that $Y _ { t }$ is non-stationary.

# Example 4.4.2 Integrated Moving Averages

Consider the model

$$
Y _ {t} = Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1}.
$$

This is similar to an ARMA(1,1) model, but again it is non-stationary.

Both these models can be transformed to stationarity by differencing — transforming to $\nabla Y _ { t } = Y _ { t } - Y _ { t - 1 }$ . In the first example we have,

$$
\nabla Y _ {t} = \varepsilon_ {t},
$$

which is the white noise model. In the second we have,

$$
\nabla Y _ {t} = \varepsilon_ {t} + \theta \varepsilon_ {t - 1},
$$

which is the MA(1) model.

# 4.4.4 The Effect of Differencing

Suppose that $Y _ { t }$ has a linear trend

$$
Y _ {t} = \beta_ {0} + \beta_ {1} t + Z _ {t}
$$

where $Z _ { t }$ is stationary with $\operatorname { E } ( Z _ { t } ) = 0$ .

$$
\nabla Y _ {t} = \beta_ {1} + \nabla Z _ {t}
$$

Differencing has removed the trend. Now suppose that $\{ Y _ { t } \}$ has a deterministic quadratic trend

$$
Y _ {t} = \beta_ {0} + \beta_ {1} t + \beta_ {2} t ^ {2} + Z _ {t}
$$

then

$$
\begin{array}{l} \nabla Y _ {t} = (\beta_ {0} + \beta_ {1} t + \beta_ {2} t ^ {2}) - (\beta_ {0} + \beta_ {1} (t - 1) + \beta_ {2} (t - 1) ^ {2}) + \nabla Z _ {t} \\ = \beta_ {1} + \beta_ {2} (t ^ {2} - (t ^ {2} - 2 t + 1)) + \nabla Z _ {t} \\ \mathbf {\beta} = (\beta_ {1} - \beta_ {2}) + 2 \beta_ {2} t + \nabla Z _ {t} \\ = \text {l i n e a r} \\ \end{array}
$$

Differencing again produces

$$
\nabla^ {2} Y _ {t} = 2 \beta_ {2} + \nabla^ {2} Z _ {t}.
$$

In general, a polynomial trend of order $k$ can be eliminated by differencing $k$ times.

Now let’s consider the case of a “stochastic trend.” Suppose that

$$
Y _ {t} = M _ {t} + \varepsilon_ {t}
$$

where $M _ { t }$ is a random process which changes slowly over time. In particular, we can assume that $M _ { t }$ is generated by a random walk model.

$$
M _ {t} = M _ {t - 1} + \eta_ {t}
$$

with $\eta _ { t }$ independent of $\varepsilon _ { t }$ . Then

$$
\nabla Y _ {t} = \eta_ {t} + \varepsilon_ {t} - \varepsilon_ {t - 1}.
$$

$\nabla Y _ { t }$ is stationary and has an autocorrelation function like that of an MA(1) series.

$$
\rho (1) = \frac {- 1}{2 + (\sigma_ {\eta} / \sigma_ {\varepsilon}) ^ {2}}
$$

More generally, “higher order” stochastic trend models can be reduced to stationarity by repeated differencing.

# 4.5 ARIMA Models

If $W _ { t } = \nabla ^ { d } Y _ { t }$ is an ARMA(p,q) series than $Y _ { t }$ is said to be an integrated autoregressive moving-average $( p , d , q )$ series, denoted ARIMA(p,d,q). If we write

$$
\phi (L) = 1 - \phi_ {1} L - \dots - \phi_ {p} L ^ {p}
$$

and

$$
\theta (L) = 1 + \theta_ {1} L + \dots + \theta_ {q} L ^ {q}
$$

then we can write down the operator formulation

$$
\phi (L) \nabla^ {d} Y _ {t} = \theta (L) \varepsilon_ {t}.
$$

Example 4.5.1 The IMA(1,1) Model This model is widely used in business and economics. It is defined by

$$
Y _ {t} = Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1}.
$$

$Y _ { t }$ can be thought of as a random walk with correlated errors.

Notice that

$$
\begin{array}{l} Y _ {t} = Y _ {t - 1} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1} \\ = Y _ {t - 2} + \varepsilon_ {t - 1} + \theta \varepsilon_ {t - 2} + \varepsilon_ {t} + \theta \varepsilon_ {t - 1} \\ = Y _ {t - 2} + \varepsilon_ {t} + (1 + \theta) \varepsilon_ {t - 1} + \theta \varepsilon_ {t - 2} \\ \begin{array}{c} \vdots \\ \vdots \\ \vdots \end{array} \\ = Y _ {- m} + \varepsilon_ {t} + (1 + \theta) \varepsilon_ {t - 1} + \dots + (1 + \theta) \varepsilon_ {- m} + \theta \varepsilon_ {- m - 1} \\ \end{array}
$$

If we assume that $Y _ { - m } = 0$ (i.e. observation started at time $- m$ ),

$$
Y _ {t} = \varepsilon_ {t} + (1 + \theta) \varepsilon_ {t - 1} + \dots + (1 + \theta) \varepsilon_ {- m} + \theta \varepsilon_ {- m - 1}
$$

This representation can be used to derive the formulae

$$
\operatorname {v a r} \left(Y _ {t}\right) = \left(1 + \theta^ {2} + (1 + \theta) ^ {2} (t + m)\right) \sigma_ {\varepsilon} ^ {2}
$$

$$
\begin{array}{l} \operatorname {c o r} \left(Y _ {k}, Y _ {t - k}\right) = \frac {1 + \theta^ {2} + (1 + \theta) ^ {2} (t + m - k)}{\left(\operatorname {v a r} (Y _ {t}) \operatorname {v a r} (Y _ {t - k})\right) ^ {1 / 2}} \\ = \sqrt {\frac {t + m - k}{t + m}} \\ \approx 1 \\ \end{array}
$$

for $m$ large and $k$ moderate. (We are considering behaviour after “burn-in.”) This means that we can expect to see very slow decay in the autocorrelation function.

The very slow decay of the acf function is characteristic of ARIMA series with $d > 0$ . Figures 4.7 and 4.8 show the estimated autocorrelation functions from a simulated random walk and an integrated autoregressive model. Both functions show very slow declines in the acf.

![](images/3279860e16c0cfced0a4312b49b1bcc055a920e729481ed983e8ed0c40aee2d4.jpg)  
Figure 4.7: The autocorrelation function of the ARIMA(0,1,0) (random walk) model.

![](images/2242226036af88eac1c6a3ffa20a442dc790b8b80e303690d3bdc066c383da8f.jpg)  
Figure 4.8: The autocorrelation function of the ARIMA(1,1,0) model with $\phi _ { 1 } = . 5$ .

# Chapter 5

# Fitting and Forecasting

# 5.1 Model Fitting

Suppose that we have identified a particular ARIMA(p,d,q) model which appears to describe a given time series. We now need to fit the identified model and assess how well the model fits. Fitting is usually carried out using maximum likelihood. For a given set of model parameters, we calculate a series of onestep-ahead predictions.

$$
\widehat {Y} _ {k + 1} = P _ {\mathcal {H} _ {k}} Y _ {k + 1}
$$

where $\mathcal { H } _ { k }$ is the linear space spanned by $Y _ { 1 } , \dots , Y _ { k }$ . The predictions are obtained in a recursive fashion using a process known as Kalman filtering. Each prediction results in a prediction error $\widehat { Y } _ { k + 1 } - Y _ { k + 1 }$ . These are, by construction, uncorrelated. If we add the requirement that the $\{ Y _ { t } \}$ series is normally distributed, the prediction errors are independent normal random variables and this can be used as the basis for computing the likelihood.

The parameters which need to be estimated are the AR coefficients $\phi _ { 1 } , \ldots , \phi _ { p }$ , the MA coefficients $\theta _ { 1 } , \ldots , \theta _ { q }$ and a constant term (either $\mu$ or $\theta _ { 0 }$ as outlined in section 4.4.1). Applying maximum-likelihood produces both estimates and standard errors.

# 5.1.1 Computations

Given a time series y in $\mathrm { R }$ , we can fit an ARMA(p,d,q) model to the series as follows

$$
> z = \operatorname {a r i m a} (y, \operatorname {o r d e r} = c (p, d, q))
$$

The estimation results can be inspected by printing them.

# Example 5.1.1 U.S. Unemployment Rates

Figure 5.1 shows a plot of the seasonally adjusted quarterly United States unemployment rates from the first quarter of 1948 to the first quarter of 1978. If the data is stored as a time series in the R data set unemp, the plot can be produced with the command

> plot(unemp)

![](images/56e804237f62029d8b6424aa8908538d06edec5904a2db4fcc6c4082695a3268.jpg)  
Figure 5.1: United States quarterly unemployment rates (seasonally adjusted).

Neither the original series nor the presence of very slow decay in the acf (figure 5.2) indicate strongly that differencing is required so we will leave the series undifferenced and attempt to find an appropriate ARMA model.

The acf and pacf functions for the series can be computed and plotted with the following commands

> acf(unemp)   
> pacf(unemp)

The resulting plots (figures 5.2 and 5.3) show the strong signature of an AR(2) series (slow decay of the acf and sharp cutoff of the pacf after two lags.)

With the series identified we can go about estimating the unknown parameters. We do this with the arima function in R.

> $z = \text{arima(unemp, order} = c(2, 0, 0))$ > $z$

```txt
Call:  
arima(x = unemp, order = c(2, 0, 0)) 
```

```txt
Coefficients: ar1 ar2 intercept 1.5499 -0.6472 5.0815 s.e. 0.0681 0.0686 0.3269 
```

sigma^2 estimated as 0.1276: log likelihood $=$ -48.76, aic $=$ 105.53

![](images/f907e44200899c0cd172697a77fb3f73bc3d1bd13861d26027b49d4820c8847f.jpg)  
Figure 5.2: The acf for the unemployment series.

![](images/b6beafcba4e5a76a3121a66f1c2299b6228b8b9a12f1d4e13c9ce008c8fc2d52.jpg)  
Figure 5.3: The pacf for the unemployment series.

The fitted model in this case is

$$
Y _ {t} = 5. 0 8 1 5 + 1. 5 4 9 9 Y _ {t - 1} - 0. 6 4 7 2 Y _ {t - 2} + \varepsilon_ {t}
$$

where $\varepsilon _ { t }$ has an estimated variance of 0.1276.

# Example 5.1.2 Railroad Bond Yields

Figure 5.4 shows a plot of the monthly yields on AA rated railroad bonds (as a percentage times 100). With the data values stored in the R variable rrbonds, the plot was produced with the command

> plot(rrbonds, ylab = "Bond Yields")

In this case it is clear that the series is non-stationary and we need to transform to stationarity by taking differences. The series can be differenced and the result plotted as follows

> rrdiffs = diff(rrbonds)   
> plot(rrdiffs, ylab = "Differenced Yields")

Figure 5.5 shows a plot of the differenced series and it is clear from this plot that the assumption of stationarity is much more reasonable. To confirm this, and to suggest possible models we need to examine the acf and pacf functions. These are shown in figures 5.6 and 5.7.

The model signature here is less certain than that of the previous example. A possible interpretation is that the acf is showing rapid decay and the pacf is showing sharp cutoff after one lag. This suggests that original series can be modelled as an ARIMA(1,1,0) series.

The estimation of parameters can be carried out for this model as follows

> z = arima(rrbonds,order=c(1,1,0)) > z

Call: arima(x = rrbonds, order = c(1, 1, 0))

Coefficients: ar1 0.4778 s.e. 0.0865

sigma^2 estimated as 84.46: log likelihood $=$ -367.47, aic $=$ 738.94

The fitted model in this case is

$$
\nabla Y _ {t} = 0. 4 7 7 8 \nabla Y _ {t} + \varepsilon_ {t}.
$$

with $\varepsilon _ { t }$ having an estimated variance of 84.46.

# 5.2 Assessing Quality of Fit

Once a model has been fitted to a set of data it is always important to assess how well the model fits. This is because the inferences we make depend crucially

![](images/4e537d848e09f7783e80a924ceb1bb4319db70528e0e72dd0d605cadc0c88aa1.jpg)  
Figure 5.4: Monthly AA railroad bond yields $\% \times 1 0 0 )$ .

![](images/de4fa60378153867a7655b34483650486f9f7f0498fa6c44b22684f6f6f82d85.jpg)  
Figure 5.5: Differenced monthly AA railroad bond yields.

![](images/a8f442d153508010b81709923fa3a3463aea47a4aace65ebdf61978b522d8519.jpg)  
Figure 5.6: The ACF for the differenced monthly AA railroad bond yields.

![](images/89d9d811091d4d835d90ecdf705dc1bb1d30bb0dde98243e5aed9164b8bcd58b.jpg)  
Figure 5.7: The PACF for the differenced monthly AA railroad bond yields.

on the appropriateness of the fitted model. The usual way of assessing goodness of fit is through the examination of residuals.

In the case of autoregressive models it is easy to see how residuals might be defined. In the case of the AR(p) model

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t}
$$

it is clear that we can take the residuals to be

$$
\widehat {\varepsilon} _ {t} = Y _ {t} - \widehat {\phi} _ {1} Y _ {t - 1} + \dots + \widehat {\phi} _ {p} Y _ {t - p}
$$

In the general ARMA case

$$
Y _ {t} = \phi_ {1} Y _ {t - 1} + \dots + \phi_ {p} Y _ {t - p} + \varepsilon_ {t} + \theta_ {1} \varepsilon_ {t - 1} + \dots + \theta_ {q} \varepsilon_ {t - q}
$$

or

$$
\phi (L) = \theta (L) \varepsilon_ {t - q}
$$

we must first transform to autoregressive form by inverting the MA operator.

$$
\theta (L) ^ {- 1} \phi (L) = \varepsilon_ {t}
$$

or

$$
Y _ {t} = \sum_ {u = 1} ^ {\infty} \pi_ {u} Y _ {t - u} + \varepsilon_ {t}.
$$

The residuals can then be defined as

$$
\widehat {\varepsilon} _ {t} = Y _ {t} - \sum_ {u = 1} ^ {\infty} \widehat {\pi} _ {u} Y _ {t - u}.
$$

This is a useful theoretical approach, but in practise the residuals are obtained as a byproduct of the computation of the likelihood (they are the prediction errors from the one-step ahead forecasts). If the ARMA model is correct (and the series is normally distributed) then the residuals are approximately independent normal random variables with mean zero and variance $\sigma _ { \varepsilon } ^ { 2 }$ .

A simple diagnostic is to simply plot the residuals and to see whether they appear to be a white noise series. In the case of the US unemployment series we can do this as follows

The results are shown in figure 5.8.

It is also possible to carry out tests of normality on the residuals. This can be done by simply producing a histogram of the residuals or by performing a normal quantile-quantile plot. This can be done as follows:

> hist(resid(z))   
> qqnorm(resid(z))

A simple check of heteroscedasticity can be carried out by plotting the residuals against the fitted values. This is done with the following command:

None of these plots indicate that there is any problem with the fit of the model.

![](images/eef0aa5cab5f3056f47ffe2ebf3e2f398a895727d15e51bb22d62b7680c9ee72.jpg)  
Figure 5.8: Residuals from the unemployment data.

# 5.3 Residual Correlations

It is tempting to examine the quality of model fit by seeing whether the residuals form an uncorrelated sequence. One might for example plot the estimated acf of the residuals and look for lags where the correlations exceed $\pm 2 / \sqrt { T }$ . Unfortunately, while these limits are approximately correct for large lags, for small lags they overstate the variability of the estimated correlations. This should be no surprise, the effect of model-fitting is to remove as much of the correlation present in the series as possible. The correlations between the residuals should be closer to zero than for a non-fitted series.

In addition to checking whether there are large individual correlations present in a time series, it can be useful to pool information from successive correlations to see whether there is significant correlation left in the residuals.

One test statistic in common use is the modified Box-Pierce (or Ljung-Box-Pierce) statistic

$$
Q ^ {*} = T (T + 2) \sum_ {k = 1} ^ {K} \frac {\widehat {r} _ {k} ^ {2}}{T - k}.
$$

If the true underlying model is ARMA $( p , q )$ , the distribution of $Q ^ { * }$ is approximately χ2K−p−q. $\chi _ { K - p - q } ^ { 2 }$

In R, the modified Box-Pierce statistic (and an older variant) can be computed with the function Box.test (you should specify type="Ljung"). An alternative is to use the function tsdiag which plots the (standardised) residuals, the acf of the residuals and the modified Box-Pierce statistic for a variety of values of $K$ . In the case of the US unemployment series, an appropriate

command would be

> tsdiag(z)

This produces the plot shown in figure 5.9. The first panel of the plot shows the (standardised) residuals from the model fit. The residuals look reasonably random but during the period from 1965 to 1970 there is a sequence of values which are all negative. This indicates that there may be problems with the model fit. The second panel shows the autocorrelation function for the residuals. One of the correlations (that at a lag of 7 quarters) lies outside the two standard error bounds about zero. Since we would expect one in twenty of the estimated correlations to exceed these bounds this does not provide evidence for a significant correlation. The third panel shows p-values for the Ljung-Box statistics at lags from one quarter to ten quarters. There is no evidence of significant correlation in this plot.

Overall, there is some evidence of lack of fit, but there is no obvious way of fixing the problem. Because of this we will move on to making forecasts for the series, but keep in mind that we need to be cautious in making use of these forecasts.

# 5.4 Forecasting

Once we have decided on an appropriate time-series model, estimated its unknown parameters and established that the model fits well, we can turn to the problem of forecasting future values of the series.

The autoregressive representation

$$
Y _ {t} = \sum_ {u = 1} ^ {\infty} \pi_ {u} Y _ {t - u} + \varepsilon_ {t}.
$$

suggests predicting the next observation beyond $Y _ { 1 } , \dots , Y _ { T }$ using

$$
\widehat {Y} _ {T + 1} = \sum_ {u = 1} ^ {\infty} \widehat {\pi} _ {u} Y _ {T + 1 - u}.
$$

where the $\widehat { \pi } _ { u }$ are obtained by substituting the estimated parameters in place of bthe theoretical ones.

Once a forecast is obtained for $Y _ { T + 1 }$ we can use it to obtain a forecast for $Y _ { T + 2 }$ and then use these two forcasts to generate a forecast for $Y _ { T + 3 }$ . The process can be continued to obtain forecasts out to any point in the future. Because uncertainty increases as we predict further and further from the data we have, we can expect the standard errors associated with our predictions to increase.

In practise, forecasts are generated by the same Kalman filter algorithm used to compute the likelihood used for parameter estimation.

# 5.4.1 Computation

Once a model has been fitted using arima, the function predict can be used to obtain forecasts. In the case of the US unemployment series we could obtain 10 future forecasts as follows:

![](images/b97e97ab1d2c2384ae557189d171d9c6951c07f41e03bbb10379002a36bfa54c.jpg)

![](images/078069d20c4a8175379b6b803ddcf5ebf48a81e121be65572111509382878968.jpg)

![](images/56de34b94d83474fcd3af834d09e1b13d121913370a04363dd6268d80f7c735f.jpg)  
Figure 5.9: Residual diagnostics for the US unemployment series.

# 5.5. Seasonal Models

$$
\begin{array}{l} > z = \operatorname {a r i m a} (\text {u n e m p}, \text {o r d e r} = c (2, 0, 0)) \\ > p = \text {p r e d i c t} (z, n. a h e a d = 1 0) \\ \end{array}
$$

The predictions can be viewed with the command

> p$pred

Qtr1 Qtr2 Qtr3 Qtr4

1978 5.812919 5.491268 5.243253

1979 5.067017 4.954379 4.893856 4.872947

1980 4.879708 4.903719 4.936557

and their standard errors with

> p$se

Qtr1 Qtr2 Qtr3 Qtr4

1978 0.3572328 0.6589087 0.9095040

1979 1.0969935 1.2248696 1.3040856 1.3479499

1980 1.3689669 1.3771201 1.3792859

It can be useful to plot the forecasts on the same graph as the original time series. This a relatively complex task, and would probably be worth packaging up as an R function. Here is how 20 forecasts for the unemp series and their standard errors can be plotted

$=$

The result of this appears in figure 5.10.

Notice that the standard errors around forecasts widen rapidly and the forecasts themselves seem to be tending to a constant value. If we extend the forecast period, this becomes more obvious as shown in figure 5.11. In fact, over the long term, forecasts for stationary series ultimately converge to the mean of the series and the standard errors for the forecasts tend to the standard deviation of the series. This means that we can only expect to gain advantage from the use of short-term forecasts.

# 5.5 Seasonal Models

# 5.5.1 Purely Seasonal Models

Many time series exhibit strong seasonal characteristics. We’ll use $s$ to denote the seasonal period. For monthly series, $s = 1 2$ , and for quarterly series $s = 4$ . These are the most common cases, but seasonal patterns can show up in other places (e.g. weekly patterns in daily observations or daily patterns in hourly data).

![](images/b016acc62596dd7c966b0a26151745e7e6773332b4eda88bb770f084520d58c6.jpg)  
Figure 5.10: Forecasts for the unemployment data.

![](images/9c85e941602e97b4f56286e15720dff5116a0a4dedff1bb8678c0df8fd71ce7b.jpg)  
Figure 5.11: Long-term forecasts for the US unemployment series.

Seasonal effects can be modelled by including coefficients at lags which are multiples of the seasonal period. For example, the model

$$
Y _ {t} + \Phi_ {1} Y _ {t - s} + \Phi_ {2} Y _ {t - 2 s} + \dots + \Phi_ {P} Y _ {t - P s} = \varepsilon_ {t} + \Theta_ {1} \varepsilon_ {t - s} + \Theta_ {2} \varepsilon_ {t - 2 s} + \dots + \Theta_ {q} \varepsilon_ {t - Q s}
$$

is the seasonal analog of an ARMA model. Caution is required with models which only involve coefficients at multiples of the seasonal period because they provide independent models for each of $s$ seasonal sub-series and make no statement about the relationship between the series. For example, the model above applies equally well to the case where the seasonal sub-series are identical

$$
Y _ {k s + 1} = Y _ {k s + 2} = \dots = Y _ {k s + s}
$$

as it does to the case where they are independent.

# 5.5.2 Models with Short-Term and Seasonal Components

In practise, series will have a mixture of both seasonal and short-term dependencies. It is possible to consider models for such series by including both seasonal and non-seasonal terms. This can be done directly, but it turns out to be more useful to consider a slightly different class of model.

Recall that the general ARMA(p,q) model can be written as

$$
\phi (L) Y _ {t} = \boldsymbol {\theta} (L) \varepsilon_ {t}.
$$

Each of the $\pmb \theta ( L )$ and $\phi$ operators can be written as polynomials in $L$ . These have the factorised form

$$
(1 + a _ {1} L) (1 + a _ {2} L) \dots (1 + a _ {p} L) Y _ {t} = (1 + b _ {1} L) (1 + b _ {2} L) \dots (1 + b _ {p} L) \varepsilon_ {t}.
$$

Non-stationarity can also be handled by introducing additional factors of the form $( 1 - L )$ . This suggests a different way of handling seasonal effects. We can simply introduce additional factors of the form $\left( 1 + A L ^ { 1 2 } \right)$ into the autoregressive operator or $( 1 + B L ^ { 1 2 } )$ into the moving average operator.

The operator on each side of the general model is generally written as a product of a polynomial in $L$ times a polynomial in $L ^ { s }$ . The general ARMA model is

$$
\Phi (L ^ {s}) \phi (L) Y _ {t} = \Theta (L ^ {s}) \theta (L) \varepsilon_ {t},
$$

where $\Phi$ is a polynomial of degree $P$ , $\phi$ is a polynomial of degree $p$ , $\Theta$ is a polynomial of order $Q$ and $\pmb { \theta }$ is a polynomial of degree $q$ . Such a model is denoted as $\mathrm { A R M A } ( p , q ) \times ( P , Q ) _ { s }$ .

Non-stationarity can be accommodated by introducing additional differencing terms. This produces a seasonal ARIMA model, the most general form of which is

$$
\boldsymbol {\Phi} (L ^ {s}) \phi (L) (1 - L) ^ {d} (1 - L ^ {s}) ^ {D} Y _ {t} = \boldsymbol {\Theta} (L ^ {s}) \boldsymbol {\theta} (L) \varepsilon_ {t},
$$

which is denoted by $\mathrm { A R M A } ( p , d , q ) \times ( P , D , Q ) _ { s }$ .

As an example, we’ll consider the monthly average temperatures in Dubuque, Iowa, from January 1964 to December 1975. Figure 5.12 shows a plot of the series. It contains a very strong seasonal pattern. The strength of the pattern suggests that we should start by differencing the series at the seasonal lag.

![](images/cd2b47c8c6c0291b61534f91f3a54945d25e8fec4569872fb7a22ceef6a35d42.jpg)  
Figure 5.12: Monthly average temperatures $\circ$ C in Dubuque, Iowa.

![](images/00f0229ceaefa2e27ca077facbb9c364918e5d7e7cc0b77bb494a345542fc20d.jpg)  
Figure 5.13: The seasonally differenced Dubuque temperature series.

![](images/b0ce497216555b183bef202182c16351d994da88b15839a6705e6df2beb6a7a7.jpg)  
Figure 5.14: The acf of the seasonally differenced Dubuque temperature series.

Figure 5.13 shows a plot of the seasonally differenced series and 5.14 shows its acf function. Together the plots indicate the differenced series is stationary. To decide on an appropriate model we also need to inspect a plot of the pacf of the seasonally differenced series. This is shown in figure 5.15. When taken in conjunction with the structure of the acf, we have clear evidence that a seasonal MA(1) is an appropriate model for the differenced series.

The R function arima can be used to fit the full model, which is ARIMA $( 0 , 0 , 0 ) \times ( 0 , 1 , 1 ) _ { 1 2 }$ . Assuming that the series has been read into the variable tempdub, the fitting process and display of the results can be carried out as follows.

> $z =$ arima(tempdub, seas $= c(0,1,1)$ $>\mathbf{z}$ Call:   
arima $\mathrm{x} =$ tempdub, seasonal $= c(0,1,1)$ Coefficients: sma1 -1.0000   
s.e. 0.0967   
sigma^2 estimated as 11.69: log likelihood $= -364.48$ aic $= 732.96$

![](images/e908adcaa39a34cfececa2b91fd8ae1314260a6316cc106d3fca4b4555207d40.jpg)  
Figure 5.15: The pacf of the seasonally differenced Dubuque temperature series.

Before producing forecasts of the series we need to check the residuals from the fitting process to see that they are (close to) white noise. As before, this can be done with the tsdiag function.

> tsdiag(z)

As shown by figure 5.16, the model seems to fit well.

# 5.5.3 A More Complex Example

Figure 5.17 shows a plot of a data set presented by Box and Jenkins in their classic time series text. The plot shows the number of international airline passengers, recorded monthly. There is clearly a strong seasonal trend present in the data — the number of passengers peaks during the Northern summer.

There is a clear seasonal effect present in the series, but the size of the seasonal effects seems to be increasing as the level of the series increases. The number of passengers is clearly increasing with time, with the number travelling in July and August always being roughly $5 0 \%$ greater than the number travelling in January and February. This kind of proportional variability suggests that it would be more appropriate to examine the series on a log scale. Figure 5.18 shows the data plotted in this way. On that scale the series shows a consistent level of seasonal variation across time. It seems appropriate to analyse this time series on the log scale.

The transformed series is clearly nonstationary. This means that we need to consider differencing. The series appears to contain both an upward trend and a

![](images/8b247d781a45383a2c0d86a41243b9dea2c67239136fe9e3622b5cd70b5e7ba4.jpg)  
Standardized Residuals   
ACF of Residuals

![](images/5a29437b663c5727c3bf3083a1b044f2325081b75d69e9eab7d8f42d4675136f.jpg)

![](images/3cf091a5aef984ba28e95d6dac0a63512e2b2efdf31d22817603be8d79df3bca.jpg)  
p values for Ljung−Box statistic   
Figure 5.16: Residual diagnostics for the Dubuque temperature series.

![](images/479a3c32e2aca0f3dd80f13eb8ed2b17aa7d78c99f3a43b6412af49fa0383eec.jpg)  
Figure 5.17: International airline passengers, monthly totals (in thousands).

![](images/10f87d2512da4128cb5f6995403e60dccc51e45c8fff02f154880872652045f4.jpg)  
Figure 5.18: The log international airline passenger series.

![](images/d1bff1061fbe9af6685cd09df01d7dacc7c6a58cacd4b02bb1c34823706ca1c4.jpg)  
Figure 5.19: The seasonally differenced log international airline passenger series.

seasonal pattern. This means that we need to choose between differencing at lag 1 and at lag 12. If we choose to difference at lag 12 it may be possible to eliminate both trends, so it seems preferable to start with this kind of differencing. The results of the differencing are shown in figure 5.19.

There is a possibility that the differenced series is non-stationary. We need to check this by computing and plotting its acf. This is shown in figure 5.20.

The acf does not appear to be dying out, which suggests that an additional amount of differencing is required. Again, there is a choice between differencing at lag 1 or at lag 12. Because there is no strong seasonal pattern we will try differencing at lag 1. The resulting series and its acf are shown in figures 5.21 and 5.22.

The series now seems to be stationary and so we need to decide on an appropriate model to fit. To do this we need to examine the pacf of the twice differenced series. A plot of this pacf is shown in figure 5.23.

The message conveyed by the acf and pacf functions is not as clear as it has been in previous examples. At least one of the plots must show a mix of decay and oscillation. The “better” candidate for this is the pacf and we will proceed by assuming that this is indeed the case.

There are two large correlations in the acf; at lags of 1 and 12 months. This suggests that an appropriate model for the log passengers series would be ARIMA $( 0 , 1 , 1 ) \times ( 0 , 1 , 1 )$ . This model can be fitted as follows:

$$
\begin{array}{l} > z = \operatorname {a r i m a} (\log 1 0 (\text {a i r p a s s}), \text {o r d e r} = c (0, 1, 1), \text {s e a s} = c (0, 1, 1)) \\ > z \end{array}
$$

![](images/7486f38d8e15c27f5d393cd7b842e290e9d38f855fae7137ccf5e557367ba1ef.jpg)  
Figure 5.20: The acf of the seasonally differenced log international airline passengers series.

![](images/f281ea96d23d0a3400bf8e40ce402ba5e02d1bc032082cd755f72abb2be286b2.jpg)  
Figure 5.21: The twice differenced log international airline passenger series.

![](images/66d0be0169c942eb76a3165f0e9d42f7ff002e410f0fe862ab4963f04ff88939.jpg)  
Figure 5.22: The acf of the twice differenced log international airline passengers series.

![](images/2253dec9aa4115993daaf3eed913be9f551c9aab30ebaebc8b450aa124c625a7.jpg)  
Figure 5.23: The pacf of the twice differenced log international airline passengers series.

```txt
Call:  
arima(x = log10(airpass), order = c(0, 1, 1), seasonal = c(0, 1, 1)) 
```

Coefficients:

ma1 sma1

-0.4018 -0.5569

s.e. 0.0896 0.0731

```txt
sigma^2 estimated as 0.0002543: log likelihood = 353.96, aic = -701.92 
```

Both coefficients are highly significant, so we can move onto examining the residuals with the tsdiag function. The results are shown in figure 5.24 and indicate that the model fits well.

Finally, we can obtain and plot forecasts for the series. These are shown in figure 5.25.

![](images/d5a7fea7adcde273f8a6653b2b25ccfce0a9fa3b3df21eaa9061ff47bacce68f.jpg)  
Standardized Residuals   
ACF of Residuals

![](images/bca1c7f91bba421702ad4a1c734a3690df901b2e1735020c72b6ff631be51d35.jpg)

![](images/78e65dda5c42461e9b7332ccae9b285cb0918a1aa8b96e6a0a29b4923ae5dc3b.jpg)  
p values for Ljung−Box statistic   
Figure 5.24: Residual diagnostics for the log air passenger series.

![](images/41e716459d1b4eb6aa6e08fa3703b16b8bae370f63b793b57aed61ef1a0ceaf5.jpg)  
Figure 5.25: Forecasts for the log air passenger series.

# Chapter 6

# Frequency Domain Analysis

# 6.1 Some Background

# 6.1.1 Complex Exponentials, Sines and Cosines

The following formula defines the relationship between the complex exponential function and the real sine and cosine functions.

$$
e ^ {i \theta} = \cos \theta + i \sin \theta
$$

From this it is possible to derive many trigonometric identities. For example, we know that

$$
e ^ {i (\theta + \phi)} = \cos (\theta + \phi) + i \sin (\theta + \phi)
$$

and also that

$$
\begin{array}{l} e ^ {i (\theta + \phi)} = e ^ {i \theta} e ^ {i \phi} \\ = (\cos \theta + i \sin \theta) (\cos \phi + i \sin \phi) \\ = \cos \theta \cos \phi - \sin \theta \sin \phi + i (\cos \theta \sin \phi + \sin \theta \cos \phi). \\ \end{array}
$$

Equating real and imaginary parts

$$
\cos (\theta + \phi) = \cos \theta \cos \phi - \sin \theta \sin \phi
$$

$$
\sin (\theta + \phi) = \cos \theta \sin \phi + \sin \theta \cos \phi .
$$

It is also possible to “invert” the basic formula to obtain the following representations for the sine and cosine functions.

$$
\cos \theta = \frac {e ^ {i \theta} + e ^ {- i \theta}}{2}
$$

$$
\sin \theta = \frac {e ^ {i \theta} - e ^ {- i \theta}}{2 i}.
$$

For many people it is a natural instinct to try to rewrite $e ^ { i \theta }$ in the $\cos \theta + i \sin \theta$ form. This is often a mistake because the exponential function is usually easier to handle.

Example 6.1.1 (From Homework)

$$
\sum_ {t = - T} ^ {T} e ^ {i \lambda t} = \frac {\sin \lambda (T + 1 / 2)}{\sin \lambda / 2}
$$

While it is possible to show this by converting immediately to cosines and sines, it is much simpler to recognise that this is just a geometric series and use the formula for summing a geometric series.

$$
\begin{array}{l} \sum_ {t = - T} ^ {T} e ^ {i \lambda t} = e ^ {- i \lambda T} \sum_ {t = 0} ^ {2 T} e ^ {i \lambda t} \\ = e ^ {- i \lambda T} \left(\frac {e ^ {i \lambda (2 T + 1)} - 1}{e ^ {i \lambda} - 1}\right) \\ = \frac {e ^ {i \lambda (T + 1)} - e ^ {- i \lambda T}}{e ^ {i \lambda} - 1} \\ = \frac {e ^ {i \lambda (T + 1)} - e ^ {- i \lambda T}}{e ^ {i \lambda} - 1} \times \frac {e ^ {- i \lambda / 2}}{e ^ {- i \lambda / 2}} \\ = \frac {e ^ {i \lambda (T + 1 / 2)} - e ^ {- i \lambda (T + 1 / 2)}}{e ^ {i \lambda / 2} - e ^ {- i \lambda / 2}} \\ = \frac {\sin \lambda (T + 1 / 2)}{\sin \lambda / 2} \\ \end{array}
$$

# 6.1.2 Properties of Cosinusoids

The general cosinusiod function is defined to be

$$
f (t) = a \cos (\lambda t + \phi)
$$

where $a$ is the amplitude, $\lambda$ is the angular frequency and $\phi$ is the phase of the cosinusoid.

When $t$ takes integer values, it makes sense to restrict $\lambda$ to the range $[ 0 , 2 \pi ]$ , because

$$
\begin{array}{l} a \cos ((\lambda + 2 k \pi) t + \phi) = a \cos (\lambda t + \phi + 2 k \pi t) \\ = a \cos (\lambda t + \phi) \\ \end{array}
$$

(cos is periodic with period $2 \pi$ and $2 k \pi t$ is a multiple of $2 \pi$ .) This lack of identifiability is known as the aliasing problem. It is illustrated in figure 6.1.

Note that

$$
a \sin (\lambda t + \phi) = a \cos (\lambda t + (\phi + \pi))
$$

so that sines are also cosinusoids. It is also common to refer the function

$$
a e ^ {i (\lambda t + \phi)}
$$

as a complex cosinusoid.

![](images/40d4c75f0f9511654886e958fcfdd69e7e977bbd9f9034b4e6ce3a63e2f5e17b.jpg)  
Figure 6.1: The aliasing problem for cosines

# 6.1.3 Frequency and Angular Frequency

A cosinusoid with frequency $\pi$

$$
a \cos (\pi t + \phi)
$$

repeats itself every two time units. Such a function is usually said to have a frequency of 0.5 because it goes through 0.5 cycles in a unit time period.

In general

$$
\text {F r e q u e n c y} = \frac {\text {A n g u l a r F r e q u e n c y}}{2 \pi}.
$$

Frequency is more “meaningful” but leads to lots of $2 \pi \mathrm { s }$ in formulae. Because of this, it is usual to carry out theoretical studies of time series with angular frequency, but to perform data analysis in terms of frequency.

Theory

Practise

$$
a \cos (\lambda t + \phi)
$$

$$
a \cos (2 \pi \lambda t + \phi)
$$

The “curse” of time series analysis is that $2 \pi \neq 1$ .

# 6.1.4 Invariance and Complex Exponentials

We will be considering “experimental” situations which are in some sense “timeinvariant.” This means that we can expect to obtain the same types of results today as we might tomorrow. One definition of invariance for a function $f$ is that it satisfy

$$
f (t + u) = f (t) \qquad t, u = 0, \pm 1, \pm 2, \dots
$$

The only functions which satisfy this condition are constant.

A less restrictive condition would require

$$
f (t + u) = C _ {u} f (t) \quad t, u = 0, \pm 1, \pm 2, \dots , \text {a n d} C _ {1} \neq 0 \tag {6.1}
$$

For positive $t$ this means

$$
f (t) = C _ {1} f (t - 1) = C _ {1} ^ {2} f (t - 2) = \dots = C _ {1} ^ {t} f (0) \quad t \geq 0,
$$

while for negative $t$

$$
f (t) = C _ {1} f (t + 1) = C _ {1} ^ {2} f (t + 2) = \dots = C _ {1} ^ {t} f (0) \quad t \leqslant 0.
$$

This means that for any $t \in \mathbb { Z }$ we can write

$$
f (t) = C _ {1} ^ {t} f (0).
$$

If we write $C _ { 1 } = e ^ { \alpha }$ (for $\alpha$ real or complex) and $A = f ( 0 )$ , then the general solution of equation 6.1 is

$$
f (t) = A e ^ {\alpha t}.
$$

The bounded solutions correspond to $\alpha = i \lambda$ for $\lambda$ real. In other words, the general bounded solution to 6.1 is

$$
f (t) = A e ^ {i \lambda t}.
$$

This type of invariance also extends by linearity to functions of the form

$$
f (t) = \sum_ {j} c _ {j} e ^ {i \lambda_ {j} t}
$$

because

$$
\begin{array}{l} f (t + u) = \sum_ {j} c _ {j} e ^ {i \lambda_ {j} (t + u)} \\ = \sum_ {j} c _ {j} e ^ {i \lambda_ {j} t} e ^ {i \lambda_ {j} u} \\ = \sum_ {j} c _ {j} ^ {\prime} e ^ {i \lambda_ {j} t} \\ \end{array}
$$

The study of functions which can be written as a sum of complex exponentials is called harmonic analysis or Fourier analysis.

# 6.2 Filters and Filtering

# 6.2.1 Filters

A filter is an operation which takes one time series as input and produces another as output. We indicate that $Y ( t )$ is a filtered version of $X ( t )$ as follows.

$$
Y (t) = \mathcal {A} [ X ] (t).
$$

A filter is called linear if it satisfies

$$
\mathcal {A} [ \alpha X + \beta Y ] (t) = \alpha \mathcal {A} [ X ] (t) + \beta \mathcal {A} [ Y ] (t)
$$

for all constants $\alpha$ and $\beta$ , and time-invariant if it satisfies

$$
\mathcal {A} \left[ L ^ {u} X \right] (t) = L ^ {u} \mathcal {A} [ X ] (t)
$$

for all integer values of $u$

An important class of linear, time-invariant filters can be written in the form

$$
\mathcal {A} [ X ] (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u).
$$

Here the $a ( u )$ are called the filter coefficients.

# Example 6.2.1 Moving Average Filters

Moving average filters of the form

$$
\mathcal {A} [ X ] (t) = \frac {1}{2 M + 1} \sum_ {u = - M} ^ {M} X (t - u)
$$

are used for smoothing time series.

# Example 6.2.2 The Differencing Filter

The differencing filter defined by

$$
\mathcal {A} [ X ] (t) = X (t) - X (t - 1)
$$

is used to eliminate long-term trends from time series.

# 6.2.2 Transfer Functions

While the filter coefficients provide a complete description of what a filter does, they may not provide much intuition about what kind of effect a filter will produce. An alternative way of investigating what a filter does, is to examine its effect on complex exponentials (or equivalently on sine and cosine functions). For notational convenience we will define the function $E ^ { \lambda } ( t )$ by

$$
E ^ {\lambda} (t) = e ^ {i \lambda t}.
$$

Clearly,

$$
\begin{array}{l} L ^ {u} E ^ {\lambda} (t) = e ^ {i \lambda (t + u)} \\ = e ^ {i \lambda u} E ^ {\lambda} (t). \\ \end{array}
$$

Time invariance and linearity then allow us to show

$$
\begin{array}{l} \mathcal {A} [ E ^ {\lambda} ] (t + u) = L ^ {u} \mathcal {A} [ E ^ {\lambda} ] (t) \\ = \mathcal {A} \left[ L ^ {u} E ^ {\lambda} \right] (t) \\ = \mathcal {A} [ e ^ {i \lambda u} E ^ {\lambda} ] \\ = e ^ {i \lambda u} \mathcal {A} [ E ^ {\lambda} ] (t). \\ \end{array}
$$

Setting $t = 0$ produces

$$
\mathcal {A} [ E ^ {\lambda} ] (u) = e ^ {i \lambda u} \mathcal {A} [ E ^ {\lambda} ] (0).
$$

The function $A ( \lambda ) = \mathcal { A } [ E ^ { \lambda } ] ( 0 )$ is known as the transfer function of the filter. The argument above has shown that

$$
\mathcal {A} [ E ^ {\lambda} ] (u) = A (\lambda) E ^ {\lambda} (u).
$$

In other words, linear time-invariant filtering of a complex exponential function produces a constant multiple of a complex exponential function with the same frequency.

Note that for any integer value of $k$ ,

$$
E ^ {\lambda + 2 \pi k} (t) = E ^ {\lambda} (t)
$$

for all $t \in \mathbb { Z }$ . This means that transfer functions are periodic with period $2 \pi$

In general, transfer functions are complex-valued. It can often be useful to rewrite them in their polar form

$$
A (\lambda) = G (\lambda) e ^ {i \phi (\lambda)}.
$$

$G ( \lambda )$ is the gain function of the filter and $\phi ( \lambda )$ is the phase function.

If the filter’s coefficients are real-valued then it is easy to show that the transfer function satisfies

$$
A (- \lambda) = \overline {{A (\lambda)}}.
$$

This in turn means that the gain must satisfy

$$
G (- \lambda) = G (\lambda)
$$

and the phase must satisfy

$$
\phi (- \lambda) = - \phi (\lambda).
$$

# 6.2.3 Filtering Sines and Cosines

The transfer function describes the effect of a filter on complex exponential functions. Using linearity and the representations of sin and cos in terms of complex exponentials it is easy to show that filtering

$$
R \cos (\lambda t + \theta)
$$

produces the result

$$
G (\lambda) R \cos (\lambda t + \theta + \phi (\lambda)).
$$

The gain and phase functions (or equivalently the transfer function) of a filter describe the action of the filter on cosinusoids in exactly the same way as they do for complex exponentials.

# 6.2.4 Filtering General Series

We have seen that a filter’s transfer function can be used to describe the effect of the filter on a single complex cosinusoid. It can also be used to describe the effect of the filter on more general series.

If a series can be represented in the form

$$
X (t) = \sum_ {j} c _ {j} e ^ {i \lambda_ {j} t},
$$

linearity and time invariance mean

$$
\mathcal {A} [ X ] (t) = \sum_ {j} A (\lambda_ {j}) c _ {j} e ^ {i \lambda_ {j} t}.
$$

If $A ( \lambda _ { j } )$ is small, the component at that frequency will be damped down. If $A ( \lambda _ { j } )$ is large, the component will be preserved or amplified.

# 6.2.5 Computing Transfer Functions

Because transfer functions are a good way of describing the effect of filters, it is useful to have a simple way of computing them. Suppose that the filter coefficients satisfy

$$
\sum_ {u = - \infty} ^ {\infty} | a (u) | <   \infty
$$

then the transfer function is given by

$$
A (\lambda) = \sum_ {u = - \infty} ^ {\infty} a (u) e ^ {- i \lambda u}.
$$

We can see this as follows:

$$
\begin{array}{l} \mathcal {A} [ E ^ {\lambda} ] (t) = \sum_ {u = - \infty} ^ {\infty} a (u) E ^ {\lambda} (t - u) \\ = \sum_ {u = - \infty} ^ {\infty} a (u) e ^ {i \lambda (t - u)} \\ = \sum_ {u = - \infty} ^ {\infty} a (u) e ^ {- i \lambda u} e ^ {i \lambda t} \\ = A (\lambda) E ^ {\lambda} (t). \\ \end{array}
$$

In mathematical terms, $A ( \lambda )$ is the discrete Fourier transform of the filter coefficients. The summability condition ensures the existence of the transform.

# 6.2.6 Sequential Filtering

Filters are often applied sequentially when processing time series data and it is often important to understand the combined effect of a sequence of filters. Suppose that $\boldsymbol { A }$ and $\boldsymbol { \beta }$ are filters defined by

$$
\mathcal {A} [ X ] (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u),
$$

$$
\mathcal {B} [ X ] (t) = \sum_ {u = - \infty} ^ {\infty} b (u) X (t - u).
$$

A little algebra shows that the combined effect of $\boldsymbol { B }$ followed by $\boldsymbol { A }$ is

$$
\mathcal {C} [ X ] (t) = \sum_ {u = - \infty} ^ {\infty} c (u) X (t - u),
$$

where

$$
c (u) = \sum_ {v = - \infty} ^ {\infty} a (v) b (u - v).
$$

The sequence $\{ c ( u ) \}$ is said to be formed by the convolution of the sequences $\{ a ( u ) \}$ and $\{ b ( u ) \}$ .

Convolutions are comparatively complex and it is difficult to determine what the effect of combining filters might be by just inspecting the coefficient sequence of the convolution. Transfer functions make the task much easier.

$$
\begin{array}{l} C (\lambda) = \sum_ {u = - \infty} ^ {\infty} c (u) e ^ {- i \lambda u} \\ = \sum_ {u = - \infty} ^ {\infty} \sum_ {v = - \infty} ^ {\infty} a (v) b (u - v) e ^ {- i \lambda u} \\ = \sum_ {u = - \infty} ^ {\infty} \sum_ {v = - \infty} ^ {\infty} a (v) e ^ {- i \lambda v} b (u - v) e ^ {- i \lambda (u - v)} \\ = \sum_ {u ^ {\prime} = - \infty} ^ {\infty} \sum_ {v = - \infty} ^ {\infty} a (v) e ^ {- i \lambda v} b \left(u ^ {\prime}\right) e ^ {- i \lambda u ^ {\prime}} \\ = \left(\sum_ {v = - \infty} ^ {\infty} a (v) e ^ {- i \lambda v}\right) \left(\sum_ {u ^ {\prime} = - \infty} ^ {\infty} b \left(u ^ {\prime}\right) e ^ {- i \lambda u ^ {\prime}}\right) \\ = A (\lambda) B (\lambda) \\ \end{array}
$$

So, when filters are applied sequentially, their transfer functions multiply. This simple description of what happens when filters are applied sequentially is another reason that transfer functions are important.

# 6.3 Spectral Theory

# 6.3.1 The Power Spectrum

Suppose that $X ( t )$ is a stationary time series with autocovariance function $\gamma ( u )$ . If $\gamma ( u )$ satisfies

$$
\sum_ {u = - \infty} ^ {\infty} | \gamma (u) | <   \infty
$$

then we define the power spectrum of $X ( t )$ to be

$$
f _ {X X} (\lambda) = \frac {1}{2 \pi} \sum_ {u = - \infty} ^ {\infty} \gamma (u) e ^ {- i \lambda u} \tag {6.2}
$$

Because $\gamma ( u ) = \gamma ( - u )$ , $f _ { X X } ( \lambda )$ must be real valued. It is also possible to show that $f _ { X X } ( \lambda ) \geq 0$ .

Equation 6.2 can be inverted as follows:

$$
\begin{array}{l} \int_ {0} ^ {2 \pi} e ^ {i \lambda t} f _ {X X} (\lambda) d \lambda = \int_ {0} ^ {2 \pi} e ^ {i \lambda t} \frac {1}{2 \pi} \sum_ {u = - \infty} ^ {\infty} \gamma (u) e ^ {- i \lambda u} \\ = \sum_ {u = - \infty} ^ {\infty} \gamma (u) \frac {1}{2 \pi} \int_ {0} ^ {2 \pi} e ^ {i \lambda (t - u)} d \lambda . \\ \end{array}
$$

Now

$$
\frac {1}{2 \pi} \int_ {0} ^ {2 \pi} e ^ {i \lambda (t - u)} d \lambda = \left\{ \begin{array}{l l} 1 & \text {i f} u = t, \\ 0 & \text {o t h e r w i s e}, \end{array} \right.
$$

which means that

$$
\gamma (u) = \int_ {0} ^ {2 \pi} e ^ {i \lambda u} f _ {X X} (\lambda) d \lambda .
$$

This equation is called the spectral decomposition of the autocovariance function.

Note that since $\gamma ( 0 ) = \operatorname { v a r } [ X ( t ) ]$ , the spectral decomposition says that

$$
\operatorname {v a r} [ X (t) ] = \int_ {0} ^ {2 \pi} f _ {X X} (\lambda) d \lambda
$$

This equation shows the variability in $X ( t )$ being broken down by frequency. To understand the significance of this, we need to see that the time series can be decomposed into independent frequency components.

# 6.3.2 The Cram´er Representation

To define the Cram´er representation we have to introduce the idea of Stieltjes Integration. The Stieljes integral of $g ( x )$ with respect to $F ( x )$ over the interval $[ a , b ]$ , can be thought of as the limit of approximating sums of the form

$$
\sum_ {n = 0} ^ {N} g (x _ {i}) [ F (x _ {i + 1}) - F (x _ {i}) ],
$$

where $a = x _ { 0 } < x _ { 1 } < \cdot \cdot \cdot < x _ { N } = b$ . The notation

$$
\int_ {a} ^ {b} \phi (x) d F (x)
$$

is used to indicate the limiting value.

When $F ( x )$ is differentiable with $f ( x ) = F ^ { \prime } ( x )$ , the definition of derivative means

$$
F (x _ {i + 1}) - F (x _ {i}) \approx f (x _ {i}) (x _ {i + 1} - x _ {i})
$$

so that the approximating sums have the form

$$
\sum_ {n = 0} ^ {N} g (x _ {i}) f (x _ {i}) (x _ {i + 1} - x _ {i}).
$$

In this case

$$
\int_ {a} ^ {b} \phi (x) d F (x) = \int_ {a} ^ {b} \phi (x) f (x) d x.
$$

On the other hand, if $F ( x )$ is a step function with a step of height $c _ { i }$ at the value $u _ { i }$ , the Stieltjes integral reduces to the sum

$$
\sum_ {i} c _ {i} \phi (u _ {i}).
$$

The Stieltjes integral has the benefit of unifying both summation and integration.

To state the Cram´er representation we need to extend the Stieltjes integral to handle integration against stochastic processes.

Definition 6.3.1 A stochastic process $Z ( \lambda )$ on the interval $[ 0 , 2 \pi ]$ is an indexed set of random variables, which assigns a random variable $Z ( \lambda )$ to each $\lambda \in$ $[ 0 , 2 \pi ]$ . The process is said to have uncorrelated (resp. independent) increments if for $\lambda _ { 1 } < \lambda _ { 2 } < \lambda _ { 3 } < \lambda _ { 4 }$ , the increments $Z ( \lambda _ { 2 } ) - Z ( \lambda _ { 1 } )$ and $Z ( \lambda _ { 4 } ) - Z ( \lambda _ { 3 } )$ are uncorrelated (resp. independent).

It is possible to define an integral against such a process as follows:

$$
\int_ {0} ^ {2 \pi} \phi (\lambda) d Z (\lambda) = \mathrm {l . i . m .} \sum_ {n = 0} ^ {N - 1} \phi \Big (\frac {2 \pi n}{N} \Big) \left[ Z \Big (\frac {2 \pi (n + 1)}{N} \Big) - Z \Big (\frac {2 \pi n}{N} \Big) \right].
$$

The Cram´er representation says that it is possible to represent a stationary time series $X ( t )$ in the form

$$
X (t) = \int_ {0} ^ {2 \pi} e ^ {i \lambda t} d Z _ {X} (\lambda)
$$

for a stochastic process $Z _ { X } ( \lambda )$ with uncorrelated increments.

The process $Z _ { X } ( \lambda )$ is defined as follows. First we define

$$
d _ {X} ^ {T} (\lambda) = \sum_ {u = - T} ^ {T} X (u) e ^ {- i \lambda u}
$$

and then

$$
Z _ {X} ^ {T} (\lambda) = \int_ {0} ^ {\lambda} d _ {X} ^ {T} (\alpha) d \alpha = \sum_ {u = - T} ^ {T} X (u) \left(\frac {1 - e ^ {- i \lambda u}}{- i u}\right).
$$

Finally we let $T \to \infty$ and set

$$
Z _ {X} (\lambda) = \lim  _ {T \to \infty} Z _ {X} (\lambda).
$$

It is possible to show that $Z _ { X } ( \lambda )$ is a well-defined stochastic process on $[ 0 , 2 \pi ]$ which has uncorrelated increments and satisfies symmetry properties such as

$$
\begin{array}{l} Z _ {X} (\lambda + 2 \pi) = Z _ {X} (\lambda) \\ Z _ {X} (- \lambda) = \overline {{Z _ {X} (\lambda)}} \\ \end{array}
$$

Most important of all, it is possible to make statements about the variability of the increments of $Z _ { X } ( \lambda )$ . For what we are interested in, it will be necessary to assume that the series $X ( t )$ satisfies the additional mixing condition

$$
\sum_ {u = - \infty} ^ {\infty} | \gamma (u) | <   \infty .
$$

This says that values of $X ( t )$ which are well separated in time will be close to uncorrelated.

If the series is mixing, the variability of the quantities

$$
d Z _ {X} (\lambda) = Z _ {X} (\lambda + d \lambda) - Z _ {X} (\lambda).
$$

can be written in terms of the power spectrum $f _ { X X } ( \lambda )$ .

$$
\operatorname {v a r} \left(d Z _ {X} (\lambda)\right) = f _ {X X} (\lambda) (d \lambda) ^ {2}
$$

This together with the uncorrelatedness of the increments can be written in the operational form

$$
\operatorname {c o v} \left(d Z _ {X} (\lambda), d Z _ {X} (\mu)\right) = \delta (\lambda - \mu) f _ {X X} (\lambda) d \lambda d \mu , \tag {6.3}
$$

where $\delta ( u )$ is the Dirac delta function, which is defined so that

$$
\int \phi (u) \delta (u - u _ {0}) d u = \phi (u _ {0})
$$

Equation 6.3 is understood to mean

$$
\begin{array}{l} \operatorname {c o v} \left(\int_ {0} ^ {2 \pi} \phi (\lambda) d Z _ {X} (\lambda), \int_ {0} ^ {2 \pi} \psi (\lambda) d Z _ {X} (\lambda)\right) \\ = \int_ {0} ^ {2 \pi} \int_ {0} ^ {2 \pi} \phi (\lambda) \overline {{\psi (\mu)}} \operatorname {c o v} (d Z _ {X} (\lambda), d Z _ {X} (\mu)) \\ = \int_ {0} ^ {2 \pi} \int_ {0} ^ {2 \pi} \phi (\lambda) \overline {{\psi (\mu)}} \delta (\lambda - \mu) f _ {X X} (\lambda) d \lambda d \mu \\ = \int_ {0} ^ {2 \pi} \phi (\lambda) \overline {{\psi (\lambda)}} f _ {X X} (\lambda) d \lambda \\ \end{array}
$$

# 6.3.3 Using The Cram´er Representation

The Cram´er representation says that we can approximate the time series $X ( t )$ to any level of accuracy by an approximation of the form

$$
X (t) \approx \sum_ {n = 0} ^ {N} \exp \left(i \frac {2 \pi n}{N} t\right) Z _ {n}
$$

where the $Z _ { n }$ are uncorrelated random variables. This provides an intuitive way of handling time series theory.

As an example, let’s suppose that the series $X ( t )$ has the Cram´er representation

$$
X (t) = \int_ {0} ^ {2 \pi} e ^ {i \lambda t} d \lambda
$$

and that we filter $X ( t )$ with a filter which has transfer function $A ( \lambda )$ to obtain

$$
Y (t) = \mathcal {A} [ X ] (t).
$$

The Cram´er representation says that we arbitrarily approximate the series $X ( t )$ with the sum

$$
\sum_ {n = 0} ^ {N} \exp \Bigl (i \frac {2 \pi n}{N} t \Bigr) Z _ {n},
$$

where the $Z _ { n }$ are independent random variables. When this approximating series is filtered, the result is (by linearity)

$$
\sum_ {n = 0} ^ {N} A \Big (\frac {2 \pi n}{N} \Big) \exp \Big (i \frac {2 \pi n}{N} t \Big) Z _ {n}.
$$

On taking limits, we obtain

$$
Y (t) = \int_ {0} ^ {2 \pi} e ^ {i \lambda t} A (\lambda) d Z _ {X} (\lambda).
$$

providing a spectral representation of $Y ( t )$ .

We can also use the Cram´er representation to obtain a formula for the power spectrum of the $Y ( t )$ series. The representation above says that

$$
d Z _ {Y} (\lambda) = A (\lambda) d Z _ {X} (\lambda),
$$

and since

$$
\begin{array}{l} \operatorname {v a r} \left(d Z _ {Y} (\lambda)\right) = \operatorname {c o v} \left(d Z _ {Y} (\lambda), d Z _ {Y} (\lambda)\right) \\ = \operatorname {c o v} \left(A (\lambda) d Z _ {X} (\lambda), A (\lambda) d Z _ {X} (\lambda)\right) \\ = A (\lambda) \overline {{A (\lambda)}} \operatorname {c o v} \left(d Z _ {X} (\lambda), d Z _ {X} (\lambda)\right) \\ = | A (\lambda) | ^ {2} \operatorname {v a r} \left(d Z _ {X} (\lambda)\right) \\ \end{array}
$$

we immediately see that the power spectrum for $Y ( t )$ must be

$$
f _ {Y Y} (\lambda) = | A (\lambda) | ^ {2} f _ {X X} (\lambda).
$$

# 6.3.4 Power Spectrum Examples

Because of its relationship with the Cram´er representation, the power spectrum is a fundamental parameter of interest when dealing with stationary time series. It can be useful to see how the power spectrum behaves for some of the stationary series we have encountered.

# Example 6.3.1 (White Noise)

The autocovariance function of a white-noise series $X ( t )$ is given by

$$
\gamma (u) = \left\{ \begin{array}{l l} \sigma^ {2} & u = 0, \\ 0 & \text {o t h e r w i s e .} \end{array} \right.
$$

The power spectrum can be computed directly from this.

$$
\begin{array}{l} f _ {X X} (\lambda) = \frac {1}{2 \pi} \sum_ {u = - \infty} ^ {\infty} e ^ {- i \lambda u} \gamma (u) \\ = \frac {\sigma^ {2}}{2 \pi} \\ \end{array}
$$

This says that a white-noise series is composed of “equal amounts of every frequency.” The name, white noise, comes from an analogy with white light, which contains equal amounts of every colour (wavelength).

# 6.3. Spectral Theory

Example 6.3.2 The MA(1) Series.

The MA(1) series is defined by

$$
Y (t) = \varepsilon (t) + \theta \varepsilon (t - 1)
$$

and has an autocovariance function defined by

$$
\gamma (u) = \left\{ \begin{array}{l l} \sigma^ {2} (1 + \theta^ {2}) & u = 0, \\ \sigma^ {2} \theta & u = \pm 1, \\ 0 & \text {o t h e r w i s e}. \end{array} \right.
$$

The power spectrum is thus

$$
\begin{array}{l} f _ {Y Y} (\lambda) = \frac {\sigma^ {2}}{2 \pi} \left(\theta e ^ {- i \lambda} + (1 + \theta^ {2}) + \theta e ^ {i \lambda}\right) \\ = \frac {\sigma^ {2}}{2 \pi} \left(1 + \theta^ {2} + 2 \theta \cos \lambda\right) \\ \end{array}
$$

Example 6.3.3 The AR(1) Series.

The AR(1) series is defined by

$$
Y (t) = \phi Y (t - 1) + \varepsilon (t)
$$

and has an autocovariance function defined by

$$
\gamma (u) = \sigma^ {2} \phi^ {| u |}
$$

The power spectrum is

$$
\begin{array}{l} f _ {Y Y} (\lambda) = \frac {\sigma^ {2}}{2 \pi} \sum_ {u = - \infty} ^ {\infty} e ^ {- i \lambda u} \phi^ {| u |} \\ = \frac {\sigma^ {2}}{2 \pi} \frac {1}{1 + \theta^ {2} - 2 \phi \cos \lambda}. \\ \end{array}
$$

The last equality can be shown by direct algebraic manipulation. Alternatively, we can use the fact that $Y ( t )$ can be filtered to obtain white noise.

$$
Y (t) - \phi Y (t - 1) = \varepsilon (t)
$$

If $A ( \lambda )$ is the transfer function of the filter with coefficients

$$
a (u) = \left\{ \begin{array}{l l} 1 & u = 0, \\ \phi & u = 1, \\ 0 & \text {o t h e r w i s e}. \end{array} \right.
$$

then

$$
| A (\lambda) | ^ {2} f _ {Y Y} (\lambda) = f _ {\varepsilon \varepsilon} (\lambda) = \frac {\sigma^ {2}}{2 \pi},
$$

or equivalently,

$$
f _ {Y Y} (\lambda) = \frac {\sigma^ {2}}{2 \pi} \frac {1}{| A (\lambda) | ^ {2}}.
$$

The transfer function is easily seen to be

$$
A (\lambda) = 1 - \phi e ^ {- i \lambda}
$$

and hence

$$
\begin{array}{l} \left| A (\lambda) \right| ^ {2} = A (\lambda) \overline {{A (\lambda)}} \\ = (1 - \phi e ^ {- i \lambda}) (1 - \phi e ^ {i \lambda}) \\ = 1 + \phi^ {2} - 2 \phi \cos \lambda \\ \end{array}
$$

from which the result follows.

# 6.4 Statistical Inference

# 6.4.1 Some Distribution Theory

In the frequency domain, inference is based on the discrete Fourier transform

$$
\mathrm {d} _ {X} ^ {T} (\lambda) = \sum_ {t = 0} ^ {T - 1} X (t) e ^ {- i \lambda t}
$$

of a set of $T$ data values $X ( 0 ) , \ldots , X ( T - 1 )$ . The discrete Fourier transform has the following analytic properties:

$$
\begin{array}{l} \mathrm {d} _ {X} ^ {T} (0) = \sum_ {t = 0} ^ {T - 1} X (t) \\ \mathrm {d} _ {X} ^ {T} (\lambda + 2 \pi) = \mathrm {d} _ {X} ^ {T} (\lambda) \\ \mathrm {d} _ {X} ^ {T} (- \lambda) = \overline {{\mathrm {d} _ {X} ^ {T} (\lambda)}} \\ \mathrm {d} _ {X} ^ {T} (2 \pi - \lambda) = \overline {{\mathrm {d} _ {X} ^ {T} (- \lambda)}} \\ \end{array}
$$

This means that all the information contained in the discrete Fourier transform can be displayed by plotting $\mathrm { d } _ { X } ^ { \mathrm { { \it I } } ^ { \prime } } ( \lambda )$ over the interval $[ 0 , \pi ]$ .

Most importantly, although the discrete Fourier transform is a complex transformation of the values $X ( 0 ) , \ldots , X ( T - 1 )$ , it can be computed rapidly using a fast Fourier transform (FFT) algorithm. The FFT computes the values of $\mathrm { d } _ { X } ^ { T } ( \lambda )$ for the discrete set of frequencies

$$
\lambda_ {t} = \frac {2 \pi t}{T}, \qquad t = 0, \ldots , T - 1.
$$

Many statistical software packages contain an implementation of the FFT.

Theorem 6.4.1 (The Distribution of the Fourier Transform). If $X ( t )$ is a stationary, mean-zero time series which satisfies the mixing condition

$$
\sum_ {u = - \infty} ^ {\infty} | \gamma (u) | <   \infty
$$

and has power spectrum $f _ { X X } ( \lambda )$ , then

$$
\operatorname {E} \left(\mathrm {d} _ {X} ^ {T} (\lambda)\right) = 0
$$

$$
\operatorname {v a r} \left(\frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}}\right)\rightarrow f _ {X X} (\lambda)
$$

$$
\operatorname {c o v} \left(\frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}}, \frac {\mathrm {d} _ {X} ^ {T} (\mu)}{\sqrt {2 \pi T}}\right) \to 0, \qquad \text {p r o v i d e d},   \lambda \neq \mu .
$$

Finally, under some additional mixing conditions (involving higher order moments), $\mathrm { d } _ { X } ^ { \mathrm { { \it { I } } ^ { \prime } } } ( \lambda )$ is asymptotically (complex) normal.

A complete proof of this result can be found David Brillinger’s book Time Series: Data Analysis and Theory. We will just show how some of the proof works.

First, by linearity, it is trivial to show that

$$
\operatorname {E} \left[ \mathrm {d} _ {X} ^ {T} (\lambda) \right] = 0.
$$

The variance result can be shown as follows

$$
\begin{array}{l} \mathrm {E} \left| \frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}} \right| ^ {2} = \mathrm {E} \left[ \frac {\mathrm {d} _ {X} ^ {T} (\lambda) \overline {{\mathrm {d} _ {X} ^ {T} (\lambda)}}}{2 \pi T} \right] \\ = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \mathrm {E} \left[ X (t) X (s) \right] e ^ {- i \lambda t} e ^ {- i \lambda s} \\ = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \gamma (t - s) e ^ {- i \lambda (t - s)} \\ = \frac {1}{2 \pi T} \sum_ {u = - T + 1} ^ {T - 1} (T - | u |) \gamma (u) e ^ {- i \lambda u} \\ = \frac {1}{2 \pi} \sum_ {u = - T + 1} ^ {T - 1} \left(1 - \frac {| u |}{T}\right) \gamma (u) e ^ {- i \lambda u} \\ \rightarrow f _ {X X} (\lambda) \\ \end{array}
$$

The convergence follows because because $( 1 - | u | / T ) \uparrow 1$ as $T \to \infty$ .

To show the covariance result we need the preliminary technical result that if $\nu \neq 0$ then the value of

$$
\left| \sum_ {s = N _ {1}} ^ {N _ {2}} e ^ {- i \nu s} \right|
$$

is bounded by some constant $B _ { \nu }$ . The result follows because

$$
\sum_ {s = 0} ^ {T} e ^ {- i \nu s} = \frac {1 - e ^ {- i \nu T}}{1 - e ^ {- i \nu}}
$$

which converges to 0 as $T \to \infty$ provided $\nu \neq 0$ .

$$
\begin{array}{l} \operatorname {E} \left[ \frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}}, \frac {\mathrm {d} _ {X} ^ {T} (\mu)}{\sqrt {2 \pi T}} \right] = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \operatorname {E} \left[ X (t) X (s) \right] e ^ {- i \lambda t} e ^ {- i \mu s} \\ = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \gamma (t - s) e ^ {- i \lambda t} e ^ {- i \mu s} \\ = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \gamma (t - s) e ^ {- i (\lambda t - \mu s)} \\ = \frac {1}{2 \pi T} \sum_ {t = 0} ^ {T - 1} \sum_ {s = 0} ^ {T - 1} \gamma (t - s) e ^ {- i \lambda (t - s)} e ^ {- i (\lambda - \mu) s} \\ = \frac{1}{2\pi T}\sum_{u = -T + 1}^{T - 1}\sum_{s = \max (0, - u)}^{\min (T - 1,T - 1 - u)}\gamma (u)e^{-i(\lambda -\mu)s}e^{-i\lambda u} \\ = \frac {1}{2 \pi T} \sum_ {u = - T + 1} ^ {T - 1} \gamma (u) e ^ {- i \lambda u} \sum_ {s = \max  (0, - u)} ^ {\min  (T - 1, T - 1 - u)} e ^ {i (\lambda - \mu) s} \\ \end{array}
$$

This says that

$$
\left| \mathrm {E} \left[ \frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}}, \frac {\mathrm {d} _ {X} ^ {T} (\mu)}{\sqrt {2 \pi T}} \right] \right| \leqslant \frac {B _ {\lambda}}{T} \left| \frac {1}{2 \pi} \sum_ {u = - T + 1} ^ {T - 1} \gamma (u) e ^ {- i \lambda u} \right|
$$

The sum on the right converges to $f _ { X X } ( \lambda )$ , so the whole right hand side must converge to 0.

If the original time series $X ( t )$ is normally distributed, then by linearity, $\mathrm { d } _ { X } ^ { \mathrm { { \it I } } ^ { \prime } } ( \lambda )$ must also be normally distributed. The general result can be found in Brillinger’s book.

# 6.4.2 The Periodogram and its Distribution

Asymptotically, the discrete Fourier transform has a complex normal distribution with mean 0 and variance proportional to the power spectrum.

$$
\mathrm {d} _ {X} ^ {T} (\lambda) \sim \mathrm {A N} ^ {c} (0, 2 \pi T f _ {X X} (\lambda)).
$$

This says that as $T \to \infty$ ,

$$
\left. \operatorname {E} \left[ \frac {1}{2 \pi T} \left| \mathrm {d} _ {X} ^ {T} (\lambda) \right| ^ {2} \right]\rightarrow f _ {X X} (\lambda). \right. \tag {6.4}
$$

The quantity

$$
I _ {X X} ^ {T} (\lambda) = \frac {1}{2 \pi T} \left| \mathrm {d} _ {X} ^ {T} (\lambda) \right| ^ {2}
$$

is called the periodogram. Equation 6.4 says that the periodogram provides an asymptotically unbiased estimator of the power spectrum.

It is relatively easy to derive the asymptotic distribution of the periodogram. We know that as $T \to \infty$ ,

$$
\frac {\mathrm {d} _ {X} ^ {T} (\lambda)}{\sqrt {2 \pi T}} \to \mathrm {N} ^ {c} (0, f _ {X X} (\lambda)).
$$

We can represent this limiting distribution in the form

$$
(U + i V) \sqrt {f _ {X X} (\lambda) / 2}
$$

where $U$ and $V$ are independent (real-valued) normals, each with mean equal to 0 and variance equal to 1. The limiting distribution of the periodogram can then be written as

$$
(U ^ {2} + V ^ {2}) \frac {f _ {X X} (\lambda)}{2}
$$

Because $U$ and $V$ are standard normals, the distribution of $U ^ { 2 } + V ^ { 2 }$ is $\chi _ { 2 } ^ { 2 }$ , or an exponential distribution with mean 2. This means that the asymptotic distribution of $I _ { X X } ^ { T } ( \lambda )$ is exponential with mean $f _ { X X } ( \lambda )$ .

There are two important consequences which follow because of the asymptotic distribution of the periodogram. First, $I _ { X X } ^ { T } ( \lambda )$ is not a consistent estimator of $f _ { X X } ( \lambda )$ . Second, the asymptotic variance of the periodogram is $f _ { X X } ( \lambda ) ^ { 2 }$ . This means that from a data analytic standpoint, it is better to draw graphs of $\log I _ { X X } ^ { \prime } ( \lambda )$ rather than $I _ { X X } ^ { T } ( \lambda )$ itself (log is the variance stabilising transformation for the exponential).

# 6.4.3 An Example – Sunspot Numbers

During the early 1600s Galileo used his invention, the astronomical telescope, to study the heavens. One of the objects he investigated was the sun, and a focus of his study the phenomenon of sunspots. Sunspots are dark areas which appear from time to time on the surface of the sun. They range in size from about 1,500km to 150,000km across. The phenomenon had been known to earlier Greek and Chinese astronomers, but Galileo was the first to systematically study and write about them.

Sunspots are now believed to be areas where the convection currents rising up from the interior of the sun are inhibited by its strong magnetic fields. The temperatures at the centre of a sunspot can be some $2 0 0 0 ^ { \circ } \mathrm { K }$ below the usual 6,000◦K surface temperature of the sun.

It is now known that the number of sunspots observed on the sun varies with an irregular 11 year period. An index of the level of sunspot has been kept for hundreds of years. The index is related to both the number of sunspots and the area they cover. A value of 100 is high and anything above 150 is regarded as unusually high. The sunspot series is displayed in figure 6.2. From a statistical point of view, it is desirable to transform the series to make the variability

independent of the mean. Because the index is based on counts, variance stabilisation can be carried out by taking square roots. The transformed series is also shown in figure 6.2.

Because the sun has a direct effect on the earth’s climate the sunspot cycle has been the subject of intense study by climatologists and astronomers. Because it provides a direct measure of solar activity, the sunspots series has been studied intensively to see if it can be used to predict medium and long-term climate trends.

The periodogram is a useful tool to use when looking for periodicities. Figures 6.3 and 6.4 show the periodogram computed for the square-root of the sunspot index. The vertical lines in the second of these figures correspond to periodicities of 5.5 years, 11 years and 76 years. The first two of these periodicities correspond directly to the 11 year sunspot cycle. The 5.5 yearly period is a harmonic which is produced because the sunspot index increases more rapidly than it declines. The 76 year periodicity corresponds to a basic oscillation in the size of the sun. The observed diameter of the sun varies by about 140km over a 76 year cycle.

# 6.4.4 Estimating The Power Spectrum

The periodogram provides an asymptotically unbiased estimator of the power spectrum, but one which is not consistent. However, it is possible to derive consistent estimators from it.

Assume that the power spectrum $f _ { X X } ( \lambda )$ is near-constant in the region of the frequency $\lambda _ { 0 }$ . This says that values of $I _ { X X } ( \lambda )$ with $\lambda$ close to $\lambda _ { 0 }$ will be approximately i.i.d. with mean $f _ { X X } ( \lambda _ { 0 } )$ . Averaging these values will provide an estimate of $f _ { X X } ( \lambda _ { 0 } )$ which may have a small amount of bias, but which will have a smaller variance. By trading off variability for bias, we can potentially obtain a much better estimator.

We proceed by choosing a sequence of positive bandwidth values $B _ { T }$ , and taking the average of the periodogram values in the interval from $\lambda _ { 0 } - B _ { T } / 2$ to $\lambda _ { 0 } + B _ { T } / 2$ . This produces a sequence of spectral estimates $f _ { X X } ^ { T } ( \lambda _ { 0 } )$ . If $B _ { T }$ is chosen so that $B _ { T } ~ \downarrow ~ 0$ , but at a rate more slowly than $1 / T$ and if the power spectrum is smooth in the vicinity of $\lambda _ { 0 }$ , then the sequence $f _ { X X } ^ { T } ( \lambda _ { 0 } )$ will converge to $f _ { X X } ( \lambda _ { 0 } )$ . Such smoothed periodogram estimators provide a consistent way of estimating the power spectrum. In practise we can either nominate a value for $B _ { T }$ , or specify the number of values to be averaged.

The distribution of smoothed periodogram estimates has a simple asymptotic form. If $k$ periodogram values are averaged to obtain the estimate then the estimate will have an approximate distribution which is $f _ { X X } { ( \lambda _ { 0 } ) } \chi _ { 2 k } ^ { 2 }$ distribution (because it is the sum of independent $f _ { X X } ( \lambda _ { 0 } ) \chi _ { 2 } ^ { 2 }$ variables).

This distribution has a variance which is proportional to its mean and so such estimates are better viewed on a logarithmic scale. Taking logs also has the advantage that there is a single standard error which applies across all frequencies.

To compute an estimate of the spectrum we must first specify the amount of smoothing to be used, either with a bandwidth or a specification of the number of values to be averaged. There is no no firm rule for choosing the amount of smoothing and it is best to try a number of values. In regions where the spectrum

![](images/ab27fbacc70bde6f640179af33b4e472ec2db7d7118e3ce2dfd19daa7085e1c5.jpg)  
6.4. Statistical Inference

![](images/05bc4ebbef47576c8c9b547412ed376e56303385feadaee4d8678c9549f33115.jpg)  
Figure 6 . 2 : The sunspot index series and its square root .

![](images/2b6c0087f6661e4d4441114db26d5cf3bf1cc68f1aafc6434ac8b9ff9ec413b5.jpg)  
Figure 6.3: The log periodogram computed for the square-root of the sunspot index series.

![](images/ec0f07ed9176510de16a3c68842da4b54e79af84e16b3a21c2d3483c116a436a.jpg)  
Figure 6.4: An expanded view of the the log periodogram computed for the square-root of the sunspot index series.

![](images/21ae31e9ff16ca4f8231e0255872c519fe2f3a77a08ae4bdebd9cc8afc03699f.jpg)  
Figure 6.5: The log spectrum computed for the square-root of the sunspot index series.

is flat, it is appropriate to specify a large amount of smoothing. Where there are peaks or troughs a much smaller amount of smoothing should be used.

Figure 6.5 shows an estimate of the power spectrum for the sunspot series computed by averaging 7 periodogram values. A comparison with figure 6.3 shows that the variability of the estimate has been reduced a great deal. On the other hand, figure 6.6 shows that peaks visible in figure 6.4 have been smoothed out, making it harder to identify the corresponding frequencies. The location of the lowest peak is difficult to determine.

# 6.4.5 Tapering and Prewhitening

Power spectrum estimates obtained by averaging periodogram values can be improved in a number of ways. First, the process of sampling introduces discontinuities at the ends of the time series (a sudden drop to zero). The presence of these discontinuities introduces ripples into the periodogram and hence into power spectrum estimates. The effect of the discontinuity can be reduced by tapering the time series. This means at each end of the series the values are reduced toward zero by multiplying by a taper function.

One common choice for the taper function is the raised cosine. If the first $K$ values are tapered, the effect is to multiply $X ( k )$ by

$$
\frac {1 - \cos (k \pi / (K + 1))}{2} \qquad \mathrm {f o r} k = 0, \ldots , K - 1.
$$

The effect of the tapering the last $K$ values is defined similarly.

![](images/f21cee7b331d2b1af580bb1e146d827fb6c219314113d6a37526f80e206f57b8.jpg)  
Figure 6.6: An expanded view of the the log spectrum computed for the square-root of the sunspot index series.

A second improvement which can be made in spectrum estimation is to use pre-whitening. This means removing obvious structure from the time series by filtering it before the spectrum is estimated. After the spectrum is estimated, it is recoloured using the transfer function of the filter, in a process known as recolouring. This process is useful when a very accurate estimate of the spectrum is required for some purpose.

# 6.4.6 Cross Spectral Analysis

Although it can be informative to look at the power spectrum for a single time series, it can be much more useful to use frequency domain methods to examine the relationship between series. The most important problem is that of making inferences about linear, time-invariant relationships of the form

$$
Y (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u).
$$

The information about the linear dependence between the time series $X ( t )$ and $Y ( t )$ is carried by the cross-covariance function

$$
c _ {Y X} (u) = \operatorname {c o v} (Y (t + u), X (t)).
$$

Provided that $X ( t )$ and $Y ( t )$ have summable autocovariance functions we can define the equivalent cross-spectrum in the frequency domain.

$$
f _ {Y X} (\lambda) = \sum_ {u = - \infty} ^ {\infty} c _ {Y X} (u) e ^ {- i \lambda u}
$$

Estimation of the cross-spectrum is based on the cross-periodogram.

$$
I _ {Y X} (\lambda) ^ {T} = \frac {1}{2 \pi T} \mathrm {d} _ {Y} ^ {T} (\lambda) \overline {{\mathrm {d} _ {X} ^ {T} (\lambda)}}
$$

In parallel with the result for power spectra, it is possible to show that

$$
E \Big (I _ {Y X} (\lambda) ^ {T} \Big) \rightarrow f _ {Y X} (\lambda).
$$

Again, in parallel with the power spectrum case, the cross-periodogram is an inconsistent estimator of the cross-spectrum, but consistent estimates can be obtained by smoothing. If $B _ { T }$ is chosen as in the power spectrum case then the estimator $f _ { Y X } ^ { T } ( \lambda _ { 0 } )$ obtained by averaging the cross-periodogram over an interval of width $B _ { T }$ centred on $\lambda _ { 0 }$ provides a consistent estimator of $f _ { Y X } ( \lambda _ { 0 } )$ .

$$
f _ {Y X} ^ {T} (\lambda_ {0}) \to f _ {Y X} (\lambda_ {0}) \quad \mathrm {a s} T \to \infty .
$$

Having defined the necessary parameters, we can now set down a simple regression model which relates two time series, namely

$$
Y (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u) + \varepsilon (t). \tag {6.5}
$$

Here $\varepsilon ( t )$ is a stationary time series which is independent of $X ( t )$ (note that we do not require that $\varepsilon ( t )$ be white noise).

Now we note that

$$
Y (t + u) = \sum_ {v = - \infty} ^ {\infty} a (v) X (t + u - v) + \varepsilon (t + u)
$$

and hence

$$
Y (t + u) X (t) = \sum_ {v = - \infty} ^ {\infty} a (v) X (t + u - v) X (t) + \varepsilon (t + u) X (t).
$$

Taking expectations through this, we see that

$$
c _ {Y X} (u) = \sum_ {v = - \infty} ^ {\infty} a (u) c _ {X X} (v - u).
$$

Transforming into the frequency domain, we find that

$$
\begin{array}{l} f _ {Y X} (\lambda) = \frac {1}{2 \pi} \sum_ {u = - \infty} \sum_ {v = - \infty} a (v) c _ {X X} (v - u) e ^ {- i \lambda u} \\ = \frac {1}{2 \pi} \sum_ {u = - \infty} \sum_ {v = - \infty} a (v) c _ {X X} (v - u) e ^ {- i \lambda v} e ^ {- i \lambda (u - v)} \\ = \frac {1}{2 \pi} \sum_ {u = - \infty} c _ {X X} (u) e ^ {- i \lambda u} \sum_ {v = - \infty} a (v) e ^ {- i \lambda v} \\ = f _ {X X} (\lambda) A (\lambda) \\ \end{array}
$$

This suggests that we can estimate $A ( \lambda )$ by

$$
\widehat {A} (\lambda) = \frac {f _ {Y X} ^ {T} (\lambda)}{f _ {X X} ^ {T} (\lambda)}.
$$

Taking the gain and phase of $\widehat { A } ( \lambda )$ will give us estimates of the gain and phase of $A ( \lambda )$ .

The independence of $X ( t )$ and $\varepsilon ( t )$ in equation 6.5 means that we have the following relationship between power spectra.

$$
f _ {Y Y} (\lambda) = | A (\lambda) | ^ {2} f _ {X X} (\lambda) + f _ {\varepsilon \varepsilon} (\lambda)
$$

where $f _ { \varepsilon \varepsilon } ( \lambda )$ , the power spectrum of $\varepsilon ( t )$ , is known as the residual spectrum. The last equation can be written in the form

$$
\begin{array}{l} f _ {Y Y} (\lambda) = \frac {| f _ {Y X} (\lambda) | ^ {2}}{f _ {X X} (\lambda) ^ {2}} f _ {X X} (\lambda) + f _ {\varepsilon \varepsilon} (\lambda) \\ = \frac {\left| f _ {Y X} (\lambda) \right| ^ {2}}{f _ {X X} (\lambda)} + f _ {\varepsilon \varepsilon} (\lambda) \\ \end{array}
$$

which allows us to set down the following estimate for the residual spectrum.

$$
f _ {\varepsilon \varepsilon} ^ {T} (\lambda) = f _ {Y Y} ^ {T} (\lambda) - \frac {| f _ {Y X} ^ {T} (\lambda) | ^ {2}}{f _ {X X} ^ {T} (\lambda)}
$$

To assess the quality of the fit of the model given by equation 6.5, we can compare the spectrum of the fitted series with that of the observed series.

$$
\frac {| A (\lambda) | ^ {2} f _ {X X} (\lambda)}{f _ {Y Y} (\lambda)} = \frac {| f _ {Y X} (\lambda) | ^ {2}}{f _ {Y Y} (\lambda) f _ {X X} (\lambda)}
$$

The quantity

$$
| R _ {Y X} (\lambda) | ^ {2} = \frac {| f _ {Y X} (\lambda) | ^ {2}}{f _ {Y Y} (\lambda) f _ {X X} (\lambda)}
$$

is called the coherence of the time series $Y ( t )$ and $X ( t )$ at frequency $\lambda$ . $| R _ { Y X } ( \lambda ) | ^ { 2 }$ provides a measure of how related the frequency $\lambda$ components of $X ( t )$ and $Y ( t )$ are. Its value lies between zero and one. An obvious estimate of $| R _ { Y X } ( \lambda ) | ^ { 2 }$ is obtained by substituting suitable power spectrum and cross-spectrum estimates into the last equation.

While the estimated gain and phase of the fitted filter give us complete information on the nature of the fitted relationship, it can also be useful to examine the estimated filter coefficients. The coefficients are collectively known as the impulse response of the filter because it is the result of applying a filter with coefficients $\{ a ( u ) \}$ to the impulse series

$$
X (t) = \left\{ \begin{array}{l l} 1 & t = 0, \\ 0 & \text {o t h e r w i s e} \end{array} \right.
$$

is to produce the output (or response) $a ( t )$ . The impulse response function can be estimated by direct inversion of the estimated transfer function.

Finally, it is possible (but not easy) to derive the asymptotic distributions of all the estimates presented in this section. The details of these derivations and the generalisation to multivariate time series can be found in David Brillinger’s book Time Series: Data Analysis and Theory.

# 6.5 Computation

# 6.5.1 A Simple Spectral Analysis Package for R

There is a simple spectral analysis package I put together because the current facilities available in R and S are not as good as they could be. You can pick up the R code from

http://www.stat.auckland.ac.nz/~ihaka/726/spectrum.R

Use the source command to read this into R.

The code is not particularly sophisticated, but should give you some idea of what is possible. You should also be able to see that it corresponds directly to formulae you’ve seen in class. (I am planning to implement a real spectral analysis library in the future).

Note that all frequencies (including the smoothing bandwidths) are specified in “cycles per unit time”. E.g. for monthly data, a frequency of 1/12 corresponds to a yearly cycle.

# 6.5.2 Power Spectrum Estimation

These calls are appropriate for estimating the power spectrum of a single series. More sophisticated techniques are possible, but this will get you most of the information present in a series.

1. Compute and plot the periodogram.

```txt
z = power.spectrum(x) plot(fxx(z)) 
```

2. Compute and plot a smoothed periodogram estimate with a given smoothing bandwidth.

```txt
z = power.spectrum(x, bw = .01) plot(fxx(z)) 
```

3. Compute and plot a smoothed periodogram estimate with a given smoothing span. The span is an odd, positive integer and the estimate will be obtained by averaging span periodogram ordinates.

```txt
z = power.spectrum(x, span = 11) plot(fxx(z)) 
```

4. There are a number of options to the plotting command. Zoom in on a given frequency range.

```txt
plot(fxx(z), xlim = c(0, .2)) 
```

Plot the confidence limits around the estimate.

```r
plot(fxx(z), ci = TRUE) 
```

# 6.5.3 Cross-Spectral Analysis

The model to be fitted is

$$
Y (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u) + \varepsilon (t)
$$

The key assumption is that $\varepsilon ( t )$ be a stationary, mixing series. $X ( t )$ and $Y ( t )$ are not required to be stationary, although this is case we have theory for.

1. Estimate the Spectra and Cross Spectra (no plotting).

$$
z = \text {s p e c t r u m} (x, y, b w = . 0 1)
$$

2. Display the spectra for the $X$ and $Y$ series. The ci and xlim options can be specified.

$$
\begin{array}{l} \text {p l o t (f x x (z))} \\ \text {p l o t (f y y (z))} \end{array}
$$

3. Display the coherence (the 95% null point is shown).

$$
\operatorname {p l o t} (\text {c o h e r e n c e} (z))
$$

4. Display the spectrum of the residual series (ci and xlim also apply in this case).

$$
\text {p l o t} (\text {r e s i d u a l . s p e c t r u m} (z))
$$

5. Display the gain and phase of the fitted filter (ci and xlim also apply in this case).

$$
\begin{array}{l} \text {p l o t (g a i n (z))} \\ \text {p l o t (p h a s e (z))} \end{array}
$$

6. Display the filter coefficients (the impulse response).

$$
\operatorname {p l o t} (\text {i m p u l s e . r e s p o n s e} (z))
$$

# 6.6 Examples

The series berlin and vienna (available from the class web site) contain the monthly average temperatures (in $^ \circ \mathrm { C }$ ) observed in Berlin and Vienna over the years 1775–1950. We will examine these series using the cross-spectral techniques developed in section 6.4.6. We will take the Vienna series to be $X ( t )$ and the Berlin series to be $Y ( t )$ and we will fit a model of the form

$$
Y (t) = \sum_ {u = - \infty} ^ {\infty} a (u) X (t - u) + \varepsilon (t).
$$

(Note that we are doing this as a pure exploration, not because we think that there is any kind of causal influence of Vienna temperatures on Berlin ones.)

We will begin by trying to obtain a reasonable estimate of the spectra of the $x$ and $y$ series. It is usual to have to experiment with various amounts of

![](images/f0df5b3347dc80dbde0f826456e8ab8328906815fdf2ff36a03ae27f32171c3d.jpg)  
Figure 6.7: The spectrum of the Vienna temperature series.

smoothing when obtaining spectrum estimates. We’ll begin with just a small amount of smoothing. This will enable us to look precisely at any periodic components of the series. The first estimate smooths 9 periodogram estimates.

> z = spectrum(vienna, berlin, span=9)   
> plot(fxx(z))

Figure 6.7 shows the resulting power spectrum. The highest peak is at frequency 1/12 and corresponds to the yearly seasonal cycle. The peak to the right of this is at frequency 2/12 and so is a harmonic which affects the shape of seasonal waveform. The peak very close to frequency zero indicates that there is some type of long period variation or trend in the series.

Expanding the low frequency region of the spectrum enables us to get a better look at the most interesting part of the spectrum. This can be done as follows:

$$
> p l o t (f x x (z), x l i m = c (0, 0. 2))
$$

The result is shown in figure 6.8. No additional information is revealed.

We can also extract the power spectrum for the Berlin series and examine it in the same way using the command

$$
> p l o t (f y y (z), x l i m = c (0, 0. 2))
$$

The result is shown in figure 6.9. The same major seasonal peak appears in the Berlin spectrum, but the harmonic at frequency 2/12 is diminished. This suggests that the temperature variation in Berlin is closer to being a pure sine

![](images/b1b60a2ecfbcae029bf64f9a35d339baf741cc27db42a0576b80d09b625772c8.jpg)  
Figure 6.8: The spectrum of the Vienna temperature series.

![](images/e40b8e6d556299fb9afb05309b705a76050906b05dcf702f0b8f250db8287b70.jpg)  
Figure 6.9: The spectrum of the Berlin temperature series.

![](images/5cb3bd07d5f8788d404022b80a850366598beacf0d9eab57c0949b7e5708f3e2.jpg)  
Figure 6.10: The coherence of the Vienna and Berlin temperature series.

wave than it is in Vienna. In addition, the low frequency portion of the Berlin spectrum is lower than that of the Vienna one.

We begin an examination of the relationship between the two series by looking at the coherence between them. This can be done with the command

$$
> p l o t (\text {c o h e r e n c e} (z), x \lim  = c (0, 0. 2))
$$

The coherence is high right across the spectrum although it is clearly strongest in the region of the spectral peak at frequency 1/12. There is also a region of low coherence in the very lowest frequency region.

The message that this plot conveys is that the two temperature series are strongly related. We can examine the best fitting filter in either the frequency domain or the time domain. We’ll begin in the frequency domain. The gain of the best fitting filter can be plotted with the command

> plot(gain(z))

The result is shown in figure 6.11. The figure shows that that the estimated gain varies about a horizontal line which is slightly less than 1 in magnitude. This means that the temperatures in Berlin show a similar pattern to those in Vienna, but are slightly colder. The exception to this general rule is that the long-term slow variations appear to be unrelated. This is in agreement with what the coherence shows.

The alternative way of looking at the filter is to examine the filter coefficients or impulse response. A plot of the impulse response can be produced with the command

> plot(impulse.response(z))

![](images/3f710d6bac5ee3a15774bd7ccde79a393dacd237646bba794d0b0db9973bd64c.jpg)  
Figure 6.11: The gain of the filter which approximates the Berlin series using the Vienna one.

![](images/98731482ec9aad0253599472b7a5397ae615e99be0363995661d284d2fd49845.jpg)  
Figure 6.12: The coefficients of the filter which best approximates the Berlin series using the Vienna one.

This produces the result shown in figure 6.12. The plot shows that the average monthly temperatures in Berlin and Vienna move in step, with the temperature in Berlin being between 0.8 and 0.9 times that in Vienna.

The cities of Berlin and Vienna are geographically close and weather systems pass between them in a matter of days. Because of this it should be no surprise that the best fitting filter has the form that it does. What is surprising is that there is such a lack of similarity at the very lowest frequencies. This suggests that long term temperature variations are a local effect, possibly the result of human activity.

![](images/b989c7efba0395bca881f5bcd485cdbac6143cada7adaab377c6daf17dcf8bb8.jpg)

# Time Series Analysis

# Lecture Review

![](images/24897c2e5df3185013b399a04e493744c19ccfb06e13c22a3deb859a5b81e5d0.jpg)

# Dr. Kalyan N

Assistant Professor

Dept. of CSE (Data Science)

B.M.S College of Engineering

Bengaluru - 560019.

kalyan.cds@bmsce.ac.in

Homepage

October, 2024.

# Contents

# 1 Time Series Data 4

1.1 Purpose . 4   
1.2 Time series 5

1.2.1 Uses of Time series 5   
1.2.2 Plots . 5   
1.2.3 Trends . 6   
1.2.4 Seasonal Variation 6

1.3 Decomposition of Series 6

1.3.1 Notation . 6   
1.3.2 Models 6   
1.3.3 Estimating trends and seasonal effects 7   
1.3.4 Smoothing 7   
1.3.5 Decomposition in $R$ 7

# 2 Characteristics of Time Series 10

2.1 Introduction and Examples 10   
2.2 Objectives and Nature of Time Series 10   
2.3 Introduction to Time Series Databases and Applications . 11   
2.4 Measures of Dependence . 14

2.4.1 Introduction to Measures of Dependence . 14   
2.4.2 Example Problem: Estimating Autocorrelation 15

2.5 Stationary Time Series . 16

2.5.1 Definition and Importance of Stationarity 16   
2.5.2 Features of Stationary Time Series 16   
2.5.3 R Example: Plotting a Stationary Series . 16

2.6 Estimation of Correlation 17

2.6.1 Definition of Correlation . 17   
2.6.2 Proof of Correlation for Time Series 17

2.7 Vector-Valued and Multi-Dimensional Series . 17

2.7.1 Definition and Importance . . 17   
2.7.2 Example: Vector-Valued Series in R 18

# 3 Components of Time Series 19

3.1 Additive and Multiplicative models . 21   
3.2 Resolving components of a Time Series . 23

3.3 Measuring Trend . . 24

3.3.1 Graphic 24   
3.3.2 Semi-Averages 26   
3.3.3 Example . . 26   
3.3.4 Moving Average 27   
3.3.5 Method of Least Squares 30

# 4 Correlation 36

4.1 Expectation and the ensemble . 36

4.1.1 The Ensemble and Stationarity 38   
4.1.2 Ergodic Series . 39

4.2 Variance function . 39   
4.2.1 Autocorrelation . 40

4.3 correlogram, covariance of sum of random variables . . 43

4.3.1 General discussion 43   
4.3.2 Example based on air passenger series 44

# 5 Seasonal Variation 46

5.1 Method of Simple Averages . 46   
5.2 Ratio-to- Trend Method 51   
5.3 Ratio-to-Moving Average Method and Link Relative Method 60   
5.4 Link relative method 65   
5.5 Cyclical and Random Fluctuations 67

5.5.1 Example of Cyclical Fluctuations 67

5.6 Random Fluctuations 70

5.6.1 Example of Random Fluctuations 70   
5.6.2 Deseasonalisation . 70

5.7 Variate Difference Methods 72

5.7.1 Example 1: Monthly Sales Data 72   
5.7.2 Example 2: Daily Temperature Records 73   
5.7.3 Conclusion 75

# 6 Index Numbers and their Definitions 76

6.1 Construction and Uses of Fixed and Chain based Index Numbers 76   
6.2 Simple and Weighted Index Numbers . 76   
6.3 Laspeyres, Paasche’s, Fisher’s, and Marshall - Edgeworth Index Numbers . 76   
6.4 Optimum Tests for Index Numbers 76   
6.5 Cost of Living Index Numbers . 76

# 7 Forecasting Strategies 77

7.1 Leading variables and associated variables . . 77   
7.2 Bass Model 77   
7.3 Exponential Smoothing and Holt-Winters method 77

# 8 Basic Stochastic Models 78

8.1 White Noise, Random Walks, Fitted models & diagnostic plots 78   
8.2 Autoregressive models 78

8.2.1 stationary and non-stationary Autoregressive process . . 78

# 9 Time series Regression and Exploratory Data Analysis 79

9.1 Classical Regression 79   
9.2 Exploratory Data Analysis . . 79   
9.3 generalized least square method . 79   
9.4 linear models with seasonal variables . 79   
9.5 Harmonic seasonal models 79   
9.6 logarithmic transforms 79

# 10 Linear Models 80

10.1 Moving Average models 80   
10.2 Fitted MA Models 80

10.2.1 Autoregressive Moving Average Models 80

10.3 Differential Equations 80   
10.4 Autocorrelation and Partial Correlation 80   
10.5 Forecasting & Estimation 80   
10.6 Non-stationary Models 80

10.6.1 Building non-seasonal ARIMA Models . 80   
10.6.2 ARCH Models & GARCH Models 80

# Module - 1

# Chapter - 1

A time series is a sequence of statistical data organized according to the time of occurrence or in chronological order. The numerical data collected at various points in time, forming a set of observations, is referred to as a time series. In time series analysis, current data within a series can be compared with past data from the same series. Additionally, the progression of two or more series over time can be compared. These comparisons can provide valuable insights for individual businesses. Time series analysis is crucial in fields such as economics, statistics, and commerce.

# 1 Time Series Data

A time series consists of observations made at specific time intervals and arranged in chronological order. For example, tracking agricultural production, sales, or National Income over a span of 3 to 5 years constitutes a time series. It is essentially a sequence of quantitative readings recorded at regular intervals, which could be hourly, daily, weekly, monthly, or annually. Examples of time series include hourly temperature readings, daily shop sales, weekly market sales, monthly production figures, yearly agricultural outputs, and population growth over ten years. Analyzing a time series involves comparing past data with current data to forecast future trends and evaluate past performance. The focus of time series analysis is on understanding chronological variations. Key requirements for a time series are:

• The time intervals between observations should be as consistent as possible.   
• The dataset must be homogeneous.   
• Data should be collected over an extended period.

Symbolically, if $t$ represents time and $y _ { t }$ denotes the value at time $t$ , then the paired values $( t , y _ { t } )$ constitute the time series data. Ex 1: Production of rice in Karnataka for the period from 2010-11 to 2016-17.

Table 1: Production of rice in Karnataka (in ‘000 metric tons)   

<table><tr><td>Year</td><td>Production</td></tr><tr><td>2010-11</td><td>800</td></tr><tr><td>2011-12</td><td>950</td></tr><tr><td>2012-13</td><td>870</td></tr><tr><td>2013-14</td><td>920</td></tr><tr><td>2014-15</td><td>860</td></tr><tr><td>2016-17</td><td>720</td></tr></table>

# 1.1 Purpose

Time series analysis is crucial for understanding historical data and forecasting future trends, which aids managers and policymakers in making informed decisions. By quantifying key features and random variations in data, time series methods have become widely applicable across government, industry, and commerce, especially with advances in computing power. The Kyoto Protocol, an amendment to the United Nations Framework Convention on Climate Change, was signed in December 1997 and came into effect on February 16, 2005. The rationale for reducing greenhouse gas emissions involves a blend of scientific data, economic considerations, and time series analysis. The decisions made in the coming years will have significant implications for the planet’s future.

In 2006, Singapore Airlines expanded its fleet by ordering twenty Boeing 787-9s and expressing intent to purchase twenty-nine Airbus planes, including twenty A350s and nine A380s (superjumbos). This expansion was guided by time series analysis of passenger trends and strategic corporate planning to maintain or enhance market share. Time

series methods are also employed in everyday operational decisions. For instance, UK gas suppliers must place orders for offshore gas one day in advance. The variation from the seasonal average is influenced by temperature and, to a lesser extent, wind speed. Time series analysis helps forecast demand by adjusting the seasonal average with one-day-ahead weather forecasts.

Additionally, time series models underpin many computer simulations. Examples include evaluating inventory control strategies using simulated demand series, comparing wave power device designs with simulated sea states, and simulating daily rainfall to assess the long-term environmental impacts of proposed water management policies.

# 1.2 Time series

In many fields, including science, engineering, and commerce, variables are measured sequentially over time. For instance, reserve banks track daily interest and exchange rates, governments report annual GDP figures, and meteorological offices log rainfall at various locations. When data are collected at regular intervals, they form a time series. A historical time series is created from observations recorded at fixed intervals. In this context, time series are often treated as realizations of sequences of random variables, known as discrete-time stochastic processes or time series models. Our focus will be on applying these models using R to fit data and perform analysis.

Time series data often exhibit trends and seasonal variations that can be modeled mathematically. Additionally, observations close in time are typically correlated. Time series analysis aims to explain this correlation and other data features using statistical models. Once a model is fitted, it can be used to forecast future values, conduct statistical tests, and summarize the main characteristics of the data, aiding decision-making.Sampling intervals impact data quality. Aggregated data, like daily tourist arrivals, or sampled data, such as daily stock prices, need appropriate intervals to accurately reflect the original signal. In high-frequency trading or signal processing, continuous signals are sampled at very high rates to create time series for detailed analysis.

# 1.2.1 Uses of Time series

The analysis of time series is of great significance not only to economists and business people but also to scientists, astronomers, geologists, sociologists, biologists, and researchers. This is due to the following reasons:

• It helps in understanding past behavior.   
• It assists in planning future operations.   
• It aids in evaluating current accomplishments.   
• It facilitates comparison.

# 1.2.2 Plots

Visualizing time series data is crucial for identifying patterns and trends. Common types of plots include:

• Line Plot: Displays data points connected by lines to show changes over time. Useful for identifying trends and seasonal patterns.   
• Scatter Plot: Plots individual data points to observe the relationship between two variables or to identify patterns and outliers.   
• Bar Plot: Represents data with bars, helpful for comparing discrete time periods or categories.   
• Histogram: Shows the distribution of data over specified intervals, useful for understanding the frequency of values.   
• Box Plot: Displays the distribution of data based on quartiles, highlighting median, and potential outliers.

# 1.2.3 Trends

Trends refer to the long-term movement or direction in the data over a period. Identifying trends helps in understanding the overall pattern:

• Upward Trend: Indicates a general increase in values over time.   
• Downward Trend: Shows a general decrease in values.   
• Stationary Trend: The data fluctuates around a constant mean without a long-term trend.

# 1.2.4 Seasonal Variation

Variations refer to the deviations from the trend and can be categorized into:

• Seasonal Variations: Regular patterns that repeat at consistent intervals, such as monthly or quarterly.   
• Cyclical Variations: Fluctuations that occur over longer periods, influenced by economic or business cycles.   
• Irregular Variations: Unpredictable changes due to unforeseen events or anomalies that do not follow a pattern.

Understanding these components allows for effective analysis and forecasting of time series data.

# 1.3 Decomposition of Series

# 1.3.1 Notation

The analysis so far has focused on plotting data to identify features such as trends and seasonal variations. While this is a crucial first step, the next stage involves fitting time series models. We represent a time series of length $n$ as $\{ x _ { t } : t = 1 , \ldots , n \} = \{ x _ { 1 } , x _ { 2 } , \ldots , x _ { n } \}$ , where $n$ values are sampled at discrete times $t = 1 , 2 , \ldots , n$ . When the series length is not essential, we abbreviate it as $\{ x _ { t } \}$ .

A time series model is a sequence of random variables, and the observed series is a realization of this model. We use the same notation for both, with context distinguishing between them. An overline denotes sample means.

$$
\bar {x} = \sum \frac {x _ {i}}{n} \tag {1}
$$

The ‘hat’ notation represents a prediction or forecast. For a series $\{ x _ { t } : t = 1 , \ldots , n \}$ , $\hat { x } _ { t + k | t }$ denotes a forecast made at time $t$ for the value at $t + k$ . The number of steps into the future, $k$ , is the lead time. Depending on the context, $\hat { x } _ { t + k | t }$ may refer to either the random variable or its numerical value.

# 1.3.2 Models

Many time series are dominated by trend and/or seasonal effects. A simple additive decomposition model is given by:

$$
x _ {t} = m _ {t} + s _ {t} + z _ {t} \tag {2}
$$

where $x _ { t }$ is the observed series, $m _ { t }$ is the trend, $s _ { t }$ is the seasonal effect, and $z _ { t }$ is the error term, often a sequence of correlated random variables with mean zero. Two main approaches for extracting $m _ { t }$ and $s _ { t }$ will be outlined along with R functions for this.

For cases where the seasonal effect increases with the trend, a multiplicative model may be more suitable:

$$
x _ {t} = m _ {t} \cdot s _ {t} + z _ {t} \tag {3}
$$

Alternatively, an additive decomposition for $\log ( x _ { t } )$ can be used:

$$
\log \left(x _ {t}\right) = m _ {t} + s _ {t} + z _ {t} \tag {4}
$$

Care is needed when transforming back to $x _ { t }$ from $\log ( x _ { t } )$ to avoid bias. If $z _ { t }$ is normally distributed with mean 0 and variance $\sigma ^ { 2 }$ , the predicted mean value is:

$$
\hat {x} _ {t} = e ^ {m _ {t} + s _ {t} + \frac {1}{2} \sigma^ {2}} \tag {5}
$$

For non-normal distributions, bias correction may lead to overcorrection, requiring an empirical adjustment. This is critical, for instance, in financial forecasts, where underestimating mean costs is a common issue.

# 1.3.3 Estimating trends and seasonal effects

A simple way to estimate the trend $m _ { t }$ is by calculating a moving average centered on $x _ { t }$ . A moving average smooths the time series by averaging a specified number of values around each $x _ { t }$ , except for the first and last few terms. For monthly data, the moving average spans 12 months. Since the average of $t = 1$ (January) to $t = 1 2$ (December) falls between June and July (i.e., $t = 6 . 5$ ), we average two consecutive moving averages to center the result at $t = 7$ . The centered moving average for $m _ { t }$ is given by:

$$
\hat {m} _ {t} = \frac {1}{1 2} \left(\frac {1}{2} x _ {t - 6} + x _ {t - 5} + \dots + x _ {t + 5} + \frac {1}{2} x _ {t + 6}\right) \tag {6}
$$

where $t = 7 , \ldots , n - 6$ . The coefficients sum to 1, ensuring equal weight for each value. This method generalizes to other seasonal frequencies (e.g., quarterly) by maintaining the condition that coefficients sum to unity.

The seasonal effect $\hat { s } _ { t }$ can be estimated by subtracting the trend:

$$
\hat {s} _ {t} = x _ {t} - \hat {m} _ {t} \tag {7}
$$

Averaging the monthly estimates across all years provides a single estimate of the effect for each month. To ensure the seasonal effects sum to zero, they are adjusted by subtracting the mean. For multiplicative models, the estimate becomes:

$$
\hat {s} _ {t} = \frac {x _ {t}}{\hat {m} _ {t}} \tag {8}
$$

and multiplicative factors are adjusted to average to 1. Seasonally adjusted data, often used in economic indicators, removes seasonal effects. If the seasonal effect is additive, the adjusted series is $x _ { t } - s _ { t }$ , and if multiplicative, it is $x _ { t } / \bar { s } _ { t }$ , where $s _ { t }$ is the mean seasonal adjustment for the given time.

# 1.3.4 Smoothing

The centred moving average is a smoothing procedure applied retrospectively to identify an underlying trend in a time series. It uses points before and after the target time, often leaving some missing values at the series’ start and end unless adapted for edge points. Another smoothing method in R is ‘stl‘, which uses locally weighted regression (loess). This local regression considers a small number of points around the target time, weighted to reduce the influence of outliers, making it a robust regression. While straightforward in principle, the details of ‘stl‘ are complex.

Unlike smoothing, which does not provide a forecast model, fitting a linear trend has the advantage of enabling extrapolation. The term ”filtering” is also used in this context, particularly in engineering, to describe obtaining the best estimate of a variable based on past and current noisy measurements. Filtering is vital in control algorithms, such as those used by the Huygens probe during its 2005 landing on Titan.

# 1.3.5 Decomposition in $\pmb { R }$

In R, the function ‘decompose‘ estimates trends and seasonal effects using a moving average. Nesting it within ‘plot‘ (e.g., ‘plot(stl())‘) produces a figure showing the original series $x _ { t }$ , and decomposed series $m _ { t }$ , $s _ { t }$ , and $z _ { t }$ . For example, additive and multiplicative decomposition plots for electricity data are created by the following commands, with the seasonal effect superimposed on the trend using ‘lty‘ for line types.

![](images/025b3e5ae2c80ccbba9e3ae20e15d79b409d6e2f0c1a00f9a19c6b4dbfac1b17.jpg)  
Listing 1: Decomposition of Time Series in R

Figure 1: Electricity production data: trend with superimposed multiplicative seasonal effects.

1 # Decomposition of the time series
2 plot(decompose(Elec.ts))
3
4 # Multiplicative decomposition
5 Elec.decom <- decompose(Elec.ts, type = "mult")
6 plot(Elec.decom)
7
8 # Extracting the trend and seasonal components
9 Trend <- Elec.decom\(trend
10 Seasonal <- Elec.decom\)seasonal
11
12 # Plotting the trend and the product of trend and seasonal effect
13 ts.plot(cbind(Trend, Trend * Seasonal), lty = 1:2)

A multiplicative model is often more suitable than an additive one when the variance of the series and trend increase over time. However, if the random component $z _ { t }$ also shows increasing variance, a log-transformation (Eq. 1.4) may be more appropriate.

![](images/cc0463303f733ea2748d06539a092187205be877f0e629affb771f299be06c80.jpg)  
Decomposition ofmultiplicative time series   
Figure 2: Decomposition of the electricity production data.

The random series from ‘decompose‘ is not the true realization of $z _ { t }$ , but an estimate derived from the trend and seasonal components, treated as a residual error series, yet used as a realisation of the random process.

# Module - 1

# Chapter - 2

# 2 Characteristics of Time Series

A time series is a collection of data points indexed in time order, usually spaced at uniform intervals. It captures observations at successive points in time, and this ordering makes time series distinct from other types of data because time series analysis is inherently about trends, patterns, and dependencies across time. To effectively analyze time series data, it is important to understand its core characteristics. These characteristics form the basis for any meaningful analysis, forecasting, or modeling.

# 2.1 Introduction and Examples

Time series is a sequence of data points collected or recorded at regular time intervals. It is used in various domains such as economics, finance, meteorology, medicine, and engineering to analyze trends, patterns, and seasonal variations. Unlike cross-sectional data, time series data captures the dynamics and changes over time, allowing for forecasting and insight extraction from historical patterns.

Common examples of time series data include:

• Stock market prices recorded every minute.   
• Daily temperature recordings in a city.   
• Monthly sales data for a retail store.   
• Quarterly GDP of a country.   
• Yearly rainfall data in a specific region.

In R, we can visualize a simple time series data using the AirPassengers dataset:

```r
1 # Example in R:  
2 data("AirPassengers")  
3 plot(AirPassengers, main="AirPassengers Dataset",  
4 ylab="Number of Passengers", xlab="Year") 
```

Listing 2: Example in R

# 2.2 Objectives and Nature of Time Series

The main objectives of time series analysis include:

• Understanding the underlying patterns in the data.   
• Identifying components such as trend, seasonality, and cyclic behaviors.   
• Modeling the time series to predict future values.   
• Detecting anomalies or unexpected changes.   
• Smoothing to eliminate noise and reveal important patterns.

The nature of time series can be categorized into:

• Trend Component (T): A long-term increase or decrease in the data. For example, the overall upward movement in stock market prices over several years.

• Seasonal Component (S): Regular fluctuations that repeat over a specific period, such as monthly sales peaking every December.   
• Cyclic Component (C): Recurrent but non-periodic fluctuations often linked to economic cycles.   
• Irregular Component (I): Random variations that do not follow a pattern.

These components can be combined using the following additive or multiplicative models:

$$
Y (t) = T (t) + S (t) + C (t) + I (t) \tag {9}
$$

or

$$
Y (t) = T (t) \times S (t) \times C (t) \times I (t) \tag {10}
$$

In R, we can decompose a time series to analyze these components:

```r
1 # Decomposition Example in R:  
2 decomposed <- decompose(AirPassengers)  
3 plot(decomposed) 
```

Listing 3: Decomposition Example in R

# 2.3 Introduction to Time Series Databases and Applications

Time series databases (TSDB) are optimized for storing and querying time series data. Unlike traditional relational databases, TSDBs are built to efficiently handle timestamped data, which makes them ideal for applications that require storing large volumes of time-dependent data with high write-throughput and quick retrieval.

Some popular time series databases include:

• InfluxDB: InfluxDB is an open-source time series database designed specifically for storing and managing time series data such as metrics, events, and analytics. It is widely used in the Internet of Things (IoT), DevOps, real-time analytics, and monitoring applications. InfluxDB is part of the InfluxData stack, which includes Telegraf (a plugin-based collector of metrics), Chronograf (a visualization tool), and Kapacitor (an alerting and processing tool).

InfluxDB uses a simple and flexible query language called InfluxQL, which is similar to SQL but optimized for time series operations like aggregations, time windowing, and transformations. It also supports the newer Flux language, which offers more powerful queries. InfluxDB is known for its high write throughput, enabling it to handle millions of writes per second, which makes it ideal for real-time data collection and analysis.

InfluxDB stores data in a compressed time series format and offers a retention policy feature, where users can automatically delete old data to manage storage effectively. It also supports downsampling, which helps reduce storage costs by keeping high-resolution data for shorter periods while retaining summarized, lower-resolution data for longer periods.

InfluxDB uses the InfluxQL or Flux query languages. Below is an example using InfluxQL.

```txt
1 # Storing time series data in InfluxDB  
2 INSERT temperature, location = room1 value = 72.5  
3 INSERT temperature, location = room2 value = 75.3 
```

Listing 4: Storing Time Series Data in InfluxDB

```txt
1 # Querying time series data in InfluxDB  
2 SELECT mean("value") FROM "temperature"  
3 WHERE time >= '2021-07-29T00:00:00Z' AND time < '2021-07-30T00:00:00Z'  
4 GROUP BY time(1h), "location" fill(none) 
```

Listing 5: Querying Time Series Data in InfluxDB

# Advantages of InfluxDB:

– High Performance: InfluxDB is optimized for fast writes, making it ideal for use cases where data is collected frequently, such as IoT applications or system monitoring. Its write throughput is among the best in class for time series databases.   
– Retention Policies: Users can define retention policies to automatically expire older data, thus managing storage costs efficiently. This is particularly useful in environments where data grows exponentially over time.   
– Schema-Free: InfluxDB is schemaless, meaning that data can be written with any fields and tags, making it flexible to adapt to new use cases and metrics without predefined structures.   
– Integrations: InfluxDB integrates easily with other tools such as Grafana for visualization, Telegraf for data collection, and Kapacitor for alerting and data processing.

# Cons of InfluxDB:

– Query Complexity: While InfluxQL is simple for basic queries, more complex queries involving joins or transformations might be challenging. Flux, the newer query language, addresses these issues but introduces a learning curve.   
– Scaling Issues: Scaling InfluxDB horizontally (i.e., across multiple nodes) can be challenging. The enterprise version of InfluxDB offers clustering, but the open-source version does not, making scaling limited for high-availability deployments.   
– Storage Costs: Although InfluxDB offers compression, the storage requirements for high-frequency data can still be substantial, especially in long-term retention scenarios.

• TimescaleDB: TimescaleDB is an open-source time series database built as an extension to PostgreSQL. By leveraging the mature and robust PostgreSQL ecosystem, TimescaleDB inherits features like ACID compliance, powerful indexing, relational joins, and SQL support, making it a reliable option for time series applications that also require relational data.

TimescaleDB splits large datasets into ”chunks” based on time intervals, which allows for efficient time-series queries. This method also makes TimescaleDB horizontally scalable while keeping storage costs down. Additionally, TimescaleDB supports native compression, significantly reducing the storage footprint for large datasets.

One of the strengths of TimescaleDB is its seamless integration with the broader PostgreSQL ecosystem, which includes extensions, tools, and libraries. This makes it an attractive choice for users who already have a PostgreSQL setup and are looking to incorporate time series capabilities into their existing infrastructure without migrating to a new system.

TimescaleDB uses standard SQL, with time series data stored in hypertables.

```sql
-- Creating a hypertable in TimescaleDB  
CREATE TABLE temperature (  
time TIMESTAMPTZ NOT NULL,  
location TEXT NOT NULL,  
temperature DOUBLE PRECISION NOT NULL);  
-- Convert the table to a hypertable  
SELECT create_hypertable('temperature', 'time');  
-- Inserting data into TimescaleDB  
INSERT INTO temperature (time, location, temperature)  
VALUES (NOW(), 'room1', 72.5), (NOW(), 'room2', 75.3); 
```

Listing 6: Storing Time Series Data in TimescaleDB

```sql
1 -- Querying the average temperature by hour  
2 SELECT time_bucket('1 hour', time) AS bucket, location, avg(temperature)  
3 FROM temperature  
4 WHERE time > NOW() - interval '24 hours'  
5 GROUP BY bucket, location 
```

6 ORDER BY bucket DESC ;

# Listing 7: Querying Time Series Data in TimescaleDB

# Advantages of TimescaleDB:

– PostgreSQL Ecosystem: Since TimescaleDB is an extension of PostgreSQL, it benefits from the stability, reliability, and community support of PostgreSQL. This includes support for advanced indexing, relational joins, transactions, and other features common to relational databases.   
– SQL Support: TimescaleDB supports standard SQL queries, making it easy for developers familiar with SQL to work with time series data. This reduces the learning curve compared to other TSDBs that use custom query languages.   
Efficient Time Series Storage: TimescaleDB automatically partitions data into chunks based on time intervals, which improves query performance. It also supports data compression, making it highly efficient for storing large datasets.   
– Scalability: TimescaleDB provides built-in tools for scaling horizontally, allowing it to handle large time series datasets across distributed environments.

# Cons of TimescaleDB:

– Limited for Extreme Real-Time Use Cases: While TimescaleDB performs well for most time series applications, it may not be as optimized for extreme high-frequency, real-time applications as InfluxDB or Prometheus.   
– Complexity with Large Joins: Although relational joins are a strength of TimescaleDB, performing large-scale joins on massive datasets can lead to performance issues, particularly for real-time queries.   
– Enterprise Features: Some advanced features, like continuous aggregation and advanced compression, are part of TimescaleDB’s enterprise offering, which can be a limitation for users relying only on the open-source version.

• Prometheus: Prometheus is a highly popular, open-source monitoring and alerting toolkit designed specifically for cloud-native environments. It was developed as part of the Cloud Native Computing Foundation and is often used in conjunction with Kubernetes for monitoring application performance, infrastructure metrics, and other system behaviors.

Prometheus works by scraping metrics from instrumented services at regular intervals, storing them as time series data. It supports multi-dimensional data collection using labels, which are key-value pairs attached to the metrics. Prometheus uses its own query language called PromQL (Prometheus Query Language), which is specifically designed for aggregating and filtering time series data. Its alerting mechanism is flexible and integrates easily with various notification systems like PagerDuty, Slack, and email.

One of the primary use cases for Prometheus is in monitoring cloud infrastructure, where it excels at tracking the performance of servers, containers, and microservices. The system is designed to be lightweight and works well in environments where quick real-time insights and monitoring are critical.

Prometheus uses PromQL for querying, and data is scraped from instrumented services.

```yaml
1 An example of Prometheus scrape configuration  
2 scrapeconfigs:  
3 - job_name: 'node_exporter'  
4 staticconfigs:  
5 - targets: ['localhost:9100'] 
```

Listing 8: Scraping Time Series Data in Prometheus

```txt
1 # Querying time series data in Prometheus using PromQL  
2 avg_over_time(node_cpuSeconds_total[5m]) 
```

Listing 9: Querying Time Series Data in Prometheus

# Advantages of Prometheus:

– Cloud-Native Friendly: Prometheus is designed to work seamlessly in dynamic cloud-native environments, particularly with Kubernetes. It is well-suited for containerized environments where services come and go frequently.   
– Highly Scalable: Prometheus is built for large-scale, distributed environments. Its pull-based metrics collection makes it efficient for monitoring hundreds or thousands of services.   
Alerting System: Prometheus has a powerful alerting system that allows users to define alerting rules based on metric thresholds. It integrates easily with notification tools, enabling quick responses to system failures or abnormal metrics.   
– Multi-Dimensional Data Collection: Prometheus allows users to attach labels to their metrics, making it easy to filter and aggregate data along different dimensions, such as by service, data center, or cluster.

# Cons of Prometheus:

Limited Long-Term Storage: Prometheus is not designed for long-term data retention. While it excels at real-time monitoring, users often need to integrate it with external databases like Thanos or Cortex to store time series data for long-term historical analysis.   
– No Built-In Clustering: Prometheus does not support clustering in its native form, which can be a limitation for users requiring high availability and fault tolerance without external dependencies.   
Query Language Complexity: PromQL, the query language used by Prometheus, can be complex for new users, particularly for those used to SQL or other more common query languages. Learning to write efficient queries in PromQL can take time.

Applications of time series databases include:

• IoT Data Storage: Time series databases are commonly used in IoT devices to store sensor data, such as temperature readings, GPS data, or humidity levels.   
• Financial Market Analysis: TSDBs handle high-frequency trading data, storing stock prices, trading volumes, and other financial indicators over time.   
• DevOps Monitoring: Tracking system performance metrics like CPU usage, memory consumption, and network bandwidth usage in real-time.

An R example to work with a simple time series dataset:

```r
1 # Simulate time series data and store it  
2 time_series_data <- ts(rnorm(100), frequency=12, start=c(2020, 1))  
3 plot(time_series_data, main="Simulated Time Series Data",  
4 ylab="Values", xlab="Time") 
```

Listing 10: Simulate Time Series Data in R

# 2.4 Measures of Dependence

# 2.4.1 Introduction to Measures of Dependence

In time series analysis, measures of dependence refer to the statistical relationships between observations in a time series dataset, especially over time lags. Understanding these dependencies is crucial because they indicate whether and how past values influence future values. A time series is dependent when the values at different points in time are not independent but rather exhibit a relationship that we can measure and analyze.

One of the primary measures of dependence in time series is the autocorrelation function (ACF). This function helps determine how observations at different time points are correlated with one another. The ACF for a time series $\{ X _ { t } \}$ at lag $k$ is given by:

$$
\rho (k) = \frac {\operatorname {C o v} \left(X _ {t} , X _ {t + k}\right)}{\sqrt {\operatorname {V a r} \left(X _ {t}\right) \cdot \operatorname {V a r} \left(X _ {t + k}\right)}}
$$

where Cov denotes covariance, and Var represents the variance of the time series.

The partial autocorrelation function (PACF) is another measure of dependence, which describes the relationship between an observation and its lagged values, excluding the influence of intermediate lags. This is particularly useful in autoregressive (AR) models, where PACF helps determine the order of the model.

# 2.4.2 Example Problem: Estimating Autocorrelation

Consider a simple time series dataset where we observe daily stock prices for 10 days:

$$
X = \{1 2 0, 1 2 2, 1 1 9, 1 1 8, 1 2 1, 1 2 3, 1 2 4, 1 2 5, 1 2 6, 1 2 8 \}.
$$

We want to calculate the autocorrelation at lag 1 and lag 2.

Step 1: Compute the mean of the series. First, compute the mean $X$ of the series:

$$
\bar {X} = \frac {1 2 0 + 1 2 2 + 1 1 9 + 1 1 8 + 1 2 1 + 1 2 3 + 1 2 4 + 1 2 5 + 1 2 6 + 1 2 8}{1 0} = \frac {1 2 2 6}{1 0} = 1 2 2. 6.
$$

Step 2: Define the autocorrelation formula. The formula for autocorrelation at lag $k$ is:

$$
\rho (k) = \frac {\sum_ {t = 1} ^ {n - k} (X _ {t} - \bar {X}) (X _ {t + k} - \bar {X})}{\sum_ {t = 1} ^ {n} (X _ {t} - \bar {X}) ^ {2}},
$$

where:

• $X _ { t }$ is the value at time $t$   
• $X$ is the mean of the time series,   
• $k$ is the lag,   
• $n$ is the total number of observations.

Step 3: Calculate the denominator for all lags. The denominator for both lag 1 and lag 2 is the same:

$$
\sum_ {t = 1} ^ {n} (X _ {t} - \bar {X}) ^ {2} = (1 2 0 - 1 2 2. 6) ^ {2} + (1 2 2 - 1 2 2. 6) ^ {2} + (1 1 9 - 1 2 2. 6) ^ {2} + \dots + (1 2 8 - 1 2 2. 6) ^ {2}.
$$

Substitute the values:

$$
\begin{array}{l} = (- 2. 6) ^ {2} + (- 0. 6) ^ {2} + (- 3. 6) ^ {2} + (- 4. 6) ^ {2} + (- 1. 6) ^ {2} + (0. 4) ^ {2} + (1. 4) ^ {2} + (2. 4) ^ {2} + (3. 4) ^ {2} + (5. 4) ^ {2}. \\ = 6. 7 6 + 0. 3 6 + 1 2. 9 6 + 2 1. 1 6 + 2. 5 6 + 0. 1 6 + 1. 9 6 + 5. 7 6 + 1 1. 5 6 + 2 9. 1 6 = 9 2. 4. \\ \end{array}
$$

Thus, the denominator is 92.4.

Step 4: Calculate the numerator for lag 1. Now, compute the numerator for lag 1, which is:

$$
\sum_ {t = 1} ^ {n - 1} (X _ {t} - \bar {X}) (X _ {t + 1} - \bar {X}) = (1 2 0 - 1 2 2. 6) (1 2 2 - 1 2 2. 6) + (1 2 2 - 1 2 2. 6) (1 1 9 - 1 2 2. 6) + \ldots + (1 2 6 - 1 2 2. 6) (1 2 8 - 1 2 2. 6).
$$

Substitute the values:

$$
\begin{array}{l} = (- 2. 6) (- 0. 6) + (- 0. 6) (- 3. 6) + (- 3. 6) (- 4. 6) + (- 4. 6) (- 1. 6) + (- 1. 6) (0. 4) + (0. 4) (1. 4) + (1. 4) (2. 4) + (2. 4) (3. 4) + (3. 4) (5. 4). \\ = 1. 5 6 + 2. 1 6 + 1 6. 5 6 + 7. 3 6 + (- 0. 6 4) + 0. 5 6 + 3. 3 6 + 8. 1 6 + 1 8. 3 6 = 5 7. 6 8. \\ \end{array}
$$

Step 5: Calculate autocorrelation at lag 1. Now that we have the numerator and denominator, calculate the autocorrelation:

$$
\rho (1) = \frac {5 7 . 6 8}{9 2 . 4} \approx 0. 6 2 4.
$$

Thus, the autocorrelation at lag 1 is approximately 0.624, indicating a moderate positive correlation between consecutive values.

Step 6: Calculate the numerator for lag 2. For lag 2, compute the numerator:

$$
\sum_ {t = 1} ^ {n - 2} (X _ {t} - \bar {X}) (X _ {t + 2} - \bar {X}) = (1 2 0 - 1 2 2. 6) (1 1 9 - 1 2 2. 6) + (1 2 2 - 1 2 2. 6) (1 1 8 - 1 2 2. 6) + \dots + (1 2 5 - 1 2 2. 6) (1 2 8 - 1 2 2. 6).
$$

Substitute the values:

$$
\begin{array}{l} = (- 2. 6) (- 3. 6) + (- 0. 6) (- 4. 6) + (- 3. 6) (- 1. 6) + (- 4. 6) (0. 4) + (- 1. 6) (1. 4) + (0. 4) (2. 4) + (1. 4) (3. 4) + (2. 4) (5. 4). \\ = 9. 3 6 + 2. 7 6 + 5. 7 6 + (- 1. 8 4) + (- 2. 2 4) + 0. 9 6 + 4. 7 6 + 1 2. 9 6 = 3 2. 4 8. \\ \end{array}
$$

Step 7: Calculate autocorrelation at lag 2. Finally, calculate the autocorrelation at lag 2:

$$
\rho (2) = \frac {3 2 . 4 8}{9 2 . 4} \approx 0. 3 5 2.
$$

Thus, the autocorrelation at lag 2 is approximately 0.352, indicating a weaker positive correlation between values that are two time steps apart.

Conclusion From these calculations, we see that the autocorrelation at lag 1 is higher (0.624) compared to lag 2 (0.352). This suggests that consecutive stock prices are more closely related than prices separated by two days, which is a typical observation in time series where immediate past values have a stronger influence on the present.

# 2.5 Stationary Time Series

# 2.5.1 Definition and Importance of Stationarity

A stationary time series is one whose statistical properties such as mean, variance, and autocorrelation are constant over time. Stationarity is important because many time series models, such as ARMA, ARIMA, or GARCH, assume that the data is stationary. If the data is not stationary, the model’s performance can suffer, leading to poor forecasts.

Formally, a time series $\{ X _ { t } \}$ is stationary if for all time points $t$ , the following conditions hold:

• $\mathbb { E } ( X _ { t } ) = \mu$ (constant mean)  
• $\mathrm { V a r } ( X _ { t } ) = \sigma ^ { 2 }$ (constant variance)  
• $\operatorname { C o v } ( X _ { t } , X _ { t + k } ) = \gamma ( k )$ (constant autocovariance that depends only on lag $k$

# 2.5.2 Features of Stationary Time Series

Key characteristics of a stationary series include:

• The series fluctuates around a constant mean.   
• There is no long-term trend.   
• The autocorrelation function decreases quickly as the lag increases.

# 2.5.3 R Example: Plotting a Stationary Series

We can generate and plot a stationary time series in R using the following code:

1 set . seed (123)   
2 stationary _ series <- ts( rnorm (100) , frequency =12)   
3 plot ( stationary _ series , main =" Stationary Time Series ", ylab $= 1$ " Values ", xlab =" Time ")

Listing 11: Generating a Stationary Time Series

![](images/0881b1f71a5e27af7a388f1a26aa88cf3a8ff7b7c79c93a4839ddd842d8e2e20.jpg)  
Figure 3: Stationary Time Series

The plot of the stationary series will show random fluctuations around a constant mean with no visible trend.

# 2.6 Estimation of Correlation

# 2.6.1 Definition of Correlation

Correlation is a measure of the strength and direction of the linear relationship between two variables. In the context of time series, correlation helps identify how strongly values at one time point relate to values at a later time point (lagged values). Estimating correlation is crucial for understanding the underlying patterns in the data, such as seasonality or trends.

The Pearson correlation coefficient is given by:

$$
r = \frac {\sum_ {t = 1} ^ {n} (X _ {t} - \bar {X}) (Y _ {t} - \bar {Y})}{\sqrt {\sum_ {t = 1} ^ {n} (X _ {t} - \bar {X}) ^ {2} \sum_ {t = 1} ^ {n} (Y _ {t} - \bar {Y}) ^ {2}}}
$$

In time series analysis, we often compute autocorrelation or the correlation between values at different time lags. Estimating the autocorrelation function (ACF) helps us determine whether previous values have predictive power for future values.

# 2.6.2 Proof of Correlation for Time Series

For a time series $\{ X _ { t } \}$ , the autocorrelation at lag $k$ is:

$$
\rho (k) = \frac {\sum_ {t = k + 1} ^ {n} (X _ {t} - \bar {X}) (X _ {t - k} - \bar {X})}{\sum_ {t = 1} ^ {n} (X _ {t} - \bar {X}) ^ {2}}
$$

This equation calculates the correlation between observations separated by $k$ time steps. As $k$ increases, $\rho ( k )$ typically decreases, reflecting the diminishing influence of earlier observations on future values.

# 2.7 Vector-Valued and Multi-Dimensional Series

# 2.7.1 Definition and Importance

A vector-valued time series consists of multiple time series observed together. These can be considered multidimensional or multivariate, where each dimension represents a different but related time series. Analyzing such series is

important in fields like economics (e.g., analyzing stock prices for multiple companies) and environmental science (e.g., temperature, humidity, and wind speed together).

Multidimensional time series analysis focuses on understanding the relationships between these multiple series and how they jointly evolve over time. The vector autoregressive (VAR) model is a common model used for such series.

# 2.7.2 Example: Vector-Valued Series in R

We can create and analyze a vector-valued time series in R using the following code:

Listing 12: Creating and Plotting a Multidimensional Time Series   
```r
1 # Simulate two related time series   
2 set.seed(123)   
3 ts1 <- ts(rnorm(100), frequency=12)   
4 ts2 <- ts(rnorm(100, mean=2), frequency=12)   
5   
6 # Combine them into a multivariate time series   
7 multi_series <- ts(cbind(ts1, ts2), frequency=12)   
8   
9 # Plot the multivariate series   
10 plot(multi_series, main="Vector-Valued Time Series", col=c("blue", "red"), lty=1:2)   
11 legend("topright", legend=c("Series 1", "Series 2"), col=c("blue", "red"), lty=1:2) 
```

Equation for Multivariate Model: In a multivariate time series model, each variable depends on its own past values and the past values of other variables. The vector autoregressive (VAR) model for two time series $X _ { t }$ and $Y _ { t }$ is given by:

$$
X _ {t} = \alpha_ {1} X _ {t - 1} + \beta_ {1} Y _ {t - 1} + \epsilon_ {1 t}
$$

$$
Y _ {t} = \alpha_ {2} X _ {t - 1} + \beta_ {2} Y _ {t - 1} + \epsilon_ {2 t}
$$

where $\alpha _ { 1 } , \alpha _ { 2 } , \beta _ { 1 } , \beta _ { 2 }$ are coefficients and $\epsilon _ { 1 t } , \epsilon _ { 2 t }$ are error terms.

This type of modeling is crucial in understanding how multiple series interact over time.

# Module - 1

Chapter - 3 & 4

# 3 Components of Time Series

article amsmath

The characteristics of a time series are defined by the various types of movements or fluctuations that occur over time. These movements, known as the components of a time series, help explain the underlying patterns in the data. There are four main components:

# 1. Secular Trend (T)

The Secular Trend, also known as the long-term trend or simply trend, refers to the general movement of data, either upward or downward, over an extended period. It captures the long-term tendency of a dataset to grow or decline, ignoring short-term fluctuations.

For example, the population of India shows a clear upward trend over the years, while the death rate after independence has steadily declined due to improvements in literacy and healthcare. It’s important to note that what constitutes a ”long period” depends on the context of the data. For instance, an increase in cloth store sales over one year (e.g., from 1996 to 1997) is too short a period to be considered a secular trend.

However, in certain cases, a shorter time frame can reflect a trend if the nature of the data allows. For example, in a bacterial culture exposed to germicide, counting the number of organisms still alive every 10 seconds over 5 minutes could reveal a general decline in numbers, which would represent a secular trend over that period.

Mathematically, secular trends are categorized into two types:

1. Linear Trend: A consistent, straight-line increase or decrease over time.   
2. Curvi-Linear Trend (Non-Linear Trend): A trend where the rate of change is not constant, resulting in a curved pattern.

![](images/06837c01ab3d24dc3d8f6492b7886a3a6ebe9e2de7f918c2dd399ca00b13fcab.jpg)  
Figure 4: Linear Trend and Non Linear Trend

Example: A consistent rise in global temperatures over decades due to climate change.

# 2. Seasonal Variations (S)

Seasonal variations occur in a time series due to rhythmic forces that repeat in a regular and periodic manner within a period of less than one year. These variations follow the same pattern year after year. The period may be monthly, weekly, or even hourly, but if data is given in yearly terms, seasonal fluctuations do not exist.

Seasonal fluctuations in a time series arise from two main factors:

# 1. Natural forces

# 2. Manmade conventions

The most significant cause of seasonal variations is climate. Changes in weather conditions—such as rainfall, humidity, and temperature—impact industries and products differently. For example, there is a higher demand for woolen clothes and hot drinks in winter, while in summer, cotton clothes and cold drinks see increased sales. During the rainy season, the demand for umbrellas and raincoats rises.

In addition to nature, customs, traditions, and habits also influence seasonal variation. For instance, during festivals like Diwali, Dussehra, and Christmas, there is an increased demand for sweets and clothes. Similarly, the start of a school or college year sees a surge in demand for books and stationery.

Example: Higher sales of air conditioners during summer months due to the hot weather.

# 3. Cyclical Variations (C)

Cyclical movements occur over longer time periods than seasonal variations and typically reflect economic cycles such as booms and recessions. These cycles generally last for several years and, unlike seasonal variations, they do not follow a fixed or regular pattern.

Cyclical variations refer to short-term fluctuations lasting more than one year. The rhythmic movements in a time series that repeat in the same manner over a period longer than one year are called cyclical variations, and the duration is referred to as a cycle. Time series related to business and economics often exhibit cyclical behavior.

A classic example of cyclical variation is the Business Cycle, which includes four well-defined phases:

1. Boom: This phase is characterized by rapid economic growth, high levels of production, employment, and rising prices. During the boom period, consumer demand is strong, and businesses expand rapidly. However, inflationary pressures may also build up, leading to potential overheating of the economy.

Example: The global economy in the late 1990s experienced a boom due to the dot-com bubble, where technology companies saw rapid growth and expansion.

2. Decline: After the boom, the economy begins to slow down. Production and demand decrease, unemployment starts to rise, and inflation stabilizes. This phase marks the transition from a peak towards a downturn, signaling the end of rapid economic expansion.

Example: The early 2000s saw a decline after the burst of the dot-com bubble, where stock prices fell, and many tech companies collapsed, leading to a slowdown in economic growth.

3. Depression: This is the lowest phase of the cycle, marked by a significant decline in economic activity. There is high unemployment, reduced consumer spending, lower investment, and overall economic stagnation. It represents the most severe form of economic contraction.

Example: The Great Depression of the 1930s is a classic example, where global economies shrank, unemployment reached record levels, and industrial output dropped sharply.

4. Improvement (Recovery): After the depression, the economy begins to recover. Businesses start investing again, employment rises, and consumer confidence gradually returns. Production and demand start increasing, marking the beginning of the next upward cycle.

Example: After the Great Recession of 2008, the economy began recovering in 2010, with improved job growth, increased consumer spending, and steady economic expansion.

These phases repeat over time, reflecting the fluctuating nature of economic activity.

![](images/260754e7d6490116b54e3d7d2ee6852c1fd46a4c1609a05acb489037e8f3bfa8.jpg)  
Figure 5: Phases of Business cycle

Example: Economic cycles with alternating periods of economic expansion and contraction.

# 4. Irregular Variations (I)

Irregular variations, also known as Erratic, Accidental, or Random Variations, are unpredictable and nonrecurring fluctuations in a time series caused by unexpected events. Unlike trend, seasonal, and cyclical variations—which are considered regular variations—irregular variations are random and typically short-term, making them difficult to model or forecast.

These fluctuations are the result of unforeseen circumstances that are beyond human control, such as natural disasters, wars, pandemics, or other catastrophic events. Irregular variations significantly disrupt a time series but are not as structurally important as other variations.

Example: The COVID-19 pandemic in 2020 led to severe and unexpected disruptions across global economies, causing irregular variations in many time series related to employment, GDP, and stock market performance. This variation could not be predicted and doesn’t follow any consistent or repeating pattern.

Together, these components provide a framework to analyze time series data, enabling better forecasting and understanding of the underlying patterns.

# 3.1 Additive and Multiplicative models

In time series analysis, a mathematical model represents the underlying structure of the data. It is assumed that the time series consists of various components such as trends, seasonal variations, cyclical variations, and irregular variations. These components together explain the observed value of the time series at any point in time.

The objective of a mathematical model is to decompose a time series into its constituent components in order to better understand, analyze, and forecast future values. Two widely used models in classical time series analysis are the Additive Model and the Multiplicative Model.

# Why Are Mathematical Models Needed?

Mathematical models are essential in time series analysis for the following reasons:

1. Understanding patterns: By decomposing the time series into its components, we can identify trends, seasonal behaviors, and cyclical movements that help in understanding the nature of the data.   
2. Forecasting: Mathematical models help us forecast future values based on past observations and the relationships among the components.   
3. Analyzing irregularities: With the model, irregular or random variations can be separated from systematic variations, allowing analysts to focus on predictable aspects of the data.

# Additive Model

The Additive Model assumes that the different components of a time series combine in an additive manner. That is, the observed value $Y _ { t }$ at time $t$ is the sum of the contributions of the individual components.

Mathematically, the additive model is represented as:

$$
Y _ {t} = T _ {t} + S _ {t} + C _ {t} + I _ {t}
$$

where:

• $Y _ { t }$ is the observed value at time $t$ ,   
• $T _ { t }$ is the trend component at time $t$   
• $S _ { t }$ is the seasonal component at time $t$ ,   
• $C _ { t }$ is the cyclical component at time $t$ , and   
• $I _ { t }$ is the irregular component at time $t$

# Derivation of Additive Model

The additive model is useful when the variation in the seasonal and cyclical components remains relatively constant over time. For example, if sales of ice cream increase by a fixed amount every summer, we can model that seasonal variation additively.

# Example

Consider a time series of monthly sales data for a store over a year. Suppose the trend increases by 5 units per month, the seasonal effect adds 10 units during the summer months (June, July, and August), and cyclical factors add or subtract up to 3 units. Then, using the additive model, we can express the sales data $Y _ { t }$ for a summer month as:

$$
Y _ {t} = 5 t + 1 0 + C _ {t} + I _ {t}
$$

where $C _ { t }$ is the cyclical effect and $I _ { t }$ represents any irregular variations.

# Multiplicative Model

The Multiplicative Model assumes that the components of the time series interact in a multiplicative manner. That is, the observed value $Y _ { t }$ at time $t$ is the product of the contributions of the individual components.

Mathematically, the multiplicative model is represented as:

$$
Y _ {t} = T _ {t} \times S _ {t} \times C _ {t} \times I _ {t}
$$

where the variables $Y _ { t }$ , $T _ { t }$ , $S _ { t }$ , $C _ { t }$ , and $I _ { t }$ represent the same components as in the additive model.

# Derivation of Multiplicative Model

The multiplicative model is useful when the seasonal and cyclical variations are proportional to the level of the trend. For instance, if sales of ice cream double in the summer but are still dependent on an overall increasing trend, a multiplicative model would be more appropriate.

# Example

Consider a company’s quarterly revenue over a few years. If the trend increases by 10% each quarter, and sales are doubled during the holiday season, the multiplicative model expresses the revenue as:

$$
Y _ {t} = T _ {t} \times 2 \times C _ {t} \times I _ {t}
$$

where $T _ { t }$ represents the 10% growth in each quarter, the factor 2 accounts for the seasonal holiday surge, $C _ { t }$ captures any cyclical effects, and $I _ { t }$ represents irregular variations.

# Choosing Between Additive and Multiplicative Models

The choice between the additive and multiplicative models depends on the nature of the data:

• Additive Model: Appropriate when the variations are constant over time and do not depend on the trend.   
• Multiplicative Model: Suitable when the variations grow or shrink in proportion to the trend.

# Conclusion

Both the additive and multiplicative models provide valuable ways to decompose a time series into its underlying components. By choosing the right model, analysts can gain better insights into trends, seasonal variations, and cyclical movements, and make more accurate forecasts.

# 3.2 Resolving components of a Time Series

In time series analysis, resolving the different components is a fundamental task to understand the underlying patterns. Time series data is usually composed of several components, and the key components include:

• Trend ( $T _ { t }$ ): The long-term movement in the data over time.   
• Seasonality ( $S _ { t }$ ): Regular patterns that repeat over fixed intervals of time.   
• Cyclicality ( $C _ { t }$ ): Long-term fluctuations caused by economic cycles.   
• Irregularity ( $I _ { t }$ ): Random or unpredictable movements, typically caused by unforeseen factors.

The relationship between these components can be expressed using two main models:

• Additive Model:

$$
Y _ {t} = T _ {t} + S _ {t} + C _ {t} + I _ {t}
$$

• Multiplicative Model:

$$
Y _ {t} = T _ {t} \times S _ {t} \times C _ {t} \times I _ {t}
$$

In R, you can resolve components of a time series using built-in functions like ‘decompose()‘ for additive models or ‘stl()‘ for both additive and multiplicative models. Consider the following example where we decompose the AirPassengers dataset.

```txt
1 r
2 # Load AirPassengers dataset
3 data(AirPassengers)
4
5 # Decompose the time series
6 decomposed_data <- decompose(AirPassengers, type = "multiplicative")
7
8 # Plot decomposed components
9 plot(decomposed_data) 
```

Listing 13: Creating and Plotting a Multidimensional Time Series

# 3.3 Measuring Trend

The trend component of a time series reflects the long-term movement in the data. Understanding the trend is crucial for forecasting future values and identifying underlying patterns. There are several methods commonly used to measure trends:

# 3.3.1 Graphic

The graphic method, also known as the eye inspection method, is the simplest and most intuitive approach to identifying trends in time series data. This method involves the following steps:

1. **Plot the Data:** First, plot the given time series data on a graph, with time on the x-axis and the variable of interest on the y-axis.   
2. **Draw a Trend Line:** A smooth, free-hand curve is then drawn through the plotted points, representing the general tendency of the series. This curve visually highlights the trend over time.

The graphic method effectively removes short-term variations to reveal the underlying trend in the data. The trend line can also be extended to predict or estimate future values, making it a useful tool for forecasting.

# Importance of the Graphic Method

• Provides a visual and intuitive understanding of the trend.   
• Easy to implement, requiring no complex calculations.   
• Serves as a preliminary tool before applying more sophisticated methods.

# Limitations

However, it is important to note that this method is subjective, and the accuracy of the predictions may vary depending on how the trend line is drawn. As such, while the graphic method is useful for initial analysis, it should be supplemented with more rigorous statistical techniques for reliable forecasting.

# Example

Consider monthly sales data for a retail store over a year:

Table 2: Monthly Sales Data   

<table><tr><td>Month</td><td>Sales</td></tr><tr><td>Jan</td><td>100</td></tr><tr><td>Feb</td><td>120</td></tr><tr><td>Mar</td><td>140</td></tr><tr><td>Apr</td><td>160</td></tr><tr><td>May</td><td>150</td></tr><tr><td>Jun</td><td>130</td></tr><tr><td>Jul</td><td>180</td></tr><tr><td>Aug</td><td>190</td></tr><tr><td>Sep</td><td>170</td></tr><tr><td>Oct</td><td>160</td></tr><tr><td>Nov</td><td>140</td></tr><tr><td>Dec</td><td>200</td></tr></table>

In R, the plotting can be done using the following code:

```r
1 # Define the sales data  
2 sales <- c(100, 120, 140, 160, 150, 130, 180, 190, 170, 160, 140, 200)  
3 months <- 1:12  
4  
5 # Plot the sales data  
6 plot(months, sales, type = "o", col = "blue", xlab = "Month", ylab = "Sales")  
7  
8 # Add a manually drawn trend line (approximate)  
9 lines(c(1, 12), c(100, 200), col = "red", lwd = 2) 
```

![](images/5a5c74ec3c103f88a1fd4ffe7dff1bac3bc9874f0adbfa4eaa4669ad96e296d2.jpg)  
Listing 14: Creating and Plotting a Multidimensional Time Series   
Figure 6: Trend from the Data

The red line represents the overall trend in sales. Although the data fluctuates, the general upward direction is clearly visible.

# Advantages:

• Simplicity: The graphic method is one of the simplest approaches to studying trend values and is easy to implement.   
• Expertise Benefits: An experienced statistician can often draw a trend line that better represents the data than one fitted using mathematical formulas.   
• Applicability: Despite not being recommended for beginners, this method has significant merits in the hands of skilled statisticians and is widely used in practical applications.

# Disadvantages:

• Subjectivity: The method is highly subjective; the resulting trend line can vary significantly based on who draws it.   
• Skill Requirements: It requires the work to be conducted by skilled and experienced individuals to ensure accuracy.   
• Reliability Concerns: The subjective nature of this method means that predictions derived from it may not be reliable.   
• Careful Execution: Drawing the trend line must be done carefully to avoid misrepresentation of the data.

# 3.3.2 Semi-Averages

The semi-averages method involves dividing the time series data into two equal parts with respect to time. For instance, if we have data spanning from 1999 to 2016 (a total of 18 years), we would split it into two equal parts:

- The first part: 1999 to 2007 - The second part: 2008 to 2016

In cases where the number of years is odd, such as 9, 13, or 17, the middle year is omitted. For example, for 19 years of data from 1998 to 2016, the division would be:

- The first part: 1998 to 2006 - The second part: 2008 to 2016 (omitting the middle year 2007)

Once the data is divided, we calculate the arithmetic mean for each part, yielding two average values. These averages are then plotted against the mid-year of each part, and a straight line is drawn to connect the two points. This line represents the trend, which can be extended to estimate intermediate values or predict future values.

# 3.3.3 Example

Consider the following production data over several years:

Table 3: Production Data   

<table><tr><td>Year</td><td>Production</td></tr><tr><td>2001</td><td>40</td></tr><tr><td>2002</td><td>45</td></tr><tr><td>2003</td><td>40</td></tr><tr><td>2004</td><td>42</td></tr><tr><td>2005</td><td>46</td></tr><tr><td>2006</td><td>52</td></tr><tr><td>2007</td><td>56</td></tr><tr><td>2008</td><td>61</td></tr></table>

To calculate the semi-averages:

1. Divide the data: - First part (2001 to 2004): 40, 45, 40, 42 - Second part (2005 to 2008): 46, 52, 56, 61   
2. Calculate the averages: - First part average:

$$
\mathrm {A v e r a g e} _ {1} = \frac {4 0 + 4 5 + 4 0 + 4 2}{4} = \frac {1 6 7}{4} = 4 1. 7 5
$$

- Second part average:

$$
\mathrm {A v e r a g e} _ {2} = \frac {4 6 + 5 2 + 5 6 + 6 1}{4} = \frac {2 1 5}{4} = 5 3. 7 5
$$

# 3. Plotting:

- The averages (41.75 and 53.75) are plotted against the mid-years (2002.5 for the first part and 2006.5 for the second part). - A straight line is drawn connecting these two points, which represents the trend in production.

This method effectively captures the underlying trend in the data, providing a straightforward approach to trend analysis. The blue points represent the production data over the years, while the red points indicate the semi-averages calculated for the two parts. The red line shows the trend derived from these semi-averages.

![](images/b3bc881e9882c7dc0cac95d403b2c944e1885ff699171d87bfe33a7780541c4c.jpg)  
Semi-Averages Method for Trend Analysis   
Figure 7: Trend analysis using the semi-averages method.

# Advantages:

• Simplicity: This method is easier to understand compared to the moving average method and the method of least squares.   
• Objectivity: It is an objective method for measuring trends; anyone applying this method will arrive at the same results.

# Disadvantages:

• Assumption of Linearity: The method assumes a straight-line relationship between the plotted points, regardless of whether such a relationship actually exists.   
• Data Sensitivity: If additional data is added to the original dataset, the entire calculation must be redone to obtain new trend values, and the trend line will change accordingly.   
• Influence of Extremes: Since the arithmetic mean is calculated for each half, an extreme value in either half can significantly impact the points. As a result, the trend derived from these points may not be sufficiently accurate for future forecasting.

# 3.3.4 Moving Average

The moving average method is a widely used technique for computing trend values in a time series. This method effectively eliminates short-term and random fluctuations by calculating successive arithmetic means over a specified period. The period of the moving average is denoted as $m$ , where $m$ represents the number of data points included in each average.

The moving average is calculated as follows:

• The first average is the mean of the first $m$ terms.   
• The second average is the mean of the 2nd term to the $( m + 1 )$ th term.   
• The third average is the mean of the 3rd term to the $( m + 2 )$ th term, and so on.

When $m$ is odd, the moving average is associated with the mid-value of the time interval it covers. For instance, if $m = 3$ , the moving average for the first three data points will be placed against the second data point (mid-point). However, if $m$ is even, the moving average will lie between two middle periods, which do not correspond to any specific time period. To address this, a secondary calculation is performed by taking the average of the moving averages (2-yearly moving average) to align the result with a specific time period.

Example: Calculate the 3-yearly moving average for the following data.

Table 4: 3-Yearly Moving Average Calculation   

<table><tr><td>Years</td><td>Production</td><td>3-Yearly Moving Average (Trend Values)</td></tr><tr><td>2001-02</td><td>40</td><td></td></tr><tr><td>2002-03</td><td>45</td><td>40+45+40/3=41.67</td></tr><tr><td>2003-04</td><td>40</td><td>45+40+42/3=42.33</td></tr><tr><td>2004-05</td><td>42</td><td>40+42+46/3=42.67</td></tr><tr><td>2005-06</td><td>46</td><td>42+46+52/3=46.67</td></tr><tr><td>2006-07</td><td>52</td><td>46+52+56/3=51.33</td></tr><tr><td>2007-08</td><td>56</td><td>52+56+61/3=56.33</td></tr><tr><td>2008-09</td><td>61</td><td></td></tr></table>

Calculation Explanation: - For 2002-03, the moving average is calculated using the production values for 2001-02, 2002-03, and 2003-04:

$$
\mathrm {M o v i n g A v e r a g e} = \frac {4 0 + 4 5 + 4 0}{3} = 4 1. 6 7
$$

- For 2003-04, the moving average uses the values for 2002-03, 2003-04, and 2004-05:

$$
\mathrm {M o v i n g A v e r a g e} = \frac {4 5 + 4 0 + 4 2}{3} = 4 2. 3 3
$$

This process continues until the last available data point. The moving average method is useful for smoothing out short-term fluctuations in data, providing a clearer view of the long-term trend. By systematically averaging data over a specified period, this method facilitates better forecasting and analysis in various fields, including economics, sales, and environmental studies.

Conclusion: The moving average is a fundamental tool in time series analysis, allowing for a better understanding of underlying trends by reducing noise from random fluctuations.

Calculate the 4-yearly moving average for the following data.

Table 5: 4-Yearly Moving Average Calculation   

<table><tr><td>Years</td><td>Production</td><td>4-Yearly Moving Average</td><td>2-Yearly Moving Average (Trend Values)</td></tr><tr><td>2001-02</td><td>40</td><td></td><td></td></tr><tr><td>2002-03</td><td>45</td><td>40+45+40+42/4=41.75</td><td>40+45/2=42.5</td></tr><tr><td>2003-04</td><td>40</td><td>45+40+42+46/4=43.15</td><td>40+42/2=41</td></tr><tr><td>2004-05</td><td>42</td><td>40+42+46+52/4=45</td><td>42+46/2=44</td></tr><tr><td>2005-06</td><td>46</td><td>42+46+52+56/4=49</td><td>46+52/2=49</td></tr><tr><td>2006-07</td><td>52</td><td rowspan="3">46+52+56+61/4=53.75</td><td rowspan="3">52+56/2=54</td></tr><tr><td>2007-08</td><td>56</td></tr><tr><td>2008-09</td><td>61</td></tr></table>

Calculation Explanation: - For 2003-04, the 4-yearly moving average is calculated as follows:

$$
\mathrm {M o v i n g A v e r a g e} = \frac {4 0 + 4 5 + 4 0 + 4 2}{4} = 4 1. 7 5
$$

- For 2004-05, the calculation is:

$$
\text {M o v i n g A v e r a g e} = \frac {4 5 + 4 0 + 4 2 + 4 6}{4} = 4 3. 1 5
$$

- This process continues until the last available data point.

# Additional Exercise Problems:

1. Given the following production data over a 5-year period, calculate the 3-yearly moving average. Use the moving averages to identify the trend:

• 2010: 30   
• 2011: 35   
• 2012: 50   
• 2013: 45   
• 2014: 60

2. Consider the following data for sales over 6 years. Calculate the 2-yearly moving average and discuss any observed trends:

• 2015: 80   
• 2016: 90   
• 2017: 85   
• 2018: 95   
• 2019: 100   
• 2020: 110

3. A company’s quarterly earnings over two years are as follows. Calculate the 4-quarter moving average and explain any patterns you find:

• Q1 2018: 200   
• Q2 2018: 220   
• Q3 2018: 210   
• Q4 2018: 250   
• Q1 2019: 240   
• Q2 2019: 260   
• Q3 2019: 280   
• Q4 2019: 300

# Advantages:

• This method is simple to understand and easy to execute.   
• It has flexibility in application; if new data for additional time periods are added, previous calculations remain unaffected, allowing for the generation of more trend values.   
• It provides an accurate representation of the long-term trend, particularly if the trend is linear.   
• When the period of the moving average coincides with the period of oscillation (cycle), periodic fluctuations are effectively eliminated.   
• The moving average adapts to general movements in the data, with its shape determined by the actual data rather than arbitrary choices made by the statistician.   
• It is effective for smoothing out short-term fluctuations, allowing for clearer visibility of long-term trends.   
• The moving average can be easily visualized on a graph, making it a useful tool for presentations and reports.

# Disadvantages:

• For a moving average of $2 m + 1$ , no trend values are generated for the first $m$ and last $m$ periods, limiting the analysis of the entire dataset.   
• The trend path does not correspond to any specific mathematical function, making it unsuitable for forecasting or predicting future values.   
• If the underlying trend is not linear, moving averages may not accurately reflect the true tendency of the data.   
• The selection of the period for the moving average can be subjective, potentially introducing human bias into the analysis.   
• Moving averages can lag behind actual data changes, which may lead to delays in identifying trends.   
• In cases of sudden shifts or changes in the data, moving averages may provide a misleading representation of the trend, as they are based on historical data.   
• The smoothing effect of moving averages can sometimes obscure important fluctuations that may need to be addressed.

# 3.3.5 Method of Least Squares

This method is widely used in practice. It is a mathematical approach that fits a trend line to the data, satisfying the following two conditions:

1. $\sum ( Y - { \hat { Y } } ) = 0$   
2. $\sum ( Y - { \hat { Y } } ) ^ { 2 }$ is minimized.

The method of least squares relies on two fundamental conditions to ensure that the fitted line provides the best representation of the data.

1. Condition: $P ( Y - { \hat { Y } } ) = 0$

This condition states that the sum of the residuals (the differences between the observed values $Y$ and the predicted values $\hat { Y }$ ) must equal zero.

# Explanation

• Residuals: The residual for each data point is defined as $Y _ { t } - { \hat { Y } } _ { t }$ . It measures the error between the actual observation and the value predicted by the model.   
• Sum of Residuals: When we sum these residuals across all observations, the condition $P ( Y - { \hat { Y } } ) = 0$ ensures that the positive and negative errors balance out. If this condition is satisfied, it indicates that the model does not systematically overestimate or underestimate the values.   
• Mathematical Justification:

$$
\sum \left(Y _ {t} - \hat {Y} _ {t}\right) = 0
$$

This can also be derived from the optimization process, where minimizing the sum of squared deviations inherently leads to this condition.

# 2. Condition: $P ( Y - { \hat { Y } } ) ^ { 2 }$ is minimized

This condition involves minimizing the sum of the squares of the residuals.

# Explanation

• Purpose of Squaring: Squaring the residuals ensures that positive and negative errors do not cancel each other out, which could happen in the first condition. Squaring amplifies larger errors more than smaller ones, which helps in identifying models that fit better overall.   
• Objective: The objective of the least squares method is to find the parameters (like $a$ and $b$ in a linear equation) that minimize the sum of these squared differences:

$$
S = \sum \left(Y _ {t} - \hat {Y} _ {t}\right) ^ {2}
$$

• Geometric Interpretation: In a geometric sense, this condition ensures that the trend line is as close as possible to all data points, minimizing the overall distance from each point to the line.   
• Derivation: To find the best fitting line, we take the derivative of $S$ with respect to the parameters (like $a$ and $b$ ) and set these derivatives to zero. This process yields the normal equations, which can then be solved to find the optimal values of the parameters.

# Summary

Both conditions together ensure that the best-fitting line through the data not only balances the residuals (no systematic bias) but also minimizes the overall error in terms of squared differences, leading to the most accurate predictions possible within the context of a linear model. This approach is foundational in regression analysis, helping to create models that accurately reflect underlying trends in data.

Fitting a Straight Line Trend by the Method of Least Squares Let $Y _ { t }$ be the value of the time series at time $t$ . Thus, $Y _ { t }$ is the independent variable depending on $t$ .

Assume a straight line trend of the form:

$$
\hat {Y} _ {t} = a + b t
$$

where $\hat { Y } _ { t }$ designates the trend values to distinguish them from the actual $Y _ { t }$ values, $a$ is the Y-intercept, and $b$ is the slope of the trend line.

To fit a straight line trend to a time series, we assume a linear relationship of the form:

$$
Y _ {t} ^ {c} = a + b t
$$

where $Y _ { t } ^ { c }$ is the trend value at time $t$ , $a$ is the Y-intercept, and $b$ is the slope of the trend line. The goal is to estimate the parameters $a$ and $b$ such that the sum of the squared deviations between the actual values $Y _ { t }$ and the trend values $Y _ { t } ^ { c }$ is minimized:

$$
S = \sum (Y _ {t} - Y _ {t} ^ {c}) ^ {2} = \sum (Y _ {t} - (a + b t)) ^ {2}.
$$

To find the optimal values of $a$ and $b$ , we differentiate $S$ with respect to $a$ and $b$ and set the derivatives to zero. Differentiating $S$ with respect to $a$ gives:

$$
\frac {\partial S}{\partial a} = - 2 \sum (Y _ {t} - (a + b t)) = 0.
$$

Rearranging yields:

$$
\sum \left(Y _ {t} - (a + b t)\right) = 0 \Rightarrow \sum Y _ {t} = n a + b \sum t,
$$

where $n$ is the number of observations. Thus, we obtain:

$$
n a = \sum Y _ {t} - b \sum t \Rightarrow a = \frac {1}{n} \left(\sum Y _ {t} - b \sum t\right).
$$

Substituting this back into the equation of $Y _ { t } ^ { c }$ leads to a simplified expression for $a$

Next, we differentiate $S$ with respect to $b$ :

$$
\frac {\partial S}{\partial b} = - 2 \sum t (Y _ {t} - (a + b t)) = 0.
$$

Rearranging gives:

$$
\sum t (Y _ {t} - (a + b t)) = 0 \Rightarrow \sum t Y _ {t} = a \sum t + b \sum t ^ {2}.
$$

This can be rearranged to yield:

$$
b = \frac {\sum t Y _ {t} - a \sum t}{\sum t ^ {2}}.
$$

The resulting normal equations from this process are:

(1) (11)   
(2) (12)

Solving these two normal equations will yield the estimates $\hat { a }$ and $\hat { b }$ .

If we wish to fit a parabolic trend of the form:

$$
Y _ {t} ^ {c} = a + b t + c t ^ {2},
$$

we differentiate $S$ with respect to $c$ as well:

$$
\frac {\partial S}{\partial c} = - 2 \sum \left(Y _ {t} - (a + b t + c t ^ {2})\right) t ^ {2} = 0.
$$

Rearranging yields:

$$
\sum (Y _ {t} - (a + b t + c t ^ {2})) t ^ {2} = 0 \Rightarrow \sum t ^ {2} Y _ {t} = a \sum t ^ {2} + b \sum t ^ {3} + c \sum t ^ {4}.
$$

The normal equations for the parabolic trend can be summarized as:

(1) (13)   
(2) (14)   
(3) (15)

Solving these three equations provides the values of $\hat { a }$ , $\hat { b }$ , and $\hat { c }$ . Substituting these values into the equation for the parabolic trend gives:

$$
Y _ {t} ^ {c} = \hat {a} + \hat {b} t + \hat {c} t ^ {2}.
$$

To assess the appropriateness of the parabolic trend model, one can use the method of second differences. If the second differences are constant (or nearly constant), the quadratic equation is a suitable representation of the trend component.

llustration14.The prices of a commodity during 20o2-20o7 are given below.Fita parabola $Y = a + b X + c X ^ { 2 }$ tothese data.Estimate theprice of the commodity for the year 2008

<table><tr><td>Year</td><td>Prices</td><td>Year</td><td>Prices</td></tr><tr><td>2002</td><td>100</td><td>2005</td><td>140</td></tr><tr><td>2003</td><td>107</td><td>2006</td><td>181</td></tr><tr><td>2004</td><td>128</td><td>2007</td><td>192</td></tr></table>

Also plot the actual and trend values on the graph.（B.Com（H).DU:M.Com.M.D.Univ.）

<table><tr><td>Year</td><td>Prices
(Rs.)</td><td>X</td><td>x2</td><td>x3</td><td>x4</td><td>XY</td><td>x2y</td><td>Trend
Values
(Yc)</td></tr><tr><td>2002</td><td>100</td><td>-2</td><td>4</td><td>-8</td><td>16</td><td>-200</td><td>400</td><td>97.717</td></tr><tr><td>2003</td><td>107</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td>-107</td><td>107</td><td>110.401</td></tr><tr><td>2004</td><td>128</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>126.657</td></tr><tr><td>2005</td><td>140</td><td>+1</td><td>1</td><td>+1</td><td>1</td><td>+140</td><td>140</td><td>146.485</td></tr><tr><td>2006</td><td>181</td><td>+2</td><td>4</td><td>+8</td><td>16</td><td>+362</td><td>724</td><td>169.885</td></tr><tr><td>2007</td><td>192</td><td>+3</td><td>9</td><td>+27</td><td>81</td><td>+576</td><td>1728</td><td>196.857</td></tr><tr><td>N=6</td><td>ΣY=848</td><td>ΣX=3</td><td>ΣX2=19</td><td>ΣX3=27</td><td>ΣX4=115</td><td>ΣXY=771</td><td>ΣX2y=3,099</td><td>ΣYc=848.002</td></tr><tr><td colspan="9">Multiplying the second equation by 2 and keeping the first as it is, we get</td></tr><tr><td>or</td><td colspan="7">35 b+35 c=694</td><td>...(IV)</td></tr><tr><td colspan="9">Multiplying Eqn. (II) by 19 and Eqn. (III) by 3, we get</td></tr><tr><td>or</td><td colspan="8">14,649=57 a+361 b+513 c</td></tr><tr><td colspan="9">Solving equations (IV) and (V)</td></tr><tr><td>or</td><td colspan="8">280 b+280 c=5,552</td></tr><tr><td colspan="9">Substituting the value of c in Eqn. (IV),</td></tr><tr><td>or</td><td colspan="8">35 b+(35×1.786)=694</td></tr><tr><td colspan="9">35 b=694-62.5=631.5 or b=18.042</td></tr><tr><td colspan="9">848=6 a+3 (18.042)+19 (1.786)=6 a+54.126+33.934</td></tr><tr><td colspan="9">6 a=759.94 or a=126.657</td></tr><tr><td>Thus</td><td colspan="8">a=126.657, b=18.042 and c=1.786</td></tr><tr><td colspan="9">Substituting these values in the equation,</td></tr><tr><td>when X=-2</td><td colspan="8">Y=126.657+18.042 X+1.786 X2</td></tr><tr><td>when X=-1</td><td colspan="8">Y=126.657+18.042 (-2)+1.786 (-2)2=126.657-36.084+7.144=97.717</td></tr><tr><td>when X=1</td><td colspan="8">Y=126.657+18.042 (-1)+1.786 (-1)2=126.657-18.042+1.786=110.401</td></tr></table>

$Y = 126.657 + 18.042 + 1.786 = 146.485$ when $X = 2$ $Y = 126.657 + 18.042(2) + 1.786(2)^{2} = 169.885$ when $X = 3$ $Y = 126.657 + 18.042(3) + 1.786(3)^{2} = 196.857$ Price for the year 2008 For 2008 $X$ would be equal to 4. Putting $X = 4$ in the equation, $Y = 126.657 + 18.042(4) + 1.786(4)^{2}$ $= 126.657 + 72.168 + 28.576 = 227.401.$ Thus the likely price of the commodity for the year 2008 is Rs. 227.41 approx. The graph of the actual and trend values is given below:

![](images/a36cca10aa5790df99a2690b3b73ce69dbaad7757ddf584db3081969c07aa4ce.jpg)

# Advantages

• This is a mathematical method of measuring trend, and as such, there is no possibility of subjectiveness; i.e., everyone who uses this method will get the same trend line.   
• The line obtained by this method is called the line of best fit.   
• Trend values can be obtained for all the given time periods in the series.

# Disadvantages

• Great care should be exercised in selecting the type of trend curve to be fitted, i.e., linear, parabolic, or some other type. Carelessness in this respect may lead to wrong results.   
• The method is more tedious and time-consuming.   
• Predictions are based only on long-term variations, i.e., trend, and the impact of cyclical, seasonal, and irregular variations is ignored.   
• This method cannot be used to fit growth curves like the Gompertz curve:

$$
Y = K a ^ {b ^ {X}}, \tag {16}
$$

or the logistic curve:

$$
Y = \frac {K}{1 + a b ^ {- X}}. \tag {17}
$$

# Question Bank

1. Define a time series and elaborate on its fundamental components.   
2. Discuss the notion of a secular trend in a time series and outline the methods employed to isolate it.   
3. Explain the moving average method used for trend determination, including its advantages and disadvantages.   
4. Analyze the graphic method and the least squares method for trend analysis, emphasizing their respective advantages and disadvantages.   
5. Provide a brief overview of the moving averages method for calculating trends.   
6. In what ways does time series analysis support business forecasting?   
7. Distinguish between secular trends, seasonal variations, and cyclical fluctuations, and describe the various methods used to measure each.   
8. Summarize the additive and multiplicative models of time series. Which of these models is more prevalent in practice, and why?   
9. Explain the process of determining seasonal variation using a 12-month moving average.   
10. What methods are available for identifying trends in a time series?   
11. Describe the least squares method for trend determination in detail.   
12. Given the production data of steel in a factory over the past 10 years, fit a straight-line trend and tabulate the trend values. Estimate the production for the year 1997 based on the trend:

• Year: 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996   
• Production (tonnes): 75, 86, 98, 90, 96, 108, 124, 140, 150, 165

13. Fit a straight-line trend for the following data using the least squares method and estimate production for the year 1997:

• Year: 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996   
• Production (tonnes): 12, 13, 13, 16, 19, 23, 21, 23

14. Fit a straight-line trend using the least squares method for the following data and estimate production for the year 2000:

• Year: 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997   
• Production (tonnes): 38, 40, 65, 72, 69, 67, 95, 104

15. Calculate the trend using a 4-year moving average from the following data and identify short-term oscillations:

<table><tr><td>Year</td><td>Production in Tonnes</td></tr><tr><td>1984</td><td>5</td></tr><tr><td>1985</td><td>6</td></tr><tr><td>1986</td><td>7</td></tr><tr><td>1987</td><td>7</td></tr><tr><td>1988</td><td>6</td></tr><tr><td>1989</td><td>8</td></tr><tr><td>1990</td><td>9</td></tr><tr><td>1991</td><td>10</td></tr><tr><td>1992</td><td>9</td></tr><tr><td>1993</td><td>10</td></tr><tr><td>1994</td><td>11</td></tr><tr><td>1995</td><td>11</td></tr></table>

# Module - 2

# Chapter - 1

# 4 Correlation

In time series analysis, understanding correlation after removing trend and seasonal effects is essential. We start with fundamental concepts of expectation, the ensemble, stationarity, and ergodicity.

# 4.1 Expectation and the ensemble

The expected value or expectation, $\mathbb { E } ( x )$ , represents the average of a variable $x$ over a population. The expected value of $x$ , denoted $\mu$ , is:

$$
\mathbb {E} (x) = \mu .
$$

For a random variable $x$ , the variance is the expected value of the squared deviation from the mean:

$$
\mathbb {E} \left[ (x - \mu) ^ {2} \right] = \sigma^ {2},
$$

where $\sigma ^ { 2 }$ is the variance, and $\sigma$ is the standard deviation.

For two variables, $x$ and $y$ , the covariance $\gamma ( x , y )$ is:

$$
\gamma (x, y) = \mathbb {E} [ (x - \mu_ {x}) (y - \mu_ {y}) ],
$$

which measures the linear association between them.

Covariance and correlation are key concepts in time series analysis. Covariance measures the linear association between two variables, and correlation standardizes this measure, giving a dimensionless value between -1 and 1. In this section, we will explain these concepts using an example from a study that analyzed air quality in Manhattan. The covariance between two variables $x$ and $y$ is defined as:

$$
\gamma (x, y) = \mathbb {E} [ (x - \mu_ {x}) (y - \mu_ {y}) ],
$$

where $\mu _ { x }$ and $\mu _ { y }$ are the means of $x$ and $y$ , respectively. The sample covariance, which provides an estimate from observed data, is given by:

$$
\operatorname {C o v} (x, y) = \frac {1}{n - 1} \sum_ {i = 1} ^ {n} \left(x _ {i} - \bar {x}\right) \left(y _ {i} - \bar {y}\right),
$$

where $n$ is the number of data pairs and $x , y$ are the sample means of $x$ and $y$ .

# Example: Air Quality at Herald Square

A real-world example involves the study by Colucci and Begeman (1971), who analyzed air samples from Herald Square, Manhattan. The data included carbon monoxide (CO) concentration $x$ (in parts per million) and benzoapyrene concentration $y$ (in micrograms per thousand cubic meters), both byproducts of incomplete combustion. The following R code calculates the covariance between these two variables:

# R Code for Covariance

```txt
1 # Load the Herald Square data   
2 www <- "http://www.massey.ac.nz/~pscowper/ts/Herald.dat"   
3 Herald.dat <- read.table(www, header = T)   
4 attach(Herald.dat)   
5   
6 # Calculate covariance manually and using the function 
```

```txt
7 x<-CO; y<-Benzoa; n<-length(x)   
8   
9 #Manual calculation   
10 manual_cov<-sum((x-meansx）\*y-means(y)))/ (n-1)   
11 manual_cov   
12 #Using cov() function   
13 cov_value<-cov(x,y)   
14 cov_value 
```

The manual calculation of covariance yields the same result as the built-in ‘cov()‘ function, showing a covariance value of 5.51.

# Explanation of Covariance

Covariance indicates how two variables move together. If both $x$ and $y$ increase together, the covariance is positive. Conversely, if one increases while the other decreases, the covariance is negative. In the Herald Square data, a covariance of 5.51 suggests that there is a moderate positive association between carbon monoxide and benzoapyrene levels. While covariance provides a measure of association, it depends on the units of the variables, making it difficult to compare across datasets. Correlation resolves this by standardizing covariance. The population correlation $\rho ( x , y )$ is defined as:

$$
\rho (x, y) = \frac {\gamma (x , y)}{\sigma_ {x} \sigma_ {y}},
$$

where $\sigma _ { x }$ and $\sigma _ { y }$ are the standard deviations of $x$ and $y$ . The sample correlation is calculated as:

$$
\operatorname {C o r} (x, y) = \frac {\operatorname {C o v} (x , y)}{s d (x) \cdot s d (y)}.
$$

# R Code for Correlation

```txt
1 # Calculate correlation manually and using cor() function  
2 manual(cor <- cov(x, y) / (sd(x) * sd(y))  
3 manual-cor  
4  
5 # Using cor() function  
6 cor_value <- cor(x, y)  
7 cor_value 
```

Both methods calculate the correlation between CO and benzoapyrene as 0.3551. Correlation values range between -1 and 1. A value of 1 indicates a perfect positive linear relationship, -1 indicates a perfect negative relationship, and 0 means no linear association. In this example, the correlation of 0.3551 suggests a weak to moderate positive linear relationship between CO and benzoapyrene levels.

# Graphical Interpretation

We can visualize the relationship between CO and benzoapyrene by plotting the data points and adding a regression line:

```python
1 # Plot the data  
2 plot(CO, Benzoa, main="CO vs Benzoapyrene",  
3 xlab="CO Concentration (ppm)", ylab="Benzoapyrene (micrograms)"  
4 abline(lm(Benzoa ~ CO), col="red") 
```

![](images/e712a126a12ce3cdb9d3af04a4248b777c625921453b30fa759ae8762462bfe1.jpg)  
Figure 8: Scatter plot of CO concentration vs Benzoapyrene concentration, with regression line.

The scatter plot shows a weak upward trend, confirming the positive correlation observed in the data. The red line represents a simple linear regression that best fits the data.

# 4.1.1 The Ensemble and Stationarity

The ensemble refers to the entire population of all possible time series realizations from a model. The mean function of a time series $\{ x _ { t } \}$ is:

$$
\mu (t) = \mathbb {E} [ x _ {t} ].
$$

In practice, we typically have only one realization of the time series, so we estimate the mean at each time point. A series is stationary if its mean is constant over time, i.e., $\mu ( t ) = \mu$ , for all $t$ .

If the mean function is constant, we say that the time series model is stationary in the mean. The sample estimate of the population mean, $\mu$ , is the sample mean, denoted $x$ :

$$
\bar {x} = \frac {1}{n} \sum_ {t = 1} ^ {n} x _ {t}
$$

This equation assumes that a sufficiently long time series characterizes the hypothetical model. Such models are known as ergodic models, where time averages are representative of population averages.

The expectation in this definition is an average taken across the ensemble of all the possible time series that might have been produced by the time series model in figure 9

![](images/aac9fd2591e373b42517af4fe149b6e181b88bf8fb76b09e93a36e1cf7102612.jpg)  
Figure 9: An ensemble of time series. The expected value $E ( x _ { t } )$ at a particular time $t$ is the average taken over the entire population.

# 4.1.2 Ergodic Series

A time series model that is stationary in the mean is ergodic in the mean if the time average for a single time series tends to the ensemble mean as the length of the time series increases then:

$$
\lim _ {n \to \infty} \frac {1}{n} \sum_ {t = 1} ^ {n} x _ {t} = \mu
$$

This implies that the time average is independent of the starting point. Given that we usually only have a single time series, one might wonder how a time series model can fail to be ergodic, or why we would want a model that is not ergodic.

Environmental and economic time series are typically single realizations of a hypothetical time series model, which we often define as ergodic. However, there are cases where multiple time series can arise from the same model. For instance, when investigating the acceleration at the pilot seat of a microlight aircraft design in a wind tunnel with simulated random gusts, two prototypes built to the same design may show slightly different average acceleration responses due to manufacturing differences. In such a case, the number of time series corresponds to the number of prototypes. Another example is the study of turbulent flows in a complex system where different runs may yield qualitatively different results based on initial conditions. In such experiments, it is often preferable to perform multiple runs rather than extending a single run over a long period. The number of runs corresponds to the number of time series. A stationary time series model can be adapted to be non-ergodic by defining the means of individual time series to follow a probability distribution.

# 4.2 Variance function

The variance function of a time series model that is stationary in the mean is defined as:

$$
\sigma^ {2} (t) = E \left[ \left(x _ {t} - \mu\right) ^ {2} \right]
$$

This equation suggests that the variance, $\sigma ^ { 2 } ( t )$ , could potentially take different values at each time point $t$ . However, from a single time series, it is not feasible to estimate a different variance at every point in time. Therefore, to make progress, we introduce a simplifying assumption: if the model is stationary in the variance, we can assume the variance is constant across time, denoted as $\sigma ^ { 2 }$ . In this case, we estimate the population variance using the sample variance:

$$
\operatorname {V a r} (x) = \frac {\sum (x _ {t} - \bar {x}) ^ {2}}{n - 1}
$$

In time series analysis, sequential observations may be correlated, particularly when the correlation is positive. As a result, the sample variance, $\mathrm { V a r } ( x )$ , may underestimate the true population variance, especially in short time series, because consecutive observations tend to be similar. However, this bias decreases quickly as the length of the time series, $n$ , increases.

# 4.2.1 Autocorrelation

The mean and variance play an important role in understanding statistical distributions because they summarize two key aspects: the central tendency (mean) and the spread (variance). Similarly, in time series analysis, we focus on second-order properties, which include the mean, variance, and serial correlation.

Consider a time series model that is stationary in both the mean and variance. In such models, variables may be correlated, and the model is called second-order stationary if the correlation between variables depends only on the number of time steps between them. This time difference is referred to as the lag.

When a variable is correlated with itself at different time points, this is called autocorrelation or serial correlation. For a second-order stationary time series model, we can define an autocovariance function (acvf) $\gamma _ { k }$ as a function of the lag $k$ :

$$
\gamma_ {k} = E \left[ \left(x _ {t} - \mu\right) \left(x _ {t + k} - \mu\right) \right]
$$

Here, $\gamma _ { k }$ does not depend on the specific time $t$ because the expectation is the same across all time points. This formula is a natural extension of the covariance formula, where we now compare $x _ { t }$ with $x _ { t + k }$ . Next, we define the autocorrelation function (acf) at lag $k$ , denoted as $\rho _ { k }$ , by dividing the autocovariance by the variance:

$$
\rho_ {k} = \frac {\gamma_ {k}}{\sigma^ {2}}
$$

From this definition, it follows that $\rho _ { 0 } = 1$ , meaning that the correlation of a variable with itself at the same time point is always 1.

In time series analysis, we often estimate the autocovariance function and autocorrelation function from the sample data. The sample autocovariance function (sample acvf), denoted as $c _ { k }$ , is given by:

$$
c _ {k} = \frac {1}{n} \sum_ {t = 1} ^ {n - k} \left(x _ {t} - \bar {x}\right) \left(x _ {t + k} - \bar {x}\right)
$$

Note that the sample autocovariance at lag $0$ , $c _ { 0 }$ , is just the variance of the data. The denominator $n$ is used when calculating $c _ { k }$ , although only $n - k$ terms are summed in the numerator. Finally, the sample autocorrelation function (sample acf) is defined as:

$$
r _ {k} = \frac {c _ {k}}{c _ {0}}
$$

We will now illustrate these calculations using an example in R. The data consists of wave heights (in millimeters, relative to still water level) measured in a wave tank. The sampling interval is 0.1 seconds, and the total recording length is 39.7 seconds. The waves were generated by a wave maker using a pseudo-random signal to mimic a rough sea. Since there is no trend or seasonal component, we assume that this time series is a realization of a stationary process.

# R Example: Autocovariance and Autocorrelation for Wave Height Data

First, let’s load the time series data and plot it to visually inspect the stationarity of the process.

```r
1 # Load necessary libraries  
2 library(tseries)  
3  
4 # Simulate wave height data (for illustration purposes)  
5 set.seed(123)  
6 n <- 398 # Number of observations  
7 time_interval <- 0.1 # Sampling interval in seconds  
8 time_series <- ts(arima.sim(model = list(ar = 0.7), n = n), frequency = 1/time_interval)  
9  
10 # Plot the wave height data  
11 plot(time_series, main = "Wave Heights (mm) Over Time", ylab = "Height (mm)", xlab = "Time (seconds))") 
```

![](images/361e377ca2ca7e6aa60ae7ffe8d11d385aaf802b3208adf86dee5198959dd304.jpg)  
Wave Heights (mm) Over Time   
Figure 10: Wave Heights (mm) Over Time

Next, we calculate the sample autocovariance function (acvf) at different lags using the acf function, which also gives the sample autocorrelation (acf).

```r
1 # Load necessary libraries
2 # install.packages("ggplot2") # Uncomment if ggplot2 is not installed
3 library(ggplot2)
4
5 # Simulated time series of wave heights
6 # waveht <- ... # Assume this is your time series data
7
8 # Calculate and plot sample autocovariance and autocorrelation
9acf(time_series, type = "covariance", main = "Sample Autocovariance Function")
10acf(time_series, type = "correlation", main = "Sample Autocorrelation Function")
11
12 # Plot wave heights against their lagged values
13 plot(waveht[1:396], waveht[2:397],
xlab = "Wave Height at time t",
ylab = "Wave Height at time t + 1",
main = "Wave Heights at Lag 1",
pch = 19,
col = "blue")
abline(1m(waveht[2:397] ~ waveht[1:396]), col = "red") # Add regression line 
```

To manually compute the sample autocovariance and autocorrelation at lag $k = 1$ , we use the following steps:

```txt
1 # Mean of the time series   
2 x_mean<- mean(time_series)   
3   
4 # Sample autocovariance at lag 1   
5 k<-1   
6 n_k<-length(time_series)-k   
7 sample_acvf<-sum((time_series[1:n_k]-x_mean)*(time_series[(1+k):length(time_series)]-x_ mean))/n   
8   
9 # Sample autocorrelation at lag 1   
10 sample_acf<-sample_acvf/var(time_series)   
11   
12 # Print the results   
13 sample_acvf   
14 sample_acf 
```

# Sample Output

Assuming we have the following simulated time series data, the output for the calculations will be:

> sample_acvf

[1] 0.20754 # Sample autocovariance at lag 1

> sample_acf

[1] 0.58783 # Sample autocorrelation at lag 1

These values indicate that at lag $k = 1$ , the sample autocovariance is approximately 0.20754, and the sample autocorrelation is approximately 0.58783. This suggests a moderate positive correlation between the values of the time series that are one time step apart. The acf function computes the autocovariance and autocorrelation functions for all lags, and the results are automatically constrained to lie between $^ { - 1 }$ and 1. The sample acvf and acf calculated manually for lag 1 will match those obtained by the acf function.

![](images/94cc5f6f6e48c3d75f23bdc93b1dd11f203db2293e2a9260d1b74975fd7da31c.jpg)  
Sample Autocorrelation Function   
Figure 11: Auto-correlation Plot of Wave Data

# Interpretation

From the plot of the autocorrelation function (acf), we can determine the degree of serial correlation at different lags. If the autocorrelation decays slowly, this indicates that the process is highly persistent over time. A rapid decay, on the other hand, suggests weaker serial correlation.

# 4.3 correlogram, covariance of sum of random variables

# 4.3.1 General discussion

By default, the acf function produces a plot of $r _ { k }$ against $k$ , which is called the correlogram. For example, Figure 11 gives the correlogram for the wave heights obtained from acf(waveht). In general, correlograms have the follow- ing features:

• Axes:

– X-axis: Lag (k) in sampling intervals (0.1 seconds).   
– Y-axis: Autocorrelation ( $r _ { k }$ ), which is dimensionless.

• Null Hypothesis Testing:

– If the true autocorrelation $\rho _ { k } = 0$ , the distribution of $r _ { k }$ is approximately normal with:

$$
\mathrm {M e a n} = - \frac {1}{n}, \quad \mathrm {V a r i a n c e} = \frac {1}{n}
$$

– Dotted lines are drawn at:

$$
- \frac {1}{n} \pm 2 \sqrt {\frac {1}{n}}
$$

– If $r _ { k }$ falls outside these lines, the null hypothesis is rejected at the 5% significance level. However, about 5% of values will fall outside these lines even when $\rho _ { k } = 0$ .

• Lag 0 Autocorrelation:

– Always equals 1, aiding in the comparison of other autocorrelation values.   
– Squaring the autocorrelation gives the percentage of variability explained by a linear relationship. For example, a lag 1 autocorrelation of 0.1 explains only 1% of the variability.

• Autocorrelation Patterns:

– The correlogram from an autoregressive model of order 2 typically shows a damped cosine shape.   
– Non-stationary series (e.g., air passenger bookings) can still have their sample autocorrelation function (ACF) calculated.

• Deterministic Signals and ACF Behavior:

– Trend-only Series: Slow, nearly linear decay from 1.   
– Discrete Sinusoidal Wave: Produces a discrete cosine pattern.   
– Repeated Sequence of $p$ Numbers: Displays a spike near lag $p$

• Trends in Data:

– Gradual decay of autocorrelations indicates a trend.   
– For the air passenger bookings, an annual cycle is observed in the ACF:

$^ *$ Maximum at lag 12 (positive correlation).   
∗ Dip at lag 6 (negative correlation), reflecting seasonal patterns.

# 4.3.2 Example based on air passenger series

Although we want to know about trends and seasonal patterns in a time series, we do not necessarily rely on the correlogram to identify them. The main use of the correlogram is to detect autocorrelations in the time series after we have removed an estimate of the trend and seasonal variation.

In the code below, the air passenger series is seasonally adjusted, and the trend is removed using the decompose function. To plot the random component and draw the correlogram, we must remember that a consequence of using a centred moving average of 12 months to smooth the time series, and thereby estimate the trend, is that the first six and last six terms in the random component cannot be calculated and are thus stored in R as NA. The random component and correlogram are shown in Figures 13 and 14, respectively.

![](images/deae10fe8c299fde41003604949c2382c3ff99b094860701054c559a1eacff28.jpg)  
Figure 12: Correlogram for the air passenger bookings over the period 1949–1960. The gradual decay is typical of a time series containing a trend. The peak at 1 year indicates seasonal variation.

data ( AirPassengers )   
2 AP <- AirPassengers   
3 AP . decom <- decompose ( AP , " multiplicative ")   
4 plot (ts( AP . decom $ random [7:138]) )   
5 acf ( AP . decom $ random [7:138])

![](images/b4f07bb221e29ef9d635f0eea6611d143e66ef0fbfdc7011866fb5cd4a243f25.jpg)  
Figure 13: The random component of the air passenger series after removing the trend and the seasonal variation.

The correlogram in Figure 14 suggests either a damped cosine shape that is characteristic of an autoregressive model of order 2 or that the seasonal adjustment has not been entirely effective. The latter explanation is unlikely because the decomposition does estimate twelve independent monthly indices. If we investigate further, we see that the standard deviation of the original series from July until June is:

Output: 109   
```txt
2 # Calculate the standard deviation of the original series
3 sd-original <- sd(AP[7:138])
4 sd-original 
```

Output: 41.1   
```python
1 # Decompose the time series
2 AP.decom <- decompose(AP, "multiplicative")
3
4 # Calculate the standard deviation after subtracting the trend
5 sd_trend_adjusted <- sd(AP[7:138] - AP.decom\(trend[7:138])
6 sd_trend_adjusted 
```

And the standard deviation after seasonal adjustment is:

Output: 0.0335   
```txt
1 # Calculate the standard deviation of the random component
2 sd_random <- sd(AP.decom\\(random[7:138])
3 sd_random 
```

The reduction in the standard deviation shows that the seasonal adjustment has been very effective.

![](images/aeacc3629040a89c7686480884a9e22701eb20d81b98610cce385ad4cf982dfd.jpg)  
Figure 14: Correlogram for the random component of air passenger bookings over the period 1949–1960.

# Module - 2

# Chapter - 2

# 5 Seasonal Variation

Seasonal variations are regular and periodic variations having a period of one year duration. Some of the examples which show seasonal variations are production of cold drinks, which are high during summer months and low during winter season. Sales of sarees in a cloth store which are high during festival season and low during other periods. The reason for determining seasonal variations in a time series is to isolate it and to study its effect on the size of the variable in the index form which is usually referred as seasonal index. There are different devices to measure seasonal variations, including:

• Method of Simple Averages   
• Ratio to Trend Method   
• Ratio to Moving Average Method   
• Link Relative Method

# 5.1 Method of Simple Averages

The method of simple averages is one of the simplest techniques for measuring seasonality. It is based on the additive model of time series, expressed as follows:

$$
Y _ {t} = T _ {t} + C _ {t} + S _ {t} + R _ {t}
$$

In this model, we assume that the trend component ( $T _ { t }$ ) and the cyclical component ( $C _ { t }$ ) are absent. The method consists of the following steps:

• Arrange the data by years and months (or quarters if quarterly data is given).   
• Compute the average $x _ { i }$ for the $i$ -th month or quarter across all years:

– For monthly data $i = 1 , 2 , \ldots , 1 2$ ):

$$
\bar {x} = \frac {1}{1 2} \sum_ {i = 1} ^ {1 2} x _ {i}
$$

– For quarterly data $\cdot i = 1 , 2 , 3 , 4$ ):

$$
\bar {x} = \frac {1}{4} \sum_ {i = 1} ^ {4} x _ {i}
$$

• Seasonal indices for different months (or quarters) are obtained by expressing the monthly (or quarterly) averages as percentages of $x$ . Thus, the seasonal index for the $i$ -th month (or quarter) is calculated as:

$$
\text {S e a s o n a l I n d e x} _ {i} = \frac {x _ {i}}{\bar {x}} \times 1 0 0
$$

# Advantages

# • Simplicity:

– The method is straightforward and easy to understand, making it accessible for practitioners with varying levels of statistical expertise.   
– No complex calculations or statistical software are required; basic arithmetic suffices.

# • Time Efficiency:

– It requires minimal time to implement, allowing for quick seasonal adjustments in data analysis.   
– Suitable for businesses needing rapid assessments of seasonal trends without extensive data processing.

# • Clarity of Results:

– The results, represented as seasonal indices, provide a clear and intuitive understanding of seasonal variations.   
– Stakeholders can easily interpret seasonal indices, facilitating communication of insights.

# • No Need for Advanced Techniques:

– Useful in cases where advanced statistical techniques are not available or practical.   
– Serves as a preliminary analysis tool before employing more sophisticated methods.

# Disadvantages

# • Assumption of No Trend or Cycles:

– The method assumes that the data does not contain any underlying trends or cyclical components.   
– In real-world scenarios, many time series exhibit significant trends, which can distort the results.

# • Limited Applicability:

The method may not be suitable for data with strong seasonal patterns, as it can lead to misleading conclusions.   
– Economic and business time series often include seasonal and cyclical variations, which are not adequately addressed by this method.

# • Sensitivity to Outliers:

– The method is susceptible to outliers or extreme values, which can disproportionately affect average calculations.   
– This sensitivity may result in skewed seasonal indices that do not accurately represent underlying trends.

# • Ignores Interactions:

– The method does not consider potential interactions between seasonal effects and other variables, limiting its explanatory power.   
– It provides a simplistic view of seasonality, lacking the depth of analysis found in more advanced methods.

# • Static Nature:

– The method produces static seasonal indices that may not adapt to changing patterns over time.   
– As market conditions or consumer behavior evolves, these indices may become outdated and less relevant.

# Example - 1

Consider the following monthly sales data for a product over three years:

<table><tr><td>Month</td><td>Year 1</td><td>Year 2</td><td>Year 3</td></tr><tr><td>January</td><td>120</td><td>130</td><td>140</td></tr><tr><td>February</td><td>115</td><td>125</td><td>135</td></tr><tr><td>March</td><td>140</td><td>150</td><td>160</td></tr><tr><td>April</td><td>160</td><td>170</td><td>180</td></tr><tr><td>May</td><td>170</td><td>180</td><td>190</td></tr><tr><td>June</td><td>200</td><td>210</td><td>220</td></tr><tr><td>July</td><td>190</td><td>200</td><td>210</td></tr><tr><td>August</td><td>180</td><td>190</td><td>200</td></tr><tr><td>September</td><td>160</td><td>170</td><td>180</td></tr><tr><td>October</td><td>150</td><td>160</td><td>170</td></tr><tr><td>November</td><td>130</td><td>140</td><td>150</td></tr><tr><td>December</td><td>120</td><td>130</td><td>140</td></tr></table>

# Step 1: Calculate Monthly Averages

Calculate the average sales for each month:

$$
x _ {1} = \frac {1 2 0 + 1 3 0 + 1 4 0}{3} = 1 3 0 \quad (\text {J a n u a r y})
$$

$$
x _ {2} = \frac {1 1 5 + 1 2 5 + 1 3 5}{3} = 1 2 5 \quad (\text {F e b r u a r y})
$$

$$
x _ {3} = \frac {1 4 0 + 1 5 0 + 1 6 0}{3} = 1 5 0 \quad (\text {M a r c h})
$$

$$
x _ {4} = \frac {1 6 0 + 1 7 0 + 1 8 0}{3} = 1 7 0 \quad (\text {A p r i l})
$$

$$
x _ {5} = \frac {1 7 0 + 1 8 0 + 1 9 0}{3} = 1 8 0 \quad (\text {M a y})
$$

$$
x _ {6} = \frac {2 0 0 + 2 1 0 + 2 2 0}{3} = 2 1 0 \quad (\text {J u n e})
$$

$$
x _ {7} = \frac {1 9 0 + 2 0 0 + 2 1 0}{3} = 2 0 0 \quad (J u l y)
$$

$$
x _ {8} = \frac {1 8 0 + 1 9 0 + 2 0 0}{3} = 1 9 0 \quad (\text {A u g u s t})
$$

$$
x _ {9} = \frac {1 6 0 + 1 7 0 + 1 8 0}{3} = 1 7 0 \quad (\text {S e p t e m b e r})
$$

$$
x _ {1 0} = \frac {1 5 0 + 1 6 0 + 1 7 0}{3} = 1 6 0 \quad (\text {O c t o b e r})
$$

$$
x _ {1 1} = \frac {1 3 0 + 1 4 0 + 1 5 0}{3} = 1 4 0 \quad (\text {N o v e m b e r})
$$

$$
x _ {1 2} = \frac {1 2 0 + 1 3 0 + 1 4 0}{3} = 1 3 0 \quad (\text {D e c e m b e r})
$$

# Step 2: Calculate Overall Average

Calculate the overall average $x$ :

$$
\bar {x} = \frac {1}{1 2} \sum_ {i = 1} ^ {1 2} x _ {i} = \frac {1 3 0 + 1 2 5 + 1 5 0 + 1 7 0 + 1 8 0 + 2 1 0 + 2 0 0 + 1 9 0 + 1 7 0 + 1 6 0 + 1 4 0 + 1 3 0}{1 2} = \frac {2 0 7 5}{1 2} \approx 1 7 2. 9 2
$$

# Step 3: Calculate Seasonal Indices

Now, calculate the seasonal indices for each month:

$$
\text {S e a s o n a l I n d e x} _ {\text {J a n u a r y}} = \frac {1 3 0}{1 7 2 . 9 2} \times 1 0 0 \approx 7 5. 2 3
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {F e b r u a r y}} = \frac {1 2 5}{1 7 2 . 9 2} \times 1 0 0 \approx 7 2. 2 9
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {M a r c h}} = \frac {1 5 0}{1 7 2 . 9 2} \times 1 0 0 \approx 8 6. 6 6
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {A p r i l}} = \frac {1 7 0}{1 7 2 . 9 2} \times 1 0 0 \approx 9 8. 3 3
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {M a y}} = \frac {1 8 0}{1 7 2 . 9 2} \times 1 0 0 \approx 1 0 4. 1 1
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {J u n e}} = \frac {2 1 0}{1 7 2 . 9 2} \times 1 0 0 \approx 1 2 1. 4 3
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {J u l y}} = \frac {2 0 0}{1 7 2 . 9 2} \times 1 0 0 \approx 1 1 5. 6 5
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {A u g u s t}} = \frac {1 9 0}{1 7 2 . 9 2} \times 1 0 0 \approx 1 0 9. 9 3
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {S e p t e m b e r}} = \frac {1 7 0}{1 7 2 . 9 2} \times 1 0 0 \approx 9 8. 6 6
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {O c t o b e r}} = \frac {1 6 0}{1 7 2 . 9 2} \times 1 0 0 \approx 9 2. 5 9
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {N o v e m b e r}} = \frac {1 4 0}{1 7 2 . 9 2} \times 1 0 0 \approx 8 0. 9 5
$$

$$
\text {S e a s o n a l I n d e x} _ {\text {D e c e m b e r}} = \frac {1 3 0}{1 7 2 . 9 2} \times 1 0 0 \approx 7 5. 2 3
$$

This example illustrates how to use the method of simple averages to calculate seasonal indices, which can help analyze seasonal patterns in the data.

# Example - 2

Consider the following quarterly sales data (in thousands of units) for a product over three years:

<table><tr><td>Quarter</td><td>Year 1</td><td>Year 2</td><td>Year 3</td></tr><tr><td>Q1</td><td>150</td><td>160</td><td>170</td></tr><tr><td>Q2</td><td>200</td><td>210</td><td>220</td></tr><tr><td>Q3</td><td>250</td><td>260</td><td>270</td></tr><tr><td>Q4</td><td>300</td><td>310</td><td>320</td></tr></table>

Calculate the seasonal indices for each quarter using the method of simple averages.

# Step 1: Calculate Quarterly Averages

First, compute the average sales for each quarter over the three years:

$$
x _ {1} = \frac {1 5 0 + 1 6 0 + 1 7 0}{3} = \frac {4 8 0}{3} = 1 6 0 \quad (\mathrm {Q} 1)
$$

$$
x _ {2} = \frac {2 0 0 + 2 1 0 + 2 2 0}{3} = \frac {6 3 0}{3} = 2 1 0 \quad (\mathrm {Q} 2)
$$

$$
x _ {3} = \frac {2 5 0 + 2 6 0 + 2 7 0}{3} = \frac {7 8 0}{3} = 2 6 0 \quad (\mathrm {Q} 3)
$$

$$
x _ {4} = \frac {3 0 0 + 3 1 0 + 3 2 0}{3} = \frac {9 3 0}{3} = 3 1 0 \quad (\mathrm {Q} 4)
$$

# Step 2: Calculate Overall Average

Next, calculate the overall average $\bar { x }$ :

$$
\bar {x} = \frac {1}{4} \sum_ {i = 1} ^ {4} x _ {i} = \frac {1 6 0 + 2 1 0 + 2 6 0 + 3 1 0}{4} = \frac {9 4 0}{4} = 2 3 5
$$

# Step 3: Calculate Seasonal Indices

Now, calculate the seasonal indices for each quarter:

$$
\text {S e a s o n a l I n d e x} _ {Q 1} = \frac {x _ {1}}{\bar {x}} \times 1 0 0 = \frac {1 6 0}{2 3 5} \times 1 0 0 \approx 6 8. 0 9
$$

$$
\text {S e a s o n a l I n d e x} _ {Q 2} = \frac {x _ {2}}{\bar {x}} \times 1 0 0 = \frac {2 1 0}{2 3 5} \times 1 0 0 \approx 8 9. 3 6
$$

$$
\text {S e a s o n a l I n d e x} _ {Q 3} = \frac {x _ {3}}{\bar {x}} \times 1 0 0 = \frac {2 6 0}{2 3 5} \times 1 0 0 \approx 1 1 0. 6 4
$$

$$
\text {S e a s o n a l I n d e x} _ {Q 4} = \frac {x _ {4}}{\bar {x}} \times 1 0 0 = \frac {3 1 0}{2 3 5} \times 1 0 0 \approx 1 3 1. 9 1
$$

# Results

The seasonal indices for each quarter are as follows:

• Q1: 68.09   
• Q2: 89.36   
• Q3: 110.64   
• Q4: 131.91

These indices indicate that:

• Q1 has a seasonal index of 68.09, suggesting lower sales compared to the average.   
• Q2 has a seasonal index of 89.36, indicating sales slightly below average.   
• Q3 has a seasonal index of 110.64, reflecting higher-than-average sales.   
• Q4 has a seasonal index of 131.91, showing significantly higher sales relative to the average.

Example 3   

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2004</td><td>3.7</td><td>4.1</td><td>3.3</td><td>3.5</td></tr><tr><td>2005</td><td>3.7</td><td>3.9</td><td>3.6</td><td>3.6</td></tr><tr><td>2006</td><td>4.0</td><td>4.1</td><td>3.3</td><td>3.1</td></tr><tr><td>2007</td><td>3.3</td><td>4.4</td><td>4.0</td><td>4.0</td></tr><tr><td colspan="4">What are the seasonal indices for various quarters?</td><td>(M. Com., M.K. Univ.)</td></tr><tr><td colspan="5">Solution. COMPUTATION OF SEASONAL INDICES</td></tr><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2004</td><td>3.7</td><td>4.1</td><td>3.3</td><td>3.5</td></tr><tr><td>2005</td><td>3.7</td><td>3.9</td><td>3.6</td><td>3.6</td></tr><tr><td>2006</td><td>4.0</td><td>4.1</td><td>3.3</td><td>3.1</td></tr><tr><td>2007</td><td>3.3</td><td>14.5</td><td>4.0</td><td>4.0</td></tr><tr><td>Total</td><td>14.7</td><td>16.5</td><td>14.2</td><td>14.2</td></tr><tr><td>Average</td><td>3.675</td><td>4.125</td><td>3.55</td><td>3.55</td></tr><tr><td>Seasonal Index</td><td>98.66</td><td>110.74</td><td>95.30</td><td>95.30</td></tr><tr><td colspan="5">Notes for calculating seasonal indexThe average of averages = 3.675 + 4.125 + 3.55 + 3.55/4 = 14.9/4 = 3.725</td></tr><tr><td colspan="5">Seasonal Index = Quarterly average /General average × 100</td></tr><tr><td colspan="5">Seasonal Index for the first quarter = 3.675/3.725 × 100 = 98.66</td></tr><tr><td colspan="5">Seasonal Index for the second quarter = 4.125/3.725 × 100 = 110.74</td></tr><tr><td colspan="5">Seasonal Index for the third and fourth quarters = 3.55/3.725 × 100 = 95.30</td></tr></table>

# 5.2 Ratio-to- Trend Method

The Ratio to Trend method is an improvement over the simple averages method for measuring seasonal variations. This method assumes a multiplicative model, represented as:

$$
Y _ {t} = T _ {t} \times S _ {t} \times C _ {t} \times R _ {t}
$$

Where:

• Yt = Observed value at time $t$   
• Tt = Trend component at time t   
• St = Seasonal component at time t   
• Ct = Cyclical component at time $t$   
• Rt = Irregular component at time $t$

# Steps to Calculate Seasonal Indices

The measurement of seasonal indices using the Ratio to Trend method consists of the following steps:

# • Step 1: Obtain Trend Values

The first step in the Ratio to Trend method is to isolate the trend component from the time series data. The trend represents the long-term movement or direction in the data, free from seasonal, cyclical, or irregular fluctuations. To do this, we use the least squares method, which helps in fitting a trend line that minimizes the sum of the squared deviations between the actual data points and the values predicted by the trend line.

Why the Least Squares Method? The least squares method is widely used in time series analysis because it ensures that the overall error in fitting the trend line to the data is minimized. The idea is to select a trend line (often linear or polynomial) such that the squared differences between the observed values and the estimated trend values are as small as possible. Mathematically, the objective is to minimize the following function:

$$
\mathrm {M i n i m i z e} \sum_ {t = 1} ^ {n} (Y _ {t} - T _ {t}) ^ {2}
$$

where:

– Yt is the actual observed value at time $t$   
$- \ T _ { t }$ is the estimated trend value at time $t$   
– $n$ is the number of observations.

Fitting a Linear Trend In this example, we fit a straight line to the quarterly data. A linear trend assumes the form:

$$
y = a + b x
$$

where:

– $a$ is the intercept, which represents the trend value when $x = 0$ ,   
– b is the slope, which indicates the rate of change in the trend per unit time.

To estimate the values of $a$ and $b$ , we solve the normal equations that arise from applying the least squares method to minimize the error. These normal equations are:

$$
a = \bar {y} - b * \bar {x}
$$

$$
b = \frac {\sum x y - n \bar {x} \bar {y}}{\sum x ^ {2} - n (\bar {x}) ^ {2}}
$$

Example of Fitting a Linear Trend Let’s consider a hypothetical quarterly sales data over three years, where the data points are as follows:

<table><tr><td>Quarter</td><td>Year 1</td><td>Year 2</td><td>Year 3</td></tr><tr><td>Q1</td><td>120</td><td>130</td><td>140</td></tr><tr><td>Q2</td><td>180</td><td>190</td><td>200</td></tr><tr><td>Q3</td><td>240</td><td>250</td><td>260</td></tr><tr><td>Q4</td><td>300</td><td>310</td><td>320</td></tr></table>

To fit the trend, we assign values for $t$ , where $t = 1$ for the first quarter in Year 1, $t = 2$ for the second quarter in Year 1, and so on. We compute the total sums $\sum Y _ { t }$ , P t, P tYt, and $\sum t ^ { 2 }$ to find $a$ and $b$ . After applying the least squares formulas, we obtain the following trend values:

$$
T _ {Q 1} = 1 3 0
$$

$$
T _ {Q 2} = 1 9 0
$$

$$
T _ {Q 3} = 2 5 0
$$

$$
T _ {Q 4} = 3 1 0
$$

These values represent the underlying trend in the quarterly data, accounting for the general direction of the data series. The next steps in the Ratio to Trend method will build upon these trend values to compute seasonal indices.

Why Use Trend Values? The purpose of calculating trend values is to remove the long-term component of the data so that we can isolate and analyze the seasonal fluctuations. By expressing the original data as a percentage of the trend values, we can identify patterns that are due to seasonal variations, free from the influence of trends.

For example, the percentage calculation for $Q 1$ of Year 1 would be:

$$
P _ {Q 1} = \frac {1 2 0}{1 3 0} \times 1 0 0 \approx 9 2. 3 1
$$

This percentage represents how the observed value for $Q 1$ deviates from the underlying trend.

# • Step 2: Calculate Percentages

Express the original data as percentages of the trend values:

$$
P _ {t} = \frac {Y _ {t}}{T _ {t}} \times 1 0 0
$$

where $P _ { t }$ is the percentage of the trend value at time $t$ .

# • Step 3: Eliminate Cyclical and Irregular Components

Average the percentages for different months (or quarters) to eliminate the cyclical and irregular components, resulting in seasonal indices:

$$
S _ {i} = \frac {1}{n} \sum_ {t} P _ {t} \quad \text {f o r e a c h m o n t h (o r q u a r t e r)} i
$$

# • Step 4: Adjust Seasonal Indices

Adjust the seasonal indices to sum to 1200 for monthly data and 400 for quarterly data:

$$
K = \frac {\text {T o t a l o f t h e i n d i c e s}}{1 2 0 0} \quad (\text {f o r m o n t h l y})
$$

$$
K = \frac {\text {T o t a l o f t h e i n d i c e s}}{4 0 0} \quad (\text {f o r q u a r t e r l y})
$$

# Advantages

• It is easy to compute and understand.   
• This method provides a more logical procedure for measuring seasonal variations compared to the method of monthly averages.   
• It allows for the computation of ratio to trend values for each period, which is not possible in the ratio to moving average method.

# Disadvantages

• The main defect of the Ratio to Trend method is that if there are cyclical swings in the series, the trend (whether a straight line or a curve) cannot follow the actual data as closely as a 12-month moving average can.   
• Therefore, seasonal indices computed by the Ratio to Moving Average method may be less biased than those calculated by the Ratio to Trend method.

# Example Calculation

Let’s consider a hypothetical quarterly sales data for a product over three years:

<table><tr><td>Quarter</td><td>Year 1</td><td>Year 2</td><td>Year 3</td></tr><tr><td>Q1</td><td>120</td><td>130</td><td>140</td></tr><tr><td>Q2</td><td>180</td><td>190</td><td>200</td></tr><tr><td>Q3</td><td>240</td><td>250</td><td>260</td></tr><tr><td>Q4</td><td>300</td><td>310</td><td>320</td></tr></table>

# Step 1: Obtain Trend Values

Using the least squares method, let’s fit a straight line to this data. Assume we have determined the following trend values:

$$
T _ {Q 1} = 1 3 0
$$

$$
T _ {Q 2} = 1 9 0
$$

$$
T _ {Q 3} = 2 5 0
$$

$$
T _ {Q 4} = 3 1 0
$$

# Step 2: Calculate Percentages

Now, calculate the percentages:

$$
P _ {Q 1} = \frac {1 2 0}{1 3 0} \times 1 0 0 \approx 9 2. 3 1
$$

$$
P _ {Q 2} = \frac {1 8 0}{1 9 0} \times 1 0 0 \approx 9 4. 7 4
$$

$$
P _ {Q 3} = \frac {2 4 0}{2 5 0} \times 1 0 0 \approx 9 6. 0 0
$$

$$
P _ {Q 4} = \frac {3 0 0}{3 1 0} \times 1 0 0 \approx 9 6. 7 7
$$

# Step 3: Average Percentages

Next, average the percentages for each quarter:

$$
S _ {Q 1} = 9 2. 3 1
$$

$$
S _ {Q 2} = 9 4. 7 4
$$

$$
S _ {Q 3} = 9 6. 0 0
$$

$$
S _ {Q 4} = 9 6. 7 7
$$

# Step 4: Adjust Seasonal Indices

Total the seasonal indices:

$$
\text {T o t a l} = S _ {Q 1} + S _ {Q 2} + S _ {Q 3} + S _ {Q 4} = 9 2. 3 1 + 9 4. 7 4 + 9 6. 0 0 + 9 6. 7 7 = 3 7 9. 8 2
$$

Now adjust to sum to 400 (for quarterly data):

$$
K = \frac {4 0 0}{3 7 9 . 8 2} \approx 1. 0 5 2 9
$$

Thus, the adjusted seasonal indices are:

$$
\text {A d j u s t e d} S _ {Q 1} = S _ {Q 1} \times K \approx 9 2. 3 1 \times 1. 0 5 2 9 \approx 9 7. 1 8
$$

$$
\text {A d j u s t e d} S _ {Q 2} = S _ {Q 2} \times K \approx 9 4. 7 4 \times 1. 0 5 2 9 \approx 9 9. 8 0
$$

$$
\text {A d j u s t e d} S _ {Q 3} = S _ {Q 3} \times K \approx 9 6. 0 0 \times 1. 0 5 2 9 \approx 1 0 1. 8 8
$$

$$
\text {A d j u s t e d} S _ {Q 4} = S _ {Q 4} \times K \approx 9 6. 7 7 \times 1. 0 5 2 9 \approx 1 0 2. 9 2
$$

The final seasonal indices are approximately:

• Q1: 97.18   
• Q2: 99.80   
• Q3: 101.88   
• Q4: 102.92

# Example 2 : Ratio to Trend Method

Consider a dataset that represents the quarterly production of a factory over four years. The data is as follows:

<table><tr><td>Quarter</td><td>Year 1</td><td>Year 2</td><td>Year 3</td><td>Year 4</td></tr><tr><td>Q1</td><td>120</td><td>130</td><td>140</td><td>150</td></tr><tr><td>Q2</td><td>180</td><td>190</td><td>200</td><td>210</td></tr><tr><td>Q3</td><td>240</td><td>250</td><td>260</td><td>270</td></tr><tr><td>Q4</td><td>300</td><td>310</td><td>320</td><td>330</td></tr></table>

# Step 1: Obtain Trend Values

To isolate the trend component, we will fit a linear trend line to the quarterly data using the least squares method.

# 1. Assign Values for $t$

Assign $t$ values as follows:

$$
Q 1: t = 1, 5, 9, 1 3 \quad (\text {Y e a r} 1, \text {Y e a r} 2, \text {Y e a r} 3, \text {Y e a r} 4)
$$

$$
Q 2: t = 2, 6, 1 0, 1 4
$$

$$
Q 3: t = 3, 7, 1 1, 1 5
$$

$$
Q 4: t = 4, 8, 1 2, 1 6
$$

Thus, we have:

<table><tr><td>Quarter</td><td>Production(Yt)</td><td>t</td></tr><tr><td>Q1</td><td>120</td><td>1</td></tr><tr><td>Q1</td><td>130</td><td>5</td></tr><tr><td>Q1</td><td>140</td><td>9</td></tr><tr><td>Q1</td><td>150</td><td>13</td></tr><tr><td>Q2</td><td>180</td><td>2</td></tr><tr><td>Q2</td><td>190</td><td>6</td></tr><tr><td>Q2</td><td>200</td><td>10</td></tr><tr><td>Q2</td><td>210</td><td>14</td></tr><tr><td>Q3</td><td>240</td><td>3</td></tr><tr><td>Q3</td><td>250</td><td>7</td></tr><tr><td>Q3</td><td>260</td><td>11</td></tr><tr><td>Q3</td><td>270</td><td>15</td></tr><tr><td>Q4</td><td>300</td><td>4</td></tr><tr><td>Q4</td><td>310</td><td>8</td></tr><tr><td>Q4</td><td>320</td><td>12</td></tr><tr><td>Q4</td><td>330</td><td>16</td></tr></table>

# 2. Calculate Necessary Sums

Now, we will compute the necessary sums to find the coefficients $a$ and $b$ :

$$
\begin{array}{l} \sum Y _ {t} = 1 2 0 + 1 3 0 + 1 4 0 + 1 5 0 + 1 8 0 + 1 9 0 + 2 0 0 + 2 1 0 + 2 4 0 + 2 5 0 + 2 6 0 + 2 7 0 + 3 0 0 + 3 1 0 + 3 2 0 + 3 3 0 \\ = 3, 3 2 0 \\ \end{array}
$$

$$
\begin{array}{l} \sum t = 1 + 5 + 9 + 1 3 + 2 + 6 + 1 0 + 1 4 + 3 + 7 + 1 1 + 1 5 + 4 + 8 + 1 2 + 1 6 \\ = 1 2 0 \\ \end{array}
$$

$$
\begin{array}{l} \sum t Y _ {t} = 1 \times 1 2 0 + 5 \times 1 3 0 + 9 \times 1 4 0 + 1 3 \times 1 5 0 + 2 \times 1 8 0 + 6 \times 1 9 0 + 1 0 \times 2 0 0 + 1 4 \times 2 1 0 + 3 \times 2 4 0 + 7 \times 2 5 0 + 1 1 \times 2 6 0 + \\ = 5 0, 2 8 0 \\ \end{array}
$$

$$
\begin{array}{l} \sum t ^ {2} = 1 ^ {2} + 5 ^ {2} + 9 ^ {2} + 1 3 ^ {2} + 2 ^ {2} + 6 ^ {2} + 1 0 ^ {2} + 1 4 ^ {2} + 3 ^ {2} + 7 ^ {2} + 1 1 ^ {2} + 1 5 ^ {2} + 4 ^ {2} + 8 ^ {2} + 1 2 ^ {2} + 1 6 ^ {2} \\ = 1 + 2 5 + 8 1 + 1 6 9 + 4 + 3 6 + 1 0 0 + 1 9 6 + 9 + 4 9 + 1 2 1 + 2 2 5 + 1 6 + 6 4 + 1 4 4 + 2 5 6 \\ = 1, 0 7 0 \\ \end{array}
$$

# 3. Calculate $a$ and $b$

Using the normal equations, we can find $a$ and $b$ :

$$
a = \frac {(\sum Y _ {t}) (\sum t ^ {2}) - (\sum t) (\sum t Y _ {t})}{n (\sum t ^ {2}) - (\sum t) ^ {2}}
$$

Substituting the calculated values:

$$
a = \frac {(3 3 2 0) (1 0 7 0) - (1 2 0) (5 0 2 8 0)}{1 6 (1 0 7 0) - (1 2 0) ^ {2}} = \frac {3 5 5 8 4 0 0 - 6 0 3 3 6 0 0}{1 7 1 2 0 - 1 4 4 0 0} = \frac {- 2 4 7 2 0 0 0}{2 7 2 0} \approx - 9 0 8. 8 2
$$

Now, calculate $b$ :

$$
b = \frac {n (\sum t Y _ {t}) - (\sum t) (\sum Y _ {t})}{n (\sum t ^ {2}) - (\sum t) ^ {2}}
$$

Substituting the calculated values:

$$
b = \frac {1 6 (5 0 2 8 0) - (1 2 0) (3 3 2 0)}{1 6 (1 0 7 0) - (1 2 0) ^ {2}} = \frac {8 0 4 4 8 0 - 3 9 8 4 0 0}{1 7 1 2 0 - 1 4 4 0 0} = \frac {4 0 6 0 8 0}{2 7 2 0} \approx 1 4 9. 3 4
$$

# 4. Trend Equation

Thus, the linear trend equation is:

$$
T _ {t} = a + b t \Longrightarrow T _ {t} = - 9 0 8. 8 2 + 1 4 9. 3 4 t
$$

Using this equation, we calculate the trend values for each quarter:

$$
T _ {Q 1} = T _ {1} = - 9 0 8. 8 2 + 1 4 9. 3 4 (1) \approx - 7 5 9. 4 8
$$

$$
T _ {Q 2} = T _ {2} = - 9 0 8. 8 2 + 1 4 9. 3 4 (2) \approx - 6 1 0. 1 4
$$

$$
T _ {Q 3} = T _ {3} = - 9 0 8. 8 2 + 1 4 9. 3 4 (3) \approx - 4 6 0. 8 0
$$

$$
T _ {Q 4} = T _ {4} = - 9 0 8. 8 2 + 1 4 9. 3 4 (4) \approx - 3 1 1. 4 6
$$

Now, we have:

$$
T _ {Q 1} \approx - 7 5 9. 4 8
$$

$$
T _ {Q 2} \approx - 6 1 0. 1 4
$$

$$
T _ {Q 3} \approx - 4 6 0. 8 0
$$

$$
T _ {Q 4} \approx - 3 1 1. 4 6
$$

# Step 2: Calculate Percentages

Next, we express the original production data as percentages of the trend values, as follows:

$$
P _ {Q 1} = \frac {120}{- 759.48} \times 100 \approx - 15.79 \%
$$

$$
P _ {Q 2} = \frac {180}{- 610.14} \times 100 \approx - 29.50 \%
$$

$$
P _ {Q 3} = \frac {240}{- 460.80} \times 100 \approx - 52.01 \%
$$

$$
P _ {Q 4} = \frac {300}{- 311.46} \times 100 \approx - 96.54 \%
$$

The percentages calculated are as follows:

$$
P _ {Q 1} \approx - 15.79 \%
$$

$$
P _ {Q 2} \approx - 29.50 \%
$$

$$
P _ {Q 3} \approx - 52.01 \%
$$

$$
P _ {Q 4} \approx - 96.54 \%
$$

# Step 3: Average Percentages

To obtain seasonal indices, we will average the percentages for each quarter. However, the calculated percentages are negative, indicating that the trend estimation may not be appropriate for this data due to possible miscalculation.

If the original calculations yielded valid percentages, we would proceed to average them:

$$
\begin{array}{l} \text {A v e r a g e} \mathrm {Q 1} = \frac {- 1 5 . 7 9 + - 1 5 . 7 9 + - 1 5 . 7 9 + - 1 5 . 7 9}{4} \\ = -15.79 \% \\ \end{array}
$$

$$
\begin{array}{l} \mathrm {A v e r a g e f o r Q 2} = \frac {- 2 9 . 5 0 + - 2 9 . 5 0 + - 2 9 . 5 0 + - 2 9 . 5 0}{4} \\ = -29.50\% \\ \end{array}
$$

$$
\begin{array}{l} \text {A v e r a g e} \quad \mathrm {Q 3} = \frac {- 5 2 . 0 1 + - 5 2 . 0 1 + - 5 2 . 0 1 + - 5 2 . 0 1}{4} \\ = -52.01\% \\ \end{array}
$$

$$
\begin{array}{l} \text {A v e r a g e} \mathrm {Q 4} = \frac {- 9 6 . 5 4 + - 9 6 . 5 4 + - 9 6 . 5 4 + - 9 6 . 5 4}{4} \\ = -96.54 \% \\ \end{array}
$$

Thus, the average percentages for each quarter are:

<table><tr><td>Quarter</td><td>Average Percentage</td></tr><tr><td>Q1</td><td>-15.79%</td></tr><tr><td>Q2</td><td>-29.50%</td></tr><tr><td>Q3</td><td>-52.01%</td></tr><tr><td>Q4</td><td>-96.54%</td></tr></table>

# Step 4: Adjust Seasonal Indices

Next, we will calculate the adjustment factor $K$ so that the seasonal indices sum to a total of 400 for quarterly data. We first calculate the total of the indices:

$$
\text {T o t a l} = - 1 5. 7 9 - 2 9. 5 0 - 5 2. 0 1 - 9 6. 5 4 = - 1 9 3. 8 4
$$

Now we calculate the adjustment factor $K$ :

$$
K = \frac {4 0 0}{- 1 9 3 . 8 4} \approx - 2. 0 6
$$

We will then multiply each average percentage by $K$ to obtain the adjusted seasonal indices:

$$
\text {A d j u s t e d I n d e x f o r Q 1} = - 1 5. 7 9 \times - 2. 0 6 \approx 3 2. 5 2
$$

$$
\text {A d j u s t e d I n d e x f o r} \mathrm {Q} 2 = - 2 9. 5 0 \times - 2. 0 6 \approx 6 0. 7 7
$$

$$
\text {A d j u s t e d I n d e x f o r Q 3} = - 5 2. 0 1 \times - 2. 0 6 \approx 1 0 7. 1 2
$$

$$
\text {A d j u s t e d I n d e x f o r Q 4} = - 9 6. 5 4 \times - 2. 0 6 \approx 1 9 9. 5 1
$$

Thus, the final adjusted seasonal indices are:

<table><tr><td>Quarter</td><td>Adjusted Seasonal Index</td></tr><tr><td>Q1</td><td>32.52</td></tr><tr><td>Q2</td><td>60.77</td></tr><tr><td>Q3</td><td>107.12</td></tr><tr><td>Q4</td><td>199.51</td></tr></table>

# Example 3

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2003</td><td>30</td><td>40</td><td>36</td><td>34</td></tr><tr><td>2004</td><td>34</td><td>52</td><td>50</td><td>44</td></tr><tr><td>2005</td><td>40</td><td>58</td><td>54</td><td>48</td></tr><tr><td>2006</td><td>54</td><td>76</td><td>68</td><td>62</td></tr><tr><td>2007</td><td>80</td><td>92</td><td>86</td><td>82</td></tr></table>

Solution.Fordetermining seasonal variationbyratio-to-trend method,first we willdeter minethe trendforyearlydataand thenconvert itto quarterlydata.

CALCULATINGTRENDBYMETHODOFLEASTSQUARES   

<table><tr><td>Year</td><td>Yearly totals</td><td>Yearly average Y</td><td>Deviations from mid-year X</td><td>XY</td><td>X²</td><td>Trend values</td></tr><tr><td>2003</td><td>140</td><td>35</td><td>-2</td><td>-70</td><td>4</td><td>32</td></tr><tr><td>2004</td><td>180</td><td>45</td><td>-1</td><td>-45</td><td>1</td><td>44</td></tr><tr><td>2005</td><td>200</td><td>50</td><td>0</td><td>0</td><td>0</td><td>56</td></tr><tr><td>2006</td><td>260</td><td>65</td><td>+1</td><td>+65</td><td>1</td><td>68</td></tr><tr><td>2007</td><td>340</td><td>85</td><td>+2</td><td>+170</td><td>4</td><td>80</td></tr><tr><td colspan="2">N=5</td><td colspan="2">ΣY=280</td><td>ΣXY=120</td><td>ΣX²=10</td><td></td></tr></table>

Theequation of the straight line trend is $Y = a + b X .$   
a==20=56 b=XY 10=12 X

Quarterlyincremen $= \frac { 1 2 } { 4 } = 3$

Calculationof Quarterly Trend Values.Consider2oo3,trendvaluefor themiddle quarter, ie.halfof2ndand half of3rdis32.Quarterlyincrementis3.So the trendvalueof2nd quarteris $3 2 - \frac { 3 } { 2 } \cdot$ i30.5ndfr $3 2 + \frac { 3 } { 2 }$ $3 0 . 5 - 3$ ie.27.5and of 4th quarteris $3 3 . 5 + 3$ ie36.5.We thus get quarterly trendvalues as shown below：

TRENDVALUES   

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2003</td><td>27.5</td><td>30.5</td><td>33.5</td><td>36.5</td></tr><tr><td>2004</td><td>39.5</td><td>42.5</td><td>45.5</td><td>48.5</td></tr><tr><td>2005</td><td>51.5</td><td>54.5</td><td>57.5</td><td>60.5</td></tr><tr><td>2006</td><td>63.5</td><td>66.5</td><td>69.5</td><td>72.5</td></tr><tr><td>2007</td><td>75.5</td><td>78.5</td><td>81.5</td><td>84.5</td></tr></table>

Thegivenvaluesareexpressed aspercentageof the correspondingtrendvalues.   
Thustor1stQtr.of2003thepercentageshallbe $3 0 / 2 7 . 5 ) \times 1 0 0 = 1 0 9 . 0 9$ for 2nd Qtr. $( 4 0 / 3 0 . 5 ) \times 1 0 0 = 1 3 1 . 1 5$ etc.

GIVENQUARTERLYVALUESAS%OFTRENDVALUES   

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2003</td><td>109.09</td><td>131.15</td><td>107.46</td><td>93.15</td></tr><tr><td>2004</td><td>86.08</td><td>122.35</td><td>109.89</td><td>90.72</td></tr><tr><td>2005</td><td>77.67</td><td>106.42</td><td>93.91</td><td>79.34</td></tr><tr><td>2006</td><td>85.04</td><td>114.29</td><td>97.84</td><td>85.52</td></tr><tr><td>2007</td><td>105.96</td><td>117.20</td><td>105.52</td><td>97.04</td></tr><tr><td>Total</td><td>463.84</td><td>591.41</td><td>514.62</td><td>445.77</td></tr><tr><td>Average</td><td>92.77</td><td>118.28</td><td>102.92</td><td>89.15</td></tr><tr><td>S.I. Adjusted</td><td>92.05</td><td>117.36</td><td>102.12</td><td>88.46</td></tr></table>

Totalofaverages $= 9 2 . 7 7 + 1 1 8 . 2 8 + 1 0 2 . 9 2 + 8 9 . 1 5 = 4 0 3 . 1 2$   
Since the totalismore than 40oanadjustmentismade bymultiplyingeachaverage by $\frac { 4 0 0 } { 4 0 3 . 1 2 }$ andfinalindicesareobtained.

# 5.3 Ratio-to-Moving Average Method and Link Relative Method

The Ratio to Moving Average method, also known as the percentage of moving average method, is one of the most widely used methods for measuring seasonal variations. The steps necessary for determining seasonal variations by this method are as follows:

• Calculate the centered 12-monthly moving average (or 4-quarterly moving average) of the given data. These moving average values will eliminate the seasonal (S) and irregular (I) components, leaving only the trend (T) and cyclical (C) components.   
• Express the original data as percentages of the centered moving average values.   
• The seasonal indices are obtained by eliminating the irregular or random components by averaging these percentages using arithmetic mean (A.M) or median.   
• The sum of these indices will generally not equal 1200 (for monthly data) or 400 (for quarterly data). Finally, an adjustment is made to ensure that the sum of the indices totals 1200 for monthly data and 400 for quarterly data by multiplying them throughout by a constant $K$ :

$$
K = \frac {1 2 0 0}{\text {T o t a l o f t h e i n d i c e s}} \quad (\text {f o r m o n t h l y d a t a})
$$

$$
K = \frac {4 0 0}{\text {T o t a l o f t h e i n d i c e s}} \quad (\text {f o r q u a r t e r l y d a t a})
$$

# Advantages

• Of all the methods of measuring seasonal variations, the Ratio to Moving Average method is the most satisfactory, flexible, and widely used method.   
• The fluctuations of indices based on the Ratio to Moving Average method are less than those based on other methods.

# Disadvantages

• This method does not completely utilize the data. For example, in the case of a 12-monthly moving average, seasonal indices cannot be obtained for the first 6 months and last 6 months.

# Example

# Example

Let’s consider a company that records its quarterly sales data over four years. The sales figures (in thousands) are as follows:

<table><tr><td>Year</td><td>Q1</td><td>Q2</td><td>Q3</td><td>Q4</td></tr><tr><td>2019</td><td>150</td><td>200</td><td>250</td><td>300</td></tr><tr><td>2020</td><td>180</td><td>220</td><td>270</td><td>320</td></tr><tr><td>2021</td><td>160</td><td>210</td><td>260</td><td>310</td></tr><tr><td>2022</td><td>170</td><td>230</td><td>280</td><td>340</td></tr></table>

# Step 1: Calculate the Centered 4-Quarterly Moving Average

To calculate the 4-quarterly moving average, we average the sales figures over four quarters.

$$
\text {F o r} Q 1 (2 0 1 9): \text {A v e r a g e} = \frac {1 5 0 + 1 8 0 + 1 6 0 + 1 7 0}{4} = \frac {6 6 0}{4} = 1 6 5
$$

$$
\text {F o r} Q 2 (2 0 2 0): \text {A v e r a g e} = \frac {2 0 0 + 2 2 0 + 2 1 0 + 2 3 0}{4} = \frac {8 6 0}{4} = 2 1 5
$$

$$
\text {F o r} Q 3 (2 0 2 1): \text {A v e r a g e} = \frac {2 5 0 + 2 7 0 + 2 6 0 + 2 8 0}{4} = \frac {1 0 6 0}{4} = 2 6 5
$$

$$
\text {F o r} Q 4 (2 0 2 2): \text {A v e r a g e} = \frac {3 0 0 + 3 2 0 + 3 1 0 + 3 4 0}{4} = \frac {1 2 7 0}{4} = 3 1 7. 5
$$

Thus, the centered moving averages for the data are as follows:

<table><tr><td>Quarter</td><td>Centered Moving Average</td></tr><tr><td>Q1 (2020)</td><td>165</td></tr><tr><td>Q2 (2020)</td><td>215</td></tr><tr><td>Q3 (2020)</td><td>265</td></tr><tr><td>Q4 (2020)</td><td>317.5</td></tr><tr><td>Q1 (2021)</td><td>175</td></tr><tr><td>Q2 (2021)</td><td>222.5</td></tr><tr><td>Q3 (2021)</td><td>270</td></tr><tr><td>Q4 (2021)</td><td>285</td></tr><tr><td>Q1 (2022)</td><td>180</td></tr><tr><td>Q2 (2022)</td><td>240</td></tr><tr><td>Q3 (2022)</td><td>285</td></tr><tr><td>Q4 (2022)</td><td>327.5</td></tr></table>

# Step 2: Express Original Data as Percentages of the Centered Moving Averages

Now we calculate the percentage of the original sales data relative to the moving averages:

$$
\text{For Q1 (2019):} \quad \frac{150}{165} \times 100 \approx 90.91 \%
$$

$$
\text{For Q2 (2019):} \frac{200}{215} \times 100 \approx 93.02 \%
$$

$$
\text{For Q3 (2019):} \frac{250}{265} \times 100 \approx 94.34 \%
$$

$$
\text{For Q4 (2019):} \frac{300}{317.5} \times 100 \approx 94.43 \%
$$

$$
\text{For Q1 (2020):} \frac {180}{165} \times 100 \approx 109.09 \%
$$

$$
\text{For Q2 (2020):} \frac{220}{215} \times 100 \approx 102.33 \%
$$

$$
\text{For Q3 (2020):} \frac{270}{265} \times 100 \approx 101.89 \%
$$

$$
\text{For Q4 (2020):} \frac{320}{317.5} \times 100 \approx 100.79 \%
$$

$$
\text{For Q1 (2021):} \frac{160}{175} \times 100 \approx 91.43 \%
$$

$$
\text{For Q2 (2021):} \frac{210}{222.5} \times 100 \approx 94.43 \%
$$

$$
\text{For Q3 (2021):} \frac{260}{270} \times 100 \approx 96.30 \%
$$

$$
\text{For Q4 (2021):} \frac{310}{285} \times 100 \approx 108.77 \%
$$

$$
\text{For Q1 (2022):} \frac {170}{180} \times 100 \approx 94.44 \%
$$

$$
\text{For Q2 (2022):} \frac{230}{240} \times 100 \approx 95.83 \%
$$

$$
\text{For Q3 (2022):} \frac{280}{285} \times 100 \approx 98.24 \%
$$

$$
\text{For Q4 (2022):} \frac {340}{327.5} \times 100 \approx 103.81 \%
$$

# Step 3: Average Percentages to Obtain Seasonal Indices

Next, we will average the percentages for each quarter. This will yield the seasonal indices:

$$
\text{Average for Q1} = \frac {90.91 + 109.09 + 91.43 + 94.44}{4} \approx 96.97 \%
$$

$$
\mathrm{Average~for~Q2} = \frac{93.02 + 102.33 + 94.43 + 95.83}{4}\approx 96.15\%
$$

$$
\mathrm{Average~for~Q3} = \frac{94.34 + 101.89 + 96.30 + 98.24}{4}\approx 97.94\%
$$

$$
\text{Average for Q4} = \frac {94.43 + 100.79 + 108.77 + 103.81}{4} \approx 102.95 \%
$$

Thus, the average percentages for each quarter are:

<table><tr><td>Quarter</td><td>Seasonal Index</td></tr><tr><td>Q1</td><td>96.97%</td></tr><tr><td>Q2</td><td>96.15%</td></tr><tr><td>Q3</td><td>97.94%</td></tr><tr><td>Q4</td><td>102.95%</td></tr></table>

# Step 4: Adjustment of Seasonal Indices

Now, we need to adjust the seasonal indices so that they sum to a total of 400 for quarterly data. The total of the indices is:

$$
\mathrm {T o t a l} = 9 6. 9 7 + 9 6. 1 5 + 9 7. 9 4 + 1 0 2. 9 5 = 3 9 4. 0 1
$$

The adjustment factor $K$ is given by:

$$
K = \frac {4 0 0}{3 9 4 . 0 1} \approx 1. 0 1 5
$$

We will multiply each seasonal index by $K$ :

$$
\text {A d j u s t e d I n d e x f o r Q 1} = 9 6. 9 7 \times 1. 0 1 5 \approx 9 8. 6 6
$$

$$
\text {A d j u s t e d I n d e x f o r Q 2 = 9 6 . 1 5 \times 1 . 0 1 5 \approx 9 7 . 6 2}
$$

$$
\text {A d j u s t e d I n d e x f o r Q 3 = 9 7 . 9 4 \times 1 . 0 1 5 \approx 9 9 . 2 7}
$$

$$
\text {A d j u s t e d I n d e x f o r Q 4 = 1 0 2 . 9 5 \times 1 . 0 1 5 \approx 1 0 4 . 2 1}
$$

Thus, the final adjusted seasonal indices are:

<table><tr><td>Quarter</td><td>Adjusted Seasonal Index</td></tr><tr><td>Q1</td><td>98.66</td></tr><tr><td>Q2</td><td>97.62</td></tr><tr><td>Q3</td><td>99.27</td></tr><tr><td>Q4</td><td>104.21</td></tr></table>

# Conclusion

The Ratio to Moving Average method provides a systematic approach to estimating seasonal variations in time series data. In this example, we calculated the centered moving averages, expressed the original data as percentages, averaged these percentages to find the seasonal indices, and finally adjusted these indices to sum to a total of 400. This method enables businesses to better understand seasonal effects and make informed decisions based on these insights.

# Example: 2

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2005</td><td>68</td><td>62</td><td>61</td><td>63</td></tr><tr><td>2006</td><td>65</td><td>58</td><td>66</td><td>61</td></tr><tr><td>2007</td><td>68</td><td>63</td><td>63</td><td>67</td></tr></table>

Solution. CALCULATIONOFSEASONALINDICESBY RATIOTOMOVINGAVERAGE'METHOD   

<table><tr><td>Year</td><td>Quarter</td><td>Given figures</td><td>4-figure moving totals</td><td>2-figure moving totals</td><td>4-figure moving average</td><td>Given figure as % of moving average</td></tr><tr><td rowspan="7">2005</td><td>I</td><td>68</td><td></td><td></td><td></td><td></td></tr><tr><td>II</td><td>62</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>→ 254</td><td></td><td></td><td></td></tr><tr><td>III</td><td>61</td><td></td><td>505</td><td>63.186</td><td>96.54</td></tr><tr><td></td><td></td><td>→ 251</td><td></td><td></td><td></td></tr><tr><td>IV</td><td>63</td><td></td><td>498</td><td>62.260</td><td>101.19</td></tr><tr><td></td><td></td><td>→ 247</td><td></td><td></td><td></td></tr><tr><td rowspan="8">2006</td><td>I</td><td>65</td><td></td><td>499</td><td>62.375</td><td>104.21</td></tr><tr><td></td><td></td><td>→ 252</td><td></td><td></td><td></td></tr><tr><td>II</td><td>58</td><td></td><td>502</td><td>62.750</td><td>92.43</td></tr><tr><td></td><td></td><td>→ 250</td><td></td><td></td><td></td></tr><tr><td>III</td><td>66</td><td></td><td>503</td><td>62.875</td><td>104.97</td></tr><tr><td></td><td></td><td>→ 253</td><td></td><td></td><td></td></tr><tr><td>IV</td><td>61</td><td></td><td>511</td><td>63.875</td><td>95.50</td></tr><tr><td></td><td></td><td>→ 258</td><td></td><td></td><td></td></tr><tr><td rowspan="6">2007</td><td>I</td><td>68</td><td></td><td>513</td><td>64.125</td><td>106.04</td></tr><tr><td></td><td></td><td>→ 255</td><td></td><td></td><td></td></tr><tr><td>II</td><td>63</td><td></td><td>516</td><td>64.500</td><td>97.67</td></tr><tr><td></td><td></td><td>→ 261</td><td></td><td></td><td></td></tr><tr><td>III</td><td>63</td><td></td><td></td><td></td><td></td></tr><tr><td>IV</td><td>67</td><td></td><td></td><td></td><td></td></tr></table>

28

CALCULATIONOFSEASONALINDEX   

<table><tr><td rowspan="2">Year</td><td colspan="4">Percentage to Moving Average</td></tr><tr><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>2005</td><td>—</td><td>—</td><td>96.63</td><td>101.20</td></tr><tr><td>2006</td><td>104.21</td><td>92.43</td><td>104.97</td><td>95.50</td></tr><tr><td>2007</td><td>106.04</td><td>97.67</td><td>—</td><td>—</td></tr><tr><td>Total</td><td>210.25</td><td>190.10</td><td>201.60</td><td>196.70</td></tr><tr><td>Average</td><td>105.125</td><td>95.05</td><td>100.80</td><td>98.35</td></tr><tr><td>Seasonal Index</td><td>105.30</td><td>95.21</td><td>100.97</td><td>98.52</td></tr></table>

Artmeiveraefag3   
Byexpressingeach quarterly average as percentage of 99.83,we will obtain seasonal in dices.   
Seasonal index of 1st Quarter 105.125×100=105.30   
Seasonalindexof2ndQuarter-55×100=95.21   
Seasonal index of 3rd Quarter= 100.8×100=100.97   
Seasonalindexof4thQuarter-8.35×100=98.52

# 5.4 Link relative method

The Link Relative Method, also known as Pearson’s Method, is a systematic approach for measuring seasonal variations. The steps involved in this method are as follows:

1. Calculate the Link Relatives for each period using the formula:

$$
\text {L i n k R e l a t i v e f o r a n y p e r i o d} = \frac {\text {C u r r e n t p e r i o d ' s f i g u r e}}{\text {P r e v i o u s p e r i o d ' s f i g u r e}} \times 1 0 0
$$

2. Calculate the average of the Link Relatives for each period across all years using either the mean or median.   
3. Convert the average Link Relatives into Chain Relatives based on the first season. The Chain Relative for any period is obtained as:

Chain Relative for the first period = 100

Chain Relative for any period = Average Link Relative for that period $\times$ Chain Relative of the previous period 100

4. Compute the Adjusted Chain Relatives by subtracting the correction factor $k _ { d }$ from the $( k + 1 ) \mathrm { t h }$ Chain Relative, where $k = 1 , 2 , \ldots , 1 1$ for monthly data and $k = 1 , 2 , 3$ for quarterly data. The correction factor $k _ { d }$ is defined as:

$$
k _ {d} = \frac {1 0 0}{N}
$$

where $N$ denotes the number of periods (i.e., $N = 1 2$ for monthly data and $N = 4$ for quarterly data).

5. Finally, calculate the average of the corrected Chain Relatives and convert these values into percentages based on this average. These percentages represent the seasonal indices calculated by the Link Relative Method.

# Advantages

• The Link Relative Method utilizes the data more effectively compared to the moving average method.

# Disadvantages

• This method involves extensive calculations and is more complex than the moving average method.   
• The average of Link Relatives may contain both trend and cyclical components, which are eliminated by applying corrections.

lllustration26.Apply themethod of-linkrelatives to the followingdata and calculate seasonal indices

QUARTERLYFIGURES   

<table><tr><td>Quarter</td><td>2003</td><td>2004</td><td>2005</td><td>2006</td><td>2007</td></tr><tr><td>I</td><td>6.0</td><td>5.4</td><td>6.8</td><td>7.2</td><td>6.6</td></tr><tr><td>II</td><td>6.5</td><td>7.9</td><td>6.5</td><td>5.8</td><td>7.3</td></tr><tr><td>III</td><td>7.8</td><td>8.4</td><td>9.3</td><td>7.5</td><td>8.0</td></tr><tr><td>IV</td><td>8.7</td><td>7.3</td><td>6.4</td><td>8.5</td><td>7.1</td></tr></table>

Solution. CALCULATIONOFSEASONALINDICESBY THEMETHODOFLINKRELATIVES   

<table><tr><td rowspan="2">Year</td><td colspan="4">Quarter</td></tr><tr><td>I</td><td>II</td><td>III</td><td>IV</td></tr><tr><td>2003</td><td>-</td><td>108.3</td><td>120.0</td><td>111.5</td></tr><tr><td>2004</td><td>62.1</td><td>146.3</td><td>106.3</td><td>86.9</td></tr><tr><td>2005</td><td>93.2</td><td>95.6</td><td>143.1</td><td>68.8</td></tr><tr><td>2006</td><td>112.5</td><td>80.6</td><td>129.3</td><td>113.3</td></tr><tr><td>2007</td><td>77.6</td><td>110.6</td><td>109.6</td><td>88.8</td></tr><tr><td>Arithmetic average</td><td>345.4/4=86.35</td><td>541.4/5=108.28</td><td>608.3/5=121.66</td><td>469.3/5=93.86</td></tr><tr><td rowspan="2">Chain relatives</td><td rowspan="2">100</td><td>100×108.28</td><td>121.66×108.28</td><td>93.86×131.73</td></tr><tr><td>100=108.28</td><td>100=131.73</td><td>100=123.64</td></tr><tr><td>Corrected chain relatives</td><td>100</td><td>108.28 - 1.675 =106.605</td><td>131.73 - 3.35 =128.38</td><td>123.64 - 5.025 =118.615</td></tr><tr><td>Seasonal indices</td><td>100×100/113.4=88.18</td><td>106.605/113.4×100=94.01</td><td>128.38/113.4×100=113.21</td><td>118.615/113.4×100=104.60</td></tr></table>

Thecalculations in theabove tableareexplained below： Chainrelative of thefirst quarter(on the basis offirst quarter $= 1 0 0$ Chainrelative of thefirst quarter(on the basis of the last quarter)

$$
= \frac {8 6 . 3 5 \times 1 2 3 . 6 4}{1 0 0} = 1 0 6. 7.
$$

Thedifference between these chain relatives=106.7-100=6.7.

Diferenceperquarter $= \frac { 6 . 7 } { 4 } = 1 . 6 7 5$

Adjustedchainrelatives areobtained by subtracting1×1.675，2×1.675，3×1.675fromthe chainrelativesof the 2nd,3rd and4th quartersrespectively.

Average of corrected chain relatives

$$
= \frac {1 0 0 + 1 0 6 . 6 0 5 + 1 2 8 . 3 8 + 1 1 8 . 6 1 5}{4} = \frac {4 5 3 . 6}{4} = 1 1 3. 4
$$

Seasonal variation index= orretchanraivesx10 113.4

# 5.5 Cyclical and Random Fluctuations

Cyclical fluctuations refer to the oscillations in data that occur in a systematic pattern over a longer period, typically aligned with economic or business cycles. These cycles are not fixed in length and can vary widely, commonly seen in economic indicators like GDP, employment rates, and business profits.

For example, economic activity tends to rise during expansions and fall during recessions, creating a cyclical pattern. Cycles can span several years, such as the typical business cycle of about 4 to 10 years.

# 5.5.1 Example of Cyclical Fluctuations

Consider the following quarterly GDP data for a hypothetical economy over five years:

<table><tr><td>Year</td><td>Q1</td><td>Q2</td><td>Q3</td><td>Q4</td></tr><tr><td>1</td><td>200</td><td>220</td><td>230</td><td>240</td></tr><tr><td>2</td><td>250</td><td>270</td><td>260</td><td>280</td></tr><tr><td>3</td><td>290</td><td>300</td><td>310</td><td>320</td></tr><tr><td>4</td><td>310</td><td>330</td><td>340</td><td>350</td></tr><tr><td>5</td><td>340</td><td>350</td><td>360</td><td>370</td></tr></table>

In this example, we can observe an increasing trend in GDP, but there may also be fluctuations that correspond to economic cycles, indicating periods of growth followed by stagnation or decline.

![](images/612b90c6905806c257e3a5d151a57ed9762872c92bc1ba9237d7f489e305aa69.jpg)  
Figure 15: Cyclic Variations

article amsmath amssymb graphicx array

# Methods for Measuring Cyclical Variations

Cyclical variations in data occur due to periodic fluctuations in economic activity, which can affect various sectors of the economy. Several methods are used to measure these variations effectively. The key methods include:

• Residual Method   
• Reference Cycle Analysis Method   
• Direct Method   
• Harmonic Analysis Method

# 1. Residual Method

The Residual Method involves isolating the cyclical component of a time series by removing the trend and seasonal components. The cyclical variation is derived as the residuals after fitting a trend line and seasonal pattern to the data.

# Steps:

1. Fit a trend line (linear, polynomial, etc.) to the time series data.   
2. Identify and remove seasonal variations.   
3. Calculate the residuals, which represent the cyclical variations.

# Example:

Given a time series data of quarterly sales figures:

$$
\mathrm {S a l e s} = [ 2 0 0, 2 2 0, 2 1 0, 2 4 0, 2 6 0, 2 8 0, 2 7 0, 3 0 0 ]
$$

Assume we fit a linear trend:

$$
\begin{array}{l} \text {T r e n d} = 1 8 0 + 1 0 t (t = 1, 2, \dots , 8) \end{array}
$$

The fitted values and residuals can be calculated as follows:

<table><tr><td>Quarter</td><td>Sales</td><td>Trend</td><td>Residuals</td></tr><tr><td>1</td><td>200</td><td>190</td><td>10</td></tr><tr><td>2</td><td>220</td><td>200</td><td>20</td></tr><tr><td>3</td><td>210</td><td>210</td><td>0</td></tr><tr><td>4</td><td>240</td><td>220</td><td>20</td></tr><tr><td>5</td><td>260</td><td>230</td><td>30</td></tr><tr><td>6</td><td>280</td><td>240</td><td>40</td></tr><tr><td>7</td><td>270</td><td>250</td><td>20</td></tr><tr><td>8</td><td>300</td><td>260</td><td>40</td></tr></table>

The residuals represent the cyclical variations.

# 2. Reference Cycle Analysis Method

The Reference Cycle Analysis Method involves comparing a specific cycle with a standard reference cycle. The cyclical components of different time series can be analyzed to identify similarities and differences against a benchmark.

# Steps:

1. Define a reference cycle based on historical data.   
2. Compare the current data cycle with the reference cycle.   
3. Measure deviations and similarities quantitatively.

# Example:

Suppose the reference cycle is defined as follows:

$$
\text {R e f e r e n c e C y c l e} = [ 1, 0. 9, 1. 1, 1. 2 ]
$$

We compare this with a new cycle:

$$
\text {C u r r e n t C y c l e} = [ 1. 1, 0. 8, 1. 2, 1. 3 ]
$$

The deviations can be calculated:

$$
\text {D e v i a t i o n} = \frac {\text {C u r r e n t C y c l e}}{\text {R e f e r e n c e C y c l e}} = [ 1. 1, 0. 8 9, 1. 0 9, 1. 0 8 ]
$$

This analysis helps in assessing the performance against established benchmarks.

# 3. Direct Method

The Direct Method involves directly measuring the cyclical component from the time series data without removing the trend or seasonal effects. This method focuses on identifying peaks and troughs in the data.

# Steps:

1. Identify the peaks and troughs in the data.   
2. Calculate the amplitude of the cycles (the difference between peaks and troughs).   
3. Analyze the duration of cycles to assess periodicity.

# Example:

Given a time series of monthly sales:

$$
\text {S a l e s} = [ 1 0 0, 1 2 0, 1 3 0, 1 2 5, 1 5 0, 1 6 0, 1 4 0, 1 3 0 ]
$$

Identifying peaks and troughs:

$$
\begin{array}{l l} \text {P e a k s} = [ 1 3 0, 1 5 0, 1 6 0 ] & \text {T r o u g h s} = [ 1 0 0, 1 2 5, 1 4 0 ] \end{array}
$$

The amplitudes can be calculated as follows:

$$
\text {A m p l i t u d e} = \text {P e a k} - \text {T r o u g h}
$$

For the first cycle:

$$
\mathrm {A m p l i t u d e} = 1 3 0 - 1 0 0 = 3 0
$$

And so forth for each cycle.

# 4. Harmonic Analysis Method

Harmonic Analysis Method is a mathematical technique used to decompose time series data into its constituent sine and cosine components. This method is effective in identifying cyclical patterns in data that may not be readily apparent.

# Steps:

1. Use Fourier transforms to convert the time series data into the frequency domain.   
2. Identify significant harmonics that represent cyclical variations.   
3. Reconstruct the cyclical component using selected harmonics.

# Example:

Suppose we have a time series data:

$$
\mathrm {D a t a} = [ 1, 2, 3, 4, 5, 4, 3, 2 ]
$$

Applying Fourier transform yields harmonics:

$$
\text {H a r m o n i c s} = \left[ A _ {1} \sin \left(\omega_ {1} t\right), A _ {2} \cos \left(\omega_ {2} t\right), \dots \right]
$$

Assuming two significant harmonics:

$$
\text {C y c l i c a l} = 2 \sin \left(\frac {2 \pi}{T} t\right) + 3 \cos \left(\frac {2 \pi}{T} t\right)
$$

Where $T$ is the period of the cycle.

The reconstructed cycle can show periodic behavior that highlights cyclical variations.

# Conclusion

Each of these methods provides unique insights into the cyclical variations in time series data. The choice of method depends on the nature of the data, the underlying cycles, and the objectives of the analysis.

# 5.6 Random Fluctuations

Random fluctuations are unpredictable variations in data that do not follow a discernible pattern. These fluctuations can be caused by irregular, unforeseen events such as natural disasters, political instability, or sudden market changes. Unlike cyclical fluctuations, random variations are typically short-term and do not contribute to the overall trend.

# 5.6.1 Example of Random Fluctuations

Consider a stock price over time that displays random fluctuations due to market sentiment, news events, or economic reports:

<table><tr><td>Day</td><td>Stock Price</td></tr><tr><td>1</td><td>100</td></tr><tr><td>2</td><td>98</td></tr><tr><td>3</td><td>102</td></tr><tr><td>4</td><td>101</td></tr><tr><td>5</td><td>95</td></tr><tr><td>6</td><td>110</td></tr><tr><td>7</td><td>97</td></tr><tr><td>8</td><td>105</td></tr><tr><td>9</td><td>99</td></tr><tr><td>10</td><td>103</td></tr></table>

In this example, the stock price fluctuates randomly without showing any consistent trend, indicating that the changes are primarily driven by unpredictable market forces.

# 5.6.2 Deseasonalisation

Deseasonalisation is the process of removing seasonal components from time series data to obtain data that reflects only the underlying trends and cycles. The resulting data, free from seasonal variations, is known as deseasonalised data.

# 1. Multiplicative Model

In a multiplicative model, the relationship between the observed data $Y _ { t }$ , the trend $T _ { t }$ , and the seasonal component $S _ { t }$ is given by:

$$
Y _ {t} = T _ {t} \times S _ {t}
$$

To deseasonalise the data, we divide the original data by the seasonal index. The seasonal index is typically expressed as a percentage, so we must adjust for that by using an adjustment multiplier of 100.

# Formula for Deseasonalisation:

$$
\mathrm {D e s e a s o n a l i s e d D a t a} = \frac {Y _ {t}}{\mathrm {S e a s o n a l I n d e x} \times 0 . 0 1}
$$

# Example:

Consider the following quarterly sales data and corresponding seasonal indices:

<table><tr><td>Quarter</td><td>Sales (Y)</td><td>Seasonal Index</td></tr><tr><td>Q1</td><td>120</td><td>110</td></tr><tr><td>Q2</td><td>150</td><td>90</td></tr><tr><td>Q3</td><td>180</td><td>100</td></tr><tr><td>Q4</td><td>200</td><td>130</td></tr></table>

Calculating the deseasonalised data:

$$
\text {D e s e a s o n a l i s e d S a l e s} (\mathrm {Q 1}) = \frac {1 2 0}{1 1 0 \times 0 . 0 1} = \frac {1 2 0}{1 . 1} \approx 1 0 9. 0 9
$$

$$
\text {D e s e a s o n a l i s e d S a l e s} (\mathrm {Q 2}) = \frac {1 5 0}{9 0 \times 0 . 0 1} = \frac {1 5 0}{0 . 9} \approx 1 6 6. 6 7
$$

$$
\text {D e s e a s o n a l i s e d S a l e s} (\mathrm {Q 3}) = \frac {1 8 0}{1 0 0 \times 0 . 0 1} = \frac {1 8 0}{1 . 0} = 1 8 0. 0 0
$$

$$
\text {D e s e a s o n a l i s e d S a l e s} (\mathrm {Q} 4) = \frac {2 0 0}{1 3 0 \times 0 . 0 1} = \frac {2 0 0}{1 . 3} \approx 1 5 3. 8 5
$$

The deseasonalised data is:

<table><tr><td>Quarter</td><td>Deseasonalised Sales</td></tr><tr><td>Q1</td><td>109.09</td></tr><tr><td>Q2</td><td>166.67</td></tr><tr><td>Q3</td><td>180.00</td></tr><tr><td>Q4</td><td>153.85</td></tr></table>

# 2. Additive Model

In an additive model, the relationship is expressed as:

$$
Y _ {t} = T _ {t} + S _ {t}
$$

In this case, deseasonalisation involves subtracting the seasonal component from the original data.

# Formula for Deseasonalisation:

$$
\text {D e s e a s o n a l i s e d D a t a} = Y _ {t} - S _ {t}
$$

# Example:

Using the same quarterly sales data:

<table><tr><td>Quarter</td><td>Sales (Y)</td><td>Seasonal Component (S)</td></tr><tr><td>Q1</td><td>120</td><td>10</td></tr><tr><td>Q2</td><td>150</td><td>20</td></tr><tr><td>Q3</td><td>180</td><td>30</td></tr><tr><td>Q4</td><td>200</td><td>40</td></tr></table>

Calculating the deseasonalised data:

$$
\text {D e s e a s o n a l i s e d S a l e s (Q 1)} = 1 2 0 - 1 0 = 1 1 0
$$

$$
\text {D e s e a s o n a l i s e d S a l e s (Q 2)} = 1 5 0 - 2 0 = 1 3 0
$$

$$
\text {D e s e a s o n a l i s e d S a l e s (Q 3)} = 1 8 0 - 3 0 = 1 5 0
$$

$$
\text {D e s e a s o n a l i s e d S a l e s (Q 4)} = 2 0 0 - 4 0 = 1 6 0
$$

The deseasonalised data is:

<table><tr><td>Quarter</td><td>Deseasonalised Sales</td></tr><tr><td>Q1</td><td>110</td></tr><tr><td>Q2</td><td>130</td></tr><tr><td>Q3</td><td>150</td></tr><tr><td>Q4</td><td>160</td></tr></table>

# Uses and Limitations of Seasonal Indices

# Uses:

• Seasonal indices provide a quantitative measure of typical seasonal behavior.   
• They are used for forecasting and making informed business decisions by understanding seasonal fluctuations.

# Limitations:

• Seasonal indices may not capture unexpected shocks or anomalies in data.   
• They rely on historical data, which may not always predict future patterns accurately.

# Conclusion

Deseasonalisation is a critical step in time series analysis, allowing analysts to focus on the underlying trends and cycles in data without the influence of seasonal fluctuations.

# 5.7 Variate Difference Methods

Variate difference methods, also known as difference methods or differencing, are techniques used in time series analysis to stabilize the mean of a time series by removing changes in the level of a time series, thereby making it stationary. This is particularly useful for analyzing seasonal data or trends.

# 5.7.1 Example 1: Monthly Sales Data

Consider a small business that records its monthly sales over six months as follows:

<table><tr><td>Month</td><td>Sales (in thousands)</td></tr><tr><td>1</td><td>50</td></tr><tr><td>2</td><td>60</td></tr><tr><td>3</td><td>70</td></tr><tr><td>4</td><td>80</td></tr><tr><td>5</td><td>65</td></tr><tr><td>6</td><td>75</td></tr></table>

To apply the variate difference method, we will calculate the first differences of the sales data.

# Step 1: Calculate First Differences

The first difference is calculated as:

$$
D _ {t} = Y _ {t} - Y _ {t - 1}
$$

Where $D _ { t }$ is the first difference at time $t$ and $Y _ { t }$ is the sales at time $t$ .

<table><tr><td>Month</td><td>Sales (Y)</td><td>First Difference (D)</td></tr><tr><td>1</td><td>50</td><td>-</td></tr><tr><td>2</td><td>60</td><td>60 - 50 = 10</td></tr><tr><td>3</td><td>70</td><td>70 - 60 = 10</td></tr><tr><td>4</td><td>80</td><td>80 - 70 = 10</td></tr><tr><td>5</td><td>65</td><td>65 - 80 = -15</td></tr><tr><td>6</td><td>75</td><td>75 - 65 = 10</td></tr></table>

# Step 2: Analyze the Differences

The first differences show that the sales increased consistently for the first four months but decreased in the fifth month. The last month, however, saw an increase again. This information helps the business understand that although sales fluctuated, the overall trend was increasing with occasional drops.

# 5.7.2 Example 2: Daily Temperature Records

Suppose we have daily temperature records for a week as follows:

<table><tr><td>Day</td><td>Temperature (°C)</td></tr><tr><td>1</td><td>20</td></tr><tr><td>2</td><td>22</td></tr><tr><td>3</td><td>24</td></tr><tr><td>4</td><td>23</td></tr><tr><td>5</td><td>25</td></tr><tr><td>6</td><td>27</td></tr><tr><td>7</td><td>26</td></tr></table>

We will apply the variate difference method to analyze the temperature changes.

# Step 1: Calculate First Differences

Using the same formula for first differences:

$$
D _ {t} = Y _ {t} - Y _ {t - 1}
$$

We calculate the first differences:

<table><tr><td>Day</td><td>Temperature (Y)</td><td>First Difference (D)</td></tr><tr><td>1</td><td>20</td><td>-</td></tr><tr><td>2</td><td>22</td><td>22 - 20 = 2</td></tr><tr><td>3</td><td>24</td><td>24 - 22 = 2</td></tr><tr><td>4</td><td>23</td><td>23 - 24 = -1</td></tr><tr><td>5</td><td>25</td><td>25 - 23 = 2</td></tr><tr><td>6</td><td>27</td><td>27 - 25 = 2</td></tr><tr><td>7</td><td>26</td><td>26 - 27 = -1</td></tr></table>

# Step 2: Analyze the Differences

From the first differences, we see that the temperature generally increased over the week, with minor fluctuations on days 4 and 7. The differences provide insight into the daily temperature variations, indicating stability with minor drops.

# Differencing

The simplest form of variate difference methods is first-order differencing, where the difference between consecutive observations is calculated. The first difference is given by:

$$
\Delta Y _ {t} = Y _ {t} - Y _ {t - 1}
$$

Where: - $Y _ { t }$ is the value at time $t$ , - $Y _ { t - 1 }$ is the value at the previous time period.

# Example of First-Order Differencing

Consider the following time series data representing monthly sales figures (in thousands):

<table><tr><td>Month</td><td>Sales</td></tr><tr><td>1</td><td>100</td></tr><tr><td>2</td><td>120</td></tr><tr><td>3</td><td>130</td></tr><tr><td>4</td><td>150</td></tr><tr><td>5</td><td>180</td></tr></table>

The first-order differences can be calculated as follows:

<table><tr><td>Month</td><td>Sales</td><td>ΔYt</td></tr><tr><td>1</td><td>100</td><td>-</td></tr><tr><td>2</td><td>120</td><td>120 - 100 = 20</td></tr><tr><td>3</td><td>130</td><td>130 - 120 = 10</td></tr><tr><td>4</td><td>150</td><td>150 - 130 = 20</td></tr><tr><td>5</td><td>180</td><td>180 - 150 = 30</td></tr></table>

The resulting first-order differences:

<table><tr><td>Month</td><td>ΔYt</td></tr><tr><td>2</td><td>20</td></tr><tr><td>3</td><td>10</td></tr><tr><td>4</td><td>20</td></tr><tr><td>5</td><td>30</td></tr></table>

# Second-Order Differencing

If the time series still shows non-stationarity after first differencing, a second-order differencing can be applied:

$$
\Delta^ {2} Y _ {t} = \Delta Y _ {t} - \Delta Y _ {t - 1}
$$

This method is useful in capturing the cyclical patterns that may remain even after the first differencing.

# Example of Second-Order Differencing

Continuing from the previous example, we calculate the second-order differences:

<table><tr><td>Month</td><td>ΔYt</td><td>Δ2yt</td></tr><tr><td>2</td><td>20</td><td>-</td></tr><tr><td>3</td><td>10</td><td>10 - 20 = -10</td></tr><tr><td>4</td><td>20</td><td>20 - 10 = 10</td></tr><tr><td>5</td><td>30</td><td>30 - 20 = 10</td></tr></table>

The second-order differences indicate the rate of change of the first differences, helping us understand the underlying dynamics of the time series data.

# 5.7.3 Conclusion

The variate difference methods are effective in analyzing trends and fluctuations in time series data. By calculating and interpreting the differences, we can derive valuable insights into the underlying patterns in the data.

# Question Bank

1. Distinguish between seasonal variations and cyclical fluctuations. How would you measure secular trend in any given data?   
2. Describe the method of link relatives for calculating the seasonal variation indices.   
3. How would you determine seasonal variation in the absence of trend?   
4. Briefly describe the relative merits and demerits of the ratio to trend and ratio to moving average methods.   
5. What do you understand by cyclical fluctuations in time series?   
6. What do you understand by random fluctuation in time series?   
7. Explain the term ”Business cycle” and point out the necessity of its study in time series analysis.   
8. Calculate seasonal variation for the following data of sales in thousands Rs. of a firm by the Ratio to trend method.

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>1979</td><td>30</td><td>40</td><td>36</td><td>34</td></tr><tr><td>1980</td><td>34</td><td>52</td><td>50</td><td>44</td></tr><tr><td>1981</td><td>40</td><td>58</td><td>54</td><td>48</td></tr><tr><td>1982</td><td>52</td><td>76</td><td>68</td><td>62</td></tr></table>

9. Calculate seasonal indices by the Ratio to moving average method from the following data.

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>1980</td><td>75</td><td>60</td><td>54</td><td>59</td></tr><tr><td>1981</td><td>86</td><td>65</td><td>63</td><td>80</td></tr><tr><td>1982</td><td>90</td><td>72</td><td>66</td><td>85</td></tr><tr><td>1983</td><td>100</td><td>78</td><td>72</td><td>93</td></tr></table>

10. The data below gives the average quarterly prices of a commodity for five years. Calculate seasonal indices by the method of link relatives.

<table><tr><td>Year</td><td>1st Quarter</td><td>2nd Quarter</td><td>3rd Quarter</td><td>4th Quarter</td></tr><tr><td>1979</td><td>30</td><td>26</td><td>22</td><td>31</td></tr><tr><td>1980</td><td>35</td><td>28</td><td>22</td><td>36</td></tr><tr><td>1981</td><td>31</td><td>29</td><td>28</td><td>32</td></tr><tr><td>1982</td><td>31</td><td>31</td><td>25</td><td>35</td></tr><tr><td>1983</td><td>34</td><td>36</td><td>26</td><td>33</td></tr></table>

# Module - 3

Chapter - 1

6 Index Numbers and their Definitions

6.1 Construction and Uses of Fixed and Chain based Index Numbers   
6.2 Simple and Weighted Index Numbers   
6.3 Laspeyres, Paasche’s, Fisher’s, and Marshall - Edgeworth Index Numbers   
6.4 Optimum Tests for Index Numbers   
6.5 Cost of Living Index Numbers

# Module - 3

Chapter - 2

# 7 Forecasting Strategies

7.1 Leading variables and associated variables   
7.2 Bass Model   
7.3 Exponential Smoothing and Holt-Winters method

# Module - 4

Chapter - 1

# 8 Basic Stochastic Models

8.1 White Noise, Random Walks, Fitted models & diagnostic plots   
8.2 Autoregressive models   
8.2.1 stationary and non-stationary Autoregressive process

# Module - 4

Chapter - 2

9 Time series Regression and Exploratory Data Analysis

9.1 Classical Regression   
9.2 Exploratory Data Analysis   
9.3 generalized least square method   
9.4 linear models with seasonal variables   
9.5 Harmonic seasonal models   
9.6 logarithmic transforms

# Module - 5

Chapter - 1

10 Linear Models   
10.1 Moving Average models   
10.2 Fitted MA Models   
10.2.1 Autoregressive Moving Average Models   
10.3 Differential Equations   
10.4 Autocorrelation and Partial Correlation   
10.5 Forecasting & Estimation   
10.6 Non-stationary Models   
10.6.1 Building non-seasonal ARIMA Models   
10.6.2 ARCH Models & GARCH Models

# STAT 248 - Analysis of Time Series Full Lecture Notes

Spring 2022, UC Berkeley

Aditya Guntuboyina

October 7, 2022

# Contents

# 1 Lecture One 4

1.1 State Space Models . 4   
1.2 Examples of State Space Models 5

1.2.1 Direct Examples: Tracking . . 5   
1.2.2 Trend Estimation . 6

1.3 Recommended Reading for Today . . . 7

# 2 Lecture Two 7

2.1 Local Level and Local Linear Models . 8   
2.2 Stochastic Volatility Models . 9   
2.3 Dynamic Regression Model 9   
2.4 Recommended Reading for Today . . . 10

# 3 Lecture Three 10

3.1 Connection to the Periodogram . . 13   
3.2 Recommended Reading for Today . . . 16

# 4 Lecture Four 17

4.1 The Autoregressive Model . 19   
4.2 Recommended Reading for Today . . . 21

# 5 Lecture Five 21

5.1 Outline of Approach to Calculate Smoothing Distributions . . 22   
5.2 Linear Gaussian State Space Models 23   
5.3 Recommended Reading for Today . . . 23

# 6 Lecture Six 24

6.1 General Approach for calculating Filtering Distributions . . 24   
6.2 The Kalman Filter 25   
6.3 Recommended Reading for Today . . 27

# 7 Lecture Seven 28

7.1 The Kalman Filter 28   
7.2 Some Examples . . 28

7.2.1 Tracking One: Velocity Model 29

7.2.2 Tracking Two: Acceleration Model 29   
7.2.3 Tracking Three: Local Linear Model . . 31

7.3 Use of the Kalman Filter for Parameter Estimation by Maximum Likelihood 31   
7.4 Recommended Reading for Today . . . 32

# 8 Lecture Eight 32

8.1 Some remarks on the local level model . 32   
8.2 Application of the Kalman Filter to Linear Regression 35   
8.3 Prediction 36   
8.4 Smoothing . . 36   
8.5 Recommended Reading for Today . . 37

# 9 Lecture Nine 37

9.1 Smoothing . . 37   
9.2 Backward Recursion for General State Space Models 37   
9.3 Smoothing for Linear Gaussian State Space Models . . 38   
9.4 Dealing with missing data in the context of state space models 41   
9.5 Recommended Reading for Today . . . 41

# 10 Lecture Ten 42

10.1 Summary: General Filtering and Smoothing . . 42   
10.2 Summary: Kalman Filtering and Smoothing . . . 43   
10.3 Special Case: Local Level Model 44   
10.4 Numerical Evaluation of $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ . . 45   
10.5 Recommended Reading for Today . . . 46

# 11 Lecture Eleven 46

11.1 Basic Optimization Algorithms 46

11.1.1 Gradient Ascent 46   
11.1.2 Newton’s Method . 47   
11.1.3 Quasi-Newton Method: BFGS 47

11.2 Application to Maximum Likelihood Estimation in State Space Models . . . . 49

11.2.1 Fisher Identity for the Score . . 49   
11.2.2 $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ for state space models 51

11.3 Recommended Reading for Today . . 52

# 12 Lecture Twelve 52

12.1 Pairwise Smoothing Distributions . 52   
12.2 Fisher’s Identity (from last time) 53   
12.3 The Score Function for the Local Level Model . 53   
12.4 The EM Algorithm . 55   
12.5 EM for the local level model . 55   
12.6 Calculation of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ for general state space models . 56   
12.7 Recommended Reading for Today . . 57

# 13 Lecture Thirteen 57

13.1 The MM Algorithm 57   
13.2 The EM Algorithm as a special case of MM 59

13.2.1 The Kullback-Leibler Divergence . 59   
13.2.2 EM and MM 60

13.3 Full Smoothing Distribution . 60   
13.4 Forward Filtering Backward SAMPLING 61   
13.5 Recommended Reading for Today . . . 62

# 14 Lecture Fourteen 63

14.1 Local Level Model 63   
14.2 Gibbs Sampler 64   
14.3 Gibbs Sampler for the Local Level Model 64   
14.4 Gibbs sampler for general Linear Gaussian state space models . 66   
14.5 Recommended Reading for Today . . 66

# 15 Lecture Fifteen 66

15.1 Approach One: Gibbs Sampling . . . 67   
15.2 Approach Two: Direct Sampling 67   
15.3 Approach Three: Posterior Normal Approximation 68   
15.4 Approach Four: Importance Sampling . . 69   
15.5 Recommended Reading for Today . . . 72

# 16 Lecture Sixteen 72

16.1 Notation for Discrete Distributions 73   
16.2 Monte Carlo versions of (99) and (100) . . 74   
16.3 The Bootstrap Particle Filter 75   
16.4 Importance Sampling Recalled 76   
16.5 Bootstrap Particle Filter as Importance Resampling . . 77

16.5.1 First Way of Seeing the Connection 77   
16.5.2 Second Way of Seeing the Connection 78

16.6 Likelihood Approximation from the Bootstrap Particle Filter 78   
16.7 Recommended Reading for Today . . 79

# 17 Lecture Seventeen 79

17.1 Recap: Bootstrap Particle Filter 79   
17.2 Unique Values and Particle Degeneracy 80   
17.3 The Guided Particle Filter Algorithm 81   
17.4 Weights when $q _ { t } ( u \mid x , y , \theta ) : = f _ { X _ { t } | X _ { t - 1 } = x , Y _ { t } = y , \theta } ( u )$ 83   
17.5 Example: Local Level Model 83   
17.6 Recommended Reading for Today . . . 84

# 18 Lecture Eighteen 84

18.1 Sequential Importance Resampling . 84   
18.2 Example: Local Level Model with non-Gaussian evolution errors 85   
18.3 Recommended Reading for Today . . 88

# 19 Lecture Nineteen 89

19.1 Complete Smoothing . . 89   
19.2 FFBS 91   
19.3 Recommended Reading for Today . . . 93

# 20 Lecture Twenty 94

20.1 Recap: Complete Smoothing 94   
20.2 Complete Smoothing with partial trajectory resampling . . 94   
20.3 Recap: FFBS 95   
20.4 Recommended Reading for Today . . 96

# 21 Lecture Twenty One 96

21.1 Model Selection . 96   
21.2 Akaike Information Criterion (AIC) 96

21.2.1 The simple case of no parameters . 97

21.2.2 Models with parameters 98   
21.2.3 Digression: MLE asymptotic distribution 98

21.3 Back to AIC 104   
21.4 Recommended Reading for Today . . . 105

# 22 Lecture Twenty Two 106

22.1 Recap: AIC 106   
22.2 Bayesian Model Selection 107   
22.3 Two Alternative Expressions for the Evidence . . 110   
22.4 The BIC 111   
22.5 Recommended Reading for Today . . . 112

# 23 Lecture Twenty Three 112

23.1 Recap: Frequentist and Bayesian Model Selection . . 112   
23.2 Example: Normal Mean 113   
23.3 Application: Linear Regression 114   
23.4 Recommended Reading for Today . . 117

# 1 Lecture One

Time series refers to observations collected sequentially in time. One can have univariate time series (where a single observation is collected at each point in time) or multivariate time series (where a bunch of obserations are collected at each point in time). In this class, we shall denote the observed time series by

$$
y _ {0}, y _ {1}, \dots , y _ {T}.
$$

Here $y _ { 0 }$ denotes the observed value at the first time point, $y _ { 1 }$ denotes the observed value at the second time point etc. Typically the time points where the observations are taken are uniformly spaced but there do exist situations where the time points are not uniformly spaced (if the time points are not uniformly spaced, we shall denote them by $t _ { 0 } , t _ { 1 } , \dots , t _ { T }$ and note that the observation $y _ { i }$ corresponds to the time $t _ { i }$ ).

Time series are commonly analyzed through time series models. These models assume first that the observed time series $y _ { 0 } , \ldots , y _ { T }$ are a realization of random variables $Y _ { 0 } , Y _ { 1 } , \dots , Y _ { T }$ , and then proceed to describe the joint distribution of $Y _ { 0 } , \ldots , Y _ { T }$ . We shall focus on State Space Models in this class as these are a general class of time series models with wide applicability.

# 1.1 State Space Models

State space models assume that $\{ Y _ { t } , 0 \leq t \leq T \}$ are noisy measurements of a hidden or latent Markov process $\{ X _ { t } , 0 \leq t \leq T \}$ .

Here $\{ X _ { t } , 0 \leq t \leq T \}$ is a Markov process means that the conditional distribution of $X _ { t }$ given $X _ { t - 1 } = x _ { t - 1 } , \ldots , X _ { 0 } = x _ { 0 }$ is the same as the conditional distribution of $X _ { t }$ given $X _ { t - 1 } = x _ { t - 1 }$ for every $1 \leq t \leq T$ and $x _ { 0 } , x _ { 1 } , \ldots , x _ { t }$ . We shall denote the density of $X _ { 0 }$ by $p _ { 0 } ( \cdot )$ and the density of $X _ { t }$ given $X _ { t - 1 } = x _ { t - 1 }$ by $p _ { t } ( x _ { t } \mid x _ { t - 1 } )$ for $t = 1 , \dots , T$ . $p _ { 0 }$ is called the initial distribution of the Markov process $\{ X _ { t } \}$ and $p _ { t } ( x _ { t } \mid x _ { t - 1 } )$ is called the $t ^ { t h }$ transition density. If the transition densities are the same for all $t$ , we say that $\{ X _ { t } \}$ is a time

homogeneous Markov process (otherwise, $\{ X _ { t } \}$ is said to be a time inhomogeneous Markov process). Note that the joint density of $X _ { 0 } , \ldots , X _ { T }$ equals

$$
p _ {0} (x _ {0}) p _ {1} (x _ {1} \mid x _ {0}) \dots p _ {T} (x _ {T} \mid x _ {T - 1}) = p _ {0} (x _ {0}) \prod_ {t = 1} ^ {T} p _ {t} (x _ {t} \mid x _ {t - 1}).
$$

State space models specify that $\{ X _ { t } , 0 \leq t \leq T \}$ is a Markov process and, additionally, that $Y _ { 0 } , \ldots , Y _ { T }$ are independent conditionally on $X _ { 0 } , \ldots , X _ { T }$ and, moreoever, that the conditional distribution of $Y _ { t }$ given $X _ { 0 } = x _ { 0 } , \dots , X _ { T } = x _ { T }$ is the same as the conditional distribuion of $Y _ { t }$ given $X _ { t } = x _ { t }$ for each $0 \leq t \leq T$ . We shall denote the conditional density of $Y _ { t }$ given $X _ { t } = x _ { t }$ by $f _ { t } ( y _ { t } \mid x _ { t } )$ . The conditional joint density of $Y _ { 0 } , \ldots , Y _ { T }$ given $X _ { 0 } = x _ { 0 } , \dots , X _ { T } = x _ { T }$ equals

$$
\prod_ {t = 0} ^ {T} f _ {t} (y _ {t} \mid x _ {t}).
$$

To summarize, state space models specify that the joint distribution $X _ { 0 } , Y _ { 0 } , \ldots , X _ { T } , Y _ { T }$ equals

$$
p _ {0} \left(x _ {0}\right) \prod_ {t = 1} ^ {T} p _ {t} \left(x _ {t} \mid x _ {t - 1}\right) \prod_ {t = 0} ^ {T} f _ {t} \left(y _ {t} \mid x _ {t}\right). \tag {1}
$$

The random variables $X _ { 0 } , \ldots X _ { T }$ are known as state variables (or hidden or latent variables) and $Y _ { 0 } , \ldots , Y _ { T }$ are known as data variables. Observe that the joint density of the data variables $Y _ { 0 } , \ldots , Y _ { T }$ is given by integrating (1) with respect to $x _ { 0 } , \ldots , x _ { T }$ :

$$
\int \dots \int \left[ p _ {0} (x _ {0}) \prod_ {t = 1} ^ {T} p _ {t} (x _ {t} \mid x _ {t - 1}) \prod_ {t = 0} ^ {T} f _ {t} (y _ {t} \mid x _ {t}) \right] d x _ {0} d x _ {1} \ldots d x _ {T}
$$

State space models can also be referred to as Hidden Markov Models although some authors use Hidden Markov Models to refer to models where the state variables $X _ { t }$ are discrete random variables.

# 1.2 Examples of State Space Models

# 1.2.1 Direct Examples: Tracking

In tracking problems, the goal is to track the movement of an unknown moving object from noisy measurements $\{ Y _ { t } \}$ . Here the state space model directly arises with the state variable $X _ { t }$ representing attributes of the moving object (such as position and velocity). To give a concrete example, consider a body moving in the two-dimensional plane. Suppose we discretize time to a resolution $\delta$ (so that the time points are $t _ { 0 } , t _ { 1 } , \ldots$ with $t _ { k } = k \delta$ ).

Denote the position of the object at time $t _ { k }$ by $\left( \boldsymbol { x } _ { 1 k } , \boldsymbol { x } _ { 2 k } \right)$ (remember we are assuming that the movement is in the two-dimensional plane). Also let the velocity of the object at time $t _ { i }$ is $( x _ { 3 k } , x _ { 4 k } )$ . If the velocity in the time period $[ t _ { k - 1 } , t _ { k } ]$ is assumed to be nearly constant, we would have

$$
x _ {1 k} \approx x _ {1, k - 1} + \delta x _ {3, k - 1} \quad \mathrm {a n d} \quad x _ {2 k} \approx x _ {2, k - 1} + \delta x _ {4, k - 1}.
$$

One can assume these equations to be exact (as opposed to approximate) by incorporating error variables:

$$
x _ {1 k} = x _ {1, k - 1} + \delta x _ {3, k - 1} + q _ {1 k} \quad \text {a n d} \quad x _ {2 k} = x _ {2, k - 1} + \delta x _ {4, k - 1} + q _ {2 k}
$$

Here $q _ { 1 k } , q _ { 2 k }$ denote error variables which can be modeled as i.i.d with a normal distribution. Further the assumption that the velocity is nearly constant in the time period $[ t _ { k - 1 } , t _ { k } ]$ can be written as

$$
x _ {3, k} \approx x _ {3, k - 1} \quad \mathrm {a n d} \quad x _ {4, k} \approx x _ {4, k - 1}.
$$

These two equations can also be assumed to be exact by incorporating error variables:

$$
x _ {3 k} = x _ {3, k - 1} + q _ {3 k} \quad \text {a n d} \quad x _ {4 k} = x _ {4, k - 1} + q _ {4 k}.
$$

If we therefore let

$$
X _ {k} = \left( \begin{array}{c} x _ {1 k} \\ x _ {2 k} \\ x _ {3 k} \\ x _ {4 k} \end{array} \right)
$$

denote the position and velocities of the unknown object, then $X _ { k }$ satisfies the equation

$$
X _ {k} = \left( \begin{array}{c c c c} 1 & 0 & \delta & 0 \\ 0 & 1 & 0 & \delta \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{array} \right) X _ {k - 1} + q _ {k} \quad \text {w h e r e} q _ {k} = \left( \begin{array}{c} q _ {1 k} \\ q _ {2 k} \\ q _ {3 k} \\ q _ {4 k} \end{array} \right)
$$

If we assume that $q _ { k }$ are i.i.d, then it is easy to check that $\{ X _ { k } \}$ is a Markov process.

The observation $Y _ { k }$ here is a noisy measurement of $X _ { k }$ . The exact relationship between $Y _ { k }$ and $X _ { k }$ depends on the nature of the measurements. Suppose that we are obtaining noisy measurements only of the position of the object. Then

$$
Y _ {k} = \left( \begin{array}{c} x _ {1 k} \\ x _ {2 k} \end{array} \right) + \left( \begin{array}{c} \epsilon_ {1 k} \\ \epsilon_ {2 k} \end{array} \right) = \left( \begin{array}{c c c c} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \end{array} \right) X _ {k} + \left( \begin{array}{c} \epsilon_ {1 k} \\ \epsilon_ {2 k} \end{array} \right)
$$

Suppose we assume that $\epsilon _ { k } = { \binom { \epsilon _ { 1 k } } { \epsilon _ { 2 k } } }$ 1k are i.i.d and also that the two error sequences $\left\{ \epsilon _ { k } \right\}$ and 2k $\left\{ q _ { k } \right\}$ are independent. Then this represents a state space model (it turns out that this is a linear Gaussian state space model as will be clear soon).

In another measurement model, we could only be measuring the angle that the unknown object makes with the positive $x$ -axis (this is sometimes known as bearings-only tracking). Here we would have

$$
Y _ {k} = \arctan \left(\frac {x _ {2 k}}{x _ {1 k}}\right) + \epsilon_ {k}.
$$

This is again a state-space model (this is a nonlinear state space model).

# 1.2.2 Trend Estimation

State space models can be used to estimate trend in state space models. Trend in a time series can be generally understood as a smooth function that tracks well the evolution or course of the time series. One way of estimating a smooth trend is via the following state space model. As usual, we let $Y _ { 0 } , \ldots , Y _ { T }$ to be the data random variables. The idea is that the hidden state variables $X _ { 0 } , \ldots , X _ { T }$ represent the trend. Because trend is supposed to be smooth, we assume that

$$
X _ {t} = X _ {t - 1} + \eta_ {t} \qquad \mathrm {w i t h} \eta_ {k} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\eta} ^ {2}). \tag {2}
$$

This equation says that $X _ { t }$ is centered around $X _ { t - 1 }$ with an error whose size is controlled by $\sigma _ { \eta }$ . If $\sigma _ { \eta }$ is small, then $X _ { t } \approx X _ { t - 1 }$ representing a smooth trend. Note that (2) clearly implies that $\{ X _ { t } \}$ is a Markov process.

The data variables $Y _ { t }$ are connected to the state variables $X _ { t }$ via

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \quad \text {w i t h} \epsilon_ {t} ^ {\text {i . i . d}} N \left(0, \sigma_ {\epsilon} ^ {2}\right). \tag {3}
$$

This equation captures the intuition that the trend $X _ { t }$ tracks the time series $Y _ { t }$ .

The noise parameters $\sigma _ { \eta }$ and $\sigma _ { \epsilon }$ control the twin objectives of smooth trend and tracking the data respectively. If $\sigma _ { \eta }$ is small, we would get smoother trends while if $\sigma _ { \epsilon }$ is small, our trend estimate will closely track the data. Note however if the observed time series $y _ { t }$ is not very smooth, then both the objectives cannot be simultaneously achieved. In general, one chooses $\sigma _ { \eta }$ and $\sigma _ { \epsilon }$ so as to obtain the best fit to the data (we shall see all this later).

The state space model given by the pair of equations (2) and (3) is called the local level model. It is a common way of estimating trend in time series.

# 1.3 Recommended Reading for Today

1. Definition of State Space Models: Sections 2.1 and 2.2 of the Chopin-Papaspiliopoulos book.   
2. Tracking application of State Space Models: Section 2.4.1 of the Chopin-Papaspiliopoulos book, and Section 1.3.2 of the Triantafyllopoulos book.   
3. Local level model: Section 2.1 of the Durbin-Koopman book, and Section 1.2 of the Triantafyllopoulos book.

# 2 Lecture Two

In the last class, we introduced state space models and looked at two examples (a tracking model and the local level model). To recap, state space models describe the distribution of $Y _ { 0 } , \ldots , Y _ { T }$ in terms of a hidden set of random variables $X _ { 0 } , \ldots , X _ { T }$ . The joint distribution of $X _ { 0 } , Y _ { 0 } , \ldots , X _ { T } , Y _ { T }$ is specified via the joint density:

$$
p _ {0} \left(x _ {0}\right) \prod_ {t = 1} ^ {T} p _ {t} \left(x _ {t} \mid x _ {t - 1}\right) \prod_ {t = 0} ^ {T} f _ {t} \left(y _ {t} \mid x _ {t}\right). \tag {4}
$$

This means that the density of $X _ { 0 }$ is $p _ { 0 }$ , the conditional density of $X _ { t }$ given $X _ { t - 1 } = x _ { t - 1 }$ (as well as given $X _ { t - 1 } = x _ { t - 1 } , \ldots , X _ { 0 } = x _ { 0 }$ ) equals $p _ { t } ( x _ { t } \mid x _ { t - 1 } )$ and the conditional density of $Y _ { t }$ given $X _ { t } = x _ { t }$ (as well as given $X _ { t } = x _ { t } , X _ { s } = x _ { s }$ for $s \neq t$ ) equals $f _ { t } ( y _ { t } \mid x _ { t } )$ .

Specifying the joint distribution via the joint density (4) requires writing down $p _ { 0 } ( x _ { 0 } )$ , $p _ { t } ( x _ { t } \mid x _ { t - 1 } )$ as well as $f _ { t } ( y _ { t } \mid x _ { t } )$ . In practice, people specify state space models via equations involving independent random variables. More precisely, one usually first specifies the distribution $p _ { 0 }$ of $X _ { 0 }$ (this is often a diffuse density such as a normal with a large variance or a uniform over a large range), and then specify the distribution of $X _ { t }$ via the equation:

$$
X _ {t} = K _ {t} \left(X _ {t - 1}, U _ {t}\right) \quad \text {f o r} t = 1, 2, \dots \tag {5}
$$

where $\{ U _ { t } \}$ are independent random variables that are also independent of $X _ { 0 }$ . Finally the distribution of $Y _ { t }$ is specified via

$$
Y _ {t} = H _ {t} (X _ {t}, V _ {t}) \qquad \mathrm {f o r} t = 0, 1, 2, \ldots \tag {6}
$$

where $\{ V _ { t } \}$ are independent random variables that are also independent of $\left\{ U _ { t } \right\}$ and $X _ { 0 }$ . The functions $K _ { t }$ and $H _ { t }$ in (5) and (6) can be completely arbitrary.

Linear Gaussian State Space Models form a special case of state space models (inference is particularly easy in linear Gaussian State Space Model because of the Kalman filter; as we shall study in the next few weeks). Specifically, for a linear Gaussian state space model, $X _ { 0 }$ is normal, the state evolution equation (5) takes the form

$$
X _ {t} = F _ {t - 1} X _ {t - 1} + U _ {t} \qquad \mathrm {w i t h} U _ {t} \stackrel {\mathrm {i n d e p e n d e n t}} {\sim} N (0, Q _ {t})
$$

and the observation equation (6) takes the form

$$
Y _ {t} = H _ {t} X _ {t} + V _ {t} \qquad \mathrm {w i t h} V _ {t} \stackrel {\mathrm {i n d e p e n d e n t}} {\sim} N (0, R _ {t})
$$

Here $F _ { t - 1 }$ and $H _ { t }$ are deterministic matrices, and $Q _ { t }$ and $R _ { t }$ are covariance matrices. Note that for the linear Gaussian state space model, each of the densities $p _ { 0 } ( x _ { 0 } )$ , $p _ { t } ( x _ { t } \mid x _ { t - 1 } )$ and $f _ { t } ( y _ { t } \mid x _ { t } )$ are normal with mean being a linear function of the underlying variable and the covariance being a deterministic matrix.

We shall look at a few additional examples of state space models today.

# 2.1 Local Level and Local Linear Models

In the last class, we looked at the simple local level model:

$$
X _ {0} \sim N (m _ {0}, \Gamma_ {0})
$$

$$
X _ {t} = X _ {t - 1} + \eta_ {t} \qquad \mathrm {w i t h} \eta_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\eta} ^ {2})
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

This model has the two parameters $\sigma _ { \eta } ^ { 2 }$ and $\sigma _ { \epsilon } ^ { 2 }$ (the parameters $m _ { 0 }$ and $\Gamma _ { 0 }$ of $X _ { 0 }$ are usually set to be some standard values corresponding to a diffuse distribution such $m _ { 0 } = 0$ and $\Gamma _ { 0 } = 1 0 ^ { 8 }$ ). We have seen simulation examples involving smooth trend estimation where this model does a decent job in recovering the underlying smooth trend function (it does not work however when the underlying trend function is nonsmooth). But often the trend estimate provided by this model is somewhat wiggly and we might want to obtain a smoother fit. This can be achieved by the local linear model given by

$$
X _ {0} \sim N (m _ {0}, \Gamma_ {0})
$$

$$
X _ {t} - X _ {t - 1} = X _ {t - 1} - X _ {t - 2} + \eta_ {t} \qquad \mathrm {w i t h} \eta_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\eta} ^ {2})
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

The difference between the local level and the local linear models is that the random walk specification in the local linear model is in terms of the slopes $X _ { t } - X _ { t - 1 }$ as opposed to the levels as in the local level model. This generally leads to smoother fits.

Note that the local linear model is also a state space model even though $\{ X _ { t } \}$ as defined by $X _ { t } - X _ { t - 1 } = X _ { t - 1 } - X _ { t - 2 } + \eta _ { t }$ is not Markov. This is because we can rewrite the model in terms of the state variable $\ddot { X } _ { t }$ defined by

$$
\tilde {X} _ {t} := \left( \begin{array}{c} X _ {t} \\ X _ {t - 1} \end{array} \right).
$$

The equation $X _ { t } - X _ { t - 1 } = X _ { t - 1 } - X _ { t - 2 } + \eta _ { t }$ is easily seen to be equivalent to

$$
\tilde {X} _ {t} = \left( \begin{array}{c c} 2 & - 1 \\ 1 & 0 \end{array} \right) \tilde {X} _ {t - 1} + \left( \begin{array}{c} \eta_ {t} \\ 0 \end{array} \right)
$$

which implies that $\{ \tilde { X } _ { t } \}$ is a Markov process. The observation equation $Y _ { t } = X _ { t } + \epsilon _ { t }$ can be written in terms of $\ddot { X } _ { t }$ as

$$
Y _ {t} = \left(1 0\right) \tilde {X} _ {t} + \epsilon_ {t}.
$$

This shows that the local linear model is also a state space model.

This re-writing of a second order Markov process $\{ X _ { t } \}$ in terms of the Markov process ${ \ddot { X } } _ { t }$ is reminiscent of a similar argument in Ordinary Differential Equations. For example, the second order differential equation

$$
x ^ {\prime \prime} (t) = - \omega^ {2} x (t)
$$

can be re-written as the first order differential equation

$$
\left( \begin{array}{c} x _ {1} ^ {\prime} (t) \\ x _ {2} ^ {\prime} (t) \end{array} \right) = \left( \begin{array}{c c} 0 & 1 \\ - \omega^ {2} & 0 \end{array} \right) \left( \begin{array}{c} x _ {1} (t) \\ x _ {2} (t) \end{array} \right)
$$

# 2.2 Stochastic Volatility Models

Consider the model

$$
X _ {t} = X _ {t - 1} + \eta_ {t} \qquad \mathrm {w i t h} \eta_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\eta} ^ {2})
$$

$$
Y _ {t} = \exp \left(X _ {t} / 2\right) \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

Data generated from this model exhibits volatility clustering i.e., the variance remains high or low for considerable periods of time. This model is useful for finance data (say for logreturns of stocks) which exhibit volatility clustering. This model is an alternative to volatility time series models such as ARCH or GARCH (which are somewhat less natural even though they are widely used). It is easy to check that this is also a state space model (it is not a linear Gaussian state space model however).

# 2.3 Dynamic Regression Model

Consider the following model for a response variable $Y _ { t }$ and an explanatory variable $x t$ ( $x t$ will be treated as deterministic and non-random in the model below) which are both indexed by time $t = 0 , 1 , \ldots , T$ . Dynamic regression models (also known as linear regression with time varying parameters) are of the form:

$$
y _ {t} = \alpha_ {t} + \beta_ {t} x _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

The difference with the usual simple linear regression model is that both the intercept and the slope coefficients above are allowed to depend on $t$ . In order to make estimation of this model feasible, we need further restrictions on $\left\{ \alpha _ { t } \right\}$ and $\{ \beta _ { t } \}$ (otherwise there are just too many parameters in the model). One simple restriction is to assume that:

$$
\alpha_ {t} = \alpha_ {t - 1} + w _ {\alpha , t} \qquad \mathrm {w i t h} w _ {\alpha , t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\alpha} ^ {2})
$$

$$
\beta_ {t} = \beta_ {t - 1} + w _ {\beta , t} \qquad \text {w i t h} w _ {\beta , t} \stackrel {{\mathrm {i . i . d}}} {{\sim}} N (0, \sigma_ {\beta} ^ {2})
$$

Note that this is an example of a state space model with the state variable:

$$
S _ {t} = \left( \begin{array}{c} \alpha_ {t} \\ \beta_ {t} \end{array} \right)
$$

which satisfies

$$
S _ {t} = S _ {t - 1} + \left( \begin{array}{c} w _ {\alpha t} \\ w _ {\beta t} \end{array} \right)
$$

which implies that the state process is Markov. Further the observation equation can be written as

$$
Y _ {t} = \left( \begin{array}{c c} 1 & x _ {t} \end{array} \right) S _ {t} + \epsilon_ {t}.
$$

Dynamic regression models are used in many regression situations where the response and explanatory variables are collected in time. One example is when $y _ { t }$ gives the returns on a particular stock and $x _ { t }$ gives the average returns of the market. Then the dynamic regression model allows one to study the performance of the stock with respect to the average performance of the market over the course of time.

# 2.4 Recommended Reading for Today

1. For a description of linear Gaussian state space models, see Section 2.4 of the Petris-Petrone-Campagnoli book and Section 3.1 of the Durbin-Koopman book.   
2. Local Linear Model: Section 3.2.1 of the Durbin-Koopman book, Section 11.3 of the Kitagawa book.   
3. Stochastic volatility models: page 49 of Petris-Petrone-Campagnoli, Section 2.4.3 of Chopin-Papaspiliopoulos, Section 1.3.3 of Triantafyllopoulos   
4. Dynamic linear regression: Section 3.2.7 of Petris-Petrone-Campagnoli and Section 4.1.5 of Triantafyllopoulos.

# 3 Lecture Three

We are in the midst of looking at different applications of state space models. Our next step is to see that ARMA models are special cases of state space models. We shall first consider the AR(2) model before going to general state space models. Historically, the AR(2) model was introduced in the context of the sunspots data (see the classical 1927 paper titled “On a method of investigating periodicities disturbed series, with special reference to Wolfer’s sunspot numbers” by G. Udny Yule or the 2011 book “The Foundations of Modern Time Series Analysis” by T.C. Mills). It is often claimed that (see, for example, https://en. wikipedia.org/wiki/Sunspot) the sunspot number varies according to an approximately 11-year cycle. We can verify this by fitting the simple sinusoidal model:

$$
Y _ {i} = \mu + \alpha_ {1} \cos (\omega t _ {i}) + \alpha_ {2} \sin (\omega t _ {i}) + \epsilon_ {i} \quad \text {f o r} i = 1, \dots , n \tag {7}
$$

to the observed data $( t _ { 1 } , y _ { 1 } ) , \ldots , ( t _ { n } , y _ { n } )$ . Here $t _ { i }$ refers to year $i$ and $y _ { i }$ denotes the average number of sunspots for year $t _ { i }$ . In the dataset (obtained from https://wwwbis.sidc.be/ silso/infosnytot), we have data for all years from 1700 to 2019. So we are analyzing the whole data, we can take $n = 3 2 0$ and $t _ { 1 } = 1 7 0 0 , t _ { 2 } = 1 7 0 1 , t _ { 3 } = 1 7 0 2 , . . . , t _ { n } = 2 0 1 9$ . In general, it is not necessary to have the observed times $t _ { i }$ to be consecutive (i.e., it is okay for the time series to have some observation gaps).

Today, we shall study the problem of fitting the model (7) and obtaining estimates of the frequency parameter $\omega$ from the sunspots data. Note that, if we believe the 11-year cycle for the sunspots data, then we would expect the data to give an estimate of $\omega$ (in the model (7)) that is close to $2 \pi / 1 1 = 0 . 5 7 1 2$ . In the next class, we shall see the connection between the model (7) and AR(2).

For the model (7), we shall assume that

$$
\epsilon_ {1}, \ldots , \epsilon_ {n} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma^ {2})
$$

which is the most standard distributional assumption for errors. The problem then is to estimate the frequency parameter $\omega$ . The other four parameters $\mu , \alpha _ { 1 } , \alpha _ { 2 } , \sigma$ are unknown but they are not our main focus (these parameters can be termed nuisance parameters). For principled estimation of $\omega$ in the presence of the nuisance parameters $\mu , \alpha _ { 1 } , \alpha _ { 2 } , \sigma$ , we shall take the Bayesian approach with the following natural prior:

$$
\omega , \mu , \alpha_ {1}, \alpha_ {2}, \log \sigma \stackrel {\mathrm {i . i . d}} {\sim} \operatorname {U n i f} (- C, C)
$$

for a large number $C$ (the exact value of $C$ will not matter in the following calculations). Note that as $\sigma$ is always positive, we have made the uniform assumption on $\log \sigma$ (by the change of variable formula, we would have fσ(x) = flog σ(log x) 1x = I{−C<log x<C}2Cx = I{e−C <x<eC }2Cx . $\begin{array} { r } { f _ { \sigma } ( x ) = f _ { \log \sigma } ( \log x ) \frac { 1 } { x } = \frac { I \{ - C < \log x < C \} } { 2 C x } = \frac { I \{ e ^ { - C } < x < e ^ { C } \} } { 2 C x } } \end{array}$ 2C 2Cx

The posterior for all the unknown parameters $\omega , \mu , \alpha _ { 1 } , \alpha _ { 2 } , \log \sigma$ is then (below we write the term “data” for $Y _ { 1 } = y _ { 1 } , . . . , Y _ { n } = y _ { n }$ ):

$$
f _ {\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma | \mathrm {d a t a}} (\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma) \propto f _ {Y _ {1}, \ldots , Y _ {n} | \omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma} (y _ {1}, \ldots , y _ {n}) f _ {\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma} (\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma).
$$

The two terms on the right hand side above are

$$
\begin{array}{l} f _ {Y _ {1}, \dots , Y _ {n} | \omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma} (y _ {1}, \dots , y _ {n}) \propto \prod_ {i = 1} ^ {n} f _ {Y _ {i} | \omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma} (y _ {i}) \\ = \prod_ {i = 1} ^ {n} f _ {\epsilon_ {i} | \mu , \sigma , \alpha_ {1}, \alpha_ {2}, \sigma} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i})) \\ = \prod_ {i = 1} ^ {n} \frac {1}{\sqrt {2 \pi} \sigma} \exp \left(- \frac {(y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2}}{2 \sigma^ {2}}\right) \\ \propto \sigma^ {- n} \exp \left(- \frac {1}{2 \sigma^ {2}} \sum_ {i = 1} ^ {n} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2}\right), \\ \end{array}
$$

and

$$
\begin{array}{l} f _ {\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma} (\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma) = f _ {\omega} (\omega) f _ {\mu} (\mu) f _ {\alpha_ {1}} (\alpha_ {1}) f _ {\alpha_ {2}} (\alpha_ {2}) f _ {\sigma} (\sigma) \\ \propto \frac {I \{- C <   \omega <   C \}}{2 C} \frac {I \{- C <   \mu <   C \}}{2 C} \frac {I \{- C <   \alpha_ {1} <   C \}}{2 C} \frac {I \{- C <   \alpha_ {2} <   C \}}{2 C} \frac {I \{e ^ {- C} <   \sigma <   e ^ {C} \}}{2 C \sigma} \\ \propto \frac {1}{\sigma} I \left\{- C <   \omega , \mu , \alpha_ {1}, \alpha_ {2}, \log \sigma <   C \right\}. \\ \end{array}
$$

We thus obtain

$$
\begin{array}{l} f _ {\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma | \mathrm {d a t a}} (\omega , \mu , \alpha_ {1}, \alpha_ {2}, \sigma) \\ \propto \sigma^ {- n - 1} \exp \left(- \frac {1}{2 \sigma^ {2}} \sum_ {i = 1} ^ {n} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2}\right) I \left\{- C <   \omega , \mu , \alpha_ {1}, \alpha_ {2}, \log \sigma <   C \right\}. \\ \end{array}
$$

To obtain the posterior density of $\omega$ , we simply integrate the above with respect to $\mu , \alpha _ { 1 } , \alpha _ { 2 } , \sigma$ Thus for every $\omega \in ( - C , C )$ ,

$$
f _ {\omega | \mathrm {d a t a}} (\omega) \propto \int_ {e ^ {- C}} ^ {e ^ {C}} \int_ {- C} ^ {C} \int_ {- C} ^ {C} \int_ {- C} ^ {C} \sigma^ {- n - 1} \exp \left(- \frac {\sum_ {i = 1} ^ {n} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2}}{2 \sigma^ {2}}\right) d \mu d \alpha_ {1} d \alpha_ {2} d \sigma .
$$

When $C$ is large, the above integral is well-approximated by

$$
\int_ {0} ^ {\infty} \int_ {- \infty} ^ {\infty} \int_ {- \infty} ^ {\infty} \int_ {- \infty} ^ {\infty} \sigma^ {- n - 1} \exp \left(- \frac {\sum_ {i = 1} ^ {n} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2}}{2 \sigma^ {2}}\right) d \mu d \alpha_ {1} d \alpha_ {2} d \sigma .
$$

This integral can be evaluated exactly. The calculation is easiest done using matrix notation. Let

$$
Y = \left( \begin{array}{c} y _ {1} \\ \cdot \\ \cdot \\ \cdot \\ y _ {n} \end{array} \right) \quad \text {a n d} \quad X = \left( \begin{array}{c c c} 1 & \cos (\omega t _ {1}) & \sin (\omega t _ {1}) \\ \cdot & \cdot & \cdot \\ \cdot & \cdot & \cdot \\ \cdot & \cdot & \cdot \\ 1 & \cos (\omega t _ {n}) & \sin (\omega t _ {n}) \end{array} \right) \quad \text {a n d} \quad \beta = \left( \begin{array}{c} \mu \\ \alpha_ {1} \\ \alpha_ {2} \end{array} \right).
$$

With this notation,

$$
\sum_ {i = 1} ^ {n} (y _ {i} - \mu - \alpha_ {1} \cos (\omega t _ {i}) - \alpha_ {2} \sin (\omega t _ {i}) ^ {2} = \| Y - X \beta \| ^ {2}.
$$

so that (8) is the same as

$$
\int_ {0} ^ {\infty} \sigma^ {- n - 1} \int_ {\mathbb {R} ^ {3}} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \beta d \sigma \tag {9}
$$

Now if $\hat { \beta }$ is the least squares estimator:

$$
\hat {\beta} := \operatorname * {a r g m i n} _ {\beta} \| Y - X \beta \| ^ {2},
$$

then

$$
\| Y - X \beta \| ^ {2} = \| Y - X \hat {\beta} \| ^ {2} + \| X \beta - X \hat {\beta} \| ^ {2} = \| Y - X \hat {\beta} \| ^ {2} + (\beta - \hat {\beta}) ^ {T} X ^ {T} X (\beta - \hat {\beta}).
$$

The integral (9) then becomes

$$
\begin{array}{l} \int_ {0} ^ {\infty} \int_ {\mathbb {R} ^ {3}} \sigma^ {- n - 1} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) \exp \left(- \frac {(\beta - \hat {\beta}) X ^ {\prime} X (\beta - \hat {\beta})}{2 \sigma^ {2}}\right) d \beta d \sigma \\ = \int_ {0} ^ {\infty} \sigma^ {- n - 1} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) \int_ {\mathbb {R} ^ {3}} \exp \left(- \frac {(\beta - \hat {\beta}) X ^ {\prime} X (\beta - \hat {\beta})}{2 \sigma^ {2}}\right) d \beta d \sigma . \\ \end{array}
$$

We shall now use the formula:

$$
\int_ {\mathbb {R} ^ {p}} \exp \left(- \frac {1}{2} (x - \mu) ^ {T} \Sigma^ {- 1} (x - \mu)\right) d x _ {1} \ldots d x _ {p} = (2 \pi) ^ {p / 2} \sqrt {\det (\Sigma)}
$$

where $\Sigma$ is a $p \times p$ positive definite matrix and the integral is over $\boldsymbol { x } = ( x _ { 1 } , \dots , x _ { p } )$ . This is basically the formula for the normalizing constant for the multivariate normal distribution which we shall study next week.

This formula with $p = 3$ and $\Sigma ^ { - 1 } = X ^ { \prime } X / ( \sigma ^ { 2 } )$ (or equivalently $\Sigma = \sigma ^ { 2 } ( X ^ { \prime } X ) ^ { - 1 } )$ ) gives

$$
\int_ {\mathbb {R} ^ {3}} \exp \left(- \frac {(\beta - \hat {\beta}) ^ {T} X ^ {T} X (\beta - \hat {\beta})}{2 \sigma^ {2}}\right) d \beta = (2 \pi) ^ {p / 2} \sqrt {\det \left(\sigma^ {2} (X ^ {\prime} X) ^ {- 1}\right)} = (2 \pi) ^ {p / 2} \sigma^ {p} \left(\det (X ^ {\prime} X)\right) ^ {- 1 / 2}.
$$

The integral (8) thus equals

$$
(2 \pi) ^ {p / 2} (\det (X ^ {\prime} X)) ^ {- 1 / 2} \int_ {0} ^ {\infty} \sigma^ {- n + p - 1} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) d \sigma .
$$

The change of variable

$$
t = \frac {\sigma}{\| Y - X \hat {\beta} \|}
$$

then gives

$$
\begin{array}{l} (2 \pi) ^ {p / 2} (\det  (X ^ {\prime} X)) ^ {- 1 / 2} \int_ {0} ^ {\infty} \sigma^ {- n + p - 1} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) d \sigma \\ = (2 \pi) ^ {p / 2} (\det  (X ^ {\prime} X)) ^ {- 1 / 2} \| Y - X \hat {\beta} \| ^ {- n + p} \int_ {0} ^ {\infty} t ^ {- n + p - 1} \exp \left(- \frac {1}{2 t ^ {2}}\right) d t \\ \propto \left(\det  \left(X ^ {\prime} X\right)\right) ^ {- 1 / 2} \| Y - X \hat {\beta} \| ^ {- n + p}. \\ \end{array}
$$

Putting everything together, we have proved that

$$
f _ {\omega | \mathrm {d a t a}} (\omega) \propto (\det (X ^ {\prime} X)) ^ {- 1 / 2} \| Y - X \hat {\beta} \| ^ {- n + p}.
$$

Note that the right hand side depends crucially on $\omega$ because $X$ depends on $\omega$ . Also $\hat { \beta }$ depends on $X$ as ${ \hat { \beta } } = ( X ^ { \prime } X ) ^ { - 1 } X ^ { \prime } Y$ . To make this explicit, let us write $X ( \omega )$ for $X$ and $\hat { \beta } ( \omega )$ for $\hat { \beta }$ :

$$
\left. f _ {Y _ {1}, \dots , Y _ {n} | \omega} \left(y _ {1}, \dots , y _ {n}\right) \propto \left(\det \left(X (\omega) ^ {\prime} X (\omega)\right)\right) ^ {- 1 / 2} \| Y - X (\omega) \hat {\beta} (\omega) \| ^ {- (n - p)}. \right. \tag {10}
$$

This function of $\omega$ can be plotted on the computer (and normalized so the density integrates to one). Note that $p = 3$ . This allows inference on $\omega$ based on the data.

# 3.1 Connection to the Periodogram

It turns out the Bayesian posterior (10) can be related to the periodogram which is a standard object in time series analysis. The periodogram corresponding to the time series data $( t _ { i } , y _ { i } )$ is defined as

$$
I (\omega) := \frac {1}{n} \left[ \left(\sum_ {j} y _ {j} \cos (\omega t _ {j})\right) ^ {2} + \left(\sum_ {j} y _ {j} \sin (\omega t _ {j})\right) ^ {2} \right]. \tag {11}
$$

This is a function of $\omega \in \mathbb R$ . Usually, the periodogram is computed for uniformly spaced data (where the time points $t _ { j }$ can be taken to be consecutive integers such as $0 , \ldots , n - 1 )$ and when $\omega$ is of the form $\textstyle { \frac { 2 \pi k } { n } }$ for some integer $k \in \{ 1 , \ldots , n - 1 \}$ . These values of $\omega$ are known as Fourier Frequencies. Observe that $I ( \omega )$ can also be written as

$$
I (\omega) = \frac {1}{n} \left| \sum_ {j} y _ {j} e ^ {i \omega t _ {j}} \right| ^ {2}
$$

where $i = \sqrt { - 1 }$ , $e ^ { i \omega t _ { j } }$ is the complex number $\cos ( \omega t _ { j } ) + i \sin ( \omega t _ { j } )$ and $| z |$ for a complex number $z$ denotes its modulus. The complex number

$$
b (\omega) := \sum_ {j} y _ {j} e ^ {i \omega t _ {j}}
$$

is termed the Discrete Fourier Transform of the data when $t _ { j } = j - 1$ and $\omega$ ranges over the Fourier frequencies. Thus, the periodogram is basically the squared modulus of the DFT (scaled by $n$ ).

It is a standard procedure to look at the periodogram of an observed time series in order to determine periodic components present in the data. It turns out that the Bayesian posterior (10) is related to the periodogram as we shall argue below. To see this, first note that the posterior (10) is described in terms of the matrix $X ( \omega )$ . For this matrix, it is easy to see that

$$
X ^ {\prime} (\omega) X (\omega) = \left( \begin{array}{c c c} n & \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) & \sum_ {j = 1} ^ {n} \sin (\omega t _ {j}) \\ \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) & \sum_ {j = 1} ^ {n} \cos^ {2} (\omega t _ {j}) & \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \sin (\omega t _ {j}) \\ \sum_ {j = 1} ^ {n} \sin (\omega t _ {j}) & \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \sin (\omega t _ {j}) & \sum_ {j = 1} ^ {n} \sin^ {2} (\omega t _ {j}). \end{array} \right)
$$

Quite often, this $X ^ { \prime } ( \omega ) X ( \omega )$ matrix can be well-approximated as

$$
n \left( \begin{array}{c c c} 1 & \frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) & \frac {1}{n} \sum_ {j = 1} ^ {n} \sin (\omega t _ {j}) \\ \frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) & \frac {1}{n} \sum_ {j = 1} ^ {n} \cos^ {2} (\omega t _ {j}) & \frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \sin (\omega t _ {j}) \\ \frac {1}{n} \sum_ {j = 1} ^ {n} \sin (\omega t _ {j}) & \frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \sin (\omega t _ {j}) & \frac {1}{n} \sum_ {j = 1} ^ {n} \sin^ {2} (\omega t _ {j}). \end{array} \right) = n \left( \begin{array}{c c c} 1 & 0 & 0 \\ 0 & 1 / 2 & 0 \\ 0 & 0 & 1 / 2 \end{array} \right)
$$

To see this, consider the case where the time points are consecutive in which case we take $t _ { j } = j - 1$ . Then for a wide range of $\omega$ , we will argue that

$$
\frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \approx 0 \quad \frac {1}{n} \sum_ {j = 1} ^ {n} \sin (\omega t _ {j}) \approx 0
$$

$$
\frac {1}{n} \sum_ {j = 1} ^ {n} \cos^ {2} (\omega t _ {j}) \approx \frac {1}{2} \quad \frac {1}{n} \sum_ {j = 1} ^ {n} \sin^ {2} (\omega t _ {j}) \approx \frac {1}{2}
$$

$$
\frac {1}{n} \sum_ {j = 1} ^ {n} \cos (\omega t _ {j}) \sin (\omega t _ {j}) \approx 0
$$

Let me provide the argument for one of the above assertions. The argument for the others is similar. We shall consider the assertion

$$
\frac {1}{n} \sum_ {j = 1} ^ {n} \cos^ {2} (\omega t _ {j}) \approx \frac {1}{2}. \tag {12}
$$

To see this, write

$$
\begin{array}{l} \frac {1}{n} \sum_ {j = 1} ^ {n} \cos^ {2} (\omega t _ {j}) = \frac {1}{n} \sum_ {j = 1} ^ {n} \frac {1 + \cos (2 \omega t _ {j})}{2} \\ = \frac {1}{2} + \frac {1}{2 n} \sum_ {j = 1} ^ {n} \cos (2 \omega t _ {j}) = \frac {1}{2} + \frac {1}{4 n} \sum_ {j = 1} ^ {n} e ^ {2 i \omega t _ {j}} + \frac {1}{4 n} \sum_ {j = 1} ^ {n} e ^ {- 2 i \omega t _ {j}} \\ \end{array}
$$

The sums above can be evaluated explicitly under the assumption that the times are uniformly spaced $t _ { j } = j - 1$ :

$$
\sum_ {j = 1} ^ {n} e ^ {2 i \omega t _ {j}} = \sum_ {j = 1} ^ {n} e ^ {2 i \omega (j - 1)} = \sum_ {j = 1} ^ {n} (e ^ {2 i \omega}) ^ {j - 1} = \frac {e ^ {2 i \omega n} - 1}{e ^ {2 i \omega} - 1},
$$

and similarly

$$
\sum_ {j = 1} ^ {n} e ^ {- 2 i \omega t _ {j}} = \frac {e ^ {- 2 i \omega n} - 1}{e ^ {- 2 i \omega} - 1}.
$$

Now if $\omega$ is a Fourier frequency of the form $\omega = 2 \pi k / n$ , then $e ^ { \pm 2 i \omega n } = e ^ { \pm 4 i \pi k } = \cos ( 4 \pi k ) \pm$ $i \sin ( 4 \pi k ) = 1 $ so the above displayed sums are zero leading to (12). If $\omega$ is not a Fourier frequency, we can write

$$
\left| \frac {1}{4 n} \sum_ {j = 1} ^ {n} e ^ {2 i \omega t _ {j}} \right| = \left| \frac {1}{4 n} \frac {e ^ {2 i \omega n} - 1}{e ^ {2 i \omega} - 1} \right| \leq \frac {1}{2 n | e ^ {2 i \omega} - 1 |}
$$

because $| e ^ { 2 i \omega n } - 1 | \leq | e ^ { 2 i \omega n } | + 1 \leq 2$ . We can thus ignore this term if $n | e ^ { 2 i \omega } - 1 |$ is large. Similarly the term

$$
\frac {1}{4 n} \sum_ {j = 1} ^ {n} e ^ {- 2 i \omega t _ {j}}
$$

can be ignored if $n | e ^ { - 2 i \omega } - 1 |$ is large. The assertion (12) is therefore justified if $n | e ^ { \pm 2 i \omega } - 1 |$ is large (which will often be the case unless $\omega$ is too close to zero).

In the rest of this section, we shall assume that

$$
X ^ {\prime} (\omega) X (\omega) \approx \left( \begin{array}{c c c} n & 0 & 0 \\ 0 & n / 2 & 0 \\ 0 & 0 & n / 2 \end{array} \right)
$$

Under this condition, the integral (9) can be evaluated in the following alternative way. We start with

$$
\begin{array}{l} \| Y - X \beta \| ^ {2} = Y ^ {\prime} Y - 2 Y ^ {\prime} X \beta + \beta^ {\prime} X ^ {\prime} X \beta \\ = \sum_ {i} y _ {i} ^ {2} - 2 \sum_ {i = 1} ^ {n} y _ {i} (\mu + \alpha_ {1} \cos (\omega t _ {i}) + \alpha - 2 \sin (\omega t _ {i})) + n \mu^ {2} + \frac {n}{2} \alpha_ {1} ^ {2} + \frac {n}{2} \alpha_ {2} ^ {2} \\ = \sum_ {i} y _ {i} ^ {2} - 2 \mu \sum_ {i} y _ {i} + n \mu^ {2} - 2 \alpha_ {1} \sum_ {i} y _ {i} \cos (\omega t _ {i}) + \frac {n}{2} \alpha_ {1} ^ {2} - 2 \alpha_ {2} \sum_ {i} y _ {i} \sin (\omega t _ {i}) + \frac {n}{2} \alpha_ {2} ^ {2} \\ \end{array}
$$

Thus the inner integral over $\mathbb { R } ^ { 3 }$ in (9) can be broken down into 3 one dimensional integrals (as opposed to one three-dimensional integral) as

$$
\begin{array}{l} \int_ {\mathbb {R} ^ {3}} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \beta \\ = \exp \left(- \frac {\sum_ {i} y _ {i} ^ {2}}{2 \sigma^ {2}}\right) \left[ \int \exp \left(\frac {\mu \sum_ {i} y _ {i}}{\sigma^ {2}} - \frac {n \mu^ {2}}{2 \sigma^ {2}}\right) d \mu \right] \left[ \int \exp \left(\frac {\alpha_ {1} \sum_ {i} y _ {i} \cos (\omega t _ {i})}{\sigma^ {2}} - \frac {n \alpha_ {1} ^ {2}}{4 \sigma^ {2}}\right) d \alpha_ {1} \right] \\ \left[ \int \exp \left(\frac {\alpha_ {2} \sum_ {i} y _ {i} \sin (\omega t _ {i})}{\sigma^ {2}} - \frac {n \alpha_ {2} ^ {2}}{4 \sigma^ {2}}\right) d \alpha_ {2} \right] \\ \end{array}
$$

can be evaluated in the following alternative way. Each of the above three integrals can be evaluated explicitly using the one-dimensional integration formula:

$$
\int_ {- \infty} ^ {\infty} \exp \left(x C _ {1} - \frac {C _ {2}}{2} x ^ {2}\right) d x = \sqrt {\frac {2 \pi}{C _ {2}}} \exp \left(\frac {C _ {1} ^ {2}}{2 C _ {2}}\right).
$$

We thus deduce

$$
\begin{array}{l} \int_ {\mathbb {R} ^ {3}} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \beta \\ \propto \exp \left(- \frac {\sum_ {i} y _ {i} ^ {2}}{2 \sigma^ {2}}\right) \sigma^ {3} \exp \left(\frac {(\sum_ {i} y _ {i}) ^ {2}}{2 n \sigma^ {2}}\right) \exp \left(\frac {(\sum_ {i} y _ {i} \cos (\omega t _ {i})) ^ {2}}{2 \sigma^ {2}}\right) \exp \left(\frac {(\sum_ {i} y _ {i} \sin (\omega t _ {i})) ^ {2}}{2 \sigma^ {2}}\right). \\ \end{array}
$$

Finally the integration over $\sigma$ can be done as before to obtain

$$
\begin{array}{l} f _ {\omega | \mathrm {d a t a}} (\omega) \propto \left[ \frac {\sum_ {i} y _ {i} ^ {2}}{2} - \frac {(\sum_ {i} y _ {i}) ^ {2}}{2 n} - \frac {1}{n} \left(\sum_ {i} y _ {i} \cos (\omega t _ {i})\right) ^ {2} - \frac {1}{n} \left(\sum_ {i} y _ {i} \sin (\omega t _ {i})\right) ^ {2} \right] ^ {- (n - p) / 2} \\ = \left[ \frac {\sum_ {i} (y _ {i} - \bar {y}) ^ {2}}{2} - \frac {1}{n} \left(\sum_ {i} y _ {i} \cos (\omega t _ {i})\right) ^ {2} - \frac {1}{n} \left(\sum_ {i} y _ {i} \sin (\omega t _ {i})\right) ^ {2} \right] ^ {- (n - p) / 2} \\ \end{array}
$$

Using the periodogram formula (11), we can write the above as

$$
\begin{array}{l} f _ {\omega | \mathrm {d a t a}} (\omega) \propto \left[ \frac {\sum_ {i} (y _ {i} - \bar {y}) ^ {2}}{2} - I (\omega) \right] ^ {- (n - p) / 2} \\ \propto \left[ 1 - \frac {2 I (\omega)}{\sum_ {i = 1} ^ {n} (y _ {i} - \bar {y}) ^ {2}} \right] ^ {- (n - p) / 2}. \\ \end{array}
$$

Thus the Bayesian posterior for $\omega$ is essentially a function of the periodogram (and the sample variance of the data). But it is important to note that it is a very specific function which can look quite different from the raw periodogram. For example, for the sunspots dataset, the periodogram has several peaks but the Bayesian posterior is typically quite strongly concentrated. Thus if we are trying to find a single frequency in a time series dataset, the Bayesian posterior will provide that information much more precisely compared to the periodogram.

# 3.2 Recommended Reading for Today

1. The Bayesian analysis of the model (7) is taken from the book Bayesian spectrum analysis and parameter estimation by Larry Bretthorst (available freely online). You can read Chapters 1 and 2 of that book.

2. The periodogram is a standard object in time series analysis and it can be found in many books; see for example Chapter 4 of the book Time series analysis and its applications by Shumway and Stoffer (note that some authors use slightly different scaling factors while defining the periodogram).

# 4 Lecture Four

In the last class, we studied the model

$$
Y _ {i} = \mu + \alpha_ {1} \cos (\omega t _ {i}) + \alpha_ {2} \sin (\omega t _ {i}) + \epsilon_ {i} \quad \text {f o r} i = 1, \dots , n \tag {13}
$$

for the sunspots dataset. We used a Bayesian method to infer the frequency parameter $\omega$ (which is the main parameter of interest) and this led to an estimated period of close to 11 (which is often cited as the period of the solar cycle). Note however that (13) is not ideal for the sunspots dataset for at least two reasons: (a) the fit to the data is not very good (some of the oscillations have a much higher amplitude than that explained by the single sinusoid), (b) data generated from the model (13) look much more “noisy” compared to the actual sunspots data. Starting with these observations, Yule (1927) proposed an alternative model that is also based on a single sinuosoid. This is the topic of this lecture.

Yule started with the following basic observation. Let $s _ { t }$ denote the sinusoid:

$$
s _ {t} = \mu + \alpha_ {1} \cos (\omega t) + \alpha_ {2} \sin (\omega t) \tag {14}
$$

The same sinusoid can be understood as the solution to a specific difference equation. To derive the difference equation, let us first note that, in continuous time, $s ( t )$ satisfies

$$
s ^ {\prime \prime} (t) = - \omega^ {2} \left(\alpha_ {1} \cos (\omega t) + \alpha_ {2} \sin (\omega t)\right) = - \omega^ {2} \left(s (t) - \mu\right). \tag {15}
$$

In discrete time (where $t \in \{ \ldots , - 2 , - 1 , 0 , 1 , 2 , \ldots \}$ ), the sequence (14) satisfies the following difference equation that is analogous to (15):

$$
s _ {t + 2} - 2 s _ {t + 1} + s _ {t} = 2 (\cos \omega - 1) (s _ {t + 1} - \mu). \tag {16}
$$

To see this, note that

$$
\begin{array}{l} s _ {t + 2} - 2 s _ {t + 1} + s _ {t} \\ = \alpha_ {1} \left(\cos (\omega (t + 2)) - 2 \cos (\omega (t + 1)) + \cos (\omega t)\right) + \alpha_ {2} \left(\sin (\omega (t + 2)) - 2 \sin (\omega (t + 1)) + \sin (\omega t)\right) \\ \end{array}
$$

Writing $A = \omega ( t + 1 )$ and $B = \omega$ , we get

$$
\begin{array}{l} \cos (\omega (t + 2)) - 2 \cos (\omega (t + 1)) + \cos (\omega t) = \cos (A + B) - 2 \cos A + \cos (A - B) \\ = 2 \cos A (\cos B - 1) \\ = 2 (\cos \omega - 1) \cos (w (t + 1)) \\ \end{array}
$$

and similarly

$$
\sin (\omega (t + 2)) - 2 \sin (\omega (t + 1)) + \sin (\omega t) = 2 (\cos \omega - 1) \sin (\omega (t + 1))
$$

This proves

$$
s _ {t + 2} - 2 s _ {t + 1} + s _ {t} = 2 (\cos \omega - 1) (\alpha_ {1} \cos (\omega (t + 1)) + \alpha_ {2} \sin (\omega (t + 1))) = 2 (\cos \omega - 1) (s _ {t + 1} - \mu)
$$

and this proves (16).

The converse is also true in the sense that every solution $\left\{ { { s } _ { t } } \right\}$ to the difference equation (16) say, for $t = 0 , 1 , 2 , \ldots$ , with given values of $s _ { 0 }$ and $s _ { 1 }$ (initial conditions) is of the form (14) for some $\alpha _ { 1 }$ and $\alpha _ { 2 }$ . To see this, let $g _ { t } = s _ { t } - \mu$ and note that $\{ g _ { t } \}$ satisfies

$$
g _ {t + 2} - 2 g _ {t + 1} + g _ {t} = 2 (\cos \omega - 1) g _ {t + 1}.
$$

We find $\alpha _ { 1 }$ and $\alpha _ { 2 }$ such that

$$
h _ {t} := \alpha_ {1} \cos (\omega t) + \alpha_ {2} \sin (\omega t)
$$

matches $g _ { t }$ for $t = 0 , 1$ . Now if $g _ { t } = h _ { t }$ and $g _ { t + 1 } = h _ { t + 1 }$ , then

$$
\begin{array}{l} g _ {t + 2} = (2 \cos \omega) g _ {t + 1} - g _ {t} \\ = (2 \cos \omega) (\alpha_ {1} \cos (\omega (t + 1)) + \alpha_ {2} \sin (\omega (t + 1))) - (\alpha_ {1} \cos (\omega t) + \alpha_ {2} \sin (\omega t)) \\ = \alpha_ {1} (2 \cos \omega \cos (\omega (t + 1)) - \cos (\omega t)) + \alpha_ {2} (2 \cos \omega \sin (\omega (t + 1)) - \sin (\omega t)) \\ = \alpha_ {1} (\cos (\omega t) (2 \cos^ {2} \omega - 1) - \sin (\omega t) 2 \sin \omega \cos \omega) \\ + \alpha_ {2} \left(\sin (\omega t) \left(2 \cos^ {2} \omega - 1\right) + \cos (\omega t) 2 \sin \omega \cos \omega\right) \\ = \alpha_ {1} (\cos (\omega t) \cos (2 \omega) - \sin (\omega t) \sin (2 \omega)) + \alpha_ {2} (\sin (\omega t) \cos (2 \omega) + \cos (\omega t) \sin (2 \omega)) \\ = \alpha_ {1} \cos (\omega (t + 2)) + \alpha_ {2} \sin (\omega (t + 2)) = h _ {t + 2}. \\ \end{array}
$$

Using this for $t = 0 , 1 , 2 , \ldots$ proves that (14) is the unique solution to (16).

To summarize, an alternative way of describing a sinusoid of frequency $\omega$ is via the difference equation (16) which is equivalent to

$$
s _ {t + 2} = (2 \cos \omega) s _ {t + 1} - s _ {t} + 2 (1 - \cos \omega) \mu .
$$

Based on this equation, Yule proposed the model:

$$
Y _ {t + 2} = \theta Y _ {t + 1} - Y _ {t} + c + Z _ {t + 2} \tag {17}
$$

with two parameters $\theta$ and $c$ (and the additional noise parameter $\sigma$ in $Z _ { t + 2 } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma ^ { 2 } ) )$ Note that this is also a single sinusoid plus noise model but now the noise is in a different place. To better understand the difference between (17) and the earlier model:

$$
Y _ {t} = \mu + \alpha_ {1} \cos (\omega t) + \alpha_ {2} \sin (\omega t) + \epsilon_ {t}, \tag {18}
$$

consider the following physical situation where sinusoids naturally arise (see e.g., page 2 of the Fourier Analysis book by Stein and Shakarchi). Consider a mass $m$ that is attached to a horizontal spring, which itself is attached to fixed wall, and assume that the system lies on a frictionless surface. Choose an axis whose origin coincides with the center of the mass when the spring is neither compressed or stretched. When the spring is compressed or stretched and released, the mass undergoes simple harmonic motion.

Let $y ( t )$ denote the displacement of the mass at time $t$ . Hooke’s law says that the force exerted by the spring on the mass is given by $F = - \kappa y ( t )$ where $\kappa > 0$ is the spring constant. By Newton’s law (note that the acceleration is given by $y ^ { \prime \prime } ( t )$ ), we have

$$
- \kappa y (t) = m y ^ {\prime \prime} (t)
$$

This is same as

$$
y ^ {\prime \prime} (t) = - \omega^ {2} y (t) \qquad \mathrm {w h e r e} \omega := \sqrt {\frac {k}{m}}
$$

whose general solution is the sinusoid $\alpha _ { 1 } \cos ( \omega t ) + \alpha _ { 2 } \sin ( \omega t )$ . In the context of this physical situation, the two different sinusoid plus models ((18) and (17)) can be understood as follows. We are taking measurements of the displacement $Y _ { t }$ at various times $t$ .

Model (18): Here our measurements are noisy and every measurement is corrupted by an unknown noise which we are terming $\epsilon _ { t }$ and modeling as $N ( 0 , \sigma ^ { 2 } )$ .

Model (17): Here there is no measurement error and our measurement mechanism is perfect. However the actual oscillation of the mass is not perfectly sinusoidal and is affected by noise. For example, imagine, as Yule put it, that some kids are randomly throwing stones at the mass (sometimes from the left and sometimes from the right) while it is oscillating.

It is very interesting to note that observations generated from Model (17) are much smoother compared to observations generated from Model (18). Yule used this to argue that (17) is a better model for the sunspots data compared to (18).

It is natural to wonder if it makes sense to incorporate both kinds of errors simultaneously (measurement errors and errors affecting the oscillation). This leads to the model:

$$
X _ {t} = \theta X _ {t - 1} - X _ {t - 2} + c + Z _ {t}
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t}
$$

This is a state space model if we take the state variable to be

$$
\tilde {X} _ {t} = \left( \begin{array}{c} X _ {t} \\ X _ {t - 1} \end{array} \right)
$$

because the state evolution

$$
\tilde {X} _ {t + 1} = \left( \begin{array}{c} c \\ 0 \end{array} \right) + \left( \begin{array}{c c} \theta & - 1 \\ 1 & 0 \end{array} \right) + \left( \begin{array}{c} Z _ {t} \\ 0 \end{array} \right)
$$

is Markov, and the observations are

$$
Y _ {t} = \left(1 0\right) \tilde {X} _ {t} + \epsilon_ {t}.
$$

# 4.1 The Autoregressive Model

Yule (1927) also fit models to the sunspots dataset that are more complicated compared to (17) and introduced the Autoregressive Model (of order 2) in this process. The AR(2) model is given by

$$
Y _ {t + 2} = \phi_ {1} Y _ {t + 1} + \phi_ {2} Y _ {t} + c + Z _ {t + 2} \tag {19}
$$

Note that (17) can be seen as a simpler version of the above model where the $\phi _ { 2 }$ parameter is set to the value $- 1$ . We can fit this model to the observed sunspots data $y _ { 1 } , \ldots , y _ { T }$ to obtain parameter estimates $\hat { c } , \hat { \phi } _ { 1 } , \hat { \phi } _ { 2 }$ and $\hat { \sigma }$ of the model parameters. Using the fitted model, future values can be predicted by recursing the equation:

$$
Y _ {t} = \hat {c} + \hat {\phi} _ {1} Y _ {t - 1} + \hat {\phi} _ {2} Y _ {t - 2} \quad \text {f o r} t = T + 1, T + 2, \dots
$$

with $Y _ { T }$ and $Y _ { T - 1 }$ set to the observed values $y _ { T }$ and $y _ { T - 1 }$ respectively. For the sunspots data, these predictions follow a damped sinusoid. Indeed, fitting the AR(2) model to the sunspots data for the time period 1700 1969 led to the model:

$$
Y _ {t + 2} = 2 3. 9 2 + 1. 3 8 Y _ {t + 1} - 0. 6 9 Y _ {t} + Z _ {t + 2}
$$

which gives the prediction equation:

$$
Y _ {t} = 2 3. 9 2 + 1. 3 8 Y _ {t - 1} - 0. 6 9 Y _ {t - 2}
$$

for the future values of sunspot numbers from 1970 onwards. This equation can also be written as

$$
Y _ {t} - 7 7. 1 6 = 1. 3 8 \left(Y _ {t - 1} - 7 7. 1 6\right) - 0. 6 9 \left(Y _ {t - 2} - 7 7. 1 6\right)
$$

Thus the predictions for $U _ { t } : = Y _ { t } - 7 7 . 1 6$ are given by recursing the equation:

$$
U _ {t} = 1. 3 8 U _ {t - 1} - 0. 6 9 U _ {t - 2} \tag {20}
$$

for $t = T + 1 , T + 2 , . . .$ (note that $U _ { T - 1 }$ and $U _ { T }$ are observed from the data). It follows from the following fact that the general solution of (20) is of the form:

$$
c _ {1} (1. 2) ^ {- t} \cos (0. 5 9 t + c _ {2})
$$

for two constants $c _ { 1 }$ and $c _ { 2 }$ . The above is clearly a damped sinusoid (the sinusoid $\cos \left( 0 . 5 9 t + c _ { 2 } \right)$ is damped by the factor $( 1 . 2 ) ^ { - t }$ ) .

Fact 4.1. Consider the difference equation

$$
U _ {t} = \phi_ {1} U _ {t - 1} + \phi_ {2} U _ {t - 2} \quad f o r t \in \{k + 1, \dots \}. \tag {21}
$$

with initial conditions $U _ { k - 1 } = \alpha$ and $U _ { k } = \beta$ . Suppose that the quadratic polynomial

$$
1 - \phi_ {1} z - \phi_ {2} z ^ {2}
$$

has complex roots $z _ { 1 }$ and $z _ { 2 }$ . As $\phi _ { 1 }$ and $\phi _ { 2 }$ are real, $z _ { 1 }$ and $z _ { 2 }$ must be complex conjugates of each other so they can be written as $r e ^ { i \theta }$ and $r e ^ { - i \theta }$ for some $r > 0$ and $\theta \ \in \ \mathbb { R }$ (here $i = \sqrt { - 1 }$ ). Then the solution to (21) is of the form:

$$
U _ {t} = c _ {1} r ^ {- t} \cos (\theta t + c _ {2}) \quad f o r t = k + 1, k + 2, \dots \tag {22}
$$

for some constants $c _ { 1 }$ and $c _ { 2 }$

Proof. Let $H _ { t } = c _ { 1 } r ^ { - t } \cos \left( \theta t + c _ { 2 } \right)$ . We find $c _ { 1 }$ and $c _ { 2 }$ such that $H _ { t } = U _ { t }$ for $t = k - 1$ and $t = k$ . Then observe that

$$
\begin{array}{l} H _ {t} = c _ {1} r ^ {- t} \cos (\theta t + c _ {2}) \\ = 2 c _ {1} r ^ {- t} \left(e ^ {i \theta t} e ^ {i c _ {2}} + e ^ {- i \theta t} e ^ {- i c _ {2}}\right) \\ = 2 c _ {1} e ^ {i c _ {2}} \left(r e ^ {- i \theta}\right) ^ {- t} + 2 c _ {2} e ^ {- i c _ {2}} \left(r e ^ {i \theta}\right) ^ {- t} \\ = 2 c _ {1} e ^ {i c _ {2}} z _ {1} ^ {- t} + 2 c _ {1} e ^ {- i c _ {2}} z _ {2} ^ {- t}. \\ \end{array}
$$

This gives

$$
\begin{array}{l} H _ {t} - \phi_ {1} H _ {t - 1} - \phi_ {2} H _ {t - 2} = 2 c _ {1} e ^ {i c _ {2}} \left(z _ {1} ^ {- t} - \phi_ {1} z _ {1} ^ {- t + 1} - \phi_ {2} z _ {1} ^ {- t + 2}\right) + 2 c _ {1} e ^ {- i c _ {2}} \left(z _ {2} ^ {- t} - \phi_ {1} z _ {2} ^ {- t + 1} - \phi_ {2} z _ {2} ^ {- t + 2}\right) \\ = 2 c _ {1} e ^ {i c _ {2}} z _ {1} ^ {- t} \left(1 - \phi_ {1} z _ {1} - \phi_ {2} z _ {1} ^ {2}\right) + 2 c _ {1} e ^ {- i c _ {2}} z _ {2} ^ {- t} \left(1 - \phi_ {1} z _ {2} - \phi_ {2} z _ {2} ^ {2}\right) = 0 \\ \end{array}
$$

because $1 - \phi _ { 1 } z _ { 1 } - \phi _ { 2 } z _ { 1 } ^ { 2 } = 1 - \phi _ { 1 } z _ { 2 } - \phi _ { 2 } z _ { 2 } ^ { 2 } = 0$ as $z _ { 1 }$ and $z _ { 2 }$ are roots of the polynomial $1 - \phi _ { 1 } z - \phi _ { 2 } z ^ { 2 }$ . Thus $H _ { t }$ satisfies the given difference equation and it matches $U _ { t }$ for $t = k { - } 1 , k$ which implies that it matches $U _ { t }$ for all $t \geq k + 1$ . □

# 4.2 Recommended Reading for Today

1. A very nice account of Yule’s influential 1927 paper is Chapter 6 of the 2011 book “The Foundations of Modern Time Series Analysis” by T. C. Mills. (available for free from the library website).   
2. Section 3.4 of the Durbin-Koopman book writes ARMA and ARIMA models in state space form.

# 5 Lecture Five

We start today with the problem of fitting state space models to observed time series data. This is the main topic of the class. We shall denote the observed time series data by $y _ { 0 } , y _ { 1 } , \dotsc , y _ { T }$ (note that the number of observations is $T + 1$ ). We shall assume that the observations are realizations of random variables $Y _ { 0 } , Y _ { 1 } , \dots , Y _ { T }$ . State space models describe the distribution of $Y _ { 0 } , \ldots , Y _ { T }$ in terms of a hidden set of state random variables $X _ { 0 } , \ldots , X _ { T }$ . The joint density of $X _ { 0 } , \ldots , X _ { T } , Y _ { 0 } , \ldots , Y _ { T }$ is given by

$$
f _ {X _ {0}} (x _ {0}) \prod_ {t = 1} ^ {T} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}} (x _ {t}) \prod_ {t = 0} ^ {T} f _ {Y _ {t} | X _ {t} = x _ {t}} (y _ {t}).
$$

As we have seen previously, this means that $X _ { 0 } , \ldots , X _ { T }$ is Markov, and also that $Y _ { 0 } , \ldots , Y _ { T }$ are independent conditional on $X _ { 0 } = x _ { 0 } , \dots , X _ { T } = x _ { T }$ with

$$
Y _ {t} \mid X _ {0} = x _ {0}, \ldots , X _ {T} = x _ {T} \stackrel {\mathrm {d}} {=} Y _ {t} \mid X _ {t} = x _ {t}.
$$

Often, in actual specifications of state space models, the description of the conditional densities $f _ { X _ { 0 } } , f _ { X _ { t } | X _ { t - 1 } } , f _ { Y _ { t } | X _ { t } }$ depends on additional unknown parameters $\theta$ (for example, in the local level model, $\theta = ( \sigma _ { \eta } ^ { 2 } , \sigma _ { \epsilon } ^ { 2 } )$ where $\sigma _ { \eta } ^ { 2 }$ and $\sigma _ { \epsilon } ^ { 2 }$ are the state and observation error variances). We shall follow the full Bayesian approach in the treatment of these nuisance parameters $\theta$ . Specifically, we shall assume that they are random and employ a (usually diffuse) prior density $f _ { \theta } ( \cdot )$ . From now on, we shall explicitly acknowledge that $f _ { X _ { 0 } } , f _ { X _ { t } | X _ { t - 1 } } , f _ { Y _ { t } | X _ { t } }$ depend on $\theta$ by using the notation:

$$
f _ {X _ {0} | \theta}, f _ {X _ {t} | X _ {t - 1}, \theta}, f _ {Y _ {t} | X _ {t}, \theta}.
$$

Our main goal is to fit the state space model to the observed data $y _ { 0 } , \ldots , y _ { T }$ . Fitting a model in the Bayesian context means computing the conditional distribution of the unknown parameters of the model given the observed data $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ . For the state space model, the unknown parameters are $X _ { 0 } , \ldots , X _ { T }$ as well as $\theta$ . The conditional distribution of $X _ { 0 } , \dots , X _ { T } , \theta$ given the observed data $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ equals

$$
\begin{array}{l} f _ {X _ {0}, \dots , X _ {T}, \theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {t}} (x _ {0}, \dots , x _ {t}, \theta) \\ \propto f _ {X _ {0}, \dots , X _ {T}, Y _ {0}, \dots , Y _ {T}, \theta} (x _ {0}, \dots , x _ {T}, y _ {0}, \dots , y _ {T}, \theta) \\ = f _ {X _ {0}, \dots , X _ {T}, Y _ {0}, \dots , Y _ {T} | \theta} (x _ {0}, \dots , x _ {T}, y _ {0}, \dots , y _ {T}) f _ {\theta} (\theta) \\ = f _ {X _ {0} | \theta} (x _ {0}) \prod_ {t = 1} ^ {T} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) \prod_ {t = 0} ^ {T} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) f _ {\theta} (\theta). \\ \end{array}
$$

With the normalizing constant,

$$
\begin{array}{l} f _ {X _ {0}, \dots , X _ {T}, \theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {t}} (x _ {0}, \dots , x _ {t}, \theta) \\ = \frac {f _ {X _ {0} | \theta} \left(x _ {0}\right) \prod_ {t = 1} ^ {T} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} \left(x _ {t}\right) \prod_ {t = 0} ^ {T} f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} \left(y _ {t}\right) f _ {\theta} (\theta)}{\int \dots \int \int f _ {X _ {0} | \theta} \left(x _ {0}\right) \prod_ {t = 1} ^ {T} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} \left(x _ {t}\right) \prod_ {t = 0} ^ {T} f _ {Y _ {t} | X _ {t} + x _ {t} , \theta} \left(y _ {t}\right) f _ {\theta} (\theta) d x _ {0} \dots d x _ {T} d \theta} \tag {23} \\ \end{array}
$$

This is a high-dimensional density which, in principle, answers any inferential question about the unknown parameters $X _ { 0 } , \dots , X _ { T } , \theta$ based on the data $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . In practice, the quantities of main interest would be the conditional densities of each individual state conditioned on the data $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ :

$$
X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T} \qquad \mathrm {f o r} t = 0, 1, \ldots , T.
$$

In principle it is possible to deduce

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (x _ {t}) \tag {24}
$$

from the full posterior (23). But a naive way of doing this would involve high dimensional integration that would not be computationally feasible. We shall study principled computationally feasible algorithms for obtaining (24) for $t = 0 , \ldots , T$ . I will give a high level overview of the main ideas in this class and we shall study full details in the coming classes. The first step is to write (24) as

$$
f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (x _ {t}) = \int f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta} (x _ {t}) f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) d \theta .
$$

This implies that the task of calculating (24) can be broken down into the following two subtasks:

1. Calculate $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T } , \theta } ( x _ { t } )$ . This is the conditional density of $X _ { t }$ given the entire data as well as $\theta$ .   
2. Calculate $f _ { \theta | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T } } ( \theta )$ . This is the conditional density of $\theta$ given the entire data. This can be done via calculating the likelihood $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ because, by Bayes rule,

$$
f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \propto f _ {Y _ {0}, \dots , Y _ {T} | \theta} (y _ {0}, \dots , y _ {T}) f _ {\theta} (\theta)
$$

It is convenient here to introduce some standard terminology. The conditional distributions:

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta \quad \text {f o r} t = 0, 1, \dots , T \tag {25}
$$

are called smoothing distributions. Thus, the conditional densities (24) can be determined from the smoothing distributions as well as the likelihood $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ .

# 5.1 Outline of Approach to Calculate Smoothing Distributions

The approach that we will use for efficiently calculating all the smoothing distributions i.e., all the conditional distributions (25) for $t = 0 , 1 , \ldots , T$ is the following. This is a sequential approach that has the following two steps:

1. The first step calculates the distributions:

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \tag {26}
$$

for each $t = 0 , 1 , \ldots , T$ . Note that the conditioning above is on $Y _ { 0 } , \ldots , Y _ { t }$ and not on the whole data $Y _ { 0 } , \ldots , Y _ { T }$ . These conditional distributions are known as Filtering Distributions and algorithms for calculating them are called Filtering Algorithms. We shall study the standard filtering algorithms: Kalman filter (for Linear Gaussian State Space Models) and Partile filter (for arbitrary state space models). These algorithms calculate the filtering densities recursively starting from $t = 0$ and then for $t = 1 , \ldots , T ^ { \prime }$ .

2. After the filtering step, the last smoothing distribution:

$$
X _ {T} \mid Y _ {0} = y _ {0}, Y _ {1} = y _ {1}, \dots , Y _ {T} = y _ {T}, \theta
$$

is already available. From here, the idea is to calculate the rest of the smoothing distributions (25) recursively for $t = T - 1 , T - 2 , \dots , 0$ . Note that this is a backward recursion.

This overall approach to calculating the smoothing distributions is known as FFBS (Forward Filtering and Backward Smoothing). We shall study this approach in the case of general state space models. For the special case of linear Gaussian state space models, these recursions can be solved in closed form.

# 5.2 Linear Gaussian State Space Models

A state space model is specified by the densities $f _ { X _ { 0 } | \theta } ( x _ { 0 } )$ , $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } , \theta } ( x _ { t } )$ for $t = 1 , \dots , T$ and $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ for $t = 0 , \ldots , T$ . We say that a state space model is Linear Gaussian if the following three conditions are all satisfied:

1. $f _ { X _ { 0 } | \theta } ( \cdot )$ is a Gaussian density.   
2. $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } } ( \cdot )$ is a Gaussian density whose mean is a linear function of $x _ { t - 1 }$ and whose covariance does not depend on $x _ { t - 1 }$ .   
3. $f _ { Y _ { t } | X _ { t } = x _ { t } } ( \cdot )$ is a Gaussian density whose mean is a linear function of $x _ { t }$ and whose covariance does not depend on $x _ { t }$ .

Quite often, linear Gaussian state space models are specified as:

$$
X _ {0} \sim N (0, \Sigma_ {0})
$$

$$
X _ {t} = A _ {t} X _ {t - 1} + U _ {t}
$$

$$
Y _ {t} = B _ {t} X _ {t} + V _ {t}
$$

where $X _ { 0 } , U _ { 1 } , \dots , U _ { T } , V _ { 0 } , \dots , V _ { T }$ are independent with

$$
U _ {t} \sim N (0, \Sigma_ {t}) \quad \text {a n d} \quad V _ {t} \sim N (0, R _ {t}).
$$

It is easy to see that this specification satisfies the three conditions of the Linear Gaussian State Space Model. The quantities $\Sigma _ { 0 } , A _ { t } , B _ { t } , \Sigma _ { t } , R _ { t }$ all potentially depend on unknown parameters $\theta$ .

For the linear Gaussian state space model, all the filtering and smoothing distributions turn out to be Gaussian which means that they are specified by means and covariances. The general approach for filtering and smoothing can be specialized to this case as recursions in terms of means and covariances. This leads to the Kalman Filter and Kalman Smoother algorithms. We shall start our study of these in the next class.

# 5.3 Recommended Reading for Today

1. Definitions of filtering and smoothing distributions and the general problem of Sequential Analysis of State Space Models is described in Section 2.3 of the Chopin-Papaspiliopoulos book.   
2. Chapter 1 of the S¨arkk¨a book also describes the main goals in the analysis of state space models and gives a list of the common Filtering and Smoothing algorithms.

# 6 Lecture Six

The goal of today’s lecture is to study the general filtering algorithm and then specialize it to the case of linear Gaussian State Space Models leading to the Kalman Filter.

Let us recall the basic setup. We have a state space model describing the distribution of random variables $X _ { 0 } , Y _ { 0 } , X _ { 1 } , Y _ { 1 } , \dots , X _ { T } , Y _ { T }$ as

$$
f _ {X _ {0} | \theta} (x _ {0}) \prod_ {t = 1} ^ {T} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) \prod_ {t = 0} ^ {T} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t})
$$

Here $f _ { X _ { 0 } | \theta }$ is the density of $X _ { 0 }$ , $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } , \theta }$ is the conditional density of $X _ { t }$ given $X _ { t - 1 } =$ $x t - 1$ and $f _ { Y _ { t } | X _ { t } = x _ { t } , \theta }$ is the conditional density of $Y _ { t }$ given $X _ { t } ~ = ~ x _ { t }$ . Throughout there is additional conditioning on $\theta$ .

Our aim is to calculate the conditional distributions:

$$
X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta
$$

for various values of $s$ and $t$ . These conditional distributions have known by different names depending on the specific values of $s$ and $t$ :

1. Filtering Distributions: These correspond to $s = t$ .   
2. Smoothing Distributions: These correspond to $s \leq t$ .   
3. Prediction Distributions: These correspond to $s > t$ .

The importance of calculating these three types of conditional distributions varies with the application. In tracking applications, interest mainly lies in filtering and prediction distributions while in applications such as trend estimation, interest mainly lies in smoothing and prediction distributions.

# 6.1 General Approach for calculating Filtering Distributions

Let us now study the general recursive scheme for calculating the filtering distributions. The main step is to go from the filtering density at time $t - 1$ :

$$
f _ {X _ {t - 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t - 1})
$$

to the filtering density at time $t$ :

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, Y _ {t} = y _ {t}. \theta} (x _ {t})
$$

This recursion is carried out in two steps:

1. Step One: Go from the filtering density $f _ { X _ { t - 1 } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( x _ { t - 1 } )$ at time $t - 1$ to the one-step ahead prediction density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( x _ { t } )$ at time $t - 1$ . This step is known as the one-step prediction update.   
2. Step Two: Go from the one-step ahead prediction density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( x _ { t } )$ at time $t - 1$ to the filtering density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } = y _ { t } , \theta } ( x _ { t } )$ at time $t$ . This step is known as the filtering update.

The one-step ahead prediction update is carried out via the formula:

$$
\begin{array}{l} f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}) \\ = \int f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}) f _ {X _ {t - 1} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t - 1}) d x _ {t - 1} \\ \end{array}
$$

Now by the Markov nature of the state variables and the independence of the observation random variables conditioned on the state variables, we have

$$
f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}) = f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}).
$$

Thus

$$
f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}) = \int f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) f _ {X _ {t - 1} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t - 1}) d x _ {t - 1} \quad (2 7)
$$

This equation tells us how to go from the filtering density at time $t - 1$ to the one-step up ahead prediction density at time $t - 1$ .

Let us now see the filtering update which specifies how to go from the one-step ahead prediction density at time $t - 1$ to the filtering density at time $t$ . By Bayes rule, we can write

$$
\begin{array}{l} f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}) \\ \propto f _ {Y _ {t} | X _ {t} = x _ {t}, Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}). \\ \end{array}
$$

The Markov nature of the state variables and the independence of the observation random variables conditioned on the state variables implies that

$$
f _ {Y _ {t} | X _ {t} = x _ {t}, Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) = f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}).
$$

Thus

$$
f _ {X _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {t}) \propto f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) f _ {X _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}).
$$

The constant underlying the proportionality symbol $\propto$ above is simply the constant that makes the left hand side integrate to one. We thus get

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}) = \frac {f _ {Y _ {t} \mid X _ {t} = x _ {t} , \theta} (y _ {t}) f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t})}{\int f _ {Y _ {t} \mid X _ {t} = u , \theta} (y _ {t}) f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (u) d u} \tag {28}
$$

The two steps (27) and (28) together describe the recursion to go from the filtering density at time $t - 1$ to the filtering density at time $t$ . The recursion can be initialized by simply using (28) with $t = 0$ and replacing $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( x _ { t } )$ on the right hand by $f _ { X _ { 0 } | \theta } ( x _ { 0 } )$ for $t = 0$ .

For linear Gaussian state space models, steps (27) and (28) can be implemented in closed form leading to the Kalman Filter which we shall study next.

# 6.2 The Kalman Filter

Consider the linear Gaussian state space model:

$$
\begin{array}{l} X _ {0} \sim N (\mu_ {0}, \Gamma_ {0}) \\ X _ {t} = A _ {t} X _ {t - 1} + U _ {t} \tag {29} \\ Y _ {t} = B _ {t} X _ {t} + V _ {t} \\ \end{array}
$$

with $X _ { 0 } , U _ { 1 } , \dots , V _ { 0 } , V _ { 1 } , \dots .$ independent and $U _ { t } \sim N ( 0 , \Sigma _ { t } )$ and $V _ { t } \sim N ( 0 , R _ { t } )$ . In this case, it turns out every conditional distributions $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ are Gaussian so we can write

$$
X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \sim N (m _ {s | t}, Q _ {s | t}). \tag {30}
$$

The Kalman filtering algorithm specifies how to compute $m _ { t | t } , Q _ { t | t }$ for $t = 0 , 1 , \ldots$ . by essentially solving the equations (27) and (28) in closed form. Equation (27) specifies how to calculate $m _ { t | t - 1 } , Q _ { t | t - 1 }$ from $m _ { t - 1 | t - 1 } , Q _ { t - 1 | t - 1 }$ . For this, we can either explicitly compute the integral in (27) or just use standard properties of normal distributions as:

$$
X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta \stackrel {\mathrm {d}} {=} A _ {t} X _ {t - 1} + U _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta .
$$

Because, conditional on $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ , the random variables $X _ { t - 1 }$ and $U _ { t }$ are independently distributed as ${ \cal N } ( m _ { t - 1 \vert t - 1 } , Q _ { t - 1 \vert t - 1 } )$ and $N ( 0 , \Sigma _ { t } )$ respectively, we obtain

$$
X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta \sim N (A _ {t} m _ {t - 1 | t - 1}, A _ {t} Q _ {t - 1 | t - 1} A _ {t} ^ {\prime} + \Sigma_ {t})
$$

Thus

$$
m _ {t \mid t - 1} = A _ {t} m _ {t - 1 \mid t - 1} \quad \text {a n d} \quad Q _ {t \mid t - 1} = A _ {t} Q _ {t - 1 \mid t - 1} A _ {t} ^ {\prime} + \Sigma_ {t}. \tag {31}
$$

We next calculate $m _ { t | t } , Q _ { t | t }$ from $m _ { t | t - 1 } , Q _ { t | t - 1 }$ by calculating filtering update (28). The basic idea behind this calculation is encapsulated in the result below.

Fact 6.1. Suppose $X \sim N ( m _ { 0 } , Q _ { 0 } )$ and $Y \mid X = x \sim N ( B x , R )$ (note that the condition $Y \mid X = x \sim N ( B x , R )$ can also be written as $Y = B X + V$ where $V \sim N ( 0 , R )$ with $V , X$ being independent). Then

$$
X \mid Y = y \sim N (m _ {1}, Q _ {1})
$$

where

$$
m _ {1} = \left(Q _ {0} ^ {- 1} + B ^ {\prime} R ^ {- 1} B\right) ^ {- 1} \left(Q _ {0} ^ {- 1} m _ {0} + B ^ {\prime} R ^ {- 1} y\right) \quad a n d \quad Q _ {1} = \left(Q _ {0} ^ {- 1} + B ^ {\prime} R ^ {- 1} B\right) ^ {- 1}. \tag {32}
$$

The following two simple examples can be used to better understand the formula (32).

Example 6.2 (Normal Mean Estimation). Suppose $\Theta \sim N ( \mu , \tau ^ { 2 } )$ and $Y _ { 1 } , \dots , Y _ { n } \mid \Theta =$ $\theta \stackrel { i . i . d } { \sim } N ( \theta , \sigma ^ { 2 } )$ . Then it is well-known that

$$
\Theta \mid Y _ {1} = y _ {1}, \ldots , Y _ {n} = y _ {n} \sim N \left(\frac {\mu / \tau^ {2} + n \bar {y} / \sigma^ {2}}{1 / \tau^ {2} + n / \sigma^ {2}}, \frac {1}{1 / \tau^ {2} + n / \sigma^ {2}}\right).
$$

This result is a special case of (32) corresponding to $m _ { 0 } = \mu , Q _ { 0 } = \tau ^ { 2 }$ , $Y = ( Y _ { 1 } , \ldots , Y _ { n } ) ^ { \prime }$ , $y = ( y _ { 1 } , \ldots , y _ { n } ) ^ { \prime }$ , $B = ( 1 , \ldots , 1 ) ^ { \prime }$ and $R = \sigma ^ { 2 } I _ { n }$ .

Example 6.3 (Linear Regression). Suppose $\beta \sim N ( m _ { 0 } , Q _ { 0 } )$ and $Y \mid \beta \sim N ( Z \beta , \sigma ^ { 2 } I _ { n } )$ where $Z$ is a deterministic $n \times p$ matrix. The formula (32) then gives

$$
\beta \mid Y = y \sim N \left(\left(Q _ {0} ^ {- 1} + \frac {X ^ {\prime} X}{\sigma^ {2}}\right) ^ {- 1} \left(\frac {X ^ {\prime} Y}{\sigma^ {2}} + Q _ {0} ^ {- 1} m _ {0}\right), \left(Q _ {0} ^ {- 1} + \frac {X ^ {\prime} X}{\sigma^ {2}}\right) ^ {- 1}\right).
$$

This result is expected because when $Q _ { 0 } = C I$ for a large constant $C$ , we can neglect the effect of $Q _ { 0 }$ and this leads to

$$
\beta \mid Y = y \approx N \left((X ^ {\prime} X) ^ {- 1} X ^ {\prime} Y, \sigma^ {2} (X ^ {\prime} X) ^ {- 1}\right)
$$

which is familiar from usual least squares theory.

The Sherman-Morrison-Woodbury formula:

$$
(A + U C V) ^ {- 1} = A ^ {- 1} - A ^ {- 1} U \left(C ^ {- 1} + V A ^ {- 1} U\right) ^ {- 1} V A ^ {- 1}
$$

can be used with $A = Q _ { 0 } ^ { - 1 }$ , $U = B ^ { \prime }$ , $C = R ^ { - 1 }$ , $V = B$ to obtain the following alternative formulae for $m _ { 1 }$ and $Q _ { 1 }$ :

$$
m _ {1} = m _ {0} + Q _ {0} B ^ {\prime} \left(B Q _ {0} B ^ {\prime} + R\right) ^ {- 1} (y - B m _ {0})
$$

$$
Q _ {1} = Q _ {0} - Q _ {0} B ^ {\prime} \left(B Q _ {0} B ^ {\prime} + R\right) ^ {- 1} B Q _ {0} \tag {33}
$$

Note that (32) involves inversion of the matrix $Q _ { 0 } ^ { - 1 } + B ^ { \prime } R ^ { - 1 } B$ while (53) involves inversion of $B Q _ { 0 } B ^ { \prime } { + } R$ . When the dimension of $B Q _ { 0 } B ^ { \prime } { + } R$ is much smaller than that of $Q _ { 0 } ^ { - 1 } + B ^ { \prime } R ^ { - 1 } B$ , it is computationally advantageous to work with (53) compared to (32). This will often be the case so we shall mainly use the formula (53).

Now let us get back to the derivation of the filtering updates for the Linear Gaussian State Space Model where we need to calculate $m _ { t | t }$ and $Q _ { t | t }$ in terms of $m _ { t \left| t - 1 \right. }$ and $Q _ { t \mid t - 1 }$ . It is easy to check that Fact 9.1 is directly applicable with $m = m _ { t | t - 1 }$ , $Q _ { 0 } = Q _ { t | t - 1 }$ , $B = B _ { t }$ , $R = R _ { t }$ and $m _ { 1 } = m _ { t | t }$ , $Q _ { 1 } = Q _ { t | t }$ . The formula (53) then gives

$$
m _ {t \mid t} = m _ {t \mid t - 1} + Q _ {t \mid t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t \mid t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} \left(y _ {t} - B _ {t} m _ {t \mid t - 1}\right) \tag {34}
$$

$$
Q _ {t | t} = Q _ {t | t - 1} - Q _ {t | t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} B _ {t} Q _ {t | t - 1}
$$

The equations (51) and (52) together comprise the Kalman Filter. They provide the solution for the filtering problem for linear Gaussian state space models. Here is a formal description of the Kalman Filter including the initialization step: We are given the model (49) and we assume that $\mu _ { 0 } , \Gamma _ { 0 } , \{ A _ { t } , t \ge 1 \} , \{ B _ { t } , t \ge 0 \}$ , $\left\{ \Sigma _ { t } , t \geq 0 \right\}$ and $\{ R _ { t } , t \geq 0 \}$ are known. The Kalman filter for calculating the conditional distributions (50) for $s = t$ is:

1. Initialization: Set $m _ { 0 | - 1 } = \mu _ { 0 }$ and $Q _ { 0 | - 1 } = \Gamma _ { 0 }$ . Implement (52) for $t = 0$ to obtain $m _ { 0 | 0 }$ and $Q _ { 0 | 0 }$ .   
2. Recursion: For each $t = 1 , 2 , \ldots { }$ , implement (51) and (52).

Note that the Kalman Filter algorithm also computes the one-step ahead prediction means $m _ { t \left| t - 1 \right. }$ and covariances $Q _ { t \mid t - 1 }$ in intermediate computations. So the Kalman Filter can also be used to obtain these one-step ahead predictions.

# 6.3 Recommended Reading for Today

1. The general filtering approach described in Section 6.1 can be found in:

a) Section 6.2 of the Kitagawa-Gersch book   
b) Section 14.2 of the Kitagawa book.   
c) Section 2.7.1 of the Petris-Petrone-Campagnoli book

2. The Kalman filter is described in the all the books listed in the course outline:

a) Section 5.2 of the Kitagawa-Gersch book   
b) Section 9.2 of the Kitagawa book   
c) Section 4.3 of the Durbin-Koopman book

d) Section 4.3 of the S¨arkk¨a book   
e) Section 2.7.2 of the Petris-Petrone-Campagnoli book   
f) Section 3.2 of the Triantafyllopoulos book

Section 7.2 of the Chopin-Papaspiliopoulos book also discusses the Kalman filter. They however derive the algorithm from a general Feynman-Kac formalism (see their Chapter 5). I will discuss the Feynman-Kac stuff in class a few weeks later.

# 7 Lecture Seven

# 7.1 The Kalman Filter

Consider the linear Gaussian state space model:

$$
X _ {0} \sim N (\mu_ {0}, \Gamma_ {0})
$$

$$
X _ {t} = A _ {t} X _ {t - 1} + U _ {t} \tag {35}
$$

$$
Y _ {t} = B _ {t} X _ {t} + V _ {t}
$$

with $X _ { 0 } , U _ { 1 } , \dots , V _ { 0 } , V _ { 1 } , \dots .$ independent and $U _ { t } \sim N ( 0 , \Sigma _ { t } )$ and $V _ { t } \sim N ( 0 , R _ { t } )$ . Each of the quantities $\mu _ { 0 } , \Gamma _ { 0 } , A _ { t } , B _ { t } , \Sigma _ { t } , R _ { t }$ appearing in the model above can depend on an unknown vector of parameters $\theta$ . Every conditional distribution $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ is Gaussian and we can write

$$
X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \sim N \left(m _ {s \mid t}, Q _ {s \mid t}\right). \tag {36}
$$

The Kalman filtering algorithm specifies how to compute $m _ { t | t } , Q _ { t | t }$ for $t = 0 , 1 , \ldots$ using the following equations:

$$
m _ {t \mid t - 1} = A _ {t} m _ {t - 1 \mid t - 1} \quad \text {a n d} \quad Q _ {t \mid t - 1} = A _ {t} Q _ {t - 1 \mid t - 1} A _ {t} ^ {\prime} + \Sigma_ {t}. \tag {37}
$$

and

$$
m _ {t \mid t} = m _ {t \mid t - 1} + Q _ {t \mid t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t \mid t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} \left(y _ {t} - B _ {t} m _ {t \mid t - 1}\right) \tag {38}
$$

$$
Q _ {t | t} = Q _ {t | t - 1} - Q _ {t | t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} B _ {t} Q _ {t | t - 1}
$$

Equations (51) and (52) together comprise the Kalman Filter. The formal description of the Kalman Filter including the initialization is as follows. We are given the model (49) and we assume that $\mu _ { 0 } , \Gamma _ { 0 } , \{ A _ { t } , t \ge 1 \} , \{ B _ { t } , t \ge 0 \}$ , $\left\{ \Sigma _ { t } , t \geq 0 \right\}$ and $\{ R _ { t } , t \geq 0 \}$ are known. The Kalman filter for calculating the conditional distributions (50) for $s = t$ is:

1. Initialization: Set $m _ { 0 | - 1 } = \mu _ { 0 }$ and $Q _ { 0 | - 1 } = \Gamma _ { 0 }$ . Implement (52) for $t = 0$ to obtain $m _ { 0 | 0 }$ and $Q _ { 0 | 0 }$ .   
2. Recursion: For each $t = 1 , 2 , \ldots$ , implement (51) and (52).

Note that the Kalman Filter algorithm also computes the one-step ahead prediction means $m _ { t \left| t - 1 \right. }$ and covariances $Q _ { t \mid t - 1 }$ in intermediate computations. So the Kalman Filter can also be used to obtain these one-step ahead predictions.

# 7.2 Some Examples

We shall give here some simple examples of linear Gaussian state space models and write the Kalman recursions more explicitly.

# 7.2.1 Tracking One: Velocity Model

Consider the problem of tracking the position of an object moving on a straight line. We observe the position of the object every $\Delta t$ seconds but these measurements are imprecise. For $k = 0 , 1 , 2 , , \ldots ,$ , let $x _ { k }$ denote the actual position of the object at time $k ( \Delta t )$ and let $y _ { k }$ denote the measurement. We assume that

$$
y _ {k} = x _ {k} + \epsilon_ {k} \qquad \mathrm {w i t h} \epsilon_ {k} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2})
$$

for $k = 0 , 1 , 2 , \ldots$ For the state model, in this “velocity model”, we assume that the velocity of the particle stays constant at a level $u _ { k }$ in the time interval $[ ( k - 1 ) ( \Delta t ) , k \Delta t ]$ leading to the equation:

$$
x _ {k} = x _ {k - 1} + u _ {k} (\Delta t) \quad \text {f o r} k = 1, 2, \dots .
$$

Further, we shall assume that $u _ { 1 } , u _ { 2 } , \ldots$ are i.i.d $N ( 0 , \sigma _ { u } ^ { 2 } )$ . Finally assume that $x _ { 0 } \sim N ( 0 , C )$ for a large positive constant $C$ . This is basically the local level model with the state evolution error variance equal to $\sigma _ { u } ^ { 2 } ( \Delta t ) ^ { 2 }$ .

The Kalman filter for this model for computing

$$
x _ {k} \mid y _ {0}, \dots , y _ {k}, \sigma_ {\epsilon}, \sigma_ {u}, C
$$

is easily checked to be given by

$$
m _ {k | k - 1} = m _ {k - 1 | k - 1} \quad \mathrm {a n d} \quad Q _ {k | k - 1} = Q _ {k - 1 | k - 1} + \sigma_ {u} ^ {2} (\Delta t) ^ {2}
$$

and

$$
m _ {k \mid k} = m _ {k \mid k - 1} + \frac {Q _ {k \mid k - 1}}{Q _ {k \mid k - 1} + \sigma_ {\epsilon} ^ {2}} \left(y _ {k} - m _ {k \mid k - 1}\right) \tag {39}
$$

$$
Q _ {k | k} = Q _ {k | k - 1} - \frac {Q _ {k | k - 1} ^ {2}}{Q _ {k | k - 1} + \sigma_ {\epsilon} ^ {2}} = \frac {Q _ {k | k - 1} \sigma_ {\epsilon} ^ {2}}{Q _ {k | k - 1} + \sigma_ {\epsilon} ^ {2}}.
$$

The Kalman Filter is initialized with $m _ { 0 | - 1 } = 0$ and $Q _ { 0 | - 1 } = C$ which leads to (via the filter update (39))

$$
m _ {0 | 0} = m _ {0 | - 1} + \frac {Q _ {0 | - 1}}{Q _ {0 | - 1} + \sigma_ {\epsilon} ^ {2}} \left(y _ {0} - m _ {0 | - 1}\right) = \frac {C}{C + \sigma_ {\epsilon} ^ {2}} y _ {0}
$$

$$
Q _ {0 | 0} = \frac {Q _ {0 | - 1} \sigma_ {\epsilon} ^ {2}}{Q _ {0 | - 1} + \sigma_ {\epsilon} ^ {2}} = \frac {C \sigma_ {\epsilon} ^ {2}}{C + \sigma_ {\epsilon} ^ {2}}.
$$

It is clear that when $C$ is large, the above equations imply that $m _ { 0 | 0 } \approx y _ { 0 }$ and $Q _ { 0 | 0 } \approx \sigma _ { \epsilon } ^ { 2 }$ Thus a commonly used initialization for the local level model is $m _ { 0 | 0 } = y _ { 0 }$ and $Q _ { 0 | 0 } = \sigma _ { \epsilon } ^ { 2 }$ .

# 7.2.2 Tracking Two: Acceleration Model

Consider the same setting as the last subsection. We now consider a different model for the state evolution where we assume that the acceleration (not velocity) remains constant in each time period $[ ( k - 1 ) ( \Delta t ) , k ( \Delta t ) ]$ . Denoting this acceleration by $a _ { k }$ , we see that the velocity at time $( k - 1 ) ( \Delta t )$ (which we denote by $x _ { k - 1 , 2 }$ ) and the velocity at time $k ( \Delta t )$ (which we denote by $x _ { k , 2 }$ ) are related by the equation:

$$
x _ {k, 2} = x _ {k - 1, 2} + a _ {k} (\Delta t). \tag {40}
$$

Further the position at time $( k - 1 ) ( \Delta t )$ (which we denote by $x _ { k - 1 , 1 }$ ) and the position at time $k ( \Delta t )$ (which we denote by $x _ { k , 1 }$ ) are related by the equation:

$$
x _ {k, 1} = x _ {k - 1, 1} + x _ {k - 1, 2} (\Delta t) + \frac {1}{2} (\Delta t) ^ {2} a _ {k}. \tag {41}
$$

Letting the state vector at time $k$ to be both the position and the velocity at time $k$ :

$$
x _ {k} = \left( \begin{array}{c} x _ {k, 1} \\ x _ {k, 2} \end{array} \right),
$$

we can write the state evolution as

$$
x _ {k} = \left( \begin{array}{c c} 1 & \Delta t \\ 0 & 1 \end{array} \right) x _ {k - 1} + a _ {k} \left( \begin{array}{c} (\Delta t) ^ {2} / 2 \\ \Delta t \end{array} \right).
$$

Because the accelerations $a _ { 1 } , a _ { 2 } , \dotsc$ are unknown, a simple way of dealing with them is to assume that:

$$
a _ {1}, a _ {2}, \ldots \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {a} ^ {2}).
$$

Then the state evolution becomes

$$
x _ {k} = \left( \begin{array}{c c} 1 & \Delta t \\ 0 & 1 \end{array} \right) x _ {k - 1} + U _ {k} \qquad \text {w h e r e} U _ {k} \sim N _ {2} \left(\left[ \begin{array}{c} 0 \\ 0 \end{array} \right], \sigma_ {a} ^ {2} \left[ \begin{array}{c c} (\Delta t) ^ {4} / 4 & (\Delta t) ^ {3} / 2 \\ (\Delta t) ^ {3} / 2 & (\Delta t) ^ {2} \end{array} \right]\right)
$$

The equation relating the observation and state variables becomes

$$
y _ {k} = x _ {k, 1} + \epsilon_ {k} = \left( \begin{array}{c c} 1 & 0 \end{array} \right) x _ {k} + \epsilon_ {k} \qquad \text {w h e r e} \epsilon_ {k} \stackrel {{\text {i . i . d}}} {{\sim}} N (0, \sigma_ {\epsilon} ^ {2}).
$$

The Kalman filter for this model simplifies to the following equations. Note that $m _ { s \mid t }$ is a $2 \times 1$ vector and $Q _ { s \mid t }$ is a $2 \times 2$ matrix. The one-step prediction update is

$$
m _ {t | t - 1} = \left( \begin{array}{c c} 1 & \Delta t \\ 0 & 1 \end{array} \right) m _ {t - 1 | t - 1}
$$

and

$$
Q _ {t | t - 1} = \left( \begin{array}{c c} 1 & \Delta t \\ 0 & 1 \end{array} \right) Q _ {t - 1 | t - 1} \left( \begin{array}{c c} 1 & 0 \\ \Delta t & 1 \end{array} \right) + \sigma_ {a} ^ {2} \left( \begin{array}{c c} (\Delta t) ^ {4} / 4 & (\Delta t) ^ {3} / 2 \\ (\Delta t) ^ {3} / 2 & (\Delta t) ^ {2} \end{array} \right)
$$

The filter update is given by the two equations:

$$
\begin{array}{l} m _ {t | t} = m _ {t | t - 1} + \frac {\left(y _ {t} - \left( \begin{array}{c c} 1 & 0 \end{array} \right) m _ {t | t - 1}\right)}{\left( \begin{array}{c c} 1 & 0 \end{array} \right) Q _ {t | t - 1} \left( \begin{array}{c} 1 \\ 0 \end{array} \right) + \sigma_ {\epsilon} ^ {2}} Q _ {t | t - 1} \left( \begin{array}{c} 1 \\ 0 \end{array} \right) \\ = m _ {t | t - 1} + \frac {\left(y _ {t} - m _ {t | t - 1} [ 1 ]\right)}{Q _ {t | t - 1} [ 1 , 1 ] + \sigma_ {\epsilon} ^ {2}} \left( \begin{array}{c} Q _ {t | t - 1} [ 1, 1 ] \\ Q _ {t | t - 1} [ 2, 1 ] \end{array} \right), \\ \end{array}
$$

and

$$
\begin{array}{l} Q _ {t | t} = Q _ {t | t - 1} - \frac {Q _ {t | t - 1} \left( \begin{array}{c} 1 \\ 0 \end{array} \right) \left( \begin{array}{c c} 1 & 0 \end{array} \right) Q _ {t | t - 1}}{\left( \begin{array}{c c} 1 & 0 \end{array} \right) Q _ {t | t - 1} \left( \begin{array}{c} 1 \\ 0 \end{array} \right) + \sigma_ {\epsilon} ^ {2}} \\ = Q _ {t | t - 1} - \frac {1}{Q _ {t | t - 1} [ 1 , 1 ] + \sigma_ {\epsilon} ^ {2}} \left( \begin{array}{c c} Q _ {t | t - 1} ^ {2} [ 1, 1 ] & Q _ {t | t - 1} [ 1, 1 ] Q _ {t | t - 1} [ 2, 1 ] \\ Q _ {t | t - 1} [ 1, 1 ] Q _ {t | t - 1} [ 2, 2 ] & Q _ {t | t - 1} ^ {2} [ 2, 1 ] \end{array} \right) \\ \end{array}
$$

In the above, we used $Q _ { t | t - 1 } | i , j |$ for the $( i , j ) ^ { t h }$ entry of the matrix $Q _ { t \mid t - 1 }$ and $m _ { t | t - 1 }$ [1] for the first entry of the $2 \times 1$ vector $m _ { t \left| t - 1 \right. }$ .

# 7.2.3 Tracking Three: Local Linear Model

The local linear model that we saw previously can be seen as an approximation of the acceleration model of the last subsection. Specifically, in the position equation (41), we drop the last term $a _ { k } ( \Delta t ) ^ { 2 } / 2$ the idea being that if $\Delta t$ is small, then this term will generally be negligible compared to at least one of the other two terms $x _ { k - 1 , 1 } ( \Delta t )$ and $x _ { k - 1 , 1 } ( \Delta t )$ . This leads to the equations:

$$
x _ {k, 1} = x _ {k - 1, 1} + x _ {k - 1, 2} (\Delta t) \quad \text {a n d} \quad x _ {k, 2} = x _ {k - 1, 2} + a _ {k} (\Delta t).
$$

We can combine these two equations into one by using $\begin{array} { r } { x _ { k , 2 } = \frac { x _ { k + 1 , 1 } - x _ { k , 1 } } { \Delta t } } \end{array}$ (which is obtained from the first equation) in the second equation to deduce

$$
x _ {k, 1} - 2 x _ {k - 1, 1} + x _ {k - 2, 1} = a _ {k - 1} (\Delta t) ^ {2} \sim N (0, \sigma_ {a} ^ {2} (\Delta t) ^ {4})
$$

which is the local linear model with the state evolution error variance equal to $\sigma _ { a } ^ { 2 } ( \Delta t ) ^ { 4 }$ . This can be written as a state space model using $\binom { x _ { k , 1 } } { x _ { k - 1 , 1 } }$ as the state or as in the previous xk−1,1 subsection with $\binom { x _ { k , 1 } } { ( \Delta t ) ^ { - 1 } ( x _ { k , 1 } - x _ { k - 1 , 1 } ) }$ xk,1 as the state. Note that this shows that there can be many different ways to write a model in state space form. The Kalman recursions for the local level model are left as exercise.

# 7.3 Use of the Kalman Filter for Parameter Estimation by Maximum Likelihood

As mentioned previously, the quantities $\mu _ { 0 } , \Gamma _ { 0 } , A _ { t } , B _ { t } , \Sigma _ { t } , R _ { t }$ appearing in the state space model (49) typically depend on an unknown vector of parameters $\theta$ which needs to be estimated from the observed data $y _ { 0 } , \ldots , y _ { T }$ . A standard method for parameter estimation is maximum likelihood and the Kalman filter output is useful for writing down the likelihood function. To see this, first note that the likelihood for the observed data $y _ { 0 } , \ldots , y _ { T }$ is given by

$$
f _ {Y _ {0}, \ldots , Y _ {T} | \theta} (y _ {0}, \ldots , y _ {T}) = \prod_ {t = 0} ^ {T} f _ {Y _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) = \prod_ {t = 0} ^ {T} f _ {B _ {t} X _ {t} + V _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}).
$$

Conditionally on $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ , the random variables $X _ { t }$ and $V _ { t }$ are independent having the $N ( m _ { t \mid t - 1 } , Q _ { t \mid t - 1 } )$ and $N ( 0 , R _ { t } )$ respectively. Thus

$$
B _ {t} X _ {t} + V _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta \sim N (B _ {t} m _ {t | t - 1}, B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}).
$$

Thus, for each $t = 0 , 1 , \ldots , T$ , we have

$$
\begin{array}{l} f _ {Y _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) \\ = \left| 2 \pi \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) \right| ^ {- 1 / 2} \exp \left(- \frac {1}{2} \left(y _ {t} - B _ {t} m _ {t | t - 1}\right) ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} \left(y _ {t} - B _ {t} m _ {t | t - 1}\right)\right) \\ \end{array}
$$

where $| \cdot |$ denotes determinant. Let

$$
\epsilon_ {t} (\theta) := y _ {t} - B _ {t} m _ {t | t - 1} \quad \text {a n d} \quad H _ {t} (\theta) := B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}
$$

for $t = 0 , 1 , 2 , \ldots$ Then

$$
- 2 \log f _ {Y _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) = \log | 2 \pi H _ {t} (\theta) | + \epsilon_ {t} ^ {\prime} (\theta) H _ {t} ^ {- 1} (\theta) \epsilon_ {t} (\theta)
$$

Thus

$$
(- 2) \times \log \text {- l i k e l i h o o d} = \sum_ {t = 0} ^ {T} \left[ \log | 2 \pi H _ {t} (\theta) | + \epsilon_ {t} ^ {\prime} (\theta) H _ {t} ^ {- 1} (\theta) \epsilon_ {t} (\theta) \right].
$$

For calculating this likelihood, we only need $m _ { t \left| t - 1 \right. }$ and $Q _ { t \mid t - 1 }$ for $t = 0 , 1 , 2 , \ldots$ which can be obtained from the Kalman Filter. One can maximize likelihood by minimizing the right hand side above over the parameters $\theta$ . Numerical optimization routines can be used for this purpose.

# 7.4 Recommended Reading for Today

1. The local level model is analyzed in detail in Chapter 2 of the Durbin-Koopman book. In particular, see Section 2.2.1 for the Kalman filter updates in the local level model. Some comments on the initial distribution $X _ { 0 } \sim { \cal N } ( 0 , C )$ (for a large $C$ ) can be found in Section 2.9.   
2. The acceleration model of Subsection 7.2.2 can be found in https://en.wikipedia. org/wiki/Kalman_filter (see Section 7).   
3. For likelihood computation using the Kalman filter, see Section 9.6 of the Kitagawa book.

# 8 Lecture Eight

# 8.1 Some remarks on the local level model

Consider the local level model:

$$
X _ {0} \sim N (0, C) \quad X _ {t} = X _ {t - 1} + Z _ {t} \quad Y _ {t} = X _ {t} + \epsilon_ {t}
$$

where $X _ { 0 } , Z _ { 1 } , Z _ { 2 } , \ldots , \epsilon _ { 0 } , \epsilon _ { 1 } , \ldots .$ are independent with $Z _ { t } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma _ { Z } ^ { 2 } )$ and $\epsilon _ { t } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma _ { \epsilon } ^ { 2 } )$ . The Kalman filter recursions for this model are given by

$$
m _ {t | t - 1} = m _ {t - 1 | t - 1} \quad \mathrm {a n d} \quad Q _ {t | t - 1} = Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2}
$$

and

$$
m _ {t | t} = m _ {t | t - 1} + \frac {Q _ {t | t - 1}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} \left(y _ {t} - m _ {t | t - 1}\right) = \frac {\sigma_ {\epsilon} ^ {2}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} m _ {t | t - 1} + \frac {Q _ {t | t - 1}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} y _ {t}
$$

$$
Q _ {t | t} = \frac {Q _ {t | t - 1} \sigma_ {\epsilon} ^ {2}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}}.
$$

Here $m _ { s \mid t }$ and $Q _ { s \mid t }$ denote the conditional mean and variance of $X _ { s }$ given $Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t }$ (and $\sigma _ { Z } , \sigma _ { \epsilon }$ ).

It is interesting to note that $m _ { t | t }$ is a weighted linear combination of $m _ { t \left| t - 1 \right. }$ and $y _ { t }$ . We see in simulations that when the $\sigma _ { Z }$ parameter is large, then the filtering mean $m _ { t | t }$ is close to $y _ { t }$ for each $t \geq 0$ . This can be explained as follows. Because $Q _ { t | t - 1 } = Q _ { t - 1 | t - 1 } + \sigma _ { Z } ^ { 2 } \geq \sigma _ { Z } ^ { 2 }$ , it follows that, when $\sigma _ { Z }$ is large, each $Q _ { t \mid t - 1 }$ is also large. As a result, the weight for $y _ { t }$ dominates the weight for $m _ { t \left| t - 1 \right. }$ in the formula for $m _ { t \mid t }$ leading to $m _ { t | t } \approx y _ { t }$ when $\sigma _ { Z }$ is large.

Note that $m _ { t | t } \approx y _ { t }$ does not imply that the model is overfitting the observed data. This is because the log-likelihood multiplied by $\left( - 2 \right)$ is given by

$$
\begin{array}{l} (- 2) \mathrm {l o g - l i k e l i h o o d} = \sum_ {t = 0} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {\left(y _ {t} - m _ {t | t - 1}\right) ^ {2}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} \right] \\ = \sum_ {t = 0} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {\left(y _ {t} - m _ {t - 1 | t - 1}\right) ^ {2}}{Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2}} \right] \\ \end{array}
$$

When $\sigma _ { Z }$ is large, we would have $m _ { t - 1 | t - 1 } \approx y _ { t - 1 }$ as remarked above. Thus the above expression for large $O Z$ becomes

$$
(- 2) \mathrm {l o g - l i k e l i h o o d} \approx \sum_ {t = 0} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - y _ {t - 1}) ^ {2}}{Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2}} \right]
$$

The second term in the sum above is of smaller order compared to the first term when $\sigma _ { Z }$ is large. Thus the behavior of the whole expression will be similar to the behavior to the first term which is increasing in $\sigma _ { Z }$ . Thus as $\sigma _ { Z }$ increases, the log-likelihood decreases (note that the above is the expression for negative log-likelihood multiplied by 2). This means that there is no overfitting for large $O Z$ (overfitting would happen when the likelihood keeps getting better and better when $o _ { Z }$ is increased which is not happening here).

In the last class, we mentioned that parameter estimates of $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ can be obtained by maximizing the likelihood (or equivalently, minimizing negative two times the log-likelihood) over $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ . The result of this optimization cannot be written in closed because it is a somewhat complicated optimization. This is because it depends on $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ in a not-sosimple way. To highlight this, let us note that $Q _ { t \mid t - 1 }$ and $m _ { t \left| t - 1 \right. }$ depend on $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ , and also on the initial state variance $C$ . We shall therefore write them as $Q _ { t | t - 1 } ( C , \sigma _ { Z } , \sigma _ { \epsilon } )$ and $m _ { t | t - 1 } ( C , \sigma _ { Z } , \sigma _ { \epsilon } )$ respectively. We thus have

$$
\begin{array}{l} \ell \left(\sigma_ {Z}, \sigma_ {\epsilon}\right) := (- 2) \log \text {- l i k e l i h o o d} \\ = \sum_ {t = 0} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (C, \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - m _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon})) ^ {2}}{Q _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right]. \\ \end{array}
$$

The dependence of this function on $C , \sigma _ { Z } , \sigma _ { \epsilon }$ is not so simple. Numerical routines can be used to optimize this function of $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ . The following trick reduces this to a one-parameter optimization problem and it can be quite handy. To see this, first note that for $t = 0$ , we have $Q _ { 0 | - 1 } = C$ and $m _ { 0 | - 1 } = 0$ . Thus

$$
\begin{array}{l} \ell (\sigma_ {Z}, \sigma_ {\epsilon}) = \log \left\{2 \pi \left(C + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {y _ {0} ^ {2}}{C + \sigma_ {\epsilon} ^ {2}} \\ + \sum_ {t = 1} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (C, \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - m _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon})) ^ {2}}{Q _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right]. \\ \end{array}
$$

As $C$ is large, the first term is approximately $\log ( 2 \pi C )$ and the second term is zero. Thus

$$
\ell (\sigma_ {Z}, \sigma_ {\epsilon}) \approx \log (2 \pi C) + \sum_ {t = 1} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (C, \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - m _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon})) ^ {2}}{Q _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right].
$$

The $\log ( 2 \pi C )$ term does not depend on $o _ { Z }$ or $\sigma _ { \epsilon }$ so it can be removed from the optimization so the goal is to minimize:

$$
\sum_ {t = 1} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (C, \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - m _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon})) ^ {2}}{Q _ {t | t - 1} (C , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right].
$$

We shall now take $C = + \infty$ . The quantities $Q _ { t | t - 1 } ( \infty , \sigma _ { Z } , \sigma _ { \epsilon } )$ and $m _ { t | t - 1 } ( \infty , \sigma _ { Z } , \sigma _ { \epsilon } )$ are then obtained for $t = 1 , 2 , \ldots$ by running the Kalman filter steps with the initialization $m _ { 0 | 0 } = y _ { 0 }$ and $Q _ { 0 | 0 } = \sigma _ { \epsilon } ^ { 2 }$ . Our goal is to minimize

$$
\ell^ {*} (\sigma_ {Z}, \sigma_ {\epsilon}) := \sum_ {t = 1} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (\infty , \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {(y _ {t} - m _ {t | t - 1} (\infty , \sigma_ {Z} , \sigma_ {\epsilon})) ^ {2}}{Q _ {t | t - 1} (\infty , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right].
$$

We now note the following useful fact:

$$
m _ {t \mid t - 1} (\infty , \sigma_ {Z}, \sigma_ {\epsilon}) = m _ {t \mid t - 1} (\infty , \frac {\sigma_ {Z}}{\sigma_ {\epsilon}}, 1) \quad \text {a n d} \quad Q _ {t \mid t - 1} (\infty , \sigma_ {Z}, \sigma_ {\epsilon}) = \sigma_ {\epsilon} ^ {2} Q _ {t \mid t - 1} (\infty , \frac {\sigma_ {Z}}{\sigma_ {\epsilon}}, 1). \tag {42}
$$

I will leave the proof of this fact as an exercise. To compute $m _ { t | t - 1 } ( \infty , \sigma _ { Z } / \sigma _ { \epsilon } , 1 )$ and $Q _ { t | t - 1 } ( \infty , \sigma _ { Z } / \sigma _ { \epsilon } , 1 )$ , we would need to run the Kalman filter with $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ replaced by $\sigma _ { Z } / \sigma _ { \epsilon }$ and 1 respectively (the initialization would then be $m _ { 0 | 0 } = y _ { 0 }$ and $Q _ { 0 | 0 } = 1$ ).

Because of the scaling fact (42), we can write $\ell ^ { * } ( \sigma _ { Z } , \sigma _ { \epsilon } )$ as

$$
\begin{array}{l} \ell^ {*} (\sigma_ {Z}, \sigma_ {\epsilon}) := \sum_ {t = 1} ^ {T} \left[ \log \left\{2 \pi \left(Q _ {t | t - 1} (\infty , \sigma_ {Z}, \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}\right) \right\} + \frac {\left(y _ {t} - m _ {t | t - 1} (\infty , \sigma_ {Z} , \sigma_ {\epsilon})\right) ^ {2}}{Q _ {t | t - 1} (\infty , \sigma_ {Z} , \sigma_ {\epsilon}) + \sigma_ {\epsilon} ^ {2}} \right] \\ = T \log (2 \pi \sigma_ {\epsilon} ^ {2}) + \sum_ {t = 1} ^ {T} \log \left(Q _ {t | t - 1} (\infty , \frac {\sigma_ {Z}}{\sigma_ {\epsilon}}, 1) + 1\right) + \frac {1}{\sigma_ {\epsilon} ^ {2}} \sum_ {t = 1} ^ {T} \frac {\left(y _ {t} - m _ {t | t - 1} (\infty , \frac {\sigma_ {Z}}{\sigma_ {\epsilon}} , 1)\right) ^ {2}}{Q _ {t | t - 1} (\infty , \frac {\sigma_ {Z}}{\sigma_ {\epsilon}} , 1) + 1}. \\ \end{array}
$$

The goal is to minimize the above function over all $\sigma _ { \epsilon } > 0$ and $\sigma _ { Z } > 0$ . Equivalently, we need to minimize this over all $\sigma _ { \epsilon } > 0$ and $\begin{array} { r } { q : = \frac { \upsilon _ { Z } } { \sigma _ { \epsilon } } > 0 } \end{array}$ . The advantage of viewing the problem as an optimization over $\sigma _ { \epsilon }$ and $q$ is that it is easy to find the best $\sigma _ { \epsilon }$ for each value of $q$ . Specifically, we need to minimize

$$
T \log (2 \pi \sigma_ {\epsilon} ^ {2}) + \sum_ {t = 1} ^ {T} \log \left(Q _ {t | t - 1} (\infty , q, 1) + 1\right) + \frac {1}{\sigma_ {\epsilon} ^ {2}} \sum_ {t = 1} ^ {T} \frac {\left(y _ {t} - m _ {t | t - 1} (\infty , q , 1)\right) ^ {2}}{Q _ {t | t - 1} (\infty , q , 1) + 1} \tag {43}
$$

over both $\sigma _ { \epsilon } > 0$ and $q > 0$ . For each fixed $q$ , it is easy to find the minimizing $\sigma _ { \epsilon }$ by simply taking the derivative with respect to $\sigma _ { \epsilon } ^ { 2 }$ and setting it equal to zero. This gives

$$
\hat {\sigma} _ {\epsilon} ^ {2} (q) := \frac {1}{T} \sum_ {t = 1} ^ {T} \frac {\left(y _ {t} - m _ {t | t - 1} (\infty , q , 1)\right) ^ {2}}{Q _ {t | t - 1} (\infty , q , 1) + 1}. \tag {44}
$$

Plugging this value of $\sigma _ { \epsilon } ^ { 2 }$ in (43), we get

$$
T \log (2 \pi \hat {\sigma} _ {\epsilon} ^ {2} (q)) + \sum_ {t = 1} ^ {T} \log \left(Q _ {t | t - 1} (\infty , q, 1) + 1\right) + T. \tag {45}
$$

This function will need to be numerically minimized over $q > 0$ to obtain the minimizer $\hat { q }$ . This is an easier optimization problem (compared to minimizing $\ell ^ { * } ( \sigma _ { Z } , \sigma _ { \epsilon } )$ over both $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ ) for numerical methods as it only depends on the one variable $q$ . After obtaining the minimizer $\hat { q }$ , $\sigma _ { \epsilon } ^ { 2 }$ is estimated by $\hat { \sigma } _ { \epsilon } ^ { 2 } ( \hat { q } )$ (i.e., the right hand side of (44) with $q = \hat { q }$ ) and then $\sigma _ { Z }$ is estimated by $\hat { q } \hat { \sigma } _ { \epsilon } ( \hat { q } )$ . Finally, note that to form the objective (45), we need to calculate $\hat { \sigma } _ { \epsilon } ^ { 2 } ( q )$ and, for this, it is necessary to implement the Kalman filter with $\sigma _ { Z }$ set to $q$ and $\sigma _ { \epsilon }$ set to 1 in order to calculate $m _ { t | t - 1 } ( \infty , q , 1 )$ and $Q _ { t | t - 1 } ( \infty , q , 1 )$ .

# 8.2 Application of the Kalman Filter to Linear Regression

Consider the usual linear regression setting where we observe data $( z _ { 0 } , y _ { 0 } ) , \dotsc , ( z _ { T } , y _ { T } )$ where $z _ { t }$ is the $p \times 1$ covariate and $y _ { t }$ is the scalar response corresponding to index $t$ . The usual linear model for this setting assumes that the covariates $z _ { 0 } , \dots , z _ { T }$ are deterministic and the response $y _ { t }$ is related to $z _ { t }$ via

$$
y _ {t} = z _ {t} ^ {\prime} \beta + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

In Bayesian treatments of the linear model, one supplements the model above with the prior

$$
\beta \sim N (\mu_ {0}, \Gamma_ {0}).
$$

If no information on $\beta$ is available, one can set $\mu _ { 0 } = 0$ and $\Gamma _ { 0 } = C I$ for a large constant $C$ . Having a prior is a good idea in general as it avoids degeneracy issues. For example, when the matrix $Z$ of covariates (whose rows are $z _ { 0 } ^ { \prime } , \dots , z _ { T } ^ { \prime } )$ ) does not have full column rank, the usual least squares estimator is not defined but the Bayesian posterior is well-defined as long as $\Gamma _ { 0 }$ is invertible.

The posterior distribution of $\beta$ is given by

$$
\beta \mid \text {d a t a}, \sigma \sim N \left(\left(\Gamma_ {0} ^ {- 1} + \frac {Z ^ {\prime} Z}{\sigma^ {2}}\right) ^ {- 1} \left(\frac {Z ^ {\prime} Y}{\sigma^ {2}} + \Gamma_ {0} ^ {- 1} \mu_ {0}\right), \left(\Gamma_ {0} ^ {- 1} + \frac {Z ^ {\prime} Z}{\sigma^ {2}}\right) ^ {- 1}\right) \tag {46}
$$

Direct computation of mean vector and covariance matrix of the above posterior distribution requires inverting the $p \times p$ matrix $\Gamma _ { 0 } ^ { - 1 } + Z ^ { \prime } Z / \sigma ^ { 2 }$ and this can be computationally costly (note that calculating $\Gamma _ { 0 } ^ { - 1 }$ is usually not hard as $\Gamma _ { 0 }$ is commonly a constant multiple of the identity; the main issue here involves inverting $\Gamma _ { 0 } ^ { - 1 } + Z ^ { \prime } Z / \sigma ^ { 2 } )$ ).

The Kalman filter provides an alternative way of computing the posterior mean and variance via a sequential algorithm which does not involve matrix inversion at any step. This is described below. The first step is to write the linear regression model in state space form. We take the state variables to be $\beta _ { 0 } , \beta _ { 1 } , \ldots$ with the state evolution as

$$
\beta_ {t} = \beta_ {t - 1} \qquad \text {f o r} t = 1, 2, \ldots
$$

The observation is

$$
y _ {t} = z _ {t} ^ {\prime} \beta_ {t} + \epsilon_ {t} \qquad \text {f o r} t = 0, 1, 2, \ldots
$$

Finally the initial condition is $\beta _ { 0 } \sim N ( \mu _ { 0 } , \Gamma _ { 0 } )$ . This linear Gaussian state space model is exactly the Bayesian linear regression model and so we can apply the Kalman filter. Note that (46) is simply the filtering distribution in this state space model at time $T$ . Thus

$$
m _ {T | T} = \left(\Gamma_ {0} ^ {- 1} + \frac {Z ^ {\prime} Z}{\sigma^ {2}}\right) ^ {- 1} \left(\frac {Z ^ {\prime} Y}{\sigma^ {2}} + \Gamma_ {0} ^ {- 1} \mu_ {0}\right) \quad \mathrm {a n d} \quad Q _ {T | T} = \left(\Gamma_ {0} ^ {- 1} + \frac {Z ^ {\prime} Z}{\sigma^ {2}}\right) ^ {- 1}.
$$

The Kalman filter provides an alternative way of computing $m _ { T | T }$ and $Q _ { T | T }$ using the following recursions. Because $\beta _ { t } ~ = ~ \beta _ { t - 1 }$ , the one-step ahead prediction update is simply $m _ { t | t - 1 } = m _ { t - 1 | t - 1 }$ and $Q _ { t | t - 1 } = Q _ { t - 1 | t - 1 }$ . The filter update is

$$
m _ {t | t} = m _ {t | t - 1} + \frac {y _ {t} - z _ {t} ^ {\prime} m _ {t | t - 1}}{z _ {t} ^ {\prime} Q _ {t | t - 1} z _ {t} + \sigma_ {\epsilon} ^ {2}} Q _ {t | t - 1} z _ {t}
$$

$$
Q _ {t | t} = Q _ {t | t - 1} - \frac {Q _ {t | t - 1} z _ {t} z _ {t} ^ {\prime} Q _ {t | t - 1}}{z _ {t} ^ {\prime} Q _ {t | t - 1} z _ {t} + \sigma_ {\epsilon} ^ {2}}.
$$

These recursions are initialized with $m _ { 0 | - 1 } = \mu _ { 0 } , Q _ { 0 | - 1 } = \Gamma _ { 0 }$ leading to

$$
m _ {0 | 0} = \mu_ {0} + \frac {y _ {0} - z _ {0} ^ {\prime} \mu_ {0}}{z _ {0} ^ {\prime} \Gamma_ {0} z _ {0} + \sigma_ {\epsilon} ^ {2}} \Gamma_ {0} z _ {0}
$$

$$
Q _ {0 | 0} = \Gamma_ {0} - \frac {\Gamma_ {0} z _ {0} z _ {0} ^ {\prime} \Gamma_ {0}}{z _ {0} ^ {\prime} \Gamma_ {0} z _ {0} + \sigma_ {\epsilon} ^ {2}}.
$$

The main point to be noted here is that, in the Kalman filter, at no point do we need to invert a $p \times p$ matrix. There are matrix vector products and other elementary operations but there is no matrix inversion.

# 8.3 Prediction

Prediction, in the context of state space models, refers to the problem of finding the distribution $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ for $s > t$ . The prediction problem for linear Gaussian state space models is readily solved by the Kalman filter. To see this, note that we need to find the mean $m _ { s \mid t }$ and covariance $Q _ { s \mid t }$ for each $s > t$ . The Kalman filter tells us how to compute $m _ { t | t } , Q _ { t | t }$ . The prediction problem for $s = t + 1$ is easily solved via (this is basically the same as the one-step ahead prediction update used in the Kalman filter):

$$
m _ {t + 1 | t} = A _ {t + 1} m _ {t | t} \quad \text {a n d} \quad Q _ {t + 1 | t} = A _ {t + 1} Q _ {t | t} A _ {t + 1} ^ {\prime} + \Sigma_ {t + 1}. \tag {47}
$$

Next for $s = t + 2$ , observe that

$$
X _ {t + 2} \mid (Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta) = A _ {t + 2} X _ {t + 1} + U _ {t + 2} \mid (Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta)
$$

Note now that

$$
X _ {t + 1} \mid (Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta) \sim N (m _ {t + 1 | t}, Q _ {t + 1 | t})
$$

$$
U _ {t + 2} \mid (Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta) \sim N (0, \Sigma_ {t + 2})
$$

and further $X _ { t + 1 }$ and $U _ { t + 2 }$ are independent conditional on $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta$ . Thus

$$
X _ {t + 2} \mid (Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta) \sim N (A _ {t + 2} m _ {t + 1 | t}, A _ {t + 2} ^ {\prime} Q _ {t + 1 | t} A _ {t + 2} + \Sigma_ {t + 2}).
$$

Therefore

$$
m _ {t + 2 | t} = A _ {t + 2} m _ {t + 1 | t} \quad \mathrm {a n d} \quad Q _ {t + 2 | t} = A _ {t + 2} ^ {\prime} Q _ {t + 1 | t} A _ {t + 2} + \Sigma_ {t + 2}.
$$

Note that the terms $m _ { t + 1 | t }$ and $Q _ { t + 1 | t }$ appearing on the right hand side above have already been calculated in (47).

More generally, one can write $m _ { s | t } , Q _ { s | t }$ for $s > t$ in terms of $m _ { s - 1 | t } , Q _ { s - 1 | t }$ as

$$
m _ {s \mid t} = A _ {s} m _ {s - 1 \mid t} \quad \text {a n d} \quad Q _ {s \mid t} = A _ {s} Q _ {s - 1 \mid t} A _ {s} ^ {\prime} + \Sigma_ {s}.
$$

This equation can be used recursively for $s = t + 1 , t + 2$ , to calculate all prediction distributions.

# 8.4 Smoothing

Smoothing, in the context of state space models, refers to the problem of finding the distribution of $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ for $s \leq t$ . These are calculated by backward recursion starting for $s = t$ and then decreasing $s$ (note that the smoothing distribution for $s = t$ is a filtering distribution which is given by the Kalman filter). The details for this will be discussed next week.

# 8.5 Recommended Reading for Today

1. The technique described in Section 8.1 for reducing the likelihood optimization to a one-dimensional optimization problem can be found in Section 2.10.2 of the Durbin-Koopman. This technique holds in some more settings as described in Section 9.6 of the Kitagawa book.   
2. See Sections 3.1, 3.2 and 3.3 of the S¨arkk¨a book for treatment of linear regression and application of the Kalman filter for recursive linear regression. Also see Section 3.4 for a treatment of the linear regression with drift model.   
3. The prediction recursions can be found in Section 9.5 of the Kitagawa book.

# 9 Lecture Nine

# 9.1 Smoothing

Smoothing, in the context of state space models, refers to the problem of finding the conditional distribution $X _ { s } ~ \mid ~ Y _ { 0 } = y _ { 0 } , \dotsc , Y _ { t } = y _ { t } , \theta$ for $s \leq t$ . The main interest in these conditional distributions is in the case $t = x$ (recall that our observed data is $y _ { 0 } , \ldots , y _ { T }$ ).

The algorithm that we shall discuss proceeds by first running the filtering step which calculates the distributions $X _ { t } \ | \ Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ for $t = 0 , 1 , 2 , \ldots$ . Following this, one follows backward recursion starting from $s = t$ and then decreasing $s$ as $t - 1 , t - 2 , \ldots$ to calculate the conditional distributions $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ for $s \leq t$ . The overall algorithm is often referred to as FFBS (Forward Filtering Backward Smoothing).

We shall understand the backward recursion in the general case of arbitrary state space models. Subsequently, we shall specialize this to the case of linear Gaussian state space models.

# 9.2 Backward Recursion for General State Space Models

Fix a value of $t \geq 0$ . Assume that we have computed the conditional density:

$$
f _ {X _ {s + 1} \mid} Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta
$$

for some $s < t$ . The goal is then to figure out how to use the above density to calculate

$$
f _ {X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta}.
$$

For this, we write

$$
f _ {X _ {s} | Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {s}) = \int f _ {X _ {s} | X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {s}) f _ {X _ {s + 1} | Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {s + 1}) d x _ {s + 1}.
$$

The key now is to note that

$$
X _ {s} \mid (X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta) \stackrel {\mathrm {d}} {=} X _ {s} \mid (X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \ldots , Y _ {s} = y _ {s}, \theta).
$$

In words, the above means that conditional on $X _ { s + 1 } = x _ { s + 1 } , Y _ { 0 } = y _ { 0 } , \dots , Y _ { s } = y _ { s }$ , the random objects $X _ { s }$ and $( Y _ { s + 1 } , \ldots , Y _ { t } )$ are independent. I will leave the verification of this

property as an exercise. We thus have

$$
f _ {X _ {s} | Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) = \int f _ {X _ {s} | X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s}) f _ {X _ {s + 1} | Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s + 1}) d x _ {s + 1}.
$$

The next step is to calculate $f _ { X _ { s } | X _ { s + 1 } = x _ { s + 1 } , Y _ { 0 } = y _ { 0 } , \ldots , Y _ { s } = y _ { s } , \theta } ( x _ { s } )$ . For this we use Bayes rule to write

$$
\begin{array}{l} f _ {X _ {s} \mid X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s}) \propto f _ {X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s}) f _ {X _ {s + 1} \mid X _ {s} = x _ {s}, Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s + 1}) \\ = f _ {X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s}) f _ {X _ {s + 1} \mid X _ {s} = x _ {s}, \theta} (x _ {s + 1}) \\ = \frac {f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (x _ {s}) f _ {X _ {s + 1} | X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (u) f _ {X _ {s + 1} | X _ {s} = u , \theta} (x _ {s + 1}) d u}. \\ \end{array}
$$

We can thus write the backward smoothing recursion in one step as

$$
\begin{array}{l} f _ {X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) \\ = \int \left[ \frac {f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (x _ {s}) f _ {X _ {s + 1} | X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (u) f _ {X _ {s + 1} | X _ {s} = u , \theta} (x _ {s + 1}) d u} \right] f _ {X _ {s + 1} | Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s + 1}) d x _ {s + 1} \tag {48} \\ \end{array}
$$

Note that the right hand side above involves the densities fXs+1|Y0=y0,...,Yt=yt,θ, fXs|Y0=y0,...,Ys=ys,θ $f _ { X _ { s + 1 } | Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta }$ $f _ { X _ { s } | Y _ { 0 } = y _ { 0 } , \dots , Y _ { s } = y _ { s } , \theta }$ and $f _ { X _ { s + 1 } | X _ { s } = u , \theta }$ . The first of these densities is available to us because we are assuming that we calculated the smoothing density for $s + 1$ . The second of these densities is a filtering density and will be available after running the forward filtering algorithm. The third of these densities is the transition density of the hidden Markov process that is available from the specification of the state space model.

For the linear Gaussian state space models, the recursion above can be re-written in closed form in terms of the means and covariances of the distributions as we show in the next section.

# 9.3 Smoothing for Linear Gaussian State Space Models

Consider the linear Gaussian state space model:

$$
X _ {0} \sim N (\mu_ {0}, \Gamma_ {0})
$$

$$
X _ {t} = A _ {t} X _ {t - 1} + U _ {t} \tag {49}
$$

$$
Y _ {t} = B _ {t} X _ {t} + V _ {t}
$$

with $X _ { 0 } , U _ { 1 } , \dots , V _ { 0 } , V _ { 1 } , \dots .$ independent and $U _ { t } \sim N ( 0 , \Sigma _ { t } )$ and $V _ { t } \sim N ( 0 , R _ { t } )$ . Each of the quantities $\mu _ { 0 } , \Gamma _ { 0 } , A _ { t } , B _ { t } , \Sigma _ { t } , R _ { t }$ appearing in the model above can depend on an unknown vector of parameters $\theta$ . Every conditional distribution $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ is Gaussian and we can write

$$
X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \sim N \left(m _ {s \mid t}, Q _ {s \mid t}\right). \tag {50}
$$

We have already seen that the Kalman filter computes $m _ { t | t } , Q _ { t | t }$ using the following equations:

$$
m _ {t \mid t - 1} = A _ {t} m _ {t - 1 \mid t - 1} \quad \text {a n d} \quad Q _ {t \mid t - 1} = A _ {t} Q _ {t - 1 \mid t - 1} A _ {t} ^ {\prime} + \Sigma_ {t}. \tag {51}
$$

and

$$
m _ {t \mid t} = m _ {t \mid t - 1} + Q _ {t \mid t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t \mid t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} \left(y _ {t} - B _ {t} m _ {t \mid t - 1}\right) \tag {52}
$$

$$
Q _ {t | t} = Q _ {t | t - 1} - Q _ {t | t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} B _ {t} Q _ {t | t - 1}
$$

The smoothing algorithm described below computes $m _ { s | t } , Q _ { s | t }$ for a fixed $t \geq 0$ and all $s \leq t$ . We shall make use of the following fact that we used previously in the derivation of the Kalman Filter:

Fact 9.1. Suppose $X \sim N ( m _ { 0 } , Q _ { 0 } )$ and $Y \mid X = x \sim N ( B x , R )$ (note that the condition $Y \mid X = x \sim N ( B x , R )$ can also be written as $Y = B X + V$ where $V \sim N ( 0 , R )$ with $V , X$ being independent). Then the following assertions hold:

1. $X \mid Y = y \sim N ( \tilde { m } ( y ) , \tilde { Q } )$ where

$$
\begin{array}{l} \tilde {m} (y) = m _ {0} + Q _ {0} B ^ {\prime} \left(B Q _ {0} B ^ {\prime} + R\right) ^ {- 1} (y - B m _ {0}) \\ \tilde {\text {一}} = Q _ {0} - C _ {0} R ^ {\prime} (R a, R ^ {\prime} - R) ^ {- 1} R a \end{array} \tag {53}
$$

$$
\tilde {Q} = Q _ {0} - Q _ {0} B ^ {\prime} \left(B Q _ {0} B ^ {\prime} + R\right) ^ {- 1} B Q _ {0}
$$

2. $Y \sim N ( B m _ { 0 } , B Q _ { 0 } B ^ { \prime } + R )$

Note that $\tilde { m } ( y )$ depends on $y$ but $\tilde { Q }$ does not depend on $y$ .

Remark 9.1. Fact 9.1 can be reformulated in terms of densities as follows. Let $\phi ( x ; \mu , \Sigma )$ denote the multivariate normal density with mean vector $\mu$ and covariance matrix $\Sigma$ evaluated at x i.e.,

$$
\phi (x; \mu , \Sigma) := (2 \pi \det (\Sigma)) ^ {- 1 / 2} \exp \left(- \frac {1}{2} (x - \mu) ^ {\prime} \Sigma^ {- 1} (x - \mu)\right).
$$

The first conclusion $X \mid Y = y \sim N ( \tilde { m } ( y ) , \tilde { Q } )$ of Fact 9.1 is equivalent to the identity

$$
\frac {\phi (x ; m _ {0} , Q _ {0}) \phi (y ; B x , R)}{\int \phi (u ; m _ {0} , Q _ {0}) \phi (y ; B u , R) d u} = \phi (x; \tilde {m} (y), \tilde {Q}) \tag {54}
$$

This is because the left hand side above is simply

$$
\frac {f _ {Y | X = x} (y) f _ {X} (x)}{\int f _ {Y | X = u} (y) f _ {X} (u) d u} = f _ {X | Y = y} (x).
$$

The second conclusion of Fact (9.1) is equivalent to the identity:

$$
\int \phi (y; B x, R) \phi (x; m _ {0}, Q _ {0}) d x = \phi (y; B m _ {0}, B Q _ {0} B ^ {\prime} + R). \tag {55}
$$

This is because the left hand side above is

$$
\int f _ {Y | X = x} (y) f _ {X} (x) d x = f _ {Y} (y).
$$

It should be easy to see that (55) is easily extended to the case where the Bx term on the left hand side is replaced by $B x + c$ for a deterministic vector c:

$$
\int \phi (y; B x + c, R) \phi (x; m _ {0}, Q _ {0}) d x = \phi (y; B m _ {0} + c, B Q _ {0} B ^ {\prime} + R). \tag {56}
$$

Using the identities (54) and (55), we can rewrite the general backward smoothing recursion (48) as follows.

$$
\begin{array}{l} \phi (x _ {s}; m _ {s \mid t}, Q _ {s \mid t}) \\ = f _ {X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) \\ = \int \left[ \frac {f _ {X _ {s} | Y _ {0} = y _ {0} , . . . , Y _ {s} = y _ {s} , \theta} (x _ {s}) f _ {X _ {s + 1} | X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {X _ {s} | Y _ {0} = y _ {0} , . . . , Y _ {s} = y _ {s} , \theta} (u) f _ {X _ {s + 1} | X _ {s} = u , \theta} (x _ {s + 1}) d u} \right] f _ {X _ {s + 1} | Y _ {0} = y _ {0},.., Y _ {t} = y _ {t}, \theta} (x _ {s + 1}) d x _ {s + 1} \\ = \int \left[ \frac {\phi (x _ {s} ; m _ {s | s} , Q _ {s | s}) \phi (x _ {s + 1} ; A _ {s + 1} x _ {s} , \Sigma_ {s + 1})}{\int \phi (u ; m _ {s | s} , Q _ {s | s}) \phi (x _ {s + 1} ; A _ {s + 1} u , \Sigma_ {s + 1}) d u} \right] \phi (x _ {s + 1}; m _ {s + 1 | t}, Q _ {s + 1 | t}) d x _ {s + 1} \\ \end{array}
$$

Applying (54) with $m _ { 0 } = m _ { s | s }$ , $Q _ { 0 } = Q _ { s | s }$ , $B = A _ { s + 1 }$ and $R = \Sigma _ { s + 1 }$ , we deduce that the term inside the square brackets above equals

$$
\frac {\phi \left(x _ {s} ; m _ {s \mid s} , Q _ {s \mid s}\right) \phi \left(x _ {s + 1} ; A _ {s + 1} x _ {s} , \Sigma_ {s + 1}\right)}{\int \phi \left(u ; m _ {s \mid s} , Q _ {s \mid s}\right) \phi \left(x _ {s + 1} ; A _ {s + 1} u , \Sigma_ {s + 1}\right) d u} = \phi \left(x _ {s}; \tilde {m} \left(x _ {s + 1}\right), \tilde {Q}\right) \tag {57}
$$

where

$$
\tilde {m} (x _ {s + 1}) = m _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} \left(x _ {s + 1} - A _ {s + 1} m _ {s | s}\right)
$$

$$
\tilde {Q} = Q _ {s | s} - Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s}
$$

As a result

$$
\phi \left(x _ {s}; m _ {s \mid t}, Q _ {s \mid t}\right) = \int \phi \left(x _ {s}; \tilde {m} \left(x _ {s + 1}\right), \tilde {Q}\right) \phi \left(x _ {s + 1}; m _ {s + 1 \mid t}, Q _ {s + 1 \mid t}\right) d x _ {s + 1} \tag {58}
$$

We now apply (56). Note that $\tilde { m } ( x _ { s + 1 } )$ is a linear function of $x _ { s + 1 }$ and it can be written as $B x _ { s + 1 } + c$ with

$$
B := Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1}
$$

and

$$
c := m _ {s | s} - Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} m _ {s | s}.
$$

The identity (56) therefore gives that the integral on the right hand side of (58) equals the multivariate normal density with mean $B m _ { 0 } + c$ and covariance $B Q _ { 0 } B ^ { \prime } + R$ evaluated at $x _ { s }$ (here $m = m _ { s + 1 | t }$ , $Q _ { 0 } = Q _ { s + 1 | t }$ and $R = \tilde { Q }$ ). Because the left hand side of (58) is the multivariate normal density with mean $m _ { s \mid t }$ and $Q _ { s \mid t }$ , we deduce the equations

$$
m _ {s | t} = m _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} \left(m _ {s + 1 | t} - A _ {s + 1} m _ {s | s}\right)
$$

and

$$
\begin{array}{l} Q _ {s | t} \\ = B Q _ {0} B ^ {\prime} + R \\ = Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} Q _ {s + 1 | t} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s} \\ + Q _ {s \mid s} - Q _ {s \mid s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s \mid s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s \mid s} \\ = Q _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} Q _ {s + 1 | t} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s} \\ - Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s} \\ = Q _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} Q _ {s + 1 | t} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s} \\ - Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s} \\ = Q _ {s | s} + \\ \end{array}
$$

$$
Q _ {s | s} A _ {s + 1} ^ {\prime} \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} \left(Q _ {s + 1 | t} - A _ {s + 1} Q _ {s | s} A _ {s + 1} - \Sigma_ {s + 1}\right) \left(A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}\right) ^ {- 1} A _ {s + 1} Q _ {s | s}
$$

We shall now write these equations concisely by using the following notation. Recall that from the one-step ahead prediction updates (51), we have

$$
m _ {s + 1 | s} = A _ {s + 1} m _ {s | s} \quad \mathrm {a n d} \quad Q _ {s + 1 | s} = A _ {s + 1} Q _ {s | s} A _ {s + 1} ^ {\prime} + \Sigma_ {s + 1}.
$$

Replacing the terms $A _ { s + 1 } m _ { s | s }$ and $Q _ { s + 1 | s } = A _ { s + 1 } Q _ { s | s } A _ { s + 1 } ^ { \prime } + \Sigma _ { s + 1 }$ by $m _ { s + 1 | s }$ and $Q _ { s + 1 | s }$ in the smoothing recursion equations, we get

$$
m _ {s | t} = m _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} Q _ {s + 1 | s} ^ {- 1} \left(m _ {s + 1 | t} - m _ {s + 1 | s}\right)
$$

$$
Q _ {s | t} = Q _ {s | s} + Q _ {s | s} A _ {s + 1} ^ {\prime} Q _ {s + 1 | s} ^ {- 1} \left(Q _ {s + 1 | t} - Q _ {s + 1 | s}\right) Q _ {s + 1 | s} ^ {- 1} A _ {s + 1} Q _ {s | s}
$$

Finally using the notation

$$
\Gamma_ {s + 1} := Q _ {s | s} A _ {s + 1} ^ {\prime} Q _ {s + 1 | s} ^ {- 1},
$$

we get

$$
m _ {s \mid t} = m _ {s \mid s} + \Gamma_ {s + 1} \left(m _ {s + 1 \mid t} - m _ {s + 1 \mid s}\right)
$$

$$
Q _ {s | t} = Q _ {s | s} + \Gamma_ {s + 1} \left(Q _ {s + 1 | t} - Q _ {s + 1 | s}\right) \Gamma_ {s + 1} ^ {\prime}
$$

These are the Kalman Smoothing equations; alternatively known as the Rauch-Tung-Striebel equations. They allow the calculation of $m _ { s | t } , Q _ { s | t }$ from knowledge of $m _ { s + 1 | t } , Q _ { s + 1 | t }$ as well as from $m _ { s | s } , Q _ { s | s } , m _ { s + 1 | s } , Q _ { s + 1 | s }$ (these four quantities are obtained by running the Kalman filter). One runs these smoothing equations starting from $s = t - 1$ and decreasing $s$ all the way to zero.

# 9.4 Dealing with missing data in the context of state space models

Consider a time series dataset $y _ { 0 } , y _ { 1 } , \dotsc , y _ { T }$ where observations corresponding to certain time points may be missing. More precisely, the data might look like $y _ { 0 } , y _ { 1 } , y _ { 2 }$ , miss, $y _ { 4 } , y _ { 5 } , y _ { 6 }$ , miss, $y _ { 8 } , \ldots .$ How does one analyze this dataset? In the context of state space models, this is quite straightforward. As usual, we use a state space model with a hidden Markov process $\{ X _ { t } \}$ and then connect it to the observation random variables $Y _ { 0 } , Y _ { 1 } , \ldots$ In contrast to the fully observed setup, we now assume that each $Y _ { t }$ takes an additional value “miss” which means that we should also model:

$$
\mathbb {P} \left\{Y _ {t} = \mathrm {m i s s} \mid X _ {t} = x \right\}.
$$

Modeling this probability requires us to know the missing mechanism which is quite difficult in general. A simplistic assumption is that

$$
\mathbb {P} \left\{Y _ {t} = \text {m i s s} \mid X _ {t} = x \right\} \text {d o e s n o t d e p e n d o n} x. \tag {59}
$$

This is can be viewed as a “missing at random” assumption. Under this assumption, analysis is quite straightforward and the Kalman filter and smoother for the model with missing observations are obtained by a simple modification of the model without missing observations. For example, here is how to run the Kalman filter in the presence of missing observations and the missing at random assumption (59). The Kalman filter tells us about the step:

$$
X _ {t - 1} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta \quad \mathrm {t o} \quad X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta
$$

which is the one-step ahead prediction update and then about the

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta \quad \text {a n d} \quad X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, Y _ {t} = y _ {t}, \theta \tag {60}
$$

which is the filter update. When $y _ { t }$ is observed, both these steps are carried out as usual. However when $y _ { t }$ is missing, then there is nothing to do in the filter update so we just take the two conditional distributions in (60) to be the same (observe that the missing at random assumption is crucial here). The smoothing procedure is the same as in the fully observed case. We shall look at specific examples in the next class.

# 9.5 Recommended Reading for Today

1. The general smoothing approach described in Section 9.2 can be found in:

a) Section 6.2.1 of the Kitagawa-Gersch book (in particular, see Equation (6.7))

b) Section 14.2 of the Kitagawa book.   
c) Section 2.7.4 of the Petris-Petrone-Campagnoli book   
d) Section 8.1 of the S¨arkk¨a book

2. The Kalman/Rauch-Tung-Striebel smoothing equations are described in all the books listed in the course outline:

a) Section 5.2 of the Kitagawa-Gersch book (in particular, see equation (5.6)   
b) Section 9.3 of the Kitagawa book   
c) Section 4.4 of the Durbin-Koopman book   
d) Section 8.2 of the S¨arkk¨a book   
e) Proposition 2.4 of the Petris-Petrone-Campagnoli book   
f) Theorem 3.4 of the Triantafyllopoulos book

Section 7.2 of the Chopin-Papaspiliopoulos book also discusses the Kalman smoothing equations. They however derive the algorithm from a general Feynman-Kac formalism (see their Chapter 5). I will discuss the Feynman-Kac stuff in class a few weeks later.

3. For missing data:

a) See Section 2.7 of the Durbin-Koopman book for a treatment of missing observations for the local level model and Section 4.10 of the Durbin-Koopman book for a more general treatment of missing observations for linear Gaussian state space models.   
b) See Section 9.7 of the Kitagawa book.   
c) Section 2.7.3 of the Petris-Petrone-Campagnoli book for filtering with missing observations (also see page 62 of Petris-Petrone-Campagnoli where it is argued that no changes to the smoothing step is necessary for dealing with missing observations).

# 10 Lecture Ten

# 10.1 Summary: General Filtering and Smoothing

Let us use the following simpler notation. Let $f _ { s | t } ( x _ { s } )$ denote the conditional density of $X _ { s }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta$ evaluated at the point $x _ { s }$ .

Filtering recursions for general state space models are (see Lecture Six) the following. The one-step ahead prediction update is

$$
f _ {t \mid t - 1} (x _ {t}) = \int f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) f _ {t - 1 \mid t - 1} (x _ {t - 1}) d x _ {t - 1}, \tag {61}
$$

and the filter update is

$$
f _ {t \mid t} (x _ {t}) \propto f _ {Y _ {t} \mid X _ {t} = x _ {t}, \theta} (y _ {t}) f _ {t \mid t - 1} (x _ {t}). \tag {62}
$$

The backward smoothing recursion for general state space models is (see Lecture Nine):

$$
f _ {s \mid t} (x _ {s}) = \int \left[ \frac {f _ {s \mid s} (x _ {s}) f _ {X _ {s + 1} \mid X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {s \mid s} (u) f _ {X _ {s + 1} \mid X _ {s} = u , \theta} (x _ {s + 1}) d u} \right] f _ {s + 1 \mid t} (x _ {s + 1}) d x _ {s + 1} \tag {63}
$$

This can be rewritten in the following way. Note first that the denominator (inside the square brackets) equals:

$$
\begin{array}{l} \int f _ {s | s} (u) f _ {X _ {s + 1} | X _ {s} = u, \theta} (x _ {s + 1}) d u \\ = \int f _ {X _ {s} | Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (u) f _ {X _ {s + 1} | X _ {s} = u, \theta} (x _ {s + 1}) d u \\ = \int f _ {X _ {s} | Y _ {0} = y _ {0}, \ldots , Y _ {s} = y _ {s}, \theta} (u) f _ {X _ {s + 1} | X _ {s} = u, Y _ {0} = y _ {0}, \ldots , Y _ {s} = y _ {s}, \theta} (x _ {s + 1}) d u \\ = f _ {X _ {s + 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s + 1}) = f _ {s + 1 \mid s} (x _ {s + 1}) \\ \end{array}
$$

Thus (63) becomes

$$
f _ {s | t} (x _ {s}) = \int \frac {f _ {s | s} (x _ {s}) f _ {X _ {s + 1} | X _ {s} , \theta} (x _ {s + 1})}{f _ {s + 1 | s} (x _ {s + 1})} f _ {s + 1 | t} (x _ {s + 1}) d x _ {s + 1}.
$$

Note also that the $f _ { s | s } ( x _ { s } )$ term on the right hand side can be pulled out of the integral (as it does not depend on $x _ { s + 1 }$ which is the variable of integration). Thus the smoothing recursion becomes:

$$
f _ {s \mid t} \left(x _ {s}\right) = f _ {s \mid s} \left(x _ {s}\right) \int \frac {f _ {X _ {s + 1} \mid X _ {s} , \theta} \left(x _ {s + 1}\right) f _ {s + 1 \mid t} \left(x _ {s + 1}\right)}{f _ {s + 1 \mid s} \left(x _ {s + 1}\right)} d x _ {s + 1}. \tag {64}
$$

# 10.2 Summary: Kalman Filtering and Smoothing

The general filtering and smoothing recursions can be computed in closed form for the case of the linear Gaussian state space model:

$$
X _ {0} \sim N (\mu_ {0}, \Gamma_ {0})
$$

$$
X _ {t} = A _ {t} X _ {t - 1} + U _ {t}
$$

$$
Y _ {t} = B _ {t} X _ {t} + V _ {t}
$$

with $X _ { 0 } , U _ { 1 } , \dots , V _ { 0 } , V _ { 1 } , \dots .$ independent and $U _ { t } \sim N ( 0 , \Sigma _ { t } )$ and $V _ { t } \sim N ( 0 , R _ { t } )$ . Here every density $f _ { s \mid t }$ is normal and we shall write $m _ { s \mid t }$ and $Q _ { s \mid t }$ for the mean and covariance corresponding to the (possibly multivariate) normal density $f _ { s \mid t }$ . The one-step ahead prediction update (61) becomes

$$
m _ {t \mid t - 1} = A _ {t} m _ {t - 1 \mid t - 1} \quad \text {a n d} \quad Q _ {t \mid t - 1} = A _ {t} Q _ {t - 1 \mid t - 1} A _ {t} ^ {\prime} + \Sigma_ {t}
$$

The filter update (62) becomes

$$
m _ {t | t} = m _ {t | t - 1} + Q _ {t | t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} \left(y _ {t} - B _ {t} m _ {t | t - 1}\right)
$$

$$
Q _ {t | t} = Q _ {t | t - 1} - Q _ {t | t - 1} B _ {t} ^ {\prime} \left(B _ {t} Q _ {t | t - 1} B _ {t} ^ {\prime} + R _ {t}\right) ^ {- 1} B _ {t} Q _ {t | t - 1}
$$

Finally the smoothing backward recursion (63) becomes

$$
m _ {s \mid t} = m _ {s \mid s} + \Gamma_ {s + 1} \left(m _ {s + 1 \mid t} - m _ {s + 1 \mid s}\right)
$$

$$
Q _ {s | t} = Q _ {s | s} + \Gamma_ {s + 1} \left(Q _ {s + 1 | t} - Q _ {s + 1 | s}\right) \Gamma_ {s + 1} ^ {\prime}
$$

where

$$
\Gamma_ {s + 1} := Q _ {s | s} A _ {s + 1} ^ {\prime} Q _ {s + 1 | s} ^ {- 1}.
$$

# 10.3 Special Case: Local Level Model

Let us specialize the Kalman filtering and smoothing recursions for the special case of the local level model:

$$
X _ {0} \sim N (0, C)
$$

$$
X _ {t} = X _ {t - 1} + Z _ {t} \qquad \mathrm {w i t h} U _ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {Z} ^ {2})
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2})
$$

We have already seen that the Kalman filter for the local level model is:

$$
m _ {t | t - 1} = m _ {t - 1 | t - 1} \quad \mathrm {a n d} \quad Q _ {t | t - 1} = Q _ {t - 1 | t - 1} + \sigma_ {Z} ^ {2}
$$

and

$$
m _ {t | t} = \frac {\sigma_ {\epsilon} ^ {2}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} m _ {t | t - 1} + \frac {Q _ {t | t - 1}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}} y _ {t} \quad \mathrm {a n d} \quad Q _ {t | t} = \frac {\sigma_ {\epsilon} ^ {2} Q _ {t | t - 1}}{Q _ {t | t - 1} + \sigma_ {\epsilon} ^ {2}}.
$$

The Kalman smoothing equations become (note that $\begin{array} { r } { \Gamma _ { s + 1 } = \frac { Q _ { s | s } } { Q _ { s + 1 | s } } = \frac { Q _ { s | s } } { Q _ { s | s } + \sigma _ { Z } ^ { 2 } } ) } \end{array}$ Qs+1|s Qs|s Qs|s

$$
\begin{array}{l} m _ {s | t} = m _ {s | s} + \frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} \left(m _ {s + 1 | t} - m _ {s + 1 | s}\right) \\ = m _ {s | s} + \frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} \left(m _ {s + 1 | t} - m _ {s | s}\right) = \frac {\sigma_ {Z} ^ {2}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} m _ {s | s} + \frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} m _ {s + 1 | t}, \\ \end{array}
$$

and

$$
\begin{array}{l} Q _ {s | t} = Q _ {s | s} + \left(\frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}}\right) ^ {2} \left(Q _ {s + 1 | t} - Q _ {s + 1 | s}\right) \\ = Q _ {s | s} + \left(\frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}}\right) ^ {2} \left(Q _ {s + 1 | t} - Q _ {s | s} - \sigma_ {Z} ^ {2}\right) \\ = Q _ {s | s} - \frac {Q _ {s | s} ^ {2}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} + \left(\frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}}\right) ^ {2} Q _ {s + 1 | t} = \frac {Q _ {s | s} \sigma_ {Z} ^ {2}}{Q _ {s | s} + \sigma_ {Z} ^ {2}} + \left(\frac {Q _ {s | s}}{Q _ {s | s} + \sigma_ {Z} ^ {2}}\right) ^ {2} Q _ {s + 1 | t}. \\ \end{array}
$$

This local level model is useful for estimating smooth trends in time series. However it does not work well for estimating nonsmooth trends such as piecewise constant trend functions. For piecewise constant trend functions, using certain non-Gaussian distributions for the evolution errors $\{ Z _ { t } \}$ works well. For example, one can use

$$
Z _ {t} \stackrel {\text {i . i . d}} {\sim} C \left(0, \sigma_ {Z} ^ {2}\right) \tag {65}
$$

or

$$
Z _ {t} \stackrel {\text {i . i . d}} {\sim} \alpha N (0, \text {s m a l l}) + (1 - \alpha) N \left(0, \sigma_ {2} ^ {2}\right). \tag {66}
$$

In (65), $C ( 0 , \sigma _ { Z } ^ { 2 } )$ denotes the Cauchy density centered at 0 with scale parameter $\sigma _ { Z }$ :

$$
z \mapsto \frac {\sigma_ {Z}}{\pi (z ^ {2} + \sigma_ {Z} ^ {2})}.
$$

(66) is a mixture density with two components: the first component is a normal density centered at zero with small variance and the second component is a normal density centered at zero with variance $\sigma _ { 2 } ^ { 2 }$ . For fitting piecewise constant trend functions, we would take $\alpha$ t o be close to 1.

When the density of $Z _ { t }$ is not normal (as when it is of the form (65) or (66)), the overall model is not “linear Gaussian” so that Kalman filtering and smoothing are not applicable. We will study two ways of solving the filtering and smoothing problems in such models. The first approach is to numerically evaluate the general recursions of Section 10.1 by discretization. This method is described in the next section. The second approach is to use Monte Carlo approximation and we shall discuss this later (this approach is known as “Sequential Monte Carlo” and is the main focus of the Chopin-Papaspiliopoulos book for example).

# 10.4 Numerical Evaluation of $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$

This method works for arbitrary state space models. It is also conceptually simpler (compared to the Kalman recursions) but it is computationally quite intensive because we need to recursively compute entire densities (as opposed to just means and covariances as in the Kalman recursions).

We shall discretize space by placing a dense grid $x ^ { ( g ) } , g \in G$ covering the range of $X _ { t }$ . We shall use the same grid for each $X _ { t }$ for simplicity although in principle different grids may be used for different values of $t$ . We shall reduce all densities to probability mass functions over $\{ x ^ { ( g ) } , g \in G \}$ . Let $p _ { s | t } ( x ^ { ( g ) } ) , g \in G$ denote the probability mass function that approximates the density $f _ { s | t } ( \cdot )$ i.e.,

$$
p _ {s | t} (x ^ {(g)}) \propto f _ {s | t} (x ^ {(g)})
$$

or, more precisely,

$$
p _ {s | t} (x ^ {(g)}) = \frac {f _ {s | t} (x ^ {(g)})}{\sum_ {g ^ {\prime} \in G} f _ {s | t} (x ^ {(g ^ {\prime})})}.
$$

From knowledge of $p _ { s | t } ( x ^ { ( g ) } ) , g \in G$ , the density $f _ { s \mid t } ( x )$ cannot be determined precisely for all $x$ but it can be approximated well if the grid $G$ is dense. For example, one can use the approximation

$$
f _ {s | t} (x) \propto p _ {s | t} (x ^ {(g)}) \qquad \mathrm {f o r} x ^ {(g)} \mathrm {t h a t i s c l o s e s t t o} x.
$$

We shall discretize the recursions (61), (62) and(63). The discrete equation corresponding to the one-step ahead prediction update (61) is given by

$$
p _ {t | t - 1} (x ^ {(g)}) \propto \sum_ {\tilde {g} \in G} f _ {X _ {t} | X _ {t - 1} = x ^ {(\tilde {g})}} (x ^ {(g)}) p _ {t - 1 | t - 1} (x ^ {\tilde {g}})
$$

The normalization constant can be written explicitly as

$$
p _ {t \mid t - 1} \left(x ^ {(g)}\right) = \frac {\sum_ {\tilde {g} \in G} f _ {X _ {t} \mid X _ {t - 1} = x ^ {(\tilde {g})} , \theta} \left(x ^ {(g)}\right) p _ {t - 1 \mid t - 1} \left(x ^ {\tilde {g}}\right)}{\sum_ {g ^ {\prime}} \sum_ {\tilde {g} \in G} f _ {X _ {t} \mid X _ {t - 1} = x ^ {(\tilde {g})}} \left(x ^ {(g ^ {\prime})}\right) p _ {t - 1 \mid t - 1} \left(x ^ {\tilde {g}}\right)} \tag {67}
$$

The discrete equation corresponding to the filtering update (62) is given by

$$
p _ {t | t} (x ^ {(g)}) \propto f _ {Y _ {t} | X _ {t} = x ^ {(g)}} (y _ {t}) p _ {t | t - 1} (x ^ {(g)})
$$

which becomes the following with proper normalization:

$$
p _ {t \mid t} \left(x ^ {(g)}\right) = \frac {f _ {Y _ {t} \mid X _ {t} = x ^ {(g)}} \left(y _ {t}\right) p _ {t \mid t - 1} \left(x ^ {(g)}\right)}{\sum_ {g ^ {\prime} \in G} f _ {Y _ {t} \mid X _ {t} = x ^ {(g ^ {\prime})}} \left(y _ {t}\right) p _ {t \mid t - 1} \left(x ^ {(g ^ {\prime})}\right)} \tag {68}
$$

Finally the discretized version of the smoothing recursion (63) is

$$
p _ {s \mid t} (x ^ {(g)}) = p _ {s \mid s} (x ^ {(g)}) \sum_ {\tilde {g} \in G} \left(\frac {f _ {X _ {s + 1} \mid X _ {s} = x ^ {(g)} , \theta} (x ^ {(\tilde {g})})}{\sum_ {g ^ {\prime} \in G} f _ {X _ {s + 1} \mid X _ {s} = x ^ {(g)} , \theta} (x ^ {(g ^ {\prime})})}\right) \frac {p _ {s + 1 \mid t} (x ^ {(g)})}{p _ {s + 1 \mid s} (x ^ {(\tilde {g})})} \tag {69}
$$

These three equations (67), (68) and (69) can be implemented to compute $p _ { s | t }$ for all $s \leq t$ . The recursions can be initialized with

$$
p _ {0 | - 1} (x ^ {(g)}) \propto 1 \qquad \mathrm {f o r a l l} g \in G.
$$

This corresponds to a diffuse prior on $X _ { 0 }$ .

These recursions are used, for example, to fit the local level model with evolution errors (65) or (66).

# 10.5 Recommended Reading for Today

1. Kalman smoothing equations for the local level model can be found in Section 2.4 of the Durbin-Koopman book and Example 8.1 of the S¨arkk¨a book   
2. The numerical recursions for filtering and smoothing can be found in Section 6.3 of the Kitagawa-Gersch book and Section 14.3 of the Kitagawa book.   
3. For estimating smooth trend functions with state space models, see Section 8.2 of the Kitagawa-Gersch book or Chapter 11 of the Kitagawa book.   
4. The local level model with Cauchy errors has been used to fit a piecewise constant trend function in Section 14.4 of the Kitagawa book (they actually used the more general Pearson family for the evolution errors). Section 8.4 of the Kitagawa-Gersch book also considers the Pearson family for the evolution errors as well as the normal mixture distribution (66).

# 11 Lecture Eleven

We shall discuss optimization algorithms for maximum likelihood estimation for state space models. We start with a general discussion of optimization algorithms before specializing to the case of state space models.

# 11.1 Basic Optimization Algorithms

The goal is to maximize a function $F ( \theta )$ over $\theta$ . Optimization algorithms are iterative and output a sequence of values $\theta ^ { ( 0 ) } , \theta ^ { ( 1 ) } , \ldots$ which is supposed to converge to a (local) maximizer of $F$ . We shall describe briefly three standard optimization algorithms: Gradient Ascent, Newton’s method and BFGS.

# 11.1.1 Gradient Ascent

Given the current iterate $\theta ^ { ( n ) }$ , consider the first order Taylor expansion of $F$ near $\theta ^ { ( n ) }$ :

$$
F (\theta) \approx F (\theta^ {(n)}) + \left\langle \nabla F (\theta^ {(n)}), \theta - \theta^ {(n)} \right\rangle .
$$

This suggests that $F ( \theta ) \geq F ( \theta ^ { ( n ) } )$ provided

$$
\left\langle \nabla F (\theta^ {(n)}), \theta - \theta^ {(n)} \right\rangle \geq 0
$$

which will be satisfied when

$$
\theta - \theta^ {(n)} = \alpha_ {n} \nabla F (\theta^ {(n)}) \qquad \mathrm {f o r} \alpha \geq 0.
$$

Motivated by this, the gradient ascent update is

$$
\theta^ {(n + 1)} = \theta^ {(n)} + \alpha_ {n} \nabla F (\theta^ {(n)}).
$$

The quantity $\alpha _ { n }$ is called the step-size and the best way to choose it (which guarantees improvement in function values) is to maximize the quantity

$$
F \left(\theta^ {(n)} + \alpha \nabla F (\theta^ {(n)})\right) \qquad \text {o v e r a l l} \alpha \geq 0.
$$

The above one-parameter maximization can be done by a line search.

# 11.1.2 Newton’s Method

Given the current iterate $\theta ^ { ( n ) }$ , consider the second order Taylor expansion of $F$ near $\theta ^ { ( n ) }$ :

$$
F (\theta) \approx F \left(\theta^ {(n)}\right) + \left\langle \nabla F \left(\theta^ {(n)}\right), \theta - \theta^ {(n)} \right\rangle + \frac {1}{2} \left(\theta - \theta^ {(n)}\right) ^ {\prime} H F \left(\theta^ {(n)}\right) \left(\theta - \theta^ {(n)}\right). \tag {70}
$$

The maximizer of the right hand side above can be calculated in closed form as:

$$
\theta - \theta^ {(n)} = \left(- H F (\theta^ {(n)})\right) ^ {- 1} \left(\nabla F (\theta^ {(n)})\right).
$$

This motivates setting

$$
\theta^ {(n + 1)} = \theta^ {(n)} + \alpha_ {n} \left(- H F \left(\theta^ {(n)}\right)\right) ^ {- 1} \left(\nabla F \left(\theta^ {(n)}\right)\right) \tag {71}
$$

where again $\alpha _ { n }$ is chosen to maximize the quantity

$$
F \left(\theta^ {(n)} + \alpha \left(- H F (\theta^ {(n)})\right) ^ {- 1} \left(\nabla F (\theta^ {(n)})\right)\right) \quad \text {o v e r a l l} \alpha \geq 0.
$$

Note that it is important that $- H F ( \theta ^ { ( n ) }$ must be positive semi-definite for the quadratic approximation (70) to have a well-defined maximum (otherwise, its maximum will be $+ \infty$ ).

Newton’s method works very well when initialized reasonably close to the actual maximizer of $F$ . But one needs to calculate the Hessian matrix $H F ( \theta ^ { ( n ) } )$ which may be difficult on impossible in some applications.

# 11.1.3 Quasi-Newton Method: BFGS

Quasi-Newton methods mimic the Newton update (71) without explicitly including Hessian matrices. Instead the idea is to have approximate Hessians and update them at each step. The most popular of these methods is BFGS (Broyden-Fletcher-Goldfarb-Shanno) and this method works as follows. At each step of the procedure, the current estimate of the maximizer $\theta ^ { ( n ) }$ is updated to the next value $\theta ^ { ( n + 1 ) }$ and the current approximate Hessian matrix $H ^ { ( n ) }$ is also updated to the next value $H ^ { ( n + 1 ) }$ . The update $\theta ^ { ( n ) } \to \theta ^ { ( n + 1 ) }$ is exactly the same as (71) with $H F ( \theta ^ { ( n ) } )$ replaced by the current Hessian approximation $H ^ { ( n ) }$ :

$$
\theta^ {(n + 1)} = \theta^ {(n)} + \alpha_ {n} \left(- H ^ {(n)}\right) ^ {- 1} \left(\nabla F \left(\theta^ {(n)}\right)\right) \tag {72}
$$

where, as before, $\alpha _ { n }$ is chosen to maximize the quantity

$$
F \left(\theta^ {(n)} + \alpha \left(- H ^ {(n)}\right) ^ {- 1} \left(\nabla F \left(\theta^ {(n)}\right)\right)\right) \quad \text {o v e r a l l} \alpha \geq 0.
$$

The update for the Hessian is given by (we are assuming that each $- H ^ { ( n ) }$ is symmetric and positive definite)

$$
H ^ {(n + 1)} = H ^ {(n)} + \frac {g g ^ {\prime}}{g ^ {\prime} s} - \frac {H ^ {(n)} s s ^ {\prime} H ^ {(n)}}{s ^ {\prime} H ^ {(n)} s} \tag {73}
$$

where

$$
s := \theta^ {(n + 1)} - \theta^ {(n)} \quad \mathrm {a n d} \quad g := \nabla F (\theta^ {(n + 1)}) - \nabla F (\theta^ {(n)}).
$$

The Hessian update can also be written in terms of $( H ^ { ( n ) } ) ^ { - 1 }$ :

$$
\left(H ^ {(n + 1)}\right) ^ {- 1} = \left(I - \frac {s g ^ {\prime}}{g ^ {\prime} s}\right) \left(H ^ {(n)}\right) ^ {- 1} \left(I - \frac {g s ^ {\prime}}{g ^ {\prime} s}\right) + \frac {s s ^ {\prime}}{g ^ {\prime} s}. \tag {74}
$$

This is useful because the $\theta$ -update (72) is written in terms of the inverse of $H ^ { ( n ) }$ .

Here is some intuition behind the Hessian update (73) (or, equivalently, (74)). It is easy to check that $H ^ { ( n + 1 ) } s = g$ which is same as

$$
H ^ {(n + 1)} \left(\theta^ {(n + 1)} - \theta^ {(n)}\right) = \nabla F (\theta^ {(n + 1)}) - \nabla F (\theta^ {(n)}).
$$

This is a reasonable condition to insist because $H ^ { ( n + 1 ) }$ is supposed to approximate $H F ( \theta ^ { ( n + 1 ) } )$ . Observe that when the dimension equals 1, the equality $H ^ { ( n + 1 ) } s = g$ is the same as

$$
H ^ {(n + 1)} = \frac {F ^ {\prime} (\theta^ {(n + 1)}) - F ^ {\prime} (\theta^ {(n)})}{\theta^ {(n + 1)} - \theta^ {(n)}}.
$$

The matrix $H ^ { ( n + 1 ) }$ defined by (73) is actually the solution to the following optimization problem:

$$
H ^ {(n + 1)} = \operatorname * {a r g m i n} _ {X} \left\{D (X \| H ^ {(n)}): X s = g \text {a n d} X \text {i s p s d} \right\}
$$

where

$$
D (X \| H) := \frac {1}{2} \left[ \operatorname {t r} \left((H ^ {(n)}) ^ {- 1} X\right) - \log \det  \left((H ^ {(n)}) ^ {- 1} X\right) - d \right].
$$

Here $d$ is the dimension of $\theta$ (note that each $H$ is $d { \times } d$ ). The above expression $D ( X \| H )$ is the Kullback-Leibler divergence between the multivariate normal distribution with covariance $X$ and the multivariate normal distribution with covariance $H$ . At a high level, $H ^ { ( n + 1 ) }$ should be understood as the closed matrix to $H ^ { ( n ) }$ (measured in terms of the divergence $D ( \cdot \| H ^ { ( n ) } ) )$ subject to the condition $H ^ { ( n + 1 ) } s \ = \ g$ . It is standard to initialize $H ^ { ( 0 ) }$ with the identity matrix.

Observe that in order to apply the gradient ascent and the BFGS methods, it is necessary to be able to compute the gradients of $F$ . To apply the Newton method, one also needs to compute the Hessian of $F$ .

If you want to learn more about these optimization algorithms, you can read standard books on nonlinear optimization; I can recommend Numerical Optimization by Nocedal and Wright, or the first chapter of Introductory Lectures on Convex Optimization by Nesterov, or Iterative Methods for Optimization by Kelley.

# 11.2 Application to Maximum Likelihood Estimation in State Space Models

We shall apply the optimization algorithms for obtaining maximum likelihood estimates in state space models. The function $F$ in the previous section will now be the log-likelihood function. We have seen that it can be calculated for state space models by filtering (in particular, the Kalman filter can be used for likelihood computation in linear Gaussian state space models). As we saw in the previous section, gradient ascent and BFGS require gradient evaluations. We thus need to calculate the gradient of the log-likelihood function in state space models. One often uses the term score vector or score function for the gradient of the log-likelihood function.

For calculating the score vector in state space models (and more generally in latent variable models), it is convenient to use the Fisher identity which we shall describe next.

# 11.2.1 Fisher Identity for the Score

Consider a general latent variable model which describes the joint density $f _ { Y , X | \theta } ( y , x )$ of two variables $Y , X$ in terms of parameters $\theta$ . Here $Y$ denotes the observed variable (the observed data from $Y$ will be denoted by $y$ ) and $X$ denotes the hidden or latent variable (we will not be observing any specific realizations $x$ corresponding to $X$ ). This setting is quite general and includes the state space model as special case. For state space models, $Y = ( Y _ { 0 } , \dots , Y _ { T } )$ and $X = ( X _ { 0 } , \ldots , X _ { T } )$ .

The likelihood of the observation $y$ is simply equal to the density of $Y$ at $y$ :

$$
f _ {Y | \theta} (y) = \int f _ {Y, X | \theta} (y, x) d x
$$

viewed as a function of the parameters $\theta$ . Generally in latent variable models, $f _ { Y | \theta } ( y )$ is harder to evaluate compared to $f _ { Y , X | \theta } ( y , x )$ . Our goal here is to calculate the score function (gradient of the log-likelihood) at a specific parameter value $\theta ^ { ( 0 ) }$ . More precisely, we want to calculate:

$$
\nabla_ {\theta} \log f _ {Y | \theta} (y) \bigg | _ {\theta = \theta^ {(0)}}
$$

Fisher’s identity provides a formula for the score in terms of $f _ { Y , X \mid \theta }$ :

Fact 11.1 (Fisher’s Identity). For every $\theta ^ { ( 0 ) }$ and $y$ , we have

$$
\left. \nabla_ {\theta} \log f _ {Y \mid \theta} (y) \right| _ {\theta = \theta^ {(0)}} = \nabla_ {\theta} E (\theta , \theta^ {(0)}) \Bigg | _ {\theta = \theta^ {(0)}} \tag {75}
$$

where

$$
E \left(\theta , \theta^ {(0)}\right) := \int \left[ \log f _ {Y, X | \theta} (y, x) \right] f _ {X | Y = y, \theta = \theta^ {(0)}} (x) d x \tag {76}
$$

Proof. Fix $\theta ^ { ( 0 ) }$ and $y$ . Note that for every $x$ ,

$$
f _ {Y | \theta} (y) = \frac {f _ {Y , X | \theta} (y , x)}{f _ {X | Y = y , \theta} (x)}
$$

which can be rewritten as

$$
\log f _ {Y | \theta} (y) = \log f _ {Y, X | \theta} (y, x) - \log f _ {X | Y = y, \theta} (x). \tag {77}
$$

We now integrate both sides of the above equality with respect to the probability density

$$
q (x) := f _ {X \mid Y = y, \theta = \theta^ {(0)}} (x).
$$

Note that the function $x \mapsto q ( x )$ depends on $y$ and $\theta ^ { ( 0 ) }$ but it does not depend on the generic parameter value $\theta$ appearing in (77). Integrating both sides of (77) with respect to $q ( x )$ (note that the left hand side of (77) does not depend on $x$ ), we get

$$
\begin{array}{l} \log f _ {Y \mid \theta} (y) = \int \left[ \log f _ {Y, X \mid \theta} (y, x) \right] q (x) d x - \int \left[ \log f _ {X \mid Y = y, \theta} (x) \right] q (x) d x \\ = E (\theta , \theta^ {(0)}) - \int \left[ \log f _ {X | Y = y, \theta} (x) \right] q (x) d x. \\ \end{array}
$$

We now take the gradient on both sides with respect to $\theta$ and evaluate the gradient at $\theta = \theta ^ { ( 0 ) }$ . This leads to

$$
\nabla_ {\theta} \log f _ {Y | \theta} (y) \bigg | _ {\theta = \theta^ {(0)}} = \nabla_ {\theta} E (\theta , \theta^ {(0)}) \bigg | _ {\theta = \theta^ {(0)}} - \nabla_ {\theta} \int \left[ \log f _ {X | Y = y, \theta} (x) \right] q (x) d x \bigg | _ {\theta = \theta^ {(0)}}.
$$

Thus, to complete the proof of (82), it is enough to show that the last term above equals zero. This is true because

$$
\begin{array}{l} \nabla_ {\theta} \int \left[ \log f _ {X | Y = y, \theta} (x) \right] q (x) d x \bigg | _ {\theta = \theta^ {(0)}} = \int \nabla_ {\theta} \left[ \log f _ {X | Y = y, \theta} (x) \right] \bigg | _ {\theta = \theta^ {(0)}} q (x) d x \\ = \int \frac {\nabla_ {\theta} f _ {X \mid Y = y , \theta} (x) \Big | _ {\theta = \theta^ {(0)}}}{f _ {X \mid Y = y , \theta = \theta^ {(0)}} (x)} q (x) d x \\ = \int \frac {\nabla_ {\theta} f _ {X | Y = y , \theta} (x) \Bigg | _ {\theta = \theta^ {(0)}}}{f _ {X | Y = y , \theta = \theta^ {(0)}} (x)} f _ {X | Y = y, \theta = \theta^ {(0)}} (x) d x \\ = \int \nabla_ {\theta} f _ {X | Y = y, \theta} (x) \Bigg | _ {\theta = \theta^ {(0)}} d x \\ = \nabla_ {\theta} \left[ \int f _ {X | Y = y, \theta} (x) d x \right] \Bigg | _ {\theta = \theta^ {(0)}} \\ = \nabla_ {\theta} [ 1 ] \bigg | _ {\theta = \theta^ {(0)}} = 0. \\ \end{array}
$$

Note that at two places in the above chain of equalities, we interchanged the operations of differentiation (with respect to $\theta$ ) and integration (with respect to $x$ ). □

As we shall see in the next class, the quantity $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ also appears in the EM algorithm. We shall often write it as

$$
E (\theta , \theta^ {(0)}) = \mathbb {E} _ {\theta^ {(0)}} \left[ \log f _ {Y, X | \theta} (y, X) \mid Y = y \right].
$$

The notation on the right hand side needs to be understood correctly. The parameter $\theta$ appearing in $\log f _ { Y , X \mid \theta } ( y , X )$ will remain as $\theta$ (i.e., it will not be replaced by $\theta ^ { ( 0 ) }$ ). $\mathbb { E } _ { \theta ^ { ( 0 ) } }$ represents expectation over $X$ with respect to the density $f _ { X | Y = y , \theta = \theta ^ { ( 0 ) } }$ .

# 11.2.2 $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ for state space models

For state space models,

$$
\begin{array}{l} \log f _ {Y, X | \theta} (y, x) = \log f _ {X _ {0}, \dots , X _ {T}, Y _ {0}, \dots , Y _ {T} | \theta} (x _ {0}, \dots , x _ {T}, y _ {0}, \dots , y _ {T}) \\ = \log f _ {X _ {0} | \theta} (x _ {0}) + \sum_ {t = 1} ^ {T} \log f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) + \sum_ {t = 0} ^ {T} \log f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}). \\ \end{array}
$$

Observe that the right hand side above involves three kinds of quantities: the observed data $y _ { 0 } , \ldots , y _ { T }$ , the parameters $\theta$ and the quantities $x _ { 0 } , \ldots , x _ { T }$ . From here, to obtain $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ , we leave $y _ { 0 } , \dots , y _ { T } , \theta$ unchanged in the right hand side and take the expectation over $x _ { 0 } , \ldots , x _ { T }$ conditional on $y _ { 0 } , \ldots , y _ { T }$ . This conditional expectation depends on parameters and we shall fix the parameters at $\theta ^ { ( 0 ) }$ (as opposed to the $\theta$ that is already appearing on the right hand side). We can thus write

$$
E (\theta , \theta^ {(0)}) = I _ {1} (\theta , \theta^ {(0)}) + I _ {2} (\theta , \theta^ {(0)}) + I _ {3} (\theta , \theta^ {(0)}) \tag {78}
$$

where

$$
\begin{array}{l} I _ {1} (\theta , \theta^ {(0)}) = \int \left[ \log f _ {X _ {0} | \theta} (x _ {0}) \right] f _ {X _ {0} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {0}) d x _ {0} \\ = \mathbb {E} \left[ \log f _ {X _ {0} | \theta} (X _ {0}) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)} \right], \\ \end{array}
$$

and

$$
\begin{array}{l} I _ {2} (\theta , \theta^ {(0)}) = \sum_ {t = 1} ^ {T} \iint \left[ \log f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) \right] f _ {X _ {t}, X _ {t - 1} | Y _ {0} = y _ {0},.. Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {t}, x _ {t - 1}) d x _ {t} d x _ {t - 1} \\ = \sum_ {t = 1} ^ {T} \mathbb {E} \left[ \log f _ {X _ {t} | X _ {t - 1} = X _ {t - 1}, \theta} (X _ {t}) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)} \right], \\ \end{array}
$$

and

$$
\begin{array}{l} I _ {3} (\theta , \theta^ {(0)}) = \sum_ {t = 0} ^ {T} \int \left[ \log f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \right] f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {t}) d x _ {t} \\ = \sum_ {t = 0} ^ {T} \mathbb {E} \left[ \log f _ {Y _ {t} | X _ {t} = X _ {t}, \theta} (y _ {t}) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)} \right]. \\ \end{array}
$$

Note that $I _ { 3 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to the conditional distribution

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}
$$

and $I _ { 1 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to the above conditional distribution for $t = 0$ . These conditional distributions are obtained from the smoothing algorithm. Further $I _ { 2 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to

$$
X _ {t}, X _ {t - 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}
$$

which can also be obtained from the smoothing algorithm (we shall see the reasoning behind this in the next class).

For the linear Gaussian state space models, $I _ { 1 } ( \theta , \theta ^ { ( 0 ) } ) , I _ { 2 } ( \theta , \theta ^ { ( 0 ) } ) , I _ { 3 } ( \theta , \theta ^ { ( 0 ) } )$ can be computed in closed form in terms of the output of the Kalman smoothing algorithm. It is also possible to obtain closed form expressions for the gradient of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ . This is a nice way of computing the score function in linear Gaussian state space models using the Kalman smoother output. We shall see the details in the next class.

# 11.3 Recommended Reading for Today

1. Some references for an in-depth coverage of optimization algorithms are the books Numerical Optimization by Nocedal and Wright, or the first chapter of Introductory Lectures on Convex Optimization by Nesterov, or Iterative Methods for Optimization by Kelley.   
2. For a quick review of optimization algorithms with the goal of applying them to parameter estimation in state space models, see Section 7.3 of the Durbin-Koopman book, Section 14.4 of the Chopin-Papaspiliopoulos book, and Appendix A of the Kitagawa book.   
3. Fisher’s identity can be found in Section 7.3.3 of the Durbin-Koopman book (although they don’t call it the Fisher identity), and Exercise 12.5 of the Chopin-Papaspiliopoulos book, and Equation (12.32) in the S¨arkk¨a book.   
4. For the formula (87), see equations (12.29) and (12.30) of the S¨arkk¨a book.

# 12 Lecture Twelve

# 12.1 Pairwise Smoothing Distributions

In our study of smoothing algorithms, we have focussed on calculating the distribution of $X _ { s } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ for fixed $s \leq t$ . For the score vector calculation (as well in the EM algorithm), we would need to calculate the conditional joint distribution of $X _ { s }$ and $X _ { s + 1 }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta$ . In the general case, this can be done via

$$
\begin{array}{l} f _ {X _ {s}, X _ {s + 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}, x _ {s + 1}) \\ = f _ {X _ {s} \mid X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) f _ {X _ {s + 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) \\ \end{array}
$$

We have seen in Lecture Nine that the first term in the right hand side above equals

$$
\begin{array}{l} f _ {X _ {s} \mid X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}) = f _ {X _ {s} \mid X _ {s + 1} = x _ {s + 1}, Y _ {0} = y _ {0}, \dots , Y _ {s} = y _ {s}, \theta} (x _ {s}) \\ = \frac {f _ {X _ {s} | Y _ {0} = y _ {0} , \ldots , Y _ {s} = y _ {s} , \theta} (x _ {s}) f _ {X _ {s + 1} | X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {X _ {s} | Y _ {0} = y _ {0} , \ldots , Y _ {s} = y _ {s} , \theta} (u) f _ {X _ {s + 1} | X _ {s} = u , \theta} (x _ {s + 1}) d u}. \\ \end{array}
$$

We thus have

$$
\begin{array}{l} f _ {X _ {s}, X _ {s + 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}, x _ {s + 1}) \\ = \left[ \frac {f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (x _ {s}) f _ {X _ {s + 1} | X _ {s} = x _ {s} , \theta} (x _ {s + 1})}{\int f _ {X _ {s} | Y _ {0} = y _ {0} , \dots , Y _ {s} = y _ {s} , \theta} (u) f _ {X _ {s + 1} | X _ {s} = u , \theta} (x _ {s + 1}) d u} \right] f _ {X _ {s + 1} | Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {s}). \\ \end{array}
$$

The above formula expresses the joint smoothing density of $X _ { s } , X _ { s + 1 }$ in terms of the smoothing density of $X _ { s + 1 }$ as well filtering and transition densities.

For linear Gaussian state space models, explicit calculations can be done leading to the formula:

$$
\binom {X _ {s + 1}} {X _ {s}} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \sim N \left(\binom {m _ {s + 1 \mid t}} {m _ {s \mid t}}, \binom {Q _ {s + 1 \mid t}} {\Gamma_ {s + 1} Q _ {s + 1 \mid t}} \begin{array}{c} Q _ {s + 1 \mid t} \Gamma_ {s + 1} ^ {\prime} \\ Q _ {s \mid t} \end{array} \right). \tag {79}
$$

Here, as before, $m _ { s \mid t }$ and $Q _ { s \mid t }$ denote the mean and covariance of $X _ { s } \mid Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } , \theta$ respectively. Also $\Gamma _ { s + 1 }$ equals

$$
\Gamma_ {s + 1} = Q _ {s | s} A _ {s + 1} ^ {\prime} Q _ {s + 1 | s} ^ {- 1}. \tag {80}
$$

Note that $\Gamma _ { s + 1 }$ appears in the Kalman smoother recursions. To prove (79), we only need to verify that

$$
\operatorname {C o v} \left(X _ {s + 1}, X _ {s} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta\right) = Q _ {s + 1 | t} \Gamma_ {s + 1} ^ {\prime}. \tag {81}
$$

This is true because (below data $^ { t }$ stands for $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } = y _ { t }$ )

$$
\begin{array}{l} \operatorname {C o v} \left(X _ {s + 1}, X _ {s} \mid \operatorname {d a t a} _ {t}, \theta\right) = \mathbb {E} \left[ \left(X _ {s + 1} - m _ {s + 1 \mid t}\right) \left(X _ {s} - m _ {s \mid t}\right) ^ {\prime} \mid \operatorname {d a t a} _ {t}, \theta \right] \\ = \mathbb {E} \left[ \left(X _ {s + 1} - m _ {s + 1 | t}\right) \mathbb {E} \left\{\left(X _ {s} - m _ {s | t}\right) ^ {\prime} \mid X _ {s + 1}, \mathrm {d a t a} _ {t}, \theta \right\} \mid \mathrm {d a t a} _ {t}, \theta \right]. \\ \end{array}
$$

We have seen in Lecture Nine that

$$
\mathbb {E} \left(X _ {s} \mid X _ {s + 1}, \mathrm {d a t a} _ {t}\right) = m _ {s | s} + \Gamma_ {s + 1} \left(X _ {s + 1} - m _ {s + 1 | s}\right)
$$

which gives

$$
\begin{array}{l} \mathbb {E} \left\{\left(X _ {s} - m _ {s | t}\right) ^ {\prime} \mid X _ {s + 1}, \mathrm {d a t a} _ {t}, \theta \right\} = \left(m _ {s | s} + \Gamma_ {s + 1} \left(X _ {s + 1} - m _ {s + 1 | s}\right) - m _ {s | t}\right) ^ {\prime} \\ = X _ {s + 1} ^ {\prime} \Gamma_ {s + 1} ^ {\prime} + \text {n o n - r a n d o m} \\ \end{array}
$$

where “non-random” refers to a quantity which is deterministic. Thus

$$
\begin{array}{l} \operatorname {C o v} \left(X _ {s + 1}, X _ {s} \mid \operatorname {d a t a} _ {t}, \theta\right) = \mathbb {E} \left[ \left(X _ {s + 1} - m _ {s + 1 \mid t}\right) \left\{X _ {s + 1} ^ {\prime} \Gamma_ {s + 1} ^ {\prime} + \text {n o n - r a n d o m} \right\} \mid \operatorname {d a t a} _ {t}, \theta \right] \\ = \mathbb {E} \left[ \left(X _ {s + 1} - m _ {s + 1 | t}\right) \left\{\left(X _ {s + 1} - m _ {s + 1 | t}\right) ^ {\prime} \Gamma_ {s + 1} ^ {\prime} + \text {n o n - r a n d o m} \right\} \mid \text {d a t a} _ {t}, \theta \right] \\ = \operatorname {C o v} \left(X _ {s + 1} \mid \operatorname {d a t a} _ {t}, \theta\right) \Gamma_ {s + 1} ^ {\prime} = Q _ {s + 1 | t} \Gamma_ {s + 1} ^ {\prime}. \\ \end{array}
$$

This proves (81) which completes the proof of (79).

# 12.2 Fisher’s Identity (from last time)

In the last class, we looked at the Fisher identity for the score function. The setting is that of a latent variable model that describes the joint density $f _ { Y , X | \theta } ( y , x )$ of two variables $Y , X$ in terms of parameters $\theta$ . $Y$ is the observed variable ( $y$ is the observed data) and $X$ is the hidden or latent variable. Fisher’s identity says that

$$
\nabla_ {\theta} \log f _ {Y | \theta} (y) \bigg | _ {\theta = \theta^ {(0)}} = \nabla_ {\theta} E (\theta , \theta^ {(0)}) \bigg | _ {\theta = \theta^ {(0)}} \tag {82}
$$

where

$$
E \left(\theta , \theta^ {(0)}\right) := \int \left[ \log f _ {Y, X | \theta} (y, x) \right] f _ {X | Y = y, \theta = \theta^ {(0)}} (x) d x \tag {83}
$$

# 12.3 The Score Function for the Local Level Model

Let us illustrate the Fisher identity for calculating the score function in the local level model:

$$
X _ {0} \sim N (\mu_ {0}, \Gamma_ {0})
$$

$$
X _ {t} = X _ {t - 1} + Z _ {t} \qquad \text {w i t h} U _ {t} \stackrel {\text {i . i . d}} {\sim} N (0, \sigma_ {Z} ^ {2})
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \quad \text {w i t h} \epsilon_ {t} \stackrel {\text {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2})
$$

vector at The parameter vector here is $\theta ^ { ( 0 ) } : = ( \sigma _ { Z } ^ { ( 0 ) } , \sigma _ { \epsilon } ^ { ( 0 ) } )$ . The log-likelihood of $\theta : = ( \sigma _ { Z } , \sigma _ { \epsilon } )$ . Let us calculate $Y _ { 0 } , \dots , Y _ { T } , X _ { 0 } , \dots , X _ { T }$ $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ to calculate the score equals

$$
\begin{array}{l} \log f _ {Y, X} (\theta) := - \frac {1}{2} \log (2 \pi \Gamma_ {0}) - \frac {1}{2 \Gamma_ {0}} (x _ {0} - \mu_ {0}) ^ {2} - \frac {T}{2} \log (2 \pi \sigma_ {Z} ^ {2}) - \frac {1}{2 \sigma_ {Z} ^ {2}} \sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2} \\ - \frac {T + 1}{2} \log (2 \pi \sigma_ {\epsilon} ^ {2}) - \frac {1}{2 \sigma_ {\epsilon} ^ {2}} \sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2} \\ \end{array}
$$

Therefore

$$
\begin{array}{l} E (\theta , \theta^ {(0)}) := - \frac {1}{2} \log (2 \pi \Gamma_ {0}) - \frac {1}{2 \Gamma_ {0}} \mathbb {E} \left\{(X _ {0} - \mu_ {0}) ^ {2} \mid \mathrm {d a t a}, \theta^ {(0)} \right\} \\ - \frac {T}{2} \log \left(2 \pi \sigma_ {Z} ^ {2}\right) - \frac {1}{2 \sigma_ {Z} ^ {2}} \mathbb {E} \left\{\sum_ {t = 1} ^ {T} \left(X _ {t} - X _ {t - 1}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \tag {84} \\ - \frac {T + 1}{2} \log (2 \pi \sigma_ {\epsilon} ^ {2}) - \frac {1}{2 \sigma_ {\epsilon} ^ {2}} \mathbb {E} \left\{\sum_ {t = 0} ^ {T} (y _ {t} - X _ {t}) ^ {2} \mid \mathrm {d a t a}, \theta^ {(0)} \right\} \\ \end{array}
$$

where “data” represents $Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ (this is basically data $' L ^ { \prime }$ in the notation of Section 12.1). As a result

$$
\nabla_ {\theta} E \left(\theta , \theta^ {(0)}\right) = \left( \begin{array}{c} - \frac {T}{\sigma_ {Z}} + \frac {1}{\sigma_ {Z} ^ {3}} \mathbb {E} \left\{\sum_ {t = 1} ^ {T} \left(X _ {t} - X _ {t - 1}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \\ - \frac {T + 1}{\sigma_ {\epsilon}} + \frac {1}{\sigma_ {\epsilon} ^ {3}} \mathbb {E} \left\{\sum_ {t = 0} ^ {T} \left(y _ {t} - X _ {t}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \end{array} \right) \tag {85}
$$

The Fisher identity therefore gives

$$
\left. \nabla_ {\theta} \log f _ {Y | \theta} (y) \right| _ {\theta = \theta^ {(0)}} = \left( \begin{array}{c} - \frac {T}{\sigma_ {Z} ^ {(0)}} + \frac {1}{\left(\sigma_ {Z} ^ {(0)}\right) ^ {3}} \mathbb {E} \left\{\sum_ {t = 1} ^ {T} \left(X _ {t} - X _ {t - 1}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \\ - \frac {T + 1}{\sigma_ {\epsilon} ^ {(0)}} + \frac {1}{\left(\sigma_ {\epsilon} ^ {(0)}\right) ^ {3}} \mathbb {E} \left\{\sum_ {t = 0} ^ {T} \left(y _ {t} - X _ {t}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \end{array} \right) \tag {86}
$$

The expectations appearing above can be calculated using the output of the Kalman smoother as shown below. Let $m _ { s | T } ( \theta ^ { ( 0 ) } )$ and $Q _ { s | T } ( \theta ^ { ( 0 ) } )$ denote the output of the Kalman smoother when the parameters are set to $\theta ^ { ( 0 ) }$ . Then

$$
\begin{array}{l} \mathbb {E} \left\{\sum_ {t = 1} ^ {T} (X _ {t} - X _ {t - 1}) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \\ = \sum_ {t = 1} ^ {T} \mathbb {E} \left\{\left(X _ {t} - X _ {t - 1}\right) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \\ = \sum_ {t = 1} ^ {T} \operatorname {v a r} \left\{X _ {t} - X _ {t - 1} \mid \mathrm {d a t a}, \theta^ {(0)} \right\} + \sum_ {t = 1} ^ {T} \left(m _ {t | T} (\theta^ {(0)}) - m _ {t - 1 | T} (\theta^ {(0)})\right) ^ {2} \\ = \sum_ {t = 1} ^ {T} \left[ Q _ {t | T} (\theta^ {(0)}) + Q _ {t - 1 | T} (\theta^ {(0)}) - 2 \mathrm {C o v} (X _ {t}, X _ {t - 1} \mid \mathrm {d a t a}, \theta^ {(0)}) \right] + \sum_ {t = 1} ^ {T} \left(m _ {t | T} (\theta^ {(0)}) - m _ {t - 1 | T} (\theta^ {(0)})\right) ^ {2} \\ = \sum_ {t = 1} ^ {T} \left[ Q _ {t | T} (\theta^ {(0)}) + Q _ {t - 1 | T} (\theta^ {(0)}) - 2 Q _ {t | T} (\theta^ {(0)}) \Gamma_ {t} (\theta^ {(0)}) \right] + \sum_ {t = 1} ^ {T} \left(m _ {t | T} (\theta^ {(0)}) - m _ {t - 1 | T} (\theta^ {(0)})\right) ^ {2} \\ \end{array}
$$

where, in the last equation, we used the formula (81) for $s = t - 1$ . The quantity $\Gamma _ { t } \big ( \theta ^ { ( 0 ) } \big )$ equals (see (80)):

$$
\Gamma_ {t} (\theta^ {(0)}) = \frac {Q _ {t - 1 | t - 1} (\theta^ {(0)})}{Q _ {t | t - 1} (\theta^ {(0)})}
$$

which can be calculated by the Kalman filter output.

Also

$$
\begin{array}{l} \mathbb {E} \left\{\sum_ {t = 0} ^ {T} (y _ {t} - X _ {t}) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} = \sum_ {t = 0} ^ {T} \mathbb {E} \left\{(y _ {t} - X _ {t}) ^ {2} \mid \text {d a t a}, \theta^ {(0)} \right\} \\ = \sum_ {t = 0} ^ {T} \left\{\operatorname {v a r} \left(X _ {t} \mid \text {d a t a}, \theta^ {(0)}\right) + \left(y _ {t} - m _ {t | T} \left(\theta^ {(0)}\right)\right) ^ {2} \right\} \\ = \sum_ {t = 0} ^ {T} \left\{Q _ {t | T} \left(\theta^ {(0)}\right) + \left(y _ {t} - m _ {t | T} \left(\theta^ {(0)}\right)\right) ^ {2} \right\}. \\ \end{array}
$$

Observe that (86) is a closed form expression for the score function (in terms of the Kalman smoother output). Using the expression (86) for the score function, we can use standard optimization methods (such as gradient ascent or BFGS) to obtain the maximum likelihood estimator for $\theta = \left( \sigma _ { Z } , \sigma _ { \epsilon } \right)$ .

# 12.4 The EM Algorithm

The EM algorithm is another method for maximizing the log-likelihood $\log f _ { Y | \theta } ( y )$ over $\theta$ i n latent variable models. It is also an iterative algorithm. The EM update

$$
\theta^ {(n)} \rightarrow \theta^ {(n + 1)}
$$

consists of the following two steps:

1. E-Step: Calculate $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ (this is (83) with $\theta ^ { ( 0 ) }$ replaced by $\theta ^ { ( n ) }$ ).   
2. M-Step: Take $\theta ^ { ( n + 1 ) }$ to be the maximizer of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ over $\theta$ .

Some intuition behind this algorithm will be provided in the next class.

# 12.5 EM for the local level model

For the local level model, the expression for $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ as well as $\nabla _ { \boldsymbol { \theta } } E ( \boldsymbol { \theta } , \boldsymbol { \theta } ^ { ( 0 ) } ) \bigg | _ { \boldsymbol { \theta } = \boldsymbol { \theta } ^ { ( 0 ) } }$ are calculated in Section 12.3 (see (84) and (85)). Using these, we can immediately write down the EM iterate in closed form. Indeed, $\theta ^ { ( n + 1 ) }$ is obtained by maximizing $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ over $\theta$ . Setting the gradient of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ (calculated in (85)) to zero, we can immediately deduce that

$$
\sigma_ {Z} ^ {(n + 1)} = \sqrt {\frac {1}{T} \mathbb {E} \left\{\sum_ {t = 1} ^ {T} (X _ {t} - X _ {t - 1}) ^ {2} \mid \mathrm {d a t a} , \theta^ {(n)} \right\}}
$$

and

$$
\sigma_ {\epsilon} ^ {(n + 1)} = \sqrt {\frac {1}{T + 1} \mathbb {E} \left\{\sum_ {t = 0} ^ {T} (y _ {t} - X _ {t}) ^ {2} \mid \mathrm {d a t a} , \theta^ {(n)} \right\}}.
$$

This is a very easy update (there are no line searches for step size selection) and thus the EM is very popular for state space models.

# 12.6 Calculation of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ for general state space models

For a general state space model,

$$
\begin{array}{l} \log f _ {Y, X \mid \theta} (y, x) = \log f _ {X _ {0}, \dots , X _ {T}, Y _ {0}, \dots , Y _ {T} \mid \theta} (x _ {0}, \dots , x _ {T}, y _ {0}, \dots , y _ {T}) \\ = \log f _ {X _ {0} | \theta} (x _ {0}) + \sum_ {t = 1} ^ {T} \log f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) + \sum_ {t = 0} ^ {T} \log f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}). \\ \end{array}
$$

Observe that the right hand side above involves three kinds of quantities: the observed data $y _ { 0 } , \ldots , y _ { T }$ , the parameters $\theta$ and the quantities $x _ { 0 } , \ldots , x _ { T }$ . From here, to obtain $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ , we leave $y _ { 0 } , \dots , y _ { T } , \theta$ unchanged in the right hand side and take the expectation over $x _ { 0 } , \ldots , x _ { T }$ conditional on $y _ { 0 } , \ldots , y _ { T }$ . This conditional expectation depends on parameters and we shall fix the parameters at $\theta ^ { ( 0 ) }$ (as opposed to the $\theta$ that is already appearing on the right hand side). We can thus write

$$
E (\theta , \theta^ {(0)}) = I _ {1} (\theta , \theta^ {(0)}) + I _ {2} (\theta , \theta^ {(0)}) + I _ {3} (\theta , \theta^ {(0)}) \tag {87}
$$

where

$$
\begin{array}{l} I _ {1} (\theta , \theta^ {(0)}) = \int \left[ \log f _ {X _ {0} | \theta} (x _ {0}) \right] f _ {X _ {0} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {0}) d x _ {0} \\ = \mathbb {E} \left[ \log f _ {X _ {0} | \theta} (X _ {0}) \mid Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T}, \theta^ {(0)} \right], \\ \end{array}
$$

and

$$
\begin{array}{l} I _ {2} (\theta , \theta^ {(0)}) = \sum_ {t = 1} ^ {T} \iint \left[ \log f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) \right] f _ {X _ {t}, X _ {t - 1} | Y _ {0} = y _ {0},.. Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {t}, x _ {t - 1}) d x _ {t} d x _ {t - 1} \\ = \sum_ {t = 1} ^ {T} \mathbb {E} \left[ \log f _ {X _ {t} | X _ {t - 1} = X _ {t - 1}, \theta} (X _ {t}) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)} \right], \\ \end{array}
$$

and

$$
\begin{array}{l} I _ {3} (\theta , \theta^ {(0)}) = \sum_ {t = 0} ^ {T} \int \left[ \log f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \right] f _ {X _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}} (x _ {t}) d x _ {t} \\ = \sum_ {t = 0} ^ {T} \mathbb {E} \left[ \log f _ {Y _ {t} | X _ {t} = X _ {t}, \theta} (y _ {t}) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)} \right]. \\ \end{array}
$$

Note that $I _ { 3 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to the conditional distribution

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta^ {(0)}
$$

and $I _ { 1 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to the above conditional distribution for $t = 0$ . These conditional distributions are obtained from the smoothing algorithm. Further $I _ { 2 } ( \theta , \theta ^ { ( 0 ) } )$ involves expectation with respect to

$$
X _ {t}, X _ {t - 1} \mid Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T}, \theta^ {(0)}
$$

which can be obtained from the pairwise smoothing algorithm of Section 12.1.

For linear Gaussian state space models, $I _ { 1 } ( \theta , \theta ^ { ( 0 ) } ) , I _ { 2 } ( \theta , \theta ^ { ( 0 ) } ) , I _ { 3 } ( \theta , \theta ^ { ( 0 ) } )$ can be computed in closed form in terms of the output of the Kalman smoothing algorithm. The details of this calculation are given in Theorem 12.4 of the S¨arkk¨a book. Often maximization of $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( 0 ) } )$ can also be done in closed form for linear Gaussian state space models (see Theorem 12.5 of the S¨arkk¨a book).

# 12.7 Recommended Reading for Today

1. The pairwise smoothing distributions for the linear Gaussian state space model are described in the proof of Theorem 8.2 of the S¨arkk¨a book.   
2. The EM algorithm is described in Section 12.2.3 of the S¨arkk¨a book, Section 2.4.2 of the Triantafyllopoulos book, and Section 14.1.3 of the Chopin-Papaspiliopoulos book.   
3. The EM algorithm for the local level model is given in Example 14.1 of the Chopin-Papaspiliopoulos book.   
4. More details on the EM algorithm for linear Gaussian state space models are given in Section 12.3.2 of the S¨arkk¨a book.

# 13 Lecture Thirteen

We shall cover the following two topics today:

1. The EM algorithm in the context of the more general MM class of algorithms   
2. The Forward Filtering Backward Sampling algorithm for sampling from the full posterior of all the states $X _ { 0 } , \ldots , X _ { T }$ given the data $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ and $\theta$ .

# 13.1 The MM Algorithm

The EM algorithm is much easier to understand in the context of a more general class of algorithms called MM. Consider the general problem of maximizing a function $F ( \theta )$ over $\theta$ . In this setting, MM stands for Minorize-Maximize (if we are studying the problem of minimizing $F ( \theta )$ as opposed to maximizing, MM would stand for Majorize-Minimize). The MM algorithm for maximizing $F ( \theta )$ over $\theta$ is iterative and the update from $\theta ^ { ( n ) }$ to $\theta ^ { ( n + 1 ) }$ has the following two steps:

1. Construct a function $G ( \theta , \theta ^ { ( n ) } )$ which minorizes $F ( \theta )$ for every $\theta$ and agrees with $F ( \theta )$ at $\theta = \theta ^ { ( n ) }$ . In other words, $G ( \theta , \theta ^ { ( n ) } )$ must satisfy:

$$
G (\theta , \theta^ {(n)}) \leq F (\theta) \text {f o r e v e r y} \theta , \quad \text {a n d} \quad G (\theta^ {(n)}, \theta^ {(n)}) = F (\theta^ {(n)}).
$$

2. Take $\theta ^ { ( n + 1 ) }$ to be the maximizer of $G ( \theta , \theta ^ { ( n ) } )$ over $\theta$ .

The most important fact about the MM algorithm is that the objective function increases (or stays the same) when going from $\theta ^ { ( n ) }$ to $\theta ^ { ( n + 1 ) }$ :

$$
F \left(\theta^ {(n + 1)}\right) \geq F \left(\theta^ {(n)}\right). \tag {88}
$$

This can be easily proved via:

$$
F (\theta^ {(n + 1)}) \geq G (\theta^ {(n + 1)}, \theta^ {(n)}) \geq G (\theta^ {(n)}, \theta^ {(n)}) = F (\theta^ {(n)}).
$$

Note that the first inequality above follows from the fact that $G \big ( \cdot , \theta ^ { ( n ) } \big )$ minorizes $F ( \theta )$ , the second inequality follows because $\theta ^ { ( n + 1 ) }$ maximizes $G \big ( \cdot , \theta ^ { ( n ) } \big )$ and the third inequality follows because $G ( \theta , \theta ^ { ( n ) } )$ matches $F ( \theta )$ at $\theta = \theta ^ { ( n ) }$ .

The property (88) is very desirable for a maximization procedure and it is remarkable that the MM algorithm satisfies it without any explicit line search scheme for choosing step sizes.

Before seeing why the EM algorithm is a special case of the MM algorithm, let us first look at two simple examples.

Example 13.1. Consider the problem of maximizing the function $F ( \theta ) = \cos \theta$ . The MM algorithm can be used for this in the following way. In order to go from $\theta ^ { ( n ) }$ to $\theta ^ { ( n + 1 ) }$ , the first step is to construct $G ( \theta , \theta ^ { ( n ) } )$ for which we argue as follows. For every $\theta$ , we can write

$$
F (\theta) = F (\theta^ {(n)}) + F ^ {\prime} (\theta^ {(n)}) (\theta - \theta^ {(n)}) + \frac {1}{2} F ^ {\prime \prime} (z) (\theta - \theta^ {(n)}) ^ {2}
$$

for some z that lies between $\theta$ and $\theta ^ { ( n ) }$ . Thus

$$
\begin{array}{l} F (\theta) = \cos \theta^ {(n)} - \left(\sin \theta^ {(n)}\right) (\theta - \theta^ {(n)}) - \frac {1}{2} (\cos z) (\theta - \theta^ {(n)}) ^ {2} \\ \geq \cos \theta^ {(n)} - \left(\sin \theta^ {(n)}\right) (\theta - \theta^ {(n)}) - \frac {1}{2} (\theta - \theta^ {(n)}) ^ {2} \\ \end{array}
$$

and thus we take

$$
G (\theta , \theta^ {(n)}) = \cos \theta^ {(n)} - \left(\sin \theta^ {(n)}\right) (\theta - \theta^ {(n)}) - \frac {1}{2} (\theta - \theta^ {(n)}) ^ {2}.
$$

It is easy to see that $G ( \theta ^ { ( n ) } , \theta ^ { ( n ) } ) = F ( \theta ^ { ( n ) } )$ . Thus $G$ satisfies both the requirements of the first step of the MM algorithm. Further as $G ( \theta , \theta ^ { ( n ) } )$ is quadratic in $\theta$ , it is easy to maximize it over $\theta$ to obtain

$$
\theta^ {(n + 1)} = \theta^ {(n)} - \sin \theta^ {(n)}.
$$

It is an exercise to show that this iterative scheme converges to the true maximizer 0 when initialized anywhere in the open interval $( - \pi , \pi )$ .

Example 13.2. Given m real numbers $y _ { 1 } , \ldots , y _ { m }$ , consider the problem of maximizing

$$
F (\theta) := - \sum_ {i = 1} ^ {m} | y _ {i} - \theta |
$$

over $\theta$ . Any solution of this problem can be termed a median of $F$ . The usual algorithms for computing the median involve sorting the data. MM provides another method for median computation that does not require sorting the data. The key to the MM iterate θ(n)  θ(n+1) $\theta ^ { ( n ) } \to \theta ^ { ( n + 1 ) }$ is the construction of $G ( \theta , \theta ^ { ( n ) } )$ . For this, consider the following inequality:

$$
| y _ {i} - \theta | = \frac {| y _ {i} - \theta |}{\sqrt {\left| y _ {i} - \theta^ {(n)} \right|}} \sqrt {\left| y _ {i} - \theta^ {(n)} \right|} \leq \frac {1}{2} \frac {\left(y _ {i} - \theta\right) ^ {2}}{\left| y _ {i} - \theta^ {(n)} \right|} + \frac {1}{2} | y _ {i} - \theta^ {(n)} | \tag {89}
$$

where we used the elementary fact: $\begin{array} { r } { a b \leq \frac { a ^ { 2 } } { 2 } + \frac { b ^ { 2 } } { 2 } } \end{array}$ . We thus take

$$
G (\theta , \theta^ {(n)}) := - \frac {1}{2} \sum_ {i = 1} ^ {n} \frac {(y _ {i} - \theta) ^ {2}}{| y _ {i} - \theta^ {(n)} |} - \frac {1}{2} \sum_ {i = 1} ^ {n} | y _ {i} - \theta^ {(n)} |.
$$

It is easy to check that $G ( \theta , \theta ^ { ( n ) } )$ minorizes $F ( \theta )$ (because of (89)) and that $G ( \theta ^ { ( n ) } , \theta ^ { ( n ) } ) =$ $F ( \theta ^ { ( n ) } )$ . Because $G ( \theta , \theta ^ { ( n ) } )$ is a quadratic function in $\theta$ , it is easy to write down its maximizer (over $\theta$ ) in closed form:

$$
\theta^ {(n + 1)} = \frac {\sum_ {i = 1} ^ {n} w _ {i} ^ {(n)} y _ {i}}{\sum_ {i = 1} ^ {n} w _ {i} ^ {(n)}} \qquad w h e r e w _ {i} ^ {(n)} := \frac {1}{| y _ {i} - \theta^ {(n)} |}.
$$

This algorithm clearly does not involve sorting the data. One problem with this algorithm is that it does not work when $\theta ^ { ( n ) }$ equals $y _ { i }$ for some i (note then that $w _ { i } ^ { ( n ) }$ equals $\boldsymbol { \mathit { 0 } }$ ). It is difficult (probably impossible) to construct a quadratic $G ( \theta , \theta ^ { ( n ) } )$ satisfying our requirements when $\theta ^ { ( n ) }$ equals yi for some $i$ . A practical fix is to change the weights $w ^ { ( n ) }$ slightly by adding a small  to the denominator as: w(ni $\begin{array} { r } { w _ { i } ^ { ( n ) } = \frac { 1 } { | y _ { i } - \theta ^ { ( n ) } | + \epsilon } } \end{array}$ .

It should be clear from the above examples that the most important step for the use of the MM algorithm is the construction of the $G ( \theta , \theta ^ { ( n ) } )$ function. There are some general ideas for this (see the book MM Optimization Algorithms by Kenneth Lange, or chapter 12 in the book Numerical Analysis for Statisticians by Kenneth Lange, or these slides: https://www.stat.berkeley.edu/~aldous/Colloq/lange-talk.pdf).

# 13.2 The EM Algorithm as a special case of MM

The EM algorithm is a special case of MM corresponding to a special choice of $G ( \theta , \theta ^ { ( n ) } )$ in the latent variable model setting. We shall describe this below. Let us first recall the notion of Kullback-Leibler divergence (also known as Relative Entropy).

# 13.2.1 The Kullback-Leibler Divergence

The Kullback-Leibler divergence $D ( p \| q )$ between two densities $p$ and $q$ is defined as

$$
D (p \| q) := \int p (x) \log \frac {p (x)}{q (x)} d x.
$$

The most important property of $D ( p \| q )$ is that it is always nonnegative. This can be proved as a consequence of the elementary inequality:

$$
u \log u \geq u - 1 \quad \text {f o r a l l} u \geq 0.
$$

Because of this inequality:

$$
\begin{array}{l} D (p \| q) = \int p (x) \log {\frac {p (x)}{q (x)}} d x \\ = \int q (x) \left(\frac {p (x)}{q (x)} \log \frac {p (x)}{q (x)}\right) d x \\ \geq \int q (x) \left(\frac {p (x)}{q (x)} - 1\right) d x = \int q (x) d x - \int p (x) d x = 1 - 1 = 0 \\ \end{array}
$$

Another way of proving $D ( p \| q ) \geq 0$ is via the use of the Jensen inequality.

It should also be noted that

$$
D (p \| q) = 0 \text {i f a n d o n l y i f} p = q \tag {90}
$$

This can be argued using the fact that $x \log x = x - 1$ if and only if $x = 1$ .

It is also very important to note that $D ( q \| p )$ and $D ( p \| q )$ are in general not equal.

# 13.2.2 EM and MM

We are now ready to explain the connection between the EM and MM algorithms. Consider the latent variable setting where the goal is to maximize the log-likelihood:

$$
F (\theta) = \log f _ {Y | \theta} (y)
$$

There is a latent variable $X$ and the model is specified via the full density $f _ { Y , X | \theta } ( y , x )$ . It is important to note that the conditional density of $X$ given $Y = y$ depends on the value of $\theta$ . We shall denote this by $f _ { X | Y = y , \theta } ( x )$ .

We shall show below that the EM update for $\theta ^ { ( n ) } \to \theta ^ { ( n + 1 ) }$ is exactly equal to the MM update corresponding to

$$
G (\theta , \theta^ {(n)}) := F (\theta) - D \left(f _ {X | Y = y, \theta^ {(n)}} \| f _ {X | Y = y, \theta}\right) \tag {91}
$$

Because the Kullback-Leibler divergence is always nonnegative, it is clear that ${ \cal G } ( \theta , \theta ^ { ( n ) } ) \leq$ $F ( \theta )$ for every $\theta$ . Further, because of (90), $G ( \theta ^ { ( n ) } , \theta ^ { ( n ) } ) = F ( \theta ^ { ( n ) } )$ . Thus $G$ satisfies the conditions required for the first step of the MM algorithm. Note that we can write $G$ alternately as

$$
\begin{array}{l} G (\theta , \theta^ {(n)}) = F (\theta) - D \left(f _ {X | Y = y, \theta^ {(n)}} \| f _ {X | Y = y, \theta}\right) \\ = \log f _ {Y | \theta} (y) - \int f _ {X | Y = y, \theta^ {(n)}} (x) \log \frac {f _ {X | Y = y , \theta} (x)}{f _ {X | Y = y , \theta^ {(n)}} (x)} d x \\ = \int f _ {X | Y = y, \theta^ {(n)}} (x) \log f _ {Y | \theta} (y) d x - \int f _ {X | Y = y, \theta^ {(n)}} (x) \log \frac {f _ {X | Y = y , \theta} (x)}{f _ {X | Y = y , \theta^ {(n)}} (x)} d x \\ = \int f _ {X | Y = y, \theta^ {(n)}} (x) \log \frac {f _ {Y | \theta} (y) f _ {X | Y = y , \theta} (x)}{f _ {X | Y = y , \theta^ {(n)}} (x)} d x \\ = \int f _ {X | Y = y, \theta^ {(n)}} (x) \log \frac {f _ {Y , X | \theta} (y , x)}{f _ {X | Y = y , \theta^ {(n)}} (x)} d x \\ = \int f _ {X | Y = y, \theta^ {(n)}} (x) \log f _ {Y, X | \theta} (y, x) d x - \int f _ {X | Y = y, \theta^ {(n)}} (x) \log f _ {X | Y = y, \theta^ {(n)} (x)} d x. \\ \end{array}
$$

Recall that the first term on the right hand side above is precisely the function $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ that appears in the Expectation Step of the EM algorithm. We have thus proved that

$$
G (\theta , \theta^ {(n)}) = E (\theta , \theta^ {(n)}) - \int f _ {X | Y = y, \theta^ {(n)}} (x) \log f _ {X | Y = y, \theta^ {(n)} (x)} d x.
$$

The second term above does not depend on $\theta$ . Therefore maximizing $G ( \theta , \theta ^ { ( n ) } )$ over $\theta$ is equivalent to maximizing $E ( { \boldsymbol { \theta } } , { \boldsymbol { \theta } } ^ { ( n ) } )$ over $\theta$ . This shows that the second steps of the MM algorithm (with $G$ defined in (91)) and the EM algorithm are identical, which completes the proof of the claim that MM (with $G$ in (91)) is exactly the EM algorithm. The EM algorithm is therefore a special case of MM.

# 13.3 Full Smoothing Distribution

In our discussion of smoothing, we have so far discussion the computation of the marginal distributions:

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta
$$

for each $t = 0 , \ldots , T$ , as well as the pairwise distributions:

$$
X _ {t}, X _ {t + 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta .
$$

It turns out ideas used for the above calculations can also be used to obtain the full conditional joint density:

$$
X _ {0}, \dots , X _ {T} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta \tag {92}
$$

for all the states given the observations (and $\theta$ ). To see this, first write (below “data” refers to $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ )

$$
f _ {X _ {0}, \ldots , X _ {T} | \mathrm {d a t a}, \theta} (x _ {0}, \ldots , x _ {T}) = f _ {X _ {T} | \mathrm {d a t a}, \theta} (x _ {T}) \prod_ {t = T - 1} ^ {0} f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, \ldots , X _ {T} = x _ {T}, \mathrm {d a t a}, \theta} (x _ {t}).
$$

The Markov property of $\{ X _ { t } \}$ and the conditional independence of $Y _ { t }$ given $X _ { 0 } , \ldots , X _ { T }$ imply

$$
f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, \dots , X _ {T} = x _ {T}, \text {d a t a}, \theta} (x _ {t}) = f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}). \tag {93}
$$

This means that $X _ { s } = x _ { s }$ for $s > t + 1$ and $Y _ { s } = y _ { s }$ for $s > t$ can be dropped from the conditioning. As a result

$$
f _ {X _ {0}, \ldots , X _ {T} | \mathrm {d a t a}, \theta} (x _ {0}, \ldots , x _ {T}) = f _ {X _ {T} | \mathrm {d a t a}, \theta} (x _ {T}) \prod_ {t = T - 1} ^ {0} f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {t}).
$$

By the Bayes rule (note that $f _ { X _ { t + 1 } | X _ { t } = x _ { t } , Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } = y _ { t } , \theta } ( x _ { t + 1 } ) = f _ { X _ { t + 1 } | X _ { t } = x _ { t } , \theta } ( x _ { t + 1 } ) )$ , we obtain

$$
f _ {X _ {0}, \ldots , X _ {T} | \mathrm {d a t a}, \theta} (x _ {0}, \ldots , x _ {T}) = f _ {X _ {T} | \mathrm {d a t a}, \theta} (x _ {T}) \prod_ {t = T - 1} ^ {0} \frac {f _ {X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (x _ {t}) f _ {X _ {t + 1} | X _ {t} = x _ {t} , \theta} (x _ {t + 1})}{\int f _ {X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (u) f _ {X _ {t + 1} | X _ {t} = u , \theta} (x _ {t + 1}) d u}.
$$

This is a formula for the full smoothing joint density in terms of the filtering densities.

For linear Gaussian state space models, the conditional density (93) can be computed in closed form (as we saw in Lecture Nine) as:

$$
\begin{array}{l} X _ {t} \mid X _ {t + 1} = x _ {t + 1}, Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \\ \sim N \left(m _ {t | t} + \Gamma_ {t + 1} \left(x _ {t + 1} - m _ {t + 1 | t}\right), Q _ {t | t} - \Gamma_ {t + 1} Q _ {t + 1 | t} \Gamma_ {t + 1} ^ {\prime}\right) \tag {94} \\ \end{array}
$$

where $\Gamma _ { t + 1 } = Q _ { t \mid t } A _ { t + 1 } ^ { \prime } Q _ { t + 1 \mid t } ^ { - 1 }$ . This gives a closed form expression for the full smoothing joint density.

# 13.4 Forward Filtering Backward SAMPLING

Suppose we want to generate independent samples

$$
X _ {0} ^ {(i)}, \ldots , X _ {T} ^ {(i)}
$$

for $i = 1 , \ldots , N$ from the conditional distribution (92). This can be done using the formulae from the previous section. For linear Gaussian state space models, we use (94) to obtain the following sampling algorithm. Repeat the following steps for each $i = 1 , \ldots , N$ :

1. Generate $X _ { T } ^ { ( i ) }$ from the filtering distribution at time $T$ i.e., we generate $X _ { T } ^ { ( i ) }$ from the ${ \cal N } ( { m _ { T | T } } , Q _ { T | T } )$ distribution.

2. Sequentially for $t = T ^ { \prime } - 1 , \dots , 0$ , generate $X _ { t } ^ { ( i ) }$ from the distribution:

$$
N \left(m _ {t | t} + \Gamma_ {t + 1} \left(X _ {t + 1} ^ {(i)} - m _ {t + 1 | t}\right), Q _ {t | t} - \Gamma_ {t + 1} Q _ {t + 1 | t} \Gamma_ {t + 1} ^ {\prime}\right).
$$

Note that this algorithm requires the quantities $m _ { T | T } , Q _ { T | T } , m _ { t | t } , Q _ { t | t } , m _ { t + 1 | t } , Q _ { t + 1 | t } , \Gamma _ { t + 1 }$ which are all obtained from the Kalman Filter. Thus, one would need to implement the Kalman Filter before running the sampling algorithm. Note however that this sampling algorithm does not use any output of the usual Kalman Smoother algorithm.

For a general state space model, sampling can be done by discretization (we shall see other approaches later). The first step is to setup a dense grid $x ^ { ( g ) } , g \in G$ covering the range of $X _ { t }$ and perform filtering. This will lead to discrete distributions:

$$
p _ {t \mid t} (x ^ {(g)}), g \in G \tag {95}
$$

which approximate the densities $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } = y _ { t } , \theta }$ for each $t = 0 , 1 , \ldots , T$ . Then the sampling algorithm to generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ 0for $i = 1 , \ldots , N$ from the conditional distribution (92) is as follows. Repeat the following steps for each $i = 1 , \ldots , N$ :

1. Generate $X _ { T } ^ { ( i ) }$ from $p _ { T | T } ( x ^ { ( g ) } ) , g \in G$ (this is the discrete filtering approximation at time $T$ ).   
2. Sequentially for $t = T ^ { \prime } - 1 , \dots , 0$ , repeat the following steps:

a) Calculate $w _ { g } : = p _ { t | t } ( x ^ { ( g ) } ) f _ { X _ { t + 1 } | X _ { t } = x ^ { ( g ) } , \theta } ( X _ { t + 1 } ^ { ( i ) } )$ for $g \in G$   
b) Normalize $w _ { g } , g \in G$ calculated above so they sum to one.   
c) Generate $X _ { t } ^ { ( i ) }$ from the discrete distribution which gives probability $w _ { g }$ to the grid point $x ^ { ( g ) }$ for $g \in G$ .

Note again that this algorithm only uses the filtering approximations (95). It is not necessary to calculate smoothing approximations to run this sampling algorithm.

These sampling algorithms for sampling observations from the full conditional distribution of the states given the data (and the parameters $\theta$ ) are known as FFBS (Forward Filtering Backward SAMPLING). They should be contrasted with the previous FFBS (Forward Filtering Backward SMOOTHING) algorithms which computed the smoothing densities (exactly or approximately).

# 13.5 Recommended Reading for Today

1. References for the MM algorithm are the book MM Optimization Algorithms by Kenneth Lange, or chapter 12 in the book Numerical Analysis for Statisticians by Kenneth Lange, or these slides: https://www.stat.berkeley.edu/~aldous/Colloq/lange-talk. pdf.   
2. For the FFBSampling algorithm, see Section 5.7.2 of the Triantafyllopoulos book or Section 4.4.1 of the Petris-Petrone-Campagnoli book,

# 14 Lecture Fourteen

We shall discuss full Bayesian estimation of state space models today. Full Bayesian estimation means that we put a prior on the unknown parameters $\theta$ (as opposed to obtaining point estimates for $\theta$ and ignoring the uncertainty in their estimation). Let us start by considering the local level model.

# 14.1 Local Level Model

We have as usual

$$
X _ {0} \sim N (0, C) \quad X _ {t} = X _ {t - 1} + Z _ {t} \quad Y _ {t} = X _ {t} + \epsilon_ {t}
$$

with $Z _ { t } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma _ { Z } ^ { 2 } )$ and $\epsilon _ { t } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma _ { \epsilon } ^ { 2 } )$ . $O Z$ and $\sigma _ { \epsilon }$ are unknown parameters and $C$ is a large constant. Previously we obtained maximum likelihood estimates for $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ and then went on to obtain smoothing estimates of $X _ { 0 } , \ldots , X _ { T }$ ignoring the uncertainty in estimation of $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ . Now we shall place priors on $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ . Natural priors on scale parameters reflecting ignorance are:

$$
\log \sigma_ {Z}, \log \sigma_ {\epsilon} \stackrel {{\text {i . i . d}}} {{\sim}} \operatorname {U n i f} (- C, C).
$$

The full joint density of $\theta , X _ { 0 } , \ldots , X _ { T } , Y _ { 0 } , \ldots , Y _ { T }$ (here $\theta = \left( \sigma _ { Z } , \sigma _ { \epsilon } \right)$ ) is proportional to

$$
\begin{array}{l} \frac {I \{e ^ {- C} <   \sigma_ {Z} , \sigma_ {\epsilon} <   e ^ {C} \}}{\sigma_ {Z} \sigma_ {\epsilon}} \phi (x _ {0}; 0, C) \prod_ {t = 1} ^ {T} \frac {1}{\sigma_ {Z}} \exp \left(- \frac {(x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) \prod_ {t = 0} ^ {T} \frac {1}{\sigma_ {\epsilon}} \exp \left(- \frac {(y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right) \\ = I \{e ^ {- C} <   \sigma_ {Z}, \sigma_ {\epsilon} <   e ^ {C} \} \phi (x _ {0}; 0, C) \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right) \\ \end{array}
$$

As a result

$$
\begin{array}{l} f _ {\theta , X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta , x _ {0}, \dots , x _ {T}) \\ \propto I \{e ^ {- C} <   \sigma_ {Z}, \sigma_ {\epsilon} <   e ^ {C} \} \phi (x _ {0}; 0, C) \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right). \\ \end{array}
$$

Often the main interest is in the conditional distribution of $X _ { 0 } , \ldots , X _ { T }$ given $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } =$ $y _ { T }$ and we can obtain this by integrating over the $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ . This integration can be done in closed form if we assume that $C$ is large (so that the indicator above can be dropped). We then get

$$
\begin{array}{l} f _ {X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} \left(x _ {0}, \dots , x _ {T}\right) \\ \propto \phi (x _ {0}; 0, C) \left[ \int_ {0} ^ {\infty} \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) d \sigma_ {Z} \right] \left[ \int_ {0} ^ {\infty} \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right) d \sigma_ {\epsilon} \right] \\ \propto \phi (x _ {0}; 0, C) \left[ \sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2} \right] ^ {- T / 2} \left[ \sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2} \right] ^ {- (T + 1) / 2}. \\ \end{array}
$$

where we used

$$
\int_ {0} ^ {\infty} \sigma^ {- m - 1} \exp \left(- \frac {G}{\sigma^ {2}}\right) d \sigma = \frac {\Gamma \left(\frac {m}{2}\right)}{G ^ {m / 2}}.
$$

and ignored the $\Gamma ( m / 2 )$ terms in proportionality.

The posterior density:

$$
\begin{array}{l} f _ {X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} \left(x _ {0}, \dots , x _ {T}\right) \\ \propto \phi \left(x _ {0}; 0, C\right) \left[ \sum_ {t = 1} ^ {T} \left(x _ {t} - x _ {t - 1}\right) ^ {2} \right] ^ {- T / 2} \left[ \sum_ {t = 0} ^ {T} \left(y _ {t} - x _ {t}\right) ^ {2} \right] ^ {- (T + 1) / 2} \tag {96} \\ \end{array}
$$

can, in principle, be used for all inference on the hidden variables $X _ { 0 } , \ldots , X _ { T }$ given the observed data. The problem is that it does not correspond to any state space model so it is not clear how to derive from it the marginal posterior densities $X _ { t } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ in an efficient way. In particular, the Kalman smoother cannot be implemented as this posterior does not correspond to a state space model. As a result, instead of integrating out $\theta$ from the joint posterior of $\theta , X _ { 0 } , \ldots , X _ { T }$ , the common approach is to obtain samples $\theta ^ { ( i ) } , X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ for $i = 1 , \ldots , N$ from the joint posterior $\theta , X _ { 0 } , \ldots , X _ { T }$ . Then $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ for $i = 1 , \ldots , N$ can be used for posterior inference on the hidden states given the observed data. Also the samples $\theta ^ { ( 1 ) } , \ldots , \theta ^ { ( N ) }$ can be used for posterior inference on the parameters $\theta$ given the observed data.

For generating the posterior samples $\theta ^ { ( i ) } , X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ for $i = 1 , \ldots , N$ , it is convenient to use the Gibbs sampler algorithm.

# 14.2 Gibbs Sampler

Suppose we want to approximate a joint distribution $f _ { A , B }$ over two random variables $A$ and $B$ . The Gibbs sampler algorithm is applicable in situations where the conditional densities $f _ { A | B = b }$ and $f _ { B | A = a }$ are easy to simulate from for each value of $a$ and $b$ . The algorithm is as follows:

1. Start with $a = a ^ { ( 0 ) }$   
2. For each $i = 1 , 2 , \dots , N$ ,

a) Generate $b ^ { ( i ) } \sim f _ { B \mid A = a ^ { ( i - 1 ) } } .$   
b) Generate $a ^ { ( i ) } \sim f _ { A | B = b ^ { ( i ) } }$

When $N$ is large, this method generates samples $( a ^ { ( i ) } , b ^ { ( i ) } )$ for $i = 1 , \ldots , N$ having the property that

$$
\frac {g (a ^ {(1)} , b ^ {(1)}) + \cdots + g (a ^ {(N)} , b ^ {(N)})}{N} \approx \int g (a, b) f _ {A, B} (a, b) d a d b
$$

for many functions $g$ .

# 14.3 Gibbs Sampler for the Local Level Model

The Gibbs sampler for generating samples $\theta ^ { ( i ) } , X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ for $i = 1 , \ldots , N$ from the full posterior distribution

$$
\theta , X _ {0}, \dots , X _ {T} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}
$$

works as follows:

1. Start with $\theta ^ { ( 0 ) } = ( \sigma _ { Z } ^ { ( 0 ) } , \sigma _ { \epsilon } ^ { ( 0 ) } )$ for some initial values $\sigma _ { Z } ^ { ( 0 ) }$ and $\sigma _ { \epsilon } ^ { \left( 0 \right) }$ .

2. For each $i = 1 , \ldots , N$ ,

a) Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ from the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . Because we are conditioning on $\theta = \theta ^ { ( i ) }$ here, these samples are obtained by the FFBSampling algorithm discussed in the last class.   
b) Generate $\theta ^ { ( i ) }$ from the conditional distribution of $\theta$ given $X _ { 0 } ~ = ~ X _ { 0 } ^ { ( i ) } , X _ { 1 } ~ =$ $X _ { 1 } ^ { ( i ) } , \ldots , X _ { T } = X _ { T } ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ . The details for doing this are given below.

For the second step above, we need to be able to simuate from the conditional distribution:

$$
\theta \mid X _ {0} = x _ {0}, \dots , X _ {T} = x _ {T}, Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T},
$$

and this can be done as follows:

$$
\begin{array}{l} f _ {\theta \mid X _ {0} = x _ {0}, \dots , X _ {T} = x _ {T}, Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \\ \propto f _ {\theta , X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta , x _ {0}, \dots , x _ {T}) \\ \propto I \{e ^ {- C} <   \sigma_ {Z}, \sigma_ {\epsilon} <   e ^ {C} \} \phi (x _ {0}; 0, C) \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right) \\ \propto I \{e ^ {- C} <   \sigma_ {Z} <   e ^ {C} \} \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right) I \{e ^ {- C} <   \sigma_ {\epsilon} <   e ^ {C} \} \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right) \\ \end{array}
$$

as calculated previously. Thus, conditional on $X _ { 0 } = x _ { 0 } , \ldots , X _ { T } = x _ { 0 } , Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ , the two parameters $\sigma _ { Z }$ and $\sigma _ { \epsilon }$ are independent with

$$
f _ {\sigma_ {Z} | X _ {0} = x _ {0}, \ldots , X _ {T} = x _ {T}, Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T}} (\sigma_ {Z}) \propto I \{e ^ {- C} <   \sigma_ {Z} <   e ^ {C} \} \sigma_ {Z} ^ {- T - 1} \exp \left(- \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2 \sigma_ {Z} ^ {2}}\right)
$$

and

$$
f _ {\sigma_ {\epsilon} | X _ {0} = x _ {0}, \ldots , X _ {T} = x _ {T}, Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T}} (\sigma_ {\epsilon}) \propto I \{e ^ {- C} <   \sigma_ {\epsilon} <   e ^ {C} \} \sigma_ {\epsilon} ^ {- T - 2} \exp \left(- \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2 \sigma_ {\epsilon} ^ {2}}\right).
$$

By changing the indicators to $I \{ \sigma _ { Z } > 0 \}$ and $I \{ \sigma _ { \epsilon } > 0 \}$ (which is justified when $C$ is large), and using the standard change of variable formula, we obtain

$$
\sigma_ {Z} ^ {- 2} \mid X _ {0} = x _ {0}, \ldots , X _ {T} = x _ {0}, Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T} \sim \mathrm {G a m m a} \left(\frac {T}{2}, \frac {\sum_ {t = 1} ^ {T} (x _ {t} - x _ {t - 1}) ^ {2}}{2}\right),
$$

and

$$
\sigma_ {\epsilon} ^ {- 2} \mid X _ {0} = x _ {0}, \ldots , X _ {T} = x _ {0}, Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T} \sim \mathrm {G a m m a} \left(\frac {T + 1}{2}, \frac {\sum_ {t = 0} ^ {T} (y _ {t} - x _ {t}) ^ {2}}{2}\right).
$$

Thus the second step in the iteration for the Gibbs sampler, we simply generate Gamma random variables $G _ { Z } ^ { ( i ) }$ and $G _ { \epsilon } ^ { \left( i \right) }$ from the above pair of distributions (with $x _ { t } = X _ { t } ^ { ( i ) }$ ) and then transform them as $\sigma _ { Z } ^ { \left( i \right) } : = 1 / \sqrt { G _ { Z } ^ { \left( i \right) } }$ and $\sigma _ { \epsilon } ^ { \left( i \right) } : = 1 / \sqrt { G _ { \epsilon } ^ { \left( i \right) } }$ . Thus implementing the Gibbs

# 14.4 Gibbs sampler for general Linear Gaussian state space models

The Gibbs sampler algorithm for general Linear Gaussian state space models is basically the same as the one we saw in the last section:

1. Start with $\theta ^ { ( 0 ) }$ .   
2. For each $i = 1 , \ldots , N$ ,

a) Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ from the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . Because we are conditioning on $\theta = \theta ^ { ( i ) }$ here, these samples are obtained by the FFBSampling algorithm discussed in the last class.   
b) Generate $\theta ^ { ( i ) }$ from the conditional distribution of $\theta$ given $X _ { 0 } ~ = ~ X _ { 0 } ^ { ( i ) } , X _ { 1 } ~ =$ $X _ { 1 } ^ { ( i ) } , \ldots , X _ { T } = X _ { T } ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ . Unlike the case of the local level model, this step may not always be carried out in closed form. It depends on the specific dependence of the matrices defining the linear Gaussian model on the parameters $\theta$ .

# 14.5 Recommended Reading for Today

1. A general introduction to the Gibbs sampler is in Section 5.7.1 of the Triantafyllopoulos book and in Section 1.6.1 of the Petris-Petrone-Campagnoli book.   
2. The Gibbs sampler for the local level model is given in Section 4.4.3 of the Petris-Petrone-Campagnoli book and Section 5.7.3 of the Triantafyllopoulos book.

# 15 Lecture Fifteen

In the last class, we started discussing Full Bayes estimation of state space models. Full Bayesian estimation means that we put a prior on the unknown parameters $\theta$ (as opposed to obtaining point estimates for $\theta$ and ignoring the uncertainty in their estimation).

In some applications of state space models such as tracking, $\theta$ represents nuisance parameters with the main focus centered on the state variables. In such applications, full Bayesian estimation ensures that uncertainty in estimation of $\theta$ is accounted for in our uncertainty quantification of the state variables. In certain other applications of state space models, the main focus is on $\theta$ (and the state variables can be considered nuisance parameters). This is for example the case for ARMA models (which can be written in state space form). Here uncertainty quantification for $\theta$ is important which is achieved by Full Bayes analysis.

We shall discuss several approaches for Full Bayesian Analysis today. The main starting point is the choice of prior on $\theta$ . We shall generally use noninformative (diffuse) priors such as Unif $( - C , C )$ or $N ( 0 , C )$ (with large $C$ ) for the components of $\theta$ or certain transformations of the components of $\theta$ (such as $\log \sigma _ { Z }$ and $\log \sigma _ { \epsilon }$ for $\theta = \left( \sigma _ { Z } , \sigma _ { \epsilon } \right)$ in the local level model). When the likelihood is peaked around the MLE (which would generally be the case when the number of observations $T$ is large), it actually does not matter much as to what the prior is. Some heuristic justification for this will be provided today.

Here are some of the ways of doing Full Bayesian Analysis of state space models. We are assuming, from now on, that we have fixed a prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ for the unknown parameters $\theta$ .

# 15.1 Approach One: Gibbs Sampling

We looked at Gibbs sampling in the last class. It proceeds according to the following algorithm.

1. Start with initial values $\theta ^ { ( 0 ) }$ .   
2. For each $i = 1 , \ldots , N$ ,

a) Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ from the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i - 1 ) }$ an d $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . Because we are conditioning on a fixed value of $\theta$ here, these samples can be obtained by the FFBSampling algorithm discussed previously.   
b) Generate $\theta ^ { ( i ) }$ from the conditional distribution of $\theta$ given $X _ { 0 } ~ = ~ X _ { 0 } ^ { ( i ) } , X _ { 1 } ~ =$ $X _ { 1 } ^ { ( i ) } , \ldots , X _ { T } = X _ { T } ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ .

The last step of the Gibbs sampling algorithm (which involves generating $\theta ^ { ( i ) }$ from the conditional distribution of $\theta$ given $X _ { 0 } = X _ { 0 } ^ { ( i ) } , X _ { 1 } = X _ { 1 } ^ { ( i ) } , \dots , X _ { T } = X _ { T } ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T } ,$ ) cannot always be carried out in closed form for state space models. In the last class, we saw how this can be done in closed form for the local level model.

The empirical probability measure of the samples $( \theta ^ { ( i ) } , X _ { 0 } ^ { ( i ) } , \dots , X _ { T } ^ { ( i ) } )$ for $i = 1 , \ldots , N$ generated by the Gibbs sampler can be used to approximate the full posterior distribution of $( \theta , X _ { 0 } , \ldots , X _ { T } )$ given the data $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ :

$$
\frac {1}{N} \sum_ {i = 1} ^ {N} \delta_ {\left(\theta^ {(i)}, X _ {0} ^ {(i)}, \dots , X _ {T} ^ {(i)}\right)} \approx f _ {\theta , X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {t}}.
$$

One implication of this is

$$
\int g (\theta , x _ {0}, \dots , x _ {T}) f _ {\theta , X _ {0}, \dots , X _ {T} | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {t}} (\theta , x _ {0}, \dots , x _ {T}) d \theta d x _ {0} \dots d x _ {T} \approx \frac {1}{N} \sum_ {i = 1} ^ {N} g (\theta^ {(i)}, X _ {0} ^ {(i)}, \dots , X _ {T} ^ {(i)}).
$$

for arbitrary functions $g$ . For example, the posterior mean of $\theta$ given $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ is approximated by

$$
\frac {1}{N} \sum_ {i = 0} ^ {N} \theta^ {(i)}.
$$

One thing to note that the samples generated by the Gibbs sampler do not correspond to independent draws from the $( \theta , X _ { 0 } , \ldots , X _ { T } )$ given the data $Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ . Instead, they represent draws from a Markov Chain whose stationary distribution is the full posterior distribution of $( \theta , X _ { 0 } , \ldots , X _ { T } )$ given the data $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . Thus the Gibbs Sampler is an example of a Markov Chain Monte Carlo (MCMC) algorithm.

# 15.2 Approach Two: Direct Sampling

Direct sampling generates independent draws $( \theta ^ { ( i ) } , X _ { 0 } ^ { ( i ) } , \dots , X _ { T } ^ { ( i ) } )$ for $i = 1 , \ldots , N$ via the following algorithm. For each $i = 1 , \ldots , N$ ,

1. Generate $\theta ^ { ( i ) }$ according to the conditional distribution of $\theta$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ .   
2. Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ (i)0 , . . . , X (i)T f rom the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ . Again, because we are conditioning on a fixed value of $\theta$ here, these samples can be obtained by the FFBSampling algorithm.

Notice the very close similarity between the Direct Sampling and the Gibbs Sampling algorithms. The issue with the Direct Sampling algorithm is that the first step is generally difficult and cannot be done in closed form using standard distributions. This is because, in most state space models, the conditional density of $\theta$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ is a somewhat complicated function given implicitly via the Kalman filter. For some simple models however (such as AutoRegressive Models as we shall discuss in the next class), this method can be carried out.

Note again that, unlike the Gibbs sampler, direct sampling generates independent draws from the full posterior.

# 15.3 Approach Three: Posterior Normal Approximation

This can be seen as a modification of the Direct Sampling algorithm where the first step is replaced by sampling from a normal approximation: For each $i = 1 , \ldots , N$ ,

1. Generate $\theta ^ { ( i ) }$ according to a normal approximation to the conditional distribution of $\theta$ given $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T }$ .   
2. Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ (i)0 , . . . , X (i)T f rom the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , . . . , Y _ { T } = y _ { T }$ . This step is the same as in the Direct Sampling algorithm.

Here is one way of obtaining the normal approximation for use in the first step of the above algorithm. Note first that

$$
f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \propto f _ {Y _ {0}, \dots , Y _ {T} | \theta} (y _ {0}, \dots , y _ {T}) f _ {\theta} (\theta)
$$

In the right hand side above, the term $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ is simply the likelihood (which is given by the Kalman filter for linear Gaussian state space models) and the second term $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ is the prior. Note that the likelihood $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ is maximized at the maximum likelihood estimate $\hat { \theta }$ . Now generally in state space models, the likelihood is quite peaked around $\hat { \theta }$ which means that the likelihood is very close to 0 outside of a small region around $\hat { \theta }$ . On the other hand, the prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ is quite flat which means that it can be well-approximated by a constant (such as $f _ { \theta } ( { \widehat { \theta } } )$ ) in the region where the likelihood is significantly different from zero. This leads to the approximation:

$$
f _ {\theta | Y _ {0} = y _ {0}, \ldots , Y _ {T} = y _ {T}} (\theta) \stackrel {\bullet} {\propto} f _ {Y _ {0}, \ldots , Y _ {T} | \theta} (y _ {0}, \ldots , y _ {T}) f _ {\theta} (\hat {\theta}) \propto f _ {Y _ {0}, \ldots , Y _ {T} | \theta} (y _ {0}, \ldots , y _ {T})
$$

where $\ddot { \propto }$ means “proportional to approximately”. In the second relation above, we dropped $f _ { \theta } ( { \widehat { \theta } } )$ as it is a constant. Thus when the prior is flat in the region where the likelihood is significantly different from zero, the posterior of $\theta$ given the data is proportional to the likelihood and does not depend on the exact form of the prior. Writing in terms of the log-likelihood:

$$
\ell (\theta) := \log f _ {Y _ {0}, \dots , Y _ {T} | \theta} (y _ {0}, \dots , y _ {T}),
$$

we get

$$
f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \stackrel {\bullet} {\propto} \exp \left(\ell (\theta)\right).
$$

We now do a second order Taylor expansion of $\ell ( \theta )$ around the MLE $\hat { \theta }$ to get

$$
\begin{array}{l} f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \stackrel {\bullet} {\propto} \exp (\ell (\theta)) \\ \approx \exp \left(\ell (\hat {\theta}) + \left\langle \nabla \ell (\hat {\theta}), \theta - \hat {\theta} \right\rangle + \frac {1}{2} \left(\theta - \hat {\theta}\right) ^ {T} H \ell (\hat {\theta}) \left(\theta - \hat {\theta}\right)\right). \\ \end{array}
$$

Note the following about the three terms appearing on the right hand side above. The first term $\exp ( \ell ( { \hat { \theta } } ) )$ is just a constant and will be ignored in proportionality. The second term equals zero because $\nabla \ell ( { \hat { \theta } } ) = 0$ as $\hat { \theta }$ is a maximizer of $\ell ( \theta )$ (this is, strictly speaking, an assumption because this may not be true if $\hat { \theta }$ is not an interior point in the domain of $\ell ( \theta ) )$ . The Hessian $H \ell ( { \hat { \theta } } )$ is negative semi-definite (i.e., $- H \ell ( \hat { \theta } )$ is positive semi-definite) as $\hat { \theta }$ maximizes $\ell ( \theta )$ (this also may not always be true but this is generally true). We therefore get

$$
f _ {\theta | Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}} (\theta) \stackrel {\bullet} {\propto} \exp \left(- \frac {1}{2} \left(\theta - \hat {\theta}\right) ^ {T} \left(- H \ell (\hat {\theta})\right) \left(\theta - \hat {\theta}\right)\right).
$$

The right hand side above is the multivariate normal density (without the normalizing constant). We thus have

$$
\theta \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T} \stackrel {\bullet} {\sim} N \left(\hat {\theta}, \left(- H \ell (\hat {\theta})\right) ^ {- 1}\right)
$$

where $\gsim$ means “approximately distributed as”. This posterior normal approximation is quite popular. Note that for state space models, the log-likelihood is calculated via the Kalman filter and the Hessian of the log-likelihood can be calculated numerically.

Therefore the sampling algorithm using posterior normal approximation is the following. For each $i = 1 , \ldots , N$ ,

1. Generate $\theta ^ { ( i ) }$ according to the multivariate normal distribution with mean $\hat { \theta }$ and covariance matrix $\left( - H \ell ( \hat { \theta } ) \right) ^ { - 1 }$ . Here $\hat { \theta }$ denotes the MLE and $\ell ( \theta )$ denotes the log-likelihood (which is obtained by filtering).   
2. Generate $X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) }$ from the conditional joint distribution of $X _ { 0 } , \ldots , X _ { T }$ given $\theta = \theta ^ { ( i ) }$ and $Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T }$ .

Note that the prior does not appear in the above algorithm at all which can be considered an attractive feature. The posterior normal approximation does not work in the following two situations:

1. The prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ varies considerably in the region of the likelihood. This is generally not an issue as we usually work with flat priors.   
2. When $\theta$ is far from $\hat { \theta }$ , the second order Taylor expansion of $\ell ( \theta )$ around $\hat { \theta }$ will not give a good approximation of $\ell ( \theta )$ . Now if $\ell ( \theta )$ is already negligible for such values of $\theta$ , this poor approximation will not be a issue. If not, then the normal approximation will not be accurate for the posterior.

# 15.4 Approach Four: Importance Sampling

Importance sampling can be used when direct sampling is infeasible and posterior normal approximation is not accurate. The basic problem is as follows. We are interested in approximating a distribution $P$ with density $p$ . We cannot sample from $P$ directly but we have the ability to obtain independent samples $X _ { 1 } , \ldots , X _ { n }$ from a distribution $Q$ (with density $q$ ). As explained below, importance sampling provides an approximation for $P$ in terms of $X _ { 1 } , \ldots , X _ { n }$ . In the state space model context, $P$ will be $f _ { \theta | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } = y _ { T } } ( \theta )$ and $Q$ will be an approximation (such as the posterior normal approximation).

Importance sampling provides two approximations for $P$ . The first approximation is

$$
\hat {P} _ {1} := \frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})} \delta_ {\{X _ {i} \}}.
$$

By $\delta _ { \{ X _ { i } \} }$ , we mean a point mass at $X _ { i }$ . Basically $\hat { P } _ { 1 }$ is a discrete measure giving the weight ${ \frac { 1 } { n } } { \frac { p ( X _ { i } ) } { q ( X _ { i } ) } }$ to the point $X _ { i }$ . Note that $\hat { P } _ { 1 }$ is not necessarily a probability measure because the weights ${ \frac { 1 } { n } } { \frac { p ( X _ { i } ) } { q ( X _ { i } ) } }$ do not necessarily add to 1. It is a approximation to $P$ in the sense that

$$
\int g (x) d \hat {P} _ {1} (x) = \frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})} g (X _ {i}) \approx \int g (x) d P (x)
$$

for most functions $g$ . This is basically a consequence of the Strong Law of Large Numbers which implies (under a minimal first moment assumption on $_ { g }$ ) that

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})} g (X _ {i}) \rightarrow \int \frac {p (x)}{q (x)} g (x) q (x) d x = \int g (x) d P (x) \quad \mathrm {a l m o s t s u r e l y a s} n \rightarrow \infty . \tag {97}
$$

There are two annoying issues with $\hat { P } _ { 1 }$ :

1. As already mentioned, it is not a probability measure.   
2. To use $\hat { P } _ { 1 }$ , we need to know the density $p ( x )$ fully. In many situations (including in our setting of state space models), we would only know $p ( x )$ upto multiplication by a normalizing constant. This would preclude use of $\hat { P } _ { 1 }$ .

To fix these two issues, importance sampling proposes the following estimator (often known as self-normalized importance sampling):

$$
\hat {P} _ {2} := \sum_ {i = 1} ^ {n} w _ {i} \delta_ {\{X _ {i} \}} \qquad \mathrm {w h e r e} w _ {i} := \frac {\frac {1}{n} \frac {p (X _ {i})}{q (X _ {i})}}{\sum_ {j = 1} ^ {n} \frac {1}{n} \frac {p (X _ {j})}{q (X _ {j})}}
$$

It is clear that $\hat { P } _ { 2 }$ is a probability measure. Also to use $\hat { P } _ { 2 }$ , it is enough to know $p ( x )$ (and also $q ( x )$ ) up to an unknown multiplicative constant. To see why $\hat { P } _ { 2 }$ is a good approximation of $P$ , observe that for a function $g$ :

$$
\int g (x) d \hat {P} _ {2} (x) = \sum_ {i = 1} ^ {n} w _ {i} g (X _ {i}) = \frac {\frac {1}{n} \sum_ {i = 1} ^ {n} g (X _ {i}) \frac {p (X _ {i})}{q (X _ {i})}}{\frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})}}
$$

As we have seen in (97), the numerator above converges to $\begin{array} { r } { \int g ( x ) d P ( x ) } \end{array}$ almost surely as $\textit { n } \to \infty$ . By another application of the law of large numbers, it can be seen that the denominator converges to 1:

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})} \to \int \frac {p (x)}{q (x)} q (x) d x = \int p (x) d x = 1 \mathrm {a l m o s t s u r e l y a s} n \to \infty .
$$

Thus

$$
\int g (x) d \hat {P} _ {2} (x) \rightarrow \int g (x) p (x) d x \qquad {\mathrm {a l m o s t s u r e l y a s}} n \rightarrow \infty .
$$

We can do a more precise comparison of the performance of the two estimators:

$$
E _ {1} := \int g (x) d \hat {P} _ {1} (x) = \frac {1}{n} \sum_ {i = 1} ^ {n} g (X _ {i}) \frac {p (X _ {i})}{q (X _ {i})}
$$

and

$$
E _ {2} := \int g (x) d \hat {P} _ {2} (x) = \frac {\frac {1}{n} \sum_ {i = 1} ^ {n} g (X _ {i}) \frac {p (X _ {i})}{q (X _ {i})}}{\frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})}}
$$

for estimating

$$
\mu := \int g (x) d P (x)
$$

by calculation of variances. Note that these estimators are based on data $X _ { 1 } , \ldots , X _ { n }$ that are independent with common distribution $Q$ . We can also compare these estimators against the simple estimator

$$
E _ {0} := \frac {1}{n} \sum_ {i = 1} ^ {n} g (X _ {i})
$$

based on independent observations $X _ { 1 } , \ldots , X _ { n }$ having distribution $P$ . $E _ { 0 }$ will not be a feasible estimator if we cannot sample from $P$ but we can still use it as a comparison benchmark for the feasible estimators $E _ { 1 }$ and $E _ { 2 }$ . Here are basic observations about these three estimators:

1. Estimator $E _ { 0 }$ : $E _ { 0 }$ is clearly an unbiased estimator of $\mu$ . Its variance is given by

$$
\operatorname {v a r} (E _ {0}) = \frac {1}{n} \operatorname {v a r} _ {P} (g (X _ {1})) = \frac {1}{n} \int (g (x) - \mu) ^ {2} p (x) d x. \tag {98}
$$

The subscript $P$ in $\mathrm { v a r } _ { P }$ refers to $X _ { 1 } \sim P$ . Note also that the mean of $g ( X _ { 1 } )$ under $X _ { 1 } \sim P$ is $\begin{array} { r } { \int g ( x ) p ( x ) d x = \mu } \end{array}$ .

2. Estimator $E _ { 1 }$ : $E _ { 1 }$ is also an unbiased estimator of $\mu$ . Its variance is given by

$$
\mathrm {v a r} (E _ {1}) = \frac {1}{n} \mathrm {v a r} _ {Q} \left(g (X _ {1}) \frac {p (X _ {1})}{q (X _ {1})}\right) = \frac {1}{n} \int \left(g (x) \frac {p (x)}{q (x)} - \mu\right) ^ {2} q (x) d x = \frac {1}{n} \int \frac {[ g (x) p (x) - \mu q (x) ] ^ {2}}{q (x)} d x.
$$

Note that it is possible that $\mathrm { v a r } ( E _ { 1 } )$ is much smaller than $\mathrm { v a r } ( E _ { 0 } )$ . This will be the case, for example, when

$$
q (x) \approx \frac {g (x) p (x)}{\mu} = \frac {g (x) p (x)}{\int g (x) p (x) d x}.
$$

In the extreme case when $q ( x )$ is exactly equal to the right hand side, $E _ { 1 }$ is a perfect estimator of $\mu$ having zero variance. This also suggests that in situations where $g$ is non-zero only in a tiny part of the support of $P$ , the importance sampling estimator $E _ { 1 } ^ { \prime }$ will work much better than the direct sampling estimator $E _ { 0 }$ when $q ( x )$ is concentrated on the specific tiny part of the support of $P$ .

3. Estimator $E _ { 2 }$ : This is not an unbiased estimator. But the numerator $\begin{array} { r } { \frac { 1 } { n } \sum _ { i = 1 } ^ { n } g ( X _ { i } ) \frac { p ( X _ { i } ) } { q ( X _ { i } ) } } \end{array}$ and denominator ${ \frac { 1 } { n } } \sum _ { i = 1 } ^ { n } { \frac { p ( X _ { i } ) } { q ( X _ { i } ) } }$ of $E _ { 2 }$ are very close (by the law of large numbers) to $\mu$ and 1 respectively. So we can approximate $E _ { 2 }$ by a simple first order Taylor expansion as follows. Let $\begin{array} { r } { f ( A , B ) : = \frac { A } { B } } \end{array}$ . For fixed points $A _ { 0 } , B _ { 0 }$ , we have

$$
\begin{array}{l} \frac {A}{B} = f (A, B) \approx f (A _ {0}, B _ {0}) + (A - A _ {0}) \frac {\partial f}{\partial A} \Bigg | _ {A = A _ {0}, B = B _ {0}} + (B - B _ {0}) \frac {\partial f}{\partial B} \Bigg | _ {A = A _ {0}, B = B _ {0}} \\ = \frac {A _ {0}}{B _ {0}} + \frac {A - A _ {0}}{B _ {0}} - \frac {A _ {0} (B - B _ {0})}{B _ {0} ^ {2}}. \\ \end{array}
$$

Using this with

$$
A := \frac {1}{n} \sum_ {i = 1} ^ {n} g (X _ {i}) \frac {p (X _ {i})}{q (X _ {i})} B := \frac {1}{n} \sum_ {i = 1} ^ {n} \frac {p (X _ {i})}{q (X _ {i})} A _ {0} = \mu B _ {0} = 1,
$$

we get

$$
E _ {2} \approx \mu + (A - \mu) - \mu (B - 1) = \mu + A - B \mu = \mu + \frac {1}{n} \sum_ {i = 1} ^ {n} (g (X _ {i}) - \mu) \frac {p (X _ {i})}{q (X _ {i})}.
$$

This implies that $E _ { 2 }$ is approximately unbiased because

$$
\begin{array}{l} \mathbb {E} (E _ {2}) \approx \mu + \mathbb {E} _ {Q} \left[ (g (X _ {1}) - \mu) \frac {p (X _ {1})}{q (X _ {1})} \right] \\ = \mu + \int (g (x) - \mu) \frac {p (x)}{q (x)} q (x) d x \\ = \mu + \int (g (x) - \mu) p (x) d x = \mu + \left(\int g (x) p (x) d x - \mu\right) = \mu . \\ \end{array}
$$

Further the variance of $E _ { 2 }$ is approximately

$$
\operatorname {v a r} \left(E _ {2}\right) \approx \frac {1}{n} \operatorname {v a r} _ {Q} \left(\left(g \left(X _ {1}\right) - \mu\right) \frac {p \left(X _ {1}\right)}{q \left(X _ {1}\right)}\right) = \frac {1}{n} \int \left(g (x) - \mu\right) ^ {2} \frac {p ^ {2} (x)}{q (x)} d x.
$$

This variance is more similar to (98) but it can still be smaller than (98). The best possible variance reduction occurs when

$$
q ^ {*} (x) = \frac {| g (x) - \mu | p (x)}{\int | g (x) - \mu | p (x) d x}
$$

when

$$
\mathrm {v a r} (E _ {2}) \approx \frac {1}{n} \left(\int | g (x) - \mu | p (x) d x\right) ^ {2}
$$

which is definitely smaller than $\mathrm { v a r } ( E _ { 0 } )$ . To see why $q ^ { * }$ minimizes $\mathrm { v a r } ( E _ { 2 } )$ , just note, by Cauchy-Schwarz inequality $\begin{array} { r } { ( \int | a ( x ) b ( x ) | d x \leq \sqrt { \int a ^ { 2 } ( x ) d x } \sqrt { \int b ^ { 2 } ( x ) d x } ) } \end{array}$ that

$$
\begin{array}{l} \int | g (x) - \mu | p (x) d x = \int \frac {| g (x) - \mu | p (x)}{\sqrt {q (x)}} \sqrt {q (x)} d x \\ \leq \sqrt {\int (g (x) - \mu) ^ {2} \frac {p ^ {2} (x)}{q (x)} d x} \sqrt {\int q (x) d x} = \sqrt {\int (g (x) - \mu) ^ {2} \frac {p ^ {2} (x)}{q (x)} d x}. \\ \end{array}
$$

# 15.5 Recommended Reading for Today

1. For the importance sampling approach to full Bayesian analysis, see Chapter 13 of the Durbin-Koopman book.   
2. A standard MCMC method such as Metropolis-Hastings can also be used in step 1 of the Direct Sampling approach. This method is described in Section 12.2.2 of the S¨arkk¨a book or in Section 6.8.1 of the Triantafyllopoulos book.   
3. For a general overview of importance sampling, see Chapter 8 of the Chopin-Papaspiliopoulos book or this book chapter: https://artowen.su.domains/mc/Ch-var-is.pdf.

# 16 Lecture Sixteen

Our next topic is Sequential Monte Carlo methods for general state space models. Here the conditional densities $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } , \theta } ( \cdot )$ and $f _ { Y _ { t } | X _ { t } = x _ { t } , \theta } ( \cdot )$ (as well as the initial density $f _ { X _ { 0 } }$ )

can be arbitrary. We shall first look at the problem of filtering. Recall that filtering can be used for writing down the likelihood (which is necessary for inference of $\theta$ ). Filtering will also be necessary for solving the smoothing problem which we shall study later.

Recall that filtering refers to the problem of determining the conditional distributions:

$$
X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \quad \text {f o r} t = 0, 1, 2, \dots , T.
$$

Our approach will be recursive and we shall determine the above distributions sequentially for $t = 0 , 1 , 2 , \ldots$ . In Lecture Six, we have seen closed form formulae for obtaining the filtering density at time $t$ using the filtering density at time $t - 1$ . This involved two steps which we termed one-step ahead prediction update and filtering update. The one-step ahead prediction update is the following formula for the density of $X _ { t }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ i n terms of the density of $X _ { t - 1 }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ :

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t}) = \int f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t}) f _ {X _ {t - 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t - 1}) d x _ {t - 1}. \tag {99}
$$

The filtering update is the following formula for the density of $X _ { t }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta$ in terms of the density of $X _ { t }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 }$ :

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}) = \frac {f _ {Y _ {t} \mid X _ {t} = x _ {t} , \theta} (y _ {t}) f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t})}{\int f _ {Y _ {t} \mid X _ {t} = u , \theta} (y _ {t}) f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (u) d u} \tag {100}
$$

Formula (100) can be seen as an application of the Bayes rule with the following choices of “prior” and “likelihood”:

$$
\text {p r i o r}: f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta}, \text {a n d l i k e l i h o o d}: f _ {Y _ {t} \mid X _ {t} = x _ {t}, \theta} = f _ {Y _ {t} \mid X _ {t} = x _ {t}, Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} \tag {101}
$$

The “posterior” corresponding to the above prior and likelihood is the density of $X _ { t }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta$ and is obtained by the Bayes rule leading to the formula (100).

For general state space models, the integral involved in (99) cannot be evaluated in closed form. This would make (100) intractable as well (because (100) needs fXt|Y0=y0,...,Yt−1=yt−1,θ $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta }$ as input). One approach for dealing with intractibility is to use Monte Carlo which leads to Sequential Monte Carlo methods for state space models. In Monte Carlo methods, the focus is not on evaluating an unknown density $f$ in closed form, and instead, the focus is on obtaining i.i.d samples $X ^ { ( 1 ) } , \ldots , X ^ { ( N ) }$ from $f$ . Once these samples are obtained, the distribution corresponding to the density $f$ is approximated by the discrete uniform distribution on $X ^ { ( 1 ) } , \ldots , X ^ { ( N ) }$ :

$$
\operatorname {U n i f} \{X ^ {(1)}, \dots , X ^ {(N)} \}. \tag {102}
$$

In order to evaluate the expectation of a function $g$ with respect to the density $f$ , the Monte Carlo approach will give

$$
\int g (x) f (x) d x \approx \frac {1}{N} \sum_ {i = 1} ^ {n} g (X ^ {(i)}).
$$

# 16.1 Notation for Discrete Distributions

We shall use the following notation in the sequel. A discrete distribution that takes the values $\boldsymbol { x } ^ { ( 1 ) } , \ldots , \boldsymbol { x } ^ { ( N ) }$ with probabilities $\boldsymbol { p } ^ { ( 1 ) } , \ldots , \boldsymbol { p } ^ { ( N ) }$ will be denoted by

$$
p ^ {(1)} \delta_ {\{x ^ {(1)} \}} + \dots + p ^ {(N)} \delta_ {\{x ^ {(N)} \}} = \sum_ {i = 1} ^ {n} p ^ {(i)} \delta_ {\{x ^ {(i)} \}}.
$$

For example, the distribution taking the three values $5 , 2 , - 6$ with probabilities 0.3, 0.5, 0.2 respectively will be written as

$$
0. 3 \delta_ {\{5 \}} + 0. 5 \delta_ {\{2 \}} + 0. 2 \delta_ {\{- 6 \}}.
$$

Note that the uniform distribution (102) is written as

$$
\sum_ {i = 1} \frac {1}{N} \delta_ {\{X ^ {(i)} \}}
$$

in this notation.

# 16.2 Monte Carlo versions of (99) and (100)

In terms of Monte Carlo, the basic question underlying filtering is the following:

Question 16.1. Suppose we are given i.i.d samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ from the distribution $X _ { t - 1 } \mid Y _ { 0 } = y _ { 0 } , \dotsc , Y _ { t - 1 } = y _ { t - 1 } , \theta$ (this is the filtering distribution at time $t - 1$ ). How then do we generate i.i.d samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ from the distribution $X _ { t } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ (this is the filtering distribution at time t)?

We shall solve this question by using Monte Carlo versions of (99) and (100). We start with i.i.d samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ from the filtering density $f _ { X _ { t - 1 } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta }$ at time $t - 1$ . For the one-step ahead prediction update, we need to obtain samples from the density of $X _ { t }$ given $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ . This is easily done via:

$$
\tilde {X} _ {t} ^ {(i)} \sim f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

This makes sense because the right hand side of (99) is simply the marginal density of $X _ { t }$ under the model:

$$
X _ {t} \mid X _ {t - 1} = x _ {t - 1} \sim f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}} \quad \mathrm {a n d} \quad X _ {t - 1} \sim f _ {X _ {t - 1} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta}.
$$

Thus $\tilde { X } _ { t } ^ { ( 1 ) } , \ldots , \tilde { X } _ { t } ^ { ( N ) }$ (1)t , . . . , X˜ (N )t a re i.i.d samples from the one-step ahead prediction distrbution $X _ { t }$ $Y _ { 0 } = y _ { 0 } , \dots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ . One can then approximate the one-step ahead prediction distribution by

$$
\left(X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta\right) \approx \operatorname {U n i f} \left\{\tilde {X} _ {t} ^ {(1)}, \dots , \tilde {X} _ {t} ^ {(N)} \right\} = \sum_ {i = 1} ^ {n} \frac {1}{N} \delta_ {\left\{\tilde {X} _ {t} ^ {(i)} \right\}}. \tag {103}
$$

Let us now come to (100). As noted earlier, this equation arises from the Bayes rule with prior and likelihood given in (101). We do not have access to the prior density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta }$ as we have not evaulated (99) in closed form. We do, however, have the Monte Carlo approximation (103) for the one-step ahead prediction distribution so it is natural to approximate (100) by applying Bayes rule with

$$
\mathrm {p r i o r}: \sum_ {i = 1} ^ {n} \frac {1}{N} \delta_ {\{\bar {X} _ {t} ^ {(i)} \}}, \quad \mathrm {a n d} \quad \mathrm {l i k e l i h o o d}: f _ {Y _ {t} | X _ {t} = x _ {t}, \theta}.
$$

The unnormalized posterior corresponding to the prior and likelihood above is given by the weights:

$$
w _ {t} ^ {(i)} := f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t} ^ {(i)}, \theta} (y _ {t}).
$$

The properly normalized posterior is then given by

$$
\sum_ {i = 1} ^ {n} W _ {t} ^ {(i)} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}} \qquad \mathrm {w h e r e} W _ {t} ^ {(i)} := \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}}.
$$

This discrete distribution approximates the filtering distribution at time $t$ :

$$
X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta \approx \sum_ {i = 1} ^ {n} W _ {t} ^ {(i)} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}.
$$

In order to generate i.i.d samples from the filtering distribution at time $t$ , we can simply generate samples from the above discrete distribution:

$$
X _ {t} ^ {(1)}, \ldots , X _ {t} ^ {(N)} \sim \sum_ {i = 1} ^ {n} W _ {t} ^ {(i)} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}.
$$

This algorithm for solving the filtering problem in general state space models using Monte Carlo is called Bootstrap Particle Filter. We stae the algorithm formally in the next section.

# 16.3 The Bootstrap Particle Filter

For each t ≥ 0, this algorithm outputs samples X(1)t , . $t \geq 0$ $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ . such that

$$
\mathrm {U n i f} \left\{X _ {t} ^ {(1)}, \ldots , X _ {t} ^ {(N)} \right\} \approx X _ {t} \mid Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta .
$$

The algorithm proceeds sequentially. At time $t - 1$ , one has access to the samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ and using these, one generates the samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ by following the three steps given below.

1. Generation: For each $i = 1 , \ldots , N$ , generate independent samples:

$$
\tilde {X} _ {t} ^ {(i)} \sim f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}}.
$$

To execute this step, we need to be able to simulate from the state transition density fXt|Xt−1=xt−1 . $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } }$

2. Weights: For each $i = 1 , \ldots , N$ , compute

$$
w _ {t} ^ {(i)} := f _ {Y _ {t} \mid X _ {t} = \tilde {X} _ {t} ^ {(i)}} (y _ {t}). \tag {104}
$$

Normalize these weights so they sum to one:

$$
W _ {t} ^ {(i)} = \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

To execute this step, we need to be able to evalute the conditional density $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ at least up to a constant that does not depend on $x _ { t }$ .

3. Resampling: Generate

$$
X _ {t} ^ {(1)}, \dots , X _ {t} ^ {(N)} \stackrel {\text {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W _ {i} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}
$$

This algorithm is initialized by taking

$$
\tilde {X} _ {0} ^ {(1)}, \dots , \tilde {X} _ {0} ^ {(N)} \stackrel {\text {i . i . d}} {\sim} f _ {X _ {0} | \theta}
$$

and then following the steps 2 (weights) and 3 (resampling) above to generate $X _ { 0 } ^ { ( 1 ) } , \ldots , X _ { 0 } ^ { ( N ) }$ . One can then repeat the recursion for $t = 1 , 2 , 3 , \ldots .$ This is similar to the way we initialized the Kalman filter.

This algorithm is called the Bootstrap Particle Filter because: (a) Monte-Carlo samples are called particles in the physics literature, (b) The resampling step is reminiscent of the bootstrap procedure in statistics.

The Bootstrap Particle Filter is very simple and easy to implement. It can also be understood from the point of view of Importance Sampling. Before describing this connection to importance sampling, let us briefly recall importance sampling.

# 16.4 Importance Sampling Recalled

Consider a probability measure $P$ with density $p$ . Suppose we do not know the formula for $p$ exactly but we only know it up to some unknown multiplicative constant factor $c$ . In other words, we know the explicit formula for the function $x \mapsto c p ( x )$ but we do not know $c$ and hence we do not know $p ( x )$ explicitly.

Importance sampling attempts to approximate $P$ using i.i.d samples $\tilde { X } ^ { ( 1 ) } , \ldots , \tilde { X } ^ { ( n ) }$ drawn from another probability measure $Q$ having density $q$ . The idea is to form weights

$$
w ^ {(i)} := \frac {c p (\tilde {X} ^ {(i)})}{q (\tilde {X} ^ {(i)})} \qquad \text {f o r} i = 1, \ldots , N
$$

and the corresponding normalized weights:

$$
W ^ {(i)} := \frac {w ^ {(i)}}{w ^ {(1)} + \cdots + w ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

Then the importance sampling approximation for $P$ is

$$
P \approx \sum_ {i = 1} ^ {N} W ^ {(i)} \delta_ {\{\tilde {X} ^ {(i)} \}}
$$

Observe that for every function $g$ , this gives the following approximation for $\int g d P$ :

$$
\int g d P \approx \sum_ {i = 1} ^ {N} W ^ {(i)} g (\tilde {X} ^ {(i)}) = \frac {\sum_ {i = 1} ^ {N} w ^ {(i)} g (\tilde {X} ^ {(i)})}{\sum_ {i = 1} ^ {N} w ^ {(i)}}.
$$

In Lecture 15, we used the terminology “self-normalized” importance sampling for the above estimator of $\int g d P$ .

don’t. This means that the approximation Note that $\boldsymbol { w } ^ { ( 1 ) } , \ldots , \boldsymbol { w } ^ { ( N ) }$ depend on the constant $c$ but the normalized weights does not depend on $W ^ { ( 1 ) } , \ldots , W ^ { ( N ) }$ . $\textstyle \sum _ { i = 1 } ^ { N } W ^ { ( i ) } \delta _ { \{ \tilde { X } ^ { ( i ) } \} }$ $c$

It will be helpful to note the following two things before moving on:

1. Estimating $c$ : Importance sampling provides the following estimate for the unknown constant $c$ :

$$
\hat {c} := \frac {1}{N} \sum_ {i = 1} ^ {N} w ^ {(i)}. \tag {105}
$$

To see why this estimator makes sense, just note that

$$
\mathbb {E} \hat {c} = \frac {1}{N} \sum_ {i = 1} ^ {N} \mathbb {E} \left(w ^ {(i)}\right) = \frac {1}{N} \sum_ {i = 1} ^ {N} \mathbb {E} \left(\frac {c p (\tilde {X} ^ {(i)})}{q (\tilde {X} ^ {(i)})}\right) = \frac {1}{N} \sum_ {i = 1} ^ {N} \int \frac {c p (x)}{q (x)} q (x) d x = \int c p (x) d x = c
$$

2. Samples from $P$ : Importance sampling can be used to obtain approximately i.i.d samples from $P$ . Indeed as the importance sampling approximation for $P$ equals $\textstyle \sum _ { i = 1 } ^ { N } W ^ { ( i ) } \delta _ { \{ \tilde { X } ^ { ( i ) } \} }$ , one can obtain (approximate) samples from $P$ by sampling from the discrete distribution $\textstyle \sum _ { i = 1 } ^ { N } W ^ { ( i ) } \delta _ { \{ \tilde { X } ^ { ( i ) } \} }$ 1 W (i)δ{X˜ (i)}:

$$
X ^ {(1)}, \ldots , X ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W ^ {(i)} \delta_ {\{\tilde {X} ^ {(i)} \}}
$$

This method of sample generation is referred to as Importance Resampling because $X ^ { ( 1 ) } , \ldots , X ^ { ( N ) }$ are sampled from $\tilde { X } ^ { ( 1 ) } , \ldots , \tilde { X } ^ { ( N ) }$ (with weights $W ^ { ( 1 ) } , \dots , W ^ { ( N ) } )$ which are themselves sampled from $Q$ .

# 16.5 Bootstrap Particle Filter as Importance Resampling

The Bootstrap Particle Filter algorithm can be understood from the lens of importance resampling. This generalized view is helpful for the creation of other particle filtering algorithms. There are two (very similar) ways of seeing the connection between the Bootstrap Particle Filter and Importance Resampling.

# 16.5.1 First Way of Seeing the Connection

As explained in Section 16.2, the samples X˜ (1)t , . $\tilde { X } _ { t } ^ { ( 1 ) } , \ldots , \tilde { X } _ { t } ^ { ( N ) }$ generated in the first step of the Bootstrap particle filter recursion (from time $t - 1$ to $t$ ) can be seen as samples from the one-step ahead prediction distribution $X _ { t } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t - 1 } = y _ { t - 1 } , \theta$ :

$$
\tilde {X} _ {t} ^ {(1)}, \ldots , \tilde {X} _ {t} ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} f _ {X _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta}.
$$

If we now apply importance sampling to use these samples to approximate the the filtering distribution at time $t$ : $X _ { t } \mid Y _ { 0 } = y _ { 0 } , . . . , Y _ { t } = y _ { t } , \theta$ , we need to use, for some positive constant $c$ , the weights

$$
\begin{array}{l} \frac {c f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t} = y _ {t} , \theta} \left(\tilde {X} _ {t} ^ {(i)}\right)}{f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} \left(\tilde {X} _ {t} ^ {(i)}\right)} \tag {106} \\ = \frac {c \frac {f _ {X _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1} , \theta} (\tilde {X} _ {t} ^ {(i)}) f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t} ^ {(i)} , \theta} (y _ {t})}{f _ {Y _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1}} (y _ {t})}}{f _ {X _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1} , \theta} (\tilde {X} _ {t} ^ {(i)})} = \frac {c f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t} ^ {(i)} , \theta} (y _ {t})}{f _ {Y _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1}} (y _ {t})}. \\ \end{array}
$$

It is now clear that the Bootstrap Particle Filter uses the above weights for

$$
c = f _ {Y _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}} (y _ {t})
$$

so that the weights simplify to $f _ { Y _ { t } | X _ { t } = \tilde { X } _ { t } ^ { ( i ) } , \theta } ( y _ { t } )$ . Therefore each recursion of the Bootstrap tParticle Filter can be seen as a version of Importance Resampling.

# 16.5.2 Second Way of Seeing the Connection

In the first step of the Bootstrap Particle Recursion to go from $t - 1$ to $t$ , we generate samples $\tilde { X } _ { t } ^ { ( 1 ) } , \ldots , \tilde { X } _ { t } ^ { ( N ) }$ . , X˜ (N )t i ndependently according to

$$
\tilde {X} _ {t} ^ {(i)} \sim f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}}
$$

This means that jointly $( X _ { t - 1 } ^ { ( i ) } , \tilde { X } _ { t } ^ { ( i ) } ) , i = 1 , \dots , N$ are i.i.d samples from the joint density:

$$
f _ {X _ {t - 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (x _ {t - 1}) f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, \theta} (x _ {t})
$$

which is just the density of $X _ { t - 1 } , X _ { t } \mid Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta$ . We can now employ importance sampling to convert these samples into an approximation of the distribution

$$
X _ {t - 1}, X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, Y _ {t} = y _ {t}, \theta .
$$

We would need to use weights (for some constant $c > 0$ )

$$
\frac {c f _ {X _ {t - 1} , X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t} = y _ {t} , \theta} \left(x _ {t - 1} , x _ {t}\right)}{f _ {X _ {t - 1} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} \left(x _ {t - 1}\right) f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1} , \theta} \left(x _ {t}\right)} \tag {107}
$$

with $x _ { t - 1 } = X _ { t - 1 } ^ { ( i ) }$ and $x _ { t } = \tilde { X } _ { t } ^ { ( i ) }$ . The above expression can be simplified using Bayes rule as

$$
\begin{array}{l} \frac {c f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (x _ {t - 1} , x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})} \\ = \frac c \frac {f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta (x _ {t - 1} , x _ {t}) f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1} , X _ {t} = x _ {t} , \theta (y _ {t})}}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta (y _ {t})}}}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})} \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \frac {f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1} , x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \frac {f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}). \\ \end{array}
$$

As a result, we can view the weights in the bootstrap particle filter as the weights given by (107) with $c = f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } )$ .

# 16.6 Likelihood Approximation from the Bootstrap Particle Filter

In the previous section, we have seen that the recursion (to go from time $t - 1$ to time $t$ ) in the Bootstrap Particle Filter can be seen as importance sampling with weights (107) (or equivalently (106)) with $c = f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } )$ . The observation (105) can therefore be used to deduce that:

$$
\frac {1}{N} \sum_ {i = 1} ^ {N} w _ {t} ^ {(i)} \approx f _ {Y _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t})
$$

for each $t = 1 , \dots , T$ (here $w _ { t } ^ { ( i ) }$ is as defined in (109)). One can also similarly argue that

$$
\frac {1}{N} \sum_ {i = 1} ^ {N} w _ {0} ^ {(i)} = \frac {1}{N} \sum_ {i = 1} ^ {N} f _ {Y _ {0} | X _ {0} = \tilde {X} _ {0} ^ {(i)}} (y _ {0}) \approx f _ {Y _ {0}} (y _ {0}).
$$

The likelihood $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ can thus be approximated as

$$
f _ {Y _ {0}, \ldots , Y _ {T} | \theta} (y _ {0}, \ldots , y _ {T}) = f _ {Y _ {0} | \theta} (y _ {0}) \prod_ {t = 1} ^ {T} f _ {Y _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) \approx \prod_ {t = 0} ^ {T} \left(\frac {1}{N} \sum_ {i = 1} ^ {N} w _ {t} ^ {(i)}\right).
$$

In this way, the bootstrap particle filter algorithm directly allows likelihood computation.

# 16.7 Recommended Reading for Today

1. For the Bootstrap Particle Filter Algorithm, I recommend Section 15.2 of the Kitagawa book (Kitagawa refers to the algorithm as simply The Monte Carlo Filter ).   
2. For more details about importance sampling and resampling, I recommend Chapters 8 and 9 of the Chopin-Papaspiliopoulos book.

# 17 Lecture Seventeen

# 17.1 Recap: Bootstrap Particle Filter

In the last class, we studied the Bootstrap Particle Filter Algorithm for solving the filtering problem via Monte Carlo in general sequential state space models.

For each t ≥ 0, this algorithm outputs samples X(1)t , . $t \geq 0$ $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ . , X (N ) such that

$$
\operatorname {U n i f} \left\{X _ {t} ^ {(1)}, \dots , X _ {t} ^ {(N)} \right\} \approx X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta . \tag {108}
$$

The algorithm proceeds sequentially. At time $t - 1$ , one has access to the samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ satisfying (108) for $t - 1$ and using these, one generates the samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ by following the three steps given below.

1. Generation: For each $i = 1 , \ldots , N$ , generate independent samples:

$$
\tilde {X} _ {t} ^ {(i)} \sim f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}}.
$$

To execute this step, we need to be able to simulate from the state transition density $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } }$ .

2. Weights: For each $i = 1 , \ldots , N$ , compute

$$
w _ {t} ^ {(i)} := f _ {Y _ {t} \mid X _ {t} = \tilde {X} _ {t} ^ {(i)}} (y _ {t}). \tag {109}
$$

Normalize these weights so they sum to one:

$$
W _ {t} ^ {(i)} = \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

To execute this step, we need to be able to evaluate the conditional density $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ .

3. Resampling: Generate

$$
X _ {t} ^ {(1)}, \ldots , X _ {t} ^ {(N)} \stackrel {\text {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W _ {i} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}
$$

This algorithm is initialized by taking

$$
\tilde {X} _ {0} ^ {(1)}, \ldots , \tilde {X} _ {0} ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} f _ {X _ {0} | \theta}
$$

and then following the steps 2 (weights) and 3 (resampling) above to generate $X _ { 0 } ^ { ( 1 ) } , \ldots , X _ { 0 } ^ { ( N ) }$ (1)0 , . . . , X (N )0 . One can then repeat the recursion for $t = 1 , 2 , 3 , \ldots$ . This is similar to the Kalman Filter initialization.

The algorithm also allows computation of the likelihood $f _ { Y _ { 0 } , \dots , Y _ { T } | \theta } ( y _ { 0 } , \dots , y _ { T } )$ as:

$$
f _ {Y _ {0}, \ldots , Y _ {T} | \theta} (y _ {0}, \ldots , y _ {T}) = f _ {Y _ {0} | \theta} (y _ {0}) \prod_ {t = 1} ^ {T} f _ {Y _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) \approx \prod_ {t = 0} ^ {T} \left(\frac {1}{N} \sum_ {i = 1} ^ {N} w _ {t} ^ {(i)}\right).
$$

# 17.2 Unique Values and Particle Degeneracy

It is clear from the description of the algorithm that the samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ output by the Bootstrap Particle Filter are actually sampled from the discrete distribution:

$$
\sum_ {i = 1} ^ {N} W _ {t} ^ {(i)} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}
$$

An immediate implication of this is that X(1)t , . $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ . . , X (N )t w ill not all be distinct and there will ong. If em. A useful diagnostic here isis particularly small for some the number of unique values , the Monte Carlo approxima $N _ { t }$ amongn (108) $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ $N _ { t }$ $t$ will not be accurate. If $N _ { t }$ is small for some time indices $t$ , then one says that the particle filter algorithm suffers from the problem of Particle Degeneracy.

The Bootstrap particle filter can suffer from particle degeneracy. To understand when this problem is particularly serious, observe first that, in the generation step, $\tilde { X } _ { t } ^ { ( 1 ) } , \ldots , \tilde { X } _ { t } ^ { ( N ) }$ can be seen as i.i.d samples from the one-step ahead prediction density:

$$
f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}}, \theta \cdot
$$

The weights $w _ { t } ^ { ( i ) } = f _ { Y _ { t } | X _ { t } = \tilde { X } _ { t } ^ { ( i ) } } ( y _ { t } )$ satisfy

$$
w _ {t} ^ {(i)} \propto \frac {f _ {X _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1} , Y _ {t} = y _ {t} , \theta} (\tilde {X} _ {t} ^ {(i)})}{f _ {X _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1} , \theta} (\tilde {X} _ {t} ^ {(i)})}
$$

The two densities in play here are the proposal density given by $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta }$ and the target density given by $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \dots , Y _ { t } = y _ { t } , \theta }$ . The algorithm will not work well if these two densities are far from each other. Specifically, particle degeneracy occurs if the target density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t } = y _ { t } , \theta } ( x _ { t } )$ is quite small when $x _ { t }$ belongs to the high-density regions of the proposal density $f _ { X _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( x _ { t } )$ . Note that the only difference between the proposal and target densities is the additional conditioning on $Y _ { t } = y _ { t }$ in the target density. Thus the proposal and target densities will be different if $Y _ { t }$ provides significantly more and different information about $X _ { t }$ beyond that already provided by $Y _ { 0 } , \dots , Y _ { t - 1 }$ . This tends to happen, for example, if the observation model relating $Y _ { t }$ to $X _ { t }$ has small errors. For example, in the local level model $Y _ { t } = X _ { t } + \epsilon _ { t }$ , if $\epsilon _ { t }$ is small (e.g., when $\sigma _ { \epsilon }$ is small), then $Y _ { t }$ is quite informative for $X _ { t }$ and, in such situations, the bootstrap particle filter algorithm suffers from particle degeneracy.

This also tends to happen for $t = 0$ when the proposal density is $f _ { X _ { 0 } | \theta }$ and the target density is $f _ { X _ { 0 } | Y _ { 0 } = y _ { 0 } , \theta }$ . The proposal density is usually quite diffuse and the target density is relatively informative leading to small weights for most of the samples (and, consequently, small $N _ { 0 }$ ).

In such situations where $Y _ { t }$ is quite informative about $X _ { t }$ , a natural fix is to change the proposal distribution by including information on $Y _ { t }$ . This is the idea underlying the Guided Particle Filter Algorithm.

# 17.3 The Guided Particle Filter Algorithm

The guided particle filter algorithm uses more general proposal distributions. For each time point $t \geq 0$ , each value $x$ in the space of the hidden variables $\{ X _ { t } \}$ , and each value $y$ in the space of the observation variables $\{ Y _ { t } \}$ , let

$$
u \mapsto q _ {t} (u \mid x, y, \theta)
$$

be an arbitrary density. The general algorithm described below works for any such set of densities $q _ { t } ( \cdot \mid x , y , \theta )$ . The only requirement is that it should be possible simulate from this density. This general algorithm is known as the guided particle filter algorithm and an alternative name for the same algorithm is the Sequential Importance Resampling (SIR) algorithm. In order to apply this algorithm in an actual problem, it is necessary to specify $q _ { t } ( \cdot \mid x , y , \theta )$ . For this, two choices are commonly used:

1. $q _ { t } ( u \mid x , y , \theta ) : = f _ { X _ { t } | X _ { t - 1 } = x , \theta } ( u )$ . The following algorithm for this choice of $q _ { t }$ reduces to the Bootstrap Particle Filter algorithm. Therefore the SIR algorithm is a generalization of the Bootstrap Particle Filter. Note that this choice of $q _ { t } ( \cdot \mid , x , y , \theta )$ does not depend on $y$ (it only depends on $x$ ).   
2. $q _ { t } ( u , \mid x , y , \theta ) : = f _ { X _ { t } \mid X _ { t - 1 } = x , Y _ { t } = y , \theta } ( u )$ . This is commonly used as an alternative to the Bootstrap particle filter when the latter suffers from particle degeneracy. The use of this density in the SIR algorithm requires one to be able to simulate from the conditional density of $X _ { t }$ given $X _ { t - 1 } = x , Y _ { t } = y , \theta$ .

The following is the SIR algorithm. As the Bootstrap particle filter algorithm, the goal is to output, for each t ≥ 0, samples X(1)t , . $t \geq 0$ $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ . , X (N )t s uch that

$$
\operatorname {U n i f} \left\{X _ {t} ^ {(1)}, \dots , X _ {t} ^ {(N)} \right\} \approx X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta . \tag {110}
$$

The algorithm proceeds sequentially. At time $t - 1$ , one has access to the samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ satisfying (114) for $t - 1$ and using these, one generates the samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ by following the three steps given below.

1. Generation: For each $i = 1 , \ldots , N$ , generate independent samples:

$$
\tilde {X} _ {t} ^ {(i)} \sim q (\cdot | x = X _ {t - 1} ^ {(i)}, y = y _ {t}, \theta)
$$

To execute this step, we obviously need to be able to simulate from $q ( \cdot \mid x = X _ { t - 1 } ^ { ( i ) } , y =$ X t−1, y = $y _ { t }$ ).

2. Weights: For each $i = 1 , \ldots , N$ , compute

$$
w _ {t} ^ {(i)} := \frac {f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)} , \theta} \left(\tilde {X} _ {t} ^ {(i)}\right) f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t} ^ {(i)} , \theta} \left(y _ {t}\right)}{q _ {t} \left(\tilde {X} _ {t} ^ {(i)} \mid x = X _ {t - 1} ^ {(i)} , y = y _ {t} , \theta\right)} \tag {111}
$$

Normalize these weights so they sum to one:

$$
W _ {t} ^ {(i)} = \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

To execute this step, we need to be able to evaluate $f _ { X _ { t } \mid X _ { t - 1 } = x _ { t - 1 } } ( x _ { t } )$ and $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ .

3. Resampling: Generate

$$
X _ {t} ^ {(1)}, \ldots , X _ {t} ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W _ {i} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}
$$

This algorithm is initialized by taking

$$
X _ {0} ^ {(1)}, \ldots , X _ {0} ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} f _ {X _ {0} | Y _ {0} = y _ {0}}
$$

and then repeating the three steps described above for $t = 1 , 2 , \ldots { }$ .

The justification for the weights (115) is as follows. Note first that $( X _ { t - 1 } ^ { ( i ) } , \tilde { X } _ { t } ^ { ( i ) } )$ for $i =$ $1 , \ldots , N$ are i.i.d samples from the joint density:

$$
\left(x _ {t - 1}, x _ {t}\right) \mapsto f _ {X _ {t - 1} \mid Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} \left(x _ {t - 1}\right) q _ {t} \left(x _ {t} \mid x _ {t - 1}, y _ {t}, \theta\right).
$$

The target should have, as its second marginal, the filtering density at time $t$ . This suggests the target density:

$$
\left(x _ {t - 1}, x _ {t}\right) \mapsto f _ {X _ {t - 1}, X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} \left(x _ {t - 1}, x _ {t}\right).
$$

The importance weights will then be given by

$$
\frac {c f _ {X _ {t - 1} , X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t} = y _ {t} , \theta} \left(x _ {t - 1} , x _ {t}\right)}{f _ {X _ {t - 1} \mid Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} \left(x _ {t - 1}\right) q _ {t} \left(x _ {t} \mid x _ {t - 1} , y _ {t} , \theta\right)} \tag {112}
$$

with $x _ { t - 1 } = X _ { t - 1 } ^ { ( i ) }$ and $x _ { t } = \tilde { X } _ { t } ^ { ( i ) }$ . The above expression can be simplified using Bayes rule as

$$
\begin{array}{l} \frac {c f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (x _ {t - 1} , x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) q _ {t} (x _ {t} \mid x _ {t - 1} , y _ {t} , \theta)} \\ = \frac {c \frac {f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1} , x _ {t}) f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1} , X _ {t} = x _ {t} , \theta} (y _ {t})}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})}}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) q _ {t} (x _ {t} \mid x _ {t - 1} , y _ {t} , \theta)} \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \frac {f _ {X _ {t - 1} , X _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1} , x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) q _ {t} (x _ {t} | x _ {t - 1} , y _ {t} , \theta)} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \frac {f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t})}{f _ {X _ {t - 1} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (x _ {t - 1}) q _ {t} (x _ {t} | x _ {t - 1} , y _ {t} , \theta)} f _ {Y _ {t} | X _ {t} = x _ {t}, \theta} (y _ {t}) \\ = \frac {c}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{q _ {t} (x _ {t} | x _ {t - 1} , y _ {t} , \theta)}. \\ \end{array}
$$

As a result, we can view the weights in the SIR algorithm as the weights given by (112) with $c = f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } )$ . This justifies the choice of weights in the SIR algorithm. Note also that because $c = f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } )$ , the average of the unnormalized weights provides an approximation of $f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } )$ :

$$
\frac {1}{n} \sum_ {i = 1} ^ {N} w _ {t} ^ {(i)} \approx f _ {Y _ {t} | Y _ {0} = y _ {0}, \dots , Y _ {t - 1} = y _ {t - 1}, \theta} (y _ {t}) \qquad \mathrm {f o r e a c h} t = 1, \dots , T.
$$

The product of these averages for $t = 1 , \dots , T$ (additionally multiplied by $f _ { Y _ { 0 } } ( y _ { 0 } )$ ) gives an approximation for the likelihood.

# 17.4 Weights when $q _ { t } ( u \mid x , y , \theta ) : = f _ { X _ { t } | X _ { t - 1 } = x , Y _ { t } = y , \theta } ( u )$

As already remarked, the two most common choices of $q _ { t }$ in the SIR algorithm are $q _ { t } ( u \mid$ $x , y , \theta ) = f _ { X _ { t } | X _ { t - 1 } = x } ( u )$ (which corresponds to the bootstrap filter) and $q _ { t } ( u \mid x , y , \theta ) =$ $f _ { X _ { t } | X _ { t - 1 } = x , Y _ { t } = y } ( u )$ . The weights for the latter choice can be simplified (using Bayes rule in the denominator) as:

$$
\begin{array}{l} \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{q _ {t} (x _ {t} \mid x _ {t - 1} , y _ {t} , \theta)} = \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , Y _ {t} = y _ {t} , \theta} (x _ {t})} \\ = \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{\frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , X _ {t - 1} = x _ {t - 1} , \theta} (y _ {t})}{f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (y _ {t})}} \\ = \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{\frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (y _ {t})}} = f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1}, \theta} (y _ {t}). \\ \end{array}
$$

In other words, the weight corresponding to $( X _ { t - 1 } ^ { ( i ) } , \tilde { X } _ { t } ^ { ( i ) } )$ for SIR with $q _ { t } ( u \mid x , y , \theta ) =$ $f _ { X _ { t } | X _ { t - 1 } = x , Y _ { t } = y } ( u )$ is given by

$$
w _ {t} ^ {(i)} = f _ {Y _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}, \theta} (y _ {t}).
$$

It is interesting to contrast this weight with the weight $f _ { Y _ { t } | X _ { t } = \tilde { X } _ { t } ^ { ( i ) } , \theta } ( y _ { t } )$ used in the bootstrap particle filter.

# 17.5 Example: Local Level Model

As already remarked, the bootstrap particle filter is widely applicable because, in order to use it, one only needs to be able to simulate from the state transition density $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } }$ and be able to compute the density $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ . On the other hand, in order to apply the Guided Particle Filter algorithm with

$$
q _ {t} (u \mid x, y, \theta) := f _ {X _ {t} \mid X _ {t - 1} = x, Y _ {t} = y, \theta} (u) \tag {113}
$$

one should be able to simulate from $f _ { X _ { t } | X _ { t - 1 } = x , Y _ { t } = y , \theta }$ and evaluate $f _ { Y _ { t } | X _ { t - 1 } = x _ { t - 1 } } ( y _ { t } )$ . While this may not always possible, here is a simple setting where the method can be easily applied. This is the case of the local level model:

$$
X _ {0} \sim N (0, C) \quad X _ {t} = X _ {t - 1} + Z _ {t} \quad Y _ {t} = X _ {t} + \epsilon_ {t}
$$

where $X _ { 0 } , Z _ { 1 } , Z _ { 2 } , \dots , \epsilon _ { 0 } , \epsilon _ { 1 } , \dots .$ are independent with $Z _ { t } \stackrel { \mathrm { \tiny ~ i . i . d } } { \sim } N ( 0 , \sigma _ { Z } ^ { 2 } )$ and $\epsilon _ { t } \stackrel { \mathrm { i . i . d } } { \sim } N ( 0 , \sigma _ { \epsilon } ^ { 2 } )$ For this model, we have

$$
X _ {t} \mid X _ {t - 1} = x _ {t - 1}, \theta \sim N (x _ {t - 1}, \sigma_ {Z} ^ {2}) \quad \mathrm {a n d} \quad Y _ {t} \mid X _ {t} = x _ {t}, X _ {t - 1} = x _ {t - 1}, \theta \sim N (x _ {t}, \sigma_ {\epsilon} ^ {2})
$$

from which it readily follows that

$$
X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}, \theta \sim N \left(\frac {\frac {x _ {t - 1}}{\sigma_ {Z} ^ {2}} + \frac {y _ {t}}{\sigma_ {\epsilon} ^ {2}}}{\frac {1}{\sigma_ {Z} ^ {2}} + \frac {1}{\sigma_ {\epsilon} ^ {2}}}, \frac {1}{\frac {1}{\sigma_ {Z} ^ {2}} + \frac {1}{\sigma_ {\epsilon} ^ {2}}}\right).
$$

Thus the Guided Particle Filter Algorithm with (113) is feasible in this case and the generation step simulates observations as:

$$
\tilde {X} _ {t} ^ {(i)} \sim N \left(\frac {\frac {X _ {t - 1} ^ {(i)}}{\sigma_ {Z} ^ {2}} + \frac {y _ {t}}{\sigma_ {\epsilon} ^ {2}}}{\frac {1}{\sigma_ {Z} ^ {2}} + \frac {1}{\sigma_ {\epsilon} ^ {2}}}, \frac {1}{\frac {1}{\sigma_ {Z} ^ {2}} + \frac {1}{\sigma_ {\epsilon} ^ {2}}}\right).
$$

We also have

$$
Y _ {t} \mid X _ {t - 1} = x _ {t - 1}, \theta \sim N (x _ {t - 1}, \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2})
$$

so that the weights are computed as

$$
w _ {t} ^ {(i)} = \phi (y _ {t}; X _ {t - 1} ^ {(i)}, \sigma_ {Z} ^ {2} + \sigma_ {\epsilon} ^ {2})
$$

where $\phi ( y ; \mu , \sigma ^ { 2 } )$ denotes the normal density with mean $\mu$ and variance $\sigma ^ { 2 }$ evaluated at $y$ . Initialization is done by generating observations from the distribution:

$$
X _ {0} \mid Y _ {0} = y _ {0}, \theta \sim N \left(\frac {y _ {0} / \sigma_ {\epsilon} ^ {2}}{1 / C + 1 / \sigma_ {\epsilon} ^ {2}}, \frac {1}{1 / C + 1 / \sigma_ {\epsilon} ^ {2}}\right).
$$

It can easily be seen (in simulations) that when $\sigma _ { \epsilon } ^ { 2 }$ is small, the bootstrap particle filter suffers from particle degeneracy. The performance of the guided particle filter with (113) is much better.

# 17.6 Recommended Reading for Today

1. Good references for the SIR or Guided Particle Filter algorithms are:

a) Section 5.1 of the Petris-Petrone-Campagnoli book   
b) Section 7.4 of the S¨arkk¨a book   
c) Section 6.7.3 of the Triantafyllopoulos book   
d) Sections 10.3.1 and 10.3.2 of the Chopin-Papaspiliopoulos (they derive these algorithms from a slightly more general viewpoint involving Feynman-Kac models which are described in Chapter 5 of their book)

# 18 Lecture Eighteen

# 18.1 Sequential Importance Resampling

In the last class, we looked at the Sequential Importance Resampling (SIR) algorithm (we also used the term “Guided Particle Filter”) which generates, for each $t ~ \geq ~ 0$ , samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ (1), . . . , X (N )t s uch that

$$
\operatorname {U n i f} \left\{X _ {t} ^ {(1)}, \dots , X _ {t} ^ {(N)} \right\} \approx X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta . \tag {114}
$$

The algorithm proceeds sequentially. At time $t - 1$ , one has access to the samples $X _ { t - 1 } ^ { ( 1 ) } , \ldots , X _ { t - 1 } ^ { ( N ) }$ satisfying (114) for $t - 1$ and using these, one generates the samples $X _ { t } ^ { ( 1 ) } , \ldots , X _ { t } ^ { ( N ) }$ by following the three steps given below.

1. Generation: For each $i = 1 , \ldots , N$ , generate independent samples:

$$
\tilde {X} _ {t} ^ {(i)} \sim q (\cdot | x = X _ {t - 1} ^ {(i)}, y = y _ {t}, \theta)
$$

o execute this step, we obviously need to be able to simulate from ). $q ( \cdot \mid x = X _ { t - 1 } ^ { ( i ) } , y =$ $y _ { t }$

2. Weights: For each $i = 1 , \ldots , N$ , compute

$$
w _ {t} ^ {(i)} := \frac {f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)} , \theta} \left(\tilde {X} _ {t} ^ {(i)}\right) f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t} ^ {(i)} , \theta} \left(y _ {t}\right)}{q _ {t} \left(\tilde {X} _ {t} ^ {(i)} \mid x = X _ {t - 1} ^ {(i)} , y = y _ {t} , \theta\right)} \tag {115}
$$

Normalize these weights so they sum to one:

$$
W _ {t} ^ {(i)} = \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

To execute this step, we need to be able to evaluate $f _ { X _ { t } \mid X _ { t - 1 } = x _ { t - 1 } } ( x _ { t } )$ and $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$

3. Resampling: Generate

$$
X _ {t} ^ {(1)}, \ldots , X _ {t} ^ {(N)} \stackrel {\mathrm {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W _ {i} \delta_ {\{\tilde {X} _ {t} ^ {(i)} \}}
$$

This algorithm is initialized by taking

$$
X _ {0} ^ {(1)}, \ldots , X _ {0} ^ {(N)} \stackrel {\text {i . i . d}} {\sim} f _ {X _ {0} | Y _ {0} = y _ {0}}
$$

and then repeating the three steps described above for $t = 1 , 2 , \ldots$ .

The density $q ( \cdot \mid x _ { t - 1 } , y _ { t } )$ appearing above is often referred to as a proposal density. The SIR algorithm works for pretty much any proposal density (the only requirement is the ability to simulate from it). The two most common choices of the proposal density are:

1. Bootstrap Particle Filter: $q ( x _ { t } \mid x _ { t - 1 } , y _ { t } ) = f _ { X _ { t } \mid X _ { t - 1 } = x _ { t - 1 } } ( x _ { t } )$ . Note that this choice of $q$ does not depend on $y _ { t }$ . The weights corresponding to this proposal are $f _ { Y _ { t } | X _ { t } = x _ { t } } ( y _ { t } )$ i.e., w(i)t = $w _ { t } ^ { ( i ) } = f _ { Y _ { t } | X _ { t } = \tilde { X } _ { t } ^ { ( i ) } } ( y _ { t } )$ .   
2. “Optimal” Guided Particle Filter: $q ( x _ { t } \mid x _ { t - 1 } , y _ { t } ) = f _ { X _ { t } \mid X _ { t - 1 } = x _ { t - 1 } , Y _ { t } = y _ { t } } ( x _ { t } )$ . This algorithm is only feasible if it is possible to simulate from the conditional density of $X _ { t }$ given $X _ { t - 1 } ~ = ~ x _ { t - 1 }$ and $Y _ { t } ~ = ~ y _ { t }$ . The reason why this choice of $q$ for the Guided Particle Filter algorithm is called “optimal” can be found, for example, in Theorem 10.1 of the Chopin-Papaspiliopoulos book. We shall not make any use of this optimality criterion. The weights corresponding to this proposal are $f _ { Y _ { t } | X _ { t - 1 } = x _ { t - 1 } } ( y _ { t } )$ i.e., $w _ { t } ^ { ( i ) } = f _ { Y _ { t } | X _ { t - 1 } = X _ { t - 1 } ^ { ( i ) } } ( y _ { t } )$ . Note that these weights do not depend on the particles $\tilde { X } _ { t } ^ { ( i ) }$ generated in this iterate of the algorithm.

The second algorithm above (optimal guided particle filter) usually suffers from less particle degeneracy compared to the Bootstrap particle filter because the function

$$
x \mapsto f _ {Y _ {t} | X _ {t - 1} = x} (y _ {t})
$$

is less concentrated compared to the function

$$
x \mapsto f _ {Y _ {t} | X _ {t} = x} (y _ {t}).
$$

# 18.2 Example: Local Level Model with non-Gaussian evolution errors

Consider the local level model:

$$
X _ {t} = X _ {t - 1} + Z _ {t} \qquad \mathrm {w i t h} Z _ {t} \stackrel {\mathrm {i . i . d}} {\sim} (1 - \alpha) N (0, \sigma_ {0} ^ {2}) + \alpha N (0, \sigma_ {a} ^ {2})
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2}).
$$

This model can be used to model trend functions that are piecewise constant. The parameter $\alpha$ and the variance $\sigma _ { 0 } ^ { 2 }$ will both be small in such applications.

The Kalman filter is obviously not applicable here as the evolution error is non-Gaussian. The bootstrap filter algorithm is quite easy to implement: in the generation step, the challenge is to simulate

$$
\tilde {x} _ {t} \sim (1 - \alpha) N (x _ {t - 1}, \sigma_ {0} ^ {2}) + \alpha N (x _ {t - 1}, \sigma_ {a} ^ {2})
$$

for $x _ { t - 1 } = X _ { t - 1 } ^ { ( i ) }$ . This is a mixture of Gaussian distributions. One can simulate from this mixture by first simulating a Bernoulli random variable $B$ with success probability $\alpha$ . If $\alpha = 1$ , then one would simulate $\scriptstyle { \tilde { x } } _ { t }$ from $N ( x _ { t - 1 } , \sigma _ { a } ^ { 2 } )$ and if $\alpha = 1$ , then one would simulate $\tilde { x } _ { t }$ from $N ( x _ { t - 1 } , \sigma _ { 0 } ^ { 2 } )$ . The weights are given by

$$
w _ {t} = f _ {Y _ {t} | X _ {t} = \tilde {x} _ {t}} (y _ {t}) = \phi (y _ {t}; \tilde {x} _ {t}, \sigma_ {\epsilon} ^ {2}) \tag {116}
$$

where $\phi ( x ; \mu , \sigma ^ { 2 } )$ stands for the normal density with mean $\mu$ and variance $\sigma ^ { 2 }$ . Note that if $y _ { t }$ is far from $\tilde { x } _ { t }$ and $\sigma _ { \epsilon }$ is relatively small, then there will be particle degeneracy. Also note that, when the parameters $\alpha$ and $\sigma _ { 0 } ^ { 2 }$ are small, most ( $( 1 - \alpha )$ fraction) of the generated observations $\tilde { x } _ { t }$ will be close to $x t - 1$ .

Now let us consider applying the optimal guided particle filter for this model. Particle generation will have to be done from the conditional density $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } , Y _ { t } = y _ { t } }$ . By Bayes rule:

$$
\begin{array}{l} f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \propto f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}} (x _ {t}) f _ {Y _ {t} \mid X _ {t} = x _ {t}, X _ {t - 1} = x _ {t - 1}} (y _ {t}) \\ = f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}} (x _ {t}) f _ {Y _ {t} \mid X _ {t} = x _ {t}} (y _ {t}) \\ = \left\{(1 - \alpha) \phi (x _ {t}; x _ {t - 1}, \sigma_ {0} ^ {2}) + \alpha \phi (x _ {t}; x _ {t - 1}, \sigma_ {a} ^ {2}) \right\} \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}) \\ = (1 - \alpha) \phi (x _ {t}; x _ {t - 1}, \sigma_ {0} ^ {2}) \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}) + \alpha \phi (x _ {t}; x _ {t - 1}, \sigma_ {a} ^ {2}) \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}). \\ \end{array}
$$

We now use the following elementary identity (which can be proved by direct calculation): For every $\theta , x , \mu \in ( - \infty , \infty )$ and $\tau , \sigma > 0$ , we have

$$
\phi (\theta ; \mu , \tau^ {2}) \phi (x; \theta , \sigma^ {2}) = \phi \left(\theta ; \frac {x / \sigma^ {2} + \mu / \tau^ {2}}{1 / \sigma^ {2} + 1 / \tau^ {2}}, \frac {1}{1 / \sigma^ {2} + 1 / \tau^ {2}}\right) \phi (x; \mu , \tau^ {2} + \sigma^ {2}). \qquad (1 1 7)
$$

We get

$$
\begin{array}{l} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \propto (1 - \alpha) \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) \\ + \alpha \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {a} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}\right) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2}). \\ \end{array}
$$

The integral of the right hand side above with respect to $x _ { t }$ is

$$
(1 - \alpha) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2}).
$$

As a result

$$
\begin{array}{l} f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \\ = \frac {(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2})}{(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})} \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right) \\ + \frac {\alpha \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})}{(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})} \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {a} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}\right). \\ \end{array}
$$

This is just a mixture of two normal distributions so one can simulate observations from it by first generating a Bernoulli random variable $B$ with success probability:

$$
\frac {\alpha \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})}{(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})}
$$

If $B = 1$ , one simulates from

$$
N \left(\frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {a} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {a} ^ {2}}\right),
$$

and if $B = 0$ , one simulates from

$$
N \left(\frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right).
$$

Finally note that

$$
f _ {Y _ {t} | X _ {t - 1} = x _ {t - 1}} (y _ {t}) = (1 - \alpha) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {a} ^ {2})
$$

which is useful for weight calculation. Note that, as a function of $x _ { t - 1 }$ , the right hand side above is more diffuse compared to the weight function in the Bootstrap filter (116). This implies that, in this example, the optimal guided particle filter suffers from less particle degeneracy compared to the Bootstrap particle filter.

It should be noted that it is not always possible to implement the optimal guided particle filter in closed form (as in the above example). For example, consider the local level model again where the $N ( 0 , \sigma _ { a } ^ { 2 } )$ distribution in the evolution error is replaced by the standard Cauchy distribution:

$$
X _ {t} = X _ {t - 1} + Z _ {t} \qquad \mathrm {w i t h} Z _ {t} \stackrel {\mathrm {i . i . d}} {\sim} (1 - \alpha) N (0, \sigma_ {0} ^ {2}) + \alpha C (0, 1)
$$

$$
Y _ {t} = X _ {t} + \epsilon_ {t} \qquad \mathrm {w i t h} \epsilon_ {t} \stackrel {\mathrm {i . i . d}} {\sim} N (0, \sigma_ {\epsilon} ^ {2})
$$

where $C ( 0 , 1 )$ denotes the standard Cauchy distribution with density proportional to $( 1 +$ $x ^ { 2 } ) ^ { - 1 }$ . In this case, $f _ { X _ { t } | X _ { t - 1 } = x _ { t - 1 } , Y _ { t } = y _ { t } }$ is given by

$$
\begin{array}{l} f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \propto f _ {X _ {t} | X _ {t - 1} = x _ {t - 1}} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t}} (y _ {t}) \\ = \left\{(1 - \alpha) \phi (x _ {t}; x _ {t -}, \sigma_ {0} ^ {2}) + \alpha \gamma (x _ {t}; x _ {t - 1}) \right\} \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}) \\ = (1 - \alpha) \phi (x _ {t}; x _ {t -}, \sigma_ {0} ^ {2}) \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}) + \alpha \gamma (x _ {t}; x _ {t - 1}) \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}) \\ \end{array}
$$

where $\gamma ( x _ { t } ; x _ { t - 1 } )$ is the density of a Cauchy random variable centered at $x _ { t - 1 }$ (and scale parameter equal to 1):

$$
\gamma (x; \mu) = \frac {1}{\pi} \frac {1}{1 + (x - \mu) ^ {2}}.
$$

Using the fact (117), we obtain

$$
f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t})
$$

$$
\propto (1 - \alpha) \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha \gamma (x _ {t}; x _ {t - 1}) \phi (y _ {t}; x _ {t}, \sigma_ {\epsilon} ^ {2}).
$$

Letting

$$
V (y; \mu , \sigma^ {2}) := \int \gamma (x; \mu) \phi (y; x, \sigma^ {2}) d x,
$$

we can write

$$
\begin{array}{l} f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \\ \propto (1 - \alpha) \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) \\ + \alpha \left[ \frac {\gamma (x _ {t} ; x _ {t - 1}) \phi (y _ {t} ; x _ {t} , \sigma_ {\epsilon} ^ {2})}{V (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2})} \right] V (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2}). \\ \end{array}
$$

The integral of the right hand side above with respect to $x _ { t }$ equals

$$
(1 - \alpha) \phi (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha V (y _ {t}; x _ {t - 1}, \sigma_ {\epsilon} ^ {2})
$$

so that

$$
\begin{array}{l} f _ {X _ {t} \mid X _ {t - 1} = x _ {t - 1}, Y _ {t} = y _ {t}} (x _ {t}) \\ = \frac {(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2})}{(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha V (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2})} \phi \left(x _ {t}; \frac {y _ {t} / \sigma_ {\epsilon} ^ {2} + x _ {t - 1} / \sigma_ {0} ^ {2}}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}, \frac {1}{1 / \sigma_ {\epsilon} ^ {2} + 1 / \sigma_ {0} ^ {2}}\right) \\ + \frac {\alpha V (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2})}{(1 - \alpha) \phi (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2} + \sigma_ {0} ^ {2}) + \alpha V (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2})} \left[ \frac {\gamma (x _ {t} ; x _ {t - 1}) \phi (y _ {t} ; x _ {t} , \sigma_ {\epsilon} ^ {2})}{V (y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2})} \right]. \\ \end{array}
$$

The density function $y \ \mapsto \ V ( y ; \mu , \sigma ^ { 2 } )$ is known as the Voigt profile (see https://en. wikipedia.org/wiki/Voigt_profile) and efficient algorithms exist for its computation. In order to simulate $\tilde { x } _ { t }$ from the above conditional density, the main challenge is to simulate from the conditional density:

$$
x _ {t} \mapsto \frac {\gamma \left(x _ {t} ; x _ {t - 1}\right) \phi \left(y _ {t} ; x _ {t} , \sigma_ {\epsilon} ^ {2}\right)}{V \left(y _ {t} ; x _ {t - 1} , \sigma_ {\epsilon} ^ {2}\right)}. \tag {118}
$$

It is not clear if this can be done in closed form. One can use some numerical techniques for this. For example, a straightforward approach is to use discretization: one can discretize the domain and approximate the continuous distribution with density given by (118) by a discrete distribution supported on the discrete set of values. One can then simulate from the discrete distribution.

Note that the filter algorithms can be used for obtaining the likelihood (which is the joint density of $Y _ { 0 } , \dots , Y _ { T }$ given the parameters) which can be used for maximum likelihood estimation of the parameters.

# 18.3 Recommended Reading for Today

1. Good references for the SIR or Guided Particle Filter algorithms are:

a) Section 5.1 of the Petris-Petrone-Campagnoli book   
b) Section 7.4 of the S¨arkk¨a book   
c) Section 6.7.3 of the Triantafyllopoulos book   
d) Sections 10.3.1 and 10.3.2 of the Chopin-Papaspiliopoulos (they derive these algorithms from a slightly more general viewpoint involving Feynman-Kac models which are described in Chapter 5 of their book)

2. The local level model with non-Gaussian errors for estimating piecewise constant trend functions is discussed in Section 15.2.6 of the Kitagawa book, and in Section 8.4 of the Kitagawa-Gersch book.

# 19 Lecture Nineteen

The goal today is to study Monte Carlo methodology for smoothing in general state space models. We shall focus on two smoothing algorithms:

1. Complete Smoothing: This method is simple and is just an extension of the particle filter algorithm. However it generally suffers from particle degeneracy.   
2. FFBS: This is based on general smoothing ideas that we previously saw in the context of linear Gaussian models. The method works well but is computationally intensive.

# 19.1 Complete Smoothing

This algorithm is an extension of particle filtering (and can also be termed complete filtering). It generates, for each $t \geq 0$ , samples

$$
(X _ {0 | t} ^ {(i)}, X _ {1 | t} ^ {(i)}, \ldots , X _ {t | t} ^ {(i)}), 1 \leq i \leq N
$$

such that the discrete uniform distribution over these samples approximates the smoothing distribution at time $t$ :

$$
\frac {1}{N} \sum_ {i = 1} ^ {N} \delta_ {\left\{\left(X _ {0 | t} ^ {(i)}, X _ {1 | t} ^ {(i)}, \dots , X _ {t | t} ^ {(i)}\right) \right\}} \approx \left(X _ {0}, \dots , X _ {t}\right) \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta \tag {119}
$$

for each $t = 0 , \ldots , T$ .

The algorithmaccess to samples $t = 0 , 1 , \ldots , T$ . At time fying (119) $t - 1$ , onime $( X _ { 0 | t - 1 } ^ { ( i ) } , X _ { 1 | t - 1 } ^ { ( i ) } , \ldots , X _ { t - 1 | t - 1 } ^ { ( i ) } ) , 1 \leq i \leq N$ $t - 1$ and using these, one generates the samples $( X _ { 0 | t } ^ { ( i ) } , X _ { 1 | t } ^ { ( i ) } , \ldots , X _ { t | t } ^ { ( i ) } ) , 1 \leq i \leq N$ by following the three steps given below.

1. Generation: For each $i = 1 , \ldots , N$ , let

$$
\tilde {X} _ {0 | t} ^ {(i)} = X _ {0 | t - 1} ^ {(i)}, \ldots , \tilde {X} _ {t | t} ^ {(i)} = X _ {t - 1 | t - 1} ^ {(i)}
$$

and

$$
\tilde {X} _ {t | t} ^ {(i)} \sim q (\cdot | x = X _ {t - 1 | t - 1} ^ {(i)}, y = y _ {t}, \theta).
$$

2. Weights: For each $i = 1 , \ldots , N$ , compute

$$
w _ {t} ^ {(i)} := \frac {f _ {X _ {t} | X _ {t - 1} = X _ {t - 1 | t - 1} ^ {(i)} , \theta} (\tilde {X} _ {t | t} ^ {(i)}) f _ {Y _ {t} | X _ {t} = \tilde {X} _ {t | t} ^ {(i)} , \theta} (y _ {t})}{q _ {t} \left(\tilde {X} _ {t | t} ^ {(i)} \mid x = X _ {t - 1 | t - 1} ^ {(i)}, y = y _ {t} , \theta\right)} \tag {120}
$$

Normalize these weights so they sum to one:

$$
W _ {t} ^ {(i)} = \frac {w _ {t} ^ {(i)}}{w _ {t} ^ {(1)} + \cdots + w _ {t} ^ {(N)}} \qquad \mathrm {f o r} i = 1, \ldots , N.
$$

3. Resampling: Generate

$$
(X _ {0 | t} ^ {(i)}, X _ {1 | t} ^ {(i)}, \ldots , X _ {t | t} ^ {(i)}), 1 \leq i \leq N \stackrel {\mathrm {i . i . d}} {\sim} \sum_ {i = 1} ^ {N} W _ {t} ^ {(i)} \delta_ {\{(\tilde {X} _ {0 | t} ^ {(i)}, \ldots , \tilde {X} _ {t | t} ^ {(i)}) \}}.
$$

The following are useful things to know about this algorithm:

1. The weights in (120) can be deduced from importance sampling. To see this, note that the generation of $( \tilde { X } _ { 0 | t } ^ { ( i ) } , \ldots , \tilde { X } _ { t | t } ^ { ( i ) } )$ is from (approximately) the density:

$$
f _ {t - 1 | t - 1} (x _ {0}, \ldots , x _ {t - 1}) q (x _ {t} \mid x _ {t - 1}, y _ {t}, \theta).
$$

where we are using the notation:

$$
f _ {s | t} (x _ {0}, \ldots , x _ {s}) := f _ {X _ {0}, \ldots , X _ {s} | Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {0}, \ldots , x _ {s}).
$$

On the other hand, the target density equals

$$
\begin{array}{l} f _ {t | t} (x _ {0}, \ldots , x _ {t}) = f _ {X _ {0}, \ldots , X _ {t} | Y _ {0} = y _ {0}, \ldots , Y _ {t} = y _ {t}, \theta} (x _ {0}, \ldots , x _ {t}) \\ = \frac {f _ {t | t - 1} (x _ {0} , \dots , x _ {t - 1}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \dots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \\ = \frac {f _ {t - 1 | t - 1} (x _ {0} , \ldots , x _ {t - 1}) f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{f _ {Y _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \\ \end{array}
$$

where we used Bayes rule in the second step. The importance weights are therefore given by

$$
\begin{array}{l} \frac {f _ {t | t} (x _ {0} , \ldots , x _ {t})}{f _ {t - 1 | t - 1} (x _ {0} , \ldots , x _ {t - 1}) q (x _ {t} \mid x _ {t - 1} , y _ {t} , \theta)} \\ = \frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{q (x _ {t} | x _ {t - 1} , y _ {t} , \theta)} \frac {1}{f _ {Y _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t - 1} = y _ {t - 1} , \theta} (y _ {t})} \\ \end{array}
$$

Note that second term above (inverse of $f _ { Y _ { t } | Y _ { 0 } = y _ { 0 } , \ldots , Y _ { t - 1 } = y _ { t - 1 } , \theta } ( y _ { t } ) )$ is a constant as it does not depend on $x t - 1$ or $x _ { t }$ . We can thus view the importance weight as simply

$$
\frac {f _ {X _ {t} | X _ {t - 1} = x _ {t - 1} , \theta} (x _ {t}) f _ {Y _ {t} | X _ {t} = x _ {t} , \theta} (y _ {t})}{q (x _ {t} | x _ {t - 1} , y _ {t} , \theta)}.
$$

$w _ { t } ^ { ( i ) }$ $x _ { t - 1 } = X _ { t - 1 | t - 1 } ^ { ( i ) }$ $x _ { t } = \tilde { X } _ { t \mid t } ^ { ( i ) }$

2. This algorithm needs to be initialized with samples from $X _ { 0 } \mid Y _ { 0 } = y _ { 0 } , \theta$ :

$$
X _ {0 | 0} ^ {(1)}, \ldots , X _ {0 | 0} ^ {(N)}.
$$

After the first iteration, it outputs samples:

$$
X _ {0 | 1} ^ {(1)}, \ldots , X _ {0 | 1} ^ {(N)}
$$

$$
X _ {1 | 1} ^ {(1)}, \ldots , X _ {1 | 1} ^ {(N)}.
$$

Note that X(1)0|1 , . $X _ { 0 | 1 } ^ { ( 1 ) } , \dots , X _ { 0 | 1 } ^ { ( N ) }$ is a resample drawn from the initial sample $X _ { 0 | 0 } ^ { ( 1 ) } , \ldots , X _ { 0 | 0 } ^ { ( N ) }$ . After the second iteration, the algorithm outputs samples:

$$
X _ {0 | 2} ^ {(1)}, \ldots , X _ {0 | 2} ^ {(N)}
$$

$$
X _ {1 | 2} ^ {(1)}, \ldots , X _ {1 | 2} ^ {(N)}
$$

$$
X _ {2 | 2} ^ {(1)}, \ldots , X _ {2 | 2} ^ {(N)}
$$

Here X (1), . $X _ { 0 | 2 } ^ { ( 1 ) } , \ldots , X _ { 0 | 2 } ^ { ( N ) }$ . , X (N ) is a resample of $X _ { 0 | 1 } ^ { ( 1 ) } , \ldots , X _ { 0 | 1 } ^ { ( N ) }$ which was already a resample from $X _ { 0 | 0 } ^ { ( 1 ) } , \ldots , X _ { 0 | 0 } ^ { ( N ) }$ . Also X (1)1|2 , . . . , X (N )1|2 i X $X _ { 1 | 2 } ^ { ( 1 ) } , \ldots , X _ { 1 | 2 } ^ { ( N ) }$ s a resample from X (1), . $X _ { 1 | 1 } ^ { ( 1 ) } , \ldots , X _ { 1 | 1 } ^ { ( N ) }$ . . , . One then proceeds iteratively ending in the final step where the algorithm ouputs:

$$
\begin{array}{l} X _ {0 | T} ^ {(1)}, \ldots , X _ {0 | T} ^ {(N)} \\ X _ {1 | T} ^ {(1)}, \ldots , X _ {1 | T} ^ {(N)} \\ \dots \dots \dots \dots \dots \dots \tag {121} \\ \dots \\ X _ {T | T} ^ {(1)}, \ldots , X _ {T | T} ^ {(N)} \\ \end{array}
$$

The columns of the above output (121) in the final iteration of the algorithm are samples from the smoothing distribution of interest: $( X _ { 0 } , \dots , X _ { T } ) \mid Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } =$ $y _ { T } , \theta$ .

3. This algorithm is very similar to the Sequential Importance Resampling (SIR) algorithm from the last couple of lectures for filtering. Indeed, if we keep track of only the filtering samples i.e., the samples

$$
X _ {t | t} ^ {(1)}, \ldots X _ {t | t} ^ {(N)}
$$

for $t = 0 , 1 , \ldots , T$ , and ignore the set of time indices $s \mid t$ for $s < t$ , we get back the SIR algorithm.

4. Particle Degeneracy: This algorithm suffers from serious particle degeneracy. Specifically, he number of unique values $N _ { t }$ among $X _ { t | T } ^ { ( 1 ) } , \dots , X _ { t | T } ^ { ( N ) }$ can be much smaller $N$ is is especially tru are created in the or small values of  iteration and the $t$ . This is because the samples ubsequent samples $X _ { t | t } ^ { ( 1 ) } , \ldots , X _ { t | t } ^ { ( N ) }$ $t ^ { t h }$

$$
X _ {t | s} ^ {(1)}, \ldots , X _ {t | s} ^ {(N)} \qquad \mathrm {s = t + 1 , \ldots , T}
$$

are all obtained by resampling from X(1)t|t , . . . , X (N )t|t $X _ { t | t } ^ { ( 1 ) } , \ldots , X _ { t | t } ^ { ( N ) }$ with various choices of weights.

This means that X (1)t|T , . . . , X (N )t|T a $X _ { \underline { { t } } | T } ^ { ( 1 ) } , \dots , X _ { t | T } ^ { ( N ) }$ re obtained after resampling T −t times from $T - t$ X (1)t|t , . . . , X (N )t|t . $X _ { \underline { { t } } | t } ^ { ( 1 ) } , \dots , X _ { t | t } ^ { ( N ) }$ Every resampling leads to a decrease in the effective sample size, and thus if $T - t$ i s large (which will be the case for small $t$ ), the number of unique samples will be much smaller than $N$ .

Computational Complexity: The complexity of this algorithm is $O ( N T )$ . This is because in each iteration of the algorithm, $O ( N )$ computations are done (note that weights need to be calculated for each of the generated samples). The final complexity is therefore $O ( N T )$ as there are $T$ iterations.

# 19.2 FFBS

This algorithm is similar to the FFBS (Forward Filtering Backward Sampling) algorithms that we studied previously for linear Gaussian state space models (we also previously looked at a numerical version of FFBS for general state space models).

The goal of FFBS is to generate $M$ samples:

$$
\left(X _ {0 | T} ^ {(i)}, X _ {1 | T} ^ {(i)}, \ldots , X _ {T | T} ^ {(i)}\right) \qquad \text {f o r} i = 1, \ldots , M
$$

form the conditional distribution

$$
\left(X _ {0}, \dots , X _ {T}\right) \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta .
$$

Note that we are using the notation $M$ for the number of smoothing samples.

The first step in FFBS is to run a particle filtering algorithm. This will result in samples:

$$
\mathcal {X} _ {t \mid t} ^ {(1)}, \dots , \mathcal {X} _ {t \mid t} ^ {(N)} \tag {122}
$$

for each $t = 0 , \ldots , T$ . The discrete uniform distribution over the samples (122) approximates the filtering distribution $X _ { t } ~ \mid ~ Y _ { 0 } = y _ { 0 } , \dotsc , Y _ { t } = y _ { t } , \theta$ for each $t = 0 , 1 , \ldots , T$ . Note that, because of the resampling stepnot be any connection between $\chi _ { t - 1 | t - 1 } ^ { ( i ) }$ −1 X (i)t|t re usand $\mathcal { X } _ { t \vert t } ^ { ( i ) }$ n particle for fixed for fixed $i$ filtering algorithms, there need(in the notation of our filtering (in the notation of our filtering algorithms, $\chi _ { t - 1 | t - 1 } ^ { ( i ) }$ 1 nd X˜(i)t a $\tilde { \mathcal { X } } _ { t } ^ { ( i ) }$ would be related but there won’t be any connection between $\tilde { \mathcal { X } } _ { t } ^ { ( i ) }$ and $\underset { \cdot } { \chi } _ { t | t } ^ { ( i ) }$ because of resampling). I am using the notation $\mathcal { X }$ (instead of the usual $X$ ) for the filtering particles to distinguish them from the smoothing samples which will be subsequently generated by FFBS.

Observe that we have $N$ filtering samples for each time $t$ . This $N$ can be distinct from the desired number $M$ of smoothing samples.

The step of running a particle filter algorithm represents the “FF” part of FFBS. We shall now describe the “BS” (Backward Sampling) part of the algorithm. Here, for each $i = 1 , \dots , M$ , we shall generate samples

$$
X _ {T | T} ^ {(i)}, X _ {T - 1 | T} ^ {(i)}, \ldots , X _ {0 | T} ^ {(i)}
$$

in backward order for t = T, . . . , 0. The first sample X(i)T|T $t = T , \dots , 0$ $X _ { T | T } ^ { ( i ) }$ is just drawn from the discrete filtering approximation for $t \ = \ T$ (this is because the filtering and smoothing marginal distributions for $t = T$ coincide):

$$
X _ {T | T} ^ {(i)} \sim \mathrm {U n i f} \left\{\mathcal {X} _ {T | T} ^ {(1)}, \ldots , \mathcal {X} _ {T | T} ^ {(N)} \right\} = \frac {1}{N} \sum_ {j = 1} ^ {N} \delta_ {\{\mathcal {X} _ {T | T} ^ {(j)} \}}.
$$

The recursive process for obtaining the subsequent samples $X _ { T - 1 | T } ^ { ( i ) } , \ldots , X _ { 0 | T } ^ { ( i ) }$ is described next.(below $X _ { t + 1 | T } ^ { ( i ) }$ to X $X _ { t | T } ^ { ( i ) }$ , we would need to generate from the conditional density $x _ { t + 1 } : = X _ { t + 1 | T } ^ { ( i ) } )$

$$
\begin{array}{l} f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta} (x _ {t}) = f _ {X _ {t} | X _ {t + 1} = x _ {t + 1}, Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}) \\ = \frac {f _ {X _ {t} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (x _ {t}) f _ {X _ {t + 1} | X _ {t} = x _ {t} , \theta} (x _ {t + 1})}{f _ {X _ {t + 1} | Y _ {0} = y _ {0} , \ldots , Y _ {t} = y _ {t} , \theta} (x _ {t + 1})}. \\ \end{array}
$$

A natural idea of generating $X _ { t | T } ^ { ( i ) }$ is to therefore use importance sampling where we first generate from a proposal density $q ( x _ { t } \mid x _ { t + 1 } , \mathrm { d a t a } , \theta )$ and then use the weight:

$$
\begin{array}{l} \operatorname {w e i g h t} (x _ {t}) = \frac {f _ {X _ {t} | X _ {t + 1} = x _ {t + 1} , Y _ {0} = y _ {0} , \dots , Y _ {T} = y _ {T} , \theta} (x _ {t})}{q (x _ {t} | x _ {t + 1} , \text {d a t a} , \theta)} \\ = \frac {f _ {X _ {t} | Y _ {0} = y _ {0} , . . . , Y _ {t} = y _ {t} , \theta} (x _ {t}) f _ {X _ {t + 1} | X _ {t} = x _ {t} , \theta} (x _ {t + 1})}{q (x _ {t} \mid x _ {t + 1} , \mathrm {d a t a} , \theta)} \frac {1}{f _ {X _ {t + 1} | Y _ {0} = y _ {0} , . . . , Y _ {t} = y _ {t} , \theta} (x _ {t + 1})} \\ \propto \frac {f _ {X _ {t} \mid Y _ {0} = y _ {0} , \dots , Y _ {t} = y _ {t} , \theta} (x _ {t}) f _ {X _ {t + 1} \mid X _ {t} = x _ {t} , \theta} (x _ {t + 1})}{q \left(x _ {t} \mid x _ {t + 1} , \text {d a t a} , \theta\right)}. \tag {123} \\ \end{array}
$$

The proportionality sign above is in terms of $x _ { t }$ (factors not depending on $x _ { t }$ can be taken as part of the proportionality).

Any proposal density $q ( x _ { t } \mid x _ { t + 1 } , \mathrm { d a t a } , \theta )$ can be used for this purpose. However, it is especially convenient to take it as the filtering density at time $t$ :

$$
q \left(x _ {t} \mid x _ {t + 1}, \text {d a t a}, \theta\right) = f _ {X _ {t} \mid Y _ {0} = y _ {0}, \dots , Y _ {t} = y _ {t}, \theta} (x _ {t}) \tag {124}
$$

for the following two reasons:

$\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ from the filtering density at time $t$ because of implementing a filtering algorithm in the first step of FFBS.   
2. With the choice (124), the weights in (123) become quite simple:

$$
\operatorname {w e i g h t} \left(x _ {t}\right) \propto f _ {X _ {t + 1} \mid X _ {t} = x _ {t}, \theta} \left(x _ {t + 1}\right).
$$

With the choice (124), the method for generating $X _ { t | T } ^ { ( i ) }$ from $X _ { t + 1 | T } ^ { ( i ) }$ becomes:

$$
X _ {t \mid T} ^ {(i)} \sim \sum_ {j = 1} ^ {N} W _ {j} \delta_ {\left\{\mathcal {X} _ {t \mid t} ^ {(j)} \right\}} \tag {125}
$$

where

$$
W _ {j} = \frac {w _ {j}}{w _ {1} + \ldots w _ {N}} \qquad \mathrm {a n d} w _ {j} = f _ {X _ {t + 1} | X _ {t} = \mathcal {X} _ {t | t} ^ {(j)}, \theta} (X _ {t + 1 | T} ^ {(i)}).
$$

(125) just means that $X _ { t | T } ^ { ( i ) }$ is just sampled from the discrete distribution that is concentrated on the filtering samples X (1)t|t , $\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ with weights $w _ { 1 } , \ldots , w _ { N }$ .

The overall FFBS algorithm is therefore:

1. Filtering: Run a particle filter algorithm to generate samples $\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ which approximate the filtering distribution $X _ { t } ~ \mid ~ Y _ { 0 } = y _ { 0 } , \dotsc , Y _ { t } = y _ { t } , \theta$ at each time $t =$ $0 , 1 , \ldots , T$ .   
2. Repeat the following for $i = 1 , \dots , M$

a) Initialization for Backward Recursion: Draw one sample $X _ { T | T } ^ { ( i ) }$ from the $\chi _ { T | T } ^ { ( 1 ) } , \dots , \chi _ { T | T } ^ { ( N ) }$ .   
b) Backward Recursion: Repeat the following $t = T ^ { \prime } - 1 , \dots , 0$ :

i. Calculate weights $w _ { j } = f _ { _ { X _ { t + 1 } | X _ { t } = \mathcal { X } _ { t | t } ^ { ( j ) } , \theta } } ( X _ { t + 1 | T } ^ { ( i ) } )$ for each $j = 1 , \ldots , N$ . Normalize these weights to obtain $W _ { 1 } , \dots , W _ { N }$ which sum to one.   
ii. Generate (i) $X _ { t | T } ^ { ( i ) }$ from the discrete distribution on (1), . $\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ Xt|t  . . , (N ) Xt|t with probabilities $W _ { 1 } , \ldots , W _ { N }$ .

# 19.3 Recommended Reading for Today

1. The complete smoothing algorithm is described in Section 15.3 of the Kitagawa book, Section 11.1 of the S¨arkk¨a book, and Section 12.1.2 of the Chopin-Papaspiliopoulos book.

2. The FFBS algorithm is described in Section 12.3.2 of the Chopin-Papaspiliopoulos book, and in Section 11.2 of the S¨arkk¨a book (S¨arkk¨a calls it the Backward-Simulation Particle Smoother algorithm).

# 20 Lecture Twenty

# 20.1 Recap: Complete Smoothing

In the last class, we studied two algorithms for smoothing in general state space models. These algorithms produce samples

$$
(X _ {0 | T} ^ {(i)}, \ldots , X _ {T | T} ^ {(i)}), 1 \leq i \leq M
$$

which approximate the smoothing distribution $( X _ { 0 } , \dots , X _ { T } ) \mid Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T } , \theta$ . The first of these algorithms was the complete smoothing algorithm (also known as the SIR-PS: Sequential Importance Resampling Particle Smoother). This algorithm works in the following way:

1. Draw $M$ samples $X _ { 0 } ^ { ( 1 ) } , \ldots , X _ { 0 } ^ { ( M ) }$ from the conditional distribution of $X _ { 0 } \mid Y _ { 0 } = y _ { 0 } , \theta$   
2. Repeat the following for each $t = 1 , \dots , T$ :

a) Draw M new samples X(1)t , $M$ $X _ { t } ^ { ( 1 ) } , \dots , X _ { t } ^ { ( M ) }$ from the importance distribution:

$$
X _ {t} ^ {(i)} \stackrel {\mathrm {i n d e p e n d e n t}} {\sim} q (\cdot \mid x _ {t - 1} = X _ {t - 1} ^ {(i)}, Y _ {t} = y _ {t}, \theta) \qquad \mathrm {f o r} i = 1, \ldots , M.
$$

b) Calculate weights

$$
w _ {t} ^ {(i)} = \frac {f _ {Y _ {t} | X _ {t} = X _ {t} ^ {(i)}} (y _ {t}) f _ {X _ {t} | X _ {t - 1} = X _ {t - 1} ^ {(i)}} (X _ {t} ^ {(i)})}{q (X _ {t} ^ {(i)} | X _ {t - 1} ^ {(i)} , y _ {t})} \qquad \mathrm {f o r} i = 1, \ldots , M.
$$

Renormalize these weights to obtain $W _ { t } ^ { ( i ) } , i = 1 , \dots , M$ which sum to one.

c) Append the samples to the state histories:

$$
X _ {0: t} ^ {(i)} = \left(X _ {0: t - 1} ^ {(i)}, X _ {t} ^ {(i)}\right).
$$

$X _ { 0 : t } ^ { ( 1 ) } , \dots , X _ { 0 : t } ^ { ( M ) }$ with probabilities $W _ { t } ^ { ( 1 ) } , \dots , W _ { t } ^ { ( M ) }$ , . . . , W (M )t .

The above description of the complete smoothing algorithm is slightly different from that given in the previous class but algorithm is exactly the same. Its computational complexity is $O ( M T )$ .

# 20.2 Complete Smoothing with partial trajectory resampling

The main problem wcally, for the samplesof unique values amo $( X _ { 0 } ^ { ( i ) } , \ldots , X _ { T } ^ { ( i ) } ) , 1 \le i \le M$ g algorithm is particle de obtained in the final iter quite small (compared to eracy. Specifi-on, the number) especially for $X _ { t } ^ { ( 1 ) } , \dots , X _ { t } ^ { ( M ) }$ (1) , . . . , X (M )t w $M$

small values of $t$ . This is because a fixed number of particles (M) are repeatedly being resampled. Otrajectories $X _ { 0 : t } ^ { ( 1 ) } , \dots , X _ { 0 : t } ^ { ( M ) }$ dhoc, fix to this problem is to resample, instead of the full state, just the trajectories

$$
X _ {t - L: t} ^ {(1)}, \ldots , X _ {t - L: t} ^ {(M)}
$$

for some fixed $L$ . Of course, here we are assuming that $t \geq L$ (if $t < L$ , the resamping is done as before from the full trajectories). This method fixes the particle degeneracy issue and the marginal samples $y _ { 0 } , . . . , Y _ { T } = y _ { T } , \theta$ $X _ { t } ^ { ( 1 ) } , \dots , X _ { t } ^ { ( M ) }$ t ( i f $L$ is not too small). However, the final trajectories . . , X (M )t w ill have distribution which is nearly the same as $X _ { 0 : T } ^ { ( 1 ) } , \ldots , X _ { 0 : T } ^ { ( M ) }$ $X _ { t } \mid Y _ { 0 } =$ no longer be treated as samples from $X _ { 0 } , \dots , X _ { T } \mid Y _ { 0 } = y _ { 0 } , \dots , Y _ { T } = y _ { T } , \theta$ .

Another way of thinking about this partial trajectory resampling fix is the following. The main problem with the complete smoothing algorithm is that it gives poor approximation, due to particle degeneracy, to the smoothing distributions of $X _ { s }$ (given $Y _ { 0 } = y _ { 0 } , \ldots , Y _ { T } =$ $y _ { T } , \theta )$ when $s$ is small. More generally, the samples will provide a poor approximation to the joint distribution:

$$
X _ {s _ {1}}, X _ {s _ {2}}, \dots , X _ {s _ {k}} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta \tag {126}
$$

when $s _ { 1 } < \cdots < s _ { k }$ and $s _ { k }$ is small. One heuristic way to obtain better approximation of this joint density is as follows. First reason that

$$
\begin{array}{l} X _ {s _ {1}}, X _ {s _ {2}}, \dots , X _ {s _ {k}} \mid Y _ {0} = y _ {0}, \dots , Y _ {T} = y _ {T}, \theta \tag {127} \\ \approx X _ {s _ {1}}, X _ {s _ {2}}, \ldots , X _ {s _ {k}} \mid Y _ {0} = y _ {0}, \ldots , Y _ {s _ {k} + L} = y _ {s _ {k} + L}, \theta \\ \end{array}
$$

for some fixed $L$ that is much smaller than $T - s _ { k }$ . The idea is that the observation values $Y _ { t } = y _ { t }$ for $t$ larger than $s _ { k } + L$ probably do not have much influence on the distribution of $X _ { s _ { 1 } } , \ldots , X _ { s _ { k } }$ . Under the approximation (127), the full smoothing distribution (126) can therefore be obtained by the right hand side of (127) which is well-approximated by the complete smoothing algorithm at iteration $s _ { k } + L$ . In other words, we don’t need to run the complete smoothing algorithm till iteration $T$ to approximate (126). The amount of resampling at iteration $s _ { k } + L$ will be much smaller than until time $T$ and this will lead to much less particle degeneracy. It is tricky however to choose an appropriate value of $L$ (one usually just takes an arbitrary value such as $L = 3 0$ ).

# 20.3 Recap: FFBS

The FFBS algorithm is:

1. Filtering: Run a particle filter algorithm to generate samples $\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ which approximate the filtering distribution $X _ { t } ~ \mid ~ Y _ { 0 } = y _ { 0 } , \dotsc , Y _ { t } = y _ { t } , \theta$ at each time $t =$ $0 , 1 , \ldots , T$ .   
2. Repeat the following for $i = 1 , \dots , M$

a) Initialization for Backward Recursion: Draw one sample discrete uniform distribution on $\chi _ { T | T } ^ { ( 1 ) } , \dots , \chi _ { T | T } ^ { ( N ) }$ . $X _ { T | T } ^ { ( i ) }$ from the   
b) Backward Recursion: Repeat the following $t = T ^ { \prime } - 1 , \dots , 0$ :

i. Calculate weights $w _ { j } = f _ { _ { X _ { t + 1 } | X _ { t } = \mathcal { X } _ { t | t } ^ { ( j ) } , \theta } } ( X _ { t + 1 | T } ^ { ( i ) } )$ for each $j = 1 , \ldots , N$ . Normalize these weights to obtain $W _ { 1 } , \dots , W _ { N }$ which sum to one.

ii. Generate (i) $X _ { t | T } ^ { ( i ) }$ from the discrete distribution on (1) $\mathcal { X } _ { t | t } ^ { ( 1 ) } , \ldots , \mathcal { X } _ { t | t } ^ { ( N ) }$ with probabilities $W _ { 1 } , \dots , W _ { N }$ .

The level of particle degeneracy of this algorithm can be checked by looking at the number of unique values among $X _ { t | T } ^ { ( 1 ) } , \dots , X _ { t | T } ^ { ( M ) }$ for each $t = 0 , \ldots , T$ . Generally, particle degeneracy is not a problem for FFBS. The issue however is speed. Notice the double loop present in the algorithm (an outer loop over $i = 1 , \dots , M$ and then an inner loop over $t = T - 1 , \dots , 0$ ). In the inner loop, there is a calculation of $N$ weights. The total computational complexity is therefore $O ( M N T )$ . The FFBS algorithm will therefore be much slower compared to the complete smoothing algorithms. However, as there is not much particle degeneracy, one can afford to choose $M$ to be much smaller than $N$ (e.g., $M$ can be of the order of a few hundreds while $N$ is in the order of tens of thousands).

# 20.4 Recommended Reading for Today

1. The complete smoothing algorithm and the partial trajectory resampling variant are described in Section 15.3 of the Kitagawa book (see also Section 12.1 of the Chopin-Papaspiliopoulos book).   
2. The FFBS algorithm is described in Section 12.3.2 of the Chopin-Papaspiliopoulos book, and in Section 11.2 of the S¨arkk¨a book (S¨arkk¨a calls it the Backward-Simulation Particle Smoother algorithm). A technique for making FFBS faster is described in Section 12.3.3 of the Chopin-Papaspiliopoulos book.

# 21 Lecture Twenty One

# 21.1 Model Selection

We shall next look at the topic of model selection. This important problem appears in almost every data analysis. In our context of state space models, consider, for example, the problem of deciding between a local level model or a local linear model. This is the problem of Model Selection. There are Frequentist and Bayesian approaches to Model Selection. One popular frequentist approach is the AIC (Akaike Information Criterion) and one popular Bayesian approach is the BIC (Bayesian Information Criterion). We shall study these procedures.

# 21.2 Akaike Information Criterion (AIC)

The AIC for a model $M$ is defined as:

$$
A I C (M) := - 2 \times (\text {M a x i m i z e d} M) + 2 \times (\text {n u m b e r o f p a r a m e t e r s i n} M).
$$

This can be calculated for any model for which we can maximize likelihood. Let us look at the logic behind this criterion in the case of i.i.d models. State Space Models are not of this i.i.d kind but the analysis can be extended to them. Consider a dataset $y _ { 1 } , \ldots , y _ { n }$ . By an i.i.d model $M$ , we mean a model which postulates that $y _ { 1 } , \ldots , y _ { n }$ are realizations of random variables $Y _ { 1 } , \dots , Y _ { n }$ which satisfy

$$
Y _ {1}, \ldots , Y _ {n} \stackrel {\mathrm {i . i . d}} {\sim} p _ {\theta}
$$

for some family of densities $p \theta$ with a $p$ -dimensional parameter $\theta$ . The log-likelihood for this model is:

$$
\sum_ {i = 1} ^ {n} \log p _ {\theta} (y _ {i}).
$$

The maximizer of this log-likelihood is the MLE (Maximum Likelihood Estimator) $\hat { \theta } _ { n }$ . The AIC for this model is thus:

$$
A I C (M) = - 2 \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(y _ {i}\right) + 2 p \tag {128}
$$

The AIC for a different model $\tilde { M }$ which says that $Y _ { 1 } , \dots , Y _ { n }$ are i.i.d $q _ { \alpha }$ with a $q$ -dimensional parameter $\alpha$ is

$$
A I C (\tilde {M}) = - 2 \sum_ {i = 1} ^ {n} \log q _ {\hat {\alpha} _ {n}} (y _ {i}) + 2 q \tag {129}
$$

The logic behind the AIC formulae (128) and (129) is explained below.

# 21.2.1 The simple case of no parameters

Consider first the case where we consider models with no parameters. Specifically, $M$ is the model $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } p$ and $\tilde { M }$ is the model $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } q$ . In this case, the AIC is simply the negative log-likelihood (multiplied by 2). In other words, we prefer the model with the higher loglikelihood. This makes sense and one of the explanations for looking at the loglikelihood is the following. Suppose that the true data generating process is given by:

$$
Y _ {1}, \dots , Y _ {n} \stackrel {\text {i . i . d}} {\sim} f ^ {*}. \tag {130}
$$

It then makes sense to pick $p$ or $q$ depending on how close they are to $f ^ { * }$ . This obviously depends on the specific way in which “closeness” is measured. One common choice is the Kullback-Leiber divergence:

$$
D (f ^ {*} \| p) := \int f ^ {*} \log {\frac {f ^ {*}}{p}} = \int f ^ {*} \log f ^ {*} - \int f ^ {*} \log p,
$$

and similarly

$$
D (f ^ {*} \| q) := \int f ^ {*} \log \frac {f ^ {*}}{q} = \int f ^ {*} \log f ^ {*} - \int f ^ {*} \log q,
$$

Note that the first term $\int f ^ { * } \log f ^ { * }$ is the same for both $D ( f ^ { * } \| p )$ and $D ( f ^ { * } \| q )$ . Thus comparing $D ( f ^ { * } \| p )$ and $D ( f ^ { * } \| q )$ is equivalent to comparing $\int f ^ { * } \log p$ and $\int f ^ { \ast } \log q$ . However $f ^ { * }$ is unknown so we cannot directly compare $\int f ^ { * } \log p$ and $\int f ^ { \ast } \log q$ . But a simple unbiased estimate of $\int f ^ { * } \log p$ is simply:

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p (Y _ {i})
$$

because the true data generating mechanism is (130). Similarly

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log q (Y _ {i})
$$

is unbiased for $\int f ^ { \ast } \log q$ . We thus compare

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p (Y _ {i}) \quad \text {a n d} \quad \frac {1}{n} \sum_ {i = 1} ^ {n} \log q (Y _ {i})
$$

and pick the model with the higher value. This is clearly the same as comparing likelihoods.

# 21.2.2 Models with parameters

Now suppose that the two models are given by

$$
\mathrm {M o d e l} M: Y _ {1}, \ldots , Y _ {n} \stackrel {\mathrm {i . i . d}} {\sim} p _ {\theta}
$$

and

$$
\text {M o d e l} \tilde {M}: Y _ {1}, \dots , Y _ {n} \stackrel {{\text {i . i . d}}} {{\sim}} q _ {\alpha}.
$$

The true data generating process is still (130). One can again consider the accuracy of estimating $f ^ { * }$ under the Kullback-Leibler divergence. Model $M$ would provide the estimate $p _ { \hat { \theta } _ { n } }$ and Model $\tilde { M }$ would provide the estimate $q _ { \hat { \alpha } _ { n } }$ for $f ^ { * }$ . Here $\hat { \theta } _ { n }$ is the MLE of $\theta$ under Model $M$ and $\hat { \alpha } _ { n }$ is the MLE of $\alpha$ under Model $\tilde { M }$ . The Kullback-Leibler divergences are

$$
D (f ^ {*} \| p _ {\hat {\theta} _ {n}}) = \int f ^ {*} \log f ^ {*} - \int f ^ {*} \log p _ {\hat {\theta} _ {n}}
$$

and

$$
D (f ^ {*} \| q _ {\hat {\alpha} _ {n}}) = \int f ^ {*} \log f ^ {*} - \int f ^ {*} \log q _ {\hat {\alpha} _ {n}}
$$

Thus comparing the Kullback-Leibler divergences is equivalent to comparing

$$
\int f ^ {*} \log p _ {\hat {\theta} _ {n}} \mathrm {a n d} \int f ^ {*} \log q _ {\hat {\alpha} _ {n}}.
$$

As we do not know $f ^ { * }$ , we would need to estimate the above integrals from the data $y _ { 1 } , \ldots , y _ { n }$ generating according to (130). Natural estimators are given by

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} (Y _ {i}) \quad \mathrm {a n d} \quad \frac {1}{n} \sum_ {i = 1} ^ {n} \log q _ {\hat {\alpha} _ {n}} (Y _ {i}).
$$

However, unlike in the case where there are no parameters, these are no longer unbiased estimators of $\int f ^ { * } \log p _ { \hat { \theta } _ { n } }$ and $\int f ^ { * } \log q _ { \hat { \alpha } _ { n } }$ respectively. Indeed, we would expect $\begin{array} { r } { \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \log p _ { \hat { \theta } _ { n } } ( Y _ { i } ) } \end{array}$ to be larger than $\int f ^ { * } \log p _ { \hat { \theta } _ { n } }$ and this will be especially true if $p \theta$ is a complicated model which overfits the data. In order to correct the bias, we need to understand the quantity:

$$
\int f ^ {*} \log p _ {\hat {\theta} _ {n}} - \frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(Y _ {i}\right), \tag {131}
$$

and the analogous quantity for the second model. In order to estimate the above quantity, we need to know something about the behaviour of the maximum likelihood estimator $\hat { \theta } _ { n }$ .

# 21.2.3 Digression: MLE asymptotic distribution

Given data $y _ { 1 } , \ldots , y _ { n }$ and a candidate model which stipulates $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } p _ { \theta }$ , consider the behaviour of the MLE:

$$
\hat {\theta} _ {n} := \operatorname * {a r g m a x} _ {\theta} \left(\sum_ {i = 1} ^ {n} \log p _ {\theta} (y _ {i})\right).
$$

The asymptotic behaviour of the MLE is usually studied under two assumptions: wellspecified model and misspecified model.

MLE Asymptotics when model is correctly specified: By “model is correctly specified”, we assume that the observed data are realizations of random variables $Y _ { 1 } , \dots , Y _ { n }$ which

are independent and identically distributed according to $p _ { \theta ^ { \ast } }$ for some $\theta ^ { * }$ . In other words, the true data generating distribution belongs to the candidate model class $\{ p _ { \theta } \}$ . In this case, the MLE $\hat { \theta } _ { n }$ is an accurate estimator of $\theta ^ { * }$ . More precisely, it can be shown that

$$
\sqrt {n} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \stackrel {\mathrm {L}} {\rightarrow} N \left(0, \left(I \left(\theta^ {*}\right)\right) ^ {- 1}\right) \tag {132}
$$

where $I ( \theta ^ { * } )$ is the Fisher information matrix:

$$
\begin{array}{l} I \left(\theta^ {*}\right) := \mathbb {E} _ {\theta^ {*}} \left\{ \right.\left.\left(\nabla_ {\theta} \log p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right)\left(\nabla_ {\theta} \log p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right) ^ {T} \right\} \\ = \mathbb {E} _ {\theta^ {*}} \left\{\frac {\left(\nabla_ {\theta} p _ {\theta} (Y) \Big | _ {\theta = \theta^ {*}}\right) \left(\nabla_ {\theta} p _ {\theta} (Y) \Big | _ {\theta = \theta^ {*}}\right) ^ {T}}{p _ {\theta^ {*}} ^ {2} (Y)} \right\} = \int \frac {\left(\nabla_ {\theta} p _ {\theta} (y) \Big | _ {\theta = \theta^ {*}}\right) \left(\nabla_ {\theta} p _ {\theta} (y) \Big | _ {\theta = \theta^ {*}}\right) ^ {T}}{p _ {\theta^ {*}} (y)} d y. \\ \end{array}
$$

Here $\mathbb { E } _ { \theta ^ { * } }$ denotes Expectation taken under the assumption $Y \sim p _ { \theta ^ { * } }$ . $I ( \theta ^ { * } )$ is a $p \times p$ matrix where $p$ is the dimension of $\theta ^ { * }$ . According to the above definition, the $( i , j ) ^ { t h }$ entry of $I ( \theta ^ { * } )$ is given by

$$
\mathbb {E} _ {\theta^ {*}} \left\{\frac {\partial (\log p _ {\theta} (Y))}{\partial \theta_ {i}} \Bigg | _ {\theta = \theta^ {*}} \frac {\partial (\log p _ {\theta} (Y))}{\partial \theta_ {j}} \Bigg | _ {\theta = \theta^ {*}} \right\} \tag {133}
$$

A sketch of the proof of (132) can be found in the next subsection in the more general setting of model misspecification.

It is important to note that the Fisher Information Matrix has two alternative formulae in this correctly specified case. The first is that

$$
I \left(\theta^ {*}\right) = \operatorname {C o v} _ {\theta^ {*}} \left(\nabla_ {\theta} \log p _ {\theta} (Y) \Big | _ {\theta = \theta^ {*}}\right) \tag {134}
$$

where $\operatorname { C o v } _ { \theta ^ { * } }$ denotes covariance taken under the assumption $Y \sim p _ { \theta ^ { * } }$ . To see this, note first that $\mathrm { C o v } ( Z ) = \mathbb { E } ( Z Z ^ { \varGamma } ) - ( \mathbb { E } Z ) ( \mathbb { E } Z ) ^ { \varGamma }$ . Thus to see why this alternative formula of $I ( \theta ^ { * } )$ is true, we only need to show that

$$
\mathbb{E}_{\theta^{*}}\left(\nabla_{\theta}\log p_{\theta}(Y)\bigg|_{\theta = \theta^{*}}\right) = 0
$$

This is true because

$$
\begin{array}{l} \mathbb{E}_{\theta^{*}}\left(\nabla_{\theta}\log p_{\theta}(Y)\bigg|_{\theta = \theta^{*}}\right) = \mathbb{E}_{\theta^{*}}\frac{\nabla_{\theta}p_{\theta}(Y)\bigg|_{\theta = \theta^{*}}}{p_{\theta^{*}}(Y)} \\ = \int \frac {\nabla_ {\theta} p _ {\theta} (y) \Big | _ {\theta = \theta^ {*}}}{p _ {\theta^ {*}} (y)} p _ {\theta^ {*}} (y) d y \\ = \int \nabla_ {\theta} p _ {\theta} (y) \bigg | _ {\theta = \theta^ {*}} d y = \nabla_ {\theta} \left(\int p _ {\theta} (y) d y\right) \bigg | _ {\theta = \theta^ {*}} = \nabla_ {\theta} (1) \bigg | _ {\theta = \theta^ {*}} = 0. \\ \end{array}
$$

Note that we have interchanged the two operations of integation with respect to $y$ and differentiation with respect to $\theta$ . Some regularity conditions are necessary for such an interchange which we are ignoring in this treatment. This mean zero property validates the alternative formula (134).

The second alternative formula of Fisher Information is:

$$
I \left(\theta^ {*}\right) = - \mathbb {E} _ {\theta^ {*}} \left\{H _ {\theta} \log p _ {\theta} (Y) \Bigg | _ {\theta = \theta^ {*}} \right\} \tag {135}
$$

where $H _ { \theta }$ denotes Hessian. The $( i , j ) ^ { t h }$ entry of $I ( \theta ^ { * } )$ according to this formula is

$$
- \mathbb {E} _ {\theta^ {*}} \left\{\left. \frac {\partial^ {2} \log p _ {\theta} (Y)}{\partial \theta_ {i} \partial \theta_ {j}} \right| _ {\theta = \theta^ {*}} \right\} \tag {136}
$$

To verify the validity of this alternative formula, we need to prove that (133) and(136) are equal. For this, observe first that

$$
\begin{array}{l} \frac {\partial^ {2} \log p _ {\theta} (y)}{\partial \theta_ {i} \partial \theta_ {j}} = \frac {\partial}{\partial \theta_ {i}} \left[ \frac {\partial \log p _ {\theta} (y)}{\partial \theta_ {j}} \right] \\ = \frac {\partial}{\partial \theta_ {i}} \left[ \frac {1}{p _ {\theta} (y)} \frac {\partial p _ {\theta} (y)}{\partial \theta_ {j}} \right] \\ = \frac {1}{p _ {\theta} (y)} \frac {\partial^ {2} p _ {\theta} (y)}{\partial \theta_ {i} \partial \theta_ {j}} - \frac {1}{(p _ {\theta} (y)) ^ {2}} \left[ \frac {\partial p _ {\theta} (y)}{\partial \theta_ {i}} \right] \left[ \frac {\partial p _ {\theta} (y)}{\partial \theta_ {j}} \right] \\ = \frac {1}{p _ {\theta} (y)} \frac {\partial^ {2} p _ {\theta} (y)}{\partial \theta_ {i} \partial \theta_ {j}} - \left[ \frac {\partial \log p _ {\theta} (y)}{\partial \theta_ {i}} \right] \left[ \frac {\partial \log p _ {\theta} (y)}{\partial \theta_ {j}} \right]. \\ \end{array}
$$

As a result

$$
\begin{array}{l} - \mathbb{E}_{\theta^{*}}\left\{\frac{\partial^{2}\log p_{\theta}(Y)}{\partial\theta_{i}\partial\theta_{j}}\bigg|_{\theta = \theta^{*}}\right\} \\ = -\int \frac{1}{p_{\theta^{*}}(y)}\frac{\partial^{2}p_{\theta}(y)}{\partial\theta_{i}\partial\theta_{j}}\bigg|_{\theta = \theta^{*}}p_{\theta^{*}}(y)dy + \mathbb{E}_{\theta^{*}}\left\{\frac{\partial(\log p_{\theta}(Y))}{\partial\theta_{i}}\bigg|_{\theta = \theta^{*}}\frac{\partial(\log p_{\theta}(Y))}{\partial\theta_{j}}\bigg|_{\theta = \theta^{*}}\right\} \\ \end{array}
$$

The first term in the right hand side above equals zero because

$$
\begin{array}{l} - \int \frac {1}{p _ {\theta^ {*}} (y)} \frac {\partial^ {2} p _ {\theta} (y)}{\partial \theta_ {i} \partial \theta_ {j}} \Bigg | _ {\theta = \theta^ {*}} p _ {\theta^ {*}} (y) d y \\ = - \int \frac {\partial^ {2} p _ {\theta} (y)}{\partial \theta_ {i} \partial \theta_ {j}} \Bigg | _ {\theta = \theta^ {*}} d y = - \frac {\partial^ {2}}{\partial \theta_ {i} \partial \theta_ {j}} \left(\int p _ {\theta} (y) d y\right) \Bigg | _ {\theta = \theta^ {*}} = - \frac {\partial^ {2}}{\partial \theta_ {i} \partial \theta_ {j}} (1) \Bigg | _ {\theta = \theta^ {*}} = 0 \\ \end{array}
$$

and this proves that (133) and (136) are equal.

Here is some popular terminology that is used to describe these results:

1. The quantity $\theta \mapsto \nabla _ { \theta } \log p _ { \theta } ( y )$ is called the score function corresponding to the model $\{ p _ { \theta } \}$ .   
2. The Fisher Information Matrix is defined as the second moment of the score function evaluated at the true parameter value.   
3. When the model is correctly specified, The Fisher Information Matrix equals the covariance matrix of the score function evaluated at the true parameter value.   
4. When the model is correctly specified, the Fisher Information Matrix equals the negative of the Hessian of the log-likelihood evaluated at the true parameter value.

MLE Asymptotics when model is misspecified: Here we assume that the data $y _ { 1 } , \ldots , y _ { n }$ are generated according to the model $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } f ^ { * }$ where $f ^ { * }$ does not necessarily belong to the class $p \theta$ . In other words, $f ^ { * }$ may not equal $p \theta$ for any parameter value

$\theta$ . This means that there is no “true” parameter value $\theta ^ { * }$ anymore. So what exactly is the MLE $\hat { \theta } _ { n }$ estimating? It turns out that the MLE $\hat { \theta } _ { n }$ is really estimating the parameter value $\theta ^ { * }$ for which $P \theta ^ { * }$ is closest to $f ^ { * }$ in Kullback-Leibler divergence:

$$
\theta^{*}:= \operatorname *{argmin}_{\theta}D(f^{*}\| p_{\theta})
$$

Because $\begin{array} { r } { D ( f ^ { * } | | p _ { \theta } ) = \int f ^ { * } \log f ^ { * } - \int f ^ { * } \log p _ { \theta } } \end{array}$ , we can also define $\theta ^ { * }$ as

$$
\theta^ {*} := \underset {\theta} {\operatorname {a r g m a x}} \int f ^ {*} (y) \log p _ {\theta} (y) d y.
$$

In other words, $\theta ^ { * }$ can also be thought of as the maximizer of the average loglikelihood (averaged with respect to the true data generating density).

In this misspecified case, it again turns out that ${ \sqrt { n } } \left( { \hat { \theta } } _ { n } - \theta ^ { * } \right)$ converges to a zero mean multivariate normal distribution with some covariance matrix. However the covariance matrix now is not simply the inverse of the Fisher Information Matrix. To understand this, first let us consider the following simple example.

Example 21.1 (Normal Mean Model). Suppose $Y _ { 1 } , \ldots , Y _ { n } \stackrel { i . i . d } { \sim } f ^ { * }$ for some density $f ^ { * }$ Consider the model $N ( \theta , 1 )$ i.e.,

$$
p _ {\theta} (y) := (2 \pi) ^ {- 1 / 2} \exp \left(- \frac {(y - \theta) ^ {2}}{2}\right).
$$

Let us consider the misspecified setting where $f ^ { * }$ is not equal to $N ( \theta , 1 )$ for any $\theta$ . What is $\theta ^ { * }$ in this case? The loglikelihood averaged with respect to $f ^ { * }$ is:

$$
\begin{array}{l} \int f ^ {*} (y) \log p _ {\theta} (y) d y = \int f ^ {*} (y) \left\{- \frac {(y - \theta) ^ {2}}{2} - \frac {1}{2} \log (2 \pi) \right\} d y \\ = - \frac {1}{2} \int (y - \theta) ^ {2} f ^ {*} (y) d y - \frac {1}{2} \log (2 \pi). \\ \end{array}
$$

It is clear that the minimizer of $\int f ^ { * } \log p _ { \theta }$ over all $\theta \in \mathbb { R }$ equals the mean corresponding to the density $f ^ { * }$ . We thus take

$$
\theta^ {*} = \int y f ^ {*} (y) d y.
$$

On the other hand, given data $Y _ { 1 } , \dots , Y _ { n }$ , the MLE of θ is easily seen to be

$$
\hat {\theta} _ {n} := \bar {Y} _ {n} := \frac {Y _ {1} + \cdots + Y _ {n}}{n}.
$$

By the Central Limit Theorem (assuming that the variance corresponding to $f ^ { * }$ is finite), we have

$$
\sqrt {n} (\hat {\theta} - \theta^ {*}) = \sqrt {n} (\bar {Y} _ {n} - \theta^ {*}) \stackrel {L} {\rightarrow} N (0, V ^ {*}) \tag {137}
$$

where $V ^ { * }$ is the variance corresponding to $f ^ { * }$ . What is the Fisher Information Matrix in this case? The loglikelihood and the score function equal respectively

$$
\log p _ {\theta} (y) = - \frac {(y - \theta) ^ {2}}{2} - \frac {1}{2} \log (2 \pi),
$$

and

$$
\frac {d}{d \theta} \log p _ {\theta} (y) = y - \theta .
$$

The second moment of the score function evaluated at $\theta = \theta ^ { * }$ is therefore:

$$
I (\theta^ {*}) = \mathbb {E} _ {f ^ {*}} (Y - \theta^ {*}) ^ {2} = V ^ {*}.
$$

Thus the asymptotic variance of the MLE does not equal the inverse of $I ( \theta ^ { * } )$ (in this case, it equals exactly the Fisher Information).

Let us now state the result for the asymptotic distribution of the MLE $\hat { \theta } _ { n }$ in the misspecified case. We need some definitions. First the Fisher Information Matrix as before is defined as the second moment of the score function:

$$
\begin{array}{l} I (\theta^ {*}) := \mathbb {E} _ {f ^ {*}} \left\{\left(\nabla_ {\theta} \log p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right) \left(\nabla_ {\theta} \log p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right) ^ {T} \right\} \\ = \mathbb {E} _ {f ^ {*}} \left\{\frac {\left(\nabla_ {\theta} p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right) \left(\nabla_ {\theta} p _ {\theta} (Y) \bigg | _ {\theta = \theta^ {*}}\right) ^ {T}}{p _ {\theta^ {*}} ^ {2} (Y)} \right\} \\ = \int \frac {\left(\nabla_ {\theta} p _ {\theta} (y) \Big | _ {\theta = \theta^ {*}}\right) \left(\nabla_ {\theta} p _ {\theta} (y) \Big | _ {\theta = \theta^ {*}}\right) ^ {T}}{p _ {\theta^ {*}} ^ {2} (y)} f ^ {*} (y) d y. \\ \end{array}
$$

The crucial difference from the correctly specified case is that the Expectation is taken to be with respect to the true density $f ^ { * }$ (and not $p _ { \theta ^ { * } }$ ). As in the well-specified case, $I ( \theta ^ { * } )$ also equals the covariance matrix of the score function evaluated at $\theta ^ { * }$ . This is because

$$
\left. \mathbb {E} _ {f ^ {*}} \left(\left. \nabla_ {\theta} \log p _ {\theta} (Y) \right| _ {\theta = \theta^ {*}}\right) = \int \nabla_ {\theta} \log p _ {\theta} (y) \right| _ {\theta = \theta^ {*}} f ^ {*} (y) d y = \nabla_ {\theta} \left(\int \log p _ {\theta} (y) f ^ {*} (y) d y\right) \Bigg | _ {\theta = \theta^ {*}} = 0. \tag {138}
$$

The last equality above is because the gradient of $\begin{array} { r } { \int \log p _ { \theta } ( y ) f ^ { * } ( y ) d y } \end{array}$ equals zero at $\theta = \theta ^ { * }$ as $\theta ^ { * }$ maximizes the average loglikelihood (with respect to $f ^ { * }$ ) over $\theta$ (this is the definition of $\theta ^ { * }$ ). Therefore

$$
I \left(\theta^ {*}\right) = \operatorname {C o v} _ {f ^ {*}} \left(\nabla_ {\theta} \log p _ {\theta} (Y) \Bigg | _ {\theta = \theta^ {*}}\right). \tag {139}
$$

In the well-specified setting, we have seen that the Fisher Information Matrix also equals the negative of the Expected Hessian of the loglikelihood evaluated at $\theta = \theta ^ { * }$ (see the formula (135)). This is no longer in the case of misspecification. Specifically here $I ( \theta ^ { * } )$ is not necessarily the same as $J ( \theta ^ { * } )$ where

$$
J \left(\theta^ {*}\right) := - \mathbb {E} _ {f ^ {*}} \left\{H _ {\theta} \log p _ {\theta} (Y) \Big | _ {\theta = \theta^ {*}} \right\}. \tag {140}
$$

That $I ( \theta ^ { * } )$ and $J ( \theta ^ { * } )$ can be distinct is seen in the simple normal example.

Example 21.2 (Normal Mean Model continued). Consider the same setting of Example (21.1). Here the Hessian of the loglikelihood is easily seen to be $\begin{array} { r } { \frac { d ^ { 2 } } { d \theta ^ { 2 } } \log p _ { \theta } ( y ) = - 1 } \end{array}$ so that $J ( \theta ^ { * } ) = 1$ . On the other hand, we saw in Example (21.1) that $I ( { \theta ^ { * } } ) = V ^ { * }$ where $V ^ { * }$ is the variance corresponding to $f ^ { * }$ . Thus, unless $V ^ { * } = 1$ , the two quantities $I ( \theta ^ { * } )$ and $J ( \theta ^ { * } )$ will be different. Note that if we insist on correct specification, $f ^ { * } = N ( \theta ^ { * } , 1 )$ , then the variance corresponding to $f ^ { * }$ will be 1 so that $I ( \theta ^ { * } )$ and $J ( \theta ^ { * } )$ will be the same.

Here is the correct asymptotic distribution result for the MLE in the misspecified setting:

$$
\sqrt {n} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \stackrel {\mathrm {L}} {\rightarrow} N \left(0, J \left(\theta^ {*}\right) ^ {- 1} I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1}\right). \tag {141}
$$

The formula $J ( \theta ^ { * } ) ^ { - 1 } I ( \theta ^ { * } ) J ( \theta ^ { * } ) ^ { - 1 }$ for the covariance is sometimes called the “Sandwich Formula” (see e.g., http://www.econ.uiuc.edu/~roger/courses/476/lectures/L10.pdf). In the case of correct specification, we have $J ( \theta ^ { * } ) = I ( \theta ^ { * } )$ as we saw in the previous section so that (141) is identical to (132).

It is easy to see that (141) gives the correct answer in the simple normal mean example.

Example 21.3 (Normal Mean Model Continued). Here $I ( { \theta ^ { * } } ) = V ^ { * }$ and $J ( \theta ^ { * } ) = 1$ so that (141) gives

$$
\sqrt {n} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \stackrel {L} {\rightarrow} N \left(0, J (\theta^ {*}) ^ {- 1} I (\theta^ {*}) J (\theta^ {*}) ^ {- 1}\right) = N (0, V ^ {*})
$$

which coincides with (137).

Here is a sketch of the proof of (141).

Proof of (141). By definition, the MLE $\hat { \theta } _ { n }$ maximizes the loglikelihood function:

$$
\ell (\theta) := \sum_ {i = 1} ^ {n} \log p _ {\theta} (Y _ {i}).
$$

Thus the gradient of the loglikelihood evaluated at the MLE $\hat { \theta } _ { n }$ will be zero:

$$
\left. \nabla_ {\theta} \ell (\theta) \right| _ {\theta = \hat {\theta} _ {n}} = \nabla \ell (\hat {\theta} _ {n}) = 0.
$$

Now intuitively, $\hat { \theta } _ { n }$ should be close to $\theta ^ { * }$ . So we do a Taylor expansion of $\nabla \ell ( { \hat { \theta } } _ { n } )$ around $\theta ^ { * }$ :

$$
0 = \nabla \ell (\hat {\theta} _ {n}) \approx \nabla \ell (\theta^ {*}) + H \ell (\theta^ {*}) \left(\hat {\theta} _ {n} - \theta^ {*}\right)
$$

which immediately gives

$$
\hat {\theta} _ {n} - \theta^ {*} \approx - \left(H \ell (\theta^ {*})\right) ^ {- 1} \left[ \nabla \ell (\theta^ {*}) \right].
$$

We rewrite the above as

$$
\sqrt {n} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \approx \left(- \frac {1}{n} H \ell (\theta^ {*})\right) ^ {- 1} \left[ \frac {1}{\sqrt {n}} \nabla \ell (\theta^ {*}) \right].
$$

Now

$$
\frac {1}{\sqrt {n}} \nabla \ell (\theta^ {*}) = \frac {1}{\sqrt {n}} \sum_ {i = 1} ^ {n} \nabla_ {\theta} \log p _ {\theta} (Y _ {i}) \Bigg | _ {\theta = \theta^ {*}}
$$

By (138), each random variable $\nabla _ { \theta } \log p _ { \theta } ( Y _ { i } )$ (note $Y _ { i } \stackrel { \mathrm { i . i . d } } { \sim } f ^ { * } )$ ) has mean zero. Thus by the Central Limit Theorem (and (139)),

$$
\frac {1}{\sqrt {n}} \nabla \ell (\theta^ {*}) = \frac {1}{\sqrt {n}} \sum_ {i = 1} ^ {n} \left. \nabla_ {\theta} \log p _ {\theta} (Y _ {i}) \right| _ {\theta = \theta^ {*}} \stackrel {\mathrm {L}} {\to} N \left(0, \operatorname {C o v} _ {f ^ {*}} \left(\left. \nabla_ {\theta} \log p _ {\theta} (Y) \right| _ {\theta = \theta^ {*}}\right)\right) = N \left(0, I (\theta^ {*})\right).
$$

Further, by the law of large numbers (and (140)),

$$
- \frac {1}{n} H \ell (\theta^ {*}) = \frac {1}{n} \sum_ {i = 1} ^ {n} \left(- H _ {\theta} \log p _ {\theta} (Y _ {i}) \Bigg | _ {\theta = \theta^ {*}}\right) \xrightarrow {\mathbb {P}} - \mathbb {E} _ {f ^ {*}} \left\{H _ {\theta} \log p _ {\theta} (Y) \Bigg | _ {\theta = \theta^ {*}} \right\} = J (\theta^ {*}).
$$

Thus

$$
\sqrt {n} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \approx \left(- \frac {1}{n} H \ell (\theta^ {*})\right) ^ {- 1} \left[ \frac {1}{\sqrt {n}} \nabla \ell (\theta^ {*}) \right] \stackrel {\mathrm {L}} {\to} N \left(0, J (\theta^ {*}) ^ {- 1} I (\theta^ {*}) J (\theta^ {*}) ^ {- 1}\right)
$$

which proves (141).

# 21.3 Back to AIC

Let us now get back to the setting of Section 21.2.2. Our goal is to understand the quantity (131). This is a random variable (as it is a function of $Y _ { 1 } , \dots , Y _ { n }$ which are independently distributed according to $f ^ { * }$ ). We shall concentrate on finding the expectation of (131):

$$
Q := \mathbb {E} \left\{\int f ^ {*} \log p _ {\hat {\theta} _ {n}} - \frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} (Y _ {i}) \right\}
$$

We write

$$
Q = Q _ {1} + Q _ {2} + Q _ {3}
$$

where

$$
Q _ {1} := \mathbb {E} \left\{\int f ^ {*} \log p _ {\tilde {\theta} _ {n}} - \int f ^ {*} \log p _ {\theta^ {*}} \right\}, \quad Q _ {2} := \mathbb {E} \left\{\int f ^ {*} \log p _ {\theta^ {*}} - \frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\theta^ {*}} (Y _ {i}) \right\}
$$

and

$$
Q _ {3} := \mathbb {E} \left\{\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\theta^ {*}} (Y _ {i}) - \frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} (Y _ {i}) \right\}
$$

It is clear that $Q _ { 2 } = 0$ so we only need to focus on $Q _ { 1 }$ and $Q _ { 3 }$ . For $Q _ { 1 }$ , Taylor expansion around $\theta ^ { * }$ gives

$$
\begin{array}{l} Q _ {1} = \mathbb {E} \left\{\int f ^ {*} \log p _ {\hat {\theta} _ {n}} - \int f ^ {*} \log p _ {\theta^ {*}} \right\} \\ \approx \mathbb {E} \left\{\left\langle \nabla_ {\theta} \int f ^ {*} \log p _ {\theta} \Big | _ {\theta = \theta^ {*}}, \hat {\theta} _ {n} - \theta^ {*} \right\rangle + \frac {1}{2} \left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} H _ {\theta} \int f ^ {*} \log p _ {\theta} \Big | _ {\theta = \theta^ {*}} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \right\} \\ \end{array}
$$

The gradient in the first term above equals zero (because of (138)). The Hessian equals

$$
H _ {\theta} \int f ^ {*} \log p _ {\theta} \bigg | _ {\theta = \theta^ {*}} = \int f ^ {*} H _ {\theta} \log p _ {\theta} \bigg | _ {\theta = \theta^ {*}} = - J (\theta^ {*})
$$

because of the definition (140) of $J ( \theta ^ { * } )$ . Thus

$$
\begin{array}{l} Q _ {1} \approx - \frac {1}{2} \mathbb {E} \left\{\left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} J \left(\theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) \right\} \\ = - \frac {1}{2} \mathbb {E} \left[ \operatorname {t r a c e} \left\{J \left(\theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} \right\} \right] \\ = - \frac {1}{2} \operatorname {t r a c e} \mathbb {E} \left\{J \left(\theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} \right\} \\ = - \frac {1}{2} \operatorname {t r a c e} \left\{J \left(\theta^ {*}\right) \mathbb {E} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} \right\} \\ \end{array}
$$

Because of (141), we take

$$
\mathbb {E} \left(\hat {\theta} _ {n} - \theta^ {*}\right) \left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} = \frac {1}{n} J (\theta^ {*}) ^ {- 1} I (\theta^ {*}) J (\theta^ {*}) ^ {- 1}
$$

to get

$$
Q _ {1} \approx - \frac {1}{2 n} \mathrm {t r a c e} \left\{J (\theta^ {*}) J (\theta^ {*}) ^ {- 1} I (\theta^ {*}) J (\theta^ {*}) ^ {- 1} \right\} = - \frac {1}{2 n} \mathrm {t r a c e} \left\{I (\theta^ {*}) J (\theta^ {*}) ^ {- 1} \right\}
$$

For $Q _ { 3 }$ , we use Taylor expansion around the MLE $\hat { \theta } _ { n }$ to get

$$
\begin{array}{l} Q _ {3} = \mathbb {E} \left\{\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\theta^ {*}} \left(Y _ {i}\right) - \frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(Y _ {i}\right) \right\} \\ \approx \mathbb{E}\left\{\left\langle \nabla_{\theta}\frac{1}{n}\sum_{i = 1}^{n}\log p_{\theta}(Y_{i})\bigg|_{\theta = \hat{\theta}_{n}},\hat{\theta}_{n} - \theta^{*}\right\rangle +\frac{1}{2}\left(\hat{\theta}_{n} - \theta^{*}\right)^{T}H_{\theta}\frac{1}{n}\sum_{i = 1}^{n}\log p_{\theta}(Y_{i})\bigg|_{\theta = \hat{\theta}_{n}}\left(\hat{\theta}_{n} - \theta^{*}\right)\right\} . \\ \end{array}
$$

The gradient in the first term above equals zero because $\hat { \theta } _ { n }$ maximizes log-likelihood. The Hessian for large $n$ can be approximated by $- J ( \theta ^ { * } )$ (this is because $\hat { \theta } _ { n }$ will be close to $\theta ^ { * }$ ) . Thus

$$
Q _ {3} \approx - \frac {1}{2} \mathbb {E} \left\{\left(\hat {\theta} _ {n} - \theta^ {*}\right) ^ {T} J (\theta^ {*}) \left(\hat {\theta} _ {n} - \theta^ {*}\right) \right\}
$$

which (just as in the computation of $Q _ { 1 }$ ) leads to

$$
Q _ {3} \approx - \frac {1}{2 n} \operatorname {t r a c e} \left\{I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1} \right\}.
$$

We have thus proved

$$
Q \approx - \frac {1}{2 n} \operatorname {t r a c e} \left\{I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1} \right\} - \frac {1}{2 n} \operatorname {t r a c e} \left\{I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1} \right\} = - \frac {1}{n} \operatorname {t r a c e} \left\{I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1} \right\}
$$

This suggests the estimator:

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(Y _ {i}\right) - \frac {1}{n} \operatorname {t r a c e} \left\{I \left(\theta^ {*}\right) J \left(\theta^ {*}\right) ^ {- 1} \right\} \tag {142}
$$

for

$$
\int f ^ {*} \log p _ {\hat {\theta} _ {n}}. \tag {143}
$$

(142) is not really an estimator because the second term depends on $\theta ^ { * }$ . However if we assume that the model is well-specified, then $I ( \theta ^ { * } ) = J ( \theta ^ { * } )$ so that the second term equals $p$ (note $p$ is the dimension of $\theta ^ { * }$ ). We then get

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} (Y _ {i}) - \frac {p}{n}
$$

as the estimate for (143). The quantity (142) is simply the AIC multiplied by the constant $- { \frac { 1 } { 2 n } }$ . This motivates the use of AIC for model selection.

# 21.4 Recommended Reading for Today

1. A description of the AIC can be found in Chapter 4 (especially Section 4.5) of the Kitagawa book.   
2. Various applications of the AIC for model selection in state space models can be found throughout the Kitagawa-Gersch and the Kitagawa books.   
3. More details on the AIC and other related model selection criteria can be found in the book Information Criteria and Statistical Modeling by Konishi and Kitagawa (accessible through the Berkeley library website).

# 22 Lecture Twenty Two

# 22.1 Recap: AIC

In the last class, we looked at frequentist model selection using the Akaike Information Criterion (AIC) which is defined as:

$$
A I C (M) := - 2 \times (\text {M a x i m i z e d} M) + 2 \times (\text {n u m b e r o f p a r a m e t e r s i n} M). \tag {144}
$$

This criterion arises in the process of estimation of the out-of-sample accuracy of the model. More precisely, suppose that the data is $y _ { 1 } , \ldots , y _ { n }$ and the model is $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } p _ { \theta }$ with parameter $\theta$ . The in-sample accuracy of this model is

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} (y _ {i}) \tag {145}
$$

where $\hat { \theta } _ { n }$ is the MLE. Its out-of-sample accuracy is defined as

$$
\int f ^ {*} (y) \log p _ {\hat {\theta} _ {n}} (y) d y \tag {146}
$$

where $f ^ { * }$ denotes the true data generating density. As we discussed last class, asymptotics (under a bunch of assumptions) justify

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(y _ {i}\right) - \frac {p}{n} \tag {147}
$$

as an estimator of (146) where $p$ is the dimension of the parameter $\theta$ . The AIC is just the above quantity multiplied by the constant factor $- 2 n$ .

It can be noted that the out-of-sample accuracy can also be estimated more directly (without using any asymptotics) if additional independent data $\tilde { y } _ { 1 } , \ldots , \tilde { y } _ { m } \stackrel { \mathrm { i . i . d } } { \sim } f ^ { * }$ is available. In this case, we can use

$$
\frac {1}{m} \sum_ {j = 1} ^ {m} \log p _ {\hat {\theta} _ {n}} (\tilde {y} _ {j}) \tag {148}
$$

as an estimate of (146). If additional data is not available, one can split the existing dataset $y _ { 1 } , \ldots , y _ { n }$ into two parts, and use one part to calculate $\hat { \theta } _ { n }$ and the other part as $\tilde { y } _ { j }$ for the calculation of (148). To summarize, AIC and related test-data out-of-sample accuracy evaluations have the following issues:

1. AIC is popular but it uses many difficult to verify assumptions for obtaining the simple estimate (147) for (146).   
2. Heldout/Test-set methodology is more popular but requires additional data. In the absence of additional data, one needs to construct training and test datasets whose choices can be adhoc. If the test dataset is too small, the estimate (148) will be noisy. On the other hand, if the tranining dataset set is too small, the MLE calculated from the training dataset will be quite different from the MLE calculated on the full dataset and which create bias in the estimation of (146).

We shall next study Bayesian Model Selection.

# 22.2 Bayesian Model Selection

Bayesian model selection works for comparing Bayesian models. By a Bayesian model, I mean a model in which both the likelihood as well as the prior are specified. For example, given data $y _ { 1 } , \ldots , y _ { n }$ , consider the two models:

$$
Y _ {1}, \dots , Y _ {n} \stackrel {\text {i . i . d}} {\sim} N (\theta , 1) \quad \text {w i t h} \theta \in [ - 5, 5 ], \tag {149}
$$

and

$$
Y _ {1}, \dots , Y _ {n} \stackrel {\mathrm {i . i . d}} {\sim} N (\theta , 1) \quad \text {w i t h} \theta \sim \operatorname {u n i f} [ - 5, 5 ]. \tag {150}
$$

Model (149) is not a Bayesian model because the prior is not specified. The constraint $\theta \in [ - 5 , 5 ]$ does not precisely say how $\theta$ is distributed on $[ - 5 , 5 ]$ . On the other hand, the model (150) is a Bayesian model.

An important advantage of Bayesian models is that they allow calculation of the probability of the observed data under the model. For example, the Bayesian model (150) would calculate the probability of the observed data $y _ { 1 } , \ldots , y _ { n }$ as

$$
\frac {1}{1 0} \int_ {- 5} ^ {5} (2 \pi) ^ {- n / 2} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} (y _ {i} - \theta) ^ {2}\right) d \theta .
$$

On the other hand, the non-Bayesian model (149) would not allow computation of the probability of the observed dataset. Indeed, under the model (149), one can write the probability of the observed data as

$$
(2 \pi) ^ {- n / 2} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} (y _ {i} - \theta) ^ {2}\right)
$$

for some $\theta \in [ - 5 , 5 ]$ . But this not give a precise answer to the probability of the observed data as it involves the unknown value $\theta$ about which we only know that $\theta \in [ - 5 , 5 ]$ .

Note the slight abuse of terminology here. By probability of the observed data under a model, I actually mean the joint density:

$$
f _ {Y _ {1}, \dots , Y _ {n}} (y _ {1}, \dots , y _ {n})
$$

when the underlying random variables are continuous. In the case where the random variables are discrete, probability of the observed data will mean

$$
\mathbb {P} \{Y _ {1} = y _ {1}, \dots , Y _ {n} = y _ {n} \}.
$$

In the continuous case, one really should think of an observation 1.29 as not being exactly equal to the number 1.29 but rather as $\left\lfloor 1 . 2 9 - \delta , 1 . 2 9 + \delta \right\rfloor$ for some very small number $\delta$ which represents recording precision. The observed dataset $y _ { 1 } , \ldots , y _ { n }$ is then really $[ y _ { 1 } -$ $\delta , y _ { 1 } + \delta ] , \dotsc , [ y _ { n } - \delta , y _ { n } + \delta ]$ . In such a case, the probability of the observed dataset will be represented by

$$
\mathbb {P} \{Y _ {1} \in [ y _ {1} - \delta , y _ {1} + \delta ], \dots , Y _ {n} \in [ y _ {n} - \delta , y _ {n} + \delta ] \} \approx f _ {Y _ {1}, \dots , Y _ {n}} (y _ {1}, \dots , y _ {n}) (2 \delta) ^ {n}.
$$

Thus, up to multiplication by the constant factor $( 2 \delta ) ^ { n }$ (which will be the same across different models), the probability of the observed dataset is proportional to the joint density. This justifies the abuse of notation referring to the joint density as the probability of the observed dataset.

Consider now a generic dataset $y$ ( $y$ could be a vector or matrix or something even more general). We have two Bayesian models for $y$ :

$$
M _ {1}: Y \mid \theta \sim p _ {\theta} \quad \text {w i t h} \theta \sim f _ {\theta} (\cdot) \tag {151}
$$

and

$$
M _ {2}: Y \mid \alpha \sim q _ {\alpha} \quad \text {w i t h} \alpha \sim f _ {\alpha} (\cdot) \tag {152}
$$

Bayesian Model Selection compares $M _ { 1 }$ and $M _ { 2 }$ by simply calculating the probabiliity of the observed data $y$ under both $M _ { 1 }$ and $M _ { 2 }$ . Specifically, we compare

$$
f _ {Y \mid M _ {1}} (y) = \int p _ {\theta} (y) f _ {\theta} (\theta) d \theta \quad \text {a n d} \quad f _ {Y \mid M _ {2}} (y) = \int q _ {\alpha} (y) f _ {\alpha} (\alpha) d \alpha .
$$

Preference will be given to the model for which the probability of observed data is higher. The following are alternative terms for $f _ { Y \mid M _ { 1 } } ( y )$ :

1. Marginal or Integrated Likelihood: $f _ { Y \mid M _ { 1 } } ( y )$ is simply the integration of the likelihood $p _ { \theta } ( y )$ with respect to the prior density $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ .   
2. Evidence: $f _ { Y \mid M _ { 1 } } ( y )$ is often referred to as the Evidence of the model $M _ { 1 }$ under the observed data $y$ .

Thus Bayesian Model Selection compares the Integrated Likelihoods or Evidences of models. The following simple example is a good illustration of the basic idea behind Bayesian Model Selection.

Example 22.1 (MacKay). This example is from Chapter 28 of David MacKay’s book titled Information Theory, Inference, and Learning Algorithms. We have the dataset $- 1 , 3 , 7 , 1 1$ . Consider the following two Bayesian models for this dataset:

1. Model 1 (linear): $Y _ { 1 } = \alpha$ and $Y _ { n + 1 } = Y _ { n } + \beta$ for $n \geq 1$ . This model has the two parameters α and $\beta$ . We assume that $\alpha$ and $\beta$ are integer-valued that they are independently uniformly distributed over the set $\{ - 5 0 , - 4 9 , \ldots , 4 9 , 5 0 \}$ which has cardinality 101.   
2. Model 2 (cubic): $Y _ { 1 } ~ = ~ a$ and $Y _ { n + 1 } = b Y _ { n } ^ { 3 } + c Y _ { n } ^ { 2 } + d$ . This model has the four parameters $a , b , c , d$ . We assume that these four parameters are independent with a having the uniform on $\{ - 5 0 , - 4 9 , \ldots , 4 9 , 5 0 \}$ and $b , c , d$ each having the distribution of $x / y$ where $x \sim U n i f \{ - 5 0 , - 4 9 , . . . , 4 9 , 5 0 \}$ and $y \sim U n i f \{ 1 , \ldots , 5 0 \}$ are independent.

Which of these two models would you use for the data? Bayesian model selection is readily applicable here as both the models are Bayesian. We only need to calculate the probability of the observed data for the two models. For the linear model (M1):

$$
\begin{array}{l} \mathbb {P} \left\{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid \mathrm {M} 1 \right\} \\ = \sum_ {i, j} \mathbb {P} \left\{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid \alpha = i, \beta = j, \mathrm {M} 1 \right\} \mathbb {P} \left\{\alpha = i, \beta = j \mid \mathrm {M} 1 \right\} \\ = \mathbb {P} \left\{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid \alpha = - 1, \beta = 4, \mathrm {M} 1 \right\} \mathbb {P} \left\{\alpha = - 1, \beta = 4 \mid \mathrm {M} 1 \right\} \\ = (1) \mathbb {P} \{\alpha = - 1 \mid \mathrm {M} 1 \} \mathbb {P} \{\beta = 4 \mid \mathrm {M} 1 \} = \left(\frac {1}{1 0 1}\right) ^ {2} = 9. 8 \times 1 0 ^ {- 5}. \\ \end{array}
$$

For the cubic model:

$$
\begin{array}{l} \mathbb {P} \left\{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid \mathrm {M} 2 \right\} \\ = \sum_ {a, b, c, d} \mathbb {P} \left\{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid a, b, c, d, \mathrm {M} 2 \right\} \mathbb {P} \left\{a = a, b = b, c = c, d = d \mid \mathrm {M} 2 \right\} \\ \end{array}
$$

It turns out that the cubic model explains the given data perfectly if and only if its four parameters $a , b , c , d$ are chosen as $a = - 1 , b = - 1 / 1 1 , c = 9 / 1 1 , d = 2 3 / 1 1$ . As a result

$$
\begin{array}{l} \mathbb {P} \{Y _ {1} = - 1, Y _ {2} = 3, Y _ {3} = 7, Y _ {4} = 1 1 \mid \mathrm {M} 2 \} \\ = \mathbb {P} \left\{a = - 1, b = - 1 / 1 1, c = 9 / 1 1, d = 2 3 / 1 1 \mid M 2 \right\} \\ = \mathbb {P} \{a = - 1 \} \mathbb {P} \{b = - 1 / 1 1 \} \mathbb {P} \{c = 9 / 1 1 \} \mathbb {P} \{d = 2 3 / 1 1 \} \\ = \left(\frac {1}{1 0 1}\right) \left(4 \cdot \frac {1}{1 0 1} \cdot \frac {1}{5 0}\right) \left(4 \cdot \frac {1}{1 0 1} \cdot \frac {1}{5 0}\right) \left(2 \cdot \frac {1}{1 0 1} \cdot \frac {1}{5 0}\right) = 2. 5 \times 1 0 ^ {- 1 2}. \\ \end{array}
$$

Clearly the probability of the observed data is much smaller for the cubic model compared to the simpler linear model. Bayesian model selection here will prefer the linear model and this would align with common sense. Note here both the models explain the data equally well. The cubic model gets downgraded however because the prior in the cubic model gives a much smaller probability to the correct parameter values compared to the linear model. We shall come back to this point later.

Bayesian model selection can also be understood from the perspective of hierarchical modeling. Specifically consider the following hierarchical model which converts the two models $M _ { 1 }$ and $M _ { 2 }$ (defined as in (151) and (152) respectively) into a single Bayesian model.

$$
\mathcal {I} \text {t a k e s t h e v a l u e s 1 a n d 2 w i t h p r o b a b i l i t i e s} \rho \text {a n d} 1 - \rho
$$

$$
Y \mid \mathcal {I} = 1, \theta \sim p _ {\theta} \quad \text {a n d} \quad \theta \mid \mathcal {I} = 1 \sim f _ {\theta} \tag {153}
$$

$$
Y \mid \mathcal {I} = 2, \theta \sim q _ {\alpha} \quad \text {a n d} \quad \alpha \mid \mathcal {I} = 2 \sim f _ {\alpha}
$$

The random variable $\mathcal { L }$ represents one of the two models $M _ { 1 }$ and $M _ { 2 }$ . More precisely $\mathcal { Z } = 1$ represents $M _ { 1 }$ and $\mathcal { Z } = 2$ represents $M _ { 2 }$ . $\rho$ and $1 - \rho$ represent the prior probabilities of $M _ { 1 }$ and $M _ { 2 }$ . Under this single Bayesian model, we can calculate the posterior distribution of $\mathcal { L }$ given the data $Y = y$ as:

$$
\mathbb {P} \left\{\mathcal {I} = 1 \mid Y = y \right\} = \frac {f _ {Y \mid M _ {1}} (y) \mathbb {P} \left\{\mathcal {I} = 1 \right\}}{f _ {Y \mid M _ {1}} (y) \mathbb {P} \left\{\mathcal {I} = 1 \right\} + f _ {Y \mid M _ {2}} (y) \mathbb {P} \left\{\mathcal {I} = 2 \right\}}
$$

and

$$
\mathbb {P} \left\{\mathcal {I} = 2 \mid Y = y \right\} = \frac {f _ {Y \mid M _ {2}} (y) \mathbb {P} \left\{\mathcal {I} = 2 \right\}}{f _ {Y \mid M _ {1}} (y) \mathbb {P} \left\{\mathcal {I} = 1 \right\} + f _ {Y \mid M _ {2}} (y) \mathbb {P} \left\{\mathcal {I} = 2 \right\}}.
$$

These are the posterior probabilities of the two models given the data $Y = y$ . Model $M _ { 1 }$ will be preferred compared to Model $M _ { 2 }$ if and only if

$$
\mathbb {P} \left\{\mathcal {I} = 1 \mid Y = y \right\} > \mathbb {P} \left\{\mathcal {I} = 2 \mid Y = y \right\}.
$$

As the denominators of the above probabilities are the same, this is equivalent to

$$
f _ {Y \mid M _ {1}} (y) \mathbb {P} \{\mathcal {I} = 1 \} > f _ {Y \mid M _ {2}} (y) \mathbb {P} \{\mathcal {I} = 2 \}.
$$

Now if ${ \mathbb P } \{ \mathcal T = 1 \} = { \mathbb P } \{ \mathcal T = 2 \}$ i.e., if the two models are a priori equally likely, then the above comparison is equivalent to comparing $f _ { Y \mid M _ { 1 } } ( y )$ and $f _ { Y \mid M _ { 2 } } ( y )$ . Thus Bayesian model selection in terms of evidences is equivalent to looking at posterior probabilities of the two models in a hierarchical model where the prior probabilities are the same. When the prior model probabilities are not the same, we need to multiply the evidences by the prior probabilities before evaluating the models.

# 22.3 Two Alternative Expressions for the Evidence

The evidence $f _ { Y \mid M _ { 1 } } ( y )$ satisfies the following two alternative expressions which bear some similarities to the AIC formula (144). Both these formulae are consequences of the following expression for posterior density of the parameter $\theta$ in the model $M _ { 1 }$ :

$$
\operatorname {p o s t e r i o r} (\theta) = \frac {\operatorname {p r i o r} (\theta) p _ {\theta} (y)}{f _ {Y | M _ {1}} (y)} \qquad \text {f o r e v e r y} \theta .
$$

Here $\mathrm { p r i o r } ( \theta ) = f _ { \theta } ( \theta )$ and posterior $( \theta )$ is the density of $\theta$ conditional on $Y = y$ in the model $M _ { 1 }$ . As a result, we have

$$
f _ {Y \mid M _ {1}} (y) = \frac {\operatorname {p r i o r} (\theta) p _ {\theta} (y)}{\operatorname {p o s t e r i o r} (\theta)} \quad \text {f o r e v e r y} \theta . \tag {154}
$$

Taking $\theta$ to be the MLE $\hat { \theta }$ in the model $M _ { 1 }$ , we obtain

$$
f _ {Y | M _ {1}} (y) = \frac {\mathrm {p r i o r} (\hat {\theta}) p _ {\hat {\theta}} (y)}{\mathrm {p o s t e r i o r} (\hat {\theta})}.
$$

This immediately gives the formula:

$$
- 2 \log f _ {Y | M _ {1}} (y) = - 2 \log p _ {\hat {\theta}} (y) + 2 \log \left[ \frac {\mathrm {p o s t e r i o r} (\hat {\theta})}{\mathrm {p r i o r} (\hat {\theta})} \right]
$$

$\log p _ { \hat { \theta } } ( \boldsymbol { y } )$ is simply the maximized log-likelihood for the model $M _ { 1 }$ . Thus

$$
- 2 \log (\operatorname {E v i d e n c e} \left(M _ {1}\right)) = - 2 \times (\text {M a x i m i z e d l o g - l i k e l i h o o d f o r} M _ {1}) + 2 \log \left[ \frac {\text {p o s t e r i o r} (\hat {\theta})}{\text {p r i o r} (\hat {\theta})} \right] \tag {155}
$$

Note the similarity of (155) with (144). The first term above measures the fit of the best model in $M _ { 1 }$ to the observed data, while the second term measures model complexity. The model complexity term is more complicated compared to (144). The posterior evaluated at the MLE will generally be larger than the prior evaluated at the MLE which means that the model complexity term in (155) will be positive.

Example 22.2 (Example 22.1 continued). Here both the models $M _ { 1 }$ (linear) and $M _ { 2 }$ (cubic) perfectly explain the observed data. Therefore the maximized log-likelihood value is the same for both $M _ { 1 }$ and $M _ { 2 }$ . Also both the models have exactly one parameter setting which explains the data perfectly, and every other setting gives zero probability to the observed data. This means that posterior(ˆθ) equals 1 for both the models. The only difference in the models will be in the prior evaluated at the best parameter setting. This term is much higher for the linear model compared to the cubic model. The reason is that the prior for the cubic model is supported on a much larger set (compared to the prior for the linear model) and consequently the prior mass assigned to each individual element of the large set is much smaller.

For the second alternative formula, take logarithms on both sides of (154) to get

$$
\log f _ {Y | M _ {1}} (y) = \log p _ {\theta} (y) - \log \left[ \frac {\mathrm {p o s t e r i o r} (\theta)}{\mathrm {p r i o r} (\theta)} \right] \qquad \mathrm {f o r e v e r y} \theta .
$$

Integrating both sides of the above equation with respect to posterior(θ), we get (note left hand side does not depend on $\theta$ ):

$$
\begin{array}{l} \log f _ {Y \mid M _ {1}} (y) = \int \operatorname {p o s t e r i o r} (\theta) \log p _ {\theta} (y) d \theta - \int \operatorname {p o s t e r i o r} (\theta) \log \left[ \frac {\operatorname {p o s t e r i o r} (\theta)}{\operatorname {p r i o r} (\theta)} \right] d \theta \\ = \mathbb {E} _ {\theta \sim \text {p o s t e r i o r}} \log p _ {\theta} (y) - D (\text {p o s t e r i o r} \| \text {p r i o r}) \\ \end{array}
$$

where $D ( \cdot \| \cdot )$ denotes Kullback-Leibler divergence. In other words

$$
- 2 \log \left(\operatorname {E v i d e n c e} \left(M _ {1}\right)\right) = \mathbb {E} _ {\theta \sim \text {p o s t e r i o r}} \left[ - 2 \log p _ {\theta} (y) \right] + 2 D \left(\text {p o s t e r i o r} \| \text {p r i o r}\right) \tag {156}
$$

This is similar to (156) except that maximized log-likelihood is replaced by the expected loglikelihood where the expectation is taken with respect to the posterior, and the complexity term is replaced by the Kullback-Leibler divergence between the posterior and the prior. Generally, for complex models, the posterior will be quite different from the prior leading to greater penalization (for a concrete example, consider the setting of Example 22.1).

# 22.4 The BIC

The BIC (Bayesian Information Criterion) is obtained as an approximation for (155) when the posterior is replaced by its normal approximation. As we have seen previously, in some cases, the posterior distribution is well approximated by a normal distribution $N _ { p } ( { \hat { \theta } } , { \Sigma } / n )$ where $\hat { \theta }$ is the MLE, $n$ denotes sample size and $\Sigma$ is a $p \times p$ covariance matrix (generally $\Sigma$ is related to the Hessian of the log-likelihood evaluated at $\hat { \theta }$ ). In such cases,

$$
\mathrm {p o s t e r i o r} (\theta) = (2 \pi) ^ {- p / 2} \left(\det (\Sigma / n)\right) ^ {- 1 / 2} \exp \left(- \frac {n}{2} (\theta - \hat {\theta}) ^ {\prime} \Sigma^ {- 1} (\theta - \hat {\theta})\right)
$$

which implies that

$$
\operatorname {p o s t e r i o r} (\hat {\theta}) = (2 \pi) ^ {- p / 2} \left(\det  (\Sigma / n)\right) ^ {- 1 / 2}.
$$

As a result

$$
\begin{array}{l} \log \left[ \frac {\operatorname {p o s t e r i o r} (\hat {\theta})}{\operatorname {p r i o r} (\hat {\theta})} \right] = \log \frac {(2 \pi) ^ {- p / 2} (\det  (\Sigma / n)) ^ {- 1 / 2}}{\operatorname {p r i o r} (\hat {\theta})} \\ = \log \frac {(2 \pi) ^ {- p / 2} n ^ {p / 2} (\det  (\Sigma)) ^ {- 1 / 2}}{\operatorname {p r i o r} (\hat {\theta})} \\ = \frac {p}{2} (\log n) - \frac {p}{2} (\log (2 \pi)) - \frac {1}{2} \log \det  \Sigma - \log \operatorname {p r i o r} (\hat {\theta}) \\ = \frac {p}{2} (\log n) \left\{1 - \frac {\frac {p}{2} (\log (2 \pi)) + \frac {1}{2} \log \det  \Sigma + \log \operatorname {p r i o r} (\hat {\theta})}{\frac {p}{2} (\log n)} \right\}. \\ \end{array}
$$

Now if the sum of the terms ${ \frac { p } { 2 } } ( \log ( 2 \pi ) )$ , $\frac { 1 } { 2 } \log \mathrm { d e t } { \Sigma }$ and log prior(ˆθ) is small compared to ${ \frac { p } { 2 } } \log n$ :

$$
\left| \frac {\frac {p}{2} (\log (2 \pi)) + \frac {1}{2} \log \det  \Sigma + \log \operatorname {p r i o r} (\hat {\theta})}{\frac {p}{2} (\log n)} \right| \ll 1, \tag {157}
$$

then we can approximate the term in the parantheses by just 1 leading to

$$
\log \left[ \frac {\mathrm {p o s t e r i o r} (\hat {\theta})}{\mathrm {p r i o r} (\hat {\theta})} \right] \approx \frac {p}{2} (\log n).
$$

The formula (156) then simplifies to

$$
- 2 \log \left(\operatorname {E v i d e n c e} \left(M _ {1}\right)\right) \approx - 2 \times (\text {M a x i m i z e d l o g - l i k e l i h o o d f o r} M _ {1}) + p \log n. \tag {158}
$$

The right hand side above is called the BIC (Bayesian Information Criterion). It is similar to the AIC with a more stringent penality for model complexity. As a result, BIC leads to smaller models compared to the AIC. Also note that because of (157), the formula (158) does not depend on the prior $\pi$ making this convenient to use in practice.

# 22.5 Recommended Reading for Today

1. For a very good treatment of Bayesian Model Comparison, see Chapter 28 of the book Information Theory, Inference and Learning Algorithms by David MacKay, or Chapter 20 of the book Probability Theory: the logic of science by E. T. Jaynes.   
2. The formulae (155) and (156) can be found in the 2010 paper titled Bayesian system identification based on probability logic by James L. Beck.

# 23 Lecture Twenty Three

# 23.1 Recap: Frequentist and Bayesian Model Selection

We studied frequentist and Bayesian methods for model selection in the last couple of classes. Frequentist methods aim to estimate the generalization accuracy of each model with the best parameter choices. For example, in the case of a model $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } p _ { \theta }$ , frequentist methods aim to estimate generalization accuracy defined as:

$$
\int f ^ {*} (y) \log p _ {\hat {\theta} _ {n}} (y) d y \tag {159}
$$

where $f ^ { * }$ denotes the true data generating density (it is assumed here that data are actually generated independently from the density $f ^ { * }$ ), and $\hat { \theta } _ { n }$ denotes the MLE of $\theta$ . Several estimators exist for the generalization error. The AIC is constructed based on the following estimate of the generalization error:

$$
\frac {1}{n} \sum_ {i = 1} ^ {n} \log p _ {\hat {\theta} _ {n}} \left(y _ {i}\right) - \frac {p}{n}. \tag {160}
$$

In fact, the AIC for the model is simply the above generalization accuracy estimate multiplied by constant factor $- 2 n$ .

In practice, people often estimate the generalization accuracy (159) by splitting the observed dataset into two parts called training data and test data respectively, and then using the estimator:

$$
\frac {1}{m} \sum_ {j = 1} ^ {m} \log p _ {\hat {\theta} _ {n - m}} (\tilde {y} _ {j}) \tag {161}
$$

where $\tilde { y } _ { 1 } , \dots , \tilde { y } _ { m }$ denotes the test data and $\hat { \theta } _ { n - m }$ is the MLE of $\theta$ computed from the training data. While this methodology is popular, there don’t exist principled ways of doing the testtraining split.

Bayesian Model Selection compares models in terms of the total probability each model assigns to the observed data. In the above context where the data is $y _ { 1 } , \ldots , y _ { n }$ and the model is $Y _ { 1 } , \ldots , Y _ { n } \stackrel { \mathrm { i . i . d } } { \sim } p _ { \theta }$ , the model is evaluated via

$$
f _ {Y _ {1}, \dots , Y _ {n}} (y _ {1}, \dots , y _ {n}) = \int \left(\prod_ {i = 1} ^ {n} p _ {\theta} (y _ {i})\right) f _ {\theta} (\theta) d \theta
$$

where $f _ { \theta }$ denotes the prior distribution of $\theta$ . This marginal probability $f _ { Y _ { 1 } , \dots , Y _ { n } } ( y _ { 1 } , \dots , y _ { n } )$ is often referred to as the Evidence of the model. In the last class, we looked at the following

alternative formula for the evidence:

$$
- 2 \log (\operatorname {E v i d e n c e} (M)) = - 2 \times (\text {M a x i m i z e d l o g - l i k e l i h o o d f o r} M) + 2 \log \left[ \frac {\text {p o s t e r i o r} (\hat {\theta})}{\text {p r i o r} (\hat {\theta})} \right] \tag {162}
$$

We remarked that this formula bears some resemblance to the formula for the AIC.

The Evidence also has some connection to estimates of generalization accuracy such as (161). This is because we can decompose the Evidence as

$$
\begin{array}{l} \operatorname {E v i d e n c e} (M) = f _ {Y _ {1}, \dots , Y _ {n}} (y _ {1}, \dots , y _ {n}) \\ = f _ {Y _ {1}} \left(y _ {1}\right) f _ {Y _ {2} | Y _ {1} = y _ {1}} \left(y _ {2}\right) f _ {Y _ {3} | Y _ {1} = y _ {1}, Y _ {2} = y _ {2}} \left(y _ {3}\right) \dots f _ {Y _ {n} | Y _ {1} = y _ {1}, \dots , Y _ {n - 1} = y _ {n - 1}} \left(y _ {n}\right). \tag {163} \\ \end{array}
$$

Thus the Evidence is simply the product of all the predictive probabilities for each of the data points, using the model “trained” on the previous data points. Note that

$$
f _ {Y _ {i} | Y _ {1} = y _ {1}, \dots , Y _ {i - 1} = y _ {i - 1}} (y _ {i}) = \int p _ {\theta} (y _ {i}) f _ {\theta | Y _ {1} = y _ {1}, \dots , Y _ {i - 1} = y _ {i - 1}} (\theta) d \theta .
$$

When $i$ is not too small, the posterior density $f _ { \theta | Y _ { 1 } = y _ { 1 } , \dots , Y _ { i - 1 } = y _ { i - 1 } } ( \theta )$ should be peaked near the MLE based on the data $Y _ { 1 } , \dots , Y _ { i - 1 }$ so this can be viewed as measuring the generalization accuracy of the MLE similar to (161).

The main issue that people have with Bayesian Model Selection is the reliance on the priors. The next section contains a simple example where the dependence on the prior can be seen explicitly.

# 23.2 Example: Normal Mean

We use Bayesian Model Selection to evaluate the following two models for the observed data $y _ { 1 } , \ldots , y _ { n }$ :

$$
\mathrm {M o d e l} 1: Y _ {1}, \ldots Y _ {n} \stackrel {\mathrm {i . i . d}} {\sim} N (0, 1),
$$

and

$$
\mathrm {M o d e l} 2: Y _ {1}, \ldots , Y _ {n} \stackrel {\mathrm {i . i . d}} {\sim} N (\theta , 1) \qquad \mathrm {w i t h} \theta \sim \mathrm {u n i f} (- C, C).
$$

The prior in Model 2 depends on the quantity $C$ . We assume that $C$ is large. The Evidence for $M _ { 1 }$ is

$$
\operatorname {E v i d e n c e} (M _ {1}) = \left(\frac {1}{\sqrt {2 \pi}}\right) ^ {n} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} y _ {i} ^ {2}\right).
$$

The Evidence for $M _ { 2 }$ is

$$
\begin{array}{l} \operatorname {E v i d e n c e} \left(M _ {2}\right) = \frac {1}{2 C} \int_ {- C} ^ {C} \left(\frac {1}{\sqrt {2 \pi}}\right) ^ {n} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} \left(y _ {i} - \theta\right) ^ {2}\right) d \theta \\ = \frac {1}{2 C} \left(\frac {1}{\sqrt {2 \pi}}\right) ^ {n} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} (y _ {i} - \bar {y}) ^ {2}\right) \int_ {- C} ^ {C} \exp \left(- \frac {n}{2} (\bar {y} - \theta) ^ {2}\right) d \theta . \\ \end{array}
$$

Because $C$ is large, the limits $- C$ and $C$ can be replaced by $- \infty$ and $\infty$ respectively without nontrivially changing the value of the integral above. Thus

$$
\begin{array}{l} \mathrm {E v i d e n c e} (M _ {2}) \approx \frac {1}{2 C} \left(\frac {1}{\sqrt {2 \pi}}\right) ^ {n} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} (y _ {i} - \bar {y}) ^ {2}\right) \int_ {- \infty} ^ {\infty} \exp \left(- \frac {n}{2} (\bar {y} - \theta) ^ {2}\right) d \theta \\ = \frac {1}{2 C} \left(\frac {1}{\sqrt {2 \pi}}\right) ^ {n} \exp \left(- \frac {1}{2} \sum_ {i = 1} ^ {n} (y _ {i} - \bar {y}) ^ {2}\right) \sqrt {\frac {2 \pi}{n}}. \\ \end{array}
$$

The ratio of the two Evidences is thus:

$$
\frac {\operatorname {E v i d e n c e} \left(M _ {1}\right)}{\operatorname {E v i d e n c e} \left(M _ {2}\right)} = 2 C \sqrt {\frac {n}{2 \pi}} \exp \left(\frac {1}{2} \sum_ {i = 1} ^ {n} \left(y _ {i} - \bar {y}\right) ^ {2} - \frac {1}{2} \sum_ {i = 1} ^ {n} y _ {i} ^ {2}\right)
$$

which can be simplified to

$$
\frac {\operatorname {E v i d e n c e} (M _ {1})}{\operatorname {E v i d e n c e} (M _ {2})} = 2 C \sqrt {\frac {n}{2 \pi}} \exp \left(\frac {- n \bar {y} ^ {2}}{2}\right) \qquad \mathrm {w h e r e} \bar {y} := \frac {y _ {1} + \cdots + y _ {n}}{n}.
$$

Note that if $y$ is exactly equal to zero or is close to zero, then the factors $C$ and $\sqrt { n }$ appearing in the formula above make the ratio of evidences quite large. Thus, when $y$ is close to zero, the simpler model $M _ { 1 }$ will be preferred. On the other hand, if $\bar { y }$ is far from zero, the factor of $n$ appearing in the exponent of $\exp ( - n { \bar { y } } ^ { 2 } / 2 )$ will make the evidence small. This, of course, is in line with intuition. If $y$ is neither very close to zero nor very far from zero, then the value of $C$ will be crucial for determining whether the ratio of evidences is larger or smaller than 1. This example shows how Bayes model selection based on evidences depends on the priors chosen in the individual models.

The ratio of the Evidence of model $M _ { 1 }$ to the Evidence of model $M _ { 2 }$ is often referred to as the Bayes Factor especially in the statistics literature (see, for example, https://en. wikipedia.org/wiki/Bayes_factor).

# 23.3 Application: Linear Regression

Let us now calculate the Evidence for a linear regression model under a natural choice of prior. These evidences can be used for comparing various linear regression models (such as those obtained by different choices of covariates) for the same dataset.

The observed dataset is $y _ { 1 } , \ldots , y _ { n }$ . For each response value $y _ { i }$ , we also associate a $p \times 1$ covariate vector $x _ { i }$ . The response values $y _ { 1 } , \ldots , y _ { n }$ are usually placed in a $n \times 1$ vector denoted by $Y$ . The covariate vectors are placed as rows of the $n \times p$ matrix $X$ . We shall consider the matrix $X$ to be deterministic. The linear model is given by

$$
Y \sim N _ {n} (X \beta , \sigma^ {2} I _ {n})
$$

for two parameters $\beta$ and $\sigma ^ { 2 }$ . The parameter vector is $\theta = ( \beta , \sigma )$ . The Maximum Likelihood Estimate of $\theta$ is $\hat { \theta } : = ( \hat { \beta } , \hat { \sigma } )$ where

$$
\hat {\beta} := \underset {\beta} {\operatorname {a r g m i n}} \| Y - X \beta \| ^ {2} = (X ^ {\prime} X) ^ {- 1} X ^ {\prime} Y \quad \mathrm {a n d} \quad \hat {\sigma} := \sqrt {\frac {1}{n} \| Y - X \hat {\beta} \| ^ {2}} = \frac {\| Y - X \hat {\beta} \|}{\sqrt {n}}
$$

To make this into a Bayesian model, we need a prior on $\theta$ . Let us consider a generic prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ for now which will be specified shortly. The Evidence is then given by

$$
\mathrm {E v i d e n c e} = \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) f _ {\theta} (\theta) d \theta
$$

The likelihood function

$$
\theta = (\beta , \sigma) \mapsto (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right)
$$

will have a single peak at $\hat { \theta }$ and usually the likelihood is concentrated around $\hat { \theta }$ . The prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ , on the other hand, will be quite diffuse. As a result, we can approximate the Evidence as

$$
\begin{array}{l} \mathrm {E v i d e n c e} = \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) f _ {\theta} (\theta) d \theta \\ \approx f _ {\theta} (\hat {\theta}) \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \theta . \\ \end{array}
$$

The integral above can be evaluated explicitly as

$$
\begin{array}{l} \int \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \beta d \sigma \\ = \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) \left\{\int \exp \left(- \frac {\| X \hat {\beta} - X \beta \| ^ {2}}{2 \sigma^ {2}}\right) d \beta \right\} d \sigma \\ = \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) \left\{\int \exp \left(- \frac {(\beta - \hat {\beta}) ^ {\prime} X ^ {\prime} X (\beta - \hat {\beta})}{2 \sigma^ {2}}\right) d \beta \right\} d \sigma \\ = \int (2 \pi) ^ {- n / 2} \sigma^ {- n} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) \left\{(\sqrt {2 \pi} \sigma) ^ {p} | X ^ {\prime} X | ^ {- 1 / 2} \right\} d \sigma \\ = (\sqrt {2 \pi}) ^ {- (n - p)} | X ^ {\prime} X | ^ {- 1 / 2} \int_ {0} ^ {\infty} \sigma^ {- (n - p)} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) d \sigma . \\ \end{array}
$$

Using the change of variable $\sigma = t ^ { - 1 / 2 }$ , the above integral can be checked to equal:

$$
\int_ {0} ^ {\infty} \sigma^ {- (n - p)} \exp \left(- \frac {\| Y - X \hat {\beta} \| ^ {2}}{2 \sigma^ {2}}\right) d \sigma = 2 ^ {(n - p - 3) / 2} \frac {\Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p - 1}}.
$$

We have thus proved

$$
\begin{array}{l} \mathrm {E v i d e n c e} \approx f _ {\theta} (\hat {\theta}) (\sqrt {2 \pi}) ^ {- (n - p)} | X ^ {\prime} X | ^ {- 1 / 2} 2 ^ {(n - p - 3) / 2} \frac {\Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p - 1}} \\ = f _ {\theta} (\hat {\theta}) 2 ^ {- 3 / 2} \pi^ {- (n - p) / 2} | X ^ {\prime} X | ^ {- 1 / 2} \frac {\Gamma (\frac {n - p - 1}{2})}{| | Y - X \hat {\beta} | | ^ {n - p - 1}}. \\ \end{array}
$$

We shall now specify the prior $f _ { \boldsymbol { \theta } } ( \boldsymbol { \theta } )$ . We take $\beta$ and $\sigma$ to be independent with

$$
\beta \sim N (0, \tau^ {2} (X ^ {\prime} X) ^ {- 1}) \quad \text {a n d} \quad \log \sigma \sim \operatorname {U n i f} (- C, C).
$$

This prior depends on the two hyperparameters $\tau$ and $\sigma$ . The normality assumption for $\beta$ is standard and facilitates computation. Note that we have taken the covariance to be proportional to $( X ^ { \prime } X ) ^ { - 1 }$ as opposed to the identity matrix. This is because usually the different components of $\beta$ correspond to widely different covariates (e.g., $X _ { 1 }$ might be age, $X _ { 2 }$ might be current weight in pounds, $X _ { 3 }$ might be weight a year ago in kilograms etc.). In such cases, we should not treat the different components in the same footing and $\beta \sim N ( 0 , \tau ^ { 2 } ( X ^ { \prime } X ) ^ { - 1 } )$ is a more sensible assumption than $\beta \sim N ( 0 , \tau ^ { 2 } I _ { p } )$ . The prior $\beta \sim N ( 0 , \tau ^ { 2 } ( X ^ { \prime } X ) ^ { - 1 } )$ is usually referred to as the Zellner prior. The uniform prior for $\log \sigma$ is quite standard. Thus

$$
f _ {\theta} (\theta) = (2 \pi) ^ {- p / 2} \tau^ {- p} | X ^ {\prime} X | ^ {1 / 2} \exp \left(- \frac {\beta^ {\prime} X ^ {\prime} X \beta}{2 \tau^ {2}}\right) \frac {I \{e ^ {- C} <   \sigma <   e ^ {C} \}}{2 C \sigma}.
$$

Our formula for the Evidence then becomes

$$
\mathrm {E v i d e n c e} \approx 2 ^ {- (p + 3) / 2} \pi^ {- n / 2} \tau^ {- p} \exp \left(- \frac {\hat {\beta} ^ {\prime} X ^ {\prime} X \hat {\beta}}{2 \tau^ {2}}\right) \frac {\Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p - 1}} \frac {I \{e ^ {- C} <   \hat {\sigma} <   e ^ {C} \}}{2 C \hat {\sigma}}.
$$

Plugging in the value of $\hat { \sigma } = n ^ { - 1 / 2 } \lVert Y - X \hat { \beta } \rVert$ , we get

$$
\mathrm {E v i d e n c e} (\tau) \approx 2 ^ {- (p + 3) / 2} \pi^ {- n / 2} \tau^ {- p} \exp \left(- \frac {\hat {\beta} ^ {\prime} X ^ {\prime} X \hat {\beta}}{2 \tau^ {2}}\right) \frac {\sqrt {n} \Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p}} \frac {I \{e ^ {- C} <   \hat {\sigma} <   e ^ {C} \}}{2 C}.
$$

This quantity depends on the two prior hyperparameters $\tau$ and $C$ . The dependence on $C$ is not very problematic because the indicator term $I \{ e ^ { - C } < \hat { \sigma } < e ^ { C } \}$ will always be positive as $C$ is large, and the other factor $\left( 1 / ( 2 C ) \right)$ will be common across the various linear regression models provided we choose the same value of $C$ in every model. The dependence on $\tau$ is more sensitive however. This means that the probability assigned to the data by the Bayesian linear regression model depends sensitively on the parameter $\tau$ . For some values of $\tau$ , the probability of the observed data will be high and for some other values of $\tau$ , the probability of the observed data will be low. Furthermore, the values of $\tau$ where the probability of the observed data will be high (or low) will depend on the specific regression model (i.e., they will be different from one regression model to another, and this will have a bearing on the model selection problem).

To deal with this, the sensible way (from a Bayes perspective) is to take a prior on $\tau$ and then integrate the evidence formula above with respect to that prior. For a prior $f _ { \tau } ( \tau )$ on $\tau$ , the integrated evidence (with respect to $f _ { \tau }$ ) equals

$$
\mathrm {E v i d e n c e} = 2 ^ {- (p + 3) / 2} \pi^ {- n / 2} \frac {\sqrt {n} \Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p}} \frac {I \{e ^ {- C} <   \hat {\sigma} <   e ^ {C} \}}{2 C} \int_ {0} ^ {\infty} \tau^ {- p} \exp \left(- \frac {\hat {\beta} ^ {\prime} X ^ {\prime} X \hat {\beta}}{2 \tau^ {2}}\right) f _ {\tau} (\tau) d \tau .
$$

We take the prior

$$
\log \tau \sim \mathrm {U n i f} (- C _ {1}, C _ {1}) \Rightarrow f _ {\tau} (\tau) = \frac {I \{e ^ {- C _ {1}} <   \tau <   e ^ {C _ {1}} \}}{2 C _ {1} \tau}.
$$

This leads to

$$
\begin{array}{l} \int_ {0} ^ {\infty} \tau^ {- p} \exp \left(- \frac {\hat {\beta} ^ {\prime} X ^ {\prime} X \hat {\beta}}{2 \tau^ {2}}\right) f _ {\tau} (\tau) d \tau = \frac {1}{2 C _ {1}} \int_ {e ^ {- C _ {1}}} ^ {e ^ {C _ {1}}} \tau^ {- p - 1} \exp \left(- \frac {\| X \hat {\beta} \| ^ {2}}{2 \tau^ {2}}\right) d \tau \\ \approx \frac {1}{2 C _ {1}} \int_ {0} ^ {\infty} \tau^ {- p - 1} \exp \left(- \frac {\| X \hat {\beta} \| ^ {2}}{2 \tau^ {2}}\right) d \tau \\ = \frac {2 ^ {(p - 2) / 2}}{2 C _ {1}} \frac {\Gamma \left(\frac {p}{2}\right)}{\| X \hat {\beta} \| ^ {p}}. \\ \end{array}
$$

We thus have

$$
\mathrm {E v i d e n c e} \approx \frac {\pi^ {- n / 2}}{2 ^ {7 / 2}} \frac {\sqrt {n} \Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p}} \frac {\Gamma \left(\frac {p}{2}\right)}{\| X \hat {\beta} \| ^ {p}} \frac {I \{e ^ {- C} <   \hat {\sigma} <   e ^ {C} \}}{4 C C _ {1}}
$$

This formula depends on $C$ and $C _ { 1 }$ . The indicator will usually equal 1. The rest of the formula is proportional to $C C _ { 1 }$ . If these constants are chosen to be equal across the different linear regression models, then all the evidences will be affected by $C$ and $C _ { 1 }$ in the same way. In that case, we can write (ignoring terms that do not depend on the particular regression model):

$$
\mathrm {E v i d e n c e} \propto \frac {\Gamma (\frac {n - p - 1}{2})}{\| Y - X \hat {\beta} \| ^ {n - p}} \frac {\Gamma \left(\frac {p}{2}\right)}{\| X \hat {\beta} \| ^ {p}}
$$

# 23.4 Recommended Reading for Today

1. For more comments on the relation between the Bayesian Evidence (163) and generalization accuracy estimates via cross validation, see David MacKay’s Bayes FAQ webpage http://www.inference.org.uk/mackay/Bayes_FAQ.html#gcv. In particular, see MacKay’s response to the question on the relation between Bayes and GCV.   
2. The simple normal mean example in Section 23.2 is taken from Section 5.3 of the 1990 paper titled From Laplace to Supernova SN 1987A: Bayesian Inference in Astrophysics by Tom Loredo.   
3. Model selection via calculations similar to Section 23.3 can be found in Chapter 5 of the book Bayesian spectrum analysis and parameter estimation by Larry Bretthorst.

# TIME SERIES

# Contents

Syllabus iii

Books iii

Keywords iv

# 1 Models for time series 1

1.1 Time series data . . . 1   
1.2 Trend, seasonality, cycles and residuals 1   
1.3 Stationary processes 1   
1.4 Autoregressive processes 2   
1.5 Moving average processes . . . 3   
1.6 White noise 4   
1.7 The turning point test . 4

# 2 Models of stationary processes 5

2.1 Purely indeterministic processes 5   
2.2 ARMA processes 5   
2.3 ARIMA processes . 6   
2.4 Estimation of the autocovariance function 6   
2.5 Identifying a $\operatorname { M A } ( q )$ process 7   
2.6 Identifying an $\operatorname { A R } ( p )$ process . . . 7   
2.7 Distributions of the ACF and PACF 8

# 3 Spectral methods 9

3.1 The discrete Fourier transform . 9   
3.2 The spectral density 9   
3.3 Analysing the effects of smoothing . . . 12

# 4 Estimation of the spectrum 13

4.1 The periodogram 13   
4.2 Distribution of spectral estimates 15   
4.3 The fast Fourier transform . 16

# 5 Linear filters 17

5.1 The Filter Theorem . . 17   
5.2 Application to autoregressive processes . . 17   
5.3 Application to moving average processes 18   
5.4 The general linear process . 19

5.5 Filters and ARMA processes . 20   
5.6 Calculating autocovariances in ARMA models 20

# 6 Estimation of trend and seasonality 21

6.1 Moving averages . . . 21   
6.2 Centred moving averages . . . 22   
6.3 The Slutzky-Yule effect . . 22   
6.4 Exponential smoothing . . . 23   
6.5 Calculation of seasonal indices . . 24

# 7 Fitting ARIMA models 25

7.1 The Box-Jenkins procedure 25   
7.2 Identification 25   
7.3 Estimation . 25   
7.4 Verification 27   
7.5 Tests for white noise 27   
7.6 Forecasting with ARMA models . 28

# 8 State space models 29

8.1 Models with unobserved states . . 29   
8.2 The Kalman filter . . . 30   
8.3 Prediction 31   
8.4 Parameter estimation revisited . 32

# Syllabus

Time series analysis refers to problems in which observations are collected at regular time intervals and there are correlations among successive observations. Applications cover virtually all areas of Statistics but some of the most important include economic and financial time series, and many areas of environmental or ecological data.

In this course, I shall cover some of the most important methods for dealing with these problems. In the case of time series, these include the basic definitions of autocorrelations etc., then time-domain model fitting including autoregressive and moving average processes, spectral methods, and some discussion of the effect of time series correlations on other kinds of statistical inference, such as the estimation of means and regression coefficients.

# Books

1. P.J. Brockwell and R.A. Davis, Time Series: Theory and Methods, Springer Series in Statistics (1986).   
2. C. Chatfield, The Analysis of Time Series: Theory and Practice, Chapman and Hall (1975). Good general introduction, especially for those completely new to time series.   
3. P.J. Diggle, Time Series: A Biostatistical Introduction, Oxford University Press (1990).   
4. M. Kendall, Time Series, Charles Griffin (1976).

# Keywords

ACF, 2

AR(p), 2

ARIMA(p,d,q), 6

ARMA(p,q), 5

autocorrelation function, 2

autocovariance function, 2, 5

autoregressive moving average process, 5

autoregressive process, 2

Box-Jenkins, 18

classical decomposition, 1

estimation, 18

filter generating function, 12

Gaussian process, 5

identifiability, 14

identification, 18

integrated autoregressive moving

average process, 6

invertible process, 4

MA(q), 3

moving average process, 3

nondeterministic, 5

nonnegative definite sequence, 6

PACF, 11

periodogram, 15

sample partial autocorrelation coefficient, 11

second order stationary, 2

spectral density function, 8

spectral distribution function, 8

strictly stationary, 1

strongly stationary, 1

turning point test, 4

verification, 20

weakly stationary, 2

white noise, 4

Yule-Walker equations, 3

# 1 Models for time series

# 1.1 Time series data

A time series is a set of statistics, usually collected at regular intervals. Time series data occur naturally in many application areas.

• economics - e.g., monthly data for unemployment, hospital admissions, etc.   
• finance - e.g., daily exchange rate, a share price, etc.   
• environmental - e.g., daily rainfall, air quality readings.   
• medicine - e.g., ECG brain wave activity every $2 ^ { - 8 }$ secs.

The methods of time series analysis pre-date those for general stochastic processes and Markov Chains. The aims of time series analysis are to describe and summarise time series data, fit low-dimensional models, and make forecasts.

We write our real-valued series of observations as $\ldots , X _ { - 2 } , X _ { - 1 } , X _ { 0 } , X _ { 1 } , X _ { 2 } , \ldots$ , a doubly infinite sequence of real-valued random variables indexed by $\mathbb { Z }$ .

# 1.2 Trend, seasonality, cycles and residuals

One simple method of describing a series is that of classical decomposition. The notion is that the series can be decomposed into four elements:

Trend $( T _ { t } )$ — long term movements in the mean;

Seasonal effects $\left( I _ { t } \right)$ — cyclical fluctuations related to the calendar;

Cycles $\left( C _ { t } \right)$ — other cyclical fluctuations (such as a business cycles);

Residuals $\left( E _ { t } \right)$ — other random or systematic fluctuations.

The idea is to create separate models for these four elements and then combine them, either additively

$$
X _ {t} = T _ {t} + I _ {t} + C _ {t} + E _ {t}
$$

or multiplicatively

$$
X _ {t} = T _ {t} \cdot I _ {t} \cdot C _ {t} \cdot E _ {t}.
$$

# 1.3 Stationary processes

1. A sequence $\{ X _ { t } , t \in \mathbb { Z } \}$ is strongly stationary or strictly stationary if

$$
\left(X _ {t _ {1}}, \dots , X _ {t _ {k}}\right) \stackrel {{\mathcal {D}}} {{=}} \left(X _ {t _ {1} + h}, \dots , X _ {t _ {k} + h}\right)
$$

for all sets of time points $t _ { 1 } , \ldots , t _ { k }$ and integer $h$ .

2. A sequence is weakly stationary, or second order stationary if

(a) $\mathbb { E } ( X _ { t } ) = \mu$ , and   
(b) $\operatorname { c o v } ( X _ { t } , X _ { t + k } ) = \gamma _ { k } ,$

where $\mu$ is constant and $\gamma _ { k }$ is independent of $t$ .

3. The sequence $\{ \gamma _ { k } , k \in \mathbb { Z } \}$ is called the autocovariance function.   
4. We also define

$$
\rho_ {k} = \gamma_ {k} / \gamma_ {0} = \mathrm {c o r r} (X _ {t}, X _ {t + k})
$$

and call $\{ \rho _ { k } , k \in \mathbb { Z } \}$ the autocorrelation function (ACF).

# Remarks.

1. A strictly stationary process is weakly stationary.   
2. If the process is Gaussian, that is $( X _ { t _ { 1 } } , \ldots , X _ { t _ { k } } )$ is multivariate normal, for all $t _ { 1 } , \ldots , t _ { k }$ , then weak stationarity implies strong stationarity.   
3. $\gamma _ { 0 } = \operatorname { v a r } ( X _ { t } ) > 0$ , assuming $X _ { t }$ is genuinely random.   
4. By symmetry, $\gamma _ { k } = \gamma _ { - k }$ , for all $k$ .

# 1.4 Autoregressive processes

The autoregressive process of order $p$ is denoted AR(p), and defined by

$$
X _ {t} = \sum_ {r = 1} ^ {p} \phi_ {r} X _ {t - r} + \epsilon_ {t} \tag {1.1}
$$

where $\phi _ { 1 } , . . . , \phi _ { r }$ are fixed constants and $\left\{ \epsilon _ { t } \right\}$ is a sequence of independent (or uncorrelated) random variables with mean 0 and variance $\sigma ^ { 2 }$ .

The AR(1) process is defined by

$$
X _ {t} = \phi_ {1} X _ {t - 1} + \epsilon_ {t}. \tag {1.2}
$$

To find its autocovariance function we make successive substitutions, to get

$$
X _ {t} = \epsilon_ {t} + \phi_ {1} (\epsilon_ {t - 1} + \phi_ {1} (\epsilon_ {t - 2} + \dots)) = \epsilon_ {t} + \phi_ {1} \epsilon_ {t - 1} + \phi_ {1} ^ {2} \epsilon_ {t - 2} + \dots
$$

The fact that $\{ X _ { t } \}$ is second order stationary follows from the observation that $\mathbb { E } ( X _ { t } ) = 0$ and that the autocovariance function can be calculated as follows:

$$
\begin{array}{l} \gamma_ {0} = \mathbb {E} \left(\epsilon_ {t} + \phi_ {1} \epsilon_ {t - 1} + \phi_ {1} ^ {2} \epsilon_ {t - 2} + \dots\right) ^ {2} = \left(1 + \phi_ {1} ^ {2} + \phi_ {1} ^ {4} + \dots\right) \sigma^ {2} = \frac {\sigma^ {2}}{1 - \phi_ {1} ^ {2}} \\ \gamma_ {k} = \mathbb {E} \left(\sum_ {r = 0} ^ {\infty} \phi_ {1} ^ {r} \epsilon_ {t - r} \sum_ {s = 0} ^ {\infty} \phi_ {1} ^ {s} \epsilon_ {t + k - s}\right) = \frac {\sigma^ {2} \phi_ {1} ^ {k}}{1 - \phi_ {1} ^ {2}}. \\ \end{array}
$$

There is an easier way to obtain these results. Multiply equation (1.2) by $X _ { t - k }$ and take the expected value, to give

$$
\mathbb {E} (X _ {t} X _ {t - k}) = \mathbb {E} (\phi_ {1} X _ {t - 1} X _ {t - k}) + \mathbb {E} (\epsilon_ {t} X _ {t - k}).
$$

Thus $\gamma _ { k } = \phi _ { 1 } \gamma _ { k - 1 }$ , $k = 1 , 2 , \ldots$

Similarly, squaring (1.2) and taking the expected value gives

$$
\mathbb {E} (X _ {t} ^ {2}) = \phi_ {1} \mathbb {E} (X _ {t - 1} ^ {2}) + 2 \phi_ {1} \mathbb {E} (X _ {t - 1} \epsilon_ {t}) + \mathbb {E} (\epsilon_ {t} ^ {2}) = \phi_ {1} ^ {2} \mathbb {E} (X _ {t - 1} ^ {2}) + 0 + \sigma^ {2}
$$

and so $\gamma _ { 0 } = \sigma ^ { 2 } / ( 1 - \phi _ { 1 } ^ { 2 } )$ .

More generally, the AR(p) process is defined as

$$
X _ {t} = \phi_ {1} X _ {t - 1} + \phi_ {2} X _ {t - 2} + \dots + \phi_ {p} X _ {t - p} + \epsilon_ {t}. \tag {1.3}
$$

Again, the autocorrelation function can be found by multiplying (1.3) by $X _ { t - k }$ , taking the expected value and dividing by $\gamma _ { 0 }$ , thus producing the Yule-Walker equations

$$
\rho_ {k} = \phi_ {1} \rho_ {k - 1} + \phi_ {2} \rho_ {k - 2} + \dots + \phi_ {p} \rho_ {k - p}, k = 1, 2, \ldots .
$$

These are linear recurrence relations, with general solution of the form

$$
\rho_ {k} = C _ {1} \omega_ {1} ^ {| k |} + \dots + C _ {p} \omega_ {p} ^ {| k |},
$$

where $\omega _ { 1 } , \ldots , \omega _ { p }$ are the roots of

$$
\omega^ {p} - \phi_ {1} \omega^ {p - 1} - \phi_ {2} \omega^ {p - 2} - \dots - \phi_ {p} = 0
$$

and $C _ { 1 } , \ldots , C _ { p }$ are determined by $\rho _ { 0 } = 1$ and the equations for $k = 1 , \dotsc , p - 1$ . It is natural to require $\gamma _ { k } \to 0$ as $k  \infty$ , in which case the roots must lie inside the unit circle, that is, $| \omega _ { i } | < 1$ . Thus there is a restriction on the values of $\phi _ { 1 } , . . . , \phi _ { p }$ that can be chosen.

# 1.5 Moving average processes

The moving average process of order $q$ is denoted MA(q) and defined by

$$
X _ {t} = \sum_ {s = 0} ^ {q} \theta_ {s} \epsilon_ {t - s} \tag {1.4}
$$

where $\theta _ { 1 } , \ldots , \theta _ { q }$ are fixed constants, $\theta _ { 0 } = 1$ , and $\left\{ \epsilon _ { t } \right\}$ is a sequence of independent (or uncorrelated) random variables with mean 0 and variance $\sigma ^ { 2 }$ .

It is clear from the definition that this is second order stationary and that

$$
\gamma_ {k} = \left\{ \begin{array}{l l} 0, & | k | > q \\ \sigma^ {2} \sum_ {s = 0} ^ {q - | k |} \theta_ {s} \theta_ {s + k}, & | k | \leq q \end{array} \right.
$$

We remark that two moving average processes can have the same autocorrelation function. For example,

$$
X _ {t} = \epsilon_ {t} + \theta \epsilon_ {t - 1} \quad \mathrm {a n d} \quad X _ {t} = \epsilon_ {t} + (1 / \theta) \epsilon_ {t - 1}
$$

both have $\rho _ { 1 } = \theta / ( 1 + \theta ^ { 2 } )$ , $\rho _ { k } = 0$ , $| k | > 1$ . However, the first gives

$$
\epsilon_ {t} = X _ {t} - \theta \epsilon_ {t - 1} = X _ {t} - \theta (X _ {t - 1} - \theta \epsilon_ {t - 2}) = X _ {t} - \theta X _ {t - 1} + \theta^ {2} X _ {t - 2} - \dots
$$

This is only valid for $| \theta | < 1$ , a so-called invertible process. No two invertible processes have the same autocorrelation function.

# 1.6 White noise

The sequence $\left\{ \epsilon _ { t } \right\}$ , consisting of independent (or uncorrelated) random variables with mean 0 and variance $\sigma ^ { 2 }$ is called white noise (for reasons that will become clear later.) It is a second order stationary series with $\gamma _ { 0 } = \sigma ^ { 2 }$ and $\gamma _ { k } = 0$ , $k \neq 0$ .

# 1.7 The turning point test

We may wish to test whether a series can be considered to be white noise, or whether a more complicated model is required. In later chapters we shall consider various ways to do this, for example, we might estimate the autocovariance function, say $\{ \hat { \gamma } _ { k } \}$ , and observe whether or not $\hat { \gamma } _ { k }$ is near zero for all $k > 0$ .

However, a very simple diagnostic is the turning point test, which examines a series $\{ X _ { t } \}$ to test whether it is purely random. The idea is that if $\{ X _ { t } \}$ is purely random then three successive values are equally likely to occur in any of the six possible orders.

![](images/d983f20bb2e350be0699a0932f9e0cb13b4e75f258d1f3a801325af74e521efa.jpg)

In four cases there is a turning point in the middle. Thus in a series of $n$ points we might expect $( 2 / 3 ) ( n - 2 )$ turning points.

In fact, it can be shown that for large $n$ , the number of turning points should be distributed as about $N ( 2 n / 3 , 8 n / 4 5 )$ . We reject (at the 5% level) the hypothesis that the series is unsystematic if the number of turning points lies outside the range $2 n / 3 \pm 1 . 9 6 \sqrt { 8 n / 4 5 }$ .

# 2 Models of stationary processes

# 2.1 Purely indeterministic processes

Suppose $\{ X _ { t } \}$ is a second order stationary process, with mean 0. Its autocovariance function is

$$
\gamma_ {k} = \mathbb {E} (X _ {t} X _ {t + k}) = \operatorname {c o v} (X _ {t}, X _ {t + k}), \quad k \in \mathbb {Z}.
$$

1. As $\{ X _ { t } \}$ is stationary, $\gamma _ { k }$ does not depend on $t$ .   
2. A process is said to be purely-indeterministic if the regression of $X _ { t }$ on $X _ { t - q } , X _ { t - q - 1 } , . . .$ has explanatory power tending to 0 as $q  \infty$ . That is, the residual variance tends to $\mathrm { v a r } ( X _ { t } )$ .

An important theorem due to Wold (1938) states that every purelyindeterministic second order stationary process $\{ X _ { t } \}$ can be written in the form

$$
X _ {t} = \mu + \theta_ {0} Z _ {t} + \theta_ {1} Z _ {t - 1} + \theta_ {2} Z _ {t - 2} + \dots
$$

where $\{ Z _ { t } \}$ is a sequence of uncorrelated random variables.

3. A Gaussian process is one for which $X _ { t _ { 1 } } , \ldots , X _ { t _ { n } }$ has a joint normal distribution for all $t _ { 1 } , \ldots , t _ { n }$ . No two distinct Gaussian processes have the same autocovariance function.

# 2.2 ARMA processes

The autoregressive moving average process, ARMA $( p , q )$ , is defined by

$$
X _ {t} - \sum_ {r = 1} ^ {p} \phi_ {r} X _ {t - r} = \sum_ {s = 0} ^ {q} \theta_ {s} \epsilon_ {t - s}
$$

where again $\left\{ \epsilon _ { t } \right\}$ is white noise. This process is stationary for appropriate $\phi$ , $\theta$ .

# Example 2.1

Consider the state space model

$$
X _ {t} = \phi X _ {t - 1} + \epsilon_ {t},
$$

$$
Y _ {t} = X _ {t} + \eta_ {t}.
$$

Suppose $\{ X _ { t } \}$ is unobserved, $\{ Y _ { t } \}$ is observed and $\left\{ \epsilon _ { t } \right\}$ and $\{ \eta _ { t } \}$ are independent white noise sequences. Note that $\{ X _ { t } \}$ is AR(1). We can write

$$
\begin{array}{l} \xi_ {t} = Y _ {t} - \phi Y _ {t - 1} \\ = \left(X _ {t} + \eta_ {t}\right) - \phi \left(X _ {t - 1} + \eta_ {t - 1}\right) \\ = \left(X _ {t} - \phi X _ {t - 1}\right) + \left(\eta_ {t} - \phi \eta_ {t - 1}\right) \\ = \epsilon_ {t} + \eta_ {t} - \phi \eta_ {t - 1} \\ \end{array}
$$

Now $\xi _ { t }$ is stationary and $\mathrm { c o v } ( \xi _ { t } , \xi _ { t + k } ) = 0$ , $k \geq 2$ . As such, $\xi _ { t }$ can be modelled as a MA(1) process and $\{ Y _ { t } \}$ as $\mathrm { A R M A } ( 1 , 1 )$ .

# 2.3 ARIMA processes

If the original process $\{ Y _ { t } \}$ is not stationary, we can look at the first order difference process

$$
X _ {t} = \nabla Y _ {t} = Y _ {t} - Y _ {t - 1}
$$

or the second order differences

$$
X _ {t} = \nabla^ {2} Y _ {t} = \nabla (\nabla Y) _ {t} = Y _ {t} - 2 Y _ {t - 1} + Y _ {t - 2}
$$

and so on. If we ever find that the differenced process is a stationary process we can look for a ARMA model of that.

The process $\{ Y _ { t } \}$ is said to be an autoregressive integrated moving average process, ARIMA $( p , d , q )$ , if $X _ { t } = \nabla ^ { d } Y _ { t }$ is an $\mathrm { A R M A } ( p , q )$ $( p , q )$ process.

AR, MA, ARMA and ARIMA processes can be used to model many time series. A key tool in identifying a model is an estimate of the autocovariance function.

# 2.4 Estimation of the autocovariance function

Suppose we have data $( X _ { 1 } , \ldots , X _ { T } )$ from a stationary time series. We can estimate

• the mean by $\bar { X } = ( 1 / T ) \sum _ { 1 } ^ { T } X _ { t }$   
• the autocovariance by $\begin{array} { r } { c _ { k } = \widehat \gamma _ { k } = ( 1 / T ) \sum _ { t = k + 1 } ^ { T } ( X _ { t } - \bar { X } ) ( X _ { t - k } - \bar { X } ) } \end{array}$ , and   
• the autocorrelation by $r _ { k } = \hat { \rho } _ { k } = \hat { \gamma } _ { k } / \hat { \gamma } _ { 0 }$ .

The plot of $r _ { k }$ against $k$ is known as the correlogram. If it is known that $\mu$ is 0 there is no need to correct for the mean and $\gamma _ { k }$ can be estimated by

$$
\hat {\gamma} _ {k} = (1 / T) \sum_ {t = k + 1} ^ {T} X _ {t} X _ {t - k}.
$$

Notice that in defining $\hat { \gamma } _ { k }$ we divide by $T$ rather than by $( T - k )$ . When $T$ is large relative to $k$ it does not much matter which divisor we use. However, for mathematical simplicity and other reasons there are advantages in dividing by $T$ .

Suppose the stationary process $\{ X _ { t } \}$ has autocovariance function $\{ \gamma _ { k } \}$ . Then

$$
\mathrm {v a r} \left(\sum_ {t = 1} ^ {T} a _ {t} X _ {t}\right) = \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} a _ {t} a _ {s} \mathrm {c o v} (X _ {t}, X _ {s}) = \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} a _ {t} a _ {s} \gamma_ {| t - s |} \geq 0.
$$

A sequence $\{ \gamma _ { k } \}$ for which this holds for every $T \geq 1$ and set of constants $( a _ { 1 } , \ldots , a _ { T } )$ is called a nonnegative definite sequence. The following theorem states that $\{ \gamma _ { k } \}$ is a valid autocovariance function if and only if it is nonnegative definite.

Theorem 2.2 (Blochner) The following are equivalent.

1. There exists a stationary sequence with autocovariance function $\{ \gamma _ { k } \}$   
2. $\{ \gamma _ { k } \}$ is nonnegative definite.   
3. The spectral density function,

$$
f (\omega) = \frac {1}{\pi} \sum_ {k = - \infty} ^ {\infty} \gamma_ {k} e ^ {i k \omega} = \frac {1}{\pi} \gamma_ {0} + \frac {2}{\pi} \sum_ {k = 1} ^ {\infty} \gamma_ {k} \cos (\omega k),
$$

is positive if it exists.

Dividing by $T$ rather than by $( T - k )$ in the definition of $\hat { \gamma } _ { k }$

• ensures that $\{ \hat { \gamma } _ { k } \}$ is nonnegative definite (and thus that it could be the autocovariance function of a stationary process), and   
• can reduce the $L ^ { 2 }$ -error of $r _ { k }$

# 2.5 Identifying a MA(q) process

In a later lecture we consider the problem of identifying an ARMA or ARIMA model for a given time series. A key tool in doing this is the correlogram.

The $\mathrm { M A } ( q )$ process $X _ { t }$ has $\rho _ { k } = 0$ for all $k$ , $| k | > q$ . So a diagnostic for MA(q) is that $\left| r _ { k } \right|$ drops to near zero beyond some threshold.

# 2.6 Identifying an $\mathbf { A R } ( p )$ process

The AR(p) process has $\rho _ { k }$ decaying exponentially. This can be difficult to recognise in the correlogram. Suppose we have a process $X _ { t }$ which we believe is AR(k) with

$$
X _ {t} = \sum_ {j = 1} ^ {k} \phi_ {j, k} X _ {t - j} + \epsilon_ {t}
$$

with $\epsilon _ { t }$ independent of $X _ { 1 } , \dots , X _ { t - 1 }$ .

Given the data $X _ { 1 } , \ldots , X _ { T }$ , the least squares estimates of $( \phi _ { 1 , k } , \ldots , \phi _ { k , k } )$ are obtained by minimizing

$$
\frac {1}{T} \sum_ {t = k + 1} ^ {T} \left(X _ {t} - \sum_ {j = 1} ^ {k} \phi_ {j, k} X _ {t - j}\right) ^ {2}.
$$

This is approximately equivalent to solving equations similar to the Yule-Walker equations,

$$
\hat {\gamma} _ {j} = \sum_ {\ell = 1} ^ {k} \hat {\phi} _ {\ell , k} \hat {\gamma} _ {| j - \ell |}, \quad j = 1, \ldots , k
$$

These can be solved by the Levinson-Durbin recursion:

Step 0. $\sigma _ { 0 } ^ { 2 } : = \hat { \gamma } _ { 0 } , \quad \hat { \phi } _ { 1 , 1 } = \hat { \gamma } _ { 1 } / \hat { \gamma } _ { 0 } , \quad k : = 0$

Step 1. Repeat until $\hat { \phi } _ { k , k }$ near 0:

$$
k := k + 1
$$

$$
\hat {\phi} _ {k, k} := \left. \left(\hat {\gamma} _ {k} - \sum_ {j = 1} ^ {k - 1} \hat {\phi} _ {j, k - 1} \hat {\gamma} _ {k - j}\right) \right/ \sigma_ {k - 1} ^ {2}
$$

$$
\hat {\phi} _ {j, k} := \hat {\phi} _ {j, k - 1} - \hat {\phi} _ {k, k} \hat {\phi} _ {k - j, k - 1}, \mathrm {f o r} j = 1, \ldots , k - 1
$$

$$
\sigma_ {k} ^ {2} := \sigma_ {k - 1} ^ {2} (1 - \hat {\phi} _ {k, k} ^ {2})
$$

We test whether the order $k$ fit is an improvement over the order $k - 1$ fit by looking to see if $\hat { \phi } _ { k , k }$ is far from zero.

The statistic $\hat { \phi } _ { k , k }$ is called the $k$ th sample partial autocorrelation coefficient (PACF). If the process $X _ { t }$ is genuinely AR(p) then the population PACF, $\phi _ { k , k }$ , is exactly zero for all $k > p$ . Thus a diagnostic for $\operatorname { A R } ( p )$ is that the sample PACFs are close to zero for $k > p$ .

# 2.7 Distributions of the ACF and PACF

Both the sample ACF and PACF are approximately normally distributed about their population values, and have standard deviation of about $1 / \sqrt { T }$ , where $T$ is the length of the series. A rule of thumb it that $\rho _ { k }$ is negligible (and similarly $\phi _ { k , k }$ ) if $r _ { k }$ (similarly $\hat { \phi } _ { k , k }$ ) lies between $\pm 2 / \sqrt { T }$ . (2 is an approximation to 1.96. Recall that if $Z _ { 1 } , . . . , Z _ { n } \sim N ( \mu , 1 )$ , a test of size 0.05 of the hypothesis $H _ { 0 } : \mu = 0$ against $H _ { 1 } : \mu \neq 0$ rejects $H _ { 0 }$ if and only if $\bar { Z }$ lies outside $\pm 1 . 9 6 / \sqrt { n } $ ).

Care is needed in applying this rule of thumb. It is important to realize that the sample autocorrelations, $r _ { 1 } , r _ { 2 } , \ldots$ , (and sample partial autocorrelations, $\hat { \phi } _ { 1 , 1 } , \hat { \phi } _ { 2 , 2 } , . . . )$ are not independently distributed. The probability that any one $r _ { k }$ should lie outside $\pm 2 / \sqrt { T }$ depends on the values of the other $r _ { k }$ .

A ‘portmanteau’ test of white noise (due to Box & Pierce and Ljung & Box) can be based on the fact that approximately

$$
Q _ {m} ^ {\prime} = T (T + 2) \sum_ {k = 1} ^ {m} (T - k) ^ {- 1} r _ {k} ^ {2} \sim \chi_ {m} ^ {2}.
$$

The sensitivity of the test to departure from white noise depends on the choice of $m$ . If the true model is ARMA $( p , q )$ then greatest power is obtained (rejection of the white noise hypothesis is most probable) when $m$ is about $p + q$ .

# 3 Spectral methods

# 3.1 The discrete Fourier transform

If $h ( t )$ is defined for integers $t$ , the discrete Fourier transform of $h$ i s

$$
H (\omega) = \sum_ {t = - \infty} ^ {\infty} h (t) e ^ {- i \omega t}, \quad - \pi \leq \omega \leq \pi
$$

The inverse transform is

$$
h (t) = \frac {1}{2 \pi} \int_ {- \pi} ^ {\pi} e ^ {i \omega t} H (\omega) d \omega .
$$

If $h ( t )$ is real-valued, and an even function such that $h ( t ) = h ( - t )$ , then

$$
H (\omega) = h (0) + 2 \sum_ {t = 1} ^ {\infty} h (t) \cos (\omega t)
$$

and

$$
h (t) = \frac {1}{\pi} \int_ {0} ^ {\pi} \cos (\omega t) H (\omega) d \omega .
$$

# 3.2 The spectral density

The Wiener-Khintchine theorem states that for any real-valued stationary process there exists a spectral distribution function, $F ( \cdot )$ , which is nondecreasing and right continuous on $[ 0 , \pi ]$ such that $F ( 0 ) = 0$ , $F ( \pi ) = \gamma _ { 0 }$ and

$$
\gamma_ {k} = \int_ {0} ^ {\pi} \cos (\omega k) d F (\omega).
$$

The integral is a Lebesgue-Stieltges integral and is defined even if $F ^ { \prime }$ has discontinuities. Informally, $F ( \omega _ { 2 } ) - F ( \omega _ { 1 } )$ is the contribution to the variance of the series made by frequencies in the range $( \omega _ { 1 } , \omega _ { 2 } )$ .

$F ( \cdot )$ can have jump discontinuities, but always can be decomposed as

$$
F (\omega) = F _ {1} (\omega) + F _ {2} (\omega)
$$

where $F _ { 1 } ( \cdot )$ is a nondecreasing continuous function and $F _ { 2 } ( \cdot )$ is a nondecreasing step function. This is a decomposition of the series into a purely indeterministic component and a deterministic component.

Suppose the process is purely indeterministic, (which happens if and only if $\textstyle \sum _ { k } { \left| \gamma _ { k } \right| } < \infty \quad$ . In this case $F ( \cdot )$ is a nondecreasing continuous function, and differentiable at all points (except possibly on a set of measure zero). Its derivative $f ( \omega ) = F ^ { \prime } ( \omega )$ exists, and is called the spectral density function. Apart from a

multiplication by $1 / \pi$ it is simply the discrete Fourier transform of the autocovariance function and is given by

$$
f (\omega) = \frac {1}{\pi} \sum_ {k = - \infty} ^ {\infty} \gamma_ {k} e ^ {- i k \omega} = \frac {1}{\pi} \gamma_ {0} + \frac {2}{\pi} \sum_ {k = 1} ^ {\infty} \gamma_ {k} \cos (\omega k),
$$

with inverse

$$
\gamma_ {k} = \int_ {0} ^ {\pi} \cos (\omega k) f (\omega) d \omega .
$$

Note. Some authors define the spectral distribution function on $[ - \pi , \pi ]$ ; the use of negative frequencies makes the interpretation of the spectral distribution less intuitive and leads to a difference of a factor of 2 in the definition of the spectra density. Notice, however, that if $f$ is defined as above and extended to negative frequencies, $f ( - \omega ) = f ( \omega )$ , then we can write

$$
\gamma_ {k} = \int_ {- \pi} ^ {\pi} \frac {1}{2} e ^ {i \omega k} f (\omega) d \omega .
$$

# Example 3.1

(a) Suppose $\{ X _ { t } \}$ is i.i.d., $\gamma _ { 0 } ~ = ~ \mathrm { v a r } ( X _ { t } ) ~ = ~ \sigma ^ { 2 } ~ > ~ 0$ and $\gamma _ { k } ~ = ~ 0$ , $k \geq 1$ . Then $f ( \omega ) = \sigma ^ { 2 } / \pi$ . The fact that the spectral density is flat means that all frequencies are equally present accounts for our calling this sequence white noise.   
(b) As an example of a process which is not purely indeterministic, consider $X _ { t } =$ $\cos ( \omega _ { 0 } t + U )$ where $\omega _ { 0 }$ is a value in $[ 0 , \pi ]$ and $U \sim U [ - \pi , \pi ]$ . The process has zero mean, since

$$
\mathbb {E} (X _ {t}) = \frac {1}{2 \pi} \int_ {- \pi} ^ {\pi} \cos (\omega_ {0} t + u) d u = 0
$$

and autocovariance

$$
\begin{array}{l} \gamma_ {k} = \mathbb {E} (X _ {t}, X _ {t + k}) \\ = \frac {1}{2 \pi} \int_ {- \pi} ^ {\pi} \cos (\omega_ {0} t + u) \cos (\omega_ {0} t + \omega_ {0} k + u) d u \\ = \frac {1}{2 \pi} \int_ {- \pi} ^ {\pi} \frac {1}{2} \left[ \cos (\omega_ {0} k) + \cos (2 \omega_ {0} t + \omega_ {0} k + 2 u) \right] d u \\ = \frac {1}{2 \pi} \frac {1}{2} [ 2 \pi \cos (\omega_ {0} k) + 0 ] \\ = \frac {1}{2} \cos (\omega_ {0} k). \\ \end{array}
$$

Hence $X _ { t }$ is second order stationary and we have

$$
\gamma_ {k} = \frac {1}{2} \cos (\omega_ {0} k), \quad F (\omega) = \frac {1}{2} I _ {[ \omega \geq \omega_ {0} ]} \quad \mathrm {a n d} \quad f (\omega) = \frac {1}{2} \delta_ {\omega_ {0}} (\omega).
$$

Note that $F ^ { \prime }$ is a nondecreasing step function.

More generally, the spectral density

$$
f (\omega) = \sum_ {j = 1} ^ {n} \frac {1}{2} a _ {j} \delta_ {\omega_ {j}} (\omega)
$$

corresponds to the process $\begin{array} { r } { X _ { t } = \sum _ { j = 1 } ^ { n } a _ { j } \cos ( \omega _ { j } t + U _ { j } ) } \end{array}$ where $\omega _ { j } \in [ 0 , \pi ]$ and $U _ { 1 } , \ldots , U _ { n }$ are i.i.d. $U [ - \pi , \pi ]$ .

(c) The MA(1) process, $X _ { t } = \theta _ { 1 } \epsilon _ { t - 1 } + \epsilon _ { t }$ , where $\left\{ \epsilon _ { t } \right\}$ is white noise. Recall $\gamma _ { 0 } =$ $( 1 + \theta _ { 1 } ^ { 2 } ) \sigma ^ { 2 }$ , $\gamma _ { 1 } = \theta _ { 1 } \sigma ^ { 2 }$ , and $\gamma _ { k } = 0$ , $k > 1$ . Thus

$$
f (\omega) = \frac {\sigma^ {2} (1 + 2 \theta_ {1} \cos \omega + \theta_ {1} ^ {2})}{\pi}.
$$

(d) The AR(1) process, $X _ { t } = \phi _ { 1 } X _ { t - 1 } + \epsilon _ { t }$ , where $\left\{ \epsilon _ { t } \right\}$ is white noise. Recall

$$
\operatorname {v a r} (X _ {t}) = \phi_ {1} ^ {2} \operatorname {v a r} (X _ {t - 1}) + \sigma^ {2} \Longrightarrow \gamma_ {0} = \phi_ {1} ^ {2} \gamma_ {0} + \sigma^ {2} \Longrightarrow \gamma_ {0} = \sigma^ {2} / (1 - \phi_ {1} ^ {2})
$$

where we need $| \phi _ { 1 } | < 1$ for $X _ { t }$ stationary. Also,

$$
\gamma_ {k} = \mathrm {c o v} (X _ {t}, X _ {t - k}) = \mathrm {c o v} (\phi_ {1} X _ {t - 1} + \epsilon_ {t}, X _ {t - k}) = \phi_ {1} \gamma_ {k - 1}.
$$

So $\gamma _ { k } = \phi _ { 1 } ^ { | k | } \gamma _ { 0 }$ , $k \in \mathbb { Z }$ . Thus

$$
\begin{array}{l} f (\omega) = \frac {\gamma_ {0}}{\pi} + \frac {2}{\pi} \sum_ {k = 1} ^ {\infty} \phi_ {1} ^ {k} \gamma_ {0} \cos (k \omega) = \frac {\gamma_ {0}}{\pi} \left\{1 + \sum_ {k = 1} ^ {\infty} \phi_ {1} ^ {k} \left[ e ^ {i \omega k} + e ^ {- i \omega k} \right] \right\} \\ = \frac {\gamma_ {0}}{\pi} \left\{1 + \frac {\phi_ {1} e ^ {i \omega}}{1 - \phi_ {1} e ^ {i \omega}} + \frac {\phi_ {1} e ^ {- i \omega}}{1 - \phi_ {1} e ^ {- i \omega}} \right\} = \frac {\gamma_ {0}}{\pi} \frac {1 - \phi_ {1} ^ {2}}{1 - 2 \phi_ {1} \cos \omega + \phi_ {1} ^ {2}} \\ = \frac {\sigma^ {2}}{\pi (1 - 2 \phi_ {1} \cos \omega + \phi_ {1} ^ {2})}. \\ \end{array}
$$

Note that $\phi > 0$ has power at low frequency, whereas $\phi < 0$ has power at high frequency.

![](images/18f90b49ac6af8906d4c8dc2da590d471f7e587b724618a98a4dbe0d6666581f.jpg)

![](images/805eb36db9cd3546d8b785a3526ae5045a3d09b90134da1d966e516d617dd16e.jpg)

Plots above are the spectral densities for AR(1) processes in which $\left\{ \epsilon _ { t } \right\}$ is Gaussian white noise, with $\sigma ^ { 2 } / \pi = 1$ . Samples for 200 data points are shown below.

![](images/aefcfbbd01163c26bfcc4f9d4c323d74b1a99acf85b9543d2bb106b68bfe2286.jpg)

# 3.3 Analysing the effects of smoothing

Let $\{ a _ { s } \}$ be a sequence of real numbers. A linear filter of $\{ X _ { t } \}$ i s

$$
Y _ {t} = \sum_ {s = - \infty} ^ {\infty} a _ {s} X _ {t - s}.
$$

In Chapter 5 we show that the spectral density of $\{ Y _ { t } \}$ is given by

$$
f _ {Y} (\omega) = \left| a (\omega) \right| ^ {2} f _ {X} (\omega),
$$

where $a ( z )$ is the transfer function

$$
a (\omega) = \sum_ {s = - \infty} ^ {\infty} a _ {s} e ^ {i \omega s}.
$$

This result can be used to explore the effect of smoothing a series.

# Example 3.2

Suppose the AR(1) series above, with $\phi _ { 1 } = - 0 . 5$ , is smoothed by a moving average on three points, so that smoothed series is

$$
Y _ {t} = \frac {1}{3} \bigl [ X _ {t + 1} + X _ {t} + X _ {t - 1} \bigr ].
$$

Then $| a ( \omega ) | ^ { 2 } = | { \textstyle { \frac { 1 } { 3 } } } e ^ { - i \omega } + { \textstyle { \frac { 1 } { 3 } } } + { \textstyle { \frac { 1 } { 3 } } } e ^ { i \omega } | ^ { 2 } = { \textstyle { \frac { 1 } { 9 } } } ( 1 + 2 \cos \omega ) ^ { 2 }$ .

Notice that $\gamma _ { X } ( 0 ) = 4 \pi / 3$ , $\gamma _ { Y } ( 0 ) = 2 \pi / 9$ , so $\{ Y _ { t } \}$ has $1 / 6$ the variance of $\{ X _ { t } \}$ . Moreover, all components of frequency $\omega = 2 \pi / 3$ (i.e., period 3) are eliminated in the smoothed series.

![](images/2f4ec87d3a2861cae42461cff5077a181f2f88e25274fd34830c160f95127c49.jpg)

![](images/bab2bc25505e9be886c00ed2948941537367218a153f8c7e11b1e1cad0c73258.jpg)

![](images/11f87e539bbfb82d6080d0259ed7d387106c39341b91602d2d4465460f0aca32.jpg)

# 4 Estimation of the spectrum

# 4.1 The periodogram

Suppose we have $T = 2 m + 1$ observations of a time series, $y _ { 1 } , \ldots , y _ { T }$ . Define the Fourier frequencies, $\omega _ { j } = 2 \pi j / T$ , $j = 1 , \ldots , m$ , and consider the regression model

$$
y _ {t} = \alpha_ {0} + \sum_ {j = 1} ^ {m} \alpha_ {j} \cos (\omega_ {j} t) + \sum_ {j = 1} ^ {m} \beta_ {j} \sin (\omega_ {j} t),
$$

which can be written as a general linear model, $Y = X \theta + \epsilon$ , where

$$
\begin{array}{l} Y = \left( \begin{array}{c} y _ {1} \\ \vdots \\ y _ {T} \end{array} \right), \quad X = \left( \begin{array}{c c c c c c} 1 & c _ {1 1} & s _ {1 1} & \dots & c _ {m 1} & s _ {m 1} \\ \vdots & \vdots & \vdots & & \vdots & \vdots \\ 1 & c _ {1 T} & s _ {1 T} & \dots & c _ {m T} & s _ {m T} \end{array} \right), \quad \theta = \left( \begin{array}{c} \alpha_ {0} \\ \alpha_ {1} \\ \beta_ {1} \\ \vdots \\ \alpha_ {m} \\ \beta_ {m} \end{array} \right), \quad \epsilon = \left( \begin{array}{c} \epsilon_ {1} \\ \vdots \\ \epsilon_ {T} \end{array} \right) ^ {\prime} \\ c _ {j t} = \cos (\omega_ {j} t), \qquad s _ {j t} = \sin (\omega_ {j} t). \\ \end{array}
$$

The least squares estimates in this model are given by

$$
\hat {\theta} = (X ^ {\top} X) ^ {- 1} X ^ {\top} Y.
$$

Note that

$$
\begin{array}{l} \sum_ {t = 1} ^ {T} e ^ {i \omega_ {j} t} = \frac {e ^ {i \omega_ {j}} (1 - e ^ {i \omega_ {j} T})}{1 - e ^ {i \omega_ {j}}} = 0 \\ \Rightarrow \sum_ {t = 1} ^ {T} c _ {j t} + i \sum_ {t = 1} ^ {T} s _ {j t} = 0 \Rightarrow \sum_ {t = 1} ^ {T} c _ {j t} = \sum_ {t = 1} ^ {T} s _ {j t} = 0 \\ \end{array}
$$

and

$$
\begin{array}{l} \sum_ {t = 1} ^ {T} c _ {j t} s _ {j t} = \frac {1}{2} \sum_ {t = 1} ^ {T} \sin (2 \omega_ {j} t) = 0, \\ \sum_ {t = 1} ^ {T} c _ {j t} ^ {2} = \frac {1}{2} \sum_ {t = 1} ^ {T} \{1 + \cos (2 \omega_ {j} t) \} = T / 2, \\ \sum_ {t = 1} ^ {T} s _ {j t} ^ {2} = \frac {1}{2} \sum_ {t = 1} ^ {T} \{1 - \cos (2 \omega_ {j} t) \} = T / 2, \\ \sum_ {t = 1} ^ {T} c _ {j t} s _ {k t} = \sum_ {t = 1} ^ {T} c _ {j t} c _ {k t} = \sum_ {t = 1} ^ {T} s _ {j t} s _ {k t} = 0, \quad j \neq k. \\ \end{array}
$$

Using these, we have

$$
\hat {\theta} = \left( \begin{array}{c} \hat {\alpha} _ {0} \\ \hat {\alpha} _ {1} \\ \vdots \\ \hat {\beta} _ {m} \end{array} \right) = \left( \begin{array}{c c c c} T & 0 & \dots & 0 \\ 0 & T / 2 & \dots & 0 \\ \vdots & \vdots & & \vdots \\ 0 & 0 & \dots & T / 2 \end{array} \right) ^ {- 1} \left( \begin{array}{c} \sum_ {t} y _ {t} \\ \sum_ {t} c _ {1 t} y _ {t} \\ \vdots \\ \sum_ {t} s _ {m t} y _ {t} \end{array} \right) = \left( \begin{array}{c} \bar {y} \\ (2 / T) \sum_ {t} c _ {1 t} y _ {t} \\ \vdots \\ (2 / T) \sum_ {t} s _ {m t} y _ {t} \end{array} \right)
$$

and the regression sum of squares is

$$
\hat {Y} ^ {\top} \hat {Y} = Y ^ {\top} X (X ^ {\top} X) ^ {- 1} X ^ {\top} Y = T \bar {y} ^ {2} + \sum_ {j = 1} ^ {m} \frac {2}{T} \left[ \left\{\sum_ {t = 1} ^ {T} c _ {j t} y _ {t} \right\} ^ {2} + \left\{\sum_ {t = 1} ^ {T} s _ {j t} y _ {t} \right\} ^ {2} \right].
$$

Since we are fitting $T$ unknown parameters to $T$ data points, the model fits with no residual error, i.e., ${ \hat { Y } } = Y$ . Hence

$$
\sum_ {t = 1} ^ {T} (y _ {t} - \bar {y}) ^ {2} = \sum_ {j = 1} ^ {m} \frac {2}{T} \left[ \left\{\sum_ {t = 1} ^ {T} c _ {j t} y _ {t} \right\} ^ {2} + \left\{\sum_ {t = 1} ^ {T} s _ {j t} y _ {t} \right\} ^ {2} \right].
$$

This motivates definition of the periodogram as

$$
I (\omega) = \frac {1}{\pi T} \left[ \left\{\sum_ {t = 1} ^ {T} y _ {t} \cos (\omega t) \right\} ^ {2} + \left\{\sum_ {t = 1} ^ {T} y _ {t} \sin (\omega t) \right\} ^ {2} \right].
$$

A factor of $( 1 / 2 \pi )$ has been introduced into this definition so that the sample variance, $\begin{array} { r } { \hat { \gamma } _ { 0 } = ( 1 / T ) \sum _ { t = 1 } ^ { T } ( y _ { t } - \bar { y } ) ^ { 2 } } \end{array}$ , equates to the sum of the areas of $m$ rectangles, whose heights are $I ( \omega _ { 1 } ) , \ldots , I ( \omega _ { m } )$ , whose widths are $2 \pi / T$ , and whose bases are centred at $\omega _ { 1 } , \ldots , \omega _ { m }$ . I.e., $\begin{array} { r } { \hat { \gamma } _ { 0 } = ( 2 \pi / T ) \sum _ { j = 1 } ^ { m } I ( \omega _ { j } ) } \end{array}$ . These rectangles approximate the area under the curve $I ( \omega )$ , $0 \leq \omega \leq \pi$ .

![](images/25e1163d2f6ecd61f455b5bb246f8950a53fc18ff1dcd582aa42b82eef22083f.jpg)

Using the fact that $\textstyle \sum _ { t = 1 } ^ { T } c _ { j t } = \sum _ { t = 1 } ^ { T } s _ { j t } = 0$ , we can write

$$
\begin{array}{l} \pi T I (\omega_ {j}) = \left\{\sum_ {t = 1} ^ {T} y _ {t} \cos (\omega_ {j} t) \right\} ^ {2} + \left\{\sum_ {t = 1} ^ {T} y _ {t} \sin (\omega_ {j} t) \right\} ^ {2} \\ = \left\{\sum_ {t = 1} ^ {T} (y _ {t} - \bar {y}) \cos (\omega_ {j} t) \right\} ^ {2} + \left\{\sum_ {t = 1} ^ {T} (y _ {t} - \bar {y}) \sin (\omega_ {j} t) \right\} ^ {2} \\ = \left| \sum_ {t = 1} ^ {T} \left(y _ {t} - \bar {y}\right) e ^ {i \omega_ {j} t} \right| ^ {2} \\ = \sum_ {t = 1} ^ {T} (y _ {t} - \bar {y}) e ^ {i \omega_ {j} t} \sum_ {s = 1} ^ {T} (y _ {s} - \bar {y}) e ^ {- i \omega_ {j} s} \\ = \sum_ {t = 1} ^ {T} (y _ {t} - \bar {y}) ^ {2} + 2 \sum_ {k = 1} ^ {T - 1} \sum_ {t = k + 1} ^ {T} (y _ {t} - \bar {y}) (y _ {t - k} - \bar {y}) \cos (\omega_ {j} k). \\ \end{array}
$$

Hence

$$
I (\omega_ {j}) = \frac {1}{\pi} \hat {\gamma} _ {0} + \frac {2}{\pi} \sum_ {k = 1} ^ {T - 1} \hat {\gamma} _ {k} \cos (\omega_ {j} k).
$$

$I ( \omega )$ is therefore a sample version of the spectral density $f ( \omega )$ .

# 4.2 Distribution of spectral estimates

If the process is stationary and the spectral density exists then $I ( \omega )$ is an almost unbiased estimator of $f ( \omega )$ , but it is a rather poor estimator without some smoothing.

Suppose $\{ y _ { t } \}$ is Gaussian white noise, i.e., $y _ { 1 } , \ldots , y _ { T }$ are iid $N ( 0 , \sigma ^ { 2 } )$ . Then for any Fourier frequency $\omega = 2 \pi j / T$ ,

$$
I (\omega) = \frac {1}{\pi T} \left[ A (\omega) ^ {2} + B (\omega) ^ {2} \right], \tag {4.1}
$$

where

$$
A (\omega) = \sum_ {t = 1} ^ {T} y _ {t} \cos (\omega t), \quad B (\omega) = \sum_ {t = 1} ^ {T} y _ {t} \sin (\omega t). \tag {4.2}
$$

Clearly $A ( \omega )$ and $B ( \omega )$ have zero means, and

$$
\begin{array}{l} \mathrm {v a r} [ A (\omega) ] = \sigma^ {2} \sum_ {t = 1} ^ {T} \cos^ {2} (\omega t) = T \sigma^ {2} / 2, \\ \mathrm {v a r} [ B (\omega) ] = \sigma^ {2} \sum_ {t = 1} ^ {T} \sin^ {2} (\omega t) = T \sigma^ {2} / 2, \\ \end{array}
$$

$$
\operatorname {c o v} [ A (\omega), B (\omega) ] = \mathbb {E} \left[ \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} y _ {t} y _ {s} \cos (\omega t) \sin (\omega s) \right] = \sigma^ {2} \sum_ {t = 1} ^ {T} \cos (\omega t) \sin (\omega t) = 0.
$$

Hence $A ( \omega ) \sqrt { 2 / T \sigma ^ { 2 } }$ and $B ( \omega ) \sqrt { 2 / T \sigma ^ { 2 } }$ are independently distributed as $N ( 0 , 1 )$ , and $2 \left[ A ( \omega ) ^ { 2 } + B ( \omega ) ^ { 2 } \right] / ( T \sigma ^ { 2 } )$ is distributed as $\chi _ { 2 } ^ { 2 }$ . This gives $I ( \omega ) \sim ( \sigma ^ { 2 } / \pi ) \chi _ { 2 } ^ { 2 } / 2$ . Thus we see that $I ( w )$ is an unbiased estimator of the spectrum, $f ( \omega ) = \sigma ^ { 2 } / \pi$ , but it is not consistent, since $\mathrm { v a r } [ I ( \omega ) ] = \sigma ^ { 4 } / \pi ^ { 2 }$ does not tend to 0 as $T \to \infty$ . This is perhaps surprising, but is explained by the fact that as $T$ increases we are attempting to estimate $I ( \omega )$ for an increasing number of Fourier frequencies, with the consequence that the precision of each estimate does not change.

By a similar argument, we can show that for any two Fourier frequencies, $\omega _ { j }$ and $\omega _ { k }$ the estimates $I ( \omega _ { j } )$ and $I ( \omega _ { k } )$ are statistically independent. These conclusions hold more generally.

Theorem 4.1 Let $\{ Y _ { t } \}$ be a stationary Gaussian process with spectrum $f ( \omega )$ . Let $I ( \cdot )$ be the periodogram based on samples $Y _ { 1 } , \dots , Y _ { T }$ , and let $\omega _ { j } = 2 \pi j / T$ , $j < T / 2$ , be a Fourier frequency. Then in the limit as $T \to \infty$ ,

(a) $I ( \omega _ { j } ) \sim f ( \omega _ { j } ) \chi _ { 2 } ^ { 2 } / 2 .$   
(b) $I ( \omega _ { j } )$ and $I ( \omega _ { k } )$ are independent for $j \neq k$ .

Assuming that the underlying spectrum is smooth, $f ( \omega )$ is nearly constant over a small range of $\omega$ . This motivates use of an estimator for the spectrum of

$$
\hat {f} (\omega_ {j}) = \frac {1}{2 p + 1} \sum_ {\ell = - p} ^ {p} I (\omega_ {j + \ell}).
$$

Then $\hat { f } ( \omega _ { j } ) \sim f ( \omega _ { j } ) \chi _ { 2 ( 2 p + 1 ) } ^ { 2 } / [ 2 ( 2 p + 1 ) ]$ , which has variance $f ( \omega ) ^ { 2 } / ( 2 p + 1 )$ . The idea is to let $p \longrightarrow \infty$ as $T \to \infty$ .

# 4.3 The fast Fourier transform

$I ( \omega _ { j } )$ can be calculated from (4.1)–(4.2), or from

$$
I (\omega_ {j}) = \frac {1}{\pi T} \left| \sum_ {t = 1} ^ {T} y _ {t} e ^ {i \omega_ {j} t} \right| ^ {2}.
$$

Either way, this requires of order $T$ multiplications. Hence to calculate the complete periodogram, i.e., $I ( \omega _ { 1 } ) , \ldots , I ( \omega _ { m } )$ , requires of order $T ^ { 2 }$ multiplications. Computation effort can be reduced significantly by use of the fast Fourier transform, which computes $I ( \omega _ { 1 } ) , \ldots , I ( \omega _ { m } )$ using only order $T \log _ { 2 } T$ multiplications.

# 5 Linear filters

# 5.1 The Filter Theorem

A linear filter of one random sequence $\{ X _ { t } \}$ into another sequence $\{ Y _ { t } \}$ i s

$$
Y _ {t} = \sum_ {s = - \infty} ^ {\infty} a _ {s} X _ {t - s}. \tag {5.1}
$$

Theorem 5.1 (the filter theorem) Suppose $X _ { t }$ is a stationary time series with spec-Then the process tral density $f _ { X } ( \omega )$ $\begin{array} { r } { Y _ { t } = \sum _ { s = - \infty } ^ { \infty } a _ { s } X _ { t - s } } \end{array}$ . Let $\{ a _ { t } \}$ be a sequence of real numbers such that t=−∞ is a stationary time series with spectral density $\scriptstyle \sum _ { t = - \infty } ^ { \infty } \left| a _ { t } \right| < \infty$ . function

$$
f _ {Y} (\omega) = \left| A (e ^ {i \omega}) \right| ^ {2} f _ {X} (\omega) = | a (\omega) | ^ {2} f _ {X} (\omega),
$$

where $A ( z )$ is the filter generating function

$$
A (z) = \sum_ {s = - \infty} ^ {\infty} a _ {s} z ^ {s}, \quad | z | \leq 1.
$$

and $a ( \omega ) = A ( e ^ { i \omega } )$ is the transfer function of the linear filter.

Proof.

$$
\begin{array}{l} \operatorname {c o v} \left(Y _ {t}, Y _ {t + k}\right) = \sum_ {r \in \mathbb {Z}} \sum_ {s \in \mathbb {Z}} a _ {r} a _ {s} \operatorname {c o v} \left(X _ {t - r}, X _ {t + k - s}\right) \\ = \sum_ {r, s \in \mathbb {Z}} a _ {r} a _ {s} \gamma_ {k + r - s} \\ = \sum_ {r, s \in \mathbb {Z}} a _ {r} a _ {s} \int_ {- \pi} ^ {\pi} \frac {1}{2} e ^ {i \omega (k + r - s)} f _ {X} (\omega) d \omega \\ = \int_ {- \pi} ^ {\pi} A (e ^ {i \omega}) A (e ^ {- i \omega}) \frac {1}{2} e ^ {i \omega k} f _ {X} (\omega) d \omega \\ = \int_ {- \pi} ^ {\pi} \frac {1}{2} e ^ {i \omega k} \left| A (e ^ {i \omega}) \right| ^ {2} f _ {X} (\omega) d \omega \\ = \int_ {- \pi} ^ {\pi} \frac {1}{2} e ^ {i \omega k} f _ {Y} (\omega) d \omega . \\ \end{array}
$$

Thus $f _ { Y } ( \omega )$ is the spectral density for $Y$ and $Y$ is stationary.

# 5.2 Application to autoregressive processes

Let us use the notation $B$ for the backshift operator

$$
B ^ {0} = I, \quad (B ^ {0} X) _ {t} = X _ {t}, \quad (B X) _ {t} = X _ {t - 1}, \quad (B ^ {2} X) _ {t} = X _ {t - 2}, \quad \ldots
$$

Then the AR(p) process can be written as

$$
\left(I - \sum_ {r = 1} ^ {p} \phi_ {r} B ^ {r}\right) X = \epsilon
$$

or $\phi ( B ) X = \epsilon$ , where $\phi$ is the function

$$
\phi (z) = 1 - \sum_ {r = 1} ^ {p} \phi_ {r} z ^ {r}.
$$

By the filter theorem, $f _ { \epsilon } ( \omega ) = | \phi \left( e ^ { i \omega } \right) | ^ { 2 } f _ { X } ( \omega )$ , so since $f _ { \epsilon } ( \omega ) = \sigma ^ { 2 } / \pi$ ,

$$
f _ {X} (\omega) = \frac {\sigma^ {2}}{\pi | \phi (e ^ {i \omega}) | ^ {2}}. (5. 2)
$$

As $\begin{array} { r } { f _ { X } ( \omega ) = ( 1 / \pi ) \sum _ { k = - \infty } ^ { \infty } \gamma _ { k } e ^ { - i \omega k } } \end{array}$ , we can calculate the autocovariances by expanding $f _ { X } ( \omega )$ as a power series in $e ^ { i \omega }$ . For this to work, the zeros of $\phi ( z )$ must lie outside the unit circle in $\mathbb { C }$ . This is the stationarity condition for the AR(p) process.

# Example 5.2

For the AR(1) process, $X _ { t } - \phi _ { 1 } X _ { t - 1 } = \epsilon _ { t }$ , we have $\phi ( z ) = 1 - \phi _ { 1 } z$ , with its zero at $z = 1 / \phi _ { 1 }$ . The stationarity condition is $| \phi _ { 1 } | < 1$ . Using (5.2) we find

$$
f _ {X} (\omega) = \frac {\sigma^ {2}}{\pi | 1 - \phi e ^ {i \omega} | ^ {2}} = \frac {\sigma^ {2}}{\pi (1 - 2 \phi \cos \omega + \phi^ {2})},
$$

which is what we found by other another method in Example 3.1(c). To find the autocovariances we can write, taking $z = e ^ { i \omega }$ ,

$$
\begin{array}{l} \frac {1}{| \phi_ {1} (z) | ^ {2}} = \frac {1}{\phi_ {1} (z) \phi_ {1} (1 / z)} = \frac {1}{(1 - \phi_ {1} z) (1 - \phi_ {1} / z)} = \sum_ {r = 0} ^ {\infty} \phi_ {1} ^ {r} z ^ {r} \sum_ {s = 0} ^ {\infty} \phi_ {1} ^ {s} z ^ {- s} \\ = \sum_ {k = - \infty} ^ {\infty} z ^ {k} (\phi_ {1} ^ {| k |} (1 + \phi_ {1} ^ {2} + \phi_ {1} ^ {4} + \dots)) = \sum_ {k = - \infty} ^ {\infty} \frac {z ^ {k} \phi_ {1} ^ {| k |}}{1 - \phi_ {1} ^ {2}} \\ \Longrightarrow f _ {X} (\omega) = \frac {1}{\pi} \sum_ {k = - \infty} ^ {\infty} \frac {\sigma^ {2} \phi_ {1} ^ {| k |}}{1 - \phi_ {1} ^ {2}} e ^ {i \omega k} \\ \end{array}
$$

and so $\gamma _ { k } = \sigma ^ { 2 } \phi _ { 1 } ^ { | k | } / ( 1 - \phi _ { 1 } ^ { 2 } )$ as we saw before.

In general, it is often easier to calculate the spectral density function first, using filters, and then deduce the autocovariance function from it.

# 5.3 Application to moving average processes

The MA(q) process $\begin{array} { r } { X _ { t } = \epsilon _ { t } + \sum _ { s = 1 } ^ { q } \theta _ { s } \epsilon _ { t - s } } \end{array}$ can be written as

$$
X = \theta (B) \epsilon
$$

where $\begin{array} { r } { \theta ( z ) = \sum _ { s = 0 } ^ { q } \theta _ { s } B ^ { s } } \end{array}$ . By the filter theorem, $f _ { X } ( \omega ) = | \theta ( e ^ { i \omega } ) | ^ { 2 } ( \sigma ^ { 2 } / \pi )$ .

# Example 5.3

For the MA(1), $X _ { t } = \epsilon _ { t } + \theta _ { 1 } \epsilon _ { t - 1 }$ , $\theta ( z ) = 1 + \theta _ { 1 } z$ and

$$
f _ {X} (\omega) = \frac {\sigma^ {2}}{\pi} \left(1 + 2 \theta_ {1} \cos \omega + \theta_ {1} ^ {2}\right).
$$

As above, we can obtain the autocovariance function by expressing $f _ { X } ( \omega )$ as a power series in $e ^ { i \omega }$ . We have

$$
f _ {X} (\omega) = \frac {\sigma^ {2}}{\pi} \left(\theta_ {1} e ^ {- i \omega} + (1 + \theta_ {1} ^ {2}) + \theta_ {1} e ^ {i \omega}\right) = \frac {\sigma^ {2}}{\pi} \theta (e ^ {i \omega}) \theta (e ^ {- i \omega})
$$

So $\gamma _ { 0 } = \sigma ^ { 2 } ( 1 + \theta _ { 1 } ^ { 2 } )$ , $\gamma _ { 1 } = \theta _ { 1 } \sigma ^ { 2 }$ , γ2 = 0, |k| > 1.

As we remarked in Section 1.5, the autocovariance function of a MA(1) process with parameters $( \sigma ^ { 2 } , \theta _ { 1 } )$ is identical to one with parameters $( \theta _ { 1 } ^ { 2 } \sigma ^ { 2 } , \theta _ { 1 } ^ { - 1 } )$ . That is,

$$
\gamma_ {0} ^ {*} = \theta_ {1} ^ {2} \sigma^ {2} (1 + 1 / \theta_ {1} ^ {2}) = \sigma^ {2} (1 + \theta_ {1} ^ {2}) = \gamma_ {0}
$$

$$
\rho_ {1} ^ {*} = \theta_ {1} ^ {- 1} / (1 + \theta_ {1} ^ {- 2}) = \theta_ {1} / (1 + \theta_ {1} ^ {2}) = \rho_ {1}.
$$

In general, the MA(q) process can be written as $X = \theta ( B ) \epsilon$ , where

$$
\theta (z) = \sum_ {k = 0} ^ {q} \theta_ {k} z ^ {k} = \prod_ {k = 1} ^ {q} (\omega_ {k} - z).
$$

So the autocovariance generating function is

$$
g (z) = \sum_ {k = - q} ^ {q} \gamma_ {k} z ^ {k} = \sigma^ {2} \theta (z) \theta \left(z ^ {- 1}\right) = \sigma^ {2} \prod_ {k = 1} ^ {q} \left(\omega_ {k} - z\right) \left(\omega_ {k} - z ^ {- 1}\right). \tag {5.3}
$$

Note that $( \omega _ { k } - z ) ( \omega _ { k } - z ^ { - 1 } ) = \omega _ { k } ^ { 2 } ( \omega _ { k } ^ { - 1 } - z ) ( \omega _ { k } ^ { - 1 } - z ^ { - 1 } )$ . So $g ( z )$ is unchanged in (5.3) if (for any $k$ such that $\omega _ { k }$ is real) we replace $\omega _ { k }$ by $\omega _ { k } ^ { - 1 }$ and multiply $\sigma ^ { 2 }$ by $\omega _ { k } ^ { 2 }$ . Thus (if all roots of $\theta ( z ) = 0$ are real) there can be $2 ^ { q }$ different $M A ( q )$ processes with the same autocovariance function. For identifiability, we assume that all the roots of $\theta ( z )$ lie outside the unit circle in $\mathbb { C }$ . This is equivalent to the invertibility condition, that $\epsilon _ { t }$ can be written as a convergent power series in $\{ X _ { t } , X _ { t - 1 } , . . . \}$ .

# 5.4 The general linear process

A special case of (5.1) is the general linear process,

$$
Y _ {t} = \sum_ {s = 0} ^ {\infty} a _ {s} X _ {t - s},
$$

where $\{ X _ { t } \}$ is white noise. This has

$$
\operatorname {c o v} (Y _ {t}, Y _ {t + k}) = \sigma^ {2} \sum_ {s = 0} ^ {\infty} a _ {s} a _ {s + k} \leq \sigma^ {2} \sum_ {s = 0} ^ {\infty} a _ {s} ^ {2},
$$

where the inequality is an equality when $k ~ = ~ 0$ . Thus $\{ Y _ { t } \}$ is stationary if and only if $\textstyle \sum _ { s = 0 } ^ { \infty } a _ { s } ^ { 2 } < \infty$ . In practice the general linear model is useful when the $a _ { s }$ are expressible in terms of a finite number of parameters which can be estimated. A rich class of such models are the ARMA models.

# 5.5 Filters and ARMA processes

The ARMA $( p , q )$ model can be written as $\phi ( B ) X = \theta ( B ) \epsilon$ . Thus

$$
| \phi (e ^ {i \omega}) | ^ {2} f _ {X} (\omega) = | \theta (e ^ {i \omega}) | ^ {2} \frac {\sigma^ {2}}{\pi} \quad \Longrightarrow \quad f _ {X} (\omega) = \left| \frac {\theta (e ^ {i \omega})}{\phi (e ^ {i \omega})} \right| ^ {2} \frac {\sigma^ {2}}{\pi}.
$$

This is subject to the conditions that

• the zeros of $\phi$ lie outside the unit circle in $\mathbb { C }$ for stationarity.   
the zeros of $\theta$ lie outside the unit circle in $\mathbb { C }$ for identifiability.   
• $\phi ( z )$ and $\theta ( z )$ have no common roots.

If there were a common root, say $1 / \alpha$ , so that $( I - \alpha B ) \phi _ { 1 } ( B ) X = ( I - \alpha B ) \theta _ { 1 } ( B ) \epsilon$ , then we could multiply both sides by $\textstyle \sum _ { n = 0 } ^ { \infty } \alpha ^ { n } B ^ { n }$ and deduce $\phi _ { 1 } ( B ) X = \theta _ { 1 } ( B ) \epsilon$ , and thus that a more economical ARMA $( p - 1 , q - 1 )$ model suffices.

# 5.6 Calculating autocovariances in ARMA models

As above, the filter theorem can assist in calculating the autocovariances of a model. These can be compared with autocovariances estimated from the data. For example, an ARMA(1, 2) has

$$
\phi (z) = 1 - \phi z, \quad \theta (z) = 1 + \theta_ {1} z + \theta_ {2} z ^ {2}, \quad \mathrm {w h e r e} | \phi | <   1.
$$

Then $X = C ( B ) \epsilon$ , where

$$
C (z) = \theta (z) / \phi (z) = \left(1 + \theta_ {1} z + \theta_ {2} z ^ {2}\right) \sum_ {n = 0} ^ {\infty} \phi^ {n} z ^ {n} = \sum_ {n = 0} ^ {\infty} c _ {n} z ^ {n},
$$

with $c _ { 0 } = 1$ , $c _ { 1 } = \phi + \theta _ { 1 }$ , and

$$
c _ {n} = \phi^ {n} + \phi^ {n - 1} \theta_ {1} + \phi^ {n - 1} \theta_ {2} = \phi^ {n - 2} \left(\phi^ {2} + \phi \theta_ {1} + \theta^ {2}\right), \quad n \geq 2.
$$

So $\begin{array} { r } { X _ { t } = \sum _ { n = 0 } ^ { \infty } c _ { n } \epsilon _ { t - n } } \end{array}$ and we can compute covariances as

$$
\gamma_ {k} = \mathrm {c o v} (X _ {t}, X _ {t + k}) = \sum_ {n, m = 0} ^ {\infty} c _ {n} c _ {m} \mathrm {c o v} (\epsilon_ {t - n}, \epsilon_ {t + k - m}) = \sum_ {n = 0} ^ {\infty} c _ {n} c _ {n + k} \sigma^ {2}.
$$

For example, $\gamma _ { k } = \phi \gamma _ { k - 1 }$ , $k \geq 3$ . As a test of whether the model is ARMA(1, 2) we might look to see if the sample autocovariances decay geometrically, for $k \geq 2$ ,

# 6 Estimation of trend and seasonality

# 6.1 Moving averages

Consider a decomposition into trend, seasonal, cyclic and residual components.

$$
X _ {t} = T _ {t} + I _ {t} + C _ {t} + E _ {t}.
$$

Thus far we have been concerned with modelling $\{ E _ { t } \}$ . We have also seen that the periodogram can be useful for recognising the presence of $\{ C _ { t } \}$ .

We can estimate trend using a symmetric moving average,

$$
\hat {T} _ {t} = \sum_ {s = - k} ^ {k} a _ {s} X _ {t + s},
$$

where $a _ { s } = a _ { - s }$ . In this case the transfer function is real-valued.

The choice of moving averages requires care. For example, we might try to estimate the trend with

$$
\hat {T} _ {t} = \frac {1}{3} \left(X _ {t - 1} + X _ {t} + X _ {t + 1}\right).
$$

But suppose $X _ { t } = T _ { t } + \epsilon _ { t }$ , where trend is the quadratic $T _ { t } = a + b t + c t ^ { 2 }$ . Then

$$
\hat {T} _ {t} = T _ {t} + \frac {2}{3} c + \frac {1}{3} \big (\epsilon_ {t - 1} + \epsilon_ {t} + \epsilon_ {t + 1} \big),
$$

so $\begin{array} { r } { \mathbb { E } \hat { T } _ { t } = \mathbb { E } X _ { t } + \frac { 2 } { 3 } c } \end{array}$ and thus $\hat { T }$ is a biased estimator of the trend.

This problem is avoided if we estimate trend by fitting a polynomial of sufficient degree, e.g., to find a cubic that best fits seven successive points we minimize

$$
\sum_ {t = - 3} ^ {3} \left(X _ {t} - b _ {0} - b _ {1} t - b _ {2} t ^ {2} - b _ {3} t ^ {3}\right) ^ {2}.
$$

So

$$
\begin{array}{l} \sum X _ {t} = 7 \hat {b} _ {0} + 2 8 \hat {b} _ {2} \\ \sum t X _ {t} = 2 8 \hat {b} _ {1} + 1 9 6 \hat {b} _ {3} \\ \sum t ^ {2} X _ {t} = 2 8 \hat {b} _ {0} + 1 9 6 \hat {b} _ {2} \\ \sum t ^ {3} X _ {t} = 1 9 6 \hat {b} _ {1} + 1 5 8 8 \hat {b} _ {3} \\ \end{array}
$$

Then

$$
\begin{array}{l} \hat {b} _ {0} = \frac {1}{2 1} \left(7 \sum X _ {t} - \sum t ^ {2} X _ {t}\right) \\ = \frac {1}{2 1} \left(- 2 X _ {- 3} + 3 X _ {- 2} + 6 X _ {- 1} + 7 X _ {0} + 6 X _ {1} + 3 X _ {2} - 2 X _ {3}\right). \\ \end{array}
$$

We estimate the trend at time 0 by $\hat { T } _ { 0 } = \hat { b } _ { 0 }$ , and similarly,

$$
\hat {T} _ {t} = \frac {1}{2 1} \left(- 2 X _ {t - 3} + 3 X _ {t - 2} + 6 X _ {t - 1} + 7 X _ {t} + 6 X _ {t + 1} + 3 X _ {t + 2} - 2 X _ {t + 3}\right).
$$

A notation for this moving average is $\begin{array} { r } { \frac { 1 } { 2 1 } [ - 2 , 3 , 6 , 7 , 6 , 3 , - 2 ] } \end{array}$ . Note that the weights sum to 1. In general, we can fit a polynomial of degree $q$ to $2 q + 1$ points by applying a symmetric moving average. (We fit to an odd number of points so that the midpoint of fitted range coincides with a point in time at which data is measured.)

A value for $q$ can be identified using the variate difference method: if $\{ X _ { t } \}$ i s indeed a polynomial of degree $q$ , plus residual error $\left\{ \epsilon _ { t } \right\}$ , then the trend in $\Delta ^ { r } X _ { t }$ is a polynomial of degree $q - r$ and

$$
\Delta^ {q} X _ {t} = \mathrm {c o n s t a n t} + \Delta^ {q} \epsilon_ {t} = \mathrm {c o n s t a n t} + \epsilon_ {t} - \binom {q} {1} \epsilon_ {t - 1} + \binom {q} {2} \epsilon_ {t - 2} - \dots + (- 1) ^ {q} \epsilon_ {t - q}.
$$

The variance of $\Delta ^ { q } X _ { t }$ is therefore

$$
\mathrm {v a r} (\Delta^ {q} \epsilon_ {t}) = \left[ 1 + \binom {q} {1} ^ {2} + \binom {q} {2} ^ {2} + \dots + 1 \right] \sigma^ {2} = \binom {2 q} {q} \sigma^ {2},
$$

where the simplification in the final line comes from looking at the coefficient of $z ^ { q }$ in expansions of both sides of

$$
(1 + z) ^ {q} (1 + z) ^ {q} = (1 + z) ^ {2 q}.
$$

Define $V _ { r } = \mathrm { v a r } ( \Delta ^ { r } X _ { t } ) / \binom { 2 r } { r }$ . The fact that the plot of $V _ { r }$ against $r$ should flatten out at $r \geq q$ can be used to identify $q$ .

# 6.2 Centred moving averages

If there is a seasonal component then a centred-moving average is useful. Suppose data is measured quarterly, then applying twice the moving average ${ \scriptstyle { \frac { 1 } { 4 } } } [ 1 , 1 , 1 , 1 ]$ is equivalent to applying once the moving average $^ { \frac { 1 } { 8 } [ 1 , 2 , 2 , 2 , 1 ] }$ . Notice that this socalled centred average of fours weights each quarter equally. Thus if $X _ { t } = I _ { t } + \epsilon _ { t }$ , where $I _ { t }$ has period 4, and $I _ { 1 } + I _ { 2 } + I _ { 3 } + I _ { 4 } = 0$ , then $\hat { T } _ { t }$ has no seasonal component. Similarly, if data were monthly we use a centred average of 12s, that is, $\scriptstyle { \frac { 1 } { 2 4 } } [ 1 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 2 , 1 ]$ .

# 6.3 The Slutzky-Yule effect

To remove both trend and seasonal components we might successively apply a number of moving averages, one or more to remove trend and another to remove seasonal effects. This is the procedure followed by some standard forecasting packages.

However, there is a danger that application of successive moving averages can introduce spurious effects. The Slutzky-Yule effect is concerned with the fact that a moving average repeatedly applied to a purely random series can introduce artificial cycles. Slutzky (1927) showed that some trade cycles of the nineteenth century were no more than artifacts of moving averages that had been used to smooth the data.

To illustrate this idea, suppose the moving average $\begin{array} { r } { { \frac { 1 } { 6 } } [ - 1 , 2 , 4 , 2 , - 1 ] } \end{array}$ is applied $k$ times to a white noise series. This moving average has transfer function, $\begin{array} { r } { a ( \omega ) = \frac { 1 } { 6 } ( 4 + } \end{array}$ $4 \cos \omega - 2 \cos 2 \omega )$ , which is maximal at $\omega = \pi / 3$ . The smoothed series has a spectral density, say $f _ { k } ( \omega )$ , proportional to $a ( \omega ) ^ { 2 k }$ , and hence for $\omega \neq \pi / 3$ , $f _ { k } ( \omega ) / f _ { k } ( \pi / 3 ) \to 0$ as $k \to \infty$ . Thus in the limit the smoothed series is a periodic wave with period 6.

# 6.4 Exponential smoothing

# Single exponential smoothing

Suppose the mean level of a series drifts slowly over time. A naive one-step-ahead forecast is $X _ { t } ( 1 ) = X _ { t }$ . However, we might let all past observations play a part in the forecast, but give greater weights to those that are more recent. Choose weights to decrease exponentially and let

$$
X _ {t} (1) = \frac {1 - \omega}{1 - \omega^ {t}} \left(X _ {t} + \omega X _ {t - 1} + \omega^ {2} X _ {t - 2} + \dots + \omega^ {t - 1} X _ {1}\right),
$$

where $0 < \omega < 1$ . Define $S _ { t }$ as the right hand side of the above as $t \to \infty$ , i.e.,

$$
S _ {t} = (1 - \omega) \sum_ {s = 0} ^ {\infty} \omega^ {s} X _ {t - s}.
$$

$S _ { t }$ can serve as a one-step-ahead forecast, $X _ { t } ( 1 )$ . $S _ { t }$ is known as simple exponential smoothing. Let $\alpha = 1 - \omega$ . Simple algebra gives

$$
S _ {t} = \alpha X _ {t} + (1 - \alpha) S _ {t - 1}
$$

$$
X _ {t} (1) = X _ {t - 1} (1) + \alpha \left[ X _ {t} - X _ {t - 1} (1) \right].
$$

This shows that the one-step-ahead forecast at time $t$ is the one-step-ahead forecast at time $t - 1$ , modified by $\alpha$ times the forecasting error incurred at time $t - 1$ .

To get things started we might set $S _ { 0 }$ equal to the average of the first few data points. We can play around with $\alpha$ , choosing it to minimize the mean square forecasting error. In practice, $\alpha$ in the range 0.25–0.5 usually works well.

# Double exponential smoothing

Suppose the series is approximately linear, but with a slowly varying trend. If it were true that $X _ { t } = b _ { 0 } + b _ { 1 } t + \epsilon _ { t }$ , then

$$
\begin{array}{l} S _ {t} = (1 - \omega) \sum_ {s = 0} ^ {\infty} \omega^ {s} \left(b _ {0} + b _ {1} (t - s) + \epsilon_ {t}\right) \\ = b _ {0} + b _ {1} t - b _ {1} (1 - \omega) \sum_ {s = 0} ^ {\infty} \omega^ {s} s + b _ {1} (1 - \omega) \sum_ {s = 0} ^ {\infty} \omega^ {s} \epsilon_ {t - s}, \\ \end{array}
$$

and hence

$$
\mathbb {E} S _ {t} = b _ {0} + b _ {1} t - b _ {1} \omega / (1 - \omega) = \mathbb {E} X _ {t + 1} - b _ {1} / (1 - \omega).
$$

Thus the forecast has a bias of $- b _ { 1 } / ( 1 - \omega )$ . To eliminate this bias let $S _ { t } ^ { 1 } = S _ { t }$ be the first smoothing, and $S _ { t } ^ { 2 } = \alpha S _ { t } ^ { 1 } + ( 1 - \alpha ) S _ { t - 1 } ^ { 2 }$ be the simple exponential smoothing of $S _ { t } ^ { 1 }$ . Then

$$
\mathbb {E} S _ {t} ^ {2} = \mathbb {E} S _ {t} ^ {1} - b _ {1} \omega / (1 - \omega) = \mathbb {E} X _ {t} - 2 b _ {1} \omega / (1 - \omega),
$$

$$
\mathbb {E} (2 S _ {t} ^ {1} - S _ {t} ^ {2}) = b _ {0} + b _ {1} t, \qquad \mathbb {E} (S _ {t} ^ {1} - S _ {t} ^ {2}) = b _ {1} (1 - \alpha) / \alpha .
$$

This suggests the estimates $\hat { b } _ { 0 } + \hat { b } _ { 1 } t = 2 S _ { t } ^ { 1 } - S _ { t } ^ { 2 }$ and $\hat { b } _ { 1 } = \alpha ( S _ { t } ^ { 1 } - S _ { t } ^ { 2 } ) / ( 1 - \alpha )$ . The forecasting equation is then

$$
X _ {t} (s) = \hat {b} _ {0} + \hat {b} _ {1} (t + s) = (2 S _ {t} ^ {1} - S _ {t} ^ {2}) + s \alpha (S _ {t} ^ {1} - S _ {t} ^ {2}) / (1 - \alpha).
$$

As with single exponential smoothing we can experiment with choices of $\alpha$ and find $S _ { 0 } ^ { 1 }$ and $S _ { 0 } ^ { 2 }$ by fitting a regression line, $X _ { t } = \hat { \beta } _ { 0 } + \hat { \beta } _ { 1 } t$ , to the first few points of the series and solving

$$
S _ {0} ^ {1} = \hat {\beta} _ {0} - (1 - \alpha) \hat {\beta} _ {1} / \alpha , \qquad S _ {0} ^ {2} = \hat {\beta} _ {0} - 2 (1 - \alpha) \hat {\beta} _ {1} / \alpha .
$$

# 6.5 Calculation of seasonal indices

Suppose data is quarterly and we want to fit an additive model. Let $\hat { I } _ { 1 }$ be the average of $X _ { 1 } , X _ { 5 } , X _ { 9 } , . . .$ , let $\hat { I } _ { 2 }$ be the average of $X _ { 2 } , X _ { 6 } , X _ { 1 0 } , . . .$ , and so on for $\hat { I } _ { 3 }$ and $\hat { I } _ { 4 }$ . The cumulative seasonal effects over the course of year should cancel, so that if $X _ { t } = a + I _ { t }$ , then $X _ { t } + X _ { t + 1 } + X _ { t + 2 } + X _ { t + 3 } = 4 a$ . To ensure this we take our final estimates of the seasonal indices as $I _ { t } ^ { * } = \hat { I } _ { t } - { \textstyle \frac { 1 } { 4 } } ( \hat { I } _ { 1 } + \cdot \cdot \cdot + \hat { I } _ { 4 } )$ .

If the model is multiplicative and $X _ { t } = a I _ { t }$ , we again wish to see the cumulative effects over a year cancel, so that $X _ { t } + X _ { t + 1 } + X _ { t + 2 } + X _ { t + 3 } = 4 a$ . This means that we should take $I _ { t } ^ { * } = \hat { I } _ { t } - { \textstyle \frac { 1 } { 4 } } ( \hat { I } _ { 1 } + \cdot \cdot \cdot + \hat { I } _ { 4 } ) + 1$ , adjusting so the mean of $I _ { 1 } ^ { * } , I _ { 2 } ^ { * } , I _ { 3 } ^ { * } , I _ { 4 } ^ { * }$ is 1.

When both trend and seasonality are to be extracted a two-stage procedure is recommended:

(a) Make a first estimate of trend, say $\hat { T } _ { t } ^ { 1 }$

Subtract this from $\{ X _ { t } \}$ and calculate first estimates of the seasonal indices, say $I _ { t } ^ { 1 }$ , from $X _ { t } - \hat { T } _ { t } ^ { 1 }$ .

The first estimate of the deseasonalized series is $Y _ { t } ^ { 1 } = X _ { t } - I _ { t } ^ { 1 }$ .

(b) Make a second estimate of the trend by smoothing $Y _ { t } ^ { 1 }$ , say $\hat { T } _ { t } ^ { 2 }$ .

Subtract this from $\{ X _ { t } \}$ and calculate second estimates of the seasonal indices, say $I _ { t } ^ { 2 }$ , from $X _ { t } - \hat { T } _ { t } ^ { 2 }$ .

The second estimate of the deseasonalized series is $Y _ { t } ^ { 2 } = X _ { t } - I _ { t } ^ { 2 }$ .

# 7 Fitting ARIMA models

# 7.1 The Box-Jenkins procedure

A general ARIMA $( p , d , q )$ model is $\phi ( B ) \nabla ( B ) ^ { d } X = \theta ( B ) \epsilon$ , where $\nabla ( B ) = I - B$ .

The Box-Jenkins procedure is concerned with fitting an ARIMA model to data. It has three parts: identification, estimation, and verification.

# 7.2 Identification

The data may require pre-processing to make it stationary. To achieve stationarity we may do any of the following.

Look at it.   
• Re-scale it (for instance, by a logarithmic or exponential transform.)   
• Remove deterministic components.   
• Difference it. That is, take $\nabla ( B ) ^ { d } X$ until stationary. In practice $d = 1 , 2$ should suffice.

We recognise stationarity by the observation that the autocorrelations decay to zero exponentially fast.

Once the series is stationary, we can try to fit an ARMA $( p , q )$ model. We consider the correlogram $r _ { k } = \hat { \gamma } _ { k } / \hat { \gamma } _ { 0 }$ and the partial autocorrelations $\hat { \phi } _ { k , k }$ . We have already made the following observations.

• An MA(q) process has negligible ACF after the $q$ th term.   
• An AR(p) process has negligible PACF after the pth term.

As we have noted, very approximately, both the sample ACF and PACF have standard deviation of around $1 / \sqrt { T }$ , where $T$ is the length of the series. A rule of thumb is that ACF and PACF values are negligible when they lie between $\pm 2 / \sqrt { T }$ . An $\mathrm { A R M A } ( p , q )$ process has $k$ th order sample ACF and PACF decaying geometrically for $k > \operatorname* { m a x } ( p , q )$ .

# 7.3 Estimation

# AR processes

To fit a pure $\operatorname { A R } ( p )$ , i.e., $\begin{array} { r } { X _ { t } ~ = ~ \sum _ { r = 1 } ^ { p } \phi _ { r } X _ { t - r } + \epsilon _ { t } } \end{array}$ we can use the Yule-Walker equations $\begin{array} { r } { \gamma _ { k } = \sum _ { r = 1 } ^ { p } \phi _ { r } \gamma _ { | k - r | } } \end{array}$ . We fit $\phi$ by solving $\begin{array} { r } { \hat { \gamma } _ { k } = \sum _ { 1 } ^ { p } \phi _ { r } \hat { \gamma } _ { | k - r | } } \end{array}$ , $k = 1 , \hdots , p$ . These can be solved by a Levinson-Durbin recursion, (similar to that used to solve for partial autocorrelations in Section 2.6). This recursion also gives the estimated

residual variance $\hat { \sigma } _ { p } ^ { 2 }$ , and helps in choice of $p$ through the approximate log likelihood $- 2 \log L \simeq T \log ( \hat { \sigma } _ { p } ^ { 2 } )$ .

Another popular way to choose $p$ is by minimizing Akaike’s AIC (an information criterion), defined as $\mathrm { A I C } = - 2 \log L + 2 k$ , where $k$ is the number of parameters estimated, (in the above case $p$ ). As motivation, suppose that in a general modelling context we attempt to fit a model with parameterised likelihood function $f ( X \mid \theta )$ , $\theta \in \Theta$ , and this includes the true model for some $\theta _ { 0 } \in \Theta$ . Let $X = ( X _ { 1 } , \ldots , X _ { n } )$ be a vector of $n$ independent samples and let ${ \hat { \theta } } ( X )$ be the maximum likelihood estimator of $\theta$ . Suppose $Y$ is a further independent sample. Then

$$
- 2 n \mathbb {E} _ {Y} \mathbb {E} _ {X} \log f (Y | \hat {\theta} (X)) = - 2 \mathbb {E} _ {X} \log f (X | \hat {\theta} (X)) + 2 k + O (1 / \sqrt {n}),
$$

where $k = | \Theta |$ . The left hand side is $2 n$ times the conditional entropy of $Y$ given ${ \hat { \theta } } ( X )$ , i.e., the average number of bits required to specify $Y$ given ${ \hat { \theta } } ( X )$ . The right hand side is approximately the AIC and this is to be minimized over a set of models, say $( f _ { 1 } , \Theta _ { 1 } ) , \hdots , ( f _ { m } , \Theta _ { m } )$ .

# ARMA processes

Generally, we use the maximum likelihood estimators, or at least squares numerical approximations to the MLEs. The essential idea is prediction error decomposition. We can factorize the joint density of $( X _ { 1 } , \ldots , X _ { T } )$ as

$$
f (X _ {1}, \ldots , X _ {T}) = f (X _ {1}) \prod_ {t = 2} ^ {T} f (X _ {t} | X _ {1}, \ldots , X _ {t - 1}).
$$

Suppose the conditional distribution of $X _ { t }$ given $( X _ { 1 } , \ldots , X _ { t - 1 } )$ is normal with mean $\hat { X } _ { t }$ and variance $P _ { t - 1 }$ , and suppose also that $X _ { 1 }$ is normal $N ( \hat { X } _ { 1 } , P _ { 0 } )$ . Here $\hat { X } _ { t }$ and $P _ { t - 1 }$ are functions of the unknown parameters $\phi _ { 1 } , . . . , \phi _ { p }$ , $\theta _ { 1 } , \ldots , \theta _ { q }$ and the data.

The log likelihood is

$$
- 2 \log L = - 2 \log f = \sum_ {t = 1} ^ {T} \left[ \log (2 \pi) + \log P _ {t - 1} + \frac {(X _ {t} - \hat {X} _ {t}) ^ {2}}{P _ {t - 1}} \right].
$$

We can minimize this with respect to $\phi _ { 1 } , . . . , \phi _ { p }$ , $\theta _ { 1 } , \ldots , \theta _ { q }$ to fit $\mathrm { A R M A } ( p , q )$

Additionally, the second derivative matrix of $- \log L$ (at the MLE) is the observed information matrix, whose inverse is an approximation to the variance-covariance matrix of the estimators.

In practice, fitting $\mathrm { A R M A } ( p , q )$ the log likelihood $\left( - 2 \log L \right)$ is modified to sum only over the range $\{ m + 1 , \ldots , T \}$ , where $m$ is small.

# Example 7.1

For AR(p), take $m = p$ so $\begin{array} { r } { \hat { X } _ { t } = \sum _ { r = 1 } ^ { p } \phi _ { r } X _ { t - r } } \end{array}$ $\begin{array} { r } { \hat { X } _ { t } = \sum _ { r = 1 } ^ { p } \phi _ { r } X _ { t - r } , t \ge m + 1 , P _ { t - 1 } = \sigma _ { \epsilon } ^ { 2 } . } \end{array}$

Note. When using this approximation to compare models with different numbers of parameters we should always use the same $m$ .

Again we might choose $p$ and $q$ by minimizing the AIC of $- 2 \log L + 2 k$ , where $k = p + q$ is the total number of parameters in the model.

# 7.4 Verification

The third stage in the Box-Jenkins algorithm is to check whether the model fits the data. There are several tools we may use.

• Overfitting. Add extra parameters to the model and use likelihood ratio test or $t$ -test to check that they are not significant.   
Residuals analysis. Calculate the residuals from the model and plot them. The autocorrelation functions, ACFs, PACFs, spectral densities, estimates, etc., and confirm that they are consistent with white noise.

# 7.5 Tests for white noise

Tests for white noise include the following.

(a) The turning point test (explained in Lecture 1) compares the number of peaks and troughs to the number that would be expected for a white noise series.   
(b) The Box–Pierce test is based on the statistic

$$
Q _ {m} = T \sum_ {k = 1} ^ {m} r _ {k} ^ {2},
$$

where $r _ { k }$ is the $k$ th sample autocorrelation coefficient of the residual series, and ≪all-inclusive statistic. If the model is correct then $p + q < m \ll T$ . It is called a ‘portmanteau test’, because it is based on the $Q _ { m } \sim \chi _ { m - p - q } ^ { 2 }$ approximately.

In fact, $r _ { k }$ has variance $( T - k ) / ( T ( T + 2 ) )$ , and a somewhat more powerful test uses the Ljung-Box statistic quoted in Section 2.7,

$$
Q _ {m} ^ {\prime} = T (T + 2) \sum_ {k = 1} ^ {m} (T - k) ^ {- 1} r _ {k} ^ {2},
$$

where again, $Q _ { m } ^ { \prime } \sim \chi _ { m - p - q } ^ { 2 }$ approximately.

(c) Another test for white noise can be constructed from the periodogram. Recall that $I ( \omega _ { j } ) \sim ( \sigma ^ { 2 } / \pi ) \chi _ { 2 } ^ { 2 } / 2$ and that $I ( \omega _ { 1 } ) , \ldots , I ( \omega _ { m } )$ are mutually independent.

Define $\begin{array} { r } { C _ { j } = \sum _ { k = 1 } ^ { j } I ( \omega _ { k } ) } \end{array}$ and $U _ { j } = C _ { j } / C _ { m }$ . Recall that $\chi _ { 2 } ^ { 2 }$ is the same as the exponential distribution and that if $Y _ { 1 } , \dots , Y _ { m }$ are i.i.d. exponential random variables,

then $( Y _ { 1 } + \cdot \cdot \cdot + Y _ { j } ) / ( Y _ { 1 } + \cdot \cdot \cdot + Y _ { m } )$ , $j = 1 , \ldots , m - 1$ , have the distribution of an ordered sample of $m - 1$ uniform random variables drawn from $[ 0 , 1 ]$ . Hence under the hypothesis that $\{ X _ { t } \}$ is Gaussian white noise $U _ { j }$ , $j = 1 , \ldots , m - 1$ have the distribution of an ordered sample of $m - 1$ uniform random variables on $[ 0 , 1 ]$ . The standard test for this is the Kolomogorov-Smirnov test, which uses as a test statistic, $D$ , defined as the maximum difference between the theoretical distribution function for $U [ 0 , 1 ]$ , $F ( u ) = u$ , and the empirical distribution $\hat { F } ( u ) = \{ \# ( U _ { j } \leq u ) \} / ( m - 1 )$ . Percentage points for $D$ can be found in tables.

# 7.6 Forecasting with ARMA models

Recall that $\phi ( B ) X = \theta ( B ) \epsilon$ , so the power series coefficients of $C ( z ) = \theta ( z ) / \phi ( z ) =$ $\textstyle \sum _ { r = 0 } ^ { \infty } c _ { r } z ^ { r }$ give an expression for $X _ { t }$ as $\textstyle X _ { t } = \sum _ { r = 0 } ^ { \infty } c _ { r } \epsilon _ { t - r }$ .

But also, $\epsilon = D ( B ) X$ , where $\begin{array} { r } { D ( z ) = \phi ( z ) / \theta ( z ) = \sum _ { r = 0 } ^ { \infty } d _ { r } z ^ { r } } \end{array}$ — as long as the zeros of $\theta$ lie strictly outside the unit circle and thus $\begin{array} { r } { \epsilon _ { t } = \sum _ { r = 0 } ^ { \infty } d _ { r } X _ { t - r } } \end{array}$ .

The advantage of the representation above is that given $( \ldots , X _ { t - 1 } , X _ { t } )$ we can calculate values for $( \dots , \epsilon _ { t - 1 } , \epsilon _ { t } )$ and so can forecast $X _ { t + 1 }$ .

In general, if we want to forecast $X _ { T + k }$ from $( \ldots , X _ { T - 1 } , X _ { T } )$ we use

$$
\hat {X} _ {T, k} = \sum_ {r = k} ^ {\infty} c _ {r} \epsilon_ {T + k - r} = \sum_ {r = 0} ^ {\infty} c _ {k + r} \epsilon_ {T - r},
$$

which has the least mean squared error over all linear combinations of $( \dots , \epsilon _ { T - 1 } , \epsilon _ { T } )$ . In fact,

$$
\mathbb {E} \left(\left(\hat {X} _ {T, k} - X _ {T + k}\right) ^ {2}\right) = \sigma_ {\epsilon} ^ {2} \sum_ {r = 0} ^ {k - 1} c _ {r} ^ {2}.
$$

In practice, there is an alternative recursive approach. Define

$$
\hat {X} _ {T, k} = \left\{ \begin{array}{l l} X _ {T + k}, & - (T - 1) \leq k \leq 0  , \\ \text {o p t i m a l p r e d i c t o r o f} X _ {T + k} \text {g i v e n} X _ {1}, \ldots , X _ {T}, & 1 \leq k  . \end{array} \right.
$$

We have the recursive relation

$$
\hat {X} _ {T, k} = \sum_ {r = 1} ^ {p} \phi_ {r} \hat {X} _ {T, k - r} + \hat {\epsilon} _ {T + k} + \sum_ {s = 1} ^ {q} \theta_ {s} \hat {\epsilon} _ {T + k - s}
$$

For $k = - ( T - 1 ) , - ( T - 2 ) , \ldots , 0$ this gives estimates of $\hat { \epsilon } _ { t }$ for $t = 1 , \dots , T$ .

For $k > 0$ , this gives a forecast $\hat { X } _ { T , k }$ for $X _ { T + k }$ . We take $\hat { \epsilon } _ { t } = 0$ for $t > T$

But this needs to be started off. We need to know $\left( X _ { t } , \ t \ \leq \ 0 \right)$ and $\epsilon _ { t }$ , $t \leq 0$ . There are two standard approaches.

1. Conditional approach: take $X _ { t } = \epsilon _ { t } = 0$ , $t \leq 0$ .   
2. Backcasting: we forecast the series in the reverse direction to determine estimators of X0, X 1, . . . and ǫ0, ǫ 1, . . . . $X _ { 0 } , X _ { - 1 } , \ldots$ $\epsilon _ { 0 } , \epsilon _ { - 1 } , . . . .$

# 8 State space models

# 8.1 Models with unobserved states

State space models are an alternative formulation of time series with a number of advantages for forecasting.

1. All ARMA models can be written as state space models.   
2. Nonstationary models (e.g., ARMA with time varying coefficients) are also state space models.   
3. Multivariate time series can be handled more easily.   
4. State space models are consistent with Bayesian methods.

In general, the model consists of

$$
\begin{array}{l} \mathrm {o b s e r v e d d a t a :} \qquad X _ {t} = F _ {t} S _ {t} + v _ {t} \\ \mathrm {u n o b s e r v e d s t a t e :} S _ {t} = G _ {t} S _ {t - 1} + w _ {t} \\ \mathrm {o b s e r v a t i o n n o i s e :} v _ {t} \sim N (0, V _ {t}) \\ \mathrm {s t a t e n o i s e :} \qquad w _ {t} \sim N (0, W _ {t}) \\ \end{array}
$$

where $v _ { t } , w _ { t }$ are independent and $F _ { t } , G _ { t }$ are known matrices — often time dependent (e.g., because of seasonality).

# Example 8.1

$X _ { t } = S _ { t } + v _ { t }$ , $S _ { t } = \phi S _ { t - 1 } + w _ { t }$ . Define $Y _ { t } = X _ { t } - \phi X _ { t - 1 } = ( S _ { t } + v _ { t } ) - \phi ( S _ { t - 1 } + v _ { t - 1 } ) =$ $w _ { t } + v _ { t } - \phi v _ { t - 1 }$ . The autocorrelations of $\{ y _ { t } \}$ are zero at all lags greater than 1. So $\{ Y _ { t } \}$ is MA(1) and thus $\{ X _ { t } \}$ is $\mathrm { A R M A } ( 1 , 1 )$ .

# Example 8.2

The general $\mathrm { A R M A } ( p , q )$ $( p , q )$ model $\begin{array} { r } { X _ { t } = \sum _ { r = 1 } ^ { p } \phi _ { r } X _ { t - r } + \sum _ { s = 0 } ^ { q } \theta _ { s } \epsilon _ { t - s } } \end{array}$ is a state space model. We write $X _ { t } = F _ { t } S _ { t }$ , where

$$
F _ {t} = (\phi_ {1}, \phi_ {2}, \dots , \phi_ {p}, 1, \theta_ {1}, \dots , \theta_ {q}), \quad S _ {t} = \left( \begin{array}{c} X _ {t - 1} \\ \vdots \\ X _ {t - p} \\ \epsilon_ {t} \\ \vdots \\ \epsilon_ {t - q} \end{array} \right) \in \mathbb {R} ^ {p + q + 1}
$$

with $v _ { t } = 0$ , $V _ { t } = 0$ . $S _ { t } = G _ { t } S _ { t - 1 } + w _ { t }$ .

$$
S _ {t} = \left( \begin{array}{c} X _ {t - 1} \\ X _ {t - 2} \\ X _ {t - 3} \\ \vdots \\ X _ {t - p - 1} \\ \epsilon_ {t} \\ \epsilon_ {t - 1} \\ \epsilon_ {t - 2} \\ \vdots \\ \epsilon_ {t - q} \end{array} \right) = \left( \begin{array}{c c c c c c c c c c} \phi_ {1} & \phi_ {2} & \dots & \phi_ {p} & 1 & \theta_ {1} & \theta_ {2} & \dots & \theta_ {q - 1} & \theta_ {q} \\ 1 & 0 & \dots & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ 0 & 1 & \vdots & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \dots & \vdots & \vdots \\ 0 & 0 & 0 & 1 & 0 & 0 & 0 & \dots & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & \dots & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 1 & 0 & \dots & 0 & 0 \\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & \dots & 0 & 0 \\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \dots & \vdots & \vdots \\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & \dots & 1 & 0 \end{array} \right) \left( \begin{array}{c} X _ {t - 2} \\ X _ {t - 3} \\ \vdots \\ X _ {t - p - 1} \\ \epsilon_ {t - 1} \\ \epsilon_ {t - 2} \\ \epsilon_ {t - 3} \\ \vdots \\ \epsilon_ {t - q} \\ \epsilon_ {t - q - 1} \end{array} \right) + \left( \begin{array}{c} 0 \\ 0 \\ \vdots \\ \vdots \\ 0 \\ \epsilon_ {t} \\ \vdots \\ \vdots \\ 0 \end{array} \right).
$$

# 8.2 The Kalman filter

Given observed data $X _ { 1 } , \ldots , X _ { t }$ we want to find the conditional distribution of $S _ { t }$ and a forecast of $X _ { t + 1 }$ .

Recall the following multivariate normal fact: If

$$
Y = \binom {Y _ {1}} {Y _ {2}} \sim N \left(\binom {\mu_ {1}} {\mu_ {2}}, \binom {A _ {1 1} A _ {1 2}} {A _ {2 1} A _ {2 2}}\right) \tag {8.1}
$$

then

$$
\left(Y _ {1} \mid Y _ {2}\right) \sim N \left(\mu_ {1} + A _ {1 2} A _ {2 2} ^ {- 1} \left(Y _ {2} - \mu_ {2}\right), A _ {1 1} - A _ {1 2} A _ {2 2} ^ {- 1} A _ {2 1}\right). \tag {8.2}
$$

Conversely, if $( Y _ { 1 } \mid Y _ { 2 } )$ satisfies (8.2), and $Y _ { 2 } \sim N ( \mu _ { 2 } , A _ { 2 2 } )$ then the joint distribution is as in (8.1).

Now let $\mathcal { F } _ { t - 1 } ~ = ~ ( X _ { 1 } , \ldots , X _ { t - 1 } )$ and suppose we know that $\left( S _ { t - 1 } \mid \mathcal { F } _ { t - 1 } \right) \sim$ $N \left( \widehat { S } _ { t - 1 } , P _ { t - 1 } \right)$ . Then

$$
S _ {t} = G _ {t} S _ {t - 1} + w _ {t},
$$

so

$$
\left(S _ {t} \mid \mathcal {F} _ {t - 1}\right) \sim N \left(G _ {t} \hat {S} _ {t - 1}, G _ {t} P _ {t - 1} G _ {t} ^ {\top} + W _ {t}\right),
$$

and also $( X _ { t } \mid S _ { t } , { \mathcal { F } } _ { t - 1 } ) \sim N ( F _ { t } S _ { t } , V _ { t } )$ .

Put $Y _ { 1 } ~ = ~ X _ { t }$ and $Y _ { 2 } ~ = ~ S _ { t }$ . Let $R _ { t } = G _ { t } P _ { t - 1 } G _ { t } ^ { \top } + W _ { t }$ . Taking all variables conditional on $\mathcal { F } _ { t - 1 }$ we can use the converse of the multivariate normal fact and identify

$$
\mu_ {2} = G _ {t} \hat {S} _ {t - 1} \quad \mathrm {a n d} \quad A _ {2 2} = R _ {t}.
$$

Since $S _ { t }$ is a random variable,

$$
\mu_ {1} + A _ {1 2} A _ {2 2} ^ {- 1} (S _ {t} - \mu_ {2}) = F _ {t} S _ {t} \Longrightarrow A _ {1 2} = F _ {t} R _ {t} \quad \mathrm {a n d} \quad \mu_ {1} = F _ {t} \mu_ {2}.
$$

Also

$$
A _ {1 1} - A _ {1 2} A _ {2 2} ^ {- 1} A _ {2 1} = V _ {t} \Longrightarrow A _ {1 1} = V _ {t} + F _ {t} R _ {t} R _ {t} ^ {- 1} R _ {t} ^ {\top} F _ {t} ^ {\top} = V _ {t} + F _ {t} R _ {t} F _ {t} ^ {\top}.
$$

What this says is that

$$
\left. \binom {X _ {t}} {S _ {t}} \right| _ {\mathcal {F} _ {t - 1}} = N \left(\binom {F _ {t} G _ {t} \hat {S} _ {t - 1}} {G _ {t} \hat {S} _ {t - 1}}, \binom {V _ {t} + F _ {t} R _ {t} F _ {t} ^ {\top}} {R _ {t} ^ {\top} F _ {t} ^ {\top}} \binom {F _ {t} R _ {t}} {R _ {t}}\right).
$$

Now apply the multivariate normal fact directly to get $( S _ { t } \mid X _ { t } , { \mathcal { F } } _ { t - 1 } ) = ( S _ { t } \mid { \mathcal { F } } _ { t } ) \sim$ $N ( \hat { S } _ { t } , P _ { t } )$ , where

$$
\hat {S} _ {t} = G _ {t} \hat {S} _ {t - 1} + R _ {t} F _ {t} ^ {\top} \left(V _ {t} + F _ {t} R _ {t} F _ {t} ^ {\top}\right) ^ {- 1} \left(X _ {t} - F _ {t} G _ {t} \hat {S} _ {t - 1}\right)
$$

$$
P _ {t} = R _ {t} - R _ {t} F _ {t} ^ {\top} \left(V _ {t} + F _ {t} R _ {t} F _ {t} ^ {\top}\right) ^ {- 1} F _ {t} R _ {t}
$$

These are the Kalman filter updating equations.

Note the form of the right hand side of the expression for $\hat { S } _ { t }$ . If contains the term $G _ { t } \hat { S } _ { t - 1 }$ , which is simply what we would predict if it were known that $S _ { t - 1 } = \hat { S } _ { t - 1 }$ , plus a term that depends on the observed error in forecasting $X _ { t }$ , i.e., $\Big ( X _ { t } - F _ { t } G _ { t } \hat { S } _ { t - 1 } \Big )$ . This is similar to the forecast updating expression for simple exponential smoothing in Section 6.4.

All we need to start updating the estimates are the initial values $\hat { S } _ { 0 }$ and $P _ { 0 }$ . Three ways are commonly used.

1. Use a Bayesian prior distribution.   
2. If $F , G , V , W$ are independent of $t$ the process is stationary. We could use the stationary distribution of $S$ to start.   
3. Choosing $S _ { 0 } = 0$ , $P _ { 0 } = k I$ ( $k$ large) reflects prior ignorance.

# 8.3 Prediction

Suppose we want to predict the $X _ { T + k }$ given $( X _ { 1 } , \ldots , X _ { T } )$ . We already have

$$
\left(X _ {T + 1} \mid X _ {1}, \ldots , X _ {T}\right) \sim N \left(F _ {T + 1} G _ {T + 1} S _ {t}, V _ {T + 1} + F _ {T + 1} R _ {T + 1} F _ {T + 1} ^ {\top}\right)
$$

which solves the problem for the case $k = 1$ . By induction we can show that

$$
(S _ {T + k} \mid X _ {1}, \ldots , X _ {T}) \sim N (\hat {S} _ {T + k}, P _ {T + k})
$$

where

$$
\begin{array}{l} \hat {S} _ {T, 0} = \hat {S} _ {T} \\ P _ {T, 0} = P _ {T} \\ \hat {S} _ {T, k} = G _ {T + k} \hat {S} _ {T, k - 1} \\ P _ {T, k} = G _ {T + k} P _ {T, k - 1} G _ {T + k} ^ {\top} + W _ {T + k} \\ \end{array}
$$

and hence that $\left( X _ { T + k } \mid X _ { 1 } , \ldots , X _ { T } \right) \sim N \Big ( F _ { T + k } \hat { S } _ { T , k } , V _ { T + k } + F _ { T + k } P _ { T , k } F _ { T + k } ^ { \top } \Big ) .$

# 8.4 Parameter estimation revisited

In practice, of course, we may not know the matrices $F _ { t } , G _ { t } , V _ { t } , W _ { t }$ . For example, in $\mathrm { A R M A } ( p , q )$ they will depend on the parameters $\phi _ { 1 } , . . . , \phi _ { p }$ , θ1, . . . , θq, $\sigma ^ { 2 }$ , which we may not know.

We saw that when performing prediction error decomposition that we needed to calculate the distribution of $( X _ { t } \mid X _ { 1 } , \ldots , X _ { t - 1 } )$ . This we have now done.

# Example 8.3

Consider the state space model

$$
\begin{array}{l} \text {o b s e r v e d} X _ {t} = S _ {t} + v _ {t}, \\ \text {u n o b s e r v e d s t a t e} S _ {t} = S _ {t - 1} + w _ {t}, \\ \end{array}
$$

where $v _ { t } , w _ { t }$ are independent errors, $v _ { t } \sim N ( 0 , V )$ and $w _ { t } \sim N ( 0 , W )$ .

Then we have $F _ { t } ~ = ~ 1$ , $G _ { t } ~ = ~ 1$ , $V _ { t } ~ = ~ V$ , $W _ { t } ~ = ~ W$ . $R _ { t } = P _ { t - 1 } + W$ . So if $( S _ { t - 1 } \mid X _ { 1 } , \ldots , X _ { t - 1 } ) \sim N \left( { \widehat { S } } _ { t - 1 } , P _ { t - 1 } \right)$ then $( S _ { t } \mid X _ { 1 } , \dots , X _ { t } ) \sim N \left( { \hat { S } } _ { t } , P _ { t } \right)$ , where

$$
\begin{array}{l} \hat {S} _ {t} = \hat {S} _ {t - 1} + R _ {t} (V + R _ {t}) ^ {- 1} (X _ {t} - \hat {S} _ {t - 1}) \\ P _ {t} = R _ {t} - \frac {R _ {t} ^ {2}}{V + R _ {t}} = \frac {V R _ {t}}{V + R _ {t}} = \frac {V (P _ {t - 1} + W)}{V + P _ {t - 1} + W}. \\ \end{array}
$$

Asymptotically, $P _ { t } \to P$ , where $P$ is the positive root of $P ^ { 2 } + W P - W V = 0$ and $\hat { S } _ { t }$ behaves like $\begin{array} { r } { \dot { S } _ { t } = ( 1 - \alpha ) \sum _ { r = 0 } ^ { \infty } \alpha ^ { r } X _ { t - r } } \end{array}$ , where $\alpha = V / ( V + W + P )$ . Note that this is simple exponential smoothing.

Equally, we can predict $S _ { T + k }$ given $( X _ { 1 } , \ldots , X _ { T } )$ as $N \left( \hat { S } _ { T , k } , P _ { T , k } \right)$ where

$$
\begin{array}{l} \hat {S} _ {T, 0} = S _ {t}, \\ P _ {T, 0} = P _ {T}, \\ \hat {S} _ {T, k} = \hat {S} _ {T}, \\ P _ {T, k} = P _ {T} + k W. \\ \end{array}
$$

So $( X _ { T + k } \mid X _ { 1 } , \ldots , X _ { T } ) \sim N \Big ( \hat { S } _ { T } , V + P _ { T } + k W \Big ) .$

# Time Series Analysis

# Course notes for STAT 479

Adam B Kashlak

Mathematical & Statistical Sciences

University of Alberta

Edmonton, Canada, T6G 2G1

April 20, 2021

# cbna

This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/ by-nc-sa/4.0/.

# Contents

# Preface 1

# 1 Time Series: Overview 2

1.1 Types of Noise 2

1.1.1 White Noise . . . 2   
1.1.2 Autoregressive 3   
1.1.3 Moving Average 4   
1.1.4 Markov Processes and Martingales 4

1.2 Properties of Times Series 8

1.2.1 Autocovariance 8   
1.2.2 Cross-Covariance 9   
1.2.3 Stationarity . . 9

1.3 Estimation 11

1.3.1 Estimating the mean . . 11   
1.3.2 Estimating the autocovariance 11   
1.3.3 Detecting White Noise . . . 12

# 2 Statistical Models for Time Series 15

2.1 Regression . 16

2.1.1 Linear Regression in Brief . . 16   
2.1.2 Linear Regression for Time Series . . . 16

2.2 Smoothing . 18   
2.3 ARIMA Models for Times Series 22

2.3.1 Autoregressive Processes . 22   
2.3.2 Moving Average Process . . . 24   
2.3.3 Auto Regressive Moving Average Processes 25   
2.3.4 ARIMA 28

2.4 Testing for Stationarity and Autocorrelation . 29

2.4.1 Box-Pierce and Ljung-Box Tests 30   
2.4.2 Durbin–Watson Test . . . 30   
2.4.3 Breusch–Godfrey test 31   
2.4.4 Augmented Dickey-Fuller Test 32

2.4.5 Phillips–Perron test 33

2.5 Autocorrelation and Partial Autocorrelation 33

2.5.1 ACF for AR(p) . . . 34   
2.5.2 ACF for MA(q) . . . 35   
2.5.3 PACF for AR(p) 36   
2.5.4 PACF for MA(1) 37

# 3 Estimation and Forecasting 38

3.1 The AR process . 38

3.1.1 Estimation for AR processes 38   
3.1.2 Forecasting for AR processes 43

3.2 The ARMA Process 47

3.2.1 Estimation for ARMA processes 47   
3.2.2 Forecasting for ARMA processes . . 49

3.3 Seasonal ARIMA 53

3.3.1 Seasonal Autoregressive Processes 54   
3.3.2 Seasonal ARMA Processes . . . 55

# 4 Analysis in the Frequency Domain 57

4.1 Periodic Processes 57   
4.1.1 Regression, Estimation, and the FFT 58   
4.2 Spectral Distribution and Density . . 61   
4.2.1 Filtering and ARMA . . 63

4.3 Spectral Statistics 64

4.3.1 Spectral ANOVA . . 65   
4.3.2 Large Sample Behaviour . . 66   
4.3.3 Banding, Tapering, Smoothing, and more 67   
4.3.4 Parametric Estimation 70

4.4 Filtering 70

# Preface

The understanding’s in your mind. You only have to find it. But, time—Time, the creature said, is the simplest thing there is.

Time is the Simplest Thing Clifford D Simak (1961)

The following are lecture notes originally produced for an undergraduate course on time series at the University of Alberta in the winter of 2020. The aim of these notes is is to introduce the main topics, applications, and mathematical underpinnings of time series analysis.

These notes were produced by consolidating two main sources being the textbook of Shumway and Stoffer, Time Series Analysis and Its Applications, and the past course notes produced by Dr. Doug Weins also at the University of Alberta.

Adam B Kashlak

Edmonton, Canada

January 2020

# Chapter 1

# Time Series: Overview

# Introduction

In this chapter we consider different types of time series processes that we may encounter in practice. The main difference between time series and other areas of statistics like linear regression is that the noise or errors can be correlated. This arises from the fact that time implies causality; the past predicts the future. Thus, we no longer live in the independent and identically distributed setting of most other areas of statistics.

This chapter also reintroduces notions of covariance and correlation in the context of time series, which become autocovariance and autocorrelation. The critical property of stationarity is defined, which allows us to estimate such autocovariances and autocorrelations from a given time series dataset.

# 1.1 Types of Noise

When one is first introduced to the realm of statistics, the data on hand is treated as independent and identically distributed observations from some population. That is, the noise or errors or randomness present in the data is treated as a collection of iid random variables—typically mean zero Gaussians. Times series data breaks from the iid setting as causality becomes a key notion: the effects of random errors in the past are present in future observations as well. Thus, we consider many types of noise that can occur in real data.

# 1.1.1 White Noise

Let $w _ { t }$ denote the white noise process. This is a random variable indexed by time $t$ such that

$$
\operatorname {E} w _ {t} = 0 \text {a n d} \operatorname {V a r} \left(w _ {t}\right) = \sigma^ {2} \forall t \in [ 0, T ], \text {a n d} \operatorname {c o v} \left(w _ {t}, w _ {s}\right) = 0 \forall t \neq s.
$$

That is, $w _ { t }$ and $w _ { s }$ are uncorrelated but not necessarily independent.

This can be strengthened to iid noise if uncorrelated is replaced with independent. This can be further strengthened to Gaussian white noise were every $w _ { t } \sim \mathcal { N } \left( 0 , \sigma ^ { 2 } \right)$ . The intuition behind the term white noise comes from signals processing where a signal is white if it contains all possible frequencies. Furthermore, the white noise process will be used to generate all of the subsequent processes.

# 1.1.2 Autoregressive

The autoregressive (AR) process is a natural way to encode causality into the white noise process, that is, demonstrate how the past influences the future. The general formula is

$$
X _ {t} = \sum_ {i = 1} ^ {p} \theta_ {i} X _ {t - i} + w _ {t},
$$

which is that past time observation $X _ { t - i }$ contributions $\theta _ { i } \in \mathbb { R }$ to the present time observation $X _ { t }$ .

For example, if $p = 1$ and $\theta _ { 1 } = 1$ , then we have the process

$$
X _ {t} = X _ {t - 1} + w _ {t},
$$

which is also an example of a Markov process and a Martingale to be discussed below. This process could model, say, the price of a commodity where the previous price $X _ { t - 1 }$ is the best guess for the current price $X _ { t }$ plus or minus some noise $w _ { t }$ .

The AR process with $p = 1$ and $\theta _ { 1 } = 1$ can be thought of as a random walk. An interesting and useful extension of this process is the random walk with drift, which is

$$
X _ {t} = a + X _ {t - 1} + w _ {t}
$$

for some $a \neq 0$ . In this case, the process increases (or decreases) by the fixed amount $a$ at each time step. But there is also the addition of white noise $w _ { t }$ at each step. Hence, one could try to estimate the drift term $a$ from historical data in order to ascertain if $X _ { t }$ (say the price of some commodity) is increasing or decreasing or remaining constant up to random noise.

Example 1.1.1. In Figure 1.1, we have four examples of autoregressive processes where $w _ { t }$ is Gaussian white noise.

1. The white noise process: $X _ { t } = w _ { t }$   
2. Random Walk: $X _ { t } = X _ { t - 1 } + w _ { t }$ .   
3. AR(2): $X _ { t } = X _ { t - 1 } - 0 . 2 X _ { t - 2 } + w _ { t }$   
4. AR(3): $X _ { t } = X _ { t - 1 } - 0 . 2 X _ { t - 2 } + 0 . 1 8 X _ { t - 3 } + w _ { t }$

Based solely on the plots, the random walk and the chosen AR(3) process look similar. Likewise, it may be hard to immediately identify that the top left plot is white noise while the bottom left is an AR(2) process.

# 1.1.3 Moving Average

The moving average (MA) process is a smoother type of noise than the white noise process. It can be expressed by the formula

$$
X _ {t} = \sum_ {j = 1} ^ {q} \phi_ {j} w _ {t - j} + w _ {t}
$$

for $\phi _ { j } \in \mathbb { R }$ . Compared to the above AR formula, the MA formula averages over the noise terms $w _ { t }$ as opposed to the observed values $X _ { t }$ . It can be thought of as ripple effects in the process. That is, if there is a shock to the process $w _ { t - 1 }$ , then it’s effects are still felt at time $t$ by the term $\phi _ { 1 } w _ { t - 1 }$ .

Alternatively, this model can be written as an overall average like

$$
X _ {t} = \sum_ {j = - q / 2} ^ {q / 2} \phi_ {j} w _ {t + j}.
$$

In this way, we can consider the MA process as a weighted averaged white noise process. A simple example is $X _ { t } = ( w _ { t - 1 } + w _ { t } + w _ { t + 1 } ) / 3$ .

# 1.1.4 Markov Processes and Martingales

Three very useful tools in probability theory that have been extensively studied are Markov processes, martingales, and the Gaussian process. We briefly introduce them here noting that there has be extensive research on each topic.1

A Markov process is one where conditioning on the entire history of the process is equivalent to just conditioning on the most recent time point. More precisely, $X _ { t }$ is Markov if

$$
\mathrm {E} \left(X _ {t} | X _ {t - 1}, \dots , X _ {1}\right) = \mathrm {E} \left(X _ {t} | X _ {t - 1}\right).
$$

For example, the AR process with $p = 1$ is Markov as the present value $X _ { t }$ only depends on the past via $X _ { t - 1 }$ and no other $X _ { t - i }$ . Note that people have also studied order $p$ Markov processes where the present depends on the more recent $p$ time points, but the above definition is the most commonly used.

A martingale is often defined as a fair game being one where the expected winnings/looses is zero. That is, it is a stochastic process where the conditional expectation is equal to the most recent observation, i.e.

$$
\mathrm {E} \left(X _ {t} | X _ {t - 1}, \dots , X _ {1}\right) = X _ {t - 1}.
$$

![](images/761b1ef5780507b60cf5ffca666dca9ac2163ea8690206473636f9c1a38d9419.jpg)

![](images/e2a1a52e04a89198ec5a0ae73b174f4b7128b63eccf70befebd0cdbe2a08cf17.jpg)

![](images/9977ca00e8031d0efaa293a9ad07f2061eeee6cbe5485f407691f8d12899bbdb.jpg)

![](images/dea00a12fbafbf6817dd6bffc96d391e892599805f4af720bcd2cf0ddd790d05.jpg)  
Figure 1.1: Examples of the white noise process and autoregressive versions of that white noise process of order 1, 2, and 3.

![](images/1488cddf81a9f1762a8ab493436b32299907f37976cf05693487d04896dc2cb4.jpg)

![](images/ddb3a5fa691d3641589218a75bdde796c15f5e69c399433ee1d6434bc8f2050b.jpg)

![](images/d22bf7505aa140c22a609486fb65d40c823f3a5e5ca241383ee974d6ff3c91f8.jpg)

![](images/2f9f3cbbd771b1dd979c3a680f6759e3f25e38e17c06992751de4d24ec246f55.jpg)  
Figure 1.2: Examples of the white noise process and moving averaged versions of that white noise process averaged over windows of length 3, 9, and 21.

The AR process with $p = 1$ and $\theta _ { 1 } = 1$ is an example of a martingale. Note that supermartingales and submartingales have also been studied where the above = is replaced by a $\leq$ or $\geq$ , respectively.

As the normal distribution lends itself elegantly to other areas of statistics, so does it to time series. The Gaussian process is a generalization of the multivariate normal distribution. It is a stochastic process $X _ { t }$ where for any finite collection of time points $\{ t _ { 1 } , \ldots , t _ { k } \}$ , the random vector $( X _ { t _ { 1 } } , \dots , X _ { t _ { k } } )$ is multivariate normal. Much like the multivariate normal distribution, the Gaussian process can be defined by its mean $\mu _ { t }$ and covariance $C _ { s , t }$ where

$$
\mu_ {t} = \operatorname {E} X _ {t} \text {a n d} \Sigma_ {s, t} = \operatorname {c o v} \left(X _ {s}, X _ {t}\right).
$$

Many time series fall under the category of linear processes. Given a white noise process $w _ { t }$ , a linear process is defined as

$$
X _ {t} = \mu + \sum_ {j = - \infty} ^ {\infty} \theta_ {j} w _ {t - j},
$$

which is that every $X _ { t }$ is a linear combination of the terms in the white noise process with some mean $\mu$ added on. Here, we require $\sum \theta _ { i } ^ { 2 } < \infty$ in order for the process to have a finite variance. However, as we are generally interested in modelling casual processes in time—i.e. the past predicts the future and not vice versa—we can instead consider the more restricted definition

$$
X _ {t} = \mu + \sum_ {j = 0} ^ {\infty} \theta_ {j} w _ {t - j}.
$$

Example 1.1.2 (The AR(1) Process). We revisit the AR(1) process, $X _ { t } = \theta X _ { t - 1 } +$ $w _ { t }$ , and by using this recursive definition and assuming we can extend the series infinitely into the past, we can rewrite it as

$$
X _ {t} = \theta \left(\theta X _ {t - 2} + w _ {t - 1}\right) + w _ {t} = \dots = \sum_ {j = 0} ^ {\infty} \theta^ {j} w _ {t - j}.
$$

Infinite series are limits—i.e. $\begin{array} { r } { \sum _ { j = 0 } ^ { \infty } \theta ^ { j } w _ { t - j } = \operatorname* { l i m } _ { N \to \infty } \sum _ { j = 0 } ^ { N } \theta ^ { j } w _ { t - j } } \end{array}$ . Hence, this sum may not converge in any meaningful way. Let $\begin{array} { r } { S _ { N } ( \theta ) = \sum _ { j = 0 } ^ { N } \theta ^ { j } w _ { t - j } } \end{array}$ , then

$$
\operatorname {E S} _ {N} = 0 a n d \operatorname {V a r} \left(S _ {N}\right) = \sigma^ {2} \sum_ {j = 0} ^ {N} \theta^ {2 j} = \sigma^ {2} \left(\frac {1 - \theta^ {2 N + 2}}{1 - \theta^ {2}}\right).
$$

Thus, if $| \theta | < 1$ , then $\operatorname { V a r } \left( S _ { N } ( \theta ) \right) \to \sigma ^ { 2 } / ( 1 - \theta ^ { 2 } )$ , and if $w _ { t }$ is Gaussian noise, then

$$
S _ {N} (\theta) \stackrel {{d}} {{\to}} \mathcal {N} \left(0, \sigma^ {2} / (1 - \theta^ {2})\right).
$$

In the case of the random walk, which is $\theta = 1$ , the series does not converge, but by the central limit theorem, we have

$$
n ^ {- 1 / 2} S _ {N} (1) \xrightarrow {d} \mathcal {N} (0, 1).
$$

# 1.2 Properties of Times Series

# 1.2.1 Autocovariance

As a time series $X _ { t }$ can be thought of as a single entity, the covariance between two time points is referred to as the autocovariance and is defined as

$$
K _ {X} (s, t) = c o v (X _ {t}, X _ {s}).
$$

The notation $K$ comes from treating the autocovariance as a kernel function for an integral transform.2 Note that the autocovariance function is symmetric, $K ( s , t ) =$ $K ( t , s )$ , and positive (semi) definite in the sense that for any finite collection of time points $\{ t _ { 1 } , \ldots , t _ { k } \}$ , we have a $k \times k$ matrix with $i , j$ th entry $K ( t _ { i } , t _ { j } )$ and this matrix is positive (semi) definite.

Similar to the multivariate setting, we can normalize the autocovariance into an autocorrelation by

$$
\rho (s, t) = \frac {K _ {X} (s , t)}{\sqrt {K _ {X} (s , s) K _ {X} (t , t)}}.
$$

Example 1.2.1 (AR(1) with drift). For $w _ { t }$ a white noise process with variance $\sigma ^ { 2 }$ , consider the AR(1) with drift process

$$
X _ {t} = a + \theta X _ {t - 1} + w _ {t}
$$

for some real a and θ. We can use the recursive definition to get that

$$
\begin{array}{l} X _ {t} = a + \theta (a + \theta X _ {t - 2} + w _ {t - 1}) + w _ {t} \\ = (1 + \theta) a + \theta^ {2} X _ {t - 2} + \theta w _ {t - 1} + w _ {t}. \\ \end{array}
$$

This can be repeated m times to get

$$
X _ {t} = a \sum_ {j = 0} ^ {m} \theta^ {j} + \theta^ {m + 1} X _ {t - m} + \sum_ {j = 0} ^ {m} \theta^ {j} w _ {t - j}.
$$

Then, assuming this process has an infinite past and that $| \theta | < 1$ , we can take m to infinity to get

$$
X _ {t} = \frac {a}{1 - \theta} + \sum_ {j = 0} ^ {\infty} \theta^ {j} w _ {t - j},
$$

which happens to be a linear process. The mean can now be quickly calculated to be

$\mathrm { E } X _ { t } = a / ( 1 - \theta )$ as $\mathrm { E } w _ { t } = 0$ for all t. Furthermore, the autocovariance is

$$
\begin{array}{l} K _ {X} (s, t) = \operatorname {c o v} \left(X _ {s}, X _ {t}\right) \\ = \operatorname {c o v} \left(\sum_ {j = 0} ^ {\infty} \theta^ {j} w _ {s - j}, \sum_ {j = 0} ^ {\infty} \theta^ {j} w _ {t - j}\right) = \operatorname {E} \left(\sum_ {j, i = 0} ^ {\infty} \theta^ {j} w _ {s - j} \theta^ {i} w _ {t - i}\right) \\ = \sigma^ {2} \sum_ {j, i = 0} ^ {\infty} \theta^ {i + j} \mathbf {1} [ s - j = t - i ] = \sigma^ {2} \theta^ {| s - t |} \sum_ {j = 0} ^ {\infty} \theta^ {2 j} = \frac {\sigma^ {2} \theta^ {| s - t |}}{1 - \theta^ {2}}. \\ \end{array}
$$

This implies that the variance is $\sigma ^ { 2 } / ( 1 - \theta ^ { 2 } )$ . Note that this process is a weakly stationary process, which will be defined below.

# 1.2.2 Cross-Covariance

The cross covariance is similar to the auto covariance, but applies to multivariate time series. More simply, if we have two time series $X _ { t }$ and $Y _ { t }$ , then we can consider

$$
K _ {X Y} (t, s) = \operatorname {c o v} \left(X _ {t}, Y _ {s}\right)
$$

and the cross-correlation

$$
\rho_ {X Y} (t, s) = \frac {K _ {X Y} (t , s)}{K _ {X} (t , t) K _ {Y} (s , s)}.
$$

# 1.2.3 Stationarity

In a broad sense, stationarity implies some property of the time series is invariant to shifts in time. There are two such notions we will consider.

Definition 1.2.2 (Weak Stationarity). A process $X _ { t }$ is said to be weakly stationary if its mean and autocovariance are invariant to time shifts. That is, for any $r > 0$ ,

$$
(M e a n): \mathrm {E X} _ {t} = \mathrm {E X} _ {t + r} = \mu
$$

$$
\left(\text {A u t o c o v a r i a n c e}\right): K _ {X} (t, s) = K _ {X} (t + r, s + r)
$$

Definition 1.2.3 (Strong Stationarity). A process $X _ { t }$ is said to be strongly stationary if its joint distribution function is invariant to time shifts. That is, for any $r > 0$ , and any finite collection of time points $t _ { 1 } , \ldots , t _ { k }$ ,

$$
F \left(X _ {t _ {1}}, \dots , X _ {t _ {k}}\right) = F \left(X _ {t _ {1} + r}, \dots , X _ {t _ {k} + r}\right)
$$

where $F ( )$ is the joint CDF of the $k$ random variables. That is, $F ( X _ { t _ { 1 } } , \dots , X _ { t _ { k } } ) =$ $\mathrm { P } \left( X _ { t _ { 1 } } \leq x _ { t _ { 1 } } , \ldots , X _ { t _ { k } } \leq x _ { t _ { k } } \right)$ ) .

For a weakly (and thus for a strongly) stationary process $X _ { t }$ , we have that the autocovariance function is

$$
K _ {X} (s, t) = K _ {X} (s - t, 0) = K _ {X} (\tau)
$$

for some $\tau$ being the difference between two time points (the time lag). Hence, if a process is weakly stationary, the autocovariance can be treated as a univariate function.

Furthermore, this univariate function is both symmetric and bounded in $\tau$ . This can be seen by noting, for symmetry, that

$$
\begin{array}{l} K _ {X} (\tau) = K _ {X} ((\tau + t) - t) = K _ {X} (\tau + t, t) \\ = K _ {X} (t, \tau + t) = K _ {X} (t - (\tau + t)) = K _ {X} (- \tau), \\ \end{array}
$$

and, for boundedness, that $K _ { X } ( 0 ) = \operatorname { V a r } \left( X _ { t } \right)$ for all $t$ and by applying the Cauchy-Schwarz inequality that, for any $r$ ,

$$
K _ {X} (0) ^ {2} = \operatorname {V a r} \left(X _ {t}\right) \operatorname {V a r} \left(X _ {t + r}\right) \geq \operatorname {c o v} \left(X _ {t}, X _ {t + r}\right) ^ {2} = K _ {X} (r) ^ {2}.
$$

This implies that $| K _ { X } ( \tau ) | \le K _ { X } ( 0 )$ .

Stationarity also helps in the statistical context with estimation. Specifically, we cannot estimate the autocovariance for a single non-stationary series, but can estimate it for a stationary series. With that in mind, often we can modify a time series to make it stationary.

Example 1.2.4. Consider the time series

$$
X _ {t} = a + b t + Y _ {t}
$$

where $Y _ { t }$ is a mean zero stationary process. The mean $\mu _ { t } = a + b t$ is a function of $t$ . However, subtracting off this linear trend leaves

$$
X _ {t} - a - b t = Y _ {t},
$$

which is stationary.

As with cross-covariance, we can consider joint stationarity of two series $X _ { t }$ and $Y _ { t }$ when dealing with multiple time series at once.

Definition 1.2.5 (Joint Stationarity). The processes $X _ { t }$ and $Y _ { t }$ are said to be jointly stationary if both are individually stationary and also if the cross covariance function is also stationary—i.e. $K _ { X Y } ( t , s ) = K _ { X Y } ( t + r , s + r )$ for any $r$ .

# 1.3 Estimation

Estimating parameters in a time series model is harder than it is in standard statistics where we often assume that the observations are iid. Now, we are faced with a single sequence of points $X _ { 1 } , X _ { 2 } , \ldots , X _ { T }$ which are not iid. To estimate the mean and autocovariance we require the process to be weakly stationary. If it isn’t, then, for example, every $X _ { t }$ will have its own mean and we cannot estimate it.

Note as indicated above, we will consider time series with $T$ total observations observed at equally spaced intervals. If the observations are irregularly spaced, more work has to be done.

# 1.3.1 Estimating the mean

the usual sample average, For a weakly stationary process, $\begin{array} { r } { \bar { X } = T ^ { - 1 } \sum _ { t = 1 } ^ { T } X _ { t } } \end{array}$ $\operatorname { E } X _ { t } = \mu$ for all , as an estimator for $t = 1 , \dots , T$ , so we can consider $\mu$ . Specifically, due to the linearity of expectation, we have $\operatorname { E X } = \mu$ . However, as these $X _ { t }$ are not uncorrelated, the variance calculation is a bit more involved than usual.

$$
\begin{array}{l} \operatorname {V a r} \left(\bar {X}\right) = \operatorname {V a r} \left(\frac {1}{T} \sum_ {t = 1} ^ {T} X _ {t}\right) \\ = \frac {1}{T ^ {2}} \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} \operatorname {c o v} \left(X _ {t}, X _ {s}\right) \\ = \frac {1}{T ^ {2}} \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} K _ {X} (| t - s |) \\ = \frac {1}{T} K _ {X} (0) + \frac {2}{T} \sum_ {z = 1} ^ {T - 1} \left(1 - \frac {z}{T}\right) K _ {X} (z). \\ \end{array}
$$

Note that in the uncorrelated case $K _ { X } ( 0 ) = \sigma ^ { 2 }$ and $K _ { X } ( z ) = 0$ for $z > 0$ . Thus, the formula reduces to the usual $\sigma ^ { 2 } / T$ .

# 1.3.2 Estimating the autocovariance

For a weakly stationary process, we can define the sample autocovariance function to be

$$
\hat {K} _ {X} (h) = \frac {1}{T} \sum_ {t = 1} ^ {T - h} (X _ {t + h} - \bar {X}) (X _ {t} - \bar {X}).
$$

As $h$ gets bigger, the number of terms in the sum decreases giving less accurate estimation. Similarly, the sample autocorrelation function is defined to be

$$
\hat {\rho} (h) = \hat {K} _ {X} (h) / \hat {K} (0),
$$

and the sample cross covariance and cross correlation are

$$
\hat {K} _ {X Y} (h) = \frac {1}{T} \sum_ {t = 1} ^ {T - h} (X _ {t + h} - \bar {X}) (Y _ {t} - \bar {Y}) \mathrm {a n d} \hat {\rho} _ {X Y} (h) = \frac {\hat {K} _ {X Y} (h)}{\sqrt {\hat {K} _ {X} (0) \hat {K} _ {Y} (0)}}.
$$

Examples of estimated autocovariance functions are in Figure 1.3 for the white noise process, the random walk, the moving average process with a window of length 9, and the autoregressive process $X _ { t } = X _ { t - 1 } - 0 . 2 X _ { t - 2 } + w _ { t }$ . However, we note that the random walk and this AR(2) process are not stationary. Thus, even though we can compute the autocovariance in R with the acf function, we must consider its validity.

The sample autocovariance is defined in such a way to make the function positive semi-definite. This ensures that estimates of variances will never be negative as, for any real vector $a = ( a 1 , \dots , a _ { T } ) \in \mathbb { R } ^ { T }$ , the variance estimate for $\textstyle { a \cdot X = \sum _ { t = 1 } ^ { T } a _ { t } X _ { t } }$ is

$$
\sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} a _ {t} a _ {s} \hat {K} (| t - s |),
$$

which must be non-negative.

# 1.3.3 Detecting White Noise

A main goal of time series analysis is to transform the data into a white noise process. That is, we aim to identify trends and patterns in the process. Once those have been removed, what remains is random noise. Hence, we need to determine if a process has been transformed into a white noise process.

One way to do this is to look at the estimated autocorrelation function for a given time series as displayed in Figure 1.3. Note that for the white noise process, we see a spike at lag 0 referring to an estimate of the variance of the process ${ \hat { K } } _ { X } ( 0 )$ , which, in this case, is 1. At the remaining lags, ${ \hat { K } } _ { X } ( h )$ is small for $h \neq 0$ . The question is what does small mean?

In the plots of Figure 1.3, R includes blue dashed lines at the value $2 / \sqrt { T }$ . This is because for $w _ { t }$ iid mean zero white noise with variance $\mathrm { E } w _ { t } ^ { 2 } = \sigma ^ { 2 }$ and finite fourth moment, $\mathrm { E } w _ { t } ^ { 4 } < \infty$ , we have a sample autocovariance of approximately

$$
\hat {K} _ {w} (h) \approx \frac {1}{T} \sum_ {t = 1} ^ {T - h} w _ {t + h} w _ {t}.
$$

![](images/fecb6623b04ce6b9285a49dc3cf331449c9924a0a3476b53fb161ea02c782734.jpg)

![](images/5c5ea8cccc5e29f83d8c2074c37d7f829bc81813a2b3d48e746216ab94d4237d.jpg)

![](images/102d68844f5814e7f4658af371323cea7fdfb0652e245fdd5b176cb242bd9eb1.jpg)

![](images/e09b6a28e7df5b9ecf98b65068f1a5cb4569a55273561a3bf57947914ebc7108.jpg)  
Figure 1.3: Estimated autocorrelations from the processes from Figures 1.1 and 1.2 using the acf function in R.

For $h \neq 0$ , this has zero mean as $\mathrm { E } \left( w _ { t } w _ { s } \right) = 0$ for $s \neq t$ , and has a variance of

$$
\begin{array}{l} \frac {1}{T ^ {2}} \mathrm {V a r} \left(\sum_ {t = 1} ^ {T - h} w _ {t + h} w _ {t}\right) = \frac {1}{T ^ {2}} \sum_ {s, t = 1} ^ {T - h} \mathrm {E} [ w _ {s + h} w _ {s} w _ {t + h} w _ {t} ] = \\ \frac {1}{T ^ {2}} \sum_ {t = 1} ^ {T - h} \mathrm {E} [ w _ {t + h} ^ {2} w _ {t} ^ {2} ] = \frac {T - h}{T ^ {2}} \sigma^ {4} \approx \frac {\sigma^ {4}}{T} \\ \end{array}
$$

for large $T$ . Thus, the variance of the autocorrelation is approximately $1 / T$ , and we would expect the values ${ \hat { \rho } } _ { X } ( h )$ to be within two standard deviations from the mean, or $\pm 2 / \sqrt { T }$ , when $X _ { t }$ is a white noise process. Hence, we can examine the autocorrelations to determine whether or not the process looks like white noise.

# Chapter 2

# Statistical Models for Time Series

# Introduction

Two main goals that traverse much of statistics are fitting models to data and using such models for prediction or forecasting. In this chapter, we consider classic linear regression (briefly) to discuss its uses and its shortcomings with respect to time series data. Then, we discuss more sophisticated models for time series of the ARIMA family of models.

As mentioned in the previous chapter, we need to transform a time series $X _ { t }$ into a time series $Y _ { t }$ that is stationary. This is because stationarity allows us to do estimation from a single series. The hard part it to determine how to extract such a stationary $Y _ { t }$ from the series $X _ { t }$ . Before continuing, we need some definitions.

Definition 2.0.1 (Backshift Operator). The backshift operator $B$ acts on time series by $B X _ { t } = X _ { t - 1 }$ . This can be iterated to get $B ^ { k } X _ { t } = X _ { t - k }$ . This can also be inverted to get the forward shift operator $B ^ { - 1 } X _ { t } = X _ { t + 1 }$ . Thus, $B ^ { - 1 } B = B B ^ { - 1 } = I$ the identity operator.

Definition 2.0.2 (Difference Operator). The difference operator $\nabla$ acts on time series by $\nabla X _ { t } = X _ { t } - X _ { t - 1 }$ . Note that $\nabla X _ { t } = ( 1 - B ) X _ { t }$ . This operator can also be iterated to get

$$
\nabla^ {k} X _ {t} = (1 - B) ^ {k} X _ {t} = \sum_ {i = 0} ^ {k} (- 1) ^ {i} {\binom {k} {i}} X _ {t - i}.
$$

For example, the second difference operator is $\nabla ^ { 2 } X _ { t } = X _ { t } - 2 X _ { t - 1 } + X _ { t - 2 }$

Differencing a series can be used to remove periodic trends. Fun fact: using the gamma function, we can also consider fractional differencing for $\kappa \in \mathbb R ^ { + }$ , which is

$$
\nabla^ {\kappa} X _ {t} = \sum_ {i = 0} ^ {\kappa} (- 1) ^ {i} \frac {\Gamma (\kappa + 1)}{i ! \Gamma (\kappa - i + 1)} X _ {t - i}.
$$

# 2.1 Regression

# 2.1.1 Linear Regression in Brief

In linear regression, we consider modelling a response variable $X _ { t }$ by some independent variables or predictors $z _ { t , 1 } , \dotsc , z _ { t , p }$ as

$$
X _ {t} = \beta_ {0} + \beta_ {1} z _ {t, 1} + \dots + \beta_ {p} z _ {t, p} + \varepsilon_ {t}
$$

where the $\beta _ { i }$ are unknown fixed parameters and the $\dot { \varepsilon } _ { t }$ are iid mean zero uncorrelated errors. Written in vector-matrix form, we have $X = Z \beta + \varepsilon$ where $X \in \mathbb { R } ^ { T }$ and $Z \in \mathbb { R } ^ { T \times ( p + 1 ) }$ . Given this setup, the Gauss–Markov theorem tells us that the least squares estimator, ${ \hat { \beta } } = ( Z ^ { \mathrm { { T } } } Z ) ^ { - 1 } Z ^ { \mathrm { { T } } } X$ , is the minimal variance unbiased estimator for $\beta$ .

# 2.1.2 Linear Regression for Time Series

The big challenge for time series is that the error process $\dot { \varepsilon } _ { t }$ may not be uncorrelated white noise, but in fact, a correlated process. Thus, we consider the time series model

$$
X _ {t} = \mu_ {t} + Y _ {t} \tag {2.1.1}
$$

where $\mu _ { t }$ is a deterministic process such as $\mu _ { t } = \beta _ { 0 } + \beta _ { 1 } z _ { t , 1 } + . . . + \beta _ { p } z _ { t , p }$ and where $Y _ { t }$ is a stationary stochastic process. Starting with an observed series $X _ { t }$ , this leaves us with the goal of identifying the deterministic trend $\mu _ { t }$ and the stochastic piece $Y _ { t }$ .

When diagnosing the fit of the linear regression model to the data, we often consider the vector residuals being $r = X - { \hat { \beta } } Z$ . Plotting fitted values against the residuals, we would expect in linear regression to have residuals that look like random noise. However, with time series data, the residuals will often not be white noise but some other stochastic process.

Example 2.1.1 (Prescription Price Data). The TSA package in R contains a dataset called prescrip, which charts monthly US average prescription drug costs for 1986 to 1992. Looking at the time series in Figure 2.1, we notice that there is a steady increase over the time span of the data. A quadratic regression model to this data yielded a fitted model

$$
(\mathrm {c o s t}) = 5 0 5 0 0 0 + 5 1 0. 5 (\mathrm {t i m e}) - 0. 1 3 (\mathrm {t i m e}) ^ {2}
$$

where (time) ranges from 1986.6 to 1992.17. The F-statistic of 1612 with degrees of freedom (2, 65) is very significant (p-value $< 2 \times 1 0 ^ { - 1 6 }$ ), and the R summary for the fitted model is

<table><tr><td></td><td>Estimate</td><td>Std. Error</td><td>t value</td><td>Pr(&gt;|t|)</td></tr><tr><td>(Intercept)</td><td>505000</td><td>1.344e+05</td><td>3.757</td><td>0.0004</td></tr><tr><td>time</td><td>-510.5</td><td>1.351e+02</td><td>-3.778</td><td>0.0003</td></tr><tr><td>time²</td><td>0.129</td><td>3.396e-02</td><td>3.799</td><td>0.0003</td></tr></table>

![](images/0714c7a49c23b7348715389deac47bdc74cef06b5af106de36ab9bd8dcd2b83f.jpg)

![](images/ba87df0210eff705cf90b0c7ea6a5df1585e5672e17c616dce31acf13978a6ee.jpg)

![](images/c5e5d917150cbf68943308af6c35678b054996665d5f80ba01600045b5c666c1.jpg)

![](images/fa5b8cb29d9e42b10c56957f84f9ea87480b7aba2a6f0e0a8f1058ae777a7962.jpg)  
Figure 2.1: Plotted time series of prescription drug costs with fitted regression line (top left). The residuals for the series plotted (bottom left). The estimated autocorrelation functions for the original series (top right) and the residual series (bottom right).

By removing this trend and focusing on the residuals, we see the bottom two plots from Figure 2.1. Here, the estimated autocorrelation does not seem as extreme. However, there are still some periodic patterns that emerge and that will need to be dealt with.

To the residual process, we can fit a linear model using sines and cosines, which gives the fitted model

$$
(\text {r e s i d u a l s}) = 0. 2 - 0. 0 9 \sin (2 \pi (\text {t i m e})) - 0. 6 5 \cos (2 \pi (\text {t i m e})).
$$

The F-statistic of 33.36 with degrees of freedom (2, 65) is also very significant (pvalue $\approx 1 0 ^ { - 1 0 }$ ), and the R summary for the fitted model is as follows.

<table><tr><td></td><td>Estimate</td><td>Std. Error</td><td>t value</td><td>Pr(&gt;|t|)</td></tr><tr><td>(Intercept)</td><td>0.02</td><td>0.06</td><td>0.34</td><td>0.732</td></tr><tr><td>sin</td><td>-0.09</td><td>0.08</td><td>-1.07</td><td>0.290</td></tr><tr><td>cos</td><td>-0.65</td><td>0.08</td><td>-8.07</td><td>2.24e-11</td></tr></table>

In Figure 2.2, we have the residuals for this trigonometric model as well as the estimated autocorrelation. In the ACF plot, we see a large spike at $l a g \ = \ 0 . 1$ . Hence, considering the first difference operator applied to this process, we have the bottom two plots in Figure 2.2. Now the estimated autocorrelation is looking much more like white noise.

# Regression with time series on time series

Note also that we can consider regression of one series with respect to another. For example, given two time series $X _ { t }$ and $Y _ { t }$ , we could fit a model

$$
X _ {t} = \hat {\beta} _ {0} + \hat {\beta} _ {1} Y _ {t}.
$$

We could also consider fitting a model with a fixed lag $h$

$$
X _ {t} = \hat {\beta} _ {0} + \hat {\beta} _ {1} Y _ {t - h}.
$$

As a hypothetical example, $X _ { t }$ could be monthly rainfall and $Y _ { t - 1 }$ could be the average temperature of the previous month.

# 2.2 Smoothing

Smoothing methods are a large class of statistical tools that can be applied to noisy data. While much theoretical work has gone into understanding these methods, we will just present the main idea briefly.

# Moving Average Smoothing

For a time series $X _ { t }$ for $t = 1 , \ldots , T$ and coefficients $\theta _ { - r } , \ldots , \theta _ { 0 } , \ldots , \theta _ { r }$ with $\begin{array} { r } { \sum _ { j = - r } ^ { r } \theta _ { j } = } \end{array}$ 1, we can define a new process

$$
M _ {t} = \sum_ {j = - r} ^ {r} \theta_ {j} X _ {t - j}
$$

for $t = r + 1 , \ldots , T - r$ . The simplest example is to set $\theta _ { j } = ( 2 r + 1 ) ^ { - 1 }$ , which just compute the sample average with a window of length $2 r + 1$ . This can be performed easily in R with the filter function.

![](images/be2f3e6a1746cf9a45af90424a7a0dfe9162319e5418f1265d162ea683b635df.jpg)

![](images/ff393bf7839cdd02bcd4dd0dcc9abec4b400f129f9b6c955cdab254d99017d67.jpg)

![](images/bc0827f15ea34e593f3721a904f5cd2d1ae1b2cfa7dda39eaa734dcfc932d6fe.jpg)

![](images/20537caa4fde58973727522a6caf5b42b12b78de10cf5e83a75d5c1711e50e59.jpg)

![](images/668477111a5e7a5cc36ec0b0584737a27afd23839c0d499c624223d8fc556be6.jpg)  
Figure 2.2: The trig model fitted to the residuals (top left). The residuals for the trig model (top right). The ACF for the trig residual model (middle). The first differences of the trig residuals (bottom left). The ACF for the first differences of the trig residuals (bottom right).

# Kernel Smoothing

A kernel function $\kappa _ { h } ( \boldsymbol { x } , \boldsymbol { x } _ { 0 } )$ is a non-negative function that is decreasing in $\left| x - x _ { 0 } \right|$ and has a bandwidth parameter $h$ . We also require that $\textstyle \int _ { \mathbb { R } } \kappa _ { h } ( x , x _ { 0 } ) d x < \infty$ for all $x _ { 0 } \in \mathbb { R }$ . Examples include

Gaussian:

Triangular:

Epanechnikov:

where the notation $( \ldots ) _ { + }$ means take the positive part and set the rest to zero.

In the time series context, we can use a kernel to construct weights to be used in the previously mentioned moving average smoother. Specifically, for some $r \in \mathbb N$ , we can define $\theta _ { i }$ for $i = - r , \ldots , 0 , \ldots , r$ as

$$
\theta_ {i} = \kappa_ {h} (i, 0) / \sum_ {j = - r} ^ {r} \kappa_ {h} (j, 0).
$$

Kernel-based methods also occur in probability density estimation (the kernel density estimator) and in linear regression (Nadaraya-Watson) as well as others. Note further that kernel based estimators typically are biased estimators and as the bandwidth $h$ increases, the bias increases while the variance decreases. As a result, much research has gone into bandwidth selection. This can be implemented in R via the ksmooth function.

# Lowess

Lowess is an acronym for locally weighted scatterplot smoothing. This method combines nearest neighbours and weighted linear regression. Effectively, it takes a window of data points, say $X _ { t - r } , \ldots , X _ { t + r }$ , and applies a low degree polynomial regression to it. This can be implemented in R by the function lowess. The R manual page states that lowess “is defined by a complex algorithm”.

# Cubic Spline Smoothing

As discussed in the context of linear regression, fitting polynomials to data can be a powerful tool. However, it typically unwise to fit one high degree polynomial to your data. Instead, spline models split the $T$ data points into $k$ pieces by defining the partition

$$
1 = t _ {1} <   t _ {2} <   \dots <   t _ {k + 1} = T.
$$

These points are referred to as the knots. Then, a separate polynomial—typically cubic but could have another degree instead—is fit to each subinterval of approximately $T / k$ data points. That is, we fit a linear model

$$
M _ {t} ^ {(i)} = \beta_ {i, 0} + \beta_ {i, 1} t + \beta_ {i, 2} t ^ {2} + \beta_ {i, 3} t ^ {3}.
$$

to the $i$ th interval. As a result, this can be written as a least squares estimation problem where the $\hat { M } _ { t }$ are the fitted values that minimize

$$
\sum_ {t = 1} ^ {T} (X _ {t} - M _ {t}) ^ {2}.
$$

Here, if we assume $t = 1 , \dots , T$ and $f _ { i } ( t )$ are spline basis functions for $i = 1 , \dots , T$ , then the design matrix for the regression is $F$ with $_ { i j }$ th entry is $F _ { i , t } = f _ { i } ( t )$ . Thus, we can write ${ \hat { M } } = F { \hat { \beta } } = F ( F ^ { \mathrm { T } } F ) ^ { - 1 } F ^ { \mathrm { T } } X$ .

If we want to upgrade our spline model into a smoothing spline we fit the same polynomial but with a penalty term to enforce more smoothing. That is, we would find the $\hat { M } _ { t }$ that minimizes

$$
\sum_ {t = 1} ^ {T} (X _ {t} - M _ {t}) ^ {2} + \lambda \int (M _ {s} ^ {\prime \prime}) ^ {2} d s
$$

where $\lambda \geq 0$ is a smoothing parameter. Note that this minimization problem is taken over all possible twice continuously differentiable functions $M _ { t }$ , which is referred to as the Sobolev space $H ^ { 2 }$ . When $\lambda = 0$ , so smoothing is applied and we simply have a least squares estimator for our data. Taking $\lambda  \infty$ imposes that the second derivative of $M _ { t }$ must be zero. Hence, we have a straight line fit to our data in the limit.

Using the notation from before, we can also work out an explicit solution reminiscent of ridge regression.1 From the penalty term, we can define the matrix $\Omega$ to have entries

$$
\Omega_ {i, j} = \int f _ {i} ^ {\prime \prime} (s) f _ {j} ^ {\prime \prime} (s) d s.
$$

Then, we have

$$
\int (M _ {s} ^ {\prime \prime}) ^ {2} d s = \beta^ {\mathrm {T}} \Omega \beta ,
$$

and consequently, we are finding the coefficients $\hat { \beta }$ that minimize

$$
\| X _ {t} - F \beta \| _ {2} ^ {2} + \lambda \beta^ {\mathrm {T}} \Omega \beta ,
$$

which is ${ \hat { \beta } } = ( F ^ { \mathrm { T } } F + \lambda \Omega ) ^ { - 1 } F ^ { \mathrm { T } } X$ .

# 2.3 ARIMA Models for Times Series

In the previous section, we considered regression models like

$$
X _ {t} = f (t) + w _ {t}
$$

where $f ( t )$ is deterministic and $w _ { t }$ is white noise. The goal was to estimate the deterministic piece by some ${ \hat { f } } ( t )$ . But such an approach cannot handle time series models like the AR(1) process $X _ { t } = X _ { t - 1 } + w _ { t }$ . In this section, we take a closer look at fitting such time series models to observed data.

# 2.3.1 Autoregressive Processes

We reintroduce the autoregressive process formally as

Definition 2.3.1 (Autoregressive Process). The time series $X _ { t }$ is an $A R ( p )$ process if $X _ { t }$ has zero mean and if we can write it as

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i}
$$

where $w _ { t }$ is white noise with variance $\sigma ^ { 2 }$ and $\phi _ { 1 } , \ldots , \phi _ { p } \in \mathbb { R }$ are constants with $\phi _ { p } \neq $ 0. Using the backshift operator $B$ , we can write the $A R ( p )$ process as $\Phi ( B ) X _ { t } = w _ { t }$ where

$$
\Phi (B) = \left(1 - \sum_ {i = 1} ^ {p} \phi_ {i} B ^ {i}\right).
$$

We will refer to $\Phi ( B )$ as the autoregressive operator.

Note that we choose $X _ { t }$ to have zero mean for convenience. If $X _ { t }$ has mean $\mu \neq 0$ , then we can rewrite $X _ { t } = \tilde { X } _ { t } + \mu$ where $\tilde { X _ { t } }$ is mean zero to get

$$
\tilde {X} _ {t} + \mu = w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} (\tilde {X} _ {t} + \mu)
$$

$$
\tilde {X} _ {t} = - \mu \left(1 - \sum_ {i = 1} ^ {p} \phi_ {i}\right) + w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} \tilde {X} _ {t - i}.
$$

That is, we can rewrite $X _ { t }$ as a mean zero $\operatorname { A R } ( p )$ process with an added constant.

A major aspect to consider when analyzing AR processes is causality. We have seen that the AR(1) process with $| \phi _ { 1 } | < 1$ has a causal representation as a linear process. Specifically,

$$
X _ {t} = \phi_ {1} X _ {t - 1} + w _ {t} = \sum_ {i = 0} ^ {\infty} \phi_ {1} ^ {i} w _ {t - i}.
$$

This process was also shown to be stationary. However, when $\phi _ { 1 } = 1$ , we have a random walk which is not stationary. Writing the random walk as a linear process gives a series that does not converge.

Similarly, we can consider the setting of an AR(1) process with $| \phi _ { 1 } | > 1$ , which will grow exponentially fast. However, we can still write this process in the form of a non-causal linear process.

$$
\mathrm {i f} X _ {t + 1} = \phi_ {1} X _ {t} + w _ {t + 1} \mathrm {t h e n} X _ {t} = \phi_ {1} ^ {- 1} X _ {t + 1} - \phi_ {1} ^ {- 1} w _ {t + 1}.
$$

Continuing in this fashion and noting that $| \phi _ { 1 } ^ { - 1 } | < 1$ , we have that

$$
\begin{array}{l} X _ {t} = \phi_ {1} ^ {- 1} \left(\phi_ {1} ^ {- 1} X _ {t + 2} - \phi_ {1} ^ {- 1} w _ {t + 2}\right) - \phi_ {1} ^ {- 1} w _ {t + 1} \\ = \phi_ {1} ^ {- 2} X _ {t + 2} - \phi_ {1} ^ {- 2} w _ {t + 2} - \phi_ {1} ^ {- 1} w _ {t + 1} = \ldots = - \sum_ {i = 1} ^ {\infty} \phi_ {1} ^ {- i} w _ {t + i}, \\ \end{array}
$$

which is a linear process with reverse causality.2 Using this linear process representation, we can compute the stationary autocovariance to be

$$
\begin{array}{l} K _ {X} (\tau) = \operatorname {E} \left(\sum_ {i, j = 1} ^ {\infty} \phi_ {1} ^ {- (i + j)} w _ {t + \tau + i} w _ {t + j}\right) \\ = \sigma^ {2} \sum_ {i, j = 1} ^ {\infty} \phi_ {1} ^ {- (i + j)} \mathbf {1} [ \tau + i = j ] = \sigma^ {2} \phi_ {1} ^ {- | \tau |} \sum_ {i = 1} ^ {\infty} \phi_ {1} ^ {- 2 i} = \frac {\sigma^ {2} \phi_ {1} ^ {- | \tau |} \phi_ {1} ^ {- 2}}{1 - \phi_ {1} ^ {- 2}} \\ \end{array}
$$

where the extra $\phi _ { 1 } ^ { - 2 }$ comes from the fact that the above sums begin at 1 instead of at 0.

If we strengthen the white noise process $w _ { t }$ to be iid Gaussian with variance $\sigma ^ { 2 }$ , then we have that the process $X _ { t }$ is Gaussian. Consequently, it is completely characterized by its mean—which is zero—and its autocovariance above. Now consider the causal AR(1) process

$$
Y _ {t} = \phi^ {- 1} Y _ {t - 1} + v _ {t}
$$

where $v _ { t }$ is iid Gaussian white noise with variance $\sigma ^ { 2 } \phi ^ { - 2 }$ . This is a mean zero process with autocovariance

$$
K _ {Y} (\tau) = \frac {\sigma^ {2} \phi_ {1} ^ {- | \tau |} \phi_ {1} ^ {- 2}}{1 - \phi_ {1} ^ {- 2}}.
$$

Thus, these two processes are stochastically equivalent—i.e. for any finite collection of time points $t _ { 1 } , \ldots , t _ { k }$ , the vectors $( X _ { t _ { 1 } } , \dots , X _ { t _ { k } } )$ and $( Y _ { t _ { 1 } } , \ldots , Y _ { t _ { k } } )$ are equal in distribution. Thus the non-causal $A R ( 1 )$ process with $| \phi | > 1$ has an equivalent causal representation.

We can extend this idea to general AR(p) processes in order to rewrite a recursively defined $\operatorname { A R } ( p )$ process as stationary linear process. For some AR operator, we have the general form

$$
\Phi (B) X _ {t} = w _ {t}.
$$

If the operator $\Phi ( B )$ is invertible, then we can simply write the linear process form

$$
X _ {t} = \Phi^ {- 1} (B) w _ {t}.
$$

But then we have to determine if the inverse operator exists and what its form is.

Reconsidering the AR(1) process above, we write it as $( 1 - \phi _ { 1 } B ) X _ { t } = w _ { t }$ . Considering the complex polynomial $\Phi ( z ) = 1 - \phi _ { 1 } z$ for $z \in \mathbb { C }$ , we note that

$$
\Phi^ {- 1} (z) = \frac {1}{1 - \phi_ {1} z} = 1 + \sum_ {j = 1} ^ {\infty} \phi_ {1} ^ {j} z ^ {j},
$$

which has a radius of convergence of $| \phi _ { 1 } ^ { - 1 } |$ . In the case that $| \phi _ { 1 } | < 1$ , we can use this to quickly write

$$
X _ {t} = \left(1 + \sum_ {j = 1} ^ {\infty} \phi_ {1} ^ {j} B ^ {j}\right) w _ {t}.
$$

For the general AR(p) process, consider the complex polynomial $\Phi ( z ) = 1 - \phi _ { 1 } z -$ $\cdots \phi _ { p } z ^ { p }$ and recall that this can be factored on $\mathbb { C }$ into $\Phi ( z ) = \phi _ { p } ( z - r _ { 1 } ) \ldots ( z - r _ { p } )$ where $r _ { 1 } , \ldots , r _ { p }$ are the roots.3 Then, noting that $( - 1 ) ^ { p } \phi _ { p } \prod _ { j = 1 } ^ { p } r _ { j } \ = \ 1$ , we can write

$$
\Phi^ {- 1} (z) = \frac {1}{(1 - r _ {1} ^ {- 1} z) \ldots (1 - r _ {p} ^ {- 1} z)}.
$$

Now, assuming further that all of the roots $| r _ { i } | > 1$ , we can write $\Phi ( B ) X _ { t } = w _ { t }$ as a causal linear process

$$
X _ {t} = \Phi^ {- 1} (B) w _ {t} = \prod_ {j = 1} ^ {p} \left(1 + \sum_ {i = 1} ^ {\infty} r _ {i} ^ {- 1} B\right) w _ {t}.
$$

# 2.3.2 Moving Average Process

Next, we reintroduce the moving average process formally as

Definition 2.3.2 (Moving Average Process). The time series $X _ { t }$ is an $M A ( q )$ process if $X _ { t }$ has zero mean and if we can write it as

$$
X _ {t} = w _ {t} + \sum_ {j = 1} ^ {q} \theta_ {j} w _ {t - j}
$$

where $w _ { t }$ is white noise with variance $\sigma ^ { 2 }$ and $\theta _ { 1 } , \dots , \theta _ { q } \in \mathbb { R }$ are constants with $\theta _ { q } \neq $ 0. Using the backshift operator $B$ , we can write the $M A ( q )$ process as $X _ { t } = \Theta ( B ) w _ { t }$ where

$$
\Theta (B) = \left(1 + \sum_ {j = 1} ^ {q} \theta_ {j} B ^ {j}\right).
$$

We will refer to $\Theta ( B )$ as the moving average operator.

Unlike for autoregressive processes, we already have the MA(q) process written in the form of a linear process. Hence, it will be stationary for any choice of the $\theta _ { j }$ . However, similar to how we were able to find a causal AR process that is equivalent to a non-causal one, there is a uniqueness problem with the MA process that needs to be addressed.

For simplicity, consider the MA(1) process $X _ { t } = w _ { t } + \theta _ { 1 } w _ { t - 1 }$ with $w _ { t }$ white noise with variance $\sigma ^ { 2 }$ . This has mean zero and stationary autocovariance

$$
K _ {X} (\tau) = \left\{ \begin{array}{l l} (1 + \theta_ {1} ^ {2}) \sigma^ {2} & \mathrm {f o r} \tau = 0 \\ \theta_ {1} \sigma^ {2} & \mathrm {f o r} \tau = 1 \\ 0 & \mathrm {f o r} \tau \geq 2 \end{array} \right.
$$

Alternatively, we note that the process $Y _ { t } = v _ { t } + \theta _ { 1 } ^ { - 1 } v _ { t }$ , with $v _ { t }$ white noise with variance $\theta _ { 1 } ^ { 2 } \sigma ^ { 2 }$ , is also mean zero with the same autocovariance at $X _ { t }$ . Hence, if the white noise processes are Gaussian, then $X _ { t }$ and $Y _ { t }$ are stochastically equivalent. This can certainly cause trouble in a statistics context as if we were to estimate the parameters for the MA(1) model, which parameters would we be estimating?

To choose a specific representation for the MA process, we consider which one is invertible. That is, which process can be written as a causal AR process for white noise in terms of $X _ { t }$ ? Starting with the general form, we have $X _ { t } = \Theta ( B ) w _ { t }$ . If $\Theta ( B )$ is invertible, then we can write $w _ { t } = \Theta ^ { - 1 } ( B ) X _ { t }$ . Using the above MA(1) process as an example, we can express the white noise process as

$$
w _ {t} = \sum_ {i = 0} ^ {\infty} (- 1) ^ {i} \theta_ {1} ^ {i} X _ {t - i} \quad \mathrm {o r} \quad v _ {t} = \sum_ {i = 0} ^ {\infty} (- 1) ^ {i} \theta_ {1} ^ {- i} Y _ {t - i}.
$$

Thus, as only one of $\theta _ { 1 }$ and $\theta _ { 1 } ^ { - 1 }$ can be less than 1 in magnitude, only one of the above series is convergent in the mean squared sense. That process will be the invertible one. Note that $w _ { t }$ is equal in distribution to $\theta _ { 1 } ^ { - 1 } v _ { t }$ . Note also that if $\theta _ { 1 } = 1$ then we do not have invertibility.

# 2.3.3 Auto Regressive Moving Average Processes

Now we can combine the AR and MA processes in to the autoregressive moving average process (ARMA), which simply is as follows.

Definition 2.3.3 (Autoregressive Moving Average Process). The time series $X _ { t }$ is an ARMA(p, q) process if $X _ { t }$ has zero mean and if we can write it as

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i} + \sum_ {j = 1} ^ {q} \theta_ {j} w _ {t - j}
$$

where $w _ { t }$ is white noise with variance $\sigma ^ { 2 }$ and $\phi _ { 1 } , \ldots , \phi _ { p } , \theta _ { 1 } , \ldots , \theta _ { q } \in \mathbb { R }$ are constants with $\phi _ { p } \neq 0$ and ${ \theta } _ { q } \ne 0$ . Using the backshift operator $B$ , we can succinctly write this process as $\Phi ( B ) X _ { t } = \Theta ( B ) w _ { t }$ where as before

$$
\Phi (B) = \left(1 + \sum_ {i = 1} ^ {p} \phi_ {i} B ^ {i}\right), \quad \mathrm {a n d} \quad \Theta (B) = \left(1 + \sum_ {j = 1} ^ {q} \theta_ {j} B ^ {j}\right).
$$

The first thing to note is that similar to the introduction of the AR process, we assume in the definition that $X _ { t }$ has zero mean. If instead it has a mean $\mu \neq 0$ , we can subtract off the mean to get

$$
\Phi (B) (X _ {t} - \mu) = \Theta (B) w _ {t}
$$

$$
\Phi (B) X _ {t} = \mu \left(1 - \sum_ {i = 1} ^ {p} \phi_ {i}\right) + \Theta (B) w _ {t}
$$

and consider the mean zero process.

The second thing to note is that the model is not unique as written. That is, for some invertible operator $\eta ( B )$ , we can consider the equivalent process

$$
\eta (B) \Phi (B) X _ {t} = \eta (B) \Theta (B) w _ {t}.
$$

For example, we can consider the white noise process $X _ { t } = w _ { t }$ and, for some $| \theta | < 1$ , the equivalent process

$$
(1 - \theta B) X _ {t} = (1 - \theta B) w _ {t}
$$

$$
X _ {t} = \theta X _ {t - 1} - \theta w _ {t - 1} + w _ {t}.
$$

This may look like a more complex ARMA process, but is in fact just white noise in disguise. To address this problem, we only want to consider AR and MA operators that are relatively prime. That is, for $z \in \mathbb { C }$ , we want the polynomials

$$
\Phi (z) = 1 - \phi_ {1} z - \ldots - \phi_ {p} z ^ {p}, \mathrm {a n d}
$$

$$
\Theta (z) = 1 + \theta_ {1} z + \ldots + \theta_ {q} z ^ {q}
$$

to not have any common roots. In the case that $\Theta$ is invertible, we can write the ARMA process as

$$
\frac {\Phi (B)}{\Theta (B)} X _ {t} = w _ {t}.
$$

Thus, in this form, we see that common factors in $\Phi$ and $\Theta$ can be cancelled out.

When we write $X _ { t }$ in this way, it is said to be invertible if we have

$$
w _ {t} = \frac {\Phi (B)}{\Theta (B)} X _ {t} = X _ {t} + \sum_ {j = 1} ^ {\infty} \pi_ {j} X _ {t - j}
$$

where $\textstyle \sum _ { j = 1 } ^ { \infty } | \pi _ { j } | < \infty$ . Hence, returning the the previous discussion on the MA processes, we want to write out the process as a convergent series. Considering the MA polynomial $\Theta ( z )$ for $z \in \mathbb { C }$ , the ARMA process $X _ { t }$ is invertible if and only if all of the roots of $\Theta ( z )$ lie outside of the unit disk $\mathcal { D } = \{ z : | z | \leq 1 \}$ .

Similarly, we can write the ARMA process in the form of a stationary linear process

$$
X _ {t} = \frac {\Theta (B)}{\Phi (B)} w _ {t}.
$$

However, this process may not be causal. A causal process as discussed before can be written as

$$
X _ {t} = w _ {t} + \sum_ {j = 1} ^ {\infty} \psi_ {j} w _ {t - j}
$$

with $\textstyle \sum _ { j = 1 } ^ { \infty } | \psi _ { j } | < \infty$ . A necessary and sufficient condition for causality in an ARMA process is to have an autoregressive polynomial $\Phi ( z )$ such that all of its roots lie outside of the unit disk $\mathcal { D } = \{ z : | z | \leq 1 \}$ .

In summary, an ARMA process $X _ { t }$ is

1. causal if $r _ { 1 } , . . . , r _ { p }$ , the roots of $\Phi ( z )$ are such that $| r _ { i } | > 1$ ;   
2. invertible if $r _ { 1 } , \ldots , r _ { q }$ , the roots of $\Theta ( z )$ are such that $| r _ { i } | > 1$

Note that the proof of invertibility is mostly identical to that for causality expect focusing on $\Theta$ instead of $\Phi$ .

Proof of Causality. Let the roots of $\Phi ( z )$ be $r _ { 1 } , \ldots , r _ { p }$ . First, assume that the roots are all outside of the unit disk, and without loss of generality, are ordered so that $1 < | r _ { 1 } | \leq \ldots \leq | r _ { p } |$ . Then, let $| \boldsymbol { r } _ { 1 } | = 1 + \varepsilon$ for some $\varepsilon > 0$ . This implies that $\Phi ^ { - 1 } ( z )$ exists and has a power series expansion

$$
\Phi^ {- 1} (z) = \sum_ {j = 0} ^ {\infty} a _ {j} z ^ {j}
$$

with a radius of convergence of $\vert z \vert < 1 + \varepsilon$ .

If we choose a $\delta$ such that $0 < \delta < \varepsilon$ then the point $z = 1 + \delta$ lies within the radius of convergence, so

$$
\Phi^ {- 1} (1 + \delta) = \sum_ {j = 0} ^ {\infty} a _ {j} (1 + \delta) ^ {j} <   \infty .
$$

As this series converges, we know that there exists a constant $c > 0$ such that $| a _ { j } ( 1 + \delta ) ^ { j } | < c$ for all $j$ . Hence, $| a _ { j } | < c ( 1 + \delta ) ^ { - j }$ . Thus,

$$
\sum_ {j = 0} ^ {\infty} \left| a _ {j} \right| <   c \sum_ {j = 0} ^ {\infty} (1 + \delta) ^ {- j} <   \infty ,
$$

and the sequence of $a _ { j }$ is absolutely summable. This implies that for the ARMA process $\Phi ( B ) X _ { t } = \Theta ( B ) w _ { t }$ , we can write

$$
X _ {t} = \Phi^ {- 1} (B) \Theta (B) w _ {t} = w _ {t} + \sum_ {j = 1} ^ {\infty} \psi_ {j} w _ {t - j}.
$$

Since the $a _ { j }$ are absolutely summable, so are the coefficients $\psi _ { j }$ . Thus, we have that $X _ { t }$ is a causal process.

For the reverse, let’s assume that $X _ { t }$ , defined by $\Phi ( B ) X _ { t } = \Theta ( B ) w _ { t }$ , be a causal process. That is, we can write

$$
X _ {t} = w _ {t} + \sum_ {j = 1} ^ {\infty} \psi_ {j} w _ {t - j} \quad \mathrm {a n d} \quad \sum_ {j = 1} ^ {\infty} | \psi_ {j} | <   \infty .
$$

As a result, we can write $X _ { t } = \Psi ( B ) w _ { t }$ and also $\Phi ( B ) X _ { t } = \Theta ( B ) w _ { t }$ . Equating the two right hand expressions, we have

$$
\Theta (B) w _ {t} = \Phi (B) \Psi (B) w _ {t}.
$$

Writing the complex polynomial $\begin{array} { r } { \Phi ( z ) \Psi ( z ) = \sum _ { i = 1 } ^ { \infty } a _ { j } z ^ { j } } \end{array}$ , we know that this series has a radius of convergence of at least $| z | \le 1$ as $\Psi$ also does and $\Phi$ is a finite polynomial. Hence, it makes sense to write

$$
\sum_ {j = 1} ^ {q} \theta_ {j} w _ {t - j} = \sum_ {j = 1} ^ {\infty} a _ {j} w _ {t - j}.
$$

If we consider computing the covariance of each sum with $w _ { t - i }$ for $i = 1 , 2 , 3 , \dots$ , we get a sequence of equations $\theta _ { j } = a _ { j }$ for $j \le q$ and $a _ { j } = 0$ for $j > q$ . That is, we can equate matching coefficients in the two series. Thus, $\Theta ( z ) = \Phi ( z ) \Psi ( z )$ for $| z | \le 1$ .

We know that none of the roots of the polynomial $\Psi$ can lie on or within the unit disk. Hence, if there exists a $z _ { 0 } \in \mathcal { D }$ such that $\Phi ( z _ { 0 } ) = 0$ , then $\Theta ( z _ { 0 } ) = 0$ and the two polynomials have a common root. As they are assumed to have no common factors, this implies that all roots of $\Phi$ lie outside of the unit disk. □

# 2.3.4 ARIMA

Often, we do not have an ARMA process but an ARMA process with some deterministic trend. Thus, the process is not stationary, but often can be transformed into a

stationary process via the differencing operator. For example, if $X _ { t }$ is a stationary process, and we have $Y _ { t }$ defined by

$$
Y _ {t} = \beta_ {0} + \beta_ {1} t + X _ {t},
$$

then by applying the first difference operator, we have

$$
\nabla Y _ {t} = \beta_ {1} + X _ {t} - X _ {t - 1},
$$

which is stationary. This motivates the following definition.

Definition 2.3.4 (Autoregressive Moving Integrated Average Process). The time series $X _ { t }$ is an $A R I M A ( p , d , q )$ process if the dth difference process,

$$
\nabla^ {d} X _ {t} = (1 - B) ^ {d} X _ {t},
$$

is an $A R M A ( p , q )$ process. We can write it in terms of the backshift operator as $\Phi ( B ) ( 1 - B ) ^ { d } X _ { t } = \Theta ( B ) w _ { t }$ where as before

$$
\Phi (B) = \left(1 + \sum_ {i = 1} ^ {p} \phi_ {i} B ^ {i}\right), \quad \text {a n d} \quad \Theta (B) = \left(1 + \sum_ {j = 1} ^ {q} \theta_ {j} B ^ {j}\right).
$$

As before, we assume in the definition that $\nabla ^ { d } X _ { t }$ has zero mean. If instead it has a mean $\mu \neq 0$ , we write $\begin{array} { r } { \Phi ( B ) ( 1 - B ) ^ { d } X _ { t } = \mu \left( 1 - \sum _ { i = 1 } ^ { p } \phi _ { i } \right) + \Theta ( B ) w _ { t } } \end{array}$ . For example, if we have $X _ { t } = \beta _ { 0 } + \beta _ { 1 } t + \phi X _ { t - 1 } + w _ { t }$ for $\beta _ { 0 } , \beta _ { 1 } \in \mathbb { R }$ and $| \phi | < 1$ , then

$$
\begin{array}{l} \nabla X _ {t} = X _ {t} - X _ {t - 1} \\ = \left[ \beta_ {0} + \beta_ {1} t + \phi X _ {t - 1} + w _ {t} \right] - \left[ \beta_ {0} + \beta_ {1} (t - 1) + \phi X _ {t - 2} + w _ {t - 1} \right] \\ = \beta_ {1} + \phi \nabla X _ {t - 1} + w _ {t} - w _ {t - 1}. \\ \end{array}
$$

This is an ARMA $( 1 , 1 )$ process with non-zero mean that can be written as

$$
(1 - \phi B) \delta X _ {t} = \beta_ {1} + (1 - B) w _ {t}.
$$

Note that the mean is not $\beta _ { 1 }$ but in fact $\beta _ { 1 } / ( 1 - \phi )$ .

# 2.4 Testing for Stationarity and Autocorrelation

When presented with time series data, we often want to know if the series is stationary as it stands or after applying some difference operators. Similarly, we may be interested in knowing if there are any significant autocorrelations at various lags. These questions motivate a large collection of statistical tests.

# 2.4.1 Box-Pierce and Ljung-Box Tests

The R function Box.test() in the stats package performs both the Box-Pierce and Ljung-Box tests.

For a stationary time series $X _ { t }$ , we denote the estimated autocorrelations to be ${ \hat { \rho } } _ { X } ( h )$ at $\log h$ . If we assume that the true autocorrelations are zero—i.e. $\rho _ { X } ( h ) = 0$ for all $h \neq 0$ —then we have white noise. Instead of visually looking at a plot of the autocorrelation, we can use the Box-Pierce test to test for non-zero correlations by combining the estimated autocorrelations at lags $1 , \ldots , h$ for some user chosen value $h$ . We aim to test the hypotheses

$$
H _ {0}: \rho_ {X} (1) = \ldots = \rho_ {X} (h) = 0, H _ {1}: \exists j \mathrm {s . t .} \rho_ {X} (j) \neq 0.
$$

Under $H _ { 0 }$ , we have that $\sqrt { n } \rho _ { X } ( j )$ is approximately $\mathcal { N } \left( 0 , 1 \right)$ for $j = 1 , \ldots , h$ . The test statistic for the Box-Pierce test is

$$
Q _ {\mathrm {B P}} = n \sum_ {j = 1} ^ {h} \hat {\rho} _ {X} (j) ^ {2},
$$

which will be approximately $\chi ^ { 2 } \left( h \right)$ under $H _ { 0 }$ . Recall, however, that the ability to estimate $\hat { \rho } _ { X }$ becomes harder for large lags especially if the data size is small. Hence, $h$ should not be set to be too large in practice.

Another version of this test is the Ljung-Box test, which has a similar form to the Box-Pierce test and the same approximate $\chi ^ { 2 } \left( \left( \right) h \right)$ distribution. The alternative form is supposed to give a distribution under $H _ { 0 }$ that is closer to the desired $\chi ^ { 2 } \left( h \right)$ . The test statistic is

$$
Q _ {\mathrm {L B}} = n (n + 2) \sum_ {j = 1} ^ {h} \frac {\hat {\rho} _ {X} (j) ^ {2}}{n - j}.
$$

In the function Box.test(), there is a fitdf argument. The point of this argument is to reduce the chi-squared degrees of freedom in the case that you are fitting a model first. In particular, if you first fit an ARMA(p,q) model to $X _ { t }$ and then apply Box.test to the residual process, you should reduce the number of degrees of freedom by $p + q$ . In this case, we require $h > p + q$ to be able to perform these tests. Ljung and Box study $Q _ { \mathrm { L B } }$ in a 1978 research article4 and look at the first and second moments of their statistic for how closely it coincides with the $\chi ^ { 2 } \left( h \right)$ distribution.

# 2.4.2 Durbin–Watson Test

As mentioned above, the Box-Pierce and Ljung-Box tests can be applied to the residuals of an ARMA model with the goal of determining if there are non-zero

autocorrelations among the residuals. Similarly, the Durbin-Watson test tests for autocorrelations of order 1 among the residuals of a linear model.

Considering the linear model

$$
X _ {t} = \beta_ {0} + \beta_ {1} t + \dots + \beta_ {p} t ^ {p} + r _ {t}
$$

with $t = 1 , \dots , T$ , we can compute the least squares estimator $\hat { \beta }$ and then compute the residuals $\hat { r } _ { t } = X _ { t } - \Big \langle \hat { \beta } , ( 1 , t , \dotsc , t ^ { p } ) \Big \rangle$ . The Durbin–Watson Test assumes the following model for the residuals:

$$
\hat {r} _ {t} = \rho \hat {r} _ {t - 1} + w _ {t}
$$

where $w _ { t }$ is white noise. Then, it tests the hypotheses $H _ { 0 } : \rho = 0 , H _ { 1 } : \rho \neq 0$ . It does this by computing the test statistics

$$
Q _ {\mathrm {D W}} = \frac {\sum_ {t = 2} ^ {T} (\hat {r} _ {t} - \hat {r} _ {t - 1}) ^ {2}}{\sum_ {t = 1} ^ {T} \hat {r} _ {t} ^ {2}}.
$$

If this test statistic is close to zero, it implies that $\hat { r } _ { t }$ and $\hat { r } _ { t - 1 }$ are close in value indicating a strong positive autocorrelation of order 1. In contrast, if the test statistic is large (close to the max of 4), then it indicates that there is a strong negative autocorrelation of order 1. Otherwise, a test statistic near 2 indicates no autocorrelation of order 1. In the R function, dwtest() in the lmtest package, p-values are computed for this statistic. The documentation claims that Under the assumption of normally distributed [errors], the null distribution of the Durbin-Watson statistic is the distribution of a linear combination of chi-squared variables. Furthermore, for large sample sizes, this code apparently switches to a normal approximation for the p-value computation.

# 2.4.3 Breusch–Godfrey test

The Breusch–Godfrey test is similar to the Durbin-Watson test in the sense that it applies to the residuals of a linear model. In this case, it can test for higher order autocorrelations $\operatorname { A R } ( p )$ than just AR(1) processes. In this case, the $R ^ { 2 }$ value is computed for a regression model, being the ratio of the regression sum of squares to the total sum of squares. Then $n R ^ { 2 }$ is compared to a $\chi ^ { 2 } \left( p \right)$ where $p$ is the order of the AR process to be tested. Alternatively, the documentation for the R implementation, bgtest in the lmtest package, says that the user can use the Chi-Squared distribution or can switch to the F distribution if desired.

Note that there is also a Breusch–Pagan test, which tests for heteroskedasticity in the residuals of a linear model. An R implementation can be found in bptest in the lmtest package.

# 2.4.4 Augmented Dickey-Fuller Test

Switching away from testing for non-zero autocorrelations, we now consider testing for stationarity or non-stationarity of a time series. These tests are often referred to as unit root tests, because—recalling the previous sections—if the autoregressive operator $\Phi$ has a unit root, then the process is not stationary. Hence, these tests aim to determine whether or not a unit root exists based on some observed data.

The Dickey-Fuller Test performs such a unit root test for AR(1) models. In this case, the null hypothesis is that $\Phi ( z )$ has a root $| r | = 1$ , and the alternative is that $| r | > 1$ for all $i$ . If

$$
X _ {t} = \phi X _ {t - 1} + w _ {t}
$$

then the first difference can be written as

$$
\nabla X _ {t} = (\phi - 1) X _ {t - 1} + w _ {t}.
$$

Denoting $\phi ^ { \prime } = \phi - 1$ , we want to test the null $H _ { 0 } : \phi ^ { \prime } = 0$ against the alternative $H _ { 1 } : \phi \neq 0$ . This is done by estimating $\hat { \phi } ^ { \prime }$ and the standard error for $\hat { \phi } ^ { \prime }$ . This null hypothesis is equivalent to testing $H _ { 0 } : \phi = 1$ or that the polynomial $\Phi ( z ) = 1 - \phi z$ has a unit root.

The Augmented Dickey-Fuller Test extends this idea to AR(p) models. If we have

$$
X _ {t} = \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i} + w _ {t},
$$

then the first difference can be written as

$$
\nabla X _ {t} = \phi_ {1} ^ {\prime} X _ {t - 1} + \sum_ {i = 1} ^ {p - 1} \phi_ {i + 1} ^ {\prime} \nabla X _ {t - i} + w _ {t}
$$

where the coefficients are $\begin{array} { r } { \phi _ { 1 } ^ { \prime } = \sum _ { j = 1 } ^ { p } \phi _ { j } - 1 } \end{array}$ and $\begin{array} { r } { \phi _ { i } ^ { \prime } = - \sum _ { j = i } ^ { p } \phi _ { j } } \end{array}$ for $j > 1$ . Thus, if 1 is a root—i.e. if $\Phi ( 1 ) = 0$ —then that implies that $\phi _ { 1 } ^ { \prime } = 0$ . Hence, we can perform a similar test to the Dickey-Fuller test above.

In R, the Augmented Dickey-Fuller test is implemented in the function adf.test() in the tseries package. In this version of the test, a constant and a linear term are first assumed and the residual process is run through the above test. That is, we consider the model

$$
X _ {t} = \beta_ {0} + \beta_ {1} t + \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i} + w _ {t}
$$

with a deterministic linear trend. The R function also requires the user to choose how many lags to use when estimating the parameters $\hat { \phi }$ .

# 2.4.5 Phillips–Perron test

An alternative to the Augmented Dickey-Fuller test is the Phillips-Perron test. The set up is the same, but the test is designed to be more robust to deviations in the assumptions. In R, this test can be performed by the function pp.test() in the tseries package. The test statistic is more complicated, and the p-value is computed via a table of values and linear interpolation. The documentation also points out that the Newey-West estimator is used for the variance, which is a robust estimator of the covariance in linear regression when the classic assumptions of homoscedastic uncorrelated errors is violated.

# 2.5 Autocorrelation and Partial Autocorrelation

Given some time series data, we often wish to diagnose the type time series process that produced the data. Two tools we can use are the estimated autocorrelation function and the estimated partial autocorrelation function.

First, we recall the notion of partial correlation outside of the time series context. Given two random variables $X$ and $Y$ , we may compute the correlation $\operatorname { c o r r } ( X , Y )$ , which measures the linearity between the two variables. That is, the closer to 1 the magnitude of the correlation is, the closer $X$ and $Y$ are to being linearly dependent. Often in statistics, we are reminded that correlation does not imply causation. In fact, given two correlated random variables, there may be a third random variable $Z$ influencing both of them. Hence, consider iid observations $( X _ { 1 } , Y _ { 1 } , Z _ { 1 } ) , \dots , ( X _ { n } , Y _ { n } , Z _ { n } )$ . We can define the partial correlation between $X$ and $Y$ given $Z$ to be the correlation of the residuals of $X$ and $Y$ each regressed on $Z$ . That is, let

$$
\hat {X} _ {i} = \hat {\alpha} _ {0} + \hat {\alpha} _ {1} Z _ {i} \mathrm {a n d} \hat {Y} _ {i} = \hat {\beta} _ {0} + \hat {\beta} _ {1} Z _ {i}
$$

be the ith fitted values for $X$ and $Y$ , respectively. Then, the partial correlation is

$$
\operatorname {c o r r} (X - \hat {X}, Y - \hat {Y})
$$

where $X - { \hat { X } }$ and $Y - { \hat { Y } }$ are the residuals for $X$ and $Y$ , respectively.

The idea of partial correlation is to remove the dependency of the confounding variable $Z$ . Hence, if $\operatorname { c o r r } ( X - { \hat { X } } , Y - { \hat { Y } } ) = 0$ , then $X$ and $Y$ are said to be conditionally uncorrelated—or conditionally independent in the case that $X$ , $Y$ , and $Z$ are jointly normal. An hypothetical example is if $X$ is the price of a subjects car and $Y$ is the price of a subjects house, we may expect $X$ and $Y$ to be positively correlated. However, conditioning on $Z$ , the subjects income, the house value and car value may be conditionally uncorrelated. Note that in the case that the random variables are jointly normal, we have that

$$
\operatorname {c o r r} (X - \hat {X}, Y - \hat {Y}) = \operatorname {c o r r} (X, Y | Z) = \frac {\operatorname {E} [ (X - \operatorname {E} X) (Y - \operatorname {E} Y) | Z ]}{\operatorname {E} [ (X - \operatorname {E} X) ^ {2} | Z ] \operatorname {E} [ (Y - \operatorname {E} Y) ^ {2} | Z ]}.
$$

In the time series context we define

Definition 2.5.1 (Partial Autocorrelation). Let $X _ { t }$ be a stationary process, then the partial autocorrelation at lag h is

$$
\varphi_ {X} (h) = \left\{ \begin{array}{l l} \rho_ {X} (1) & \mathrm {i f} h = 1 \\ \operatorname {c o r r} (X _ {t + h} - \hat {X} _ {t + h}, X _ {t} - \hat {X} _ {t}) & \mathrm {i f} h > 1 \end{array} \right.
$$

where $\hat { X } _ { t + h }$ and $\hat { X } _ { t }$ are the result of regressing each respective term on all of the intermediate terms. That is,

$$
\hat {X} _ {t + h} = \beta_ {1} X _ {t + h - 1} + \dots + \beta_ {h - 1} X _ {t + 1}
$$

$$
\hat {X} _ {t} = \beta_ {1} X _ {t + 1} + \dots + \beta_ {h - 1} X _ {t + h - 1}
$$

where the intercept term is excluded as $X _ { t }$ is assumed to be mean zero. Note that due to stationarity of $X _ { t }$ and the symmetry of the autocorrelation function, the $\beta$ ’s above are the same coefficients. Lastly, if $X _ { t }$ is a Gaussian process, we can write

$$
\varphi_ {X} (h) = \operatorname {c o r r} \left(X _ {t + h}, X _ {t} \mid X _ {t + h - 1}, \dots , X _ {t + 1}\right)
$$

for $h > 1$ .

# 2.5.1 ACF for AR(p)

To begin, we consider the causal mean zero AR(1) process $X _ { t } = \phi X _ { t - 1 } + w _ { t }$ where $| \phi | < 1$ . Then, we can multiply by $X _ { t - h }$ and note that

$$
\mathrm {E} \left(X _ {t} X _ {t - h}\right) = \mathrm {E} \left(\phi X _ {t - 1} X _ {t - h}\right) + \mathrm {E} \left(w _ {t} X _ {t - h}\right)
$$

$$
K _ {X} (h) = \phi K _ {X} (h - 1) + 0.
$$

Therefore, the autocovariance is defined by a first order difference equation

$$
f (h) = \phi f (h - 1).
$$

As the characteristic polynomial is $1 - \phi z$ with root $z _ { 1 } = \phi ^ { - 1 }$ , we can solve this difference equation to get the solution $f ( h ) = c z _ { 1 } ^ { - h }$ for some constant $c$ corresponding to the initial condition $f ( 0 ) = c$ . This can be checked by plugging in the solution to the equation to get

$$
c \left(\phi^ {- 1}\right) ^ {- h} = c \phi \left(\phi^ {- 1}\right) ^ {- h + 1}.
$$

Revisiting the autocorrelation, we have $K _ { X } ( 0 ) \ = \ \mathrm { V a r } \left( X _ { t } \right)$ , so $\rho _ { X } ( h )$ follows the same difference equation with $c = 1$ . Hence, if we have an AR(1) process as above,

$$
\rho_ {X} (h) = \phi^ {- h}.
$$

For the causal AR(2) process, we have $X _ { t } = \phi _ { 1 } X _ { t - 1 } + \phi _ { 2 } X _ { t - 2 } + w _ { t }$ . Proceeding as before, we note that

$$
\mathrm {E} \left(X _ {t} X _ {t - h}\right) = \mathrm {E} \left(\phi_ {1} X _ {t - 1} X _ {t - h}\right) + \mathrm {E} \left(\phi_ {2} X _ {t - 2} X _ {t - h}\right) + \mathrm {E} \left(w _ {t} X _ {t - h}\right)
$$

$$
K _ {X} (h) = \phi_ {1} K _ {X} (h - 1) + \phi_ {2} K _ {X} (h - 2).
$$

The roots of the characteristic polynomial will tell us about the behaviour of the process $X _ { t }$ . For $1 - \phi _ { 1 } z - \phi _ { 2 } z ^ { 2 }$ , we denote the two roots as $z _ { 1 }$ and $z _ { 2 }$ . Recall that $| z _ { i } | > 1$ as we assume $X _ { t }$ is causal. There are three possible settings to consider5

1. if $z _ { 1 } \neq z _ { 2 }$ and the roots are real, then we have the solution to the second order difference equation

$$
\rho (h) = c _ {1} z _ {1} ^ {- h} + c _ {2} z _ {2} ^ {- h}
$$

where $c _ { 1 }$ and $c _ { 2 }$ are two constants such that $c _ { 1 } + c _ { 2 } = 1$ .

2. if $z _ { 1 } = z _ { 2 }$ and necessarily real, then we have $\rho ( h ) = z _ { 1 } ^ { - h } ( c _ { 1 } + c _ { 2 } h )$ .

3. if $z _ { 1 } = \bar { z } _ { 2 }$ are complex conjugate roots, then

$$
\begin{array}{l} \rho (h) = c _ {1} z _ {1} ^ {- h} + \bar {c} _ {1} \bar {z} _ {1} ^ {- h} \\ = | c _ {1} | | z _ {1} | ^ {- h} \left(\mathrm {e} ^ {- i b} \mathrm {e} ^ {- i \theta h} + \mathrm {e} ^ {i b} \mathrm {e} ^ {i \theta h}\right) \\ = 2 \left| c _ {1} \right| \left| z _ {1} \right| ^ {- h} \cos (\theta h + b) \\ \end{array}
$$

In all three cases, we have the autocorrelation $\rho ( h )$ decaying exponentially to zero. The rate of decay depends on the magnitude of the roots. Furthermore, if the roots are complex, then there is periodic behaviour in the process.

This can be extended to the AR(p) process where we have a $p$ th order difference equation for $\rho$ . The resulting solution will look like

$$
\rho (h) = z _ {1} ^ {- h} f _ {1} (h) + \ldots + z _ {r} ^ {- h} f _ {r} (h)
$$

where $z _ { 1 } , \dots , z _ { r }$ are the unique roots with multiplicities $m _ { 1 } , \ldots , m _ { r }$ with $\begin{array} { r } { \sum _ { i = 1 } ^ { r } m _ { i } = } \end{array}$ $p$ and where $f _ { i } ( h )$ is a polynomial in $h$ of degree $m _ { i }$ .

# 2.5.2 ACF for MA(q)

The exposition of the autocorrelation for the general MA(q) process is much simpler relative to the previous discussion of the AR(p) process. Let $\begin{array} { r } { X _ { t } = \sum _ { j = 0 } ^ { q } \theta _ { j } w _ { j } } \end{array}$ with $\theta _ { 0 } = 1$ , then

$$
K _ {X} (h) = \sum_ {j = 0} ^ {q - h} \theta_ {j} \theta_ {j + h}
$$

for $h = 0 , \ldots , q$ and with $K _ { X } ( h ) = 0$ otherwise. Noting the variance is $K _ { X } ( 0 ) =$ $1 + \theta _ { 1 } ^ { 2 } + \ldots + \theta _ { q } ^ { 2 }$ , we have an autocorrelation of

$$
\rho_ {X} (h) = \frac {\sum_ {j = 0} ^ {q - h} \theta_ {j} \theta_ {j + h}}{\sum_ {j = 0} ^ {q} \theta_ {j} ^ {2}} \quad \text {f o r} h \leq q.
$$

Thus, unlike the AR process, the autocorrelation for the MA(q) process is zero for $h > q$ . Thus, it can be used to identify the order of the process.

# 2.5.3 PACF for AR(p)

To introduce why the partial correlation is of interest, we first consider the causal AR(1) process $X _ { t } = \phi X _ { t - 1 } + w _ { t }$ . From before, we saw that

$$
\begin{array}{l} \operatorname {c o r r} \left(X _ {t}, X _ {t - 2}\right) = \operatorname {c o r r} \left(\phi X _ {t - 1} + w _ {t}, X _ {t - 2}\right) \\ = \operatorname {c o r r} \left(\phi^ {2} X _ {t - 2} + \phi w _ {t - 1} + w _ {t}, X _ {t - 2}\right) \\ = \operatorname {c o r r} \left(\phi^ {2} X _ {t - 2}, X _ {t - 2}\right) + \operatorname {c o r r} \left(\phi w _ {t - 1}, X _ {t - 2}\right) + \operatorname {c o r r} \left(w _ {t}, X _ {t - 2}\right) \\ = \phi^ {2} + 0 + 0. \\ \end{array}
$$

In contrast, if we consider

$$
\operatorname {c o r r} \left(X _ {t} - \phi X _ {t - 1}, X _ {t - 2} - \phi X _ {t - 1}\right) = \operatorname {c o r r} \left(w _ {t}, X _ {t - 2} - \phi X _ {t - 1}\right) = 0.
$$

Hence when taking $X _ { t - 1 }$ into account, the autocorrelation between $X _ { t }$ and $X _ { t - 2 }$ is zero.

To properly consider the partial autocorrelation, we need to compute the least squares estimator $\hat { X } _ { t }$ for $X _ { t }$ based on previous time points. For example, to compute $\varphi ( 2 )$ , we take $\hat { X } _ { t } = \hat { \beta } X _ { t - 1 }$ where $\hat { \beta }$ is chosen to minimize

$$
\begin{array}{l} \mathrm {E} \left(X _ {t} - \hat {X} _ {t}\right) ^ {2} = \mathrm {E} \left(X _ {t} - \beta X _ {t - 1}\right) ^ {2} \\ = \operatorname {E} \left(X _ {t} ^ {2}\right) - 2 \beta \operatorname {E} \left(X _ {t} X _ {t - 1}\right) + \beta^ {2} \operatorname {E} \left(X _ {t - 1} ^ {2}\right) = (1 + \beta^ {2}) K _ {X} (0) - 2 \beta K _ {X} (1). \\ \end{array}
$$

By taking the derivative with respect to $\beta$ , we can find the critical point $\hat { \beta } \ =$ $K _ { X } ( 1 ) / K _ { X } ( 0 )$ . Similarly, for $\hat { X } _ { t - 2 } = \hat { \beta } X _ { t - 1 }$ , we have

$$
\begin{array}{l} \mathrm {E} \left(X _ {t - 2} - \beta X _ {t - 1}\right) ^ {2} \\ = \mathrm {E} \left(X _ {t - 2} ^ {2}\right) - 2 \beta \mathrm {E} \left(X _ {t - 2} X _ {t - 1}\right) + \beta^ {2} \mathrm {E} \left(X _ {t - 1} ^ {2}\right) = (1 + \beta^ {2}) K _ {X} (0) - 2 \beta K _ {X} (1) \\ \end{array}
$$

as before. In the case of the AR(1) model, we have ${ \hat { \beta } } = \phi$ . Thus, we have from before that $\varphi ( 1 ) = \phi$ and $\varphi ( 2 ) = 0$ and, in fact, $\varphi ( h ) = 0$ for $h \geq 2$ .

For the general AR(p) process, $\begin{array} { r } { X _ { t } = w _ { t } + \sum _ { i = 1 } ^ { p } \phi _ { i } X _ { t - i } } \end{array}$ , we have a similar set up. For lags $h > p$ , if we assume for now that the least squares estimator is

$$
\hat {X} _ {t} = \phi_ {1} X _ {t - 1} + \ldots + \phi_ {p} X _ {t - p},
$$

then we get a similar calculation as above. Namely that

$$
\operatorname {c o r r} (X _ {t} - \hat {X} _ {t}, X _ {t - h} - \hat {X} _ {t - h}) = \operatorname {c o r r} (w _ {t}, X _ {t - h} - \hat {X} _ {t - h}) = 0.
$$

In the case that the lag is less than or equal to $p$ , we need to determine how the estimate the coefficients $\beta _ { i }$ before computing the PACF.

# 2.5.4 PACF for MA(1)

For the invertible MA(1) model $X _ { t } = w _ { t } + \theta w _ { t - 1 }$ , which is with $| \theta | < 1$ , we can write it as a convergent infinite series

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {\infty} \theta^ {i} X _ {t - i}
$$

in terms of the $X _ { t - i }$ . Then, applying similar tricks as above gives a least squares estimator for $\hat { X } _ { t } ~ = ~ \hat { \beta } X _ { t - 1 }$ to be $\hat { \beta } = K _ { X } ( 1 ) / K _ { X } ( 0 )$ . In the case of the MA(1) process, we have $\hat { \beta } = \theta / ( 1 + \theta ^ { 2 } )$ . Hence,

$$
\begin{array}{l} \operatorname {c o v} \left(X _ {t} - \frac {\theta X _ {t - 1}}{1 + \theta^ {2}}, X _ {t - 2} - \frac {\theta X _ {t - 1}}{1 + \theta^ {2}}\right) \\ = K _ {X} (2) - \frac {2 \theta}{1 + \theta^ {2}} K _ {X} (1) + \left(\frac {\theta}{1 + \theta^ {2}}\right) ^ {2} K _ {X} (0) = \frac {- \theta^ {2}}{1 + \theta^ {2}}. \\ \end{array}
$$

Also, the variance is

$$
\begin{array}{l} \operatorname {V a r} \left(X _ {t} - \frac {\theta X _ {t - 1}}{1 + \theta^ {2}}\right) = K _ {X} (0) \left(1 + \left(\frac {\theta}{1 + \theta^ {2}}\right) ^ {2}\right) - \frac {2 \theta}{1 + \theta^ {2}} K _ {X} (1) \\ = 1 + \theta^ {2} + \frac {\theta^ {2}}{1 + \theta^ {2}} - \frac {2 \theta^ {2}}{1 + \theta^ {2}} = \frac {1 + \theta^ {2} + \theta^ {4}}{1 + \theta^ {2}}. \\ \end{array}
$$

Thus, the partial autocorrelation at lag 1 is $\varphi ( 1 ) = - \theta ^ { 2 } / ( 1 + \theta ^ { 2 } + \theta ^ { 4 } )$ . This can be extended to lags greater than one to show that the partial autocorrelation for the MA(1) process decreases but does not vanish as the lag increases.

Hence, we have the following table:

<table><tr><td></td><td>AR(p)</td><td>MA(q)</td></tr><tr><td>ACF</td><td>decreases geometrically</td><td>= zero for lags &gt; q</td></tr><tr><td>PACF</td><td>= zero for lags &gt; p</td><td>decreases geometrically</td></tr></table>

This means that we can use the ACF and PACF to try to understand the behaviour of a time series process.

# Chapter 3

# Estimation and Forecasting

# Introduction

Thus far, we have considered many types of time series models, but have performed little in the way of actual statistics. In this chapter, we consider to main goals of time series models: estimating parameters and forecasting/predicting. For the first topic, we will consider different methods for estimating parameters as well as model selection methods to determine the best fit to the data. For the second part, we consider the task of prediction in time series.

For a time series observed at $X _ { 1 } , \ldots , X _ { T }$ , we may want to fit a causal invertible ARMA(p,q) process,

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i} + \sum_ {j = 1} ^ {q} \theta_ {j} w _ {t - j},
$$

to the data by estimating the coefficients $\hat { \phi } _ { i }$ and ${ \hat { \theta } } _ { j }$ .

# 3.1 The AR process

# 3.1.1 Estimation for AR processes

There are two approaches to estimating the parameters of the AR(p) process that we will consider: Using (1) the Yule-Walker equations or (2) the maximum likelihood estimator. More methods are available in the R function ar().

# The Yule-Walker Estimator

We first consider the causal AR(p) process and the autocovariance function. We first assume that the mean $\mathrm { E } X _ { t } = 0$ . In practise, we can estimate the mean by

$\begin{array} { r } { \bar { X } = T ^ { - 1 } \sum _ { t = 1 } ^ { T } X _ { t } } \end{array}$ and then consider the centred time series $X _ { i } - X$ . For estimating the variance for the white noise process $\sigma ^ { 2 }$ ,

$$
\begin{array}{l} X _ {t} = w _ {t} + \phi_ {1} X _ {t - 1} + \ldots + \phi_ {p} X _ {t - p} \\ K _ {X} (0) = \operatorname {c o v} \left(X _ {t}, X _ {t}\right) = \operatorname {c o v} \left(X _ {t}, w _ {t} + \phi_ {1} X _ {t - 1} + \ldots + \phi_ {p} X _ {t - p}\right) \\ = \sigma^ {2} + \phi_ {1} K _ {X} (1) + \dots + \phi_ {p} K _ {X} (p) \\ \sigma^ {2} = K _ {X} (0) - \phi_ {1} K _ {X} (1) - \dots - \phi_ {p} K _ {X} (p). \\ \end{array}
$$

Hence, we can use the estimates for the autocovariance to estimate $\sigma ^ { 2 }$ .

$$
\hat {\sigma} ^ {2} = \hat {K} _ {X} (0) - \phi_ {1} \hat {K} _ {X} (1) - \ldots - \hat {\phi} _ {p} K _ {X} (p).
$$

However, we need estimators for the parameters $\phi _ { i }$ . To estimate these $\phi _ { i }$ , we can consider more equations based on the autocovariance at lags 1 through p.

$$
K _ {X} (1) = \operatorname {c o v} \left(X _ {t - 1}, X _ {t}\right) = \phi_ {1} K _ {X} (0) + \phi_ {2} K _ {X} (1) + \dots + \phi_ {p} K _ {X} (p - 1)
$$

$$
K _ {X} (2) = \operatorname {c o v} \left(X _ {t - 2}, X _ {t}\right) = \phi_ {1} K _ {X} (1) + \phi_ {2} K _ {X} (0) + \dots + \phi_ {p} K _ {X} (p - 2)
$$

$$
K _ {X} (p) = \operatorname {c o v} \left(X _ {t - p}, X _ {t}\right) = \phi_ {1} K _ {X} (p - 1) + \phi_ {2} K _ {X} (p - 2) + \dots + \phi_ {p} K _ {X} (0)
$$

Here, we have $p$ linear equations with $p$ unknowns, which can be written as $K = \Gamma \phi$ where

$$
K = \left( \begin{array}{c} K _ {X} (1) \\ \vdots \\ K _ {X} (p) \end{array} \right), \phi = \left( \begin{array}{c} \phi_ {1} \\ \vdots \\ \phi_ {p} \end{array} \right), \Gamma = \left( \begin{array}{c c c c} K _ {X} (0) & K _ {X} (1) & \dots & K _ {X} (p - 1) \\ K _ {X} (1) & K _ {X} (0) & \dots & K _ {X} (p - 2) \\ \vdots & \ddots & \ddots & \vdots \\ K _ {X} (p - 1) & K _ {X} (p - 2) & \dots & K _ {X} (0) \end{array} \right).
$$

We can also write $\sigma ^ { 2 } = K _ { X } ( 0 ) - \phi ^ { \mathrm { T } } K$ . This system of $p + 1$ equations is known as the Yule-Walker Equations. We can solve for the coefficients $\phi = \Gamma ^ { - 1 } K$ as the matrix $\Gamma$ is positive definite. As a result, $\sigma ^ { 2 } = K _ { X } ( 0 ) - K ^ { \mathrm { T } } \Gamma ^ { - 1 } K$ , because $\Gamma$ is symmetric.

We can use the estimator for the autocovariance from Chapter 1 to get a data driven estimate for the parameters for this time series:

$$
\hat {\phi} = \hat {\Gamma} ^ {- 1} \hat {K}, \quad \mathrm {a n d} \quad \hat {\sigma} ^ {2} = \hat {K} _ {X} (0) - \hat {K} ^ {\mathrm {T}} \hat {\Gamma} ^ {- 1} K.
$$

These estimators can be shown to converge in distribution to a multivariate normal distribution.

Theorem 3.1.1 (Asymptotic Normality for Yule-Walker). Given $\hat { \phi } _ { i }$ and $\hat { \sigma } ^ { 2 }$ as above for a causal AR(p) process, we have as $T \to \infty$ ,

$$
\sqrt {T} (\hat {\phi} - \phi) \stackrel {d} {\to} \mathcal {N} (0, \sigma^ {2} \Gamma^ {- 1}) a n d \hat {\sigma} ^ {2} \stackrel {P} {\to} \sigma^ {2}.
$$

Corollary 3.1.1 (Asymptotic Normality for PACF). For the causal AR(p) process, as $T \to \infty$ ,

$$
\sqrt {T} \hat {\varphi} (h) \stackrel {d} {\to} \mathcal {N} (0, 1).
$$

for lags $h > p$ .

In the standard stats package in R, the function ar() fits an autoregressive model to time series data, which can implement many ways to estimate the parameters, but defaults to the Yule-Walker equations. To demonstrate it, we can use the arima.sim() function to simulate $T = 1 0 0$ data points from the AR(1) process

$$
X _ {t} = 0. 7 X _ {t - 1} + w _ {t}.
$$

Using the Yule-Walker equations, we get $\hat { \phi } _ { 1 } = 0 . 7 3$ . Note that the ar() function fits models for AR(1) up to AR(20) and then chooses the best with respect to AIC. In the case of data from the AR(3) process

$$
X _ {t} = 0. 7 X _ {t - 1} - 0. 3 X _ {t - 3} + w _ {t}
$$

we get the fitted model

$$
X _ {t} = 0. 7 5 2 X _ {t - 1} - 0. 0 0 2 X _ {t - 2} - 0. 2 8 5 X _ {t - 3}.
$$

Plots of these two processes with the estimated ACF and PACF are displayed in Figure 3.1.

# Maximum Likelihood Estimation

Given that $w _ { t }$ is Gaussian white noise, we can write down the likelihood and solve the maximum likelihood estimator. There is actually more than one MLE approach in time series. Also, this can be made more tractible by using conditional probability.

Begining with the causal AR(1) process $X _ { t } = \mu + \phi ( X _ { t - 1 } - \mu ) + w _ { t }$ with some mean $\mu \in \mathbb { R }$ , we use the recursive definition of the process to write the likelihood as

$$
\begin{array}{l} L (\mu , \phi , \sigma^ {2}; X _ {1}, \dots , X _ {T}) = f (X _ {1}, \dots , X _ {T}; \mu , \phi , \sigma^ {2}) \\ = f (X _ {1}) f (X _ {2} | X _ {1}) \dots f (X _ {T} | X _ {T - 1}). \\ \end{array}
$$

Assuming the white noise is Gaussian, the term $X _ { 1 } \sim \mathcal { N } \left( \mu , \sigma ^ { 2 } / ( 1 - \phi ^ { 2 } ) \right)$ as we have solved before.1 Meanwhile, recalling that normality is preserved under conditioning, the conditional distribution of $X _ { t } | X _ { t - 1 }$ is $\mathcal { N } \left( \mu + \phi ( X _ { t - 1 } - \mu ) , \sigma ^ { 2 } \right)$ . Hence, putting it all together gives

$$
\begin{array}{l} L (\mu , \phi , \sigma^ {2}) = \frac {(1 - \phi^ {2}) ^ {1 / 2}}{(2 \pi \sigma^ {2}) ^ {T / 2}} \\ \times \exp \left[ - \frac {1}{2 \sigma^ {2}} \left\{\left(X _ {1} - \mu\right) ^ {2} \left(1 - \phi^ {2}\right) + \sum_ {t = 2} ^ {T} \left(\left(X _ {t} - \mu\right) - \phi \left(X _ {t - 1} - \mu\right)\right) ^ {2} \right\} \right] \\ \end{array}
$$

![](images/f769045a3e7055698297e3d70258fbd01209adc297859e215b70670831cb0a9d.jpg)  
AR(1) Process

![](images/90ea036a8b132c949fa06e58e4742added220b206dea4fe03691144310936427.jpg)  
AR(3) Process

![](images/8f784dad74a8b3edb0754710150df755ef0c9ae235faa54992837eee03199306.jpg)  
ACF for AR(1)

![](images/af8bb585113894a9f54101f9a352ac41aaaed034b6d5058b7bd274b63ab2283b.jpg)  
ACF for AR(3)

![](images/3cc981de3ee3ec478ec1f10cc7d2acd702509fb104f3f09564d1c5fbf631059c.jpg)  
PACF for AR(1)

![](images/4f655dbee8ab2ad686d3520221d68569737a06f2bda6e34de3bee173ea86379c.jpg)  
PACF for AR(3)   
Figure 3.1: Simulated AR(1) and AR(3) processes with estimated ACF and PACF.

Writing the unconditional sum of squares in the exponent as

$$
S _ {u} (\mu , \phi) = (X _ {1} - \mu) ^ {2} (1 - \phi^ {2}) + \sum_ {t = 2} ^ {T} ((X _ {t} - \mu) - \phi (X _ {t - 1} - \mu)) ^ {2}
$$

we can take derivatives of the log likelihood to solve for the MLEs. For the variance,

$$
\begin{array}{l} \frac {\partial \log (L)}{\partial \sigma^ {2}} = \\ = \frac {\partial}{\partial \sigma^ {2}} \left\{\frac {1}{2} \log (1 - \phi^ {2}) - \frac {T}{2} \log (2 \pi) - \frac {T}{2} \log (\sigma^ {2}) - \frac {S _ {u} (\mu , \phi)}{2 \sigma^ {2}} \right\} \\ = - \frac {n}{2 \sigma^ {2}} + \frac {S _ {u} (\mu , \phi)}{2 \sigma^ {4}}, \\ \end{array}
$$

which gives $\hat { \sigma } ^ { 2 } = S _ { u } ( \mu , \phi ) / T$ . However, solving for MLEs $\hat { \mu }$ and $\hat { \phi }$ are not as straight forward, because we would have to solve the nonlinear system of equations

$$
0 = - 2 (1 - \phi^ {2}) (X _ {1} - \mu) + 2 (1 - \phi) \sum_ {t = 2} ^ {T} (X _ {t} - \phi X _ {t - 1} - \mu (1 - \phi))
$$

$$
0 = \frac {- \phi}{1 - \phi^ {2}} - \frac {1}{2 \sigma^ {2}} \left\{2 \phi (X _ {1} - \mu) ^ {2} - 2 \sum_ {t = 2} ^ {T} (X _ {t} - \phi X _ {t - 1} - \mu (1 - \phi)) (X _ {t - 1} - \mu) \right\}.
$$

This headache arises due to the starting point $X _ { 1 }$ . If we condition the likelihood on $X _ { 1 }$ , we can simplify the problem.2

Conditioning on $X _ { 1 }$ , we have

$$
L (\mu , \phi , \sigma^ {2} | X _ {1}) = \frac {1}{(2 \pi \sigma^ {2}) ^ {(T - 1) / 2}} \exp \left[ \sum_ {t = 2} ^ {T} ((X _ {t} - \mu) - \phi (X _ {t - 1} - \mu)) ^ {2} \right].
$$

Thus, the MLE for the variance is $\hat { \sigma } ^ { 2 } = S _ { c } ( \mu , \phi ) / ( T - 1 )$ where similarly to above $S _ { c }$ is the conditional sum of squares in the exponent. We can rewrite $S _ { c }$ as

$$
S _ {c} (\mu , \phi) = \sum_ {t = 2} ^ {T} (X _ {t} - (\alpha + \phi X _ {t - 1})) ^ {2}
$$

where $\alpha = \mu ( 1 + \phi )$ , which coincides with simple linear regression. Hence, for the design matrix $X \in \mathbb { R } ^ { ( T - 1 ) \times 2 }$ with columns 1 and $X _ { t }$ for $t = 1 , \ldots , T ^ { \prime } - 1$ , the least squares estimator is

$$
\left( \begin{array}{c} \hat {\alpha} \\ \hat {\phi} \end{array} \right) = (X ^ {\mathrm {T}} X) ^ {- 1} X ^ {\mathrm {T}} (X _ {2}, \ldots , X _ {T}) ^ {\mathrm {T}},
$$

which after some computation can be reduced to

$$
\hat {\phi} = \frac {\sum_ {t = 2} ^ {T} (X _ {t} - \bar {X} _ {(2)}) (X _ {t - 1} - \bar {X} _ {(1)})}{\sum_ {t = 2} ^ {T} (X _ {t - 1} - \bar {X} _ {(1)}) ^ {2}}
$$

where $\begin{array} { r } { \bar { X } _ { ( 1 ) } = ( T - 1 ) ^ { - 1 } \sum _ { t = 1 } ^ { T - 1 } X _ { t } } \end{array}$ and $\begin{array} { r } { \bar { X } _ { ( 2 ) } = ( T - 1 ) ^ { - 1 } \sum _ { t = 2 } ^ { T } X _ { t } } \end{array}$ .3 Given $\hat { \phi }$ , we can determine $\hat { \alpha } = \bar { X } _ { ( 2 ) } - \hat { \phi } \bar { X } _ { ( 1 ) }$ and finally

$$
\hat {\mu} = \frac {\bar {X} _ {(2)} - \hat {\phi} \bar {X} _ {(1)}}{1 - \hat {\phi}}.
$$

To compare these estimators to the Yule-Walker estimator, we note that for the AR(1) process that

$$
\hat {\phi} ^ {\mathrm {Y W}} = \frac {\hat {K} _ {X} (1)}{\hat {K} _ {X} (0)} = \frac {\sum_ {t = 2} ^ {T} (X _ {t} - \bar {X}) (X _ {t - 1} - \bar {X})}{\sum_ {t = 1} ^ {T} (X _ {t} - \bar {X}) ^ {2}},
$$

which is very similar to the MLE estimator except that the MLE uses $X _ { ( 1 ) }$ and $X _ { ( 2 ) }$ that are adjusted for the end points of the time series. In the limit, the two are equivalent.

Similarly, for the mean, the Yule-Walker equations chooses $\hat { \mu } ^ { \mathrm { Y W } } = X$ . In contrast, for the MLE, we have

$$
\frac {\bar {X} _ {(2)} - \hat {\phi} \bar {X} _ {(1)}}{1 - \hat {\phi}} \approx \frac {\bar {X} - \hat {\phi} \bar {X}}{1 - \hat {\phi}} = \bar {X}.
$$

For AR(p) processes, the MLE estimators can still be computed in a similar manor, but the equations are more complex. Still, conditioning on the starting values $X _ { 1 } , \ldots , X _ { p }$ allows for a reduction to linear regression.

# Proof of Asymptotic Normality for Yule-Walker

# 3.1.2 Forecasting for AR processes

Another significant problem in time series analysis is that of forecasting. That is, given data $X _ { 1 } , \ldots , X _ { T }$ , we want to compute the best predictions for subsequent time points $X _ { T + 1 } , X _ { T + 2 } , \dots , X _ { T + m }$ . We won’t initially assume that the process is autoregressive, but we will assume that $X _ { t }$ is stationary.

First, we can consider linear predictors, which are those of the form

$$
\hat {X} _ {T + m} = \alpha_ {0} + \sum_ {t = 1} ^ {T} \alpha_ {t} X _ {t}
$$

where we want to make a good choice of parameters $\alpha _ { t }$ . To do that, we minimize the squared error as usual:

$$
\underset {\alpha_ {1}, \ldots , \alpha_ {T}} {\arg \min} \mathrm {E} \left\{\left(X _ {T + m} - \alpha_ {0} - \sum_ {t = 1} ^ {T} \alpha_ {t} X _ {t}\right) ^ {2} \right\}.
$$

Taking the derivative with respect to each $\alpha _ { t }$ gives a system of equations

$$
0 = \operatorname {E} \left(X _ {T + m} - \hat {X} _ {T + m}\right)
$$

$$
0 = \operatorname {E} \left((X _ {T + m} - \hat {X} _ {T + m}) X _ {1}\right)
$$

$$
0 = \operatorname {E} \left(\left(X _ {T + m} - \hat {X} _ {T + m}\right) X _ {T}\right)
$$

Let the mean of the process be $\mu$ . By the first equation,

$$
\mu = \operatorname {E} \left(X _ {T + m}\right) = \operatorname {E} \left(\hat {X} _ {T + m}\right) = \operatorname {E} \left(\alpha_ {0} + \sum_ {t = 1} ^ {T} \alpha_ {t} X _ {t}\right) = \alpha_ {0} + \sum_ {t = 1} ^ {T} \alpha_ {t} \mu
$$

$$
\alpha_ {0} = \mu \left(1 - \sum_ {t = 1} ^ {T} \alpha_ {t}\right)
$$

Hence, we have $\begin{array} { r } { \hat { X } _ { t + m } = \mu + \sum _ { t = 1 } ^ { T } \alpha _ { t } ( X _ { t } - \mu ) } \end{array}$ . Thus, we can centre the process and consider time series with $\mu = 0$ and $\alpha _ { 0 } = 0$ .

For a one-step-ahead prediction, which is to estimate $\hat { X } _ { T + 1 }$ , we solve the above equations to get

$$
0 = \operatorname {E} \left((X _ {T + 1} - \hat {X} _ {T + 1}) X _ {1}\right) = K _ {X} (T) - \sum_ {t = 1} ^ {T} \alpha_ {t} K _ {X} (t - 1)
$$

$$
0 = \operatorname {E} \left((X _ {T + 1} - \hat {X} _ {T + 1}) X _ {2}\right) = K _ {X} (T - 1) - \sum_ {t = 1} ^ {T} \alpha_ {t} K _ {X} (t - 2)
$$

$$
0 = \operatorname {E} \left(\left(X _ {T + m} - \hat {X} _ {T + m}\right) X _ {T}\right) = K _ {X} (1) - \sum_ {t = 1} ^ {T} \alpha_ {t} K _ {X} (T - t)
$$

If similar to before we let $K$ be the $T$ -long vector with entries $K _ { X } ( T ) , \ldots , K _ { X } ( 1 )$ and let

$$
\Gamma = \left( \begin{array}{c c c c} K _ {X} (0) & K _ {X} (1) & \dots & K _ {X} (T - 1) \\ K _ {X} (1) & K _ {X} (0) & \dots & K _ {X} (T - 2) \\ \vdots & \ddots & \ddots & \vdots \\ K _ {X} (T - 1) & K _ {X} (T - 2) & \dots & K _ {X} (0) \end{array} \right).
$$

Then, the above equations can be written as $K = \Gamma \alpha$ or $\alpha = \Gamma ^ { - 1 } K$ in the case that the inverse exists. Thus, for $\boldsymbol { X } = ( X _ { 1 } , \ldots , X _ { T } ) ^ { \boldsymbol { \mathrm { { I } } } }$ , our one-step prediction can be written as

$$
\hat {X} _ {T + 1} = \alpha^ {\mathrm {T}} X = K ^ {\mathrm {T}} \Gamma^ {- 1} X.
$$

As like estimation for the AR process with the Yule-Walker equations, our prediction is based on the autocovariances. If we knew what the autocovariance is—i.e. we use $K$ and $\Gamma$ instead of $\hat { K }$ and $\hat { \Gamma }$ —then the mean squared prediction error is

$$
\begin{array}{l} \mathrm {E} \left(X _ {T + 1} - \hat {X} _ {T + 1}\right) ^ {2} = \mathrm {E} \left(X _ {T + 1} - K ^ {\mathrm {T}} \Gamma^ {- 1} X\right) ^ {2} \\ = \operatorname {E} \left(X _ {T + 1} ^ {2} - 2 K ^ {\mathrm {T}} \Gamma^ {- 1} X X _ {T + 1} + K ^ {\mathrm {T}} \Gamma^ {- 1} X X ^ {\mathrm {T}} \Gamma^ {- 1} K\right) \\ = K _ {X} (0) - 2 K ^ {\mathrm {T}} \Gamma^ {- 1} K + K ^ {\mathrm {T}} \Gamma^ {- 1} \Gamma \Gamma^ {- 1} K \\ = K _ {X} (0) - K ^ {\mathrm {T}} \Gamma^ {- 1} K. \\ \end{array}
$$

For the AR(p) process,

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {p} \phi_ {i} X _ {t - i},
$$

the one-step-ahead prediction comes precisely from estimating the coefficents as in the Yule-Walker equations to get

$$
\hat {X} _ {T + 1} = \sum_ {i = 1} ^ {p} \hat {\phi} _ {i} X _ {T + 1 - i}.
$$

However, if we do not know a priori that we have an order- $p$ process, then we would have to estimate $\alpha _ { i }$ for all $i = 1 , \dots , T$ , which could require the inversion of a very large matrix. Thus, for general ARMA models, we have to work harder.

# The Durbin-Levinson Algorithm

The system of equations $\alpha = \Gamma ^ { - 1 } K$ and computation of the mean squared prediction error for the one-step ahead estimate,

$$
P _ {T + 1} ^ {T} := \operatorname {E} \left(X _ {T + 1} - \hat {X} _ {T + 1}\right) ^ {2} = K _ {X} (0) - K ^ {\mathrm {T}} \Gamma^ {- 1} K,
$$

can be solved iteratively. This is because, $\Gamma$ is a Toeplitz Matrix, and the Durbin-Levinsion Algorithm can be used to solve a system of equations involving a Toeplitz

matrix. To do this, we need to consider a sequence of one-step-ahead predictors

$$
\begin{array}{l} \hat {X} _ {2} ^ {1} = \alpha_ {1, 1} X _ {1} \\ \hat {X} _ {3} ^ {2} = \alpha_ {2, 1} X _ {1} + \alpha_ {2, 2} X _ {2} \\ \tilde {X} _ {4} ^ {3} = \alpha_ {3, 1} X _ {1} + \alpha_ {3, 2} X _ {2} + \alpha_ {3, 3} X _ {3} \\ \end{array}
$$

$$
\hat {X} _ {T + 1} ^ {T} = \alpha_ {T, 1} X _ {1} + \alpha_ {T, 2} X _ {2} + \dots \alpha_ {T, T} X _ {T}.
$$

We begin recursively with $\alpha _ { 0 , 0 } = 0$ and $P _ { 0 } ^ { 1 } = K _ { X } ( 0 )$ , which is that the MSPE given no information is just the variance. Then, given coefficients $\alpha _ { t , 1 } , \ldots , \alpha _ { t , t }$ , we can compute

$$
\alpha_ {t + 1, 1} = \frac {\rho_ {X} (t) - \sum_ {i = 1} ^ {t - 1} \alpha_ {t - 1 , i} \rho_ {X} (i)}{1 - \sum_ {i = 1} ^ {t - 1} \alpha_ {t - 1 , i} \rho_ {X} (t - i)}
$$

and $P _ { t + 1 } ^ { t } = P _ { t } ^ { t - 1 } ( 1 - \alpha _ { t + 1 , 1 } ^ { 2 } )$ and for the remaining coefficients $\alpha _ { t + 1 , i } = \alpha _ { t , t - i - 1 } -$ $\alpha _ { t + 1 , 1 } \alpha _ { t , i }$

# The Innovations Algorithm

The innovations for a time series are the residuals for the one-step-ahead estimate, $X _ { t } - \hat { X } _ { t } ^ { t - 1 }$ . First, note that novations algorith $X _ { t } - \hat { X } _ { t } ^ { t - 1 }$ and ulatin $X _ { s } - { \hat { X } } _ { s } ^ { s - 1 }$ are uncorrelated for tep-ahead prediction $s \neq t$ $\hat { X } _ { T + 1 } ^ { T }$ is as follows.

First initialize $X _ { 1 } ^ { 0 } = 0$ and $P _ { 1 } ^ { 0 } = K _ { X } ( 0 )$ . Then, given the past observations $X _ { t } , \ldots , X _ { 1 }$ and past one-step predictions $X _ { t } ^ { t - 1 } , \ldots , X _ { 1 } ^ { 0 }$ , we compute

$$
X _ {t + 1} ^ {t} = \sum_ {j = 1} ^ {t} \theta_ {t, j} (X _ {t + 1 - j} - X _ {t + 1 - j} ^ {t - j})
$$

$$
P _ {t + 1} ^ {t} = K _ {X} (0) - \sum_ {j = 0} ^ {t - 1} \theta_ {t, t - j} ^ {2} P _ {j + 1} ^ {j}
$$

where

$$
\theta_ {t, t - j} = \left(K _ {X} (t - j) - \sum_ {k = 0} ^ {j - 1} \theta_ {j, j - k} \theta_ {t, t - k} P _ {k + 1} ^ {k}\right) (P _ {j + 1} ^ {j}) ^ {- 1}
$$

The innovations algorithm is useful for computing predictions for ARMA(p,q) processes specifically for the MA part. To see this, we consider a simple example: the MA(1) process.

Let $X _ { t } ~ = ~ \theta w _ { t - 1 } + w _ { t }$ . Then, we know that the autocovariance is $K _ { X } ( 0 ) =$ $\sigma ^ { 2 } ( 1 + \theta ^ { 2 } )$ , $K _ { X } ( 1 ) = \sigma ^ { 2 } \theta$ , and $K _ { X } ( h ) = 0$ for $h \geq 2$ . Then, we have that $\theta _ { 0 , 0 } = 1$

and

$$
\theta_ {1, 1} = \left[ K _ {X} (1) - 0 \right] / \left[ K _ {X} (0) - 0 \right] = \theta / \left(1 + \theta^ {2}\right) = \sigma^ {2} \theta / P _ {1} ^ {0}
$$

$$
\theta_ {2, 2} = \left[ K _ {X} (2) - 0 \right] / \left[ K _ {X} (0) - 0 \right] = 0
$$

$$
\theta_ {2, 1} = \left[ K _ {X} (1) - \theta_ {1, 1} \theta_ {2, 2} P _ {1} ^ {0} \right] / \left[ P _ {2} ^ {1} \right] = \left[ \sigma^ {2} \theta - 0 \right] / \left[ P _ {2} ^ {1} \right]
$$

$$
\theta_ {t, j} = 0, \quad \text {f o r} j > 1
$$

$$
\theta_ {t, 1} = \left[ K _ {X} (1) - 0 \right] / \left[ P _ {t} ^ {t - 1} \right] = \sigma^ {2} \theta / \left[ P _ {t} ^ {t - 1} \right]
$$

We can also update the MSPEs as $P _ { t + 1 } ^ { t } = ( 1 + \theta ^ { 2 } - \theta \theta _ { t , 1 } ) \sigma ^ { 2 }$ . Therefore, the onestep-ahead prediction is

$$
X _ {t + 1} ^ {t} = \theta_ {t, 1} (X _ {t} - X _ {t} ^ {t - 1}) = \theta (X _ {t} - X _ {t} ^ {t - 1}) \sigma^ {2} / P _ {t} ^ {t - 1}
$$

# 3.2 The ARMA Process

# 3.2.1 Estimation for ARMA processes

For an ARMA(p,q) process, we have parameters $\mu , \sigma ^ { 2 } , \phi _ { 1 } , \ldots , \phi _ { p } , \theta _ { 1 } , \ldots \theta _ { q }$ to estimate. To estimate terms for an ARMA process, we revisit the maximum likelihood approach from above for the AR process. Note first that to do this, we assume that the white noise is Gaussian so that we have a distribution for the likelihood equation. Similar to before, we need to carefully rewrite the likelihood to make it tractible. This time, we consider conditioning the tth time point on the previous $t - 1$ time points. That is,

$$
L (\mu , \sigma^ {2}, \phi , \theta) = \prod_ {t = 1} ^ {T} f (X _ {t} \mid X _ {t - 1}, \dots , X _ {1}),
$$

which means that we will consider each $X _ { t }$ predicted by the previous observations $X _ { t - 1 } , \ldots , X _ { 1 }$ .

As we assume we have a causal invertiable ARMA(p.q) process, we can write it as a linear process in the form

$$
X _ {t} = \sum_ {i = 0} ^ {\infty} \psi_ {i} w _ {t - i}
$$

where the infinite past will be convenient to assume even if the data is finite. The distribution of $X _ { t } | X _ { t - 1 } \ldots X _ { 1 }$ will be normal with mean $\hat { X } _ { t } ^ { t - 1 }$ , the one-step-ahead prediction. The variance with by $\mathrm { E } \left( ( X _ { t } - \hat { X } _ { t } ^ { t - 1 } ) ^ { 2 } \right)$ , which is also the mean squared

prediction error $P _ { t } ^ { t - 1 }$ . In the case of $t = 1$ , we just use the variance for the linear process

$$
K _ {X} (0) = \sigma^ {2} \sum_ {i = 1} ^ {\infty} \psi_ {i} ^ {2}.
$$

From there, we can use the Durbin-Levinson Algorithm to update the MSPE by $P _ { t + 1 } ^ { t } = P _ { t } ^ { t - 1 } ( 1 - \alpha _ { t + 1 , 1 } ^ { 2 } )$ . The precise computation is not important for our purposes, but we can write $P _ { t } ^ { t - 1 } = \sigma ^ { 2 } r _ { t }$ where $r _ { t }$ does not depend on $\sigma ^ { 2 }$ . This allows us to write the likelihood as

$$
L (\mu , \sigma^ {2}, \phi , \theta) = (2 \pi \sigma^ {2}) ^ {- T / 2} \left[ \prod_ {t = 1} ^ {T} r _ {t} \right] ^ {- 1 / 2} \exp \left(- \frac {S (\mu , \phi , \theta)}{2 \sigma^ {2}}\right)
$$

with the sum of squares $\begin{array} { r } { S ( \mu , \phi , \theta ) = \sum _ { t = 1 } ^ { T } ( X _ { t } - \hat { X } _ { t } ^ { t - 1 } ) ^ { 2 } / r _ { t } } \end{array}$

From all of this, we can get the MLE for the variance $\hat { \sigma } ^ { 2 } = S ( \hat { \mu } , \hat { \phi } , \hat { \theta } ) / n$ as a function of the other estimators. To find those estimators, we can maximize the concentrated likelihood, which is when we replace $\hat { \sigma } ^ { 2 }$ with $S ( \hat { \mu } , \hat { \phi } , \hat { \theta } ) / n$ and solve for the MLEs for $\hat { \mu } , \hat { \phi } , \hat { \theta }$ . That is, for some constant $C$ ,

$$
\log L (\mu , \phi , \theta) = C - \frac {T}{2} \log \hat {\sigma} ^ {2} - \frac {1}{2} \sum_ {t = 1} ^ {T} \log r _ {t}, \quad \text {o r}
$$

$$
\ell (\mu , \phi , \theta) = \log \left(\frac {S (\mu , \phi , \theta)}{T}\right) + \frac {1}{T} \sum_ {t = 1} ^ {T} \log r _ {t}.
$$

We could check that for AR(p) processes—that is, without any MA part—that we recover the MLE estimates from before.

# Asymptotic Distribution

Similar to the Yule-Walker equations for the AR process, we have a central limit-like theorem for the MLE estimator for the ARMA process. If we let $\beta = ( \phi _ { 1 } , \dots , \phi _ { p } , \theta _ { 1 } , \dots , \theta _ { q } )$ then as $T \to \infty$

$$
\sqrt {T} (\hat {\beta} - \beta) \xrightarrow {\mathrm {d}} \mathcal {N} \left(0, \sigma^ {2} \Gamma_ {p, q} ^ {- 1}\right)
$$

where $\Gamma _ { p , q }$ is a $( p + q ) \times ( p + q )$ matrix with block form

$$
\Gamma_ {p, q} = \left( \begin{array}{c c} \Gamma_ {\phi \phi} & \Gamma_ {\phi \theta} \\ \Gamma_ {\theta \phi} & \Gamma_ {\theta \theta} \end{array} \right)
$$

where the $i , j$ th entry in $\Gamma _ { \phi \phi }$ is $K _ { Y } ( i - j )$ for the AR process $\Phi ( B ) Y _ { t } = w _ { t }$ , and the $i , j$ th entry in $\Gamma _ { \theta \theta }$ is $K _ { Y ^ { \prime } } ( i - j )$ for the AR process $\Theta ( B ) Y _ { t } ^ { \prime } = w _ { t }$ , and the $i , j$ th entry in $\Gamma _ { \phi \theta }$ is the cross covariance between $Y$ and $Y ^ { \prime }$ .

Example 3.2.1 (AR(1)). For the casual AR(1) process $X _ { t } = \phi X _ { t - 1 } + w _ { t }$ , we recall that $K _ { X } ( 0 ) = \sigma ^ { 2 } / ( 1 - \phi ^ { 2 } )$ . Therefore, $\Gamma _ { 1 , 0 } = ( 1 - \phi ^ { 2 } ) ^ { - 1 }$ and we have that

$$
\hat {\phi} \stackrel {d} {\to} \mathcal {N} \left(\phi , \frac {1}{T} (1 - \phi^ {2})\right).
$$

Example 3.2.2 (MA(1)). Similar to the $A R ( { \mathit { 1 } } )$ prcess, consider the invertible MA(1) process $X _ { t } = \theta w _ { t - 1 } + w _ { t }$ . The MA polynomial is $\Theta ( B ) = 1 + \theta B$ , so the $A R ( { \mathit { 1 } } )$ process $\Theta ( B ) Y _ { t } = w _ { t }$ has a variance of $K _ { Y } ( 0 ) = \sigma ^ { 2 } / ( 1 - \theta ^ { 2 } )$ . Thus, we have that

$$
\hat {\theta} \stackrel {d} {\to} \mathcal {N} \left(\theta , \frac {1}{T} (1 - \theta^ {2})\right).
$$

Note that similar to linear regression and many other areas of statistics, if we include too many terms when fitting an ARMA process to a dataset, the standard errors of the estimate will be larger than necessary. Thus, it is typically good to keep the number of parameters as small as possible. Hence, the use of AIC and BIC in the R function arima().

# 3.2.2 Forecasting for ARMA processes

We already discussed approaches to forecasting that can be applied to the ARMA(p,q) process. In this section, we take a closer look at forecasting for the ARMA process and the behaviour of these predicted values. As usual, we will assume that the ARMA(p,q) process written in operator form as

$$
\Phi (B) X _ {t} = \Theta (B) w _ {t}
$$

is both causal and invertible as well as mean zero.4 We will also assume that we are making a prediction based on observed data $X _ { 1 } , \ldots , X _ { T }$ .

Given a sample size $T$ , there are two possible estimators for the future point $X _ { T + h }$ to consider. The prediction that minimizes the mean squared error is

$$
\hat {X} _ {T + h} = \operatorname {E} \left(X _ {T + h} \mid X _ {T}, \dots , X _ {1}\right).
$$

However, it is often mathematically convenient to consider the estimator based on the infinite past, which is

$$
\tilde {X} _ {T + h} = \mathrm {E} \left(X _ {T + h} \mid X _ {T}, \dots , X _ {1}, X _ {0}, X _ {- 1}, \dots\right).
$$

As the data size $T$ gets large, these two predictions are very close.

As we assume that that ARMA process is both causal and invertible, we can rewrite it in two different forms:

$$
X _ {T + h} = w _ {T + h} + \sum_ {j = 1} ^ {\infty} \psi_ {j} w _ {T + h - j} \quad (\text {C a u s a l})
$$

$$
w _ {T + h} = X _ {T + h} + \sum_ {j = 1} ^ {\infty} \pi_ {j} X _ {T + h - j} \quad (\text {I n v e r t i b l e})
$$

and we can consider the above conditional expectations applied to each of these equations.

First, we note that

$$
\operatorname {E} \left(w _ {t} | X _ {T}, \ldots , X _ {0}, \ldots\right) = \left\{ \begin{array}{l l} w _ {t} & \text {i f} t \leq T \\ 0 & \text {i f} t > T \end{array} \right.
$$

This is because (1) if $t > T$ then $w _ { t }$ is independent of the sequence of $X _ { T } , \dots .$ and (2) if $t \leq T$ then based on the casual and invertible representations, we have a one to one correspondence between the $X$ ’s and the $w$ ’s. Similarly,

$$
\operatorname {E} \left(X _ {t} | X _ {T}, \ldots , X _ {0}, \ldots\right) = \left\{ \begin{array}{l l} X _ {t} & \text {i f} t \leq T \\ \tilde {X} _ {t} & \text {i f} t > T \end{array} \right.
$$

Applying this idea to the causal representation, we get that

$$
\tilde {X} _ {T + h} = \sum_ {j = h} ^ {\infty} \psi_ {j} w _ {T + h - j}
$$

as the first $h - 1$ terms in the sum become zero. Then, subtracting this from $X _ { t + h }$ gives

$$
X _ {T + h} - \tilde {X} _ {T + h} = \sum_ {j = 0} ^ {h - 1} \psi_ {j} w _ {T + h - j}.
$$

Hence, the mean squared prediction error is

$$
P _ {T + h} ^ {T} = \operatorname {E} \left((X _ {T + h} - \tilde {X} _ {T + h}) ^ {2}\right) = \sigma^ {2} \sum_ {j = 0} ^ {h - 1} \psi_ {j} ^ {2}.
$$

Note that we can also apply the conditional expectation to the invertible representation. In that case, we get

$$
0 = \tilde {X} _ {T + h} + \sum_ {j = 1} ^ {h - 1} \pi_ {i} \tilde {X} _ {T + h - j} + \sum_ {j = h} ^ {\infty} \pi_ {i} X _ {T + h - j}
$$

$$
\tilde {X} _ {T + h} = - \sum_ {j = 1} ^ {h - 1} \pi_ {i} \tilde {X} _ {T + h - j} - \sum_ {j = h} ^ {\infty} \pi_ {i} X _ {T + h - j}.
$$

This shows that the $T + h$ predicted value is a function of the data $X _ { T } , \dots .$ and the previous $h - 1$ predicted values $\ddot { X } _ { T + h - 1 } , \dotsc , \ddot { X } _ { T + 1 }$ .

# Long Range Forecast Behaviour

What happens if we try to predict far into the future? If we consider an ARMA(p,q) process with mean $\mu$ , then the h-step-ahead estimator based on the infinite past is

$$
\tilde {X} _ {T + h} = \mu + \sum_ {j = h} ^ {\infty} \psi_ {j} w _ {t + h - j}.
$$

Now, we know from before that the coefficients $\psi _ { i }$ tend to zero fast enough to be absolutely summable—i.e. $\textstyle \sum _ { j = 0 } ^ { \infty } \lvert \psi _ { j } \rvert < \infty$ . Therefore, $\textstyle \sum _ { j = h } ^ { \infty } | \psi _ { j } | \to 0$ as $h  \infty$ This implies that

$$
\tilde {X} _ {T + h} \stackrel {\mathrm {P}} {\rightarrow} \mu \mathrm {a s} h \rightarrow \infty .
$$

We can prove this first by noting that the variance of $\tilde { X } _ { T + h }$ is $\textstyle \sum _ { j = h } ^ { \infty } \psi _ { j } ^ { 2 }$ . Then, for any $\varepsilon > 0$ , we can use Chebyshev’s inequality to get that

$$
\mathrm {P} \left(| \tilde {X} _ {T + h} - \mu | > \varepsilon\right) = \mathrm {P} \left(\left| \sum_ {j = h} ^ {\infty} \psi_ {j} w _ {t + h - j} \right| > \varepsilon\right) \leq \varepsilon^ {- 2} \sum_ {j = h} ^ {\infty} \psi_ {j} ^ {2} \to 0
$$

as $h \to \infty$

Meanwhile, the MSPE from above is

$$
P _ {T + h} ^ {T} = \sigma^ {2} \sum_ {j = 0} ^ {h - 1} \psi_ {j} ^ {2}.
$$

Therefore, as $h  \infty$ , we have that the MSPE tends to $K _ { X } ( 0 )$ , which is just the variance of the process $X _ { t }$ .

Hence, in the long run, the forecast for an ARMA(p,q) process tends towards its mean, and the variance tends to the variance of the process.

# Truncating the infinite past

For a small sample size $T$ , we can forecast by solving the system of equations presented above by inverting the $T \times T$ matrix $\Gamma$ . For a large sample size $T$ , we can use the recursive approach to forecast. However, it is worth considering what the effect is of not having access to the past time points $X _ { 0 } , X _ { - 1 } , \ldots$ before the dataset was collected.

Using the invertible respresentation of the time series, we have the truncated h-step-ahead prediction

$$
\tilde {X} _ {T + h} ^ {T} = - \sum_ {j = 1} ^ {h - 1} \pi_ {i} \tilde {X} _ {T + h - j} ^ {T} - \sum_ {j = h} ^ {T} \pi_ {i} X _ {T + h - j}.
$$

Given the coefficients $\phi _ { i }$ and $\theta _ { i }$ , we can write this truncated prediction as

$$
\tilde {X} _ {T + h} ^ {T} = \sum_ {i = 1} ^ {p} \phi_ {i} \tilde {X} _ {T + h - i} ^ {T} + \sum_ {j = 1} ^ {q} \theta_ {j} \tilde {w} _ {T + h - j} ^ {T}
$$

where we replace the predicted value $\ddot { X } _ { T + h - i } ^ { T }$ with the observed value $X _ { T + h - i }$ if $i \in \lfloor h , T + h - 1 \rfloor$ and with 0 if $i \geq T + h$ . Similarly, $\tilde { w } _ { t } ^ { T } = 0$ if $t < 1$ or if $t > T$ . Otherwise,

$$
\tilde {w} _ {t} ^ {T} = \Phi (B) \tilde {X} _ {t} ^ {T} - \sum_ {j = 1} ^ {q} \theta_ {j} \tilde {w} _ {t - j}.
$$

To see all of this in action, we can consider a few simple examples.

Example 3.2.3 (ARMA(1,1)). For the causal invertible ARMA(1,1) process $X _ { t + 1 } =$ $\phi X _ { t } + w _ { t + 1 } + \theta w _ { t }$ , we can consider the one-step-ahead prediction

$$
\tilde {X} _ {T + 1} ^ {T} = \phi X _ {T} + \theta \tilde {w} _ {T} ^ {T}
$$

and the h-step-ahead prediction $\tilde { X } _ { T + h } ^ { T } = \phi X _ { T + h - 1 } ^ { T }$ for $h \geq 2$

Hence, to forecast for the ARMA(1,1) process, we only need $X _ { T }$ and the estimate $\tilde { w } _ { T } ^ { T }$ . For the error term $\tilde { w } _ { T } ^ { T }$ , we have that

$$
w _ {t + 1} = X _ {t + 1} - \phi X _ {t} - \theta w _ {t}
$$

$$
\tilde {w} _ {t + 1} ^ {T} = X _ {t + 1} - \phi X _ {t} - \theta \tilde {w} _ {t} ^ {T}.
$$

Hence, we can start from $\tilde { w } _ { 0 } ^ { T } = 0$ and $X _ { 0 } = 0$ and compute the $\tilde { w } _ { t + 1 } ^ { I ^ { \prime } }$ iteratively.

We can also compute the variance of the prediction (the MSPE). For this, we note that the ARMA(1,1) process can be writen in a causal form as

$$
X _ {t} = w _ {t} + \sum_ {i = 1} ^ {\infty} \psi_ {i} w _ {t - i} = w _ {t} + \sum_ {i = 1} ^ {\infty} (\phi + \theta) \phi^ {i - 1} w _ {t - i}.
$$

Then, we have that

$$
\begin{array}{l} P _ {T + h} ^ {T} = \sigma^ {2} \sum_ {j = 0} ^ {h - 1} \psi_ {j} ^ {2} = \sigma^ {2} \left[ 1 + (\phi + \theta) ^ {2} \sum_ {j = 1} ^ {h - 1} \phi^ {2 j - 2} \right] \\ = \sigma^ {2} \left[ 1 + (\phi + \theta) ^ {2} \left(\frac {1 - \phi^ {2 h - 2}}{1 - \phi^ {2}}\right)\right]\rightarrow \sigma^ {2} \left[ 1 + \frac {(\phi + \theta) ^ {2}}{1 - \phi^ {2}} \right] \\ \end{array}
$$

as $h \to \infty$

# Backcasting

We can also consider forecasting into the past or backcasting. That is, we can predict backwards $h$ time units into the past by

$$
\hat {X} _ {1 - h} ^ {T} = \sum_ {i = 1} ^ {T} \alpha_ {i} X _ {i}
$$

for some coefficients $\alpha _ { t }$ . To do this, we proceed as before by considering for $t =$ $1 , \ldots , T$

$$
\operatorname {E} \left(X _ {1 - h} X _ {t}\right) = \sum_ {i = 1} ^ {T} \alpha_ {i} \operatorname {E} \left(X _ {i} X _ {t}\right)
$$

$$
K _ {X} (t + h - 1) = \sum_ {i = 1} ^ {T} \alpha_ {i} K _ {X} (t - i).
$$

This means we can compute the coefficients $\alpha _ { i }$ by solving the system of equations $K = \Gamma \alpha$ where

$$
K = \left( \begin{array}{c} K _ {X} (h) \\ K _ {X} (h + 1) \\ \vdots \\ K _ {X} (T + h - 1) \end{array} \right), \Gamma = \left( \begin{array}{c c c c} K _ {X} (0) & K _ {X} (1) & \dots & K _ {X} (T - 1) \\ K _ {X} (1) & K _ {X} (0) & \dots & K _ {X} (T - 2) \\ \vdots & \vdots & \ddots & \vdots \\ K _ {X} (T - 1) & K _ {X} (T - 2) & \dots & K _ {X} (0) \end{array} \right)
$$

just as we did before for forecasting.

Remark 3.2.4 (Fun Fact). For a stationary Gaussian process, the vector $( X _ { T + 1 , X _ { T } , \dots , X _ { 1 } } )$ is equal in distribution to $( X _ { 0 , X _ { 1 } , \ldots , X _ { T } } )$ , so forecasting and backcasting are equivalent.

# 3.3 Seasonal ARIMA

Very often with time series, there is a strong seasonal component to the data. For example, temperatures and other climate measurements have annual cycles. Financial data may have annual or quarterly cycles. For another example, electricity consumption may have both annual cycles and daily cycles—we use more electricity when we are awake than when we are asleep, and we use more electricity in the winter when it is dark and we are prone to staying inside, for example.

Thus, it is often beneficial to consider modelling time series data are certain lags based on the seasonality of the data. For example, instead of considering an AR(1) process

$$
X _ {t} = \phi X _ {t - 1} + w _ {t},
$$

we could consider an annual AR(1) process

$$
X _ {t} = \phi X _ {t - 1 2} + w _ {t}
$$

or more generally, $X _ { t } = \phi X _ { t - s } + w _ { t }$ which we will call an AR(1)s process for some value of $s > 1$ .

In general, we can consider a seasonal ARMA process denoted AMRA $( p ^ { \prime } , q ^ { \prime } ) _ { s }$ which is

$$
\Phi_ {s} (B ^ {s}) X _ {t} = \Theta_ {s} (B ^ {s}) w _ {t}
$$

where the polynomials $\Phi _ { s }$ and $\Theta _ { s }$ are

$$
\Phi_ {s} (B ^ {s}) = 1 - \varphi_ {1} B ^ {s} - \varphi_ {2} B ^ {2 s} - \ldots - \varphi_ {p ^ {\prime}} B ^ {p ^ {\prime s}}
$$

$$
\Theta_ {s} (B ^ {s}) = 1 + \vartheta_ {1} B ^ {s} + \vartheta_ {2} B ^ {2 s} + \ldots + \vartheta_ {q ^ {\prime}} B ^ {q ^ {\prime s}}
$$

The reason for the notation is to combine the seasonal ARMA with the regular ARMA process to get an ARMA $( p , q ) \times ( p ^ { \prime } , q ^ { \prime } ) _ { s }$ process, which can be written as

$$
\Phi_ {s} (B ^ {s}) \Phi (B) X _ {t} = \Theta_ {s} (B ^ {s}) \Theta (B) w _ {t}.
$$

If we were to include a differencing operator as in the ARIMA model to account for non-stationarity, we get the Seasonal ARIMA or SARIMA $( p , d , q ) \times ( p ^ { \prime } , d ^ { \prime } , q ^ { \prime } ) _ { s }$ model. This takes on the form

$$
\Phi_ {s} (B ^ {s}) \Phi (B) \nabla_ {s} ^ {d ^ {\prime}} \nabla^ {d} X _ {t} = \Theta_ {s} (B ^ {s}) \Theta (B) w _ {t}.
$$

where $\nabla ^ { d } = ( 1 - B ) ^ { d }$ and $\nabla _ { s } ^ { d ^ { \prime } } = ( 1 - B ^ { s } ) ^ { d ^ { \prime } }$ . The large number of parameters is why the auto.arima() function in the R package forecast takes so long to run when the seasonal component is included.

# 3.3.1 Seasonal Autoregressive Processes

We can consider a purely seasonal AR process such as an annual AR(1) like

$$
(1 - \varphi B ^ {1 2}) X _ {t} = w _ {t}
$$

$$
X _ {t} = \varphi X _ {t - 1 2} + w _ {t}
$$

where $| \phi | < 1$ . To compute the autocovariance quickly, we can rewrite this as a linear process

$$
\begin{array}{l} X _ {t} = \varphi X _ {t - 1 2} + w _ {t} \\ = \varphi \left(\varphi X _ {t - 2 4} + w _ {t - 1 2}\right) + w _ {t} \\ = \varphi^ {2} X _ {t - 2 4} + \varphi w _ {t - 1 2} + w _ {t} \\ \begin{array}{c} \bullet \\ \bullet \\ \bullet \end{array} \\ = \sum_ {j = 0} ^ {\infty} \varphi^ {j} w _ {t - 1 2 j}. \\ \end{array}
$$

Therefore, the variance is as usual $K _ { X } ( 0 ) = \sigma ^ { 2 } / ( 1 - \phi ^ { 2 } )$ . For lags $h = 1 , \ldots , 1 1$ , we have

$$
\begin{array}{l} K _ {X} (h) = \operatorname {c o v} \left(\sum_ {j = 0} ^ {\infty} \varphi^ {j} w _ {t - 1 2 j}, \sum_ {i = 0} ^ {\infty} \varphi^ {i} w _ {t - h - 1 2 i}\right) \\ = \sum_ {j = 0} ^ {\infty} \sum_ {i = 0} ^ {\infty} \varphi^ {j + i} \operatorname {c o v} \left(w _ {t - 1 2 j}, w _ {t - h - 1 2 i}\right) = 0, \\ \end{array}
$$

because the indices $t - 1 2 j$ and $t - h - 1 2 i$ will never be equal unless $h$ is a multiple of 12. In that case, we have

$$
K _ {X} (1 2) = \sigma^ {2} \varphi \sum_ {j = 0} ^ {\infty} \varphi^ {2 j} = \frac {\sigma^ {2} \varphi}{1 - \varphi^ {2}}.
$$

Note that this is the same as $K _ { Y } ( 1 )$ for the AR(1) process $Y _ { t } = \varphi Y _ { t - 1 } + w _ { t }$ . Hence, the above seasonal AR process is effectively 12 uncorrelated AR processes running in parallel to each other. This is why we often include a seasonal and non-seasonal component in the SARIMA models.

Note also that the $\mathrm { A R } ( 1 , 0 ) _ { 1 2 }$ could also be thought of as an $\mathrm { A R } ( 1 2 , 0 )$ . However, trying to estimate or forecast with an $\mathrm { A R } ( 1 2 , 0 )$ process will include many parameters that are unnecessary, which will increase the variance for our estimators and predictions.

# 3.3.2 Seasonal ARMA Processes

We can take the above process and add in an MA(1) process to get the ARMA $( 0 , 1 ) \times$ $( 1 , 0 ) _ { 1 2 }$ which is

$$
(1 - \varphi B ^ {1 2}) X _ {t} = \theta w _ {t - 1} + w _ {t}
$$

with $| \theta | < 1$ and $| \varphi | < 1$ . We can compute the variance as usual by noting that the MA piece is based on $w _ { t - 1 }$ , which is uncorrelated with the AR(1)12 piece to get

$$
K _ {X} (0) = \operatorname {V a r} \left(X _ {t}\right) = \operatorname {V a r} \left(\varphi X _ {t - 1 2} + \theta w _ {t - 1} + w _ {t}\right) = \varphi^ {2} K _ {X} (0) + \sigma^ {2} \left(\theta^ {2} + 1\right),
$$

which gives that

$$
K _ {X} (0) = \sigma^ {2} \frac {1 + \theta^ {2}}{1 - \varphi^ {2}}.
$$

For the autocovariances at other lags, we first note that if $h = 1 2 m$ is a multiple of 12, then

$$
K _ {X} (h) = K _ {X} (1 2 m) = \frac {\sigma^ {2} \varphi^ {m}}{1 - \varphi^ {2}}
$$

as above, since the MA piece will not affect the calculation. However, if $h = 1$ mod 12 or $h = 1 1$ mod 12, we have to work harder. First, consider that

$$
\begin{array}{l} K _ {X} (1) = \operatorname {E} \left(X _ {t - 1} \left[ \varphi X _ {t - 1 2} + \theta w _ {t - 1} + w _ {t} \right]\right) \\ = \varphi K _ {X} (1 1) + \sigma^ {2} \theta , \quad \text {a n d} \\ K _ {X} (1 1) = \operatorname {E} \left(X _ {t - 1 1} \left[ \varphi X _ {t - 1 2} + \theta w _ {t - 1} + w _ {t} \right]\right) \\ = \varphi K _ {X} (1). \\ \end{array}
$$

From this, we have that

$$
K _ {X} (1) = \frac {\sigma^ {2} \theta}{1 - \varphi^ {2}} \quad \mathrm {a n d} \quad K _ {X} (1 1) = \frac {\sigma^ {2} \theta \varphi}{1 - \varphi^ {2}}
$$

Continuing on, we have that

$$
K _ {X} (1 3) = \varphi K _ {X} (1) = \frac {\sigma^ {2} \theta \varphi}{1 - \varphi^ {2}}
$$

as well. Hence, we can generalize this to

$$
K _ {X} (h) = K _ {X} (1 2 m \pm 1) = \frac {\sigma^ {2} \theta \varphi^ {m}}{1 - \varphi^ {2}}.
$$

Lastly, for any lags $h \neq - 1 , 0 , 1$ mod 12, we have $K _ { X } ( h ) = 0$ as none of the indices line up in the autocovariance computation.

# Chapter 4

# Analysis in the Frequency Domain

# Introduction

Time series data often exhibits cyclic behaviour as we saw with SARIMA models in the previous chapter. Furthermore, a time series may have more than one cycle occurring simultaneously. In this chapter, we will consider spectral methods for identifying the cyclic behaviour of time series data.

In general, we are interested in the frequency $\omega$ of the time series. For example, a time series that repeats every 12 months, the frequency is $\omega = 1 / 1 2$ .

# 4.1 Periodic Processes

We will consider the periodic process

$$
X _ {t} = A \cos (2 \pi \omega t + \phi)
$$

where $A$ is the amplitude, $\omega$ is the frequency, and $\phi$ is the phase. This process can be rewritten as linear combination of trig functions as

$$
X _ {t} = U _ {1} \cos (2 \pi \omega t) + U _ {2} \sin (2 \pi \omega t)
$$

where $U _ { 1 } = A \cos ( \phi )$ and $U _ { 2 } = - A \sin ( \phi )$ . This is due to the identity $\cos ( x + y ) =$ $\cos ( x ) \cos ( y ) - \sin ( x ) \sin ( y )$ .

If we take $U _ { 1 }$ and $U _ { 2 }$ to be uncorrelated mean zero random variables with vari-

ance $\sigma ^ { 2 }$ , then we can compute the autocovariance as

$$
\begin{array}{l} K _ {X} (h) = \\ = \operatorname {c o v} \left(U _ {1} \cos (2 \pi \omega (t + h)) + U _ {2} \sin (2 \pi \omega (t + h)), U _ {1} \cos (2 \pi \omega t) + U _ {2} \sin (2 \pi \omega t)\right) \\ = \operatorname {c o v} \left(U _ {1} \cos (2 \pi \omega (t + h)), U _ {1} \cos (2 \pi \omega t)\right) \\ + \operatorname {c o v} \left(U _ {2} \sin (2 \pi \omega (t + h)), U _ {2} \sin (2 \pi \omega t)\right) \\ = \sigma^ {2} \cos (2 \pi \omega (t + h)) \cos (2 \pi \omega t) + \sigma^ {2} \sin (2 \pi \omega (t + h)) \sin (2 \pi \omega t) \\ = \sigma^ {2} \cos (2 \pi \omega h), \\ \end{array}
$$

so depending on the lag $h$ , the autocovariance with rise or fall.

We can combine $q$ different frequencies $\omega _ { 1 } , \ldots , \omega _ { q }$ to get a more general period process

$$
X _ {t} = \sum_ {j = 1} ^ {q} \left\{U _ {j 1} \cos (2 \pi \omega_ {j} t) + U _ {j 2} \sin (2 \pi \omega_ {j} t) \right\}
$$

where all of the $U _ { j 1 }$ and $U _ { j 2 }$ are uncorrelated mean zero random variance with potentially different variances $\sigma _ { j } ^ { 2 }$ . The autocovariance in this case is

$$
K _ {X} (h) = \sum_ {j = 1} ^ {q} \sigma_ {j} ^ {2} \cos (2 \pi \omega_ {j} h).
$$

Remark 4.1.1 (Aliasing). Aliasing is a problem that can occur when taking a discrete sample from a continuous signal. Since we have to sample a certain rate, high frequency behaviour in the signal may look like low frequency patterns in our sample. This is displayed in Figure 4.1 where the red dots are sampled too infrequently making it appear as if there is a low frequency oscilation in the data instead of the actually high frequency oscilation in black.

# 4.1.1 Regression, Estimation, and the FFT

Given some time series data $X _ { 1 } , \ldots , X _ { T }$ with $T$ odd, then we can exactly represent the data as

$$
X _ {t} = \beta_ {0} + \sum_ {j - 1} ^ {(T - 1) / 2} \left\{\beta_ {j 1} \cos (2 \pi t   j / T) + \beta_ {j 2} \sin (2 \pi t   j / T) \right\}.
$$

This is because the sin’s and cos’s form a basis, and similarly to how a $T ' - 1$ degree polynomial can pass through $T$ points, these $T - 1$ parameters $\beta _ { \star }$ can be used to fit the data exactly. Note that for $T$ even, we can also do this with

$$
X _ {t} = \beta_ {0} + \sum_ {j - 1} ^ {T / 2 - 1} \left\{\beta_ {j 1} \cos (2 \pi t j / T) + \beta_ {j 2} \sin (2 \pi t j / T) \right\} + \beta_ {T / 2} \cos (\pi t).
$$

![](images/60b1f124879a6816d0eb01c5defdf416ca1b9ba2dfa7e7069948ed2c3eb6b417.jpg)  
Figure 4.1: Aliasing occurs when we sample too infrequently to capture high frequency oscilations.

Of course, in practice, we do not want to include $T - 1$ parameters to fit our data exactly. Instead, we assume that most of these $\beta$ will be zero and the only non-zero $\beta$ ’s will correspond to prominent frequencies in the time series.

We can estimate all of the $\beta$ ’s by treating this as a linear regression problem.1

First, with a little work, we can show that

$$
\sum_ {t = 1} ^ {T} \cos^ {2} (2 \pi t j / T) = \sum_ {t = 1} ^ {T} \sin^ {2} (2 \pi t j / T) = n / 2 \qquad \text {f o r} j = 1, \dots T / 2 - 1
$$

$$
\sum_ {t = 1} ^ {T} \cos^ {2} (2 \pi t j / T) = n \qquad \text {f o r} j = 0, T / 2
$$

$$
\sum_ {t = 1} ^ {T} \sin^ {2} (2 \pi t j / T) = 0 \qquad \text {f o r} j = 0, T / 2
$$

$$
\sum_ {t = 1} ^ {T} \cos (2 \pi t j / T) \cos (2 \pi t k / T) = 0 \qquad \text {f o r} j \neq k
$$

$$
\sum_ {t = 1} ^ {T} \cos (2 \pi t j / T) \cos (2 \pi t k / T) = 0 \qquad \text {f o r} j \neq k
$$

$$
\sum_ {t = 1} ^ {T} \cos (2 \pi t j / T) \sin (2 \pi t k / T) = 0 \qquad \text {f o r a n y} j, k.
$$

Hence, our design matrix for linear regression has orthongal columns, so computing each $\hat { \beta }$ becomes, for $j \neq 0 , T / 2$ ,

$$
\hat {\beta} _ {j 1} = \frac {2}{T} \sum_ {t = 1} ^ {T} X _ {t} \cos (2 \pi t j / T)
$$

$$
\hat {\beta} _ {j 2} = \frac {2}{T} \sum_ {t = 1} ^ {T} X _ {t} \sin (2 \pi t j / T)
$$

and ${ \hat { \beta } } _ { 0 } = { \bar { X } }$ and, if $T$ is even, $\begin{array} { r } { \hat { \beta } _ { T / 2 } = T ^ { - 1 } \sum _ { t = 1 } ^ { T } ( - 1 ) ^ { t } X _ { t } } \end{array}$

Given these estimates, we can define the scaled periodogram $P ( j / T ) = \hat { \beta } _ { j 1 } ^ { 2 } + \hat { \beta } _ { j 2 } ^ { 2 }$ which can be used to determine which frequencies are the most prominent in the time series $X _ { t }$ . Note that the variance of for $\beta _ { j 1 } \cos ( 2 \pi t j / T ) + \beta _ { j 2 } \sin ( 2 \pi t j / T )$ is $\beta _ { j 1 } ^ { 2 } + \beta _ { j 2 } ^ { 2 }$ , so the periodogram is the sample variance for frequency $j / T$ .

Computing all of these $\beta$ as above is computationally infeasable for large $T$ . However, if $T$ is a highly composite integer—i.e. one with a lot of small integer factors like $2 ^ { m }$ —then, we can use the discrete Fourier transform,

$$
\begin{array}{l} d (j / T) = \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} X _ {t} \exp (- 2 \pi i t j / T) \\ = \frac {1}{\sqrt {T}} \left\{\sum_ {t = 1} ^ {T} X _ {t} \cos (2 \pi t j / T) - i \sum_ {t = 1} ^ {T} X _ {t} \sin (2 \pi t j / T) \right\}. \\ \end{array}
$$

The squared magnitude of the coefficients

$$
| d (j / T) | ^ {2} = \frac {1}{T} \left\{\sum_ {t = 1} ^ {T} X _ {t} \cos (2 \pi t j / T) \right\} ^ {2} + \frac {1}{T} \left\{\sum_ {t = 1} ^ {T} X _ {t} \sin (2 \pi t j / T) \right\} ^ {2}
$$

is the (unscaled) periodogram. The scaled periodogram is $P ( j / T ) = ( 4 / T ) | d ( j / T ) | ^ { 2 }$ , which follows from the equations for the $\hat { \beta }$ above. Noting that $\cos ( 2 \pi - \theta ) = \cos ( \theta )$ and that $\sin ( 2 \pi - \theta ) = - \sin ( \theta )$ , we have that $| d ( 1 - j / T ) | ^ { 2 } = | d ( j / T ) | ^ { 2 }$ and likewise $P ( 1 - j / T ) = P ( j / T )$ . Hence, we only consider frequencies $j / T < 1 / 2$ .

The DFT can be computed quickly via the Fast Fourier Transform (FFT). The DFT is just a linear transformation of the data $X _ { t }$ , which can be written at $d = W X$ for some matrix $W$ . This type of transformation would take $O ( T ^ { 2 } )$ time to compute. However, the FFT uses a sparse representation of $W$ to reduce the time to $O ( T \log _ { 2 } T )$ . There are many algorithms for the FFT, but the most common takes a divide-and-conquer approach. That is, if $T = 2 ^ { m }$ , then it breaks the data in half based on odd and even indices $X _ { 1 } , X _ { 3 } , \ldots , X _ { T - 1 }$ and $X _ { 2 } , X _ { 4 } , \ldots , X _ { T }$ and computes the Fourier transform of each separately. However, since $T / 2 = 2 ^ { m - 1 }$ i s also divisible by 2, this idea can be applied recursively to get 4 partitions of the data, then 8, and so on.

If we rewrite the DFT as

$$
\begin{array}{l} \sqrt {T} d (j / T) = \sum_ {t = 1} ^ {T / 2} X _ {2 t} \mathrm {e} ^ {- \frac {2 \pi i t j}{T / 2}} + \mathrm {e} ^ {- \frac {2 \pi i j}{T}} \sum_ {t = 1} ^ {T / 2} X _ {2 t - 1} \mathrm {e} ^ {- \frac {2 \pi i t j}{T / 2}} \\ = E _ {j} + \mathrm {e} ^ {- \frac {2 \pi i j}{T}} O _ {j}, \\ \end{array}
$$

then we can decompose it into even and odd parts $E _ { j }$ and $O _ { j }$ , respectively. These two pieces are each DFTs of size $T / 2$ . We also note that there is a redundency in the calculations, which is for $j < T / 2$ , we have

$$
\sqrt {T} d (j / T) = E _ {j} + \mathrm {e} ^ {- \frac {2 \pi i j}{T}} O _ {j}
$$

and that

$$
\sqrt {T} d (j / T + 1 / 2) = E _ {j} - \mathrm {e} ^ {- \frac {2 \pi i j}{T}} O _ {j}.
$$

Remark 4.1.2. Scaling and the FFT In Fourier analysis and for different FFT implementations in code, there are often different scaling factors included. Hence, to make sure we are estimating what we want to estimate, one needs to take care when using FFT algorithms.

# 4.2 Spectral Distribution and Density

We begin by presenting a way to represent the autocovariance function as described in the Wiener-Khintchine Theorem.2 The theorem applies to continuous time pro-

cesses. However, in this course, we only consider discrete time processes.

Theorem 4.2.1 (Wiener-Khintchine Theorem I). Let $X _ { t }$ be stationary with autocovariance $K _ { X } ( h ) = \mathrm { c o v } \left( X _ { t + h } , X _ { t } \right)$ . Then, there exists a unique monotonically increasing function $F _ { X } ( \omega )$ , called the spectral distribution function, with $F _ { X } ( - 1 / 2 ) =$ 0 and $F _ { X } ( 1 / 2 ) = K _ { X } ( 0 )$ such that

$$
K _ {X} (h) = \int_ {- 1 / 2} ^ {1 / 2} \mathrm {e} ^ {2 \pi i \omega h} d F _ {X} (\omega)
$$

where this is a Riemann-Stieltjes integral.

Given slightly stronger conditions, we can also define the spectral density. That is, if the autocovariance is absolutely summable, then the spectral distribution is absolutely continuous in turn implying that the derivative exists almost everywhere: $d F _ { X } ( \omega ) = f _ { X } ( \omega ) d \omega$ .

Theorem 4.2.2 (Wiener-Khintchine Theorem II). Let $X _ { t }$ be stationary with autocovariance $K _ { X } ( h ) = \mathrm { c o v } \left( X _ { t + h } , X _ { t } \right)$ such that

$$
\sum_ {h = - \infty} ^ {\infty} | K _ {X} (h) | <   \infty
$$

Then, we can write

$$
K _ {X} (h) = \int_ {- 1 / 2} ^ {1 / 2} \mathrm {e} ^ {2 \pi i \omega h} f _ {X} (\omega) d \omega .
$$

Furthermore, we have the inverse transformation

$$
f _ {X} (\omega) = \sum_ {h = - \infty} ^ {\infty} K _ {X} (h) \mathrm {e} ^ {- 2 \pi i \omega h}
$$

for $\omega \in [ - 1 / 2 , 1 / 2 ]$

From here we see that if $f _ { X } ( \omega )$ exists, then it is an even function—i.e. $f _ { X } ( \omega ) =$ $f _ { X } ( - \omega )$ . Also, since $\begin{array} { r } { K _ { X } ( 0 ) = \int _ { - 1 / 2 } ^ { 1 / 2 } f _ { X } ( \omega ) d \omega } \\ { . } \end{array}$ , the variance of the process can be thought of as the integral of the spectral density over all frequencies. In a way, this is similar to how the total sum of squares can be decomposed into separate sums of squares in a ANOVA.

As a simple example, consider the period process $X _ { t } = U _ { 1 } \cos ( 2 \pi \omega _ { 0 } t ) { + } U _ { 2 } \sin ( 2 \pi \omega _ { 0 } t )$ from before. Then, the autocovariance is

$$
K _ {X} (h) = \sigma^ {2} \cos (2 \pi \omega_ {0} h) = \frac {\sigma^ {2}}{2} \left(\mathrm {e} ^ {2 \pi \omega_ {0} h} + \mathrm {e} ^ {- 2 \pi \omega_ {0} h}\right) = \int_ {- 1 / 2} ^ {1 / 2} \mathrm {e} ^ {2 \pi i \omega h} d F _ {X} (\omega)
$$

where $F _ { X } ( \omega ) = 0$ for $\omega < - \omega _ { 0 }$ , $F _ { X } ( \omega ) = \sigma ^ { 2 } / 2$ for $\omega \in [ - \omega _ { 0 } , \omega _ { 0 } ]$ , and $F _ { X } ( \omega ) = \sigma ^ { 2 }$ for $\omega > \omega _ { \mathrm { 0 } }$ . Note that in this case, the autocovariance is not absolutely summable.

As a second example, we consider the white noise process $w _ { t }$ . In this case, the autocovariance is simply $\sigma ^ { 2 }$ at lag $h = 0$ and 0 for all other lags $h$ . Hence, it is absolutely summable and the spectral density is just $f _ { X } ( \omega ) = \sigma ^ { 2 }$ for all $\omega \in$ $[ - 1 / 2 , 1 / 2 ]$ . Hence, as mentioned in Chapter 1, white noise in a sense contains every frequency at once with equal power.

# 4.2.1 Filtering and ARMA

Given the spectral density for one time series $X _ { t }$ , we can find the spectral density for another related time series $\begin{array} { r } { y _ { t } = \sum _ { j = - \infty } ^ { \infty } a _ { j } X _ { t - j } } \end{array}$ for some fixed sequence $a _ { j }$ with $\textstyle \sum _ { j = - \infty } ^ { \infty } \left| a _ { j } \right| < \infty$ . Treating $a : \mathbb { Z } \to \mathbb { R }$ as a function, then $a ( j ) = a _ { j }$ is called the impulse response function and its Fourier transform

$$
A (\omega) = \sum_ {j = - \infty} ^ {\infty} a _ {j} \mathrm {e} ^ {- 2 \pi i \omega j}
$$

is the frequency response function. Given all of this, we have the following theorem.

Theorem 4.2.3. Let $\infty$ , then the spectral density for $X _ { t }$ be a time series with spectral density $\begin{array} { r } { y _ { t } = \sum _ { j = - \infty } ^ { \infty } a _ { j } X _ { t - j } } \end{array}$ is $f _ { X } ( \omega )$ and let $\scriptstyle \sum _ { j = - \infty } ^ { \infty } | a _ { j } | <$

$$
f _ {Y} (\omega) = | A (\omega) | ^ {2} f _ {X} (\omega)
$$

for $A ( \omega )$ the frequency response function from above.

Proof. To prove the above theorem, we just compute the autocovariance directly.

$$
\begin{array}{l} K _ {Y} (h) = \operatorname {c o v} \left(\sum_ {j = - \infty} ^ {\infty} a _ {j} X _ {t + h - j}, \sum_ {l = - \infty} ^ {\infty} a _ {l} X _ {t - l}\right) \\ = \sum_ {j = - \infty} ^ {\infty} \sum_ {l = - \infty} ^ {\infty} a _ {j} a _ {l} K _ {X} (h - j + l) \\ = \sum_ {j = - \infty} ^ {\infty} \sum_ {l = - \infty} ^ {\infty} a _ {j} a _ {l} \int_ {- 1 / 2} ^ {1 / 2} \mathrm {e} ^ {2 \pi i \omega (h - j + l)} f _ {X} (\omega) d \omega \\ = \int_ {- 1 / 2} ^ {1 / 2} \left[ \sum_ {j = - \infty} ^ {\infty} a _ {j} \mathrm {e} ^ {- 2 \pi i \omega j} \right] \left[ \sum_ {l = - \infty} ^ {\infty} a _ {l} \mathrm {e} ^ {2 \pi i \omega l} \right] \mathrm {e} ^ {2 \pi i \omega h} f _ {X} (\omega) d \omega \\ = \int_ {- 1 / 2} ^ {1 / 2} \mathrm {e} ^ {2 \pi i \omega h} | A (\omega) | ^ {2} f _ {X} (\omega) d \omega . \\ \end{array}
$$

Therefore, by the uniqueness of the Fourier transform, we have that $f _ { Y } ( \omega ) ~ =$ $| A ( \omega ) | ^ { 2 } f _ { X } ( \omega )$ .

We can apply this result to a causal ARMA(p,q) process. For $\Phi ( B ) X _ { t } = \Theta ( B ) w _ { t }$ , we have rewrite it as

$$
X _ {t} = \frac {\Theta (B)}{\Phi (B)} w _ {t} = \sum_ {j = 0} ^ {\infty} \psi_ {j} w _ {t - j}.
$$

Writing $\begin{array} { r } { \Psi ( z ) = \Theta ( Z ) / \Phi ( z ) = \sum _ { j = 0 } ^ { \infty } \psi _ { j } z ^ { j } } \end{array}$ and using this as the $a _ { j }$ from the above theorem, we have that

$$
A (\omega) = \sum_ {j = - \infty} ^ {\infty} \psi_ {j} \mathrm {e} ^ {- 2 \pi i \omega j} = \Psi (\mathrm {e} ^ {- 2 \pi i \omega}) = \frac {\Theta (\mathrm {e} ^ {- 2 \pi i \omega})}{\Phi (\mathrm {e} ^ {- 2 \pi i \omega})}.
$$

Using the fact that $f _ { w } ( \omega ) = \sigma ^ { 2 }$ for all $\omega$ , we have finally that

$$
f _ {X} (\omega) = | A (\omega) | ^ {2} f _ {w} (\omega) = \sigma^ {2} \left| \frac {\Theta (\mathrm {e} ^ {- 2 \pi i \omega})}{\Phi (\mathrm {e} ^ {- 2 \pi i \omega})} \right| ^ {2}.
$$

# 4.3 Spectral Statistics

Thus far, our discussion of spectral analysis for time series has not considered the issue of working with noisy data. Given a finite set of data $X _ { 1 } , \ldots , X _ { T }$ , we can compute the DFT

$$
d (\omega_ {j}) = \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} X _ {t} \mathrm {e} ^ {- 2 \pi i \omega_ {j} t}
$$

for frequencies $\omega _ { j } = j / T$ . We can also compute the real and imaginary part separately being the sine and cosine transformations:

$$
d _ {c} (\omega_ {j}) = \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} X _ {t} \cos 2 \pi \omega_ {j} t
$$

$$
d _ {s} (\omega_ {j}) = \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} X _ {t} \sin 2 \pi \omega_ {j} t
$$

so that $d ( \omega _ { j } ) = d _ { c } ( \omega _ { j } ) - i d _ { s } ( \omega _ { j } )$ .

We can compute the inverse DFT by

$$
X _ {t} = \frac {1}{\sqrt {T}} \sum_ {j = 0} ^ {T - 1} d (\omega_ {j}) \mathrm {e} ^ {2 \pi i \omega_ {j} t}
$$

for $t = 1 , \dots , T$ . This gives us the periodogram defined to be

$$
I (\omega_ {j}) = | d (\omega_ {j}) | ^ {2} = d _ {c} (\omega_ {j}) ^ {2} + d _ {s} (\omega_ {j}) ^ {2}.
$$

We can also centre the DFT when $j \neq 0$ to get

$$
d (\omega_ {j}) = \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} (X _ {t} - \bar {X}) \mathrm {e} ^ {- 2 \pi i \omega_ {j} t}
$$

as pe $\begin{array} { r } { \sum _ { t = 1 } ^ { T } \mathrm { e } ^ { - 2 \pi i \omega _ { j } t } = 0 } \end{array}$ for any  as $\omega _ { j } \neq 0$ . This is useful as it allows us to write the $j \neq 0$

$$
\begin{array}{l} I (\omega_ {j}) = \left| \frac {1}{\sqrt {T}} \sum_ {t = 1} ^ {T} (X _ {t} - \bar {X}) \mathrm {e} ^ {- 2 \pi i \omega_ {j} t} \right| ^ {2} \\ = \frac {1}{T} \sum_ {t = 1} ^ {T} \sum_ {s = 1} ^ {T} (X _ {t} - \bar {X}) (X _ {s} - \bar {X}) \mathrm {e} ^ {- 2 \pi i \omega_ {j} (t - s)} \\ = \frac {1}{T} \sum_ {h = - T + 1} ^ {T - 1} \mathrm {e} ^ {- 2 \pi i \omega_ {j} h} \sum_ {t = 1} ^ {T - | h |} (X _ {t + | h |} - \bar {X}) (X _ {t} - \bar {X}) \\ = \frac {1}{T} \sum_ {h = - T + 1} ^ {T - 1} \hat {K} _ {X} (h) \mathrm {e} ^ {- 2 \pi i \omega_ {j} h} \\ \end{array}
$$

Hence, the periodogram can be written in terms of the Fourier transform of the estimated autocovariance as we might have expected from the previous discussion. The problem we face here is that that the estimator ${ \hat { K } } _ { X } ( h )$ is very poor for large $h$ as there are relatively few pairs of time points to consider. Hence, we often truncate this summation by only summing over $| h | \leq m$ for some $m \ll T$ .

# 4.3.1 Spectral ANOVA

We can consider the spectral approach to time series as an ANOVA problem. That is, we can consider how much variation in the time series is due to a certain frequency much like the sum of squares decomposition from classic ANOVA.

For simplicity, let $T$ be odd. We consider

$$
X _ {t} = \beta_ {0} + \sum_ {j = 1} ^ {(T - 1) / 2} \left\{\beta_ {j 1} \cos (2 \pi t   j / T) + \beta_ {j 2} \sin (2 \pi t   j / T) \right\}
$$

where we found before that

$$
\begin{array}{l} \hat {\beta} _ {j 1} = \frac {2}{T} \sum_ {t = 1} ^ {T} X _ {t} \cos (2 \pi t j / T) = \frac {2}{\sqrt {T}} d _ {c} (\omega_ {j}) \\ \hat {\beta} _ {j 2} = \frac {2}{T} \sum_ {t = 1} ^ {T} X _ {t} \sin (2 \pi t j / T) = \frac {2}{\sqrt {T}} d _ {s} (\omega_ {j}) \\ \end{array}
$$

and ${ \hat { \beta } } _ { 0 } = { \bar { X } }$ . Therefore, we have

$$
X _ {t} - \bar {X} = \frac {2}{\sqrt {T}} \sum_ {j = 1} ^ {(T - 1) / 2} \{d _ {c} (\omega_ {j}) \cos (2 \pi t j / T) + d _ {s} (\omega_ {j}) \sin (2 \pi t j / T) \}
$$

and $\begin{array} { r } { \sum _ { t = 1 } ^ { T } ( X _ { t } - \bar { X } ) ^ { 2 } = 2 \sum _ { j = 1 } ^ { ( T - 1 ) / 2 } \left\{ d _ { c } ( \omega _ { j } ) ^ { 2 } + d _ { s } ( \omega _ { j } ) ^ { 2 } \right\} = 2 \sum _ { j = 1 } ^ { ( T - 1 ) / 2 } I ( \omega _ { j } ) } \end{array}$ . This is because $\begin{array} { r } { \sum _ { t = 1 } ^ { T } \cos ( 2 \pi t j / T ) ^ { 2 } = T / 2 } \end{array}$ and similarly for the sine series.

Thus, we have decomposed the total sum of squares over $T$ data points into the sum of $( T - 1 ) / 2$ terms, $2 I ( \omega _ { j } )$ , each with 2 degrees of freedom. Thus, the periodogram $I ( \omega _ { j } )$ can directly be thought of as the variation due to frequency $\omega _ { j }$ in the time series. Note that one would never want to use the aov() function in $\mathrm { R }$ to compute this. Instead, the fft() is much more efficient.

# 4.3.2 Large Sample Behaviour

In this section, we assume $X _ { t }$ is a stationary process with mean $\mu$ , absolutely summable autocovariance function $K _ { X } ( h )$ and spectral density $f _ { X } ( \omega )$ . If we write the periodogram using the true mean $\mu$ —this makes the calculations easier than using $X$ —we find that

$$
I (\omega_ {j}) = \frac {1}{T} \sum_ {h = - T + 1} ^ {T - 1} \mathrm {e} ^ {- 2 \pi i \omega_ {j} h} \sum_ {t = 1} ^ {T - | h |} (X _ {t + | h |} - \mu) (X _ {t} - \mu)
$$

$$
\operatorname {E} [ I (\omega_ {j}) ] = \sum_ {h = - T + 1} ^ {T - 1} \left(\frac {T - | h |}{T}\right) K _ {X} (h) \mathrm {e} ^ {- 2 \pi i \omega_ {j} h}.
$$

For taking the limit as $T \to \infty$ , we have to consider a sequence of frequencies $\omega _ { j } ^ { ( T ) }$ ωj that tends towards some $\omega$ as the sample size grows. For example, if we want $\omega = 1 / 3$ , we could consider

$$
\omega_ {1} ^ {(2)} = 1 / 2, \omega_ {1} ^ {(4)} = 1 / 4, \omega_ {3} ^ {(8)} = 3 / 8, \omega_ {5} ^ {(1 6)} = 5 / 1 6, \omega_ {1 1} ^ {(3 2)} = 1 1 / 3 2 \ldots
$$

In this case, if we have ω $\omega _ { j } ^ { ( T ) }  \omega$ as $T \to \infty$ , then

$$
\operatorname {E} [ I (\omega_ {j} ^ {(T)}) ] \to f _ {X} (\omega) = \sum_ {h = - \infty} ^ {\infty} K _ {X} (h) \mathrm {e} ^ {- 2 \pi i \omega_ {j} h}.
$$

Going further, if we strengthen the absolute summability condition $\scriptstyle \sum _ { h = - \infty } ^ { \infty } | K _ { X } ( h ) | <$ $\infty$ to the condition

$$
c = \sum_ {h = - \infty} ^ {\infty} | h | | K _ {X} (h) | <   \infty ,
$$

then we have that

$$
\operatorname {c o v} \left(d _ {c} (\omega_ {j}), d _ {c} (\omega_ {k})\right) = \left\{ \begin{array}{l l} f _ {X} (\omega_ {j}) / 2 + \varepsilon_ {T} & \text {f o r} \omega_ {j} = \omega_ {k} \\ \varepsilon_ {T} & \text {f o r} \omega_ {j} \neq \omega_ {k} \end{array} \right.
$$

and similarly for $d _ { s }$ where $\varepsilon _ { T }$ is an error term bound by $| \varepsilon _ { T } | \leq c / T$ . Hence, the estimated covariance matrix should have a strong diagonal with smaller noisy offdiagonal entries.

We can use this to find via the central limit theorem that if our process $X _ { t }$ is just iid white noise with variance $\sigma ^ { 2 }$ , then

$$
d _ {c} (\omega_ {j} ^ {(T)}) \stackrel {\mathrm {d}} {\to} \mathcal {N} \left(0, \sigma^ {2} / 2\right)
$$

$$
d _ {s} (\omega_ {j} ^ {(T)}) \stackrel {\mathrm {d}} {\to} \mathcal {N} \left(0, \sigma^ {2} / 2\right)
$$

Thus, recalling that $I ( \omega _ { j } ) = d _ { c } ( \omega _ { j } ) ^ { 2 } + d _ { s } ( \omega _ { j } ) ^ { 2 }$ , we have that

$$
2 I (\omega_ {j} ^ {(T)}) / \sigma^ {2} \stackrel {\mathrm {d}} {\rightarrow} \chi^ {2} (2)
$$

and this $I ( \omega _ { j } ^ { ( T ) } )$ will be asymptotically independent with some other $I ( \omega _ { k } ^ { ( T ) } )$

For the general linear process, we have

Theorem 4.3.1. If $\begin{array} { r } { X _ { t } = \sum _ { j = \infty } ^ { \infty } \psi _ { j } w _ { t - j } } \end{array}$ with the $\psi _ { j }$ absolutely summable and with $w _ { t }$ being iid white noise with variance $\sigma ^ { 2 }$ and with

$$
\sum_ {h = \infty} ^ {\infty} | h | | K _ {X} (h) | <   \infty ,
$$

then for any collection of m frequencies $\omega _ { j } ^ { ( T ) }  \omega _ { j }$ , we have jointly that

$$
2 I (\omega_ {j} ^ {(T)}) / f (\omega_ {j}) \stackrel {d} {\to} \chi^ {2} (2)
$$

given that $f ( \omega _ { j } ) > 0$ for $j = 1 , \ldots , m$ .

Thus, we can use this result for many statistical applications like constructing a $1 - \alpha$ confidence interval for the spectral density $f _ { x }$ at some frequency $\omega$ by

$$
\frac {2 I (\omega_ {j} ^ {(T)})}{\chi_ {2 , 1 - \alpha / 2} ^ {2}} \leq f _ {X} (\omega) \leq \frac {2 I (\omega_ {j} ^ {(T)})}{\chi_ {2 , \alpha / 2} ^ {2}}.
$$

# 4.3.3 Banding, Tapering, Smoothing, and more

In the previous section, it is noted that the periodogram is a natural estimator for the spectral density. However, there are many aspects of such estimation to consider. In this section, we will consider methods of averaging, smoothing, banding, and tapering, which will, if used correctly, give us a better estimator for the spectral density. Ultimately, there is no one right way to estimate a given spectral density from some time series data. One must explore some of the following techniques as appropriate.

# Bartlett’s and Welch’s Methods

For a time series $X _ { 1 } , \ldots , X _ { T }$ , we are able to compute $I ( \omega _ { j } )$ for any frequency $\omega _ { j } =$ $j / T$ . However, such fine granularity is often not necessary. Instead, computing the periodogram for fewer frequencies with better accuracy is often preferrable.

Bartlett’s method take this into consideration by splitting the time series into $K$ separate disjoint series of equal length $m = T / K$ . That is,

$$
\left\{X _ {1}, \dots , X _ {K} \right\}, \left\{X _ {K + 1}, \dots , X _ {2 K} \right\}, \dots \left\{X _ {m K - m + 1}, \dots , X _ {T} \right\}.
$$

Then, for each of these $K$ time series pieces, we can compute periodograms $I ^ { ( 1 ) } ( \omega _ { j } ) , \ldots , I ^ { ( K ) } ( \omega _ { j } )$ and average them to get

$$
I (\omega_ {j}) = K ^ {- 1} \sum_ {i = 1} ^ {K} I ^ {(i)} (\omega_ {j}).
$$

In this case, we only have periodogram values for $\omega _ { j } = j / m$ for $j = 1 , \ldots , m$ . But the variance of the estimate decreases. It is also faster to compute as performing $K$ DFTs of size $m$ is faster than performing one DFT of size $m K = T$ .

Welch’s method is nearly identical to Bartlett’s method. However, this new approach allows for the time series to be partitioned into overlaping pieces that overlap by a fixed number of data point.

# Banding

Instead of partitioning in the time domain as Barlett’s method does, we can instead partition the frequencies into bands. In this case, we can define a frequency band of $2 m + 1$ frequencies to be

$$
\mathcal {B} = \left\{\omega : \omega_ {j} - \frac {m}{T} \leq \omega \leq \omega_ {j} + \frac {m}{T} \right\}.
$$

Here, we say that $( 2 m + 1 ) / T$ is the bandwidth of $\boldsymbol { B }$ . The idea is that if locally $f _ { X } ( \omega )$ is constant for all frequencies in the band $\boldsymbol { B }$ , then the spectal density can be estimated to be

$$
\bar {I} (\omega) = \frac {1}{2 m + 1} \sum_ {i = - m} ^ {m} I (\omega_ {j} + i / T)
$$

for any $\omega \in B$ . Considering the previous result that $2 I ( \omega _ { j } ^ { ( T ) } ) / f ( \omega _ { j } ) \stackrel { \mathrm { d } } {  } \chi ^ { 2 } ( 2 )$ , we have the extension that

$$
\frac {2 (2 m + 1) \bar {I} (\omega_ {j} ^ {(T)})}{f (\omega_ {j})} \stackrel {\mathrm {d}} {\rightarrow} \chi^ {2} (4 m - 4)
$$

as long as $T$ is large and $m$ is small. Note that there typically is no optimal bandwidth and many can be tried when analyzing a time series in the spectal domain.

The above notion of banding simply weights all frequencies in the band $\boldsymbol { B }$ equally, which is $1 / ( 2 m + 1 )$ . Instead, we can use a weighted average of the frequencies of the form

$$
\tilde {I} (\omega) = \sum_ {i = - m} ^ {m} c _ {i} I (\omega_ {j} + i / T)
$$

where the weights $c _ { i }$ sum to 1. The mathematically get convergence for this object to athat d dist that ore, we require that as . Then, it can be show $T \to \infty$ and $m \to \infty$ such $m / T \to 0$ $\Sigma _ { i = - m } ^ { m } c _ { i } ^ { 2 }  0$

$$
\begin{array}{l} \operatorname {E} \left[ \tilde {I} (\omega) \right] \quad \rightarrow f _ {X} (\omega) \\ \frac {\operatorname {c o v} \left(\tilde {I} (\omega_ {1}) , \tilde {I} (\omega_ {2})\right)}{\sum_ {i = - m} ^ {m} c _ {i} ^ {2}} \qquad \qquad \rightarrow \left\{\begin{array}{l l}0&\omega_ {1} \neq \omega_ {2}\\f _ {X} (\omega) ^ {2}&\omega_ {1} = \omega_ {2} \neq 0 \neq 1 / 2\\2 f _ {X} (\omega) ^ {2}&\omega_ {1} = \omega_ {2} = 0 \text {o r} = 1 / 2\end{array}\right. \\ \end{array}
$$

In this case, $\tilde { I }$ is asymptotically a weighted sum of chi-squared random variables which is hard to work with directly. Instead, we can approximate the “length” of the band by

$$
L = \left[ \sum_ {i = - m} ^ {m} c _ {i} ^ {2} \right] ^ {- 1}
$$

to get roughly that

$$
\frac {2 L \tilde {I} (\omega_ {j} ^ {(T)})}{f (\omega_ {j})} \stackrel {\mathrm {d}} {\to} \chi^ {2} (2 L).
$$

Note that this works perfectly if we replace $c _ { i }$ with $( 2 m + 1 ) ^ { - 1 }$ recovering the equally weighted scenario from above.

One way to choose specific weights is via the Daniell kernel. In this case, we begin simply with $c _ { i } = 1 / 3$ for $i = - 1 , 0 , 1$ . Applying this to a sequence $u _ { t }$ results in

$$
u _ {t} ^ {(1)} = \frac {u _ {t - 1}}{3} + \frac {u _ {t}}{3} + \frac {u _ {t + 1}}{3}.
$$

If we apply this kernel a second time, we get

$$
\begin{array}{l} u _ {t} ^ {(2)} = \frac {u _ {t - 1} ^ {(1)}}{3} + \frac {u _ {t} ^ {(1)}}{3} + \frac {u _ {t + 1} ^ {(1)}}{3} \\ = \frac {u _ {t - 2}}{9} + \frac {2 u _ {t - 1}}{9} + \frac {3 u _ {t}}{9} + \frac {2 u _ {t + 1}}{9} + \frac {u _ {t + 2}}{9}. \\ \end{array}
$$

Also, sometimes the modified Daniell kernel is applid, which is the same idea as above be starting with

$$
u _ {t} ^ {(1)} = \frac {u _ {t - 1}}{4} + \frac {u _ {t}}{2} + \frac {u _ {t + 1}}{4}.
$$

# Tapering

Tapering a time series is another way to focus in on estimating the spectral density for a certain range of frequencies. To discuss this, we begin in the time domain. For a mean zero stationary process $X _ { t }$ with spectral density $f _ { X } ( \omega )$ , we construct a tapered process with $Y _ { t } = a _ { t } X _ { t }$ for some coefficients $a _ { t }$ . Thus, the DFT for $Y _ { t }$ gives us

$$
d _ {Y} (\omega_ {j}) = \frac {1}{T ^ {1 / 2}} \sum_ {i = 1} ^ {T} a _ {t} X _ {t} \mathrm {e} ^ {- 2 \pi i \omega_ {j} t}.
$$

Then, the expected value of the periodogram is

$$
\operatorname {E} \left[ I _ {Y} (\omega_ {j}) \right] = \int_ {- 1 / 2} ^ {1 / 2} W _ {T} (\omega_ {j} - \omega) f _ {X} (\omega) d \omega
$$

$W _ { T } ( \Omega ) = | A _ { T } ( \omega ) | ^ { 2 }$ with $A _ { T } ( \omega ) = T ^ { - 1 / 2 } \sum _ { i = 1 } ^ { T } a _ { t } \mathrm { e } ^ { - 2 \pi i \omega t }$ . Here, we refer to $W _ { T } ( \omega )$

Example 4.3.1. The Fej´er or modified Bartlett kernel is

$$
W _ {T} (\omega) = \frac {\sin (n \pi \omega) ^ {2}}{n \sin (\pi \omega) ^ {2}}
$$

with $W _ { T } ( 0 ) ~ = ~ n$ , which comes from $a _ { t } ~ = ~ 1$ for all $t$ . When averaging over a band $\boldsymbol { B }$ as above, the spectral window is similarly averaged. That is, for $I ( \omega ) =$ 12m+1 Pi=−m I(ωj + i/T ), we have $\begin{array} { r } { \frac { 1 } { 2 m + 1 } \sum _ { i = - m } ^ { m } I ( \omega _ { j } + i / T ) } \end{array}$ m

$$
W _ {T} (\omega) = \frac {1}{2 m + 1} \sum_ {i = - m} ^ {m} \frac {\sin (n \pi (\omega + i / T)) ^ {2}}{n \sin (\pi (\omega + i / T)) ^ {2}}.
$$

Example 4.3.2. Other tapers that live up to the name “tapering” include the cosine taper, which sets the coefficients $a _ { t } = [ 1 + \cos ( 2 \pi ( t - ( T + 1 ) / 2 ) / T ) ] / 2$ .

# 4.3.4 Parametric Estimation

# 4.4 Filtering

# A Survey on Deep Learning based Time Series Analysis with Frequency Transformation

Kun Yi

kunyi.cn@gmail.com

State Information Center

Beijing, China

Longbing Cao

longbing.cao@mq.edu.au

Macquarie University

Sydney, Australia

Guodong Long

guodong.long@uts.edu.au

University of Technology Sydney

Sydney, Australia

Qi Zhang*

zhangqi_cs@tongji.edu.cn

Tongji University

Shanghai, China

Shoujin Wang

shoujin.wang@uts.edu.au

University of Technology Sydney

Sydney, Australia

Liang Hu

milkrain@gmail.com

Tongji University

Shanghai, China

Hui Xiong

xionghui@ust.hk

Hong Kong University of Science and

Technology (Guangzhou)

Guangzhou, China

Wei Fan*

wei.fan@auckland.ac.nz

University of Auckland

Auckland, New Zealand

Hui He

hehui617@bit.edu.cn

Beijing Institute of Technology

Beijing, China

Qingsong Wen

qingsongedu@gmail.com

Squirrel Ai Learning

Bellevue, USA

# Abstract

Recently, frequency transformation (FT) has been increasingly incorporated into deep learning models to signicantly enhance stateof-the-art accuracy and eciency in time series analysis. The advantages of FT, such as high eciency and a global view, have been rapidly explored and exploited in various time series tasks and applications, demonstrating the promising potential of FT as a new deep learning paradigm for time series analysis. Despite the growing attention and the proliferation of research in this emerging eld, there is currently a lack of a systematic review and in-depth analysis of deep learning-based time series models with FT. It is also unclear why FT can enhance time series analysis and what its limitations are in the eld. To address these gaps, we present a comprehensive review that systematically investigates and summarizes the recent research advancements in deep learning-based time series analysis with FT. Specically, we explore the primary approaches used in current models that incorporate FT, the types of neural networks that leverage FT, and the representative FTequipped models in deep time series analysis. We propose a novel

*Corresponding Author.

taxonomy to categorize the existing methods in this eld, providing a structured overview of the diverse approaches employed in incorporating FT into deep learning models for time series analysis. Finally, we highlight the advantages and limitations of FT for time series modeling and identify potential future research directions that can further contribute to the community of time series analysis.

# CCS Concepts

• Mathematics of computing Time series analysis.

# Keywords

Time Series Analysis; Deep Learning; Frequency Transformation

# ACM Reference Format:

Kun Yi, Qi Zhang*, Wei Fan*, Longbing Cao, Shoujin Wang, Hui He, Guodong Long, Liang Hu, Qingsong Wen, and Hui Xiong. 2025. A Survey on Deep Learning based Time Series Analysis with Frequency Transformation. In Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2 (KDD ’25), August 3–7, 2025, Toronto, ON, Canada. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3711896.3736571

# 1 Introduction

Time series data is amongst the most ubiquitous data types, and has penetrated nearly every corner of our daily life [14], e.g., user-item interaction series in e-commerce and stock price series over time in nance. In recent years, time series analysis has attracted rapidly increasing attention from academia and industry, particularly in areas such as time series forecasting [5], anomaly detection [15], and classication [22]. Time series analysis has played a critical role in a wide variety of real-world applications to address signicant challenges around us long-lastingly, such as trac monitoring [3,

![](images/a51d1401a21fe896125948b038ce924e7fae172246d7a662c150f786911c3e9e.jpg)  
Figure 1: Illustration of various working mechanisms applied to time series data. We take an example of four variables and 𝑇 timestamps, as shown in the left portion of the gure. (a) GNN constructs a graph connecting variables for each timestamp. (b) Self-attention builds temporal connections for each variable. (c) RNN creates a recursive cycle for capturing temporal transitions. (d) TCN consists of a stack of causal convolutional layers over timestamps.

78], nancial analysis [23, 24], and COVID-19 prediction [9, 28]. However, time series analysis is extremely challenging due to the intricate inter-series correlations and intra-series dependencies.

Previous time series models based on deep learning have been devoted to modeling complex intra- and inter-series dependencies in the time domain to enhance downstream tasks. Representative sequential models such as recurrent neural networks (RNNs) [30, 34], temporal convolutional networks (TCNs) [4], and attention networks [65] are utilized to capture intra-series dependencies, while convolutional networks such as convolutional neural networks (CNNs) [35] and graph neural networks (GNNs) [10] are preferred to attend to inter-series correlations. Although achieving good results, those networks have inherent drawbacks of time-domain modeling, limiting their capabilities in capturing critical patterns for time series analysis. For example, GNNs are constructed based on variablewise connections as illustrated in Fig. 1(a), and the sequential models (i.e., Transformer, RNN, and TCN) are based on timestamp-wise connections as shown in Fig. 1(b), (c), and (d), respectively. These modelings consider point-wise (e.g., variable/timestamp-wise) connections and fail to attend to whole or sub time series. Therefore, they are usually incapable of modeling common but complex global patterns, such as periodic patterns of seasonality, in time series [61, 73]. These inherent drawbacks inspire researchers to address the intricate inter-series correlations and intra-series dependencies of time series from a dierent perspective.

Recently, deep learning methods leveraging frequency transformation (FT) [46], e.g., Discrete Fourier Transform (DFT) [60], Discrete Cosine Transform (DCT) [1], and Discrete Wavelet Transform (DWT) [48], have gained a surge of interest within the machine learning community [12, 27, 67, 85]. These neural models incorporating frequency transformation have demonstrated an e- cient learning paradigm in time series analysis and achieved stateof-the-art performance in terms of both eciency and eectiveness [65, 79, 87]. This can be attributed to the distinctive advantages of FT (see Section 6.1) that the frequency spectrums generated by FT contain abundant vital patterns, e.g., seasonal trends, and provide a global view of the characteristics of time series. In addition, FT facilitates obtaining multi-scale representations and multi-frequency components of time series for capturing informative representations and patterns. This motivates us to systematically summarize and analyze the advantages of FT to instruct researchers in this area and to deliver a comprehensive survey on the emerging area,

i.e., deep learning based time series analysis with FT, thereby enlightening the time series community. While the literature includes various studies that discuss time series analysis from dierent perspectives [5, 8, 11, 19, 22, 37, 47, 56, 80], there remains a lack of comprehensive summaries on the topic of time series analysis with FT. Moreover, the reasons why FT can enhance the time series analysis have not yet been summarized, and its limitations have not been thoroughly analyzed. These gaps have hindered the theoretical development and practical applications of time series analysis with FT.

In this paper, we aim to ll the aforementioned gaps by reviewing existing deep learning methods for time series analysis with FT. Specically, our primary objective is to provide answers to four crucial perspectives: i) the strategies employed by current neural time series models in incorporating neural networks with FT; ii) the specic types of neural networks utilized in conjunction with FT; iii) the representative FT-equipped neural models commonly employed in time series applications; and iv) an exploration of the reasons behind FT to enhance neural models as well as an analysis of its limitations in the context of time series analysis. By addressing these questions, we provide valuable insights into the realm of neural time series analysis with FT. To the best of our knowledge, this paper is the rst work to comprehensively and systematically review neural time series analysis with FT and to propose a new taxonomy for this emerging area, as depicted in Fig. 2.

# 2 Preliminaries

# 2.1 Time Series Analysis

In this section, we provide a brief introduction to the four fundamental tasks of time series analysis before diving into neural time series analysis with Fourier Transform (FT).

2.1.1 Forecasting. Time series forecasting is the task of predicting future data points based on past observations [5]. Consider a dataset with $N$ dierent time series measured over $T$ time steps, represented as $\mathbf { X } = [ X _ { 1 } , X _ { 2 } , . . . , X _ { T } ] \in \mathbb { R } ^ { N \times T }$ , where each $X _ { t } \in \mathbb { R } ^ { N }$ captures the values of all series at time 𝑡. To make predictions at time $t$ , we use a window of past 𝐿 observations, $\mathbf { X } _ { t } = [ X _ { t - L + 1 } , . . . , X _ { t } ]$ , as input. The goal is to forecast the next $\tau$ values, denoted $\mathbf { Y } _ { t } = [ X _ { t + 1 } , . . . , X _ { t + \tau } ]$ . A forecasting model, $f _ { \theta }$ , learns to map $\mathbf { X } _ { t }$ to an estimate $\hat { \mathbf Y } _ { t } = f _ { \theta } ( \mathbf X _ { t } )$   
2.1.2 Classification. Time series classication aims to assign a categorical label to each time series in a dataset [22]. Formally, consider a dataset $D = \{ ( X _ { 1 } , Y _ { 1 } ) , ( X _ { 2 } , Y _ { 2 } ) , \ldots , ( X _ { N } , Y _ { N } ) \}$ , where each $X _ { i } \in \mathbb { R } ^ { T }$ represents a univariate time series with 𝑇 time steps, and $Y _ { i }$ is its associated one-hot encoded label. Assuming $D$ contains $K$ distinct classes, each label $Y _ { i } \in \mathbb { R } ^ { K }$ is a binary vector such that the $j$ -th element is 1 if $X _ { i }$ belongs to class $j$ , and 0 otherwise. The goal is to learn a classier $f _ { \theta }$ , parameterized by $\theta$ , that maps input time series to class probability distributions: $Y _ { i } = f _ { \theta } ( X _ { i } )$ .   
2.1.3 Anomaly Detection. Time series anomaly detection aims to identify abnormal patterns or subsequences within a temporal sequence [11]. The objective is to design models or algorithms capable of distinguishing between normal and anomalous behaviors, enabling early detection and timely alerts for unusual events. Given a time series $X ~ = ~ \left[ x _ { 1 } , x _ { 2 } , \dots , x _ { T } \right]$ with $T$ timestamps, where $x _ { i }$

![](images/e1397a11f486a450222f2b32cccddaf2c90ed16a3b1193a7660867c2719ef2a2.jpg)  
Figure 2: A taxonomy of deep learning based time series analysis with frequency transformation.

denotes the observation at time 𝑖, the task is to identify a subset $X _ { s } \subseteq X$ corresponding to anomalous data points that deviate signicantly from expected temporal patterns.

2.1.4 Imputation. Time series imputation is the task of estimating missing values in a partially observed time series. Formally, let $X = [ x _ { 1 } , \ldots , x _ { T } ] \in \mathbb { R } ^ { T }$ denote the observed series (possibly with missing entries), and let $M \in \{ 0 , 1 \} ^ { T }$ be a binary mask such that $m _ { t } = 0$ indicates a missing value at index $t$ , and $m _ { t } = 1$ indicates an observed value. The goal is to recover a complete time series $\hat { X } \ = \ [ \hat { x } _ { 1 } , . . . , \hat { x } _ { T } ] \ \in \ \mathbb { R } ^ { \hat { T } }$ that approximates the underlying true series while lling in the unobserved entries. A typical imputation model $f _ { \theta }$ (parameterized by $\theta$ ) maps the partially observed data and mask to the reconstructed output, $\hat { X } = f _ { \theta } ( X , M )$ , such that $\hat { x } _ { t } \approx x _ { t }$ for all observed entries and $\hat { x } _ { t }$ is inferred for missing ones.

# 2.2 Frequency Transformation

In this section, we briey introduce commonly used frequency transformation that converts time-domain data into the frequency domain, including Discrete Fourier Transform (DFT), Discrete Cosine Transform (DCT), and Discrete Wavelet Transform (DWT). Additionally, we describe the convolution theorem, which is a fundamental property in the frequency domain.

2.2.1 Discrete Fourier Transform. Discrete Fourier Transform (DFT) plays an important role in the area of digital signal processing. Given a sequence $x [ n ]$ with the length of N, DFT converts $x [ n ]$ into the frequency domain by:

$$
\mathcal {X} [ k ] = \sum_ {n = 0} ^ {N - 1} x [ n ] e ^ {- j (2 \pi / N) k n}, s. t., k = 0, 1, \dots , N - 1 \tag {1}
$$

where $j$ is the imaginary unit and $X [ k ]$ represents the spectrum of $x [ n ]$ at the frequency $\omega _ { k } = 2 \pi \boldsymbol { k } / N$ . The spectrum $\boldsymbol { \chi } \in \mathbb { C } ^ { k }$ consists

of real parts $\begin{array} { r } { \mathrm { R e } = \sum _ { n = 0 } ^ { N - 1 } x [ n ] } \end{array}$ cos $( 2 \pi / N ) k n \in \mathbb { R } ^ { k }$ and imaginary parts $\begin{array} { r } { \mathrm { I m } = - \sum _ { n = 0 } ^ { N - 1 } x [ n ] } \end{array}$ sin $( 2 \pi / N ) k n \in \mathbb { R } ^ { k }$ as:

$$
\mathcal {X} = \operatorname {R e} + j \operatorname {I m}. \tag {2}
$$

The amplitude part $A$ and phase part $\theta$ of $\chi$ is dened as:

$$
A = \sqrt {\operatorname {R e} ^ {2} + \operatorname {I m} ^ {2}}. \tag {3}
$$

$$
\theta = \arctan \left(\frac {\operatorname {I m}}{\operatorname {R e}}\right). \tag {4}
$$

2.2.2 Discrete Cosine Transform. Discrete Cosine Transform (DCT) has emerged as the de-facto image transformation in most visual systems. The most common 1-D DCT $C ( k )$ of a data sequence $x [ n ]$ is dened as:

$$
C (k) = \alpha (k) \sum_ {n = 0} ^ {N - 1} x [ n ] \cos \left[ \frac {\pi (2 n + 1) k}{2 N} \right] \tag {5}
$$

where $k = 0 , 1 , . . . , N - 1$ , and $\alpha ( k )$ is dened as:

$$
\alpha (k) = \left\{ \begin{array}{l l} \sqrt {\frac {1}{N}}, f o r & k = 0 \\ \sqrt {\frac {2}{N}}, f o r & k \neq 0 \end{array} \right. \tag {6}
$$

DCT only retains the real parts of DFT, and often performs on real data with even symmetry or in some variants where the input or output data are shifted by half a sample.

2.2.3 Discrete Wavelet Transform. Discrete Wavelet Transform (DWT) has been shown to be an appropriate tool for time-frequency analysis. It decomposes a given signal into a number of sets in which each set is a time series of coecients describing the time evolution of the signal in the corresponding frequency band.

For a signal $x ( t )$ , the wavelet transform WT can be expressed as $\begin{array} { r } { \mathrm { W T } ( a , b ) = \int _ { - \infty } ^ { \infty } x ( t ) \Psi _ { a , b } ( t ) \mathrm { d } t = \left. x ( t ) , \Psi _ { a , b } ( t ) \right. } \end{array}$ where $\Psi$ is the −∞wavelet basis function. The basis generation can be dened by

Table 1: Comparison of DFT, DCT, and DWT for time series analysis.   

<table><tr><td>FT</td><td>Basis Function</td><td>Value Type</td><td>Time-Frequency</td><td>Pros</td><td>Cons</td></tr><tr><td>DFT</td><td>Sine+Cosine</td><td>Complex</td><td>No</td><td>Shift-invariant</td><td>Leakage effect Lack of time localization</td></tr><tr><td>DCT</td><td>Cosine</td><td>Real</td><td>No</td><td>Computationally efficient</td><td>No phase information Lack of time localization</td></tr><tr><td>DWT</td><td>Wavelet</td><td>Real</td><td>Yes</td><td>Multi-resolution analysis Localization in time and frequency</td><td>Computation complexity</td></tr></table>

$\begin{array} { r } { \Psi _ { a , b } ( t ) = \frac { 1 } { \sqrt { a } } \Psi \left( \frac { t - b } { a } \right) } \end{array}$ where $a$ and $^ { b }$ are the scaling and translation factors respectively. DWT discretizes the scale factor a and the translation factor b as $a = a _ { 0 } ^ { m } , b = k a _ { 0 } ^ { m } b _ { 0 } , m , k \in \mathbb { Z }$ $a = a _ { 0 } ^ { m }$ . Typically, $a _ { 0 }$ is set to 2, and $b _ { 0 }$ is set to 1. Accordingly, the DWT can be dened as:

$$
\mathrm {D W T} (a, b) = a _ {0} ^ {- m / 2} \int_ {- \infty} ^ {\infty} x (t) \Psi \left(a _ {0} ^ {- m} t - k b _ {0}\right) (t) \mathrm {d} t. \tag {7}
$$

In contrast to DFT and DCT, DWT has the ability to identify the locations containing observed frequency content, while the DFT and DCT can only extract pure frequencies from the signal. Hence, DWT can perform time-frequency analysis. In addition, DWT can obtain dierent resolution representations [39] by changing the scaling and translation factors. In Table 1, we compare the three frequency transformation methods, including their pros and cons.

2.2.4 Convolution Theorem. The convolution theorem [49] states that the Fourier transform of a circular convolution of two signals equals the point-wise product of their Fourier transforms. Given a signal $x [ n ]$ and a lter $h [ n ]$ , the convolution theorem can be dened as follows:

$$
\mathcal {F} (x [ n ] * h [ n ]) = \mathcal {F} (x) \mathcal {F} (h) \tag {8}
$$

$\begin{array} { r } { x [ n ] * h [ n ] = \sum _ { m = 0 } ^ { N - 1 } h [ m ] x [ ( n - m ) _ { N } ] } \end{array}$ $( n - m ) _ { N }$ denotes Fourier $( n - m )$ $\mathcal { F } ( x )$ ${ \mathcal { F } } ( h )$ transform of $x [ n ]$ and $h [ n ]$ , respectively.

According to the Convolution Theorem, the point-wise multiplication of the frequency spectra of two sequences corresponds to their circular convolution in the time domain. This operation, which inherently spans the entire sequence, enables more eective capture of global patterns such as periodicity, while also reducing computational cost [2].

# 3 Incorporation Approach

In this section, we present a systematic summary and discussion of the research categorization and progress regarding incorporating the frequency transformation to enhance time series analysis.

# 3.1 Feature Engineering

Previous works employ frequency transformation (DFT, DCT, and DWT) as feature engineering tools to obtain frequency domain patterns. Basically, they utilize frequency transformation to capture three primary types of information: periodic patterns, multi-scale patterns, and global dependencies.

Periodicity. Compared to the time domain, the frequency domain can provide vital information for time series, such as periodic information. Prior models take advantage of frequency domain information for periodic analysis and use it as an important complement to the time domain information. ATFN [73] proposes a

frequency-domain block to capture dynamic and complicated periodic patterns of time series data, and integrates deep learning networks with frequency patterns. TFAD [79] utilizes a frequency domain analysis branch to detect complex pattern anomalies, e.g., periodic anomalies. CoST [61] learns the trend representations in the time domain, whereas the seasonal representations are learned by a Fourier layer in the frequency domain. FreDo [50] is a frequency domain-based neural network model that is built on top of the baseline model to enhance its performance. ETSformer [62] utilized DFT to design a frequency attention mechanism to replace the self-attention mechanism to identify seasonal patterns. Deep-Time [63] leverages a novel concatenated Fourier features module to eciently learn high-frequency patterns in time series.

Multi-Scale. One big challenge for time series analysis is that there are intricate entangled temporal dynamics among time series data. To address this challenge, some methods try to solve it in terms of the frequency domain. They disentangle temporal patterns by decomposing time series data into dierent frequency components. SFM [29] separates the memory states of RNN into dierent frequency states such that they can explicitly learn the dependencies of both the low- and high-frequency patterns. [81] explicitly decomposes trading patterns into various frequency components and each component models a particular frequency of latent trading pattern underlying the uctuation of stock price. Recently, wavelet-based models have shown competitive performances since wavelet transform can retain both time and frequency information and obtain multi-resolution representations. [54] proposes a wavelet-based neural network structure for building frequency-aware deep learning models for time series analysis. [58] applies maximal overlap discrete wavelet transform to decouple time series into multiple levels of wavelet coecients and then detect single periodicity at each level. [55] devises a novel data-dependent wavelet attention mechanism for dynamic frequency analysis of non-stationary time series analysis. [69] proposes an end-to-end graph enhanced Wavelet learning framework for long sequence forecasting which utilizes DWT to represent MTS in the wavelet domain.

Global Dependencies. Existing time domain methods construct their models based on point-wise connections (see Fig. 1), which prevent them from capturing series-level patterns, such as overall characteristics of time series. By leveraging the global view property of the frequency domain, some works utilize frequency information to attend to series-level patterns. FEDformer [87] combines Fourier analysis with the Transformer which helps the Transformer better capture the global properties of time series. TFAD [79] integrates the frequency domain analysis branch with the time domain analysis branch and detects seasonality anomalies in the frequency domain. Besides, some works introduce frequency domain analysis to improve neural networks in order to address their inherent drawbacks. Vanilla convolutions in modern deep networks are known to operate locally, which causes low ecacy in connecting two distant locations in the network. To mitigate the locality limitation of convolutions, SRL [13] converts data into the frequency domain and proposes spectral residual learning for achieving a fully global receptive eld, and FFC [12] harnesses the Fourier spectral theory and designs an operation unit to leverage frequency information for enlarging the receptive eld of vanilla convolutions.

# 3.2 Compression

Previous works utilize frequency transformation to obtain sparse representations and remove redundant information in the frequency domain. Moreover, since noise signals usually appear as high frequencies, it is easy to lter them out in the frequency domain. For example, in FiLM [86], authors view time series forecasting from the sequence compression perspective and apply Fourier analysis to keep the part of the representation related to low-frequency Fourier components to remove the impact of noises. [45] proposes spectral pooling that performs dimensionality reduction by truncating the representation in the frequency domain because energy is heavily concentrated in the lower frequencies. [67] proposes a learning-based frequency selection method to identify the trivial frequency components while removing redundant information.

# 3.3 Data Augmentation

Recently, a few studies have investigated data augmentation from a frequency domain perspective for time series [59]. Since the frequency domain contains some vital information for time series analysis, such as periodic patterns, existing methods incorporate frequency domain features with time domain features for data augmentations with the aim of enhancing time series representations. For example, CoST [61] incorporates a novel frequency domain contrastive loss which encourages discriminative seasonal representations and sidesteps the issue of determining the period of seasonal patterns present in the time series data. BTSF [70] fuses the temporal and spectral features to enhance the discriminativity and expressiveness of the representations. TS-TFC [38] proposes a temporal-frequency co-training model for time-series semi-supervised learning, utilizing the complementary information from two distinct views for unlabeled data learning.

More recently, dierent from CoST and BTSF that apply DFT after augmenting samples in the time domain, one new approach named TF-C [82] introduces frequency domain augmentations that directly perturb the frequency spectrum. It develops frequencybased contrastive augmentation to leverage rich spectral information and directly perturbs the frequency spectrum to leverage frequency-invariance for contrastive learning. Compared to performing data augmentations directly in the frequency domain (e.g., TF-C), applying the FFT after augmenting samples in the time domain (e.g., CoST and BTSF) may lead to information loss.

# 3.4 Fourier Neural Operator Learning

According to the convolution theorem, dierentiation is equivalent to multiplication in the Fourier domain [36]. This eciency property makes DFT frequently used to solve dierential equations.

Recently, Fourier Neural Operators (FNOs) [36], which is currently the most promising one of the neural operators [33], have been proposed as an eective framework to solve partial dierential equations (PDEs). More recently, FNO has been introduced in time series forecasting. FEDformer [87] proposes Fourier-enhanced blocks and Wavelet-enhanced blocks to capture important structures in time series through frequency domain mapping. FourierGNN [76] reformulates the graph convolution operator in the frequency domain and eciently computes graph convolutions over a hypervariate graph which represents the high-resolution correlations between any two variables at any two timestamps.

# 4 Neural Network Design

In this section, we delve deeper into existing related models that utilize specic types of neural networks to leverage frequency information. Considering that frequency transformation outputs can be either complex values or real values (as shown in Table 1), and each value type requires distinct handling methods, we discuss the models from the perspectives of these two value types.

# 4.1 Complex-Value Data

The DFT output values are complex and can be represented in two ways. One representation is through the real and imaginary parts (as shown in Equation (2)), while the other representation is through the amplitude and phase parts (as depicted in Equations (3) and (4)). While it is possible to simplify the calculation by retaining only one part, such as discarding the imaginary components [26], this approach may result in information loss.

In fact, there are two main approaches for performing neural networks on complex values. One approach is to treat each part of the complex value as a feature and then feed them to neural networks, respectively. Afterward, the output of corresponding networks is combined as a complex type (e.g., like Equation (2)), and then the inverse DFT is executed and transmitted to the time domain. For example, StemGNN [6] conducts GLU [16] on real and imaginary parts, respectively, which concatenates them as a complex value and applies IDFT. ATFN [73] utilizes two linear layers to process the amplitude and phase parts, respectively, and then combines them as a whole. The other is to conduct complex multiplication in the frequency domain directly. FEDformer [87] randomly samples a few frequencies and conducts complex multiplication with a parameterized kernel incorporated with attention architecture.

# 4.2 Real-Value Data

The output value type of DCT and DWT is real, hence commonly used network structures can be directly applied to them. For instance, DEPTS [21] performs DCT and can be seamlessly integrated with an MLP to process the output parameters of DCT. Although the output value type of DFT is complex, some work discards one part, such as the phase part [81], making their network design eectively real-valued. Additionally, some methods just apply ltering in the frequency domain and transform back to the time domain, resulting in network designs that also belong to real-valued networks.

Except for capturing frequency patterns, in contrast to other network designs, one main purpose of network design for frequencybased models is the frequency component selection to decide which component is discriminative or critical. For example, RobustPeriod [58] applies DWT to decouple time series into multiple levels of wavelet coecients and then proposes a method to robustly calculate unbiased wavelet variance at each level and rank periodic possibilities. TimesNet [64] selects the top- $k$ amplitude values while discarding the remaining ones. FAN [74] decomposes frequency components into non-stationary and stationary parts and employs specialized network modules for each.

# 5 Applications

In this section, we review the representative FT-equipped neural time series models. We categorize them into four main applications: forecasting, anomaly detection, classication, and imputation. In Table 2, we further compare them from six dimensions.

Table 2: Summary of representative FT-equipped deep learning models in time series analysis.   

<table><tr><td>Models</td><td>Frequency Transformation</td><td>Incorporation Approach</td><td>Value Type</td><td>Neural Network</td><td>Application Domains</td><td>Leveraged Advantages</td></tr><tr><td>SFM [81]</td><td>DFT</td><td>Feature engineering</td><td>Real-value</td><td>RNN</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>StemGNN [6]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>GLU</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>Autoformer [65]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>Transformer</td><td>Forecasting</td><td>Global view Efficiency</td></tr><tr><td>DEPTS [21]</td><td>DCT</td><td>Feature engineering</td><td>Real-value</td><td>MLP</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>FEDformer [87]</td><td>DFT</td><td>Feature engineering Operator learning</td><td>Complex-value</td><td>Transformer</td><td>Forecasting</td><td>Global view Efficiency</td></tr><tr><td>CoST [61]</td><td>DFT</td><td>Data augmentation</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>FiLM [86]</td><td>DFT</td><td>Compression</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Sparse Representation</td></tr><tr><td>WAVEFORM [69]</td><td>DWT</td><td>Feature engineering</td><td>Real-value</td><td>GCN</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>FourierGNN [76]</td><td>DFT</td><td>Operator learning</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Efficiency</td></tr><tr><td>FreTS [77]</td><td>DFT</td><td>Operator learning</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Global view</td></tr><tr><td>FilterNet [75]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>FreDF [52]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>MLP</td><td>Forecasting</td><td>Decomposition</td></tr><tr><td>SR-CNN [44]</td><td>DFT</td><td>Feature engineering</td><td>Real-value</td><td>CNN</td><td>Anomaly Detection</td><td>Decomposition</td></tr><tr><td>RobustTAD [25]</td><td>DFT</td><td>Data augmentation</td><td>Complex-value</td><td>CNN</td><td>Anomaly Detection</td><td>Decomposition</td></tr><tr><td>TFAD [79]</td><td>DWT</td><td>Feature engineering</td><td>Real-value</td><td>TCN</td><td>Anomaly Detection</td><td>Decomposition</td></tr><tr><td>FITS [68]</td><td>DFT</td><td>Compression</td><td>Complex-value</td><td>MLP</td><td>Forecasting Anomaly Detection</td><td>Sparse Representation</td></tr><tr><td>RCF [54]</td><td>DWT</td><td>Feature engineering</td><td>Real-value</td><td>CNN</td><td>Classification</td><td>Decomposition</td></tr><tr><td>WD [32]</td><td>DWT</td><td>Feature engineering</td><td>Real-value</td><td>CNN</td><td>Classification</td><td>Decomposition</td></tr><tr><td>BTSF [70]</td><td>DFT</td><td>Data augmentation</td><td>Real-value</td><td>CNN</td><td>Classification Forecasting</td><td>Decomposition</td></tr><tr><td>TF-C [82]</td><td>DFT</td><td>Data augmentation</td><td>Real-value</td><td>Transformer</td><td>Classification Classification</td><td>Decomposition</td></tr><tr><td>TimesNet [64]</td><td>DFT</td><td>Feature engineering</td><td>Real-value</td><td>CNN</td><td>Forecasting Anomaly Detection Imputation</td><td>Decomposition</td></tr><tr><td>FGTI [72]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>Transformer</td><td>Imputation</td><td>Decomposition</td></tr><tr><td>PSW-I [53]</td><td>DFT</td><td>Feature engineering</td><td>Complex-value</td><td>MLP</td><td>Imputation</td><td>Decomposition</td></tr></table>

# 5.1 Time Series Forecasting

Time series forecasting is essential in various domains, such as decision making and nancial analysis. Recently, some methods leverage frequency information to improve the accuracy or e- ciency of time series forecasting. SFM [81] decomposes the hidden states of memory cells into multiple frequency components and models multi-frequency trading patterns. StemGNN [6] learns spectral representations which are easier to recognize after DFT. Autoformer [65] leverages FFT to calculate auto-correlation eciently. DEPTS [21] conducts DCT to extract periodic features and then

applies multi-layer perceptrons to these features for periodicity dependencies in time series. FEDformer [87] captures the global view of time series in the frequency domain. CoST [61] learns the seasonal representations in the frequency domain. FiLM [86] utilizes Fourier analysis to keep low-frequency Fourier components. DeRiTS [20] and FAN [74] address the non-stationary issues for time series forecasting from the frequency spectrum perspective. FreDF [52] mitigates label correlation by learning to forecast in the frequency domain, thereby reducing estimation bias.

# 5.2 Time Series Anomaly Detection

Recently, frequency-based models have been introduced in anomaly detection. RobustTAD [25] explores the data augmentation methods in the frequency domain to further increase labeled data. TFAD [79] takes advantage of frequency domain analysis for seasonality anomaly. MACE [7] introduces a pattern extraction mechanism that exploits the inherent sparsity of the frequency domain to improve the model’s generalization across diverse normal patterns. CATCH [66] patchifys the frequency domain into distinct frequency bands, and adaptively discover channel correlation across frequency bands to eectively detect both point and subsequence anomalies. FCVAE [57] integrates global and local frequency features to capture long-periodic heterogeneous patterns and ne-grained shortperiodic trends, enabling eective unsupervised anomaly detection in univariate time series. TSAD [41] employs nested sliding windows, where the outer and inner windows correspond to the time and frequency domains to bridge the discrepancy between time and frequency representations.

# 5.3 Time Series Classication

Time series classication is an important and challenging problem in time series analysis. Recently, a few models have considered frequency domain information to perform this task. RCF [54] extracts distinguishing features from the DWT decomposed results. WD [32] uses wavelet functions with adjustable scale parameters to learn the spectral decomposition directly from the signal. BTSF [70] fuses time and spectral information to enhance the discriminativity and expressiveness of the representations. TF-C [82] develops frequency-based contrastive augmentation to leverage rich spectral information and explore time-frequency consistency in time series. TSLANet [18] leverages the power of Fourier transform alongside global and local lters to cover the whole frequency spectrum, while adaptively removing high frequencies that tend to introduce noises.

# 5.4 Time Series Imputation

Time series imputation refers to the process of lling in missing values in a time-dependent dataset. FGTI [72] employs a frequencyaware diusion model that uses high-frequency lters for residual imputation and dominant-frequency lters for trend and seasonal renement. PSW-I [53] This work presents a novel Proximal Spectrum Wasserstein (PSW) discrepancy, which integrates pairwise spectral distance and selective matching regularization to accurately quantify distributional discrepancies between two sets of time series, specically tailored for the imputation task. Both methods incorporate frequency technology to enhance the accuracy of imputations by addressing dierent components of the time series.

# 6 Summary of Frequency Transformation

In this section, to investigate why FT can enhance the neural models and its limitations for time series analysis, we summarize the advantages and limitations of frequency transformation.

# 6.1 Advantages

Decomposition. Frequency transformation can decompose the original time series into dierent frequency components that embody vital time series information, such as periodic patterns of seasonality. In particular, DWT can decompose a time series into

a group of sub-series with frequencies ranked from high to low and obtain multi-scale representations. By decomposing time series in the time domain into dierent components in the frequency domain, it is naturally helpful to gure out and obtain benecial information for time series analysis.

Global View. According to Equations (1), (5), and (7), a frequency spectrum is calculated through the summation of all signals over time. Accordingly, each spectrum element in the frequency domain attends to all timestamps in the time domain, illustrating that a spectrum has a global view of the whole sequence of time series. In addition, according to the convolution theorem (see Equation (8)), the point-wise product of frequency spectrums also captures the global characteristics of the whole sequence, inspiring to parameterize global learnable lters in the frequency domain.

Sparse Representation. Frequency transformation enables the provision of sparse representations for sequences. Taking DFT as an example, a substantial number of coecients are close to zero, indicating that we can employ a reduced number of coecients to represent the entire sequence. In other words, the corresponding representations in the frequency domain have a property of energy compaction. For example, the important features of signals captured by a subset of DWT coecients are typically much smaller than the original. Specically, using DWT, it ends up with the same number of coecients as the original signal where many of the coecients may be close to zero. As a result, we can eectively represent the original signal using only a small number of non-zero coecients.

Eciency. As mentioned earlier, frequency transformation often leads to sparse representations, where a substantial number of coecients are close to zero. Exploiting this sparsity allows for ecient computations by discarding or compressing the negligible coecients, resulting in reduced memory requirements and faster processing. Moreover, according to the convolution theorem, convolution in the time domain corresponds to Hadamard’s point-wise product in the frequency domain, which allows for convolution to be calculated more eciently in the frequency domain. Therefore, considering the equivalence of the convolution theorem, convolution calculated in the frequency domain involves signicantly fewer computational operations.

# 6.2 Limitations

Loss of temporal information. Frequency transformation techniques, including DFT and DCT, primarily emphasize capturing the frequency characteristics of a time series. While these techniques oer valuable insights into the frequency domain, they may overlook or inadequately represent temporal information [71]. Certain temporal patterns or dynamics inherent in time series may not be fully captured in the frequency domain, thereby limiting the comprehensive analysis and understanding of temporal aspects [26].

Dependence on pre-dened parameters. Frequency transformation techniques often require setting parameters, such as window size, sampling rate, or frequency bands. Selecting appropriate parameter values can be challenging, and suboptimal choices may lead to inaccurate frequency representations or missing important frequency components [32, 40]. Accordingly, parameter tuning and

optimization are necessary to ensure the eectiveness of frequency transformation in time series analysis.

# 7 Discussion for Future Opportunities

In this section, we explore the prospects for future research in neural time series analysis with frequency transformation. We begin by outlining the current limitations of frequency transformation and propose innovative directions to overcome these challenges. Subsequently, we delve into open research issues and emerging trends in the eld of time series analysis that can be addressed through the utilization of frequency transformations.

# 7.1 The Perspective of Frequency Transformation

7.1.1 Leveraging New Orthogonal Transform Technology. Recent studies have shown the eciency and eectiveness of orthogonal transform which serves as a plug-in operation in neural networks, including frequency analysis and polynomial family. Some new orthogonal transform technologies have been introduced in neural networks and achieved good results. For example, [42, 43] propose the Partial Fourier Transform (PFT), an ecient and accurate algorithm designed to compute only a subset of Fourier coecients, rather than the full spectrum. The Fractional Fourier transform (FrFT) has been proven to be desirable for noise removal and can enhance the discrimination between anomalies and background [51]. In [83], the authors utilize FrFT to enhance ecient feature fusion and comprehensive feature extraction. [84] leverages FrFT to enable exible extraction of global contexts and sequential spectral information. In the future, it would be a promising direction to incorporate more new orthogonal transform technologies for deep learning in time series analysis, such as FrFT.

7.1.2 Integrating Frequency Transformation with Deep Learning. The basis functions used in frequency transformation, such as sine, cosine, and wavelet functions, are xed across dierent domains. As a result, the frequency features extracted through these basis functions are domain-invariant. In other words, the features are insensitive to unexpected noise or to changing conditions. Few previous works combine frequency transformation with the learning ability of neural networks. [32] proposes a method to eciently optimize the parameters of the spectral decomposition based on the wavelet transform in a neural network framework. [40] mimics the fast DWT cascade architecture utilizing the deep learning framework. These methods have shown promising performances, and in the future, the combination of frequency transformation with deep learning deserves further investigation.

7.1.3 Jointly Learning in the Time and Frequency Domain. The frequency domain only uses periodic components, and thus cannot accurately model the non-periodic aspects of a signal, such as a linear trend [26]. Moreover, according to the uncertainty principle [79], designing a model with a single structure that can capture the time and frequency patterns simultaneously is dicult. As a result, in the future, an interesting direction is to take advantage of corresponding characteristics of learning in the time and frequency domain to improve the accuracy and eciency of time series analysis. Few works have tried to learn representations in the time and frequency domain, respectively. More time-frequency representation learning methods are required in the future.

# 7.2 The Perspective of Time Series Analysis

7.2.1 Applying Frequency Transformation to Enhance Time Series Applications. Applying frequency transformation techniques to a broader range of time series applications has the potential to unlock valuable insights and enhance decision-making in various domains. No matter in detecting anomalies in physiological signals, uncovering market cycles in nancial data, or identifying patterns in environmental parameters, frequency transformation enables a deeper understanding of complex temporal patterns and trends. By harnessing the power of frequency analysis, researchers and practitioners can uncover hidden relationships, improve forecasting accuracy, optimize resource management, and advance knowledge in diverse elds, ultimately driving innovation and enabling datadriven decision-making in a wide range of time series applications.

7.2.2 Scalability. Scalability [31] is a key consideration in time series analysis. When coupled with frequency transformation techniques, it oers the potential for ecient and scalable analysis of large-scale time series data. Frequency transformation allows for the extraction of frequency components, reducing the dimensionality of the data and enabling more ecient processing. This dimensionality reduction can signicantly improve the scalability of time series analysis algorithms, as it reduces computational complexity and memory requirements. Scalable time series analysis with frequency transformation can pave the way for analyzing and extracting insights from big data time series applications in domains such as the Internet of Things (IoT), nancial markets, or sensor networks.

7.2.3 Privacy-preserving. Leveraging frequency transformation offers a powerful approach to data privacy-preserving [17] in time series analysis. By applying frequency transformation, time series data can be transformed into frequency domain representations without revealing the underlying raw data. This transformation allows for the extraction of frequency components and patterns while maintaining the condentiality of the original information. Privacypreserving with frequency transformation techniques can ensure individual privacy and data condentiality, and enable collaborative analysis, data sharing, and research collaborations while mitigating privacy risks. This approach is particularly valuable in domains where data sensitivity is critical, such as healthcare, nance, or personal monitoring, allowing for the utilization of frequency analysis while protecting the privacy of individuals or organizations.

# 8 Conclusion

In this paper, we present a comprehensive survey on deep learning based time series analysis methods that leverage frequency transformation. We organize the reviewed methods from the perspectives of incorporation approaches, neural network design, and application domains, and we summarize the advantages and limitations of frequency transformation for time series analysis. To the best of our knowledge, this is the rst systematic and in-depth review focused specically on neural time series analysis with frequency transformation, aiming to provide valuable insights for the research community. To support further exploration, we also provide a curated repository of related resources, available at https: //github.com/aikunyi/time_series_frequency.

# Acknowledgments

This project is funded by the State Grid Corporation of China headquarters science and technology project "Research on the optimization technology and platform of the company’s natural monopoly business and competitive business operation based on social information" (Project No. 52180025000C-194-ZN).

# References

[1] Nasir Ahmed, T_ Natarajan, and Kamisetty R Rao. 1974. Discrete cosine transform. IEEE transactions on Computers 100, 1 (1974), 90–93.   
[2] Ahmed M. Alaa, Alex James Chan, and Mihaela van der Schaar. 2021. Generative Time-series Modeling with Fourier Flows. In ICLR. OpenReview.net.   
[3] Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020. Adaptive Graph Convolutional Recurrent Network for Trac Forecasting. In NeurIPS.   
[4] Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. 2018. An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. CoRR abs/1803.01271 (2018).   
[5] Konstantinos Benidis, Syama Sundar Rangapuram, Valentin Flunkert, Yuyang Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider, David Salinas, Lorenzo Stella, Franç ois-Xavier Aubet, Laurent Callot, and Tim Januschowski. 2022. Deep Learning for Time Series Forecasting: Tutorial and Literature Survey. Comput. Surveys 55 (2022).   
[6] Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, and Qi Zhang. 2020. Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting. In NeurIPS.   
[7] Feiyi Chen, Yingying Zhang, Zhen Qin, Lunting Fan, Renhe Jiang, Yuxuan Liang, Qingsong Wen, and Shuiguang Deng. 2024. Learning Multi-Pattern Normalities in the Frequency Domain for Ecient Time Series Anomaly Detection. In ICDE. IEEE, 747–760.   
[8] Irene Y. Chen, Rahul G. Krishnan, and David A. Sontag. 2022. Clustering Interval-Censored Time-Series for Disease Phenotyping. In AAAI. AAAI Press, 6211–6221.   
[9] Yuzhou Chen, Ignacio Segovia-Dominguez, Baris Coskunuzer, and Yulia Gel. 2022. TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting. In ICLR.   
[10] Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, and Xiuzhen Cheng. 2022. Learning Graph Structures With Transformer for Multivariate Time-Series Anomaly Detection in IoT. IEEE Internet Things J. 9, 12 (2022), 9179–9189.   
[11] Zhipeng Chen, Zhang Peng, Xueqiang Zou, and Haoqi Sun. 2021. Deep Learning Based Anomaly Detection for Muti-dimensional Time Series: A Survey. In CNCERT (Communications in Computer and Information Science, Vol. 1506). Springer, 71–92.   
[12] Lu Chi, Borui Jiang, and Yadong Mu. 2020. Fast Fourier Convolution. In NeurIPS.   
[13] Lu Chi, Guiyu Tian, Yadong Mu, Lingxi Xie, and Qi Tian. 2019. Fast Non-Local Neural Networks with Spectral Residual Learning. In ACM Multimedia. ACM, 2142–2151.   
[14] Fatoumata Dama and Christine Sinoquet. 2021. Analysis and modeling to forecast in time series: a systematic review. CoRR abs/2104.00164 (2021).   
[15] Zahra Zamanzadeh Darban, Georey I. Webb, Shirui Pan, Charu C. Aggarwal, and Mahsa Salehi. 2022. Deep Learning for Time Series Anomaly Detection: A Survey. CoRR abs/2211.05244 (2022).   
[16] Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. 2017. Language Modeling with Gated Convolutional Networks. In ICML (Proceedings of Machine Learning Research, Vol. 70). PMLR, 933–941.   
[17] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. 2016. Calibrating Noise to Sensitivity in Private Data Analysis. J. Priv. Condentiality 7, 3 (2016), 17–51.   
[18] Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, and Xiaoli Li. 2024. TSLANet: Rethinking Transformers for Time Series Representation Learning. In ICML. OpenReview.net.   
[19] Amin Fakhrazari and Hamid Vakilzadian. 2017. A survey on time series data mining. In EIT. IEEE, 476–481.   
[20] Wei Fan, Kun Yi, Hangting Ye, Zhiyuan Ning, Qi Zhang, and Ning An. 2024. Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting. In IJCAI. ijcai.org, 3944–3952.   
[21] Wei Fan, Shun Zheng, Xiaohan Yi, Wei Cao, Yanjie Fu, Jiang Bian, and Tie-Yan Liu. 2022. DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting. In ICLR. OpenReview.net.   
[22] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller. 2019. Deep learning for time series classication: a review. Data Min. Knowl. Discov. 33, 4 (2019), 917–963.   
[23] Jingru Fei, Kun Yi, Wei Fan, Qi Zhang, and Zhendong Niu. 2025. Amplier: Bringing Attention to Neglected Low-Energy Components in Time Series Forecasting.

In AAAI. AAAI Press, 11645–11653.   
[24] Fuli Feng, Xiangnan He, Xiang Wang, Cheng Luo, Yiqun Liu, and Tat-Seng Chua. 2019. Temporal Relational Ranking for Stock Prediction. ACM Trans. Inf. Syst. 37, 2 (2019), 27:1–27:30.   
[25] Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, and Huan Xu. 2020. RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks. CoRR abs/2002.09545 (2020).   
[26] Luke B. Godfrey and Michael S. Gashler. 2018. Neural Decomposition of Time-Series Data for Eective Generalization. IEEE Trans. Neural Networks Learn. Syst. 29, 7 (2018), 2973–2985.   
[27] John Guibas, Morteza Mardani, Zongyi Li, Andrew Tao, Anima Anandkumar, and Bryan Catanzaro. 2022. Adaptive Fourier Neural Operators: Ecient Token Mixers for Transformers. In ICLR.   
[29] Hao Hu and Guo-Jun Qi. 2017. State-Frequency Memory Recurrent Neural Networks. In ICML (Proceedings of Machine Learning Research, Vol. 70). PMLR, 1568–1577.   
[30] Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Söderström. 2018. Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. In KDD. ACM, 387–395.   
[31] Eamonn J. Keogh and Shruti Kasetty. 2003. On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration. Data Min. Knowl. Discov. 7, 4 (2003), 349–371.   
[32] Haidar Khan and Bülent Yener. 2018. Learning lter widths of spectral decompositions with wavelets. In NeurIPS. 4606–4617.   
[33] Nikola B. Kovachki, Zongyi Li, Burigede Liu, Kamyar Azizzadenesheli, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar. 2021. Neural Operator: Learning Maps Between Function Spaces. CoRR abs/2108.08481 (2021).   
[34] Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu. 2018. Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks. In SIGIR. 95–104.   
[35] Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diusion Convolutional Recurrent Neural Network: Data-Driven Trac Forecasting. In ICLR (Poster).   
[36] Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew M. Stuart, and Anima Anandkumar. 2021. Fourier Neural Operator for Parametric Partial Dierential Equations. In ICLR.   
[37] Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, and Qingsong Wen. 2024. Foundation Models for Time Series Analysis: A Tutorial and Survey. In KDD. ACM, 6555–6565.   
[38] Zhen Liu, Qianli Ma, Peitian Ma, and Linghao Wang. 2023. Temporal-Frequency Co-training for Time Series Semi-supervised Learning. In AAAI. AAAI Press, 8923–8931.   
[39] Stéphane Mallat. 1989. A Theory for Multiresolution Signal Decomposition: The Wavelet Representation. IEEE Trans. Pattern Anal. Mach. Intell. 11, 7 (1989), 674–693.   
[40] Gabriel Michau, Gaetan Frusque, and Olga Fink. 2022. Fully learnable deep wavelet transform for unsupervised monitoring of high-frequency time series. Proceedings of the National Academy of Sciences 119, 8 (2022).   
[41] Youngeun Nam, Susik Yoon, Yooju Shin, Minyoung Bae, Hwanjun Song, Jae-Gil Lee, and Byung Suk Lee. 2024. Breaking the Time-Frequency Granularity Discrepancy in Time-Series Anomaly Detection. In WWW. ACM, 4204–4215.   
[42] Yong-chan Park, Jun-Gi Jang, and U Kang. 2021. Fast and Accurate Partial Fourier Transform for Time Series Data. In KDD. ACM, 1309–1318.   
[43] Yong-chan Park, Jongjin Kim, and U Kang. 2024. Fast Multidimensional Partial Fourier Transform with Automatic Hyperparameter Selection. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (Barcelona, Spain) (KDD ’24). Association for Computing Machinery, New York, NY, USA, 2328–2339. doi:10.1145/3637528.3671667   
[44] Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-Series Anomaly Detection Service at Microsoft. In KDD. ACM, 3009–3017.   
[45] Oren Rippel, Jasper Snoek, and Ryan P. Adams. 2015. Spectral Representations for Convolutional Neural Networks. In NIPS. 2449–2457.   
[46] Richard A Roberts and Cliord T Mullis. 1987. Digital signal processing. Addison-Wesley Longman Publishing Co., Inc.   
[47] Patrick Schäfer, Arik Ermshaus, and Ulf Leser. 2021. ClaSP - Time Series Segmentation. In CIKM. ACM, 1578–1587.   
[48] Mark J Shensa et al. 1992. The discrete wavelet transform: wedding the a trous and Mallat algorithms. IEEE Transactions on signal processing 40, 10 (1992), 2464–2482.   
[49] S. S. Soliman and MD Srinath. 1990. Continuous and discrete signals and systems. Prentice Hall, (1990).   
[50] Fan-Keng Sun and Duane S. Boning. 2022. FreDo: Frequency Domain-based Long-Term Time Series Forecasting. CoRR abs/2205.12301 (2022).

[51] Ran Tao, Xudong Zhao, Wei Li, Heng-Chao Li, and Qian Du. 2019. Hyperspectral Anomaly Detection by Fractional Fourier Entropy. IEEE J. Sel. Top. Appl. Earth Obs. Remote. Sens. 12, 12 (2019), 4920–4929.   
[52] Hao Wang, Lichen Pan, Yuan Shen, Zhichao Chen, Degui Yang, Yifei Yang, Sen Zhang, Xinggao Liu, Haoxuan Li, and Dacheng Tao. 2025. FreDF: Learning to Forecast in the Frequency Domain. In The Thirteenth International Conference on Learning Representations. https://openreview.net/forum?id=4A9IdSa1ul   
[53] Hao Wang, zhengnan li, Haoxuan Li, Xu Chen, Mingming Gong, BinChen, and Zhichao Chen. 2025. Optimal Transport for Time Series Imputation. In The Thirteenth International Conference on Learning Representations. https: //openreview.net/forum?id=xPTzjpIQNp   
[54] Jingyuan Wang, Ze Wang, Jianfeng Li, and Junjie Wu. 2018. Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis. In KDD. ACM, 2437–2446.   
[55] Jingyuan Wang, Chen Yang, Xiaohan Jiang, and Junjie Wu. 2023. WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis. In KDD. ACM, 2361–2373.   
[56] Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Mingsheng Long, and Jianmin Wang. 2024. Deep Time Series Models: A Comprehensive Survey and Benchmark. CoRR abs/2407.13278 (2024).   
[57] Zexin Wang, Changhua Pei, Minghua Ma, Xin Wang, Zhihan Li, Dan Pei, Saravan Rajmohan, Dongmei Zhang, Qingwei Lin, Haiming Zhang, Jianhui Li, and Gaogang Xie. 2024. Revisiting VAE for Unsupervised Time Series Anomaly Detection: A Frequency Perspective. In WWW. ACM, 3096–3105.   
[58] Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, and Huan Xu. 2021. RobustPeriod: Robust Time-Frequency Mining for Multiple Periodicity Detection. In SIGMOD Conference. ACM, 2328–2337.   
[59] Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue Wang, and Huan Xu. 2021. Time Series Data Augmentation for Deep Learning: A Survey. In IJCAI. ijcai.org, 4653–4660.   
[60] Shmuel Winograd. 1976. On computing the discrete Fourier transform. Proceedings of the National Academy of Sciences 73, 4 (1976), 1005–1006.   
[61] Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven C. H. Hoi. 2022. CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting. In ICLR. OpenReview.net.   
[62] Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven C. H. Hoi. 2022. ETSformer: Exponential Smoothing Transformers for Time-series Forecasting. CoRR abs/2202.01381 (2022).   
[63] Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven C. H. Hoi. 2023. Learning Deep Time-index Models for Time Series Forecasting. In ICML (Proceedings of Machine Learning Research, Vol. 202). PMLR, 37217–37237.   
[64] Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. 2023. TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis. In ICLR. OpenReview.net.   
[65] Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021. Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting. In NeurIPS. 22419–22430.   
[66] Xingjian Wu, Xiangfei Qiu, Zhengyu Li, Yihang Wang, Jilin Hu, Chenjuan Guo, Hui Xiong, and Bin Yang. 2025. CATCH: Channel-Aware Multivariate Time Series Anomaly Detection via Frequency Patching. In The Thirteenth International Conference on Learning Representations. https://openreview.net/forum?id= m08aK3xxdJ   
[67] Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, and Fengbo Ren. 2020. Learning in the Frequency Domain. In CVPR. 1737–1746.   
[68] Zhijian Xu, Ailing Zeng, and Qiang Xu. 2024. FITS: Modeling Time Series with $\$ 10 k9$ Parameters. In The Twelfth International Conference on Learning Representations. https://openreview.net/forum?id=bWcnvZ3qMb   
[69] Fuhao Yang, Xin Li, Min Wang, Hongyu Zang, Wei Pang, and Mingzhong Wang. 2023. WaveForM: Graph Enhanced Wavelet Learning for Long Sequence Forecasting of Multivariate Time Series. In AAAI. AAAI Press, 10754–10761.   
[70] Ling Yang and Shenda Hong. 2022. Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion. In ICML (Proceedings of Machine Learning Research, Vol. 162). PMLR, 25038–25054.   
[71] Runze Yang, Longbing Cao, JIE YANG, et al. 2024. Rethinking Fourier Transform from A Basis Functions Perspective for Long-term Time Series Forecasting. Advances in Neural Information Processing Systems 37 (2024), 8515–8540.   
[72] Xinyu Yang, Yu Sun, Xiaojie Yuan, and Xinyang Chen. 2024. Frequency-aware Generative Models for Multivariate Time Series Imputation. In NeurIPS.   
[73] Zhangjing Yang, Weiwu Yan, Xiaolin Huang, and Lin Mei. 2022. Adaptive Temporal-Frequency Network for Time-Series Forecasting. IEEE Trans. Knowl. Data Eng. 34, 4 (2022), 1576–1587.   
[74] Weiwei Ye, Songgaojun Deng, Qiaosha Zou, and Ning Gui. 2024. Frequency Adaptive Normalization For Non-stationary Time Series Forecasting. In The Thirty-eighth Annual Conference on Neural Information Processing Systems.   
[75] Kun Yi, Jingru Fei, Qi Zhang, Hui He, Shufeng Hao, Defu Lian, and Wei Fan. 2024. Filternet: Harnessing frequency lters for time series forecasting. Advances in Neural Information Processing Systems 37 (2024), 55115–55140.

[76] Kun Yi, Qi Zhang, Wei Fan, Hui He, Liang Hu, Pengyang Wang, Ning An, Longbing Cao, and Zhendong Niu. 2023. FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective. In NeurIPS.   
[77] Kun Yi, Qi Zhang, Wei Fan, Shoujin Wang, Pengyang Wang, Hui He, Ning An, Defu Lian, Longbing Cao, and Zhendong Niu. 2023. Frequency-domain mlps are more eective learners in time series forecasting. Advances in Neural Information Processing Systems 36 (2023), 76656–76679.   
[78] Kun Yi, Qi Zhang, Hui He, Kaize Shi, Liang Hu, Ning An, and Zhendong Niu. 2024. Deep Coupling Network for Multivariate Time Series Forecasting. ACM Trans. Inf. Syst. 42, 5 (2024), 127:1–127:28.   
[79] Chaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun. 2022. TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis. In CIKM. ACM, 2497–2507.   
[80] Kexin Zhang, Qingsong Wen, Chaoli Zhang, Rongyao Cai, Ming Jin, Yong Liu, James Y. Zhang, Yuxuan Liang, Guansong Pang, Dongjin Song, and Shirui Pan. 2024. Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects. IEEE Trans. Pattern Anal. Mach. Intell. 46, 10 (2024), 6775–6794.   
[81] Liheng Zhang, Charu C. Aggarwal, and Guo-Jun Qi. 2017. Stock Price Prediction via Discovering Multi-Frequency Trading Patterns. In KDD. ACM, 2141–2149.   
[82] Xiang Zhang, Ziyuan Zhao, Theodoros Tsiligkaridis, and Marinka Zitnik. 2022. Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency. In NeurIPS.   
[83] Xudong Zhao, Ran Tao, Wei Li, Wilfried Philips, and Wenzhi Liao. 2022. Fractional Gabor Convolutional Network for Multisource Remote Sensing Data Classication. IEEE Trans. Geosci. Remote. Sens. 60 (2022), 1–18.   
[84] Xudong Zhao, Mengmeng Zhang, Ran Tao, Wei Li, Wenzhi Liao, Lianfang Tian, and Wilfried Philips. 2022. Fractional Fourier Image Transformer for Multimodal Remote Sensing Data Classication. IEEE Trans. Neural Networks Learn. Syst. (2022), 1–13.   
[85] Kun Zhou, Hui Yu, Wayne Xin Zhao, and Ji-Rong Wen. 2022. Filter-enhanced MLP is All You Need for Sequential Recommendation. In WWW. 2388–2399.   
[86] Tian Zhou, Ziqing Ma, Xue Wang, Qingsong Wen, Liang Sun, Tao Yao, Wotao Yin, and Rong Jin. 2022. FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting. In NeurIPS.   
[87] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. 2022. FEDformer: Frequency enhanced decomposed transformer for long-term series forecasting. In ICML.