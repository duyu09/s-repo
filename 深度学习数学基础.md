# 线性代数

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 标量, 向量, 矩阵, 张量

1. 标量 (Scalar): 表⽰⼀个单独的数，通常⽤斜体⼩写字母表⽰，如 $s \in \mathbb { R } , n \in \mathbb { N } _ { \circ }$   
2. 向量 (Vector)：表⽰一列数，这些数有序排列的，可以通过下标获取对应值，通常⽤粗体⼩写字母表⽰： $\pmb { x } \in \mathbb { R } ^ { n }$ ，它表⽰元素取实数，且有 $n$ 个元素，第⼀个元素表⽰为： $x _ { 1 }$ 。将向量写成列向量的形式：

$$
\boldsymbol {x} = \left[ \begin{array}{l} x _ {1} \\ x _ {2} \\ \dots \\ x _ {n} \end{array} \right] \tag {1}
$$

有时需要向量的⼦集，例如第 1, 3, 6 个元素，那么我们可以令集合 $S = \{ 1 , 3 , 6 \}$ ，然后⽤ $\mathbf { \Omega } _ { \mathbf { \mathcal { X } } \mathbf { \Omega } } \mathbf { \Omega } _ { \mathbf { \mathcal { S } } }$ 来表⽰这个⼦集。另外，我们⽤符号 - 表⽰集合的补集： ${ \pmb x } _ { - 1 }$ 表⽰除 $x _ { 1 }$ 外 $_ { \pmb { x } }$ 中的所有元素， ${ \pmb x } _ { - S }$ 表⽰除 $x _ { 1 } , x _ { 3 } , x _ { 6 }$ 外 $_ { \pmb { x } }$ 中的所有元素。  
3. 矩阵 (Matrix): 表⽰⼀个二维数组，每个元素的下标由两个数字确定，通常⽤⼤写粗体字母表⽰： $\pmb { A } \in \mathbb { R } ^ { m \times n }$ ，它表⽰元素取实数的 $m$ ⾏ $n$ 列矩阵，其元素可以表⽰为： $A _ { 1 , 1 } , A _ { m , n }$ 。我们⽤ : 表⽰矩阵的⼀⾏或者⼀列： $A _ { i , }$ ,: 为第 $i$ ⾏， $A _ { : , j }$ 为第 $j$ 列。

矩阵可以写成这样的形式：

$$
\left[ \begin{array}{l l} A _ {1, 1} & A _ {1, 2} \\ A _ {2, 1} & A _ {2, 2} \end{array} \right] \tag {2}
$$

有时我们需要对矩阵进⾏逐元素操作，如将函数 $f$ 应⽤到 $\pmb { A }$ 的所有元素上，此时我们⽤ $f ( A ) _ { i , j }$ 表⽰。

4. 张量 (Tensor): 超过二维的数组，我们⽤ A 表⽰张量， $\mathsf { A } _ { i , j , k }$ 表⽰其元素（三维张量情况下）。

[1]: import numpy as np

```python
[2]: #s = 5#v = np.array([1,2])#m = np.array([[1,2]，[3,4]])#t = np.array([[1,2,3],[4,5,6],[7,8,9]],[[11,12,13],[14,15,16],[17,18,19]],[[21,22,23],[24,25,26],[27,28,29]],])print("：" + str(s))print("：" + str(v))print("：" + str(m))print("：" + str(t)) 
```

: 5

: [1 2]

: [[1 2]

[3 4]]

: [[[ 1 2 3]

[ 4 5 6]

[ 7 8 9]]

[[11 12 13]

[14 15 16]

[17 18 19]]

```txt
[[21 22 23]  
[24 25 26]  
[27 28 29]] 
```

# 2 矩阵转置

矩阵转置 (Transpose) 相当于沿着对角线翻转，定义如下：

$$
A _ {i, j} ^ {\top} = A _ {i, j} \tag {3}
$$

矩阵转置的转置等于矩阵本⾝：

$$
\left(\boldsymbol {A} ^ {\top}\right) ^ {\top} = \boldsymbol {A} \tag {4}
$$

转置将矩阵的形状从 $m \times n$ 变成了 $n \times m$ 。

向量可以看成是只有一列的矩阵，为了⽅便，我们可以使⽤⾏向量加转置的操作，如： $\pmb { x } = [ x _ { 1 } , x _ { 2 } , x _ { 3 } ] ^ { \top }$ 。

标量也可以看成是一行一列的矩阵，其转置等于它⾃⾝： $a ^ { \textsf { T } } = a$ 。

```python
[3]: A = np.array([[1.0,2.0],[1.0,0.0],[2.0,3.0]])
A_t = A.transpose()
print("A:", A)
print("A:", A_t) 
```

A: [[1. 2.]

[1. 0.]

[2. 3.]]

A : [[1. 1. 2.]

[2. 0. 3.]]

# 3 矩阵加法

加法即对应元素相加，要求两个矩阵的形状⼀样：

$$
C = A + B, C _ {i, j} = A _ {i, j} + B _ {i, j} \tag {5}
$$

数乘即一个标量与矩阵每个元素相乘：

$$
\boldsymbol {D} = a \cdot \boldsymbol {B} + c, D _ {i, j} = a \cdot B _ {i, j} + c \tag {6}
$$

有时我们允许矩阵和向量相加的，得到⼀个矩阵，把 b 加到了 $A$ 的每⼀⾏上，本质上是构造了⼀个将 b 按⾏复制的⼀个新矩阵，这种机制叫做⼴播 (Broadcasting)：

$$
\boldsymbol {C} = \boldsymbol {A} + \boldsymbol {b}, C _ {i, j} = A _ {i, j} + b _ {j} \tag {7}
$$

```python
[4]: a = np.array([[1.0,2.0],[3.0,4.0]]) b = np.array([[6.0,7.0],[8.0,9.0]]) print(" ", a + b) 
```

[[ 7. 9.]

[11. 13.]]

# 4 矩阵乘法

两个矩阵相乘得到第三个矩阵，我们需要 A 的形状为 $m \times n$ ， $\textbf {  { B } }$ 的形状为 $n \times p$ ，得到的矩阵为 $C$ 的形状为 $m \times p$ ：

$$
C = A B \tag {8}
$$

具体定义为

$$
C _ {i, j} = \sum_ {k} A _ {i, k} B _ {k, j} \tag {9}
$$

注意矩阵乘法不是元素对应相乘，元素对应相乘又叫 Hadamard 乘积，记作 ${ \pmb A } \odot { \pmb B }$ 。

向量可以看作是列为 1 的矩阵，两个相同维数的向量 $_ { \pmb { x } }$ 和 $\textbf {  { y } }$ 的点乘（Dot Product）或者内积，可以表⽰为 $\boldsymbol { x } ^ { \top } \boldsymbol { y }$ 。

我们也可以把矩阵乘法理解为： $C _ { i , j }$ 表⽰ $\pmb { A }$ 的第 $i$ ⾏与 $\textbf {  { B } }$ 的第 $j$ 列的点积。

```python
[5]: m1 = np.array([[1.0,3.0],[1.0,0.0]])
m2 = np.array([[1.0,2.0],[5.0,0.0]])
print(" ", np.dot(m1, m2))
print(" ", npmultiply(m1, m2))
print(" ", m1*m2)
v1 = np.array([1.0,2.0])
v2 = np.array([4.0,5.0])
print(" ", np.dot(v1, v2)) 
```

[[16. 2.]

[ 1. 2.]]

[[1. 6.]

[5. 0.]]

[[1. 6.]

[5. 0.]]

14.0

# 5 单位矩阵

为了引⼊矩阵的逆，我们需要先定义单位矩阵 (Identity Matrix)：单位矩阵乘以任意⼀个向量等于这个向量本⾝。记 ${ { I } _ { n } }$ 为保持 $n$ 维向量不变的单位矩阵，即：

$$
\boldsymbol {I} _ {n} \in \mathbb {R} ^ {n \times n}, \forall \boldsymbol {x} \in \mathbb {R} ^ {n}, \boldsymbol {I} _ {n} \boldsymbol {x} = \boldsymbol {x} \tag {10}
$$

单位矩阵的结构⼗分简单，所有的对⾓元素都为 1 ，其他元素都为 0，如：

$$
\boldsymbol {I} _ {3} = \left[ \begin{array}{l l l} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{array} \right] \tag {11}
$$

[6]: np.identity(3)

[6]: array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])

# 6 矩阵的逆

矩阵 $\pmb { A }$ 的逆 (Inversion) 记作 $A ^ { - 1 }$ ，定义为⼀个矩阵使得

$$
\boldsymbol {A} ^ {- 1} \boldsymbol {A} = \boldsymbol {I} _ {n} \tag {12}
$$

如果 $A ^ { - 1 }$ 存在，那么线性⽅程组 $\boldsymbol { A } \boldsymbol { x } = \boldsymbol { b }$ 的解为：

$$
\boldsymbol {A} ^ {- 1} \boldsymbol {A} \boldsymbol {x} = \boldsymbol {I} _ {n} \boldsymbol {x} = \boldsymbol {x} = \boldsymbol {A} ^ {- 1} \boldsymbol {b} \tag {13}
$$

[7]: A = [[1.0,2.0],[3.0,4.0]] A_inv $=$ np.linalg.inv(A) print("A ", A_inv)

A [[-2. 1. ]

[ 1.5 -0.5]]

# 7 范数

通常我们⽤范数 (norm) 来衡量向量，向量的 $L ^ { p }$ 范数定义为：

$$
\left\| \boldsymbol {x} \right\| _ {p} = \left(\sum_ {i} \left| x _ {i} \right| ^ {p}\right) ^ {\frac {1}{p}}, p \in \mathbb {R}, p \geq 1 \tag {14}
$$

$L ^ { 2 }$ 范数，也称欧⼏⾥得范数 (Euclidean norm)，是向量 $_ { \pmb { x } }$ 到原点的欧几里得距离。有时也⽤ $L ^ { 2 }$ 范数的平⽅来衡量向量： ${ \pmb x } ^ { \top } { \pmb x }$ 。事实上，平⽅ $L ^ { 2 }$ 范数在计算上更为便利，例如它的对 $_ { \pmb { x } }$ 梯度的各个分量只依赖于 $_ { \pmb { x } }$ 的对应的各个分量，⽽ $L ^ { 2 }$ 范数对 $_ { \pmb { x } }$ 梯度的各个分量要依赖于整个 $_ { \pmb { x } }$ 向量。

$L ^ { 1 }$ 范数： $L ^ { 2 }$ 范数并不⼀定适⽤于所有的情况，它在原点附近的增长就⼗分缓慢，因此不适⽤于需要区别 0 和⾮常⼩但是⾮ 0 值的情况。 $L ^ { 1 }$ 范数就是⼀个⽐较好的选择，它在所有⽅向上的增长速率都是⼀样的，定义为：

$$
\left\| \boldsymbol {x} \right\| _ {1} = \sum_ {i} \left| x _ {i} \right| \tag {15}
$$

它经常使⽤在需要区分 0 和非 0 元素的情形中。

$L ^ { 0 }$ 范数：如果需要衡量向量中⾮ 0 元素的个数，但它并不是一个范数 (不满⾜三⾓不等式和数乘)，此时 $L ^ { 1 }$ 范数可以作为它的⼀个替代。

$L ^ { \infty }$ 范数：它在数学上是向量元素绝对值的最⼤值，因此也被叫做 (Max norm)：

$$
\left\| \boldsymbol {x} \right\| _ {\infty} = \max  _ {i} \left| x _ {i} \right| \tag {16}
$$

有时我们想衡量⼀个矩阵，机器学习中通常使⽤的是 F 范数 (Frobenius norm)，其定义为：

$$
\| \boldsymbol {A} \| _ {F} = \sqrt {\sum_ {i , j} A _ {i , j} ^ {2}} \tag {17}
$$

```python
[8]: a = np.array([1.0,3.0])  
print(" 2 ", np.linalg.norm(a,ord=2))  
print(" 1 ", np.linalg.norm(a,ord=1))  
print(" ", np.linalg.norm(a,ord=np.inf)) 
```

```csv
2 3.1622776601683795  
1 4.0  
3.0 
```

```python
[9]: a = np.array([[1.0,3.0],[2.0,1.0]])
print(" F ", np.linalg.norm(a,ord="fro")) 
```

```txt
F 3.872983346207417 
```

# 8 特征值分解

如果⼀个 $n \times n$ 矩阵 $\pmb { A }$ 有 $n$ 组线性⽆关的单位特征向量 $\{ \pmb { v } ^ { ( 1 ) } , \ldots , \pmb { v } ^ { ( n ) } \}$ ，以及对应的特征值 $\lambda _ { 1 } , \ldots , \lambda _ { n }$ 。将这些特征向量按列拼接成⼀个矩阵：$V = [ \pmb { v } ^ { ( 1 ) } , \dots , \pmb { v } ^ { ( n ) } ]$ ，并将对应的特征值拼接成⼀个向量： $\pmb { \lambda } = [ \lambda _ { 1 } , \dots , \lambda _ { n } ]$ 。

$\pmb { A }$ 的特征值分解 (Eigendecomposition) 为：

$$
\boldsymbol {A} = \boldsymbol {V} \operatorname {d i a g} (\boldsymbol {\lambda}) \boldsymbol {V} ^ {- 1} \tag {18}
$$

注意：

• 不是所有的矩阵都有特征值分解  
• 在某些情况下，实矩阵的特征值分解可能会得到复矩阵

```python
[10]: A = np.array([[1.0,2.0,3.0], [4.0,5.0,6.0], [7.0,8.0,9.0]])
# print(":", np.linalg.eigvals(A))
# eigvals,eigvectors = np.linalg.eig(A)
print(":", eigvals)
print(":", eigvectors) 
```

```json
: [ 1.61168440e+01 -1.11684397e+00 -3.73313677e-16] 
```

```json
: [ 1.61168440e+01 -1.11684397e+00 -3.73313677e-16] 
```

```json
: [[-0.23197069 -0.78583024 0.40824829] 
```

```json
[-0.52532209 -0.08675134 -0.81649658] 
```

```json
[-0.8186735 0.61232756 0.40824829]] 
```

# 9 奇异值分解

奇异值分解 (Singular Value Decomposition, SVD) 提供了另⼀种分解矩阵的⽅式，将其分解为奇异向量和奇异值。

与特征值分解相⽐，奇异值分解更加通⽤，所有的实矩阵都可以进⾏奇异值分解，⽽特征值分解只对某些⽅阵可以。

奇异值分解的形式为：

$$
\boldsymbol {A} = \boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top} \tag {19}
$$

若 $\pmb { A }$ 是 $m \times n$ 的，那么 $U$ 是 $m \times m$ 的，其列向量称为左奇异向量，⽽ $V$ 是 $n \times n$ 的，其列向量称为右奇异向量，⽽ $\pmb { \Sigma }$ 是 $m \times n$ 的⼀个对⾓矩阵，其对⾓元素称为矩阵 $\pmb { A }$ 的奇异值。

事实上，左奇异向量是 $A A ^ { \top }$ 的特征向量，⽽右奇异向量是 $A ^ { \top } A$ 的特征向量，⾮ 0 奇异值的平⽅是 $A ^ { \top } A$ 的⾮ 0 特征值。

```python
[11]: A = np.array([[1.0,2.0,3.0], [4.0,5.0,6.0]]) U,D,V = np.linalg.svd(A) print("U:", U) print("D:", D) print("V:", V) 
```

```json
U: [[-0.3863177 -0.92236578] [-0.92236578 0.3863177 ]]  
D: [9.508032 0.77286964]  
V: [[-0.42866713 -0.56630692 -0.7039467 ] [0.80596391 0.11238241 -0.58119908] [0.40824829 -0.81649658 0.40824829]] 
```

# 10 PCA (主成分分析)

假设我们有 $m$ 个数据点 $\pmb { x } ^ { ( 1 ) } , \dots , \pmb { x } ^ { ( m ) } \in \mathbb { R } ^ { n }$ ，对于每个数据点 $\pmb { x } ^ { ( i ) }$ ，我们希望找到⼀个对应的点 $\pmb { c } ^ { ( i ) } \in \mathbb { R } ^ { l } , l < n$ 去表⽰它 (相当于对它进⾏降维)，并且让损失的信息量尽可能少。

我们可以将这个过程看作是⼀个编码解码的过程，设编码和解码函数分别为 $f , g$ ，则有 $f ( \pmb { x } ) = c , \pmb { x } \approx g ( f ( \pmb { x } ) )$ 。考虑⼀个线性解码函数 $g ( \pmb { c } ) =$ $D c , D \in \mathbb { R } ^ { n \times l }$ ，为了计算⽅便，我们将这个矩阵的列向量约束为相互正交的。另⼀⽅⾯，考虑到存在尺度放缩的问题，我们将这个矩阵的列向量约束为具有单位范数来获得唯⼀解。

对于给定的 $_ { \pmb { x } }$ ，我们需要找到信息损失最⼩的 $c ^ { \star }$ ，即求解：

$$
\boldsymbol {c} ^ {\star} = \arg \min  _ {\boldsymbol {c}} \| \boldsymbol {x} - g (\boldsymbol {c}) \| _ {2} = \arg \min  _ {\boldsymbol {c}} \| \boldsymbol {x} - g (\boldsymbol {c}) \| _ {2} ^ {2} \tag {20}
$$

这⾥我们⽤⼆范数来衡量信息的损失。展开之后我们有：

$$
\left\| \boldsymbol {x} - g (\boldsymbol {c}) \right\| _ {2} ^ {2} = \left(\boldsymbol {x} - g (\boldsymbol {c})\right) ^ {\top} \left(\boldsymbol {x} - g (\boldsymbol {c})\right) = \boldsymbol {x} ^ {\top} \boldsymbol {x} - 2 \boldsymbol {x} ^ {\top} g (\boldsymbol {c}) + g (\boldsymbol {c}) ^ {\top} g (\boldsymbol {c}) \tag {21}
$$

结合 $g ( c )$ 的表达式，忽略不依赖 $^ c$ 的 ${ \pmb x } ^ { \top } { \pmb x }$ 项，我们有：

$$
\begin{array}{l} \boldsymbol {c} ^ {\star} = \arg \min  _ {\boldsymbol {c}} - 2 \boldsymbol {x} ^ {\top} \boldsymbol {D} \boldsymbol {c} + \boldsymbol {c} ^ {\top} \boldsymbol {D} ^ {\top} \boldsymbol {D} \boldsymbol {c} \\ = \arg \min  _ {\boldsymbol {c}} - 2 \boldsymbol {x} ^ {\top} \boldsymbol {D} \boldsymbol {c} + \boldsymbol {c} ^ {\top} \boldsymbol {I} _ {l} \boldsymbol {c} \tag {22} \\ = \arg \min _ {\boldsymbol {c}} - 2 \boldsymbol {x} ^ {\top} \boldsymbol {D} \boldsymbol {c} + \boldsymbol {c} ^ {\top} \boldsymbol {c} \\ \end{array}
$$

这⾥ $\pmb { D }$ 具有单位正交性。

对 $^ c$ 求梯度，并令其为零，我们有：

$$
\begin{array}{l} \nabla_ {c} \left(- 2 \boldsymbol {x} ^ {\top} \boldsymbol {D} \boldsymbol {c} + \boldsymbol {c} ^ {\top} \boldsymbol {c}\right) = \boldsymbol {0} \\ - 2 D ^ {\top} \boldsymbol {x} + 2 c = 0 \tag {23} \\ \boldsymbol {c} = \boldsymbol {D} ^ {\top} \boldsymbol {x} \\ \end{array}
$$

因此，我们的编码函数为：

$$
f (\boldsymbol {x}) = \boldsymbol {D} ^ {\top} \boldsymbol {x} \tag {24}
$$

此时通过编码解码得到的重构为：

$$
r (\boldsymbol {x}) = g (f (\boldsymbol {x})) = \boldsymbol {D} \boldsymbol {D} ^ {\top} \boldsymbol {x} \tag {25}
$$

接下来求解最优的变换 $_ { D }$ 。由于我们需要将 $_ { D }$ 应⽤到所有的 $\mathbf { \nabla } _ { \mathbf { x } _ { i } }$ 上，所以我们需要最优化：

$$
\boldsymbol {D} ^ {\star} = \arg \min  _ {\boldsymbol {D}} \sqrt {\sum_ {i , j} \left(\boldsymbol {x} _ {j} ^ {(i)} - r \left(\boldsymbol {x} ^ {(i)}\right) _ {j}\right) ^ {2}} \tag {26}
$$

$$
s. t. D ^ {\top} D = I _ {l}
$$

为了⽅便，我们考虑 $l = 1$ 的情况，此时问题简化为：

$$
\boldsymbol {d} ^ {\star} = \arg \min  _ {\boldsymbol {d}} \sum_ {i} \left(\boldsymbol {x} _ {j} ^ {(i)} - \boldsymbol {d} \boldsymbol {d} ^ {\top} \boldsymbol {x} ^ {(i)}\right) ^ {2} \tag {27}
$$

$$
s. t. \boldsymbol {d} ^ {\top} \boldsymbol {d} = 1
$$

考虑 F 范数，并进⼀步的推导：

$$
\boldsymbol {d} ^ {\star} = \underset {\boldsymbol {d}} {\arg \max } \operatorname {T r} \left(\boldsymbol {d} ^ {\top} \boldsymbol {X} ^ {\top} \boldsymbol {X} \boldsymbol {d}\right) \tag {28}
$$

$$
s. t. \boldsymbol {d} ^ {\top} \boldsymbol {d} = 1
$$

优化问题可以⽤特征分解来求解。但实际计算时，我们会采⽤如下⽅式计算：

PCA 将输⼊ $_ { \pmb { x } }$ 投影表⽰成 $\scriptstyle { \pmb { c } } _ { \circ } \quad { \pmb { c } }$ 是⽐原始输⼊维数更低的表⽰，同时使得元素之间线性⽆关。假设有⼀个 $m \times n$ 的矩阵 $\boldsymbol { X }$ ，数据的均值为零，即$\mathbb { E } [ \pmb { x } ] = 0$ ， $\boldsymbol { X }$ 对应的⽆偏样本协⽅差矩阵： $\textstyle \operatorname { V a r } [ { \pmb x } ] = \frac { 1 } { m - 1 } { \pmb X } ^ { \top } { \pmb X }$ 。

PCA 是通过线性变换找到一个 $\mathbf { V a r } \left[ c \right]$ 是对角矩阵的表⽰ $\pmb { c } = \pmb { V } ^ { \top } \pmb { x }$ ，矩阵 $\boldsymbol { X }$ 的主成分可以通过奇异值分解 (SVD) 得到，也就是说主成分是 $\boldsymbol { X }$ 的右奇异向量。假设 $V$ 是 $\pmb { X } = \pmb { U } \pmb { \Sigma } \pmb { V } ^ { \top }$ 奇异值分解的右奇异向量，我们得到原来的特征向量⽅程：

$$
\boldsymbol {X} ^ {\top} \boldsymbol {X} = \left(\boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top}\right) ^ {\top} \boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top} = \boldsymbol {V} \boldsymbol {\Sigma} ^ {\top} \boldsymbol {U} ^ {\top} \boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top} = \boldsymbol {V} \boldsymbol {\Sigma} ^ {2} \boldsymbol {V} ^ {\top} \tag {29}
$$

因为根据奇异值的定义 $U ^ { \top } U = I$ 。因此 $\boldsymbol { X }$ 的⽅差可以表⽰为： $\begin{array} { r } { \operatorname { V a r } \left[ \pmb { x } \right] = \frac { 1 } { m - 1 } \pmb { X } ^ { \top } \pmb { X } = \frac { 1 } { m - 1 } \pmb { V } \pmb { \Sigma } ^ { 2 } \pmb { V } ^ { \top } , } \end{array}$ 。

所以 $^ c$ 的协⽅差满⾜： ${ \begin{array} { r } { \mathrm { V a r } [ c ] = { \frac { 1 } { m - 1 } } C ^ { \top } C = { \frac { 1 } { m - 1 } } V ^ { \top } X ^ { \top } X V = { \frac { 1 } { m - 1 } } V ^ { \top } V \Sigma ^ { 2 } V ^ { \top } V = { \frac { 1 } { m - 1 } } \Sigma ^ { 2 } } \end{array} }$ ，因为根据奇异值定义 $V ^ { \top } V = I$ 。 $^ c$ 的协⽅差是对⾓的， $^ c$ 中的元素是彼此⽆关的。

以 iris 数据为例，展⽰ PCA 的使⽤。

```python
[12]: import pandas as pd  
import numpy as np  
from sklearn.datasets import load_iris  
import matplotlib.pyplot as plt  
from sklearn.preprocessing import StandardScaler  
%matplotlib inline 
```

[13]: #iris = load_iris()df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names)df['label'] $=$ iris.targetdf.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']df.label.value_counts()

```yaml
[13]: 2 50  
1 50  
0 50  
Name: label, dtype: int64 
```

```javascript
[14]: # df.tail() 
```

```txt
[14]: sepal length sepal width petal length petal width label 145 6.7 3.0 5.2 2.3 2 146 6.3 2.5 5.0 1.9 2 147 6.5 3.0 5.2 2.0 2 148 6.2 3.4 5.4 2.3 2 149 5.9 3.0 5.1 1.8 2 
```

```python
[15]: # X = dfiloc[:, 0:4] y = dfiloc[:, 4] print(" \n", X.iloc[0, 0:4]) print(" : \n", y.iloc[0]) 
```

```txt
sepal length 5.1  
sepal width 3.5  
petal length 1.4  
petal width 0.2  
Name: 0, dtype: float64  
:  
0 
```

```python
[16]: class PCA(): def __init__(self): pass def fit(self, X, n_components): n_samples = np.shape(X)[0] covariance_matrix = (1 / (n_samples - 1)) * (X - X.mean(axis=0)).T.dot(X - X.mean(axis=0)) # eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix) # idx = eigenvalues.argsort([[:-1] eigenvalues = eigenvalues[ix][:n_components] eigenvectors = np.atleast_1d(eigenvectors[:, idx])[:, :n_components] # X_transformed = X.dot(eigenvectors) return X_transformed 
```

```python
[17]: model = PCA() Y = model.fit(X, 2) 
```

```python
[18]: principalDf = pd.DataFrame(np.array(Y), columns=['principal component 1', 'principal component 2']) Df = pd.concat([principalDf, y], axis = 1) fig = plt.figure(figsize = (5,5)) ax = fig.add_subplot(1,1,1) ax.set_xlabel('Principal Component 1', fontsize = 15) ax.set_ylabel('Principal Component 2', fontsize = 15) ax.set_title('2 component PCA', fontsize = 20) targets = [0, 1, 2] # ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'] colors = ['r', 'g', 'b'] for target, color in zip(target,colors): indicesToKeep = Df['label'] == target ax.scatter(Df.loc[indicesToKeep, 'principal component 1'] , Df.loc[indicesToKeep, 'principal component 2'] , c = color , s = 50) ax.legend Targets) ax.grid() 
```

![](images/c6b64fc3349d5cfbea2ec6c6936e407ccd0def35e7310fd266111677dcd9aa7a.jpg)

使⽤ sklearn 包实现 PCA

```python
[19]: from sklearn.decomposition import PCA as sklearnPCA  
sklearn_pca = sklearnPCA(n_components=2)  
Y = sklearn_pca.fit_transform(X) 
```

```python
[20]: principalDf = pd.DataFrame(data = np.array(Y), columns = ['principal component 1', 'principal component 2'])  
Df = pd.concat([principalDf, y], axis = 1)  
fig = plt.figure(figsize = (5,5))  
ax = fig.add_subplot(1,1,1)  
ax.set_xlabel('Principal Component 1', fontsize = 15)  
ax.set_ylabel('Principal Component 2', fontsize = 15)  
ax.set_title('2 component PCA', fontsize = 20)  
targets = [0,1,2]  
# ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']  
colors = ['r', 'g', 'b']  
for target, color in zip(target,colors):  
    indicesToKeep = Df['label'] == target  
    axscatter(Df.loc[indicesToKeep,'principal component 1'], Df.loc[indicesToKeep,'principal component 2'], c = color, s = 50)  
ax.legend Targets)  
ax.grid() 
```

![](images/70682849eaa596d8c5ec100b95f07f7c9dd916642ccbac9a51094878ec107d75.jpg)

```python
[21]: import numpy, pandas, matplotlib, sklearn  
print("numpy:", numpy.__version__)  
print("pandas:", pandas.__version__) 
```

```python
print("matplotlib:", matplotlib._version__)  
print("sklearn:", sklearn._version__) 
```

numpy: 1.14.5

pandas: 0.25.1

matplotlib: 3.1.1

sklearn: 0.21.3

# 概率与信息论

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 概率

# 1.1 概率与随机变量

• 频率学派概率 (Frequentist Probability)：认为概率和事件发⽣的频率相关。  
• 贝叶斯学派概率 (Bayesian Probability)：认为概率是对某件事发⽣的确定程度，可以理解成是确信的程度。  
• 随机变量 (Random Variable)：⼀个可能随机取不同值的变量。例如：抛掷⼀枚硬币，出现正⾯或者反⾯的结果。

# 1.2 概率分布

# 1.2.1 概率质量函数

概率质量函数 (Probability Mass Function)：对于离散型变量，我们先定义⼀个随机变量，然后⽤ ~ 符号来说明它遵循的分布： $\mathbf { x } \sim P \left( \mathbf { x } \right)$ ，函数 $P$ 是随机变量 x 的 PMF。

例如, 考虑⼀个离散型 x 有 $k$ 个不同的值，我们可以假设 x 是均匀分布的 (也就是将它的每个值视为等可能的)，通过将它的 PMF 设为：

$$
P \left(\mathrm {x} = x _ {i}\right) = \frac {1}{k} \tag {1}
$$

对于所有的 i 都成⽴。

# 1.2.2 概率密度函数

当研究的对象是连续型时，我们可以引⼊同样的概念。如果⼀个函数 $p$ 是概率密度函数 (Probability Density Function)：

• 分布满⾜⾮负性条件： $\forall x \in \mathrm { x } , p \left( x \right) \geq 0$   
• 分布满⾜归⼀化条件： $\int _ { - \infty } ^ { \infty } p \left( x \right) d x = 1$

例如在 $( a , b )$ 上的均匀分布：

$$
U (x; a, b) = \frac {\mathbf {1} _ {a b} (x)}{b - a}
$$

这⾥ ${ \mathbf { 1 } } _ { a b } ( x )$ 表⽰在 $( a , b )$ 内为 1，否则为 0。

# 1.2.3 累积分布函数

累积分布函数 (Cummulative Distribution Function) 表⽰对⼩于 $x$ 的概率的积分：

$$
\operatorname {C D F} (x) = \int_ {- \infty} ^ {x} p (t) d t \tag {2}
$$

```python
[21]: import numpy as np  
import matplotlib.pyplot as plt  
from scipy.stats import uniform%matplotlib inline 
```

```python
[22]: # fig, ax = plt.subplot(1, 1) r = uniform.rvs(loc=0, scale=1, size=1000) ax.hist(r, density=True, histtype='stepfilled', alpha=0.5) # pdf x = np.linspace(uniform.ppf(0.01), uniform.ppf(0.99), 100) ax.plot(x, uniform.pdf(x), 'r-', lw=5, alpha=0.8, label='uniform pdf') 
```

```txt
[22]: [<matplotlib.axes.Line2D at 0x118521b38>] 
```

![](images/e0e81004dc429dfc20a771e0a65dfd1d83fe9ea40b31c038b76a603d1c413f74.jpg)

# 1.3 条件概率与条件独立

边缘概率 (Marginal Probability)：如果我们知道了⼀组变量的联合概率分布，但想要了解其中⼀个⼦集的概率分布。这种定义在⼦集上的概率分布被称为边缘概率分布。

$$
\forall x \in \mathrm {x}, P (\mathrm {x} = x) = \sum_ {y} P (\mathrm {x} = x, \mathrm {y} = y) \tag {3}
$$

条件概率 (Conditional Probability)：在很多情况下，我们感兴趣的是某个事件，在给定其他事件发⽣时出现的概率。这种概率叫做条件概率。我们将给定 ${ \bf x } = x$ $\mathbf { x } = x , \ \mathbf { y } = y$ ${ \mathrm { y } } = y$ 发⽣的条件概率记为 $P ( \mathbf { y } = y \mid \mathbf { x } = x )$ )。这个条件概率可以通过下⾯的公式计算:

$$
P (\mathrm {y} = y \mid \mathrm {x} = x) = \frac {P (\mathrm {y} = y , \mathrm {x} = x)}{P (\mathrm {x} = x)} \tag {4}
$$

条件概率的链式法则 (Chain Rule of Conditional Probability)：任何多维随机变量的联合概率分布，都可以分解成只有⼀个变量的条件概率相乘的形式:

$$
P \left(x _ {1}, \dots , x _ {n}\right) = P \left(x _ {1}\right) \prod_ {i = 2} ^ {n} P \left(x _ {i} \mid x _ {1}, \dots , x _ {i - 1}\right) \tag {5}
$$

独立性 (Independence)：两个随机变量 $_ \textrm { x }$ 和 y，如果它们的概率分布可以表⽰成两个因⼦的乘积形式，并且⼀个因⼦只包含 $_ \textrm { x }$ 另⼀个因⼦只包含y，我们就称这两个随机变量是相互独⽴的:

$$
\forall x \in \mathrm {x}, y \in \mathrm {y}, p (\mathrm {x} = x, \mathrm {y} = y) = p (\mathrm {x} = x) p (\mathrm {y} = y) \tag {6}
$$

条件独立性 (Conditional Independence)：如果关于 x 和 y 的条件概率分布对于 $\mathrm { _ z }$ 的每⼀个值都可以写成乘积的形式，那么这两个随机变量 x 和y 在给定随机变量 z 时是条件独⽴的。

$$
\forall x \in \mathrm {x}, y \in \mathrm {y}, z \in \mathrm {z}, p (\mathrm {x} = x, \mathrm {y} = y \mid \mathrm {z} = z) = p (\mathrm {x} = x \mid \mathrm {z} = z) p (\mathrm {y} = y \mid \mathrm {z} = z) \tag {7}
$$

# 1.4 随机变量的度量

期望 (Expectation)：函数 $f$ 关于概率分布 $P ( \mathbf { x } )$ 或 $p ( \mathrm { x } )$ 的期望表⽰为由概率分布产⽣ $x$ ，再计算 $f$ 作⽤到 $x$ 上后 $f ( x )$ 的平均值。对于离散型随机变量，这可以通过求和得到：

$$
\mathbb {E} _ {\mathrm {X} \sim P} [ f (x) ] = \sum_ {x} \mathrm {P} (x) f (x) \tag {8}
$$

对于连续型随机变量可以通过求积分得到：

$$
\mathbb {E} _ {\mathrm {x} \sim p} [ f (x) ] = \int P (x) f (x) d x \tag {9}
$$

另外，期望是线性的：

$$
\mathbb {E} _ {\mathrm {x}} [ \alpha f (x) + \beta g (x) ] = \alpha \mathbb {E} _ {\mathrm {x}} [ f (x) ] + \beta \mathbb {E} _ {\mathrm {x}} [ f (x) ] \tag {10}
$$

方差 (Variance)：衡量的是当我们对 $x$ 依据它的概率分布进⾏采样时，随机变量 x 的函数值会呈现多⼤的差异，描述采样得到的函数值在期望上下的波动程度：

$$
\operatorname {V a r} (f (x)) = \mathbb {E} [ (f (x) - \mathbb {E} [ f (x) ]) ^ {2} ] \tag {11}
$$

将⽅差开平⽅即为标准差 (Standard Deviation)。

协方差 (Covariance)：⽤于衡量两组值之间的线性相关程度：

$$
\operatorname {C o v} (f (x), g (y)) = \mathbb {E} [ (f (x) - \mathbb {E} [ f (x) ]) (g (y) - \mathbb {E} [ g (y) ]) ] \tag {12}
$$

注意，独⽴⽐零协⽅差要求更强，因为独立还排除了非线性的相关。

[23]: x = np.array([1,2,3,4,5,6,7,8,9]) y = np.array([9,8,7,6,5,4,3,2,1]) Mean = np.mean(x) Var = np.var(x) # Var_unbias = np.var(x, ddof $= 1$ ) # Cov = np.cov(x,y)

```txt
Mean, Var, Var_unbias, Cov 
```

```txt
[23]: (5.0, 6.666666666666667, 7.5, array([[7.5, -7.5], [-7.5, 7.5]])) 
```

# 1.5 常用概率分布

# 1.5.1 伯努利分布 (两点分布)

伯努利分布 (Bernoulli Distribution) 是单个二值随机变量的分布，随机变量只有两种可能。它由⼀个参数 $\phi \in [ 0 , 1 ]$ 控制， $\phi$ 给出了随机变量等于 1 的概率：

$$
P (\mathrm {x} = 1) = \phi
$$

$$
P (\mathrm {x} = 0) = 1 - \phi \tag {13}
$$

$$
P (x = x) = \phi^ {x} (1 - \phi) ^ {1 - x}
$$

表⽰⼀次试验的结果要么成功要么失败。

[24]:   
```python
def plot_distribution(X, axes=None):
    ""PDF PMF CDF"""
if axes is None:
    fig, axes = plt.subplot(1, 2, figsize=(10, 3))
x_min, x_max = X.interval(0.99)
x = np.linspace(x_min, x_max, 1000)
if hasattr(X.dist, 'pdf'): # pdf
    axes[0].plot(x, X.pdf(x), label="PDF")
    axes[0].fill_between(x, X.pdf(x), alpha=0.5) # alpha
else: # x_int = np.unique(x.astype(int))
axes[0].bar(x_int, X/pmf(x_int), label="PMF") # pmf pdf
axes[1].plot(x, Xcdf(x), label="CDF")
for ax in axes:
    axlegend()
return axes 
```

[25]:   
```python
from scipy.stats import bernoulli  
fig, axes = plt.subplot(1, 2, figsize=(10, 3)) #  
p = 0.3  
X = bernoulli(p) #  
plot_distribution(X, axes=axes) 
```

[25]:   
```javascript
array([[matplotlib.axes._subplots.AxesSubplot object at 0x1187d3d30>, <matplotlib.axes._subplots.AxesSubplot object at 0x11885ccf8>], dtype=object) 
```

![](images/7edb521efe8ea2c7ffbe8ece406c7c1e28f36cf6ab2bc0b09ee39e1ded8d59b7.jpg)

![](images/9ed995c5a7e6c2d042611a42bf41676337204a9c6e10eb90bdf2c0d314767164.jpg)

[26]:   
#   
possibility $= 0.3$ def trials(n_samples): samples $\equiv$ np.random.binomial(n_samples, possibility) # proba_zero $=$ (n_samples-samples)/n_samples proba_one $=$ samples/n_samples return [proba_zero, proba_one]

```python
fig, axes = plt.subplot(1, 2, figsize=(10, 3))  
#  
n_samples = 1  
axes[0].bar([0, 1], trials(n_samples), label="Bernoulli")  
# n  
n_samples = 1000  
axes[1].bar([0, 1], trials(n_samples), label="Binomial")  
for ax in axes:  
    axlegend() 
```

![](images/ef71704a9f4c99cae00c35bd39dec4177c5de2041c9b560df5ed7b950a95928f.jpg)

![](images/830f243141d3c304d241ee5e951931057a02eaf3f4d454b52dc2409a1dd2b772.jpg)

# 1.5.2 范畴分布 (分类分布)

范畴分布 (Multinoulli Distribution) 是指在具有 $k$ 个不同值的单个离散型随机变量上的分布:

$$
p (\mathrm {x} = x) = \prod_ {i} \phi_ {i} ^ {x _ {i}} \tag {14}
$$

例如每次试验的结果就可以记为⼀个 $k$ 维的向量，只有此次试验的结果对应的维度记为 1，其他记为 0。

[27]: def k Possibilities(k): 10 res $=$ np.random.randint(k) _sum $=$ sum(res) for i, x in enumerate(res): res[i] $=$ x / _sum return res fig, axes $=$ plt.subplot(1, 2, figsize=(10, 3)) # k, n_samples $= 10$ , 1 samples $=$ np.random multinomial(n_samples, k Possibilities(k)) #axes[O].bar(range(len(samples)), samples/n_samples, label="Multinoulli") #n n_samples $= 1000$ samples $=$ np.random multinomial(n_samples, k Possibilities(k)) axes[1].bar(range(len(samples)), samples/n_samples, label="Multinomial") for ax in axes: axlegend()

![](images/70e33d606889ace84bf54c427fdb66fb74ccdb0d9d9ae5c7a64c5a21a9d3a2f2.jpg)

![](images/4d810eea989700d6fe0e49206ef755de83657a27dbe7ca42bbcc86dba577cf7c.jpg)

# 1.5.3 高斯分布 (正态分布)

⾼斯分布 (Gaussian Distribution) 或正态分布 (Normal Distribution) 形式如下：

$$
N (x; \mu , \sigma^ {2}) = \sqrt {\frac {1}{2 \pi \sigma^ {2}}} \exp \left(- \frac {1}{2 \sigma^ {2}} (x - \mu) ^ {2}\right) \tag {15}
$$

有时也会⽤ $\begin{array} { r } { \beta = \frac { 1 } { \sigma ^ { 2 } } } \end{array}$ 表⽰分布的精度 (precision)。中⼼极限定理 (Central Limit Theorem) 认为，⼤量的独⽴随机变量的和近似于⼀个正态分布，因此可以认为噪声是属于正态分布的。

```python
[28]: from scipy.stats import norm  
fig, axes = plt.subplot(1, 2, figsize=(10, 3)) #  
mu, sigma = 0, 1  
X = norm(mu, sigma) #  
plot_distribution(X, axes=axes) 
```

```txt
[28]: array([[<matplotlib.axes._subplots.AxesSubplot object at 0x118b76710>, <matplotlib.axes._subplots.AxesSubplot object at 0x118c54978>], dtype=object) 
```

![](images/4fcf129b8b4a83905581bb2ec6e50a81ad6c93349a6a88416eed7933ceb703fc.jpg)

![](images/1916523ff329a4569c10268714a755f9192f46a65db4095c9c3b2f018a76c53d.jpg)

# 1.5.4 多元高斯分布 (多元正态分布)

多元正态分布 (Multivariate Normal Distribution) 形式如下：

$$
N (x; \mu , \Sigma) = \sqrt {\frac {1}{(2 \pi) ^ {n} \operatorname * {d e t} (\Sigma)}} \exp \left(- \frac {1}{2} (x - \mu) ^ {\top} \Sigma^ {- 1} (x - \mu)\right) \tag {16}
$$

```python
[29]: from scipy.stats import multivariate_normal  
import matplotlib.pyplot as plt  
x, y = np.mgrid[-1:1:.01, -1:1:.01]  
pos = np.stack((x, y))  
fig = plt.figure(figsize=(4,4))  
axes = fig.add_subplot(111)  
mu = [0.5, -0.2] #  
sigma = [[2.0, 0.3], [0.3, 0.5]] #  
X = multivariate_normal(mu, sigma)  
axes.contourf(x, y, X.pdf(pos)) 
```

[29]: <matplotlib.contour.QuadContourSet at 0x118cd4438>

![](images/c10aafd368960cd6e606eb58562b2fcb8657cafa26acb54a9105d6727d517b58.jpg)

# 1.5.5 指数分布

指数分布 (Exponential Distribution) 形式如下：

$$
p (x; \lambda) = \lambda 1 _ {x \geq 0} \exp (- \lambda x) \tag {17}
$$

是⽤于在 $x = 0$ 处获得最⾼的概率的分布，其中 $\lambda > 0$ 是分布的⼀个参数，常被称为率参数 (Rate Parameter)。

```python
[30]: from scipy.stats import expon  
fig, axes = plt.subplot(1, 2, figsize=(10, 3))  
# scale = 1 / lambda  
X = expon(scale=1)  
plot_distribution(X, axes=axes) 
```

```javascript
[30]: array([[matplotlib.axes._subplots.AxesSubplot object at 0x11900f438], <matplotlib.axes._subplots.AxesSubplot object at 0x1190956d8>], dtype=object) 
```

![](images/88fc2bd9e7c349110273529b87825fffd101c09b9504d27162f815fe93bab46a.jpg)

![](images/88dd9be5d21746bf4b432867dacddbbece3bcc7a2fc771df3be0d723d55a90bd.jpg)

# 1.5.6 拉普拉斯分布

拉普拉斯分布（Laplace Distribution）形式如下：

$$
\operatorname {L a p l a c e} (x; \mu , \gamma) = \frac {1}{2 \gamma} \exp \left(- \frac {| x - \mu |}{\gamma}\right) \tag {18}
$$

这也是可以在⼀个点获得⽐较⾼的概率的分布。

```python
[31]: from scipy.stats import laplace  
fig, axes = plt.subplot(1, 2, figsize=(10, 3))  
mu, gamma = 0, 1  
X = laplace(loc=mu, scale=gamma)  
plot_distribution(X, axes=axes) 
```

```javascript
[31]: array([[matplotlib.axes._subplots.AxesSubplot object at 0x11913eb00>, <matplotlib.axes._subplots.AxesSubplot object at 0x118a3b2b0>], dtype=object) 
```

![](images/f9e844957d58ceb975809301ab5d2c2c19e0d85e7fd6b39e53b0460689d4d2fc.jpg)

![](images/52c5c57b18688111ffcd970103024b14e144430d17a11f2369cd265c4dec047d.jpg)

# 1.5.7 Dirac 分布

Dirac delta 函数定义为 $p ( x ) = \delta ( x - \mu )$ ，这是⼀个泛函数。它常被⽤于组成经验分布 (Empirical Distribution)：

$$
\hat {p} (x) = \frac {1}{m} \sum_ {i = 1} ^ {m} \delta \left(x - x ^ {(i)}\right) \tag {19}
$$

# 1.6 常用函数的有用性质

# 1.6.1 logistic sigmoid 函数

$$
\sigma (x) = \frac {1}{1 + \exp (- x)} \tag {20}
$$

logistic sigmoid 函数通常⽤来产⽣伯努利分布中的参数 $\phi$ ，因为它的范围是 $( 0 , 1 )$ ，处在 $\phi$ 的有效取值范围内。sigmoid 函数在变量取绝对值⾮常⼤的正值或负值时会出现饱和 (Saturate) 现象，意味着函数会变得很平，并且对输⼊的微⼩改变会变得不敏感。

# 1.6.2 softplus 函数

$$
\zeta (x) = \log (1 + \exp (x)) \tag {21}
$$

softplus 函数可以⽤来产⽣正态分布的 $\beta$ 和 $\sigma$ 参数，因为它的范围是 $( 0 , \infty )$ 。当处理包含 sigmoid 函数的表达式时它也经常出现。softplus 函数名来源于它是另外⼀个函数的平滑 (或 “软化”) 形式，这个函数是:

$$
x ^ {+} = \max  (0, x) \tag {22}
$$

```python
[32]: x = np.linspace(-10, 10, 100)  
sigmoid = 1/(1 + np.exp(-x))  
softplus = np.log(1 + np.exp(x))  
fig, axes = plt.subplot(1, 2, figsize=(10, 3))  
axes[0].plot(x, sigmoid, label='sigmoid')  
axes[1].plot(x, softplus, label='softplus')  
for ax in axes:  
    axlegend() 
```

![](images/cce09c529327ee5b4645247e2976dc3a59c0fc7ad855ce6fca74561d7a960f1c.jpg)

![](images/25eb527a5e483b30c726f85b13e1688dba61f947d9dc9b122ca28b42e02dd43b.jpg)

# 2 信息论

信息论背后的思想：一件不太可能的事件比一件比较可能的事件更有信息量。

信息 (Information) 需要满⾜的三个条件：

• ⽐较可能发⽣的事件的信息量要少。  
• ⽐较不可能发⽣的事件的信息量要⼤。  
• 独⽴发⽣的事件之间的信息量应该是可以叠加的。例如，投掷的硬币两次正⾯朝上传递的信息量，应该是投掷⼀次硬币正⾯朝上的信息量的两倍。

自信息 (Self-Information)：对事件 $x = x$ ，我们定义：

$$
I (x) = - \log P (x) \tag {23}
$$

⾃信息满⾜上⾯三个条件，单位是奈特 (nats) （底为 e）

香农熵 (Shannon Entropy)：上述的⾃信息只包含⼀个事件的信息，⽽对于整个概率分布 $P$ ，不确定性可以这样衡量：

$$
\mathbb {E} _ {x \sim P} [ \operatorname {I} (x) ] = - \mathbb {E} _ {x \sim P} [ \log P (x) ] \tag {24}
$$

也可以表⽰成 $\mathrm { H ( P ) }$ 。⾹农熵是编码原理中最优编码长度。

# 多个随机变量：

• 联合熵 (Joint Entropy)：表⽰同时考虑多个事件的条件下（即考虑联合分布概率）的熵。

$$
H (X, Y) = - \sum_ {x, y} P (x, y) \log (P (x, y)) \tag {25}
$$

• 条件熵 (Conditional Entropy)：表⽰某件事情已经发⽣的情况下，另外⼀件事情的熵。

$$
H (X | Y) = - \sum_ {y} P (y) \sum_ {x} P (x | y) \log (P (x | y)) \tag {26}
$$

• 互信息 (Mutual Information)：表⽰两个事件的信息相交的部分。

$$
I (X, Y) = H (X) + H (Y) - H (X, Y) \tag {27}
$$

• 信息变差 (Variation of Information)：表⽰两个事件的信息不相交的部分。

$$
V (X, Y) = H (X, Y) - I (X, Y) \tag {28}
$$

```txt
[33]: p = np.linspace(1e-6, 1-1e-6, 100) entropy = (p-1)*np.log(1-p) - p*np.log(p) plt.figure(figsize=(4,4)) plt.plot(p, entropy) plt.xlabel('p') pltylabel('Shannon entropy in nats') plt.show() 
```

![](images/c5ed21215e84a6e814baa97569730be4e48012ed8aebba3aea15fd1b70840644.jpg)

```python
[34]: def H sentence):   
```
```
```
entropy = 0
# 256 ASCII
for character_i in range(256):
    Px = sentence.count(chr(character_i))/len(sentence)
    if Px > 0:
        entropy += -Px * math.log(Px, 2) # :log 2
    return entropy 
```

[35]: import random   
import math   
# 64 simple_message $=$ ".join([chr(random.randint(0,64)) for i in range(500)]) print(simple_message)   
H(simple_message)

```txt
-.218?
2> -=?\\('<\\)
: & 5<>=>
/'+(#)>@((931":< > 5)
4\$%79@
)\\(6#63(?1.,&4'%'< 
7 )1,
<%.)*4 :57+ ? 3# 
```

```javascript
[35]: 5.939286791378741 
```

KL 散度 (Kullback-Leibler Divergence) ⽤于衡量两个分布 $P ( \mathbf { x } )$ 和 $Q ( \mathbf { x } )$ 之间的差距：

$$
\mathrm {D} _ {\mathrm {K L}} (P | | Q) = \mathbb {E} _ {x \sim P} [ \log \frac {P (x)}{Q (x)} ] = \mathbb {E} _ {x \sim P} [ \log P (x) - \log Q (x) ] \tag {29}
$$

注意 $\mathrm { D } _ { \mathrm { K L } } ( \mathrm { P } | | \mathrm { Q } ) \neq \mathrm { D } _ { \mathrm { K L } } ( \mathrm { Q } | | \mathrm { P } )$ ，不满⾜对称性。

交叉熵 (Cross Entropy)：

$$
H (P, Q) = H (P) + \mathrm {D} _ {\mathrm {K L}} (P \| Q) = - \mathbb {E} _ {x \sim P} [ \log Q (x) ] \tag {30}
$$

假设 $P$ 是真实分布， $Q$ 是模型分布，那么最⼩化交叉熵 H(P,Q) 可以让模型分布逼近真实分布。

[36]:

```python
KL   
from scipy.stats import entropy # kl   
defkl(p,q): D(P//Q) D" p = np.asarray(p, dtype=np.float) q = np.asarray(q, dtype=np.float) return np.sum(np.where(p != 0,p \* np.log(p / q),0)) 
```

[37]:

```julia
#  
p = [0.1, 0.9]  
q = [0.1, 0.9]  
print(entropy(p, q) == kl(p, q)) 
```

True

[38]:

# D(P//Q) D(Q//P)
x = np.linspace(1, 8, 500)
y1 = normpdf(x, 3, 0.5)
y2 = normpdf(x, 6, 0.5)
p = y1 + y2 # p(x)
KL_pq, KL_qp = [], []
q_list = []
for mu in np.linspace(0, 10, 50):
    for sigma in np.linspace(0.1, 5, 50): # q(x)
        q = normpdf(x, mu, sigma)
        q_list.append(q)
        KL_pq.appendentropy(p, q))
        KL_qp.appendentropy(q, p))
KL_pq_min = np.argmax(KL_pq)
KL_qp_min = np.argmax(KL_qp)
fig, axes = plt.subplot(1, 2, figsize=(10, 3))
axes[0].set_ylim(0, 0.8)
axes[0].plot(x, p/2, 'b', label='\\(p(x)\$')
axes[0].plot(x, q_list[KL_pq_min], 'g--', label='\\)q^*(x)\$')
axes[0].set_xlabel('\\(x\$')
axes[0].set_ylabel('\\)p(x)\$')
axes[0].set_title('\\(q^*=\{arg\backslash min\}-q D_{\{KL\}}(p||q)\$')
axes[1].set_ylim(0, 0.8)
axes[1].plot(x, p/2, 'b', label='\\)p(x)\$')
axes[1].plot(x, q_list[KL_qp_min], 'g--', label='\\)q^*(x)\$')
axes[1].set_xlabel('\\(x\$')
axes[1].set_ylabel('\\)p(x)\$')
axes[1].set_title('\\(q^*=\{arg\backslash min\}-q D_{\{KL\}}(q||p)\$')
for ax in axes:
    axlegend(loc='upper right')

![](images/d012cc8f6a398d5e27ec849c0d0a29048e9ae2504f97d54619562d10917f4942.jpg)

![](images/053ba09f240b51c86366b5631c6a466f2973aeb46eaff86dac9a5b30e0a45e6e.jpg)

# 3 图模型

机器学习算法会涉及到⾮常多的随机变量上的概率分布。利⽤分解可以减少表⽰联合分布的成本，于是⽤图来表⽰概率分布的分解，这称为结构化概率模型 (Structured Probabilistic Model) 或者图模型 (Graphical Model)。

# 3.1 有向图模型（Directed Model）

有向图模型的概率可以因⼦分解 ${ \begin{array} { r } { P ( x ) = P ( x _ { 1 } , . . . x _ { i } , . . . ) = \prod _ { i } P ( x _ { i } \mid \operatorname { P A } ( x _ { i } ) ) } \end{array} }$ ，其中 $\mathrm { P A } ( x _ { i } )$ 是 $x _ { i }$ 的⽗节点，单个因⼦ $P ( x _ { i } | \mathrm { P A } ( x _ { i } ) )$ ) 称为条件概率分布 (CPD)。⽰例如下图所⽰，有：

$$
P (a, b, c, d, e) = P (a) P (b \mid a) P (c \mid a, b) P (d \mid b) P (e \mid c)
$$

![](images/357066cb9e9390a903819ef537542f18adf94e59fed9cb919670f34414bb586e.jpg)  
图 1. 有向图⽰例

有向图的代表是贝叶斯网。

贝叶斯⽹与朴素贝叶斯模型建⽴在相同的直观假设上：通过利用分布的条件独立性来获得紧凑而自然的表示。贝叶斯⽹核⼼是⼀个有向⽆环图(DAG)，其节点为论域中的随机变量，节点间的有向箭头表⽰这两个节点的依赖关系。

贝叶斯网可以看作是各特征节点间的依赖关系图 (有向⽆环图表⽰) 和各特征节点相对其依赖节点的条件概率表。

有向⽆环图可以由如下 3 种元结构构成：

• 同⽗结构。例如在上图中，若不考虑节点 $a$ ，则 $c$ 和 $d$ 有同⼀⽗节点 $b$ ，于是 $P ( b , c , d ) = P ( b ) P ( c \mid b ) P ( d \mid b )$ 。  
• V 型结构。例如在上图中，若不考虑节点 $a$ 到 $b$ 的依赖关系，则 $P ( a , b , c ) = P ( a ) P ( b ) P ( c \mid a , b ) { \mathrm { } } _ { \mathrm { } }$ 。  
• 顺序结构。例如在上图中，若仅考虑节点 $a , \ b , \ d$ ，则有 $P ( a , b , d ) = P ( a ) P ( b \mid a ) P ( d \mid b ) .$ 。

基于此，我们对简化的条件概率分布 (如 $P ( c | a , b ) ,$ ) 获取条件概率表。同时，也可以求得联合概率分布 $P ( a , b , c , d , e ) = P ( a ) P ( b \mid a ) P ( c \mid a , b ) P ( d \mid$ $b ) P ( e \mid c ) .$ 。

# 3.1.1 贝叶斯网的独立性

贝叶斯⽹的基本独⽴性体现在

• 局部独立性：给定⽗节点条件下，每个节点都独⽴于它的⾮后代节点。例如，给定⽗节点 $c$ 时，e 与⽹中其他节点条件独⽴ $\implies ( e \perp a , b , d | c )$   
• 全局独立性 $\smash { ( d - }$ 分离)：d - 分离是⽤来判断变量是否条件独⽴的图形化⽅法。它常见于以下三种条件独⽴的情况：

1. tail-to-tail

![](images/1edcae5ca9632e5f8a7284b25de8d1ca6322620df3924ef1a64a8e63a94e07ee.jpg)

$\Longrightarrow$ 可以得知 $P ( a , b , c ) = P ( a \mid c ) P ( b \mid c ) P ( c ) { } _ { \mathrm { ~ } }$ 。

$\Longrightarrow$ 若 $c$ 不作为观察点，可得 $\begin{array} { r } { P ( a , b ) = \sum _ { c } P ( a \mid c ) P ( b \mid c ) P ( c ) \neq P ( a ) P ( b ) } \end{array}$ ，于是 $a$ 和 $b$ 不是 $c$ 条件独⽴的。  
$\Longrightarrow$ 若 $c$ 作为观察点，可得 $\begin{array} { r } { P ( a , b | c ) = \frac { P ( a , b , c ) } { P ( c ) } = P ( a \mid c ) P ( b \mid c ) } \end{array}$ P (a,b,c) = P (a | c)P (b | c)，于是 a 和 b 是 c 条件下独⽴的。 $a$ $b$ $c$

# 2. head-to-tail

![](images/7c0caab3254faab14e3b8c36645ac7e6f3e66170da26e77677ebfe3e4c4f412c.jpg)

$\Longrightarrow$ 可以得知 $P ( a , b , c ) = P ( b \mid c ) P ( c \mid a ) P ( a ) { \mathrm { } } _ { \mathrm { c } }$ 。  
$\Longrightarrow$ 若 $c$ 不作为观察点，可得 $\begin{array} { r } { P ( a , b ) = P ( a ) \sum _ { c } P ( c \mid a ) P ( b \mid c ) = P ( a ) P ( b \mid a ) } \end{array}$ ，于是 $a$ 和 $b$ 不是 $c$ 条件独⽴的。  
$\Longrightarrow$ 若 $c$ 作为观察点，可得 $\begin{array} { r } { P ( a , b \mid c ) = \frac { P ( a , b , c ) } { P ( c ) } = \frac { P ( a ) P ( c \mid a ) P ( b \mid c ) } { P ( c ) } = P ( a \mid c ) P ( b \mid c ) } \end{array}$ P (a)P (c|a)P (b|c) = P (a | c)P (b | c)，于是 a 和 b 是 c 条件下独⽴的。 $a$ $b$ $c$

# 3. head-to-head

![](images/cef2ec28fd0aab6556bd9f6c53228924266f20f60bb288ca7cbd51639c6ff4eb.jpg)

$\Longrightarrow$ 可以得知 $P ( a , b , c ) = P ( a ) P ( b ) P ( c \mid a , b ) .$ 。  
$\Longrightarrow$ 若 $c$ 不作为观察点，可得 $\begin{array} { r } { P ( a , b ) = P ( a ) P ( b ) \sum _ { c } P ( c \mid a , b ) = P ( a ) P ( b ) } \end{array}$ ，于是 $a$ 和 $b$ 是 $c$ 条件独⽴的。  
$\Longrightarrow$ 若 $c$ 作为观察点，可得 $\begin{array} { r } { P ( a , b | c ) = \frac { P ( a , b , c ) } { P ( c ) } = \frac { P ( a ) P ( b ) P ( c | a , b ) } { P ( c ) } \neq P ( a | c ) P ( b | c ) } \end{array}$ ，于是 $a$ 和 $b$ 不是 $c$ 条件下独⽴的。

从⽽我们考虑复杂的有向⽆环图 (DAG)，如果 A,B,C 是三个集合 (可以是单独的节点或者是节点的集合)。为了判断 A 和 B 是否是 C 条件独⽴的，我们考虑图中所有 A 和 B 之间的路径。对于其中的⼀条路径，如果它满⾜以下两个条件中的任意⼀条，则称这条路径是阻塞 (block) 的：

1. 路径中存在某个节点 X 是 head-to-tail 或者 tail-to-tail 节点，并且 X 是包含在 C 中的；  
2. 路径中存在某个节点 X 是 head-to-head 节点，并且 X 或 X 的⼉⼦是不包含在 C 中的。

如果 A,B 间所有的路径都是阻塞的，那么 A,B 就是关于 C 条件独⽴的；否则 A,B 不是关于 C 条件独⽴的。

![](images/dcc57c06aa085e3b598dc7c5a432f40336a0c597566322e9ec06f982734aebba.jpg)  
图 2. 考虑集合下的有向⽆环图

我们形象化阐述上⾯的结论：如图 2 所⽰，集合 $x _ { \mathrm { A } }$ , xB 和 $x _ { \mathrm { C } }$ ，我们希望 $x _ { \mathrm { A } }$ 和 $x _ { \mathrm { B } }$ 在给定 $x _ { \mathrm { C } }$ 下条件独⽴或所有路径阻塞，即 $x _ { \mathrm { A } } \perp x _ { \mathrm { B } } \mid x _ { \mathrm { C } \circ }$ 。对于集合中的 $a$ ，b 和 $c$ ，如果我们希望 $a {  } c {  } b$ 的路径阻塞，当路径为 tail-to-tail 或者 head-to-tail，则 $c$ 应当在集合 C 中，这便是条件 1；当路径为 head-to-head，则 $c$ 以及其后代 $d$ 不能在集合 C 中，这便是条件 2。

例如，我们再考虑图 1 中的例⼦，判断 $a$ 和 $d$ 是否是 $e$ 下条件独⽴的：可以看出 $a$ 到 $d$ 有两条路径 $a {  } c {  } b {  } d$ 以及 $a  b  d _ { \circ }$ 考虑路径 $a \to b \to d$ ，b 是 head-to-tail 类型的，但不在条件集合中，因此该路径不阻塞。考虑路径 $a {  } c {  } b {  } d$ ， $c$ 是 head-to-head 类型的，且它的⼉⼦ $e$ 在条件集合中，因此该路径也不阻塞。因此，得到结论： $a$ 和 $d$ 不是 $e$ 下条件独⽴的。

```python
[39]: import networkx as nx  
from pgmpy.models import BayesianModel  
from pgmpy+factors.discrete import TabularCPD  
import matplotlib.pyplot as plt  
%matplotlib inline  
#  
model = BayesianModel([[('a', 'b'), ('a', 'c'), ('b', 'c'), ('b', 'd'), ('c', 'e')])  
#  
cpd_a = TabularCPD(variable='a', variable_card=2, values=[[0.6, 0.4]]) # a: (0,1)  
#  
cpd_b = TabularCPD(variable='b', variable_card=2, # b: (0,1)  
values=[[0.75, 0.1],  
[0.25, 0.9]],  
evidence=['a'], 
```

```julia
evidence_card=[2])  
cpd_c = TabularCPD(variable='c', variable_card=3, # c: (0,1,2)  
values=[[0.3, 0.05, 0.9, 0.5],  
[0.4, 0.25, 0.08, 0.3],  
[0.3, 0.7, 0.02, 0.2]],  
evidence=['a', 'b'],  
evidence_card=[2, 2])  
cpd_d = TabularCPD(variable='d', variable_card=2, # d: (0,1)  
values=[[0.95, 0.2],  
[0.05, 0.8]],  
evidence=['b'],  
evidence_card=[2])  
cpd_e = TabularCPD(variable='e', variable_card=2, # e: (0,1)  
values=[[0.1, 0.4, 0.99],  
[0.9, 0.6, 0.01]],  
evidence=['c'],  
evidence_card=[3])  
#  
model.add_gpds(cpd_a, cpd_b, cpd_c, cpd_d, cpd_e)  
#  
print(u":", model.check_model())  
#  
nx.draw(model, with_labels=True, node_size=1000, font_weight='bold', node_color='y', \pos={'e': [4,3], 'c': [4,5], 'd': [8,5], 'a': [2,7], 'b': [6,7]})  
plt.text(2,7, model.get_gpds("a"), fontsize=10, color='b')  
plt.text(5,6, model.get_gpds("b"), fontsize=10, color='b')  
plt.text(1,4, model.get_gpds("c"), fontsize=10, color='b')  
plt.text(4.2,2, model.get_gpds("e"), fontsize=10, color='b')  
plt.text(7,3.4, model.get_gpds("d"), fontsize=10, color='b')  
plt.show() 
```

: True

![](images/036e3559add3e99f27b33ea9c9d7de954aeeb342ffa591b50f9e91718972d420.jpg)

# 3.2 无向图模型 (Undirected Model)：

⽆向图模型的概率可以记作 $\begin{array} { r } { P ( \pmb { x } ) = \frac { 1 } { \mathrm { Z } } \prod _ { \mathrm { C \in \mathbf { Q } } } \Phi _ { \mathrm { C } } \pmb { x } _ { \mathrm { C } } } \end{array}$ 。其中，我们将所有节点都彼此联通的集合称作团 (Clique，C)， $\Phi$ 称作因⼦ (factor)，每个因⼦和⼀个团 C 相对应，Z 是归⼀化常数。⽰例如下图所⽰，有 $\begin{array} { r } { P ( a , b , c , d , e ) = \frac { 1 } { \mathrm { Z } } \Phi ^ { ( 1 ) } ( a , b , c ) \Phi ^ { ( 2 ) } ( b , d ) \Phi ^ { ( 3 ) } ( c , e ) \mathrm { _ { c } } } \end{array}$ 。

![](images/b61e460a6830652bc5f2fa0c1033a026f10c675b347ce796defc02952222ad77.jpg)  
图 3. ⽆向图⽰例

有向图的代表是马尔可夫网。

贝叶斯⽹是根据节点依赖关系构成有向⽆环图，进⽽引申出每个节点的条件概率分布来表征其对⽗节点的依赖。但马尔可夫网节点间的依赖关系是无向的（相互平等的关系），⽆法⽤条件概率分布来表⽰，为此为引⼊极大团概念，进⽽为每个极⼤团引⼊⼀个势函数作为因⼦，然后将联合概率分布表⽰成这些因⼦的乘积再归⼀化，归⼀化常数被称作配分函数。

团: 假设⼀个特征集的任何两个特征都相互关联，那么这个特征集的联合概率分布是⽆法简化的，我们称这样的特征集为团。

极大团: 如果⼀个团不能被其他团包含，那么我们称这个团为极⼤团。

对于具有 $n$ 个特征变量 $\pmb { x } = ( x _ { 1 } , . . . , x _ { n } )$ 的马尔可夫⽹的所有极⼤团构成的集合 $\mathbf { Q }$ ，与极⼤团 $\mathbf { \boldsymbol { C } } \in \mathbf { \boldsymbol { Q } }$ 对应的属性变量集合记作 $\mathbf { \mathit { x } } _ { \mathrm { { C } } }$ ，那么马尔可夫⽹ $\mathrm { P } ( { \pmb x } )$ 可以写成因⼦分解的形式：

$$
P (\boldsymbol {x}) = \frac {1}{Z} \prod_ {\mathrm {C} \in \mathbf {Q}} \Phi_ {\mathrm {C}} \left(\boldsymbol {x} _ {\mathrm {C}}\right) \quad Z = \sum_ {\boldsymbol {x}} \prod_ {\mathrm {C} \in \mathbf {Q}} \Phi_ {\mathrm {C}} \left(\boldsymbol {x} _ {\mathrm {C}}\right) \tag {31}
$$

其中 $\Phi _ { \mathrm { C } }$ 就是极⼤团 C 对应的势函数 (因⼦)，⽤于对极⼤团 C 内的特征变量关系进⾏建模，必须为正。Z 为归⼀化因⼦ (配分函数)，就是对势函数乘积的所有属性变量求和求积分，使 P 成为概率。此时势函数可以写作 $\Phi ( \mathbf { x } _ { \mathrm { C } } ) = \exp ( - E ( \mathbf { x } _ { \mathrm { C } } ) )$ ，其中 $E$ 为能量函数，我们也称 $P ( { \pmb x } )$ 是由因⼦集 $\{ \Phi _ { \mathrm { C } } \mid \mathrm { C } \in \mathbf { Q } \}$ 参数化的吉布斯分布 (Gibbs Distribution) 或玻尔兹曼分布 (Boltzmann Distribution)。于是，⽰例的马尔可夫⽹的联合概率分布可写成：

$$
P (a, b, c, d, e) = \frac {1}{\mathsf {Z}} \Phi_ {a, b, c} (a, b, c) \Phi_ {b, d} (b, d) \Phi_ {c, e} (c, e)
$$

# 马尔可夫网的条件独立性

前⾯介绍了贝叶斯⽹的元结构及其条件独⽴性，⽽马尔可夫⽹的有向分离，同样能够引出条件独⽴性 (相对分离集)，这就是全局马尔可夫性。

如果将 $\{ a , b , c \}$ 视作团 A， $\{ b , d \}$ 视作团 B， $\{ c , e \}$ 视作团 C。特别地，我们可以验证最简单情况下的全局马尔可夫性：

$$
\begin{array}{l} \mathrm {P} (x _ {A}, x _ {B} \mid x _ {C}) = \frac {\mathrm {P} (x _ {A} , x _ {B} , x _ {C})}{\mathrm {P} (x _ {C})} \\ = \frac {\frac {1}{Z} \Phi_ {A , C} (x _ {A} , x _ {C}) \Phi_ {B , C} (x _ {B} , x _ {C})}{\sum_ {x _ {A} ^ {\prime} , x _ {B} ^ {\prime}} \mathrm {P} (x _ {A} ^ {\prime} , x _ {B} ^ {\prime} , x _ {C})} \\ \end{array}
$$

条件概率的定义

分⼦极⼤团分解

分母概率分布边缘求和 (积分)

$$
= \frac {\frac {1}{Z} \Phi_ {A , C} (x _ {A} , x _ {C}) \Phi_ {B , C} (x _ {B} , x _ {C})}{\sum_ {x _ {A} ^ {\prime} , x _ {B} ^ {\prime}} \frac {1}{Z} \Phi_ {A , C} (x _ {A} ^ {\prime} , x _ {C}) \Phi_ {B , C} (x _ {B} ^ {\prime} , x _ {C})}
$$

分母局部做极⼤团分解

$$
= \frac {\Phi_ {A , C} (x _ {A} , x _ {C})}{\sum_ {x _ {A} ^ {\prime}} \Phi_ {A , C} (x _ {A} ^ {\prime} , x _ {C})} \frac {\Phi_ {B , C} (x _ {B} , x _ {C})}{\sum_ {x _ {B} ^ {\prime}} \Phi_ {B , C} (x _ {B} ^ {\prime} , x _ {C})}
$$

简单的代数操作

$$
= \mathrm {P} (x _ {A} \mid x _ {C}) \mathrm {P} (x _ {B} \mid x _ {C})
$$

利⽤边缘求和和极⼤团分解

⽽ $P ( x _ { A } , x _ { B } , x _ { C } )$ 作为中间分布

由全局马尔可夫性可以容易推导出两个推论：

• 局部马尔可夫性：将节点 $v \in \mathrm { V }$ 的所有邻接节点集作为分离集 $\mathrm { N } ( v ) \subset \mathrm { V }$ ，于是该节点 $v$ 与被邻接变量集分离的剩余变量集是条件独⽴的 (相对 $\mathrm { N } ( v )$ ⽽⾔)。

$$
x _ {v} \perp \boldsymbol {x} _ {V \backslash N ^ {*} (v)} \mid \boldsymbol {x} _ {N (v)}, \quad N ^ {*} (v) = N (v) \cup \{v \} \tag {33}
$$

• 成对马尔可夫性：两个⾮邻接节点 $u , v \in \mathrm { V }$ ，必然可以被其他所有节点构成的集 ${ \pmb x } _ { \mathrm { V } \backslash \{ u , v \} }$ 分离，进⽽ $u , v$ 也具有条件独⽴性 (相对前⾯指定的节点集)。

$$
x _ {u} \perp x _ {v} \mid x _ {\mathrm {V} \backslash \{u, v \}}, \quad \{u, v \} \notin E, \quad E \text {是 边 集} \tag {34}
$$

![](images/820f93ee50146fef38a096efb34d48487c7c865e9ebb77201f7c1a7391fd44dd.jpg)  
图 4. 局部马尔可夫性与成对马尔可夫性

```python
[40]: import networkx as nx  
from pgmpy.models import MarkovModel  
from pgmpy+factors.discrete import DiscreteFactor  
import matplotlib.pyplot as plt  
%matplotlib inline  
#  
model = MarkovModel([[a', 'b'), ('a', 'c'), ('b', 'c'), ('b', 'd'), ('c', 'e')])  
# (  )  
factor_abc = DiscreteFactor(['a', 'b', 'c'], cardinality=[2,2,2], values=np.random.randint(8))  
factor_bd = DiscreteFactor(['b', 'd'], cardinality=[2,2], values=np.random.randint(4))  
factor_ce = DiscreteFactor(['c', 'e'], cardinality=[2,2], values=np.random.randint(4))  
#  
model.add Factors(factor_abc, factor_bd, factor_ce)  
#  
print(u":", model.check_model())  
# # ( +  )  
nx.draw(model, with_labels=True, node_size=1000, font_weight='bold', node_color='y', \pos={'e': [4,3], 'c': [4,5], 'd': [8,5], 'a': [2,7], 'b': [6,7]})  
plt.text(2,7, model.getFactors() [0], fontsize=10, color='b')  
plt.text(7,3.4, model.getFactors() [1], fontsize=10, color='b')  
plt.text(4.2,2, model.getFactors() [2], fontsize=10, color='b')  
plt.show() 
```

![](images/1880eb10ace9d42f7da0ae6aa6d40857c304c022588e4291fe84f5d777279706.jpg)

有关于图模型的更多内容会在第⼗六章呈现。

[41]: import numpy, scipy, matplotlib, networkx, pgmpy

```python
print("numpy:", numpy._version__)  
print(" scipy:", scipy._version__)  
print("matplotlib:", matplotlib._version__)  
print("networkx:", networkx._version__)  
print("pgmpy:", pgmpy._version__) 
```

numpy: 1.14.5

scipy: 1.3.1

matplotlib: 3.1.1

networkx: 2.4

pgmpy: 0.1.10

# 数值计算

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 上溢和下溢

下溢（Underflow）：当接近零的数被四舍五⼊为零时发⽣下溢。

上溢（Overflow）：当⼤量级的数被近似为 $\infty$ 或 $- \infty$ 时发⽣上溢。

必须对上溢和下溢进⾏数值稳定的⼀个例⼦是 softmax 函数。softmax 函数经常⽤于预测与范畴分布相关联的概率，定义为:

$$
\operatorname {s o f t m a x} (\boldsymbol {x}) _ {i} = \frac {\exp \left(x _ {i}\right)}{\sum_ {j = 1} ^ {n} \exp \left(x _ {j}\right)} \tag {1}
$$

```python
[1]: import numpy as np  
import numpy.linalg as la 
```

```python
[2]: x = np.array([1e7, 1e8, 2e5, 2e7])  
y = np.exp(x)/sum(np.exp(x))  
print(" ", y)  
x = x - np.max(x) #  
y = np.exp(x)/sum(np.exp(x))  
print(" ", y) 
```

```json
[nan nan nan nan] [0.1.0.0.] 
```

```python
[3]: x = np.array([-1e10, -1e9, -2e10, -1e10])  
y = np.exp(x)/sum(np.exp(x))  
print(" ", y)  
x = x - np.max(x) #  
y = np.exp(x)/sum(np.exp(x))  
print(" ", y)  
print("log softmax(x):", np.log(y))  
# log softmax  
def logsoftmax(x):  
    y = x - np.log(sum(np.exp(x)))  
    return y  
print("logsoftmax(x):", logsoftmax(x)) 
```

```txt
[nan nan nan nan] [0.1.0.0.] log softmax(x):[-inf 0.-inf -inf] logsoftmax(x):[-9.0e+09 0.0e+00-1.9e+10-9.0e+09] 
```

# 2 优化方法

# 2.1 梯度下降法

梯度下降法 (Gradient Descent) 或最速下降法 (Method of Steepest Descent) 的⽬标函数是最⼩化具有多维输⼊的函数： $f : \mathbb { R } ^ { n }  \mathbb { R }$ 。梯度下降法建议新的点为：

$$
\boldsymbol {x} ^ {\prime} = \boldsymbol {x} - \epsilon \nabla_ {\boldsymbol {x}} f (\boldsymbol {x}) \tag {2}
$$

其中 $\epsilon$ 为学习率 (learning rate)，是⼀个确定步长⼤⼩的正标量。

这⾥引⼊实例 (线性最⼩⼆乘)：

$$
f (\boldsymbol {x}) = \frac {1}{2} \| \boldsymbol {A x} - \boldsymbol {b} \| _ {2} ^ {2} \tag {3}
$$

假设我们希望找到最⼩化该式的 $x$ 值。

可以计算梯度得到：

$$
\nabla_ {\boldsymbol {x}} f (\boldsymbol {x}) = \boldsymbol {A} ^ {\top} (\boldsymbol {A} \boldsymbol {x} - \boldsymbol {b}) = \boldsymbol {A} ^ {\top} \boldsymbol {A} \boldsymbol {x} - \boldsymbol {A} ^ {\top} \boldsymbol {b} \tag {4}
$$

实例：线性最⼩⼆乘

[4]: $\begin{array}{rl} & {\mathrm{x0 = np.array([1.0,1.0,1.0])}}\\ & {\mathrm{A = np.array([[1.0, - 2.0,1.0],[0.0,2.0, - 8.0],[-4.0,5.0,9.0]]})}}\\ & {\mathrm{b = np.array([0.0,8.0, - 9.0])}}\\ & {\mathrm{epsilon = 0.001}}\\ & {\mathrm{delta = 1e - 3}}\\ & {\# \quad \texttt{A}\quad \texttt{b}\qquad \texttt{x}\quad [29,16,3]} \end{array}$ [4]

```python
[5]:   
```
```
```
def matmul_chain(*args):
    if len(args) == 0: return np.nan
        result = args[0]
        for x in args[1]:
            result = result@x
        return result
def gradient_decent(x, A, b, epsilon, delta):
    while la(norm(matmul_chain(A.T, A, x)-matmul_chain(A.T, b)) > delta:
        x -= epsilon*(matmul.chain(A.T, A, x)-matmul.chain(A.T, b))
    return x
gradient_decent(x0, A, b, epsilon, delta) 
```

```txt
[5]: array([27.82277014, 15.34731055, 2.83848939]) 
```

# 2.2 牛顿法

⽜顿法 (Newton's Method) 基于⼀个⼆阶泰勒展开来近似 $\mathbf { \boldsymbol { x } } ^ { ( 0 ) }$ 附近的 $f ( { \pmb x } )$ ：

$$
f (\boldsymbol {x}) \approx f \left(\boldsymbol {x} ^ {(0)}\right) + \left(\boldsymbol {x} - \boldsymbol {x} ^ {(0)}\right) ^ {\top} \nabla_ {\boldsymbol {x}} f \left(\boldsymbol {x} ^ {(0)}\right) + \frac {1}{2} \left(\boldsymbol {x} - \boldsymbol {x} ^ {(0)}\right) ^ {\top} \mathrm {H} \left(\boldsymbol {x} ^ {(0)}\right) \left(\boldsymbol {x} - \boldsymbol {x} ^ {(0)}\right) \tag {5}
$$

接着通过计算，我们可以得到这个函数的临界点：

$$
\boldsymbol {x} ^ {*} = \boldsymbol {x} ^ {(0)} - \mathrm {H} (\boldsymbol {x} ^ {(0)}) ^ {- 1} \nabla_ {\boldsymbol {x}} f (\boldsymbol {x} ^ {(0)}) \tag {6}
$$

⽜顿法迭代地更新近似函数和跳到近似函数的最⼩点可以⽐梯度下降法更快地到达临界点。这在接近全局极⼩时是⼀个特别有⽤的性质，但是在鞍点附近是有害的。

针对上述实例，计算得到： $\mathrm { H } = \boldsymbol { A } ^ { \intercal } \boldsymbol { A }$

进⼀步计算得到最优解：

$$
\boldsymbol {x} ^ {*} = \boldsymbol {x} ^ {(0)} - \left(\boldsymbol {A} ^ {\top} \boldsymbol {A}\right) ^ {- 1} \left(\boldsymbol {A} ^ {\top} \boldsymbol {A} \boldsymbol {x} ^ {(0)} - \boldsymbol {A} ^ {\top} \boldsymbol {b}\right) = \left(\boldsymbol {A} ^ {\top} \boldsymbol {A}\right) ^ {- 1} \boldsymbol {A} ^ {\top} \boldsymbol {b} \tag {7}
$$

```python
[6]:   
```
```
```
def matmul_chain(*args):
    if len(args) == 0: return np.nan
        result = args[0]
        for x in args[1] :
            result = result@x
        return result
def newton(x, A, b, delta): 
```

$\mathbf{x} =$ matmul_chain(np.linalg.inv(matmul_chain(A.T,A)),A.T,b) return x   
newton(x0,A,b, delta)

[6]: array([29., 16., 3.])

# 2.3 约束优化

我们希望通过 $m$ 个函数 $g ^ { ( i ) }$ 和 $n$ 个函数 $h ^ { ( j ) }$ 描述 S ，那么 S 可以表⽰为 $\mathbf { S } = \{ \pmb { x } \mid \forall i , g ^ { ( i ) } ( \pmb { x } ) = 0$ and $\forall j , h ^ { ( j ) } ( { \pmb x } ) \le 0 \}$ 。其中涉及 $g ^ { ( i ) }$ 的等式称为等式约束，涉及 $h ^ { ( j ) }$ 的不等式称为不等式约束。

我们为每个约束引⼊新的变量 $\lambda _ { i }$ 和 $\alpha _ { j }$ ，这些新变量被称为 KKT 乘⼦。⼴义拉格朗⽇式可以如下定义：

$$
L (\boldsymbol {x}, \lambda , \alpha) = f (\boldsymbol {x}) + \sum_ {i} \lambda_ {i} g ^ {(i)} (\boldsymbol {x}) + \sum_ {j} \alpha_ {j} h ^ {(j)} (\boldsymbol {x}) \tag {8}
$$

可以通过优化⽆约束的⼴义拉格朗⽇式解决约束最⼩化问题：

$$
\min  _ {\boldsymbol {x}} \max  _ {\lambda} \max  _ {\alpha , \alpha \geq 0} L (\boldsymbol {x}, \lambda , \alpha) \tag {9}
$$

优化该式与下式等价：

$$
\min  _ {\boldsymbol {x} \in \mathrm {S}} f (\boldsymbol {x}) \tag {10}
$$

针对上述实例，约束优化: $\pmb { x } ^ { \top } \pmb { x } \leq 1$

引⼊⼴义拉格朗⽇式：

$$
L (\boldsymbol {x}, \lambda) = f (\boldsymbol {x}) + \lambda \left(\boldsymbol {x} ^ {\top} \boldsymbol {x} - 1\right) \tag {11}
$$

解决以下问题：

$$
\min  _ {\boldsymbol {x}} \max  _ {\lambda , \lambda \geq 0} L (\boldsymbol {x}, \lambda) \tag {12}
$$

关于 $_ { \pmb { x } }$ 对 Lagrangian 微分，我们得到⽅程:

$$
\boldsymbol {A} ^ {\top} \boldsymbol {A} \boldsymbol {x} - \boldsymbol {A} ^ {\top} \boldsymbol {b} + 2 \lambda \boldsymbol {x} = \mathbf {0} \tag {13}
$$

得到解的形式是：

$$
\boldsymbol {x} = \left(\boldsymbol {A} ^ {\top} \boldsymbol {A} + 2 \lambda \boldsymbol {I}\right) ^ {- 1} \boldsymbol {A} ^ {\top} \boldsymbol {b} \tag {14}
$$

λ 的选择必须使结果服从约束，可以对 λ 梯度上升找到这个值：

$$
\frac {\partial}{\partial \lambda} L (\boldsymbol {x}, \lambda) = \boldsymbol {x} ^ {\top} \boldsymbol {x} - 1 \tag {15}
$$

[7]:

```python
```
```
def matmul_chain(*args):
    if len(args) == 0: return np.nan
    result = args[0]
    for x in args[1]:
        result = result@x
    return result
def constrain_opti(x, A, b, delta):
    k = len(x)
    lamb = 0
    while np.abs(np.dot(x.T, x)-1) > 5e-2: # delta 5e-2 0
        x = matmul_chain(np.linalg.inv(matmul_chain(A.T, A)+2*lamb*np_identity(k)), A.T, b)
        lamb += np.dot(x.T, x)-1
    return x
constrain_opti(x0, A, b, delta) 
```

[7]: array([ 0.23637902, 0.05135858, -0.94463626])

[8]: import numpy

print("numpy:", numpy.__version__)

numpy: 1.14.5

# 机器学习基础

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 学习算法

机器学习算法描述⼀种能够从数据中学习的算法。学习指对于某类任务 T，为其定义性能度量 P，⼀个计算机程序被认为可以从经验 E 中学习是指：通过经验 E 改进后，它在任务 T 上的性能度量 P 有所提高。

任务 T：机器学习任务定义为机器学习系统应该如何处理样本（Example）。例如，识别⼿写体数字识别的任务为：通过将输⼊的图⽚处理后，输出该图⽚对应的数字（分类）。样本是量化的特征（Feature）的集合，⽤向量 $\mathbf { \boldsymbol { x } } \in \mathbb { R } ^ { n }$ 表⽰，其中向量的每个元素 $x _ { i }$ 是⼀个特征。例如⼀张图⽚的特征就是这张图⽚⾥的像素点的值。

性能度量 P：为了评估机器学习的优劣，需要对算法的输出结果进⾏定量的衡量分析，这就需要合适的性能度量指标。

<table><tr><td></td><td>指标</td><td>说明</td></tr><tr><td>True Positive</td><td>TP</td><td>将正样本预测为正例数目</td></tr><tr><td>True Negative</td><td>TN</td><td>将负样本预测为负例数目</td></tr><tr><td>False Positive</td><td>FP</td><td>将负样本预测为正例数目</td></tr><tr><td>False Negative</td><td>FN</td><td>将正样本预测为负例数目</td></tr></table>

• 针对分类任务 (详细描述见第⼗⼀章)：

– 准确率 (Accuracy)：acc = TP+TNTP+TN+FP+FN。 $\begin{array} { r } { a c c = \frac { \mathrm { T P + T N } } { \mathrm { T P + T N + F P + F N } } \circ } \end{array}$   
– 错误率 (Error-rate)：err = 1 − acc   
– 精度 (Precision)： $\begin{array} { r } { \mathrm { P } = \frac { \mathrm { T P } } { \mathrm { T P } + \mathrm { F P } } } \end{array}$   
– 召回率 (Recall)：R = TPTP+FN $\begin{array} { r } { \mathrm { R } = \frac { \mathrm { T P } } { \mathrm { T P } + \mathrm { F N } } } \end{array}$   
$- \ \mathrm { F _ { 1 } }$ – F1 值：F1 = $\mathrm { F } _ { 1 } =$ 2PR

• 针对回归任务：距离误差

经验 E：根据经验 E 的不同，机器学习算法可以分为：⽆监督 (Unsupervised) 算法和监督 (Supervised) 算法。

• 监督学习算法 (Supervised Learning)：训练集的数据中包含样本特征和标签值，常见的分类和回归算法都是有监督的学习算法。  
• ⽆监督学习算法 (Unsupervised Learning)：训练集的数据中只包含样本特征，算法需要从中学习出特征中隐藏的结构化特征，聚类、密度估计等都是⽆监督的学习算法。

# 1.1 举例：线性回归

线性回归（Linear Regression）的⽬标：获得⼀个函数 $f$ ，满⾜ $f ( { \pmb x } ) = \hat { y }$ ，其中 $\pmb { x } \in \mathbb { R } ^ { n } , \hat { y } \in \mathbb { R }$ ，使得 $\hat { y }$ 接近于真实的标签 $y _ { \circ }$

我们定义线性回归的输出为：

$$
f (x) = \boldsymbol {w} ^ {\top} \boldsymbol {x} \tag {1}
$$

其中 $\pmb { w } \in \mathbb { R } ^ { n }$ 是我们需要学习的参数 (Parameter)。

在线性回归中，对任务 T 的定义：通过输出 $\hat { y } = \pmb { w } ^ { \top } \pmb { x }$ ，从 $_ { \pmb { x } }$ 预测 $y _ { \circ }$

性能度量 P 的定义：假设测试集的特征和标签分别⽤ $X ^ { ( t e s t ) }$ 和 $\boldsymbol y ^ { ( t e s t ) }$ 表⽰。可以采⽤的性能度量⽅式是均⽅误差（Mean Squared Error），如果$\hat { \pmb y } ^ { ( t e s t ) }$ 表⽰模型在测试集上的预测值，那么均⽅误差公式为：

$$
\mathrm {M S E} _ {\text {t e s t}} = \frac {1}{m} \sum_ {i} \left(\hat {\boldsymbol {y}} ^ {(t e s t)} - \boldsymbol {y} ^ {(t e s t)}\right) _ {i} ^ {2} = \frac {1}{m} \left\| \hat {\boldsymbol {y}} ^ {(t e s t)} - \boldsymbol {y} ^ {(t e s t)} \right\| _ {2} ^ {2} \tag {2}
$$

为了构建⼀个机器学习算法，需要设计⼀个算法，通过观察训练集 $( { \pmb X } ^ { ( t r a i n ) } , { \pmb y } ^ { ( t r a i n ) } )$ 获得经验，改进权重 $\pmb { w }$ 以减少 $\mathrm { M S E } _ { t e s t }$ 。⼀种直观的⽅式是

最小化训练集上的均方误差，即 $\mathrm { M S E } _ { t r a i n }$ 。最⼩化 $\mathrm { M S E } _ { t r a i n }$ ，我们可以简单地求解其导数为 0 的情况：

$$
\begin{array}{l} \nabla_ {\pmb {w}} \mathrm {M S E} _ {t r a i n} = 0 \\ \Rightarrow \nabla_ {\boldsymbol {w}} \frac {1}{m} \left\| \hat {\boldsymbol {y}} ^ {(t r a i n)} - \boldsymbol {y} ^ {(t r a i n)} \right\| _ {2} ^ {2} = 0 \tag {3} \\ \Rightarrow \nabla_ {\pmb {w}} \frac {1}{m} | | \pmb {X} ^ {(t r a i n)} \pmb {w} - \pmb {y} ^ {(t r a i n)} | | _ {2} ^ {2} = 0 \\ \Rightarrow \boldsymbol {w} = \left(\boldsymbol {X} ^ {(t r a i n) \top} \boldsymbol {X} ^ {(t r a i n)}\right) ^ {- 1} \boldsymbol {X} ^ {(t r a i n) \top} \boldsymbol {y} ^ {(t r a i n)} \\ \end{array}
$$

⽅程的解： ${ \pmb w } = ( { \pmb X } ^ { ( t r a i n ) \top } { \pmb X } ^ { ( t r a i n ) } ) ^ { - 1 } { \pmb X } ^ { ( t r a i n ) \top } { \pmb y } ^ { ( t r a i n ) }$ 被称为正规⽅程。

函数 $ f ( { \pmb x } ) = a { \pmb x } + b$ 称为仿射函数，其中，当 $b = 0$ 时，变为 $f ( { \pmb x } ) = a { \pmb x }$ ，称为线性函数，即线性函数是仿射函数的⼀个特例。

```python
[1]: import numpy as np  
import math  
import matplotlib.pyplot as plt 
```

[2]: X = np.hstack((np.array([[ -0.5, -0.45, -0.35, -0.35, -0.1, 0, 0.2, 0.25, 0.3, 0.5]]).reshape(-1, 1), np.ones((10, 1)) * 1))  
y = np.array([-0.2, 0.1, -1.25, -1.2, 0, 0.5, -0.1, 0.2, 0.5, 1.2]).reshape(-1, 1)  
#  
w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)  
hat_y = X.dot(w)  
print("Weight: {}.format(list(w))")  
x = np.linspace(-1, 1, 50)  
hat_y = x * w[0] + w[1]  
plt.figure(figsize=(4,4))  
plt.xlim(-1.0, 1.0)  
pltatory(-1.0, 1.0, 5))  
pltylim(-3, 3)  
plt.plot(x, hat_y, color='red')  
pltscatter(X[:,0], y[:,0], color='black')  
plt.xlabel('\\(x_1\$')  
pltylabel('\\)y\$')  
plt.title('$Linear Regression$')  
plt.show()

```json
Weight:[array([1.49333333]), array([0.04966667])] 
```

![](images/71904ac17981a0c5479b0c339b5b793a6cc0a57807f3edb44a012fc5016d5288.jpg)

# 2 容量、过拟合、欠拟合

# 2.1 泛化问题

机器学习的主要挑战在于在未见过的数据输入上表现良好，这个能⼒称为泛化能⼒ (Generalization)。我们量化⼀下模型在训练集和测试集上的表现，将其分别称为训练误差 (Training Error) 和测试误差 (Test Error)，后者也经常称为泛化误差 (Generalization Error)。可以说，理想的模型就是在最小化训练误差的同时，最小化泛化误差，具有良好泛化能⼒的算法才是符合需求的。

在实际的应⽤过程中，会采样两个数据集，减⼩训练误差得到参数后，再在测试集中验证。这个过程中，就会发⽣测试误差的期望⼤于训练误差的期望的情况。以下是决定机器学习算法效果是否好的因素：

• 降低训练误差。

• 缩⼩训练误差与测试误差之间的差距。

这俩个因素分别对应了机器学习的两个⼤挑战：⽋拟合 (Underfitting) 和过拟合 (Overfitting)。欠拟合指的是模型在训练集上的误差较大，这通常是由于训练不充分或者模型不合适导致；过拟合指的是模型在训练集和测试集上的误差差距过大，通常由于模型过分拟合了训练集中的随机噪⾳，导致泛化能⼒较差。采⽤正则化，可以降低泛化误差，我们会在第七章进⼀步的介绍。

# 2.2 容量

通过调节机器学习模型的容量，可以控制模型是否偏于过拟合还是⽋拟合，容量 (Capacity) 是描述了整个模型拟合各种函数的能力。如果容量不⾜，模型将不能够很好地表⽰数据，表现为⽋拟合；如果容量太⼤，那么模型就很容易过分拟合数据，因为其记住了不适合于测试集的训练集特性，表现为过拟合。容量的控制可以通过多种⽅法控制，包括：

• 控制模型的假设空间。  
• 添加正则项对模型进⾏偏好排除。

当机器学习算法的容量适合于所执行任务的复杂度和所提供训练数据的数量时，算法效果通常会最佳。统计学习⽅法理论提供了量化模型的容量的不同⽅法，其中最为出名的是 Vapnik-Chervonenkis 维度 (Vapnik-Chervonenkis dimension)。统计学习理论中最重要的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量增长而增长，但随着训练样本增多而下降。

通常，当模型容量上升时，训练误差会下降，直到其渐近最⼩可能误差（假设误差度量有最⼩值），⽽泛化误差会是⼀个关于模型容量的 U 形曲线函数。

![](images/4084c2e1aba3a1f8ccf58c285b4407082237d2f1b216607ba88cb86bdd4a8505.jpg)  
图 1. 容量和误差之间的典型关系

# 3 超参数与验证集

超参数：⽤来控制学习算法的参数⽽⾮学习算法本⾝学出来的参数。例如，进⾏曲线的回归拟合时，曲线的次数就是⼀个超参数；在构建模型对⼀些参数的分布假设也是超参数。

验证集 (Validation Set)：通常在需要选取超参数时，将训练集再划分为训练和验证集两部分，使⽤新的训练集训练模型，验证集用来进行测试和调整超参。通常， $8 0 \%$ 的训练数据⽤于训练学习参数， $2 0 \%$ ⽤于验证。

k 折交叉验证：将数据集均分为不相交的 k 份，每次选取其中的⼀份作为测试集，其他的为训练集，训练误差为 $k$ 次的平均误差。

[3]:

```python
def KFoldCV(D,A,k):
    k-fold
D
A
k
""
np.random.shuffle(D)
dataset = np.split(D,k)
acc_rate = 0
for i in range(k):
    train_set = dataset.copy()
    test_set = train_set.pop(i)
    train_set = np.vstack(train_set)
A.train(train_set[:,:-1],train_set[-1]) # labels = A.fit(test_set[:,:-1]) # acc_rate += np.mean(labels==test_set[:,:-1]) # 
```

# 4 偏差和方差

# 4.1 偏差

估计的偏差 (Bias) 被定义为：

$$
\operatorname {b i a s} \left(\hat {\theta} _ {m}\right) = \mathbb {E} \left(\hat {\theta} _ {m}\right) - \theta \tag {4}
$$

其中期望作⽤在所有数据上， $\theta$ 是⽤于定义数据⽣成分布的真实值。偏差反映的是模型在样本上的输出与真实值之间的误差，即模型本⾝的精准度，或者说算法本身的拟合能力。

• 如果 $b i a s ( \hat { \theta } _ { m } ) = 0$ ，那么估计量 $\hat { \theta } _ { m }$ 被称为是⽆偏 (Unbiased)。  
• 如果 $\begin{array} { r } { \operatorname* { l i m } _ { m  \infty } b i a s ( \hat { \theta } _ { m } ) = 0 } \end{array}$ ，那么估计量 $\hat { \theta } _ { m }$ 被称为是渐进⽆偏 (Asymptotically Unbiased)。

# 4.2 方差

估计的⽅差 (Variance) 被定义为：

$$
\operatorname {V a r} (\hat {\theta}) \tag {5}
$$

⽅差反映的是模型每⼀次输出结果与模型输出期望之间的误差，即模型的稳定性。

标准差被记为

$$
\operatorname {S E} \left(\hat {\mu} _ {m}\right) = \sqrt {\operatorname {V a r} \left[ \frac {1}{m} \sum_ {i = 1} ^ {m} \boldsymbol {x} ^ {(i)} \right]} = \frac {\sigma}{\sqrt {m}} \tag {6}
$$

其中， $\sigma ^ { 2 }$ 是样本 $\{ \pmb { x } ^ { ( i ) } \}$ 的真实⽅差，标准差通常被标记为 $\sigma$ 。

# 4.3 误差与偏差和方差的关系

# 一个复杂的模型并不总是能在测试集上表现出更好的性能，那么误差源于哪？

以回归为例，对测试样本 $_ { \pmb { x } }$ ，令 $y _ { D }$ 为 $_ { \pmb { x } }$ 在数据集上的标记， $y$ 为 $_ { \pmb { x } }$ 的真实标记。由于噪声的存在，有可能 $y _ { D } \ne y$ ， $f ( { \pmb x } ; D )$ 为在训练集 $D$ 上学得函数 $f$ 对 $_ { \pmb { x } }$ 的预测输出。因此，算法的期望预测可以表⽰为:

$$
\bar {f} (\boldsymbol {x}) = \mathbb {E} _ {D} [ f (\boldsymbol {x}; D) ] \tag {7}
$$

不同训练集学得的函数 $f$ 的预测输出的⽅差 (Variance) 为:

$$
\operatorname {v a r} (\boldsymbol {x}) = \mathbb {E} _ {D} \left[ \left(f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})\right) ^ {2} \right] \tag {8}
$$

期望输出与真实标记之间的差距称为偏差 (Bias) 为：

$$
\operatorname {b i a s} ^ {2} (\boldsymbol {x}) = \left(\bar {f} (\boldsymbol {x}) - y\right) ^ {2} \tag {9}
$$

噪声 (真实标记与数据集中的实际标记间的偏差) 为:

$$
\varepsilon^ {2} = \mathbb {E} _ {D} [ (y _ {D} - y) ^ {2} ] \tag {10}
$$

假定噪声期望为零，即 $\mathbb { E } _ { D } [ y _ { D } - y ] = 0$ 。算法的期望泛化误差为：

$$
\begin{array}{l} \mathbb {E} (f; D) = \mathbb {E} _ {D} [ (f (\boldsymbol {x}; D) - y _ {D}) ^ {2} ] \\ = \mathbb {E} _ {D} [ (f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x}) + \bar {f} (\boldsymbol {x}) - y _ {D}) ^ {2} ] \\ = \mathbb {E} _ {D} \left[ \left(f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})\right) ^ {2} \right] + \mathbb {E} _ {D} \left[ \left(\bar {f} (\boldsymbol {x}) - y _ {D}\right) ^ {2} \right] + \mathbb {E} _ {D} \left[ 2 \left(f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})\right) \left(\bar {f} (\boldsymbol {x}) - y _ {D}\right) \right] \\ = \mathbb {E} _ {D} \left[ \left(f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})\right) ^ {2} \right] + \mathbb {E} _ {D} \left[ \left(\bar {f} (\boldsymbol {x}) - y _ {D}\right) ^ {2} \right] \tag {11} \\ = \mathbb {E} _ {D} [ (f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})) ^ {2} ] + \mathbb {E} _ {D} [ (\bar {f} (\boldsymbol {x}) - y + y - y _ {D}) ^ {2} ] \\ = \mathbb {E} _ {D} [ (f (\boldsymbol {x}; D) - \bar {f} (\boldsymbol {x})) ^ {2} ] + \mathbb {E} _ {D} [ (\bar {f} (\boldsymbol {x}) - y) ^ {2} ] + \mathbb {E} _ {D} [ (y - y _ {D}) ^ {2} ] + \mathbb {E} _ {D} [ 2 (\bar {f} (\boldsymbol {x}) - y) (y - y _ {D}) ] \\ = \mathbb {E} _ {D} [ (f (\pmb {x}; D) - \bar {f} (\pmb {x})) ^ {2} ] + (\bar {f} (\pmb {x}) - y) ^ {2} + \mathbb {E} _ {D} [ (y - y _ {D}) ^ {2} ] \\ \end{array}
$$

式中，第⼀个加红公式等于 0，因为 $( f ( { \pmb x } ; D ) - \bar { f } ( { \pmb x } ) )$ 与 $( { \bar { f } } ( { \pmb x } ) - y _ { D } )$ 相互独⽴，所以 ${ \mathbb E } _ { D } [ 2 ( f ( { \pmb x } ; D ) - \bar { f } ( { \pmb x } ) ) ( \bar { f } ( { \pmb x } ) - y _ { D } ) ] = 2 { \mathbb E } _ { D } [ ( f ( { \pmb x } ; D ) -$ $\bar { f } ( { \pmb x } ) ) ] { \mathbb { E } _ { D } [ \bar { f } ( { \pmb x } ) - y _ { D } ) ] } _ { 0 }$ 。根据期望预测公式 $\bar { f } ( { \pmb x } ) = \mathbb { E } _ { D } [ f ( { \pmb x } ; D ) ]$ 有 $\mathbb { E } _ { D } [ ( f ( { \pmb x } ; D ) - { \bar { f } } ( { \pmb x } ) ) ] = 0 _ { \circ }$ 。同理第⼆个加红公式等于 0，因为噪声期望为 $0 _ { \circ }$ 。于是：

$$
\mathbb {E} (f; D) = \operatorname {b i a s} ^ {2} (\boldsymbol {x}) + \operatorname {v a r} (\boldsymbol {x}) + \varepsilon^ {2} \tag {12}
$$

也就是说，泛化误差可分解为偏差、⽅差与噪声之和。噪声⽆法⼈为控制，所以通常我们认为:

$$
\mathbb {E} (f; D) = \operatorname {b i a s} ^ {2} (\boldsymbol {x}) + \operatorname {v a r} (\boldsymbol {x}) \tag {13}
$$

我们需要在模型复杂度之间权衡，使偏差和⽅差得以均衡 (trade-off)，这样模型的整体误差才会最⼩。

![](images/a1fecd735be34820b175f716db32d5f888e0ce98569fe76c66bec1c2a175da98.jpg)  
图 2. 当容量增⼤ (x 轴) 时，偏差 (红线) 随之减⼩，⽽⽅差 (蓝线) 随之增⼤，使得泛化误差 (⿊线) 产⽣了另⼀种 U 形。

# 5 最大似然估计

最⼤似然估计 (Maximum Likelihood Estimation，MLE) 是⼀种最为常见的估计准则，其思想是在已知分布产生的一些样本⽽未知分布具体参数的情况下根据样本值推断最有可能产生样本的参数值。将数据的真实分布记为 $P _ { d a t a } ( \pmb { x } )$ ，为了使⽤ MLE，需要先假设样本服从某⼀簇有参数确定的分布 $P _ { m o d e l } ( \pmb { x } ; \theta )$ ，现在的⽬标就是使⽤估计的 $P _ { m o d e l }$ 来拟合真实的 $P _ { d a t a }$ (条件一：“模型已定，参数未知”)。

对于⼀组由 $m$ 个样本组成的数据集 $\pmb { X } = \{ \pmb { x } ^ { ( 1 ) } , \pmb { \cdot } \pmb { \cdot } \cdot \mathbf { \nabla } , \pmb { x } ^ { ( m ) } \}$ ，假设数据独⽴且由未知的真实数据分布 $P _ { d a t a } ( \pmb { x } )$ ⽣成 (条件二：独立同分布采样的数据)，可以通过最⼤似然估计：

$$
\begin{array}{l} \theta_ {M L} = \underset {\theta} {\arg \max } P _ {m o d e l} (\boldsymbol {X}; \theta) \\ = \arg \max  _ {\theta} \prod_ {i = 1} ^ {m} P _ {\text {m o d e l}} \left(\boldsymbol {x} ^ {(i)}; \theta\right) \tag {14} \\ \end{array}
$$

获得真实分布的参数。

通常为了计算⽅便，会对 MLE 加上 log，将乘积转化为求和然后将求和变为期望： $\begin{array} { r } { \theta _ { M L } = \arg \operatorname* { m a x } _ { \theta } \Sigma _ { i = 1 } ^ { m } \log P _ { m o d e l } ( \pmb { x } ^ { ( i ) } ; \theta ) \mathrm { { _ { \odot } } } } \end{array}$ 。

使⽤训练数据经验分布 $\hat { P } _ { d a t a }$ 相关的期望进⾏计算： $\theta _ { M L } = \arg \operatorname* { m a x } _ { \theta } \mathbb { E } _ { x \sim \hat { P } _ { d a t a } }$ log $P _ { m o d e l } ( \pmb { x } ; \theta )$ 。该式是许多监督学习算法的基础假设。

最⼤似然估计的⼀种解释是使 $P _ { m o d e l }$ 与 $P _ { d a t a }$ 之间的差异性尽可能的⼩，形式化的描述为最⼩化两者的 KL 散度。

# 6 贝叶斯统计

最⼤似然估计属于典型的频率学派统计⽅法，它假设数据是由单一的最优参数值 $\theta$ 生成，并在此基础上对参数进⾏估计。⽽另⼀种⽅法是考虑到所有的的参数值以及这些参数的先验概率分布，通过贝叶斯准则来估计参数的后验分布情况，贝叶斯统计 (Bayesian Statistics) 认为训练数据是确定的，而参数是随机且不唯一的，每个参数都有相应的概率。

在观察到数据前，将 θ 的已知知识称为先验概率分布 (Prior Probability Distribution) $p ( \theta )$ 。现在有⼀组数据样本 $\{ \pmb { x } ^ { ( 1 ) } , \cdots , \pmb { x } ^ { ( m ) } \}$ ，将数据似然及先验代⼊贝叶斯规则，得到：

$$
p \left(\theta \mid \boldsymbol {x} ^ {(1)}, \dots , \boldsymbol {x} ^ {(m)}\right) = \frac {p \left(\boldsymbol {x} ^ {(1)} , \cdots , \boldsymbol {x} ^ {(m)} \mid \theta\right) p (\theta)}{p \left(\boldsymbol {x} ^ {(1)} , \cdots , \boldsymbol {x} ^ {(m)}\right)} \tag {15}
$$

在贝叶斯常⽤情景下，先验是相对均匀的分布或高熵的高斯分布，观测数据通常会使后验的熵下降，并集中在⼏个可能性很⾼的值。当训练数据有限时，贝叶斯⽅法通常泛化得更好。

贝叶斯估计假设已知的是参数的先验分布情况和模型的类簇，之后利用数据集的样本点根据贝叶斯准则来对参数的分布情况进行修正，它得到的结果不是⼀个单⼀的参数值，⽽是根据参数先验分布和真实样本得到的修正过后的参数分布，即参数的后验分布 (Posterior Distribution)。根据贝叶斯估计，在已知 $m$ 个样本后，估计第 $m + 1$ 的样本分布的公式如下：

$$
p \left(\boldsymbol {x} ^ {(m + 1)} \mid \boldsymbol {x} ^ {(1)}, \boldsymbol {x} ^ {(2)} \dots , \boldsymbol {x} ^ {(m)}\right) = \int p \left(\boldsymbol {x} ^ {(m + 1)} \mid \theta\right) p \left(\theta \mid \boldsymbol {x} ^ {(1)} \boldsymbol {x} ^ {(2)} \dots , \boldsymbol {x} ^ {(m)}\right) d \theta \tag {16}
$$

可以看到，不同于频率学派单点估计的⽅法，贝叶斯估计在对未知数据预测时，将所有的参数分布都进⾏了考虑，同时按照参数的概率密度情况进⾏加权。(贝叶斯⽅法⽤于推断和预测可以参考第⼗⼀章)

# 7 最大后验估计

完整的贝叶斯估计需要使⽤参数的完整分布进⾏预测，然⽽对绝⼤多数的机器学习任务⽽⾔，这将会导致⼗分繁重的计算。⼀种合理的⽅式是利⽤最⼤后验估计 (Maximum A Posteriori, MAP) 来选取一个计算可行的单点估计参数作为贝叶斯估计的近似解，公式如下：

$$
\theta_ {M A P} = \underset {\theta} {\arg \max } \log p (\theta \mid \boldsymbol {x}) = \underset {\theta} {\arg \max } \log p (\boldsymbol {x} \mid \theta) + \log p (\theta) \tag {17}
$$

可以看到 MAP 的估计实际上就是对数似然加上参数的先验分布。实际上，在参数服从⾼斯分布的情况下，上式的右边就对应着 L2 正则项；在Laplace 的情况下，对应着 L1 的正则项；在均匀分布的情况下则为 0，等价于 MLE。

# 7.1 举例：线性回归

线性回归 (Linear Regression) 的⽬标：获得⼀个函数 $f$ ，满⾜ $f ( { \pmb x } ) = \hat { y }$ ，其中 $\pmb { x } \in \mathbb { R } ^ { n } , \hat { y } \in \mathbb { R }$ ，使得 $\hat { y }$ 接近于真实的标签 $y$ 。

我们定义线性回归的输出为：

$$
f (\boldsymbol {x}) = \boldsymbol {w} ^ {\top} \boldsymbol {x}
$$

其中 $\pmb { w } \in \mathbb { R } ^ { n }$ 是我们需要学习的参数。

在线性回归中，对任务 T 的定义：通过输出 $\hat { y } = \pmb { w } ^ { \top } \pmb { x }$ ，从 $_ { \pmb { x } }$ 预测 $y _ { \circ }$ 假设⼀共 $m$ 个样本。

现在通过 MLE 解释为什么性能度量方式是均方误差（Mean Squared Error）。

我们将模型预测结果和真实标签的差值定义为残差 (residual)： $\epsilon = y - f ( \pmb { x } )$ 。如果每⼀次的观测都属于独⽴事件，所有观测误差的期望和⽅差应该都⼀致：这符合中⼼极限定理，应该构成正态分布，并且误差的期望值应该是 0。所以⼤多数情况下，可以认为这个误差服从⾼斯分布，如下：

$$
\epsilon \sim N \left(0, \sigma^ {2}\right) \tag {18}
$$

于是可以得到我们的观测到的标签服从如下⾼斯分布： $y \sim N ( f ( \pmb { x } ) , \sigma ^ { 2 } )$ 。此时，我们定义了产出观测数据的模型，处于 “模型已定，参数未知” 的情况，找到⼀组参数使我们观测到⼀系列 $y$ 的概率最⼤ (最⼤似然估计的思路)。观察到结果 $y$ 的概率密度函数如下：

$$
p (y \mid \boldsymbol {x}, \boldsymbol {w}, \sigma) = \frac {1}{\sqrt {2 \pi \sigma^ {2}}} \exp \left(- \frac {(y - f (\boldsymbol {x})) ^ {2}}{2 \sigma^ {2}}\right) \tag {19}
$$

将似然函数记作： $\begin{array} { r } { \mathcal { L } ( \pmb { w } , \pmb { X } , \sigma ) = \prod _ { i = 1 } ^ { m } p ( y ^ { ( i ) } \mid \pmb { x } ^ { ( i ) } , \pmb { w } , \sigma ) } \end{array}$

对其取对数并化简：

$$
\begin{array}{l} \ln \mathcal {L} (\boldsymbol {w}, \boldsymbol {X}, \sigma) = \ln \prod_ {i = 1} ^ {m} p (y ^ {(i)} \mid \boldsymbol {x} ^ {(i)}, \boldsymbol {w}, \sigma) \\ = \sum_ {i = 1} ^ {m} \ln p \left(y ^ {(i)} \mid \boldsymbol {x} ^ {(i)}, \boldsymbol {w}, \sigma\right) (20) \\ = \sum_ {i = 1} ^ {m} \ln \left\{\frac {1}{\sqrt {2 \pi \sigma^ {2}}} \exp \left(- \frac {\left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) ^ {2}}{2 \sigma^ {2}}\right) \right\} (26) \\ = m \ln \{\frac {1}{\sqrt {2 \pi \sigma^ {2}}} \} - \frac {1}{2 \sigma^ {2}} \sum_ {i = 1} ^ {m} (y ^ {(i)} - {\pmb w} ^ {\top} {\pmb x} ^ {(i)}) ^ {2} \\ \end{array}
$$

$\sigma$ 可以假设为任意⼤于 0 的常数，优化问题化为剩下部分最⼤化 (因为负号变成最⼩化)：

$$
\boldsymbol {w} _ {\text {M L E}} = \arg \min  _ {\boldsymbol {w}} \sum_ {i = 1} ^ {m} \left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) ^ {2} \tag {21}
$$

这与 MSE ⼀致。

# 接下来考虑参数具有先验知识的情况

如果对 MLE 加⼊高斯先验分布，假设我们要求解的参数 $\pmb { w }$ 本⾝服从⼀个先验分布： ${ \pmb w } \sim N ( { \bf 0 } , { \pmb \Sigma } )$ 。这⾥我们就简单化 ${ \pmb w } \sim N ( 0 , \gamma ^ { 2 } )$ 。此时，MAP最⼤化的⽬标函数如下：

$$
\begin{array}{l} \mathcal {L} (\boldsymbol {w}) = p (y \mid \boldsymbol {X}, \boldsymbol {w}) p (\boldsymbol {w}) \\ = \prod_ {i = 1} ^ {m} \left\{\frac {1}{\sqrt {2 \pi \sigma^ {2}}} \exp \left(- \frac {\left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) ^ {2}}{2 \sigma^ {2}}\right) \right\} \prod_ {j = 1} ^ {n} \left\{\frac {1}{\sqrt {2 \pi \gamma^ {2}}} \exp \left(- \frac {\left(\boldsymbol {w} _ {j}\right) ^ {2}}{2 \gamma^ {2}}\right) \right\} \tag {22} \\ \end{array}
$$

取对数后，化简整理得如下结果：

$$
\ln \mathcal {L} (\boldsymbol {w}) = n \ln \frac {1}{\sqrt {2 \pi \sigma^ {2}}} + m \ln \frac {1}{\sqrt {2 \pi \gamma^ {2}}} - \frac {1}{2 \sigma^ {2}} \sum_ {i = 1} ^ {m} (y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}) ^ {2} - \frac {1}{2 \gamma^ {2}} \boldsymbol {w} ^ {\top} \boldsymbol {w} \tag {23}
$$

其中， $\sigma$ 和 $\gamma$ 均看作是常数，它们的取值会影响两个⽬标 (likelihood prior) 的权重，所以引⼊超参数 λ 来表⽰先验的权重，最终有:

$$
\boldsymbol {w} _ {\mathrm {M A P}} = \arg \min  _ {\boldsymbol {w}} \sum_ {i = 1} ^ {m} \left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) ^ {2} + \lambda \| \boldsymbol {w} \| ^ {2} \tag {24}
$$

上式就是标准的岭回归 (Ridge Regression) 公式，就是在最⼩⼆乘法的基础上增加的参数本⾝的先验分布，并认为参数本⾝服从⾼斯分布。

如果对 MLE 加⼊拉普拉斯分布，同样的步骤，通过 MAP 可以化简得到 (LASSO)：

$$
\boldsymbol {w} _ {\mathrm {M A P}} = \arg \min  _ {\boldsymbol {w}} \sum_ {i = 1} ^ {m} \left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}) ^ {2} + \lambda \| \boldsymbol {w} \| ^ {1} \right. \tag {25}
$$

如果对 MLE 加⼊均匀分布，最终 MAP 得到的和 MLE ⼀样。

# 自定义实现

[4]: class NaiveBayes():   
```python
def __init__(self):
    self.params = []
    self.y = None
    self_classes = None
def fit(self, X, y):
    self.y = y
    self_classes = np.unique(y) # 
    for i, c in enumerate(self_classes):
        # c X
        X.where_c = X[np.where(self.y == c)]
        self.params.append()
        # 
        for col in X.where_c.T:
            parameters = {"mean": col.mean(), "var": col.var())
            self.params[i].append(parallel)
def __calculate_prior(self, c):
    "" 
    frequency = np.mean(self.y == c)
return frequency
def __calculate_likelihood(self, mean, var, X):
    ""
    #
    # 
    eps = 1e-4 # 0
    coeff = 1.0 / math.sqrt(2.0 * math.pi * var + eps)
    exponent = math.exp(-(math.pow(X - mean, 2) / (2 * var + eps)))
    return coeff * exponent
def __calculate(probabilities(self, X):
    posteriors = []
for i, c in enumerate(self_classes):
    posterior = self._calculate_prior(c)
    for feature_value, params in zip(X, self.params[i]):
        # 
        # P(x1, x2/Y) = P(x1/Y) * P(x2/Y)
        likelihood = self._calculate_likelihood(param["mean"], params["var"], feature_value)
        posterior *= likelihood
        posteriors.append(posterior)
        # 
        return self_classes[np.argmax(posteriors)]
def predict(self, X):
    y_pred = [self._calculate(probabilities(sample) for sample in X]
return y_pred
def score(self, X, y):
    y_pred = self.predict(X)
accuracy = np.sum(y == y_pred, axis=0) / len(y)
return accuracy 
```

用自定义贝叶斯估计，iris 数据集测试  
```python
[5]: import pandas as pd from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split 
```

```python
[6]: def create_data():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    data = np.array(dfiloc[:100, :])
    return data[:,:-1], data[:,:-1]
X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
print(X_train[0], y_train[0]) 
```

```json
[5.8 2.6 4. 1.2] 1.0 
```

```julia
[7]: model = NaiveBayes()  
model.fit(X_train, y_train)  
print(model.score(X_test, y_test)) 
```

```txt
1.0 
```

用 sklearn 实现贝叶斯估计，iris 数据集测试  
[8]: # sklearn GaussianNB from sklearn.naive_bayes import GaussianNB sklearn_model $=$ GaussianNB() sklearn_model.fit(X_train，y_train) print(sk_model.score(X_test，y_test))

```txt
1.0 
```

# 8 监督学习方法

# 8.1 概率监督学习

通过定义⼀族不同的概率分布，可以将线性回归扩展到分类情况中： $p ( \boldsymbol { y } \mid \pmb { x } ; \boldsymbol { \theta } ) = N ( \boldsymbol { y } ; \boldsymbol { \theta } ^ { \top } \pmb { x } , I ) .$ 。

由于⼆元变量上的分布中，均值必须始终在 0 和 1 之间，为解决这个问题，可以使⽤ logistic sigmoid 函数将线性函数的输出压缩到区间 $( 0 , 1 )$ 上，则概率为：

$$
p (y = 1 \mid \boldsymbol {x}; \theta) = \sigma \left(\theta^ {\top} \boldsymbol {x}\right) \tag {26}
$$

这个⽅法称为逻辑回归 (Logistic Regression)。其中 logistic sigmoid 函数描述为 $\begin{array} { r } { \sigma ( x ) = \frac { 1 } { 1 + e ^ { - x } } = \frac { e ^ { x } } { 1 + e ^ { x } } } \end{array}$ 。其导数 $\begin{array} { r } { \sigma ^ { \prime } ( x ) = \sigma ( x ) ( 1 - \sigma ( x ) ) \circ } \end{array}$

具体展开为：

$$
p (y = 1 \mid \boldsymbol {x}; \theta_ {0}, \theta_ {1}) = \frac {\exp \left(\theta_ {0} + \theta_ {1} \boldsymbol {x}\right)}{1 + \exp \left(\theta_ {0} + \theta_ {1} \boldsymbol {x}\right)} = \pi (\boldsymbol {x}; \theta_ {0}, \theta_ {1}) \tag {27}
$$

$$
p (y = 0 \mid \boldsymbol {x}; \theta_ {0}, \theta_ {1}) = \frac {1}{1 + \exp (\theta_ {0} + \theta_ {1} \boldsymbol {x})} = 1 - \pi (\boldsymbol {x}; \theta_ {0}, \theta_ {1}) \tag {27}
$$

对于⼆分类问题训练⽬标, 训练⽬标为最⼤似然:

$$
\prod_ {i} ^ {m} \left[ \pi \left(\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}\right) \right] ^ {y ^ {(i)}} \left[ 1 - \pi \left(\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}\right) \right] ^ {1 - y ^ {(i)}} \tag {28}
$$

最⼤化似然相当于最⼩化其负对数似然形式：

$$
\mathcal {L} \left(\theta_ {0}, \theta_ {1}\right) = - \sum_ {i = 1} ^ {m} \left[ y ^ {(i)} \log \pi \left(\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}\right) + \left(1 - y ^ {(i)}\right) \log \left(1 - \pi \left(\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}\right)\right) \right] \tag {29}
$$

梯度下降法更新参数：

$$
\begin{array}{l} \frac {\partial \mathcal {L} (\theta)}{\partial \theta_ {j}} = - \sum_ {i = 1} ^ {m} (y ^ {(i)} \frac {1}{\pi \left(\boldsymbol {x} ^ {(i)} ; \theta_ {0} , \theta_ {1}\right)} - (1 - y ^ {(i)}) \frac {1}{1 - \pi \left(\boldsymbol {x} ^ {(i)} ; \theta_ {0} , \theta_ {1}\right)}) \frac {\partial \pi \left(\boldsymbol {x} ^ {(i)} ; \theta_ {0} , \theta_ {1}\right)}{\partial \theta_ {j}} \\ = - \sum_ {i = 1 \atop m} ^ {m} (y ^ {(i)} \frac {1}{\pi (\boldsymbol {x} ^ {(i)} ; \theta_ {0} , \theta_ {1})} - (1 - y ^ {(i)}) \frac {1}{1 - \pi (\boldsymbol {x} ^ {(i)} ; \theta_ {0} , \theta_ {1})}) \pi (\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}) (1 - \pi (\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1})) \frac {\partial \theta^ {\top} \boldsymbol {x} ^ {(i)}}{\partial \theta_ {j}} \\ = - \sum_ {i = 1} ^ {m} (y ^ {(i)} (1 - \pi (\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1})) - (1 - y ^ {(i)}) \pi (\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1})) x _ {j} ^ {(i)} \\ = - \sum_ {i = 1} ^ {m} \left(y ^ {(i)} - \pi \left(\boldsymbol {x} ^ {(i)}; \theta_ {0}, \theta_ {1}\right)\right) x _ {j} ^ {(i)} \\ \end{array}
$$

然后梯度更新 $\theta \gets \theta - \epsilon \frac { \partial \mathcal { L } ( \theta ) } { \partial \theta }$ 。 $\epsilon$ 为学习率，表⽰更新的步长。

预测过程：⽤最优 $\widehat { \theta }$ 预测新的输⼊ $_ { \pmb { x } }$ 。

$$
\widehat {\pi} (x) = \frac {\exp (\widehat {\theta} _ {0} + \widehat {\theta} _ {1} x)}{1 + \exp (\widehat {\theta} _ {0} + \widehat {\theta} _ {1} x)} \tag {31}
$$

逻辑回归的另⼀种描述：逻辑回归实质上是⽤线性模型拟合对数几率 (log odds)：

$$
\log \left(\frac {p (y = 1)}{1 - p (y = 1)}\right) = \theta^ {\top} \boldsymbol {x} \tag {32}
$$

# 自定义实现

[9]: def Sigmoid(x):

return 1/(1 + np.exp(-x))   
class LogisticRegression(): def__init__(self,learning_rate=.1): self param $=$ None self. learning_rate $=$ learning_rate self.sigmoid $=$ Sigmoid   
def __initialize_parameters(self,X): n_features $\equiv$ np.shape(X)[1] # theta[-1/sqrt(N),1/sqrt(N)] limit $= 1$ /math.sqrt(n_features) self param $=$ np.random.uniform(-limit,limit,(n_features,)   
def fit(self,X,y,n_iterations $= 4000$ ): self._initialize_parameters(X) # theta for i in range(n_iterations): # y_pred $\equiv$ self.sigmoid(X.dot(self(param)) # self param $= =$ self-learning_rate $\ast -\left(\mathrm{y - y\_pred}\right)$ .dot(X)   
def predict(self,X): y_pred $\equiv$ self.sigmoid(X.dot(self(param)) return y_pred   
def score(self,X,y): y_pred $\equiv$ self.predict(X) accuracy $=$ np.sum(y $= =$ y_pred, axis=0)/len(y) return accuracy

用自定义逻辑回归，合成数据集测试

[10]:

n_samples = 100

np.random.seed(0)

x = np.random.normal(size=n_samples)

$\mathrm{y} = (\mathrm{x} > 0)$ .astype(np.float) $\mathbf{x}[\mathbf{x} > 0] \text{== 4}$ $\mathrm{x} += .3 * \mathrm{np.random.normal(size=n_samples)}$ $\mathrm{x} = \mathrm{x}[:, \mathrm{np.newaxis}] \# \quad \text{theta}_0$ pltscatter(x, y, color='black')

[10]: <matplotlib.collections.PathCollection at 0x113db1ac8>

![](images/fee068ceca1503d1058b91f4a6dd019102c5b179524f9bf0d56422eadd57de77.jpg)

[11]: # model $=$ LogisticRegression() model.fit(x, y)

[12]: # x_test $=$ np.linspace(-5, 10, 300) x_test $=$ x_test[:, np.newaxis] prob $=$ model.predict(x_test).ravel() plt.plot(x_test, prob, color $\cdot = 1$ red', linewidth $^ { = 3 }$ ) plt.scatter(x, y, color='black'); plt.axhline(0.5, color $= " 0 . 5 "$ ); plt.ylim(-0.25, 1.25); plt.yticks([0, 0.5, 1]); plt.legend(('Logistic Regression Model'), $1 0 0 =$ lower right')

[12]: <matplotlib.legend.Legend at 0x113e21198>

![](images/3ddc8e3f5b0a301a283c17656fc9b2e530811c9200e9237602640d4b981bb14c.jpg)

用 sklearn 实现逻辑回归，合成数据集测试

[13]: from sklearn.linear_model import LogisticRegression # C solver skl_model $=$ LogisticRegression() skl_model.fit(x, y) # x_test $=$ np.linspace(-5, 10, 300) x_test $\qquad = \qquad \mathtt { x }$ _test[:, np.newaxis] prob $=$ skl_model.predict(x_test).ravel() plt.plot(x_test, prob, color $\mathrel { \mathop : } = { \mathrm { } } ^ { \mathrm { ~ } }$ 'red', linewidth $^ { = 3 }$ ) plt.scatter(x, y, color='black'); plt.axhline(0.5, color $= " 0 . 5 "$ ); plt.ylim(-0.25, 1.25); plt.yticks([0, 0.5, 1]);

```javascript
pltlegend((Logistic Regression Model'), loc='lower right') 
```

[13]: <matplotlib.legend.Legend at 0x1143a2f60>

![](images/40ec04fb487eda4031fa78495eca543693a4d25fc4c5c97ae225ba93d6952b5c.jpg)

用自定义逻辑回归，iris 数据集测试  
[14]: def create_data(): iris = load_iris() df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names) df['label'] $=$ iris.target df.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data $=$ np.array(df.iloc[:100,:]) return data[::-1],data[:,-1] X,y $=$ create_data() X_train，X_test，y_train，y_test $=$ train_test_split(X，y，test_size=0.3) print(X_train[O]，y_train[O])

[5. 3.5 1.6 0.6] 0.0   
1.0   
[15]: model $=$ LogisticRegression() model.fit(X_train，y_train) # print(model.score(X_test，y_test))

用 sklearn 实现逻辑回归，iris 数据集测试  
1.0   
```python
[16]: # sklearn Regression from sklearn.linear_model import LogisticRegression  
skl_model = LogisticRegression()  
skl_model.fit(X_train, y_train)  
#  
print(skl_model.score(X_test, y_test)) 
```

# 8.2 支持向量机

⽀持向量机 (Support Vector Machine，SVM) 同样基于线性函数 ${ \pmb w } ^ { \top } { \pmb x } + b$ ，不同于逻辑回归，SVM 不输出概率，只输出类别。SVM 的思想是找到一个分割线 (或分割平面)，把两个类别的点分得越开越好。

![](images/b3da38908706716984e8d208ffc9c95f5e5eccc9797100eb2ffc2f88b0e153c2.jpg)  
图 3. ⽀持向量机

在超平⾯ $\pmb { w } ^ { \top } \pmb { x } + b = 0$ 确定的情况下， $| { \pmb w } ^ { \top } { \pmb x } + b |$ 能够表⽰点 $_ { \pmb { x } }$ 到超平⾯的距离远近，⽽通过观察 ${ \pmb w } ^ { \top } { \pmb x } + b$ 的符号与类型标记 $y$ 符号是否⼀致，可以判断分类是否正确。于是定义函数间隔 (Functional Margin) 的概念： $\hat { \gamma } = y ( \pmb { w } ^ { \top } \pmb { x } + b ) = y f ( \pmb { x } ) \mathrm { ~ , ~ }$ 。超平面 $( { \boldsymbol { \mathbf { \mathit { w } } } } , { \boldsymbol { b } } )$ 关于训练数据集中所有样本点 $( \boldsymbol { \mathbf { \mathit { x } } } ^ { ( i ) } , \boldsymbol { \mathbf { \mathit { y } } } ^ { ( i ) } )$ 的函数间隔最小值，便成为超平面 $( { \boldsymbol { \mathbf { \mathit { w } } } } , { \boldsymbol { b } } )$ 关于数据集的的函数间隔： $\hat { \gamma } = \operatorname* { m i n } \hat { \gamma } _ { i } ( i = 1 , \ldots m ) \circ$ 。

但成⽐例的改变 $w , b$ (如都变成原来的 2 倍)，则函数间隔 $f ( { \pmb x } )$ 的值变成了原来的 2 倍，但此时超平⾯却没有改变。因此引⼊真正定义点到超平面的距离–几何间隔 (Geometrical Margin) 的概念：γe = γˆ∥w∥。 $\begin{array} { r } { \widetilde { \gamma } = \frac { \hat { \gamma } } { \Vert \pmb { w } \Vert } } \end{array}$

因此，⽬标函数可以写作： $\operatorname* { m a x } \widetilde { \gamma }$ 。

同时，限定约束条件： ${ \mathfrak { s . t . } } , y ^ { ( i ) } ( { \pmb w } ^ { \top } { \pmb x } ^ { ( i ) } + b ) = \hat { \gamma } _ { i } \geq \hat { \gamma } , \qquad i = 1 , . . . , m$

下⾯为了和传统写法统⼀以及⽅便理解，在本章的剩余内容中，我会将 $( \mathbf { \boldsymbol { x } } ^ { ( i ) } , \boldsymbol { y } ^ { ( i ) } )$ 写作 $( { \pmb x } _ { i } , y _ { i } )$ ，将样本 $_ { \pmb { x } }$ 的第 $j$ 个特征写作 $x ^ { j }$ 。如果令函数间隔$\hat { \gamma } = 1$ ，则有 $\begin{array} { r } { \widetilde { \gamma } = \frac { 1 } { \left. w \right. } } \end{array}$ 。上述⽬标函数便转化成：

$$
\left\{ \begin{array}{l} \max  \frac {1}{\| \omega \|} \\ s. t., y _ {i} \left(\omega^ {\top} \boldsymbol {x} _ {i} + b\right) = \hat {\gamma_ {i}} \geq 1, i = 1, \dots , m \end{array} \right. \tag {33}
$$

该式等价于求解：

$$
\left\{ \begin{array}{l} \min  \frac {1}{2} \| \boldsymbol {w} \| ^ {2} \\ s. t., y _ {i} \left(\boldsymbol {w} ^ {\top} \boldsymbol {x} _ {i} + b\right) = \hat {\gamma_ {i}} \geq 1, i = 1, \dots , m \end{array} \right. \tag {34}
$$

由于现在的⽬标函数是⼆次的，约束条件是线性的，所以它是⼀个凸⼆次规划问题。这个问题可以⽤现成的 QP (Quadratic Programming) 优化包进⾏求解。由于这个问题的特殊结构，还可以通过拉格朗⽇对偶性 (Lagrange Duality) 变换到对偶变量 (dual variable) 的优化问题，即通过求解与原问题等价的对偶问题 (Dual Problem) 得到原始问题的最优解，这就是线性可分条件下⽀持向量机的对偶算法。其优点在于：

• 对偶问题往往更容易求解。  
• 可以⾃然的引⼊核函数，进⽽推⼴到⾮线性分类问题。

定义拉格朗⽇函数如下式：

$$
\mathcal {L} (\boldsymbol {w}, b, \alpha) = \frac {1}{2} \| \boldsymbol {w} \| ^ {2} - \sum_ {i = 1} ^ {m} \alpha_ {i} \left[ y _ {i} \left(\boldsymbol {w} ^ {\top} \boldsymbol {x} _ {i} + b\right) - 1 \right] \tag {35}
$$

求解这个对偶学习问题，分为三个步骤 (参考第四章 KKT 条件)：

• 令 $\mathcal { L } ( w , b , \alpha )$ 关于 $\pmb { w }$ 和 b 最⼩化。  
• 利⽤ SMO 算法求解对偶问题中的拉格朗⽇乘⼦，求对 $\alpha$ 的极⼤。  
• 求参数 $\pmb { w }$ ，b 。

首先固定 $\alpha$ ，令 $\mathcal { L }$ 关于 $^ { w , b }$ 最小化

分别对 $\textbf { \em w }$ ， $b$ 求偏导数:

$$
\left\{ \begin{array}{l} \frac {\partial \mathcal {L}}{\partial \boldsymbol {w}} = 0 \Rightarrow \boldsymbol {w} = \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} \\ \frac {\partial \mathcal {L}}{\partial b} = 0 \Rightarrow \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} = 0 \end{array} \right. \tag {36}
$$

代⼊原式中得到：

$$
\begin{array}{l} \mathcal {L} (\boldsymbol {w}, b, \alpha) = \frac {1}{2} \boldsymbol {w} ^ {\top} \cdot \sum_ {i = 1} ^ {m} \alpha_ {i} \boldsymbol {x} _ {i} y _ {i} - \boldsymbol {w} ^ {\top} \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} - b \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} + \sum_ {i = 1} ^ {m} \alpha_ {i} \\ = - \frac {1}{2} \boldsymbol {w} ^ {\top} \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} - b \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} + \sum_ {i = 1} ^ {m} \alpha_ {i} \\ = - \frac {1}{2} \left[ \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} \right] ^ {\top} \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} - b \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} + \sum_ {i = 1} ^ {m} \alpha_ {i} \\ = - \frac {1}{2} \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} (\boldsymbol {x} _ {i}) ^ {\top} \cdot \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i} - b \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} + \sum_ {i = 1} ^ {m} \alpha_ {i} \\ = - \frac {1}{2} \sum_ {i, j = 1} ^ {m} \alpha_ {i} \alpha_ {j} y _ {i} y _ {j} \boldsymbol {x} _ {i} ^ {\top} \boldsymbol {x} _ {j} + \sum_ {i = 1} ^ {m} \alpha_ {i} \\ \end{array}
$$

# 利用 SMO 算法求解对偶问题中的拉格朗日乘子

经过上⼀步后得到此时的⽬标函数：

$$
\max  _ {\alpha} \sum_ {i = 1} ^ {m} \alpha_ {i} - \frac {1}{2} \sum_ {i = 1} ^ {m} \alpha_ {i} \alpha_ {j} y _ {i} y _ {j} \boldsymbol {x} _ {i} ^ {\top} \boldsymbol {x} _ {j}
$$

$$
s. t., \alpha_ {i} \geq 0, i = 1, \dots , m \tag {38}
$$

$$
\sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} = 0
$$

通过 SMO 算法可以求解对偶问题中的拉格朗⽇乘⼦ $\alpha .$ 。

# 求参数 w, b

上⾯⼀步求出了拉格朗⽇乘⼦ $\alpha$ ，可以计算出： $\begin{array} { r } { \pmb { w } ^ { * } = \sum _ { i = 1 } ^ { m } \alpha _ { i } y _ { i } \pmb { x } _ { i } . } \end{array}$

因为⽀持向量处于边界点，满⾜：

$$
\left\{ \begin{array}{l} \max  _ {y _ {i} = - 1} \boldsymbol {w} ^ {\top} \boldsymbol {x} _ {i} + b = - 1 \\ \min  _ {y _ {i} = 1} \boldsymbol {w} ^ {\top} \boldsymbol {x} _ {i} + b = 1 \end{array} \right. \tag {39}
$$

由于对于边界上的⽀持向量有 $y ( \pmb { w } ^ { \top } \pmb { x } + b ) = 1$ ，可以⽤⽀持向量求 $b$ 值： $\begin{array} { r } { b ^ { * } = y _ { j } - \sum _ { i = 1 } ^ { m } \alpha _ { i } y _ { i } \langle \pmb { x } _ { i } , \pmb { x } _ { j } \rangle , } \end{array}$ 。可以看出， $\ b { w } ^ { * }$ 和 $b ^ { * }$ 只依赖于数据中 $\alpha > 0$ 的样本点。

分类函数：

$$
\begin{array}{l} f (\boldsymbol {x}) = \left(\sum_ {\substack {i = 1 \\ m}} ^ {m} \alpha_ {i} y _ {i} \boldsymbol {x} _ {i}\right) ^ {\top} \boldsymbol {x} + b \tag{40} \\ = \sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} \langle \boldsymbol {x} _ {i}, \boldsymbol {x} \rangle + b \\ \end{array}
$$

# 8.2.1 核技巧

对于⾮线性的情况，SVM 的处理⽅法是选择⼀个核函数 $k ( \cdot , \cdot )$ ，通过将数据映射到⾼维空间，来解决在原始空间中线性不可分的问题。其思想是通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。

计算两个向量在隐式映射过后的空间中的内积的函数叫做核函数 (Kernel Function)。核函数相当于将原来的分类函数 $\begin{array} { r } { f ( { \pmb x } ) = \sum _ { i = 1 } ^ { m } \alpha _ { i } y _ { i } \langle { \pmb x } _ { i } , { \pmb x } \rangle + b } \end{array}$ 映射成了 $\begin{array} { r } { f ( { \pmb x } ) = \sum _ { i = 1 } ^ { m } \alpha _ { i } y _ { i } \langle \phi ( { \pmb x } _ { i } ) , \phi ( { \pmb x } ) \rangle + b _ { \circ } } \end{array}$ 。

其中的 $\alpha$ 值是可以通过求解由映射变形来的对偶问题得到：

$$
\max  _ {\alpha} \sum_ {i = 1} ^ {m} \alpha_ {i} - \frac {1}{2} \sum_ {i = 1} ^ {m} \alpha_ {i} \alpha_ {j} y _ {i} y _ {j} \langle \phi (\boldsymbol {x} _ {i}), \phi (\boldsymbol {x} _ {j}) \rangle
$$

$$
s. t., \alpha_ {i} \geq 0, i = 1, \dots , m \tag {41}
$$

$$
\sum_ {i = 1} ^ {m} \alpha_ {i} y _ {i} = 0
$$

这⾥的核函数描述为：对于所有的数据点 $x , z$ ，满⾜ $k ( { \pmb x } , z ) = \langle \phi ( { \pmb x } ) \cdot \phi ( z ) \rangle$ 。核函数的作用等同于用特征函数 $\phi ( { \pmb x } )$ 预处理所有输入，然后在新的转换空间学习线性模型。

# 常用核函数

线性核 (Linear kernel): $k ( u , v ) = \langle u , v \rangle$

多项式核 (Polynomial kernel): $k ( u , v ) = ( 1 + \langle u , v \rangle ) ^ { d }$

⾼斯核 (RBF kernel): $\begin{array} { r } { k ( u , v ) = N ( u - v ; 0 , \sigma ^ { 2 } I ) = \exp \left( - \frac { | | u - v | | ^ { 2 } } { 2 \sigma ^ { 2 } } \right) } \end{array}$

其中 $N ( x ; \mu , \Sigma )$ 是标准正态密度，也被称为径向基函数。

# 自定义实现

[17]:

import cvxopt   
# cuxopt   
cvxopt.solvers(options['show_progress'] = False   
def linear_kernel(\*\*karges):   
""   
def f(x1, x2): return np-inner(x1, x2) return f   
def polynomial_kernel(power, coef, \*\*karges):   
""   
def f(x1, x2): return (np(inner(x1, x2) + coef)**power return f   
def rbf_kernel(gamma, \*\*karges):   
""   
def f(x1, x2): distance $=$ np.linalg.norm(x1 - x2) \*\* 2 return np.exp(-gamma \*distance) return f   
class SupportVectorMachine():   
def __init__(self, kernel=linear_kernel, power=4, gamma=None, coef=4): self_kernel $=$ kernel self.power $=$ power self.gamma $=$ gamma self.coef $=$ coef self.lagrmultipliers $=$ None self.support_vectors $=$ None self和支持_vector_labels $=$ None self.intercept $=$ None   
def fit(self, X, y): n_samples, n_features $=$ np.shape(X) # gamma 1/n_features if not self.gamma: self.gamma $= 1$ /n_features # self_kernel $=$ self_kernel( power=slow.power, gamma=slow.gamma, coef=slow.coef) # Gram kernel_matrix $=$ np.zeros((n_samples, n_samples)) for i in range(n_samples): for j in range(n_samples): kernel_matrix[i, j] $=$ self_kernel(X[i], X[j]) # # min(1/2)x.T\*P\*x+q.T\*x,s.t. G\*x<=h,A\*x=b

```python
P = cvxopt.matrix(np外出(y, y) * kernel_matrix, tc='d')  
q = cvxopt.matrix(np.ones(n_samples) * -1)  
A = cvxopt.matrix(y, (1, n_samples), tc='d')  
b = cvxopt.matrix(0, tc='d')  
G = cvxopt.matrix(np.identity(n_samples) * -1)  
h = cvxopt.matrix(np.zeros(n_samples))  
# cvxopt  
minimization = cvxopt.solvers.qp(P, q, G, h, A, b)  
lagr_mult = np.ravel(minimization['x'])  
# 0 alpha  
idx = lagr_mult > 1e-7  
# alpha  
self.lagr-multipliers = lagr-mult[label]  
#  
self.support_vectors = X[label]  
#  
self和支持_vector_labels = y[label]  
# b  
self.intercept = self和支持_vector_labels[0]  
for i in range(len(self.lagr-multipliers)):  
    self.intercept -= self.lagr-multipliers[i] * self和支持_vector_labels[i] * self_kernel(self和支持_vectors[i], self和支持_vectors[0])  
def predict(self, X):  
    y_pred = []  
for sample in X:  
    # x, f(x)  
    prediction = 0  
    for i in range(len(self.lagr-multipliers)):  
        prediction += self.lagr-multipliers[i] * self和支持_vector_labels[i] * self_kernel(self和支持_vectors[i], sample)  
        prediction += self.intercept  
        y_pred.append(np.sign(prediction))  
return np.array(y_pred)  
def score(self, X, y):  
    y_pred = self.predict(X)  
accuracy = np.sum(y == y_pred, axis=0) / len(y)  
return accuracy 
```

用自定义的支持向量机，合成数据集测试  
[18]: <matplotlib.collections.PathCollection at 0x114594a58>   
```python
[18]: from sklearn import datasets
# X, y = datasets.makeblobs(n_samples=100, centers=2, random_state=3)
y[y == 0] = -1
y[y == 1] = 1
pltscatter(X(:,0], X(:,1)) 
```

![](images/8a1d6748f94f82247fb43366ca2022ee7b602fa649f0d3ef7887bf4bf3e2cb87.jpg)

```txt
[19]: model = SupportVectorMachine()  
model.fit(X, y)  
print(model.predict([[np.array([-0.4, -0.5])]))  
print(model.predict([[np.array([2.6, 5.3])])) 
```

[1.]

[-1.]

用 sklearn 实现支持向量机，合成数据集测试

```python
[20]: from sklearn import sm  
skl_model = sm.SVC(kernel='linear', C=1000)  
skl_model.fit(X, y)  
#  
print(sk_model.predict([[[-0.4, -0.5]]))  
print(sk_model.predict([[2.6, 5.3]])) 
```

[1]

[-1]

用自定义的支持向量机，iris 数据集测试

[21]: def create_data(): iris = load_iris() df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names) df['label'] $=$ iris.target df.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data $=$ np.array(df.iloc[:100，:]) return data[:,-1]，data[:,-1] X,y $=$ create_data() X_train，X_test，y_train，y_test $=$ train_test_split(X，y，test_size=0.3) print(X_train[O]，y_train[O]) y_train[y_train $= = 0] = -1$ # 1-1 print(X_train[O]，y_train[O])

[6.1 2.9 4.7 1.4] 1.0

[6.1 2.9 4.7 1.4] 1.0

```elixir
[22]: model = SupportVectorMachine()  
model.fit(X_train, y_train)  
#  
print(model.score(X_test, y_test)) 
```

0.43333333333333335

用 sklearn 实现支持向量机，iris 数据集测试

```python
[23]: from sklearn import sm  
skl_model = sm.SVC(kernel='linear', C=1000)  
skl_model.fit(X_train, y_train)  
#  
print(skl_model.score(X_test, y_test)) 
```

0.43333333333333335

用 sklearn 展示核函数

```python
[24]: from sklearn import smf  
from sklearn.model_selection import cross_val_score  
X, y = datasets.make_circles(n_samples=1000, factor=0.3, noise=0.1, random_state=2019)  
plt.subplot(111, aspect='equal')  
pltscatter(X[:,0], X[:,1]) 
```

[24]: <matplotlib.collections.PathCollection at 0x1146513c8>

![](images/6fba76515002e672a13b62f74b65a987ed69a11e65fb5a7a5f8d20f2b64ba8e2.jpg)

```txt
[25]: xx = np.linspace(X[:,0].min()-0.5, X[:,0].max() + 0.5, 30)  
yy = np.linspace(X[:,1].min()-0.5, X[:,1].max() + 0.5, 30)  
YY, XX = npmeshgrid(yy, xx)  
xy = np.stack([XX.ravel(), YY.ravel()]).T 
```

10-fold cv scores with linear kernel: 0.638   
```python
[26]: #  
clf =svm.SVC(kernel='linear', C=1000)  
clf.fit(X,y)  
Z = clf.decision_function(xy).reshape(XX.shape)  
#  
plt.contour(XX,YY,Z,colors='k', levels=[-1,0,1],alpha=0.5,linestyles=['--','--','--'])  
pltscatter(X[:0],X[:1]);  
print('10-fold cv scores with linear kernel: ', np.mean(cross_val_score(clf,X,y, cv=10))) 
```

![](images/8df2736616a499657b8ec35803df2511d6584b8604a2b50a6a6e397757ff7ee7.jpg)

10-fold cv scores with Polynomial kernel: 0.5290000000000001   
```txt
[27]: #  
clf =svm.SVC(kernel='poly', gamma='auto')  
clf.fit(X,y)  
Z = clf.decision_function(xy).reshape(XX.shape)  
#  
plt.contour(XX,YY,Z,colors='k',levels=[-1,0,1],alpha=0.5,linestyles=['--','--','--'])  
pltscatter(X[:0],X[:1]);  
print('10-fold cv scores with Polynomial kernel: ',np.mean(cross_val_score(clf,X,y, cv=10))) 
```

![](images/c499b7792d32da701f11ee356d4b003ad2aa75d432d8f491a1f5694c728872c9.jpg)

```python
[28]: # RBF  
clf =svm.SVC(kernel='rbf', gamma='auto')  
clf.fit(X,y)  
Z = clf.decision_function(xy).reshape(XX.shape) 
```

10-fold cv scores with RBF kernel: 1.0   
#  
plt.contour(XX,YY,Z,colors $\coloneqq$ 'k', levels $= [-1$ 0，1]，alpha $= 0.5$ ，linestyles $= [{} - - ,{} - ,{} - - ]$ pltscatter(X[;,0]，X[;,1]);  
print('10-fold cv scores with RBF kernel: ', np.mean(cross_val_score(clf，X，y，cv=10)))

![](images/fb7153eb7726ebf37b955fdeba7f33f866ff582627d05ee29ba473ef8c292087.jpg)

# 8.3 $k \mathrm { . }$ -近邻

$k \mathrm { . }$ -近邻 (k-Nearest Neighbors) 的思想是给定测试样本，基于某种距离度量 (⼀般使⽤欧⼏⾥德距离) 找出训练集中与其最靠近的 $k$ 个训练样本，然后基于这 $k$ 个 “邻居” 的信息来进⾏预测 (“物以类聚”)。

算法步骤：

• 根据给定的距离度量，在训练集中找出与 $_ { \pmb { x } }$ 最近邻的 $k$ 个点，涵盖这 $k$ 个点的 $_ { \pmb { x } }$ 的邻域记作 $\mathcal { N } _ { k } ( \pmb { x } )$ 。  
• 在 $\mathcal { N } _ { k } ( \pmb { x } )$ 中根据分类决策规则，如多数表决决定 $_ { \pmb { x } }$ 的类别 $y _ { \circ }$ 。

可见，决定了 $k$ 近邻模型的三个基本要素——距离度量、 $k$ 值的选择、分类决策规则。

# 距离度量

• ⼀般使⽤欧⼏⾥德距离   
• 相关度 (如⽪尔逊相关系数)  
• 曼哈顿距离 (Manhattan Distance)

# $k$ 值的选择

• 当选择⽐较⼩的 $k$ 值的时候，表⽰使⽤较⼩领域中的样本进⾏预测，训练误差会减⼩，但是会导致模型变得复杂，容易导致过拟合。  
• 当选择较⼤的 $k$ 值的时候，表⽰使⽤较⼤领域中的样本进⾏预测，训练误差会增⼤，同时会使模型变得简单，容易导致⽋拟合。

# 分类决策规则

• 多数表决法：每个邻近样本的权重是⼀样的，最终预测的结果为出现类别最多的那个类。  
• 加权多数表决法：每个邻近样本的权重是不⼀样的，⼀般情况下采⽤权重和距离成反⽐的⽅式来计算，最终预测结果是出现权重最⼤的那个类别。

# 自定义实现

[29]:

```python
class KNN():   
def __init__(self, k=10): self._k = k   
def fit(self, X, y): self._unique_labels = np.unique(y) self._class_num = len(self._unique_labels) self._datas = X self._labels = y.astype(np.int32)   
def predict(self, X): # dist = np.sum(np(square(X), axis=1, keepdims=True) - 2 * np.dot(X, self._datas.T) dist = dist + np.sum(np(square(self._datas), axis=1, keepdims=True).T dist = np.argsort(dist)[ :, :self._k] return np.array([np.argmax(np.bincount(self._labels[dist][i])) for i in range(len(X))) 
```

```python
def score(self, X, y):
    y_pred = self.predict(X)
    accuracy = np.sum(y == y_pred, axis=0) / len(y)
    return accuracy 
```

用自定义的 $k \mathrm { . }$ -近邻，iris 数据集测试  
[30]: def create_data(): iris = load_iris() df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names) df['label'] $=$ iris.target df.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data $=$ np.array(df.iloc[:100，:]) return data[:,-1],data[:,-1] X,y $=$ create_data() X_train,X_test,y_train,y_test $=$ train_test_split(X,y,test_size=0.3) print(X_train[O],y_train[O])

```json
[7. 3.2 4.7 1.4] 1.0 
```

[31]: model $=$ KNN() model.fit(X_train，y_train) # print(model.score(X_test，y_test))

```txt
1.0 
```

用 sklearn 实现 $k \mathrm { . }$ -近邻，iris 数据集测试  
[32]: # sklearn neighbors from sklearn import neighbors sklearn_model $=$ neighbors.KNeighborsClassifier() # sklearn_model.fit(X_train，y_train) # print(sk_model.score(X_test，y_test))

```txt
1.0 
```

# 8.4 决策树

决策树 (Decision Tree) 由节点和有向边组成，⼀般⼀棵决策树包含⼀个根节点、若⼲内部节点和若⼲叶节点。决策树的决策过程需要从决策树的根节点开始，待测数据与决策树中的特征节点进行比较，并按照比较结果选择选择下一比较分支，直到叶子节点作为最终的决策结果。

⽬标变量采⽤⼀组离散值的决策树称为分类树 (Classification Tree)(如下图左，常⽤的分类树算法有 ID3、C4.5、CART)，⽽⽬标变量采⽤连续值 (通常是实数) 的决策树被称为回归树 (Regression Tree)(如下图右，常⽤的回归树算法有 CART)。

![](images/959b13846f1f01c2b77634e77f673db554ef305adfe94cbf80818f11621160a4.jpg)  
图 4. 决策树

假设先不考虑决策树剪枝，决策树算法的核⼼问题在于特征选择和决策树⽣成。

# 8.4.1 特征选择

特征选择即选择最优划分属性，从当前数据的特征中选择⼀个特征作为当前节点的划分标准。我们希望在不断划分的过程中，决策树的分⽀节点所包含的样本尽可能属于同⼀类，即节点的 “纯度” (Impurity) 越来越⾼。⽽选择最优划分特征的标准不同，也导致了决策树算法的不同。常见的⽅

法基于以下⼏种：

• 信息增益 (Information Gain)  
• 信息增益率 (Information Gain Ratio)  
• 基尼指数 (Gini Index)

# 信息增益:

划分标准主要基于信息论。在⼀个有 $K$ 个类别的训练数据 $D$ 中，假设输出类别的概率分布为：

$$
P (y = k) = p _ {k} \tag {42}
$$

那么具有 $K$ 个类别的样本的信息熵为：

$$
H (D) = - \sum_ {k = 1} ^ {K} p _ {k} \log p _ {k} \tag {43}
$$

可以看出，当整个训练数据集只有⼀个类别时，熵最低，为 $H _ { m i n } ( D ) = - 1 \cdot l o g 1 = 0$ ；当训练数据集各类别为均匀分布时，熵最⼤，为 $H _ { m a x } ( D ) =$ $\begin{array} { r } { - K \cdot \frac { 1 } { K } \cdot \log \frac { 1 } { K } = - \log K . } \end{array}$ 。现在假设某⼀离散特征 $X _ { j }$ (表⽰取所有样本 $\boldsymbol { X }$ 的第 $j$ 个特征) 有 $V$ 个不同的的取值，那么当以特征 $x _ { j }$ 来划分时可以将数据集 $D$ 分为 $V$ 个⼦集：

$$
D = \sum_ {v = 1} ^ {V} D _ {v} \tag {44}
$$

那么划分之后的 $V$ 个⼦数据集的加权熵为：

$$
H (D \mid X _ {j}) = \sum_ {v = 1} ^ {V} \frac {\left| D _ {v} \right|}{\left| D \right|} H \left(D _ {v}\right) \tag {45}
$$

当按特征 $X _ { j }$ 来划分数据集时的信息增益 (Information Gain) 定义为：

$$
G (D, \boldsymbol {X} _ {j}) = H (D) - H (D \mid \boldsymbol {X} _ {j}) \tag {46}
$$

信息增益表⽰得知特征 $X _ { j }$ 的信息情况下使得预测类别的信息的不确定性减少程度。

信息增益有个缺点，就是会倾向于选择类别数多的特征来做划分。假设有⼀列特征 (例如样本 ID) 类别数与样本数相等，如果以该特征来进⾏划分数据集，则数据集被划分成了单样本节点，每个节点的熵均为 0，总熵也为 0。如此⼀来，就得到了最⼤的信息增益，但是这种划分显然是不合理的。

# 信息增益率：

为解决信息增益的缺点，⽽是使⽤信息增益率 (Information Gain Ratio) 来决定使⽤哪个特征来划分数据集。其定义为：

$$
G R (D, \boldsymbol {X} _ {j}) = \frac {G (D , \boldsymbol {X} _ {j})}{I V (\boldsymbol {X} _ {j})} \tag {47}
$$

其中 $I V ( \pmb { X } _ { j } )$ 被称为固有值 (Intrinsic Value)，它等价于这个特征在数据集中的熵。

具体来说，假设考虑数据集 $D$ 中的特征 $X _ { j }$ ，它有 $V$ 个不同的取值 $s _ { 1 } , \cdots , s _ { V }$ ，那么特征 $X _ { j }$ 在数据集中的概率分布为：

$$
P \left(\boldsymbol {X} _ {j} = s _ {v}\right) = \frac {\left| D _ {v} \right|}{\left| D \right|} = p _ {v} \tag {48}
$$

那么数据集中该特征的固有值 (熵) 为：

$$
I V \left(\boldsymbol {X} _ {j}\right) = - \sum_ {v = 1} ^ {V} p _ {v} \log p _ {v} \tag {49}
$$

# 基尼指数：

对于有 $K$ 个类别的数据集 $D$ ，某⼀样本属于类别 $k$ 的概率等于该类别的分布概率：

$$
P (y = k) = p _ {k} \tag {50}
$$

那么数据集 $D$ 的基尼指数定义如下：

$$
G i n i (D) = 1 - \sum_ {k = 1} ^ {K} p _ {k} ^ {2} \tag {51}
$$

由公式可以看出，基尼指数表⽰的是从数据集中随机取两个样本类别不同的概率，其值越⼩则数据集纯度越⾼。

如对⼀个数据集 $D$ 以特征 $X _ { j }$ 的⼀个取值 $s _ { v }$ 来划分，那么数据集会被划分成 $D _ { X _ { j } = s _ { v } }$ 和 $D _ { X _ { j } \neq s _ { v } }$ ，那么数据集 $D$ 依照特征 $X _ { j } = s _ { v }$ 划分之后的加权基尼指数为：

$$
G i n i (D \mid \boldsymbol {X} _ {j} = s _ {v}) = \frac {\left| D _ {\boldsymbol {X} _ {j} = s _ {v}} \right|}{\left| D \right|} G i n i \left(D _ {\boldsymbol {X} _ {j} = s _ {v}}\right) + \frac {\left| D _ {\boldsymbol {X} _ {j} \neq s _ {v}} \right|}{\left| D \right|} G i n i \left(D _ {\boldsymbol {X} _ {j} \neq s _ {v}}\right) \tag {52}
$$

# 8.4.2 决策树生成

<table><tr><td>生成算法</td><td>划分标准</td></tr><tr><td>ID3</td><td>信息增益</td></tr><tr><td>C4.5</td><td>信息增益率</td></tr><tr><td>CART</td><td>基尼指数</td></tr></table>

# ID3 算法：

ID3 算法的核⼼是在决策树各个节点上根据信息增益来选择进行划分的特征，然后递归地构建决策树。

算法思路：⾸先，树的根节点中包含整个数据集，ID3 算法会遍历所有特征分别来计算划分后的信息增益，选择信息增益最⼤的特征；然后由该特征的不同取值建⽴⼦节点，将数据集划分到新⼀层的各个⼦节点中；对各个⼦节点中的数据递归进⾏这个过程，直到信息增益⾜够⼩或者⽆特征可⽤，最终得到决策树。

# CART 算法：

# 分类树

CART 分类树选取特征的依据是基尼指数，在划分时会遍历所有的特征与其所有可能的取值，再全局考量选取⼀个最佳特征与最佳划分点。若数据集有 $n$ 个特征，每个特征 $X _ { j }$ 有 $V _ { j }$ 种不同取值，CART 分类树可以⽤下式来表述：

$$
\left(\boldsymbol {X} _ {*}, s _ {*}\right) = \arg \min  \left(G (D \mid \boldsymbol {X} _ {j} = s _ {v})\right), \quad j f r o m 1 \rightarrow n, v f r o m 1 \rightarrow V _ {j} \tag {53}
$$

# 回归树

⾸先需要说明的是前⾯分类树的输出是叶⼦节点所有样本⽬标值的多数表决，回归树的输出是叶⼦节点中所有样本⽬标值的均值。那么对于回归任务，如何⽣成树？可以采⽤⼀种直观的⽅式来对数据集进⾏划分，假设某⼀时刻数据集 (数据⼦集) $D$ 被决策树以特征 $X _ { j }$ 按取值 $s$ 划分成了两部分 (或两个叶⼦节点)：

$$
\mathrm {R} _ {1} \left(\boldsymbol {X} _ {j}, s\right) = \left\{\boldsymbol {X} \mid \boldsymbol {X} _ {j} <   s \right\} \tag {54}
$$

$$
\operatorname {R} _ {2} \left(\boldsymbol {X} _ {j}, s\right) = \left\{\boldsymbol {X} \mid \boldsymbol {X} _ {j} \geq s \right\}
$$

则此次划分的优劣可以⽤ MSE 判断，⽤真实值和划分区域的预测值的最⼩⼆乘来衡量：

$$
\operatorname {M S E} \left(\boldsymbol {X} _ {j}, s\right) = \sum_ {\mathrm {R} _ {1}} \left(y _ {i} - \bar {y} _ {\mathrm {R} _ {1}}\right) ^ {2} + \sum_ {\mathrm {R} _ {2}} \left(y _ {i} - \bar {y} _ {\mathrm {R} _ {2}}\right) ^ {2} \tag {55}
$$

其中， $\hat { y } _ { \mathrm { R _ { 1 } } }$ 为 $\mathrm { R _ { 1 } }$ 区域所有样本⽬标值的均值， $\hat { y } _ { \mathrm { R _ { 2 } } }$ 为 $\mathrm { R _ { 2 } }$ 区域所有样本⽬标值的均值。

在⽣成回归树时，使⽤贪⼼策略，遍历所有特征下所有可能的取值，找到⼀个最优分割点，然后以此类推。决策树在做预测时，⾸先将测试样本输⼊决策树进⾏判定，判定该测试样本属于哪⼀个叶⼦节点，然后把该叶⼦结点内所有训练样本的⽬标均值作为测试样本的预测值。

除了使⽤ MSE 作为分裂依据之外，还有⼀个指标可以⽤作回归树的分裂：⽅差 (Variance)。当使⽤⽅差作为分裂依据时，⽣成树的⽬的是希望⼦节点内的值越稳定越好。

回归同样是考虑分割前后使得指标变化最⼤的特征 $X _ { j }$ 及特征取值 s。

# 8.4.3 决策树正则化

决策树算法的缺点在于极易过拟合，所以控制决策树的模型复杂度以防⽌过拟合是很有必要的。

⾸先可以设定⼏个参数抑制树的⽣长：最⼤的树深、分割的最少样本数、分割的最⼩纯度。除此之外，也可以对树的⽣长不做限制，然后再对树进⾏剪枝。CART 便使⽤ Cost-Complexity 剪枝⽅法。

我们⽤ $T$ 表⽰⼀棵树， $\mathcal { L } ( T )$ 表⽰树 $T$ 的分类 (回归) 误差。设 $\alpha$ 为正则化系数， $\Omega ( T )$ 是能表⽰树结构复杂度的函数。于是 Cost-Complexity 函数：

$$
J _ {\alpha} (T) = \mathcal {L} (T) + \alpha \Omega (T) \tag {56}
$$

令树 $T$ 的结构复杂度函数等于树的叶节点数：

$$
\Omega (T) = | T | \tag {57}
$$

以及树 $T$ 的误差函数为：

$$
\mathcal {L} (T) = \sum_ {i = 1} ^ {| T |} \operatorname {e r r} \left(t _ {i}\right) p \left(t _ {i}\right) \tag {58}
$$

其中 $t _ { i }$ 为树 $T$ 中的第 $i$ 个叶节点， $e r r ( t _ { i } )$ 为该叶节点的分类误差率， $p ( t _ { i } )$ 为该叶节点的样本⽐例。所以这实质上是⼀个加权误差率。对⼀个确定的 $\alpha$ 值，⼀定会有⼀颗最⼩化 $J _ { \alpha }$ 的树 $T _ { \alpha }$ 。为了找到这颗最优剪枝树 $T _ { \alpha }$ ，使⽤最弱连接剪枝 (Weakest Link Pruning) 策略，⾃底向上地对⾮叶节点进⾏剪枝并查看效果，然后选取⼀个表现最好的 $T _ { \alpha }$ 。

假设某⼀时刻以节点 $t$ 进⾏剪枝，那么剪枝后与剪枝前的 Cost-Complexity 函数差为：

$$
\begin{array}{l} \Delta J _ {\alpha} (t) = J _ {\alpha} (T - T _ {t}) - J _ {\alpha} (T) \\ = \mathcal {L} \left(T - T _ {t}\right) - \mathcal {L} (T) + \alpha \left(\left| T - T _ {t} \right| - \left| T \right|\right) \tag {59} \\ = (- \mathcal {L} (T _ {t}) + e r r (t)) + \alpha (- | T _ {t} | + 1) \\ = e r r (t) - \mathcal {L} \left(T _ {t}\right) + \alpha \left(1 - \left| T _ {t} \right|\right) \\ \end{array}
$$

其中，Tt 为树 T 中以节点 t 为根节点的⼦树。令 ∆Jα(t) = 0，得到 g(t) = α’ = err(t)−L(Tt)|T −1| 。 $T _ { t }$ $T$ $\Delta J _ { \alpha } ( t ) = 0$ $\begin{array} { r } { g ( t ) = \alpha ^ { \prime } = \frac { e r r ( t ) - \mathcal { L } ( T _ { t } ) } { | T _ { t } - 1 | } , } \end{array}$ 。

于是算法流程如下：

1. ⽣成⼀颗完整树 $T ^ { 0 }$ ，对所有的⾮叶节点都进⾏剪枝尝试，找到⼀个最⼩化 $g ( t _ { 1 } )$ 的剪枝节点 $t _ { 1 }$ ，令 $\alpha ^ { 1 } = g ( t _ { 1 } ) , \ T ^ { 1 } = T ^ { 0 } - T _ { t _ { 1 } } { } $   
2. 对 $T ^ { 1 }$ 所有的⾮叶节点都进⾏剪枝尝试，找到⼀个最⼩化 $g ( t _ { 2 } )$ 的剪枝节点 $t _ { 2 }$ ，令 $\alpha ^ { 2 } = g ( t _ { 2 } )$ ， $T ^ { 2 } = T ^ { 1 } - T _ { t _ { 2 } }$ 。  
3. 依次进⾏下去，直到只剩下⼀个根节点为⽌，那么可以得到⼀个⼦树序列 $[ { T ^ { 0 } } , { T ^ { 1 } } , . . . , { r o o t } ]$ 和⼀系列参数 $[ \alpha ^ { 1 } , \alpha ^ { 2 } , \ldots ]$ ，然后在所有⼦树上使⽤交叉验证来选取⼀个最佳参数 $\hat { \alpha }$ 与最佳剪枝树 $T _ { \hat { \alpha } }$ 。

自定义实现 (主要基于 CART )  
[33]: class DecisionNode():   
```python
def __init__(self, feature_i=None, threshold=None, value=None, true_branch=None, false_branch=None):
    self.feature_i = feature_i # 
    self.threshold = threshold # 
    self.value = value # 
    self(true_branch = true_branch # 
    self,false_branch = falsebranch # 
```

```python
largest_impurity = 0
best criteria = None # 
best_sets = None # 
if len(np.shape(y)) == 1:
    y = npexpand_dims(y, axis=1)
Xy = np concatenate((X, y), axis=1)
n_samples, n_features = np.shape(X)
if n_samples >= self.min_samples_split and current_depth <= self.max_depth:
    # 
    for feature_i in range(n_features):
        feature_values = npexpand_dims(X[:, feature_i], axis=1)
        unique_values = np.unique(feature_values) 
        # i 
    for threshold in unique_values:
        # X i X y Xy1
Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold) 
    if len(Xy1) > 0 and len(Xy2) > 0:
        # X y
    y1 = Xy1[:, n_features:] 
    y2 = Xy2[:, n_features:] 
    # 
        impurity = self._impurity Calculation(y, y1, y2) 
    # 
    if impurity > largest_impurity:
        largest_impurity = impurity 
        best criteria = {"feature_i": feature_i, "threshold": threshold} 
        best_sets = {
            "leftX": Xy1[:, n_features], # X
            "lefty": Xy1[:, n_features], # y
            "rightX": Xy2[:, n_features], # X
            "righty": Xy2[:, n_features:] # y
        } 
if largest_impurity > self.min_impurity:
    # 
    true_branch = self._build_tree(best_sets["leftX"], best_sets["lefty"], current_depth + 1)
false_branch = self._build_tree(best_sets["rightX"], best_sets["righty"], current_depth + 1)
return DecisionNode feature_i = best criteria["feature_i"], threshold=best criteria[ "threshold"], true_branch=true_branch, falsebranch=false_branch) 
# 
leaf_value = self._leaf_value Calculation(y) 
return DecisionNode(value=leaf_value) 
def predict_value(self, x, tree=None):
    ""
    ""
    #
    if tree is None:
        tree = self.root 
    # 
if tree.value is not None: 
    return tree.value 
    #
    feature_value = x-tree.feature_i] 
branch = tree,false branch 
if isinstance(feature_value, int) or isinstance(feature_value, float): 
    if feature_value >= tree.tree:EThreshold: 
```

branch $=$ tree:true_branch
elif feature_value $\equiv$ tree.threshold:
    branch $=$ tree:true_branch
return self.predict_value(x, branch)
def predict(self, X):
    y_pred $=$ [self.predict_value(sample) for sample in X]
    return y_pred
def score(self, X, y):
    y_pred $=$ self.predict(X)
accuracy $=$ np.sum(y == y_pred, axis=0) / len(y)
return accuracy
def print_tree(self, tree=None, indent=" ):
    ""
    ""
    if not tree:
        tree = self.root
if tree.value is not None:
    print.tree.value)
else:
    print("feature|threshold -> %s | %s" % (tree.feature_i, tree.threshold))
print("%sT->" % (indent), end=(""))
self.print_tree-tree:true_branch, indent + indent)
print("%sF->" % (indent), end=("'))
self.print_tree.tree,false_branch, indent + indent)

[34]:

```python
def calculate_entropy(y):
    log2 = lambda x: math.log(x) / math.log(2)
    unique_labels = np.unique(y)
    entropy = 0
    for label in unique_labels:
        count = len(y[y == label])
        p = count / len(y)
        entropy += -p * log2(p)
    return entropy
def calculate_gini(y):
    unique_labels = np.unique(y)
    var = 0
    for label in unique_labels:
        count = len(y[y == label])
        p = count / len(y)
        var += p ** 2
    return 1 - var
class ClassificationTree(DecisionTree):
    def __calculate_gini_index(self, y, y1, y2):
        ____________
        p = len(y1) / len(y)
        gini = calculate_gini(y)
        gini_index = gini - p * \ 
```

```python
calculate_gini(y1) - (1 - p) * \  
calculate_gini(y2)  
return gini_index  
def _calculate_information_gain(self, y, y1, y2):  
    '''  
    '''  
    p = len(y1) / len(y)  
    entropy = calculate_entropy(y)  
    info_gain = entropy - p * \  
    calculate_entropy(y1) - (1 - p) * \  
    calculate_entropy(y2)  
    return info_gain  
def _majority Vote(self, y):  
    '''  
    '''  
    most_common = None  
    max_count = 0  
for label in np.unique(y):  
    count = len(y[y == label])  
    if count > max_count:  
        most_common = label  
        max_count = count  
return most_common  
def fit(self, x, y):  
    self._impurity Calculation = self._calculate_gini_index  
    self._leaf_value Calculation = self._majorityVote  
super(ClassificationTree, self).fit(x, y)  
def calculate_mse(y):  
    return np.mean((y - np.mean(y)) ** 2)  
def calculate_variance(y):  
    n_samples = np.shape(y)[0]  
variance = (1 / n_samples) * np.diag((y - np.mean(y)).T.dot(y - np.mean(y)))  
return variance  
class RegressionTree(DecisionTree):  
    '''  
    MSE/  
    '''  
def _calculate_mse(self, y, y1, y2):  
    '''  
    MSE  
    '''  
mse_tot = calculate_mse(y)  
mse_1 = calculate_mse(y1)  
mse_2 = calculate_mse(y2)  
frac_1 = len(y1) / len(y)  
frac_2 = len(y2) / len(y)  
mse_reduction = mse_tot - (frac_1 * mse_1 + frac_2 * mse_2)  
return mse Reduction  
def _calculate_variance_reduction(self, y, y1, y2): 
```

```python
```
```
var_tot = calculate-variance(y)
var_1 = calculate-variance(y1)
var_2 = calculate-variance(y2)
frac_1 = len(y1) / len(y)
frac_2 = len(y2) / len(y)
variance_reduction = var_tot - (frac_1 * var_1 + frac_2 * var_2)
return sum(variance Reduction)
def_mean_of_y(self, y):
    return value if len(value) > 1 else value[0]
def fit(self, x, y):
    self._impurity Calculation = self._calculate_mse
    self._leaf_value Calculation = self._mean_of_y
    super(RegressionTree, self).fit(x, y) 
```

用自定义的分类树，iris 数据集测试  
[36]: def create_data(): iris = load_iris() df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names) df['label'] $=$ iris.target df.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data $=$ np.array(df.iloc[:100,:]) return data[:,-1],data[:,-1] X,y $=$ create_data() X_train，X_test，y_train，y_test $=$ train_test_split(X，y，test_size=0.3) print(X_train[O]，y_train[O])

[5. 3.6 1.4 0.2] 0.0   
[37]: # model $=$ ClassificationTree() model.fit(X_train，y_train) # print(model.score(X_test，y_test))

1.0   
```txt
[38]: model.print_tree() 
```

```txt
feature|threshold -> 2 | 3.0  
T->1.0  
F->0.0 
```

用自定义的回归树，iris 数据集测试  
1.0   
[39]: # model $=$ RegressionTree() model.fit(X_train，y_train) # print(model.score(X_test，y_test))

```txt
[40]: model.print_tree() 
```

feature|threshold $\rightarrow$ 2 |3.0 T->1.0 F->0.0

用 sklearn 实现分类树，iris 数据集测试

```python
[41]: from sklearn import tree  
skl_model = tree.DecisionTreeClassifier()  
skl_model.fit(X_train, y_train)  
#  
print(skl_model.score(X_test, y_test)) 
```

```txt
1.0 
```

用 sklearn 实现回归树，iris 数据集测试

```python
[42]: from sklearn import tree  
skl_model = tree.DecisionTreeRegressor()  
skl_model.fit(X_train, y_train)  
#  
print(skl_model.score(X_test, y_test)) 
```

```txt
1.0 
```

# 9 无监督学习方法

⽆监督学习的任务是找到数据更简单的表⽰：低维表⽰、稀疏表⽰和独⽴表⽰。低维表⽰将数据压缩到维度更少的空间中；稀疏表⽰将数据扩展到更多维度，但数据倾向于表⽰在坐标轴上；独⽴表⽰将数据拆分到能独⽴统计的维度上。

# 9.1 主成分分析法

主成分分析法，亦名 PCA。在第⼆章我们已经介绍过，为⽅便阅读，这⾥重述⼀下。PCA 将输⼊ $_ { \pmb { x } }$ 投影表⽰成 $\scriptstyle c _ { \circ } \ c$ 是⽐原始输⼊维数更低的表⽰，同时使得元素之间线性⽆关。假设有⼀个 $m \times n$ 的矩阵 $\boldsymbol { X }$ ，数据的均值为零，即 $\mathbb { E } [ \pmb { x } ] = 0$ ， $\boldsymbol { X }$ 对应的⽆偏样本协⽅差矩阵： $\begin{array} { r } { \mathrm { V a r } \left[ \pmb { x } \right] = \frac { 1 } { m - 1 } \pmb { X } ^ { \top } \pmb { X } . } \end{array}$ 。

PCA 是通过线性变换找到一个 $\mathbf { V a r } \left[ c \right]$ 是对角矩阵的表⽰ $\pmb { c } = \pmb { V } ^ { \top } \pmb { x }$ ，矩阵 $\boldsymbol { X }$ 的主成分可以通过奇异值分解 (SVD) 得到，也就是说主成分是 $\boldsymbol { X }$ 的右奇异向量。假设 $V$ 是 $\pmb { X } = \pmb { U } \pmb { \Sigma } \pmb { V } ^ { \top }$ 奇异值分解的右奇异向量，我们得到原来的特征向量⽅程：

$$
\boldsymbol {X} ^ {\top} \boldsymbol {X} = \left(\boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top}\right) ^ {\top} \boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top} = \boldsymbol {V} \boldsymbol {\Sigma} ^ {\top} \boldsymbol {U} ^ {\top} \boldsymbol {U} \boldsymbol {\Sigma} \boldsymbol {V} ^ {\top} = \boldsymbol {V} \boldsymbol {\Sigma} ^ {2} \boldsymbol {V} ^ {\top} \tag {60}
$$

因为根据奇异值的定义 $U ^ { \top } U = I$ 。因此 $\boldsymbol { X }$ 的⽅差可以表⽰为： $\begin{array} { r } { \operatorname { V a r } \left[ \pmb { x } \right] = \frac { 1 } { m - 1 } \pmb { X } ^ { \top } \pmb { X } = \frac { 1 } { m - 1 } \pmb { V } \pmb { \Sigma } ^ { 2 } \pmb { V } ^ { \top } \circ } \end{array}$

所以 $^ c$ 的协⽅差满⾜： $\textstyle \operatorname { V a r } [ c ] = { \frac { 1 } { m - 1 } } C ^ { \top } C = { \frac { 1 } { m - 1 } } V ^ { \top } X ^ { \top } X V = { \frac { 1 } { m - 1 } } V ^ { \top } V \Sigma ^ { 2 } V ^ { \top } V = { \frac { 1 } { m - 1 } } \Sigma ^ { 2 }$ = 1m−1V ⊤X⊤XV = 1m− ，因为根据奇异值定义 $V ^ { \top } V = I$ 。 $^ c$ 的协⽅差是对⾓的， $^ c$ 中的元素是彼此⽆关的。

# 自定义实现

```txt
[44]: class PCA(): 
```

```python
def __init__(self):
    pass
def fit(self, X, n_components):
    n_samples = np.shape(X)[0]
    covariance_matrix = (1 / (n_samples - 1)) * (X - X.mean(axis=0)).T.dot(X - X.mean(axis=0))
    # eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    # idx = eigenvalues.argsort([[:-1])
    eigenvalues = eigenvalues[idx][:n_components]
    eigenvectors = np.atleast_1d(eigenvectors[:, idx])[:, :n_components]
    # 
```

Xtransformed $=$ X.dot(eigenvectors) return Xtransformed

用自定义的 PCA，iris 数据集测试  
[45]: def create_data(): iris = load_iris() df = pd.DataFrame(iris.data,columns $\equiv$ iris.feature_names) df['label'] $=$ iris.target df.columns $=$ ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data $=$ np.array(df.iloc[:100,:]) return data[:,-1],data[:,-1] X,y $=$ create_data() X_train,X_test,y_train,y_test $=$ train_test_split(X,y,test_size=0.3) print(X_train[O],y_train[O])

```json
[6.4 3.2 4.5 1.5] 1.0 
```

```txt
[46]: model = PCA()  
model.fit(X_train[:20], 2) # 20 
```

```json
[46]: array([-5.75535057, 6.35428159], [-2.20479768, 5.95454742], [-2.26520769, 5.87699147], [-5.75594076, 6.00577621], [-2.30122891, 6.298297 ], [-2.5234036, 6.07896967], [-6.28590718, 5.67677524], [-4.04494949, 5.07447986], [-5.72955335, 6.51557733], [-5.98904726, 5.94901496], [-2.0822997, 5.87694555], [-1.95898348, 5.11327258], [-5.71754628, 6.37514216], [-5.10531342, 5.27893081], [-5.27416173, 5.68555962], [-2.18424456, 5.46422474], [-2.18386992, 6.24395656], [-2.51767442, 6.40421362], [-5.27762276, 5.47610728], [-2.14860047, 6.44145051]] 
```

# 9.2 $k \mathrm { . }$ -均值聚类

$k \mathrm { . }$ -均值聚类 (k-means) 算法的基本思想是初始随机给定 $k$ 个簇中心，按照最邻近原则把待分类样本点分到各个簇。然后按平均法重新计算各个簇的质心，从而确定新的簇心。一直迭代，直到簇心的移动距离小于某个给定的值。 $k$ 是我们事先需要给定的聚类数⽬。

算法步骤：

• 初始化 $k$ 个不同的中⼼点 $\{ \mu _ { 1 } , \cdots , \mu _ { k } \}$ , 然后迭代交换以下两个步骤直⾄收敛。  
• 第⼀步：每个训练样本分配到最近的中⼼点 $\mu _ { i }$ 所代表的聚类 i。  
• 第⼆步：每⼀个中⼼点 $\mu _ { i }$ 更新为聚类 $i$ 中所有训练样本 $\mathbf { \boldsymbol { x } } _ { j }$ 的均值。

自定义实现  
```javascript
[47]: def distEclud(x,y): return np.sum((x-y)**2)) def randomCent(dataSet,k): 
```

```python
```
```
m,n = dataSet.shape
centroids = np.zeros((k,n))
for i in range(k):
    index = int(np.random.uniform(0,m))
    centroids[i,:] = dataSet[index,:]
return centroids
class KMeans():
    def __init__(self):
        self.dataSet = None
        self.k = None
def fit(self, dataSet, k):
    self.dataSet = dataSet
    self.k = k
    m = np.shape(dataSet)[0]
    #
    #
    clusterAssment = np.mat(np.zeros((m,2)))
    clusterChange = True
centroids = randomCent(self.dataSet,k)
while clusterChange:
    clusterChange = False
    for i in range(m):
        minDist = 1e6
        minIndex = -1
        #
        for j in range(k):
            distance = distEclud(centroids[j,:], self.dataSet[i,:])
            if distance < minDist:
                minDist = distance
                minIndex = j
            #
            if clusterAssment[i,0] != minIndex:
                clusterChange = True
                clusterAssment[i,:] = minIndex, minDist**2
            #
        for j in range(k):
            pointsInCluster = dataSet(np.nonzero(clusterAssment[:,0].A == j)[0]) # 
            centroids[j,:] = np.mean(pointsInCluster, axis=0) # 
```

# 用自定义的 $k \mathrm { . }$ -均值聚类，合成数据集测试

[48]: X, y = datasets.make_blobs(n_samples=100, centers $\scriptstyle \{ = 2$ , random_state=3)

plt.scatter(X[:,0], X[:,1]);

![](images/63b97a5022f3aaefe92e348eeacd4c099d9ca98efc1efd674ac9654987fb6dcb.jpg)

```txt
[49]: model = KMeans()  
center, clusterAssment = model.fit(X, k=2)  
y_pred = np.squeeze(np.array(clusterAssment[:,0])) 
```

```javascript
[50]: plt.scaner(X[:,0], X[:,1], c=y_pred); 
```

![](images/f844792962c1f4cee5c143eb7917f697fb685a1571eb724f0a45558b7a5ac666.jpg)

```python
[51]: import matplotlib  
import numpy  
import sklearn  
import pandas  
import cvxopt  
print("numpy:", numpy._version_)  
print("matplotlib:", matplotlib._version_)  
print("sklearn:", sklearn._version_)  
print("pandas:", pandas._version_)  
print("cvxopt:", cvxopt._version_) 
```

```txt
numpy: 1.14.5  
matplotlib: 3.1.1  
sklearn: 0.21.3  
pandas: 0.25.1  
cvxopt: 1.2.4 
```

# 深度前馈⽹络

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 深度前馈网络

深度前馈⽹络 (Deep Feedforward Network，DFN) 也叫前馈神经⽹络 (Feedforward Neural Network，FNN) 或多层感知机 (MultilayerPerceptron，MLP)，是最典型的深度学习模型。⽬标是拟合⼀个函数，如有⼀个分类器 $y \ = \ f ^ { * } ( x )$ 将输⼊ $x$ 映射到输出类别 $y _ { \mathrm { ~ c ~ } }$ 。深度前馈⽹将这个映射定义为 $f ( x , \theta )$ 并学习这个参数 $\theta$ 的值来得到最好的函数拟合。

深度前馈⽹络中信息从 $x$ 流⼊，通过中间 $f$ 的计算，最后到达输出 $y$ 。如图 1 所⽰，假设有 $f ^ { ( 1 ) } , f ^ { ( 2 ) } , f ^ { ( 3 ) }$ 这三个函数链式连接，这个链式连接可以表⽰为 $f ( x ) = f ^ { ( 3 ) } ( f ^ { ( 2 ) } ( f ^ { ( 1 ) } ( x ) ) )$ ，这种链式结构是神经⽹络最为常⽤的结构。 $f ^ { ( 1 ) } , f ^ { ( 2 ) }$ 被称为神经⽹络的第⼀层，第⼆层，也为⽹络的隐藏层(Hidden Layer)，深度前馈⽹络最后⼀层 $f ^ { ( 3 ) }$ 就是输出层 (Output Layer)。这个链的长度就是神经⽹络的深度，输⼊向量的每个元素均视作⼀个神经元。

![](images/2979b4f5f03d48b37e738cceb1b6c8e34af589018f3401bb18486b975edd9b34.jpg)  
图 1. 深度前馈⽹络⽰意图

# 2 DFN 相关设计

DFN 内部的神经⽹络层可以分为三类，输⼊层，隐藏层和输出层。为了构造⼀个可训练的 DFN，我们需要考虑⼏个⽅⾯，包括隐藏单元，输出单元，和代价函数 (损失函数)。

# 2.1 隐藏单元

层与层之间是全连接的，也就是说，第 $i$ 层的任意⼀个神经元⼀定与第 $i + 1$ 层的任意⼀个神经元相连。如下图所⽰，⼤多数隐藏单元 (Hidden Unit)都可以描述为接受输⼊向量 $_ { \pmb { x } }$ ，计算仿射变换 $\pmb { z } = \pmb { W } ^ { \top } \pmb { x } + \pmb { b }$ ，然后使⽤⼀个逐元素的⾮线性函数 $g ( z )$ 得到隐藏单元的输出 $\mathbf { \delta } \mathbf { a } _ { \textsf { c } }$ 。⽽⼤多数隐藏单元的区别仅仅在于激活函数 $g ( z )$ 的形式。(这里增加激活函数，是为了提高模型的表达能力；如果不引入激活函数，可以验证，无论多少层神经网络，输出都是输入的线性组合)

![](images/2e8e4473c1b59aa80d87475fd91f99a78276abff3a966c1c67b8bba5488519eb.jpg)  
图 2. 深度前馈⽹络及第⼀层隐藏单元⽰意图

如图 2 所⽰，假设激活函数 $g ( z )$ 为 $\sigma$ ，于是 $f ^ { ( 1 ) }$ 层的隐藏单元可以描述为：

$$
\left\{ \begin{array}{l} a _ {1} = \sigma \left(z _ {1}\right) = \sigma \left(w _ {1 1} x _ {1} + w _ {1 2} x _ {2} + w _ {1 3} x _ {3} + b _ {1}\right) \\ a _ {2} = \sigma \left(z _ {2}\right) = \sigma \left(w _ {2 1} x _ {1} + w _ {2 2} x _ {2} + w _ {2 3} x _ {3} + b _ {2}\right) \\ a _ {3} = \sigma \left(z _ {3}\right) = \sigma \left(w _ {3 1} x _ {1} + w _ {3 2} x _ {2} + w _ {3 3} x _ {3} + b _ {3}\right) \end{array} \right. \tag {1}
$$

选择隐藏单元实际上就是要选择⼀个合适的激活函数。常见的有如下⼏种激活函数：

• 整流线性单元 (ReLU)： $g ( z ) = \operatorname* { m a x } \{ 0 , z \}$ 。优点是易于优化，⼆阶导数⼏乎处处为 0，处于激活状态时一阶导数处处为 1，也就是其相⽐于引⼊⼆阶效应的激活函数，梯度⽅向对学习更有⽤。如果使⽤ ReLU，第⼀步做线性变换 ${ \pmb W } ^ { \top } { \pmb x } + { \pmb b }$ 时的 b ⼀般设置成⼩的正值。缺陷是不能通过基于梯度的⽅法学习那些使单元激活为 0 的样本。

ReLU 函数的梯度为 $g ^ { \prime } ( z ) = \left\{ { \begin{array} { l l } { 1 } & { \quad z > 0 } \\ { 0 } & { \quad z \leq 0 } \end{array} } \right.$

• sigmoid 函数 (常写作 $\sigma$ ) 或双曲正切函数 tanh。两者之间有⼀个联系： $\mathrm { t a n h } ( z ) = 2 \sigma ( 2 z ) - 1 $ 。两者都⽐较容易饱和，仅当 $z$ 接近 0 时才对输⼊强烈敏感，因此使得基于梯度的学习变得⾮常困难，不适合做前馈⽹络中的隐藏单元。如果必须要使用这两种中的一个，那么 tanh 通常表现更好，因为在 0 附近其类似于单位函数。即，如果⽹络的激活能⼀直很⼩，训练 $\hat { y } = w ^ { \top } \mathrm { t a n h } ( \mathrm { U } ^ { \top } \mathrm { t a n h } ( \mathrm { V } ^ { \top } x ) )$ 类似于训练⼀个线性模型$\begin{array} { r } { \hat { y } = w ^ { \top } \mathrm { U } ^ { \top } \mathrm { V } ^ { \top } x . } \end{array}$ 。RNN 和⼀些⾃编码器有⼀些额外的要求，因此不能使⽤分段激活函数，此时这种类 sigmoid 单元更合适。

sigmoid 函数写作 $\begin{array} { r } { g ( z ) = \sigma ( z ) = \frac { 1 } { 1 + e ^ { - z } } } \end{array}$ ，梯度为 $g ^ { \prime } ( z ) = \sigma ( z ) ( 1 - \sigma ( z ) )$

双曲正切函数写作 $\begin{array} { r } { g ( z ) = \operatorname { t a n h } ( z ) = \frac { e ^ { z } - e ^ { - z } } { e ^ { z } + e ^ { - z } } } \end{array}$ ，梯度为 $g ^ { \prime } ( z ) = 1 - \operatorname { t a n h } ^ { 2 } ( z )$

[2]: class ActivationBase(ABC):   
```python
[1]: from abc import ABC, abstractmethod import numpy as np import time import re from collections import OrderedDict 
```

def __init__(self, **kwargs): super().__init__()   
def __call__(self, z): if z.ndim == 1: $z = z$ .reshape(1,-1) return self.forward(z)   
@abstractmethod   
def forward(self, z): "" raise NotImplementedError   
@abstractmethod   
def grad(self, x, **kwargs): "" raise NotImplementedError   
class ReLU ActivationBase): ""   
def __init__(self): super().__init__()   
def __str__(self): return "ReLU"   
def forward(self, z): return np.clip(z,0,np.inf)   
def grad(self, x): return (x>0).astype(int)

```python
class Sigmoid(ActivationBase):
    ""
sigmoid        ../method
    ""
def __init__(self):
        super().__init_
    def __str__(self):
        return "Sigmoid"
    def forward(self, z):
        return 1 / (1 + np.exp(-z))
    def grad(self, x):
        return self.forward(x) * (1 - self.forward(x))
class Tanh(ActivationBase):
    ""
    ""
    def __init__(self):
        super().__init_
    def __str__(self):
        return "Tanh"
    def forward(self, z):
        return np.tanh(z)
    def grad(self, x):
        return 1 - np.tanh(x) ** 2
class Affine(ActivationBase):
    ""
affine        slope*z + intercept     slope=1     intercept=0
    ""
def __init__(self, slope=1, intercept=0):
        self.slope = slope
        self.intercept = intercept
        super().__init_
    def __str__(self):
        return "Affine(slope={}, intercept={})".format(self.slope, self.intercept)
    def forward(self, z):
        return self.slope * z + self.intercept
    def grad(self, x):
        return self.slope * np.ones_like(x)
class ActivationInitializer(object):
    def __init__(self, acti_name='sigmoid'):
        self.acti_name = acti_name
    def __call__(self):
        if self.acti_name.lower() == 'sigmoid':
            acti_fn = Sigmoid()
            elif self.acti_name.lower() == 'relu': 
```

acti_fn = ReLU()  
elif "affine" in self.acti_name.lower():  
    r = r"affine $\text{slope} = (.*)$ ，intercept $= (.*)$ ")  
slope, intercept = re.match(r, self.acti_name.lower()).groups()  
acti_fn = Affine(float(slope), float(intercept))  
return acti_fn

# 2.2 输出单元

假设前⾯已经使⽤若⼲隐藏层提供了⼀组隐藏特征 $^ { h }$ ，输出层是要对这些特征做⼀些额外变换来完成任务。

常见的有如下⼏种输出单元：

• ⽤于⾼斯输出分布的线性单元，即对隐藏特征不做⾮线性变换，直接产⽣ $\hat { \pmb { y } } = \pmb { z } = \pmb { W } ^ { \top } \pmb { h } + \pmb { b } \mathrm { \Omega }$ 。其⽤来产⽣条件⾼斯分布的均值： $p ( { \pmb y } \mid { \pmb x } ) =$ $N ( { \pmb y } ; \hat { \pmb y } , { \pmb I } )$   
• ⽤于伯努利输出分布的 sigmoid 单元，即对隐藏特征先⽤线性层求 $\pmb { z } = \pmb { W } ^ { \top } \pmb { h } + \pmb { b }$ ，然后对这个值做⼀个 sigmoid 变换 $\sigma ( z )$ 将其映射到 [0, 1]区间，转化成⼀个概率值，即 $\pmb { \hat { y } } = \sigma ( \pmb { z } ) = \sigma ( \pmb { W } ^ { \top } \pmb { h } + \pmb { b } )$   
• ⽤于多元伯努利输出分布的 softmax 单元，可以看作是伯努利输出分布的 sigmoid 单元在多分类问题上的推⼴。此时输出标签空间是一个离散的，多类别的集合。假如⼀共有 K 个类别，则标签空间 $\mathcal { Y } = \{ 0 , 1 , 2 , \ldots , \mathrm { K - 1 } \} \circ$ 。对隐藏特征做线性变换 $\pmb { z } = \pmb { W } ^ { \top } \pmb { h } + \pmb { b }$ 后，通过 softmax 函数得到个向量 softmax $( z )$ ，这个向量的每个维度可以看做是输⼊样本属于对应类别标签的概率，因此有 $\forall i \in \{ 0 , 1 , \ldots , \operatorname { K } - 1 \}$ , $z _ { i } \in [ 0 , 1 ] \land \sum _ { i } z _ { i } = 1 { } _ { { } }$ 。softmax 函数的具体形式为：

$$
\operatorname {s o f t m a x} (z) _ {i} = \frac {\exp \left(z _ {i}\right)}{\sum_ {j} \exp \left(z _ {j}\right)} \tag {2}
$$

```python
[3]: def sigmoid(x): return 1 / (1 + np.exp(-x)) def softmax(x): e_x = np.exp(x - np.max(x, axis=-1, keepdims=True)) return e_x / e_x.sum(axis=-1, keepdims=True) 
```

# 2.3 代价函数

任何能够衡量模型预测值与真实值之间的差异的函数都可以叫做代价函数。如果有多个样本，则可以将所有代价函数的取值求均值，记作 $J ( \theta )$ 。当我们确定了模型后，再要做的是训练模型的参数 θ (如 W，b)。训练参数的过程就是误差反向传递，不断调整 $\theta$ ，从而得到更小的 $J ( \theta )$ 的过程。理想情况下，当我们取到代价函数 $J$ 的最⼩值时，就得到了最优的参数 $\theta$ ，记为： $\operatorname* { m i n } _ { \theta } J ( \theta )$ 。常见的代价函数主要有：

• ⼆次代价函数，具体形式为：

$$
J (\theta) = \frac {1}{2 m} \sum_ {i = 1} ^ {m} \left(\hat {\boldsymbol {y}} ^ {(i)} - \boldsymbol {y} ^ {(i)}\right) ^ {2} \tag {3}
$$

梯度的计算：以单个样本为例，假设输出单元 ${ \hat { y } } = g ( z )$ ， $g$ 为输出单元的激活函数， $_ { z }$ 为 $\theta$ 的函数，则此时代价函数为 $\begin{array} { r } { \frac { 1 } { 2 } ( g ( z ) - \pmb { y } ) ^ { 2 } } \end{array}$ 。可以计算梯度：

$$
\frac {\partial J (\theta)}{\partial \boldsymbol {z}} = (g (\boldsymbol {z}) - \boldsymbol {y}) g ^ {\prime} (\boldsymbol {z}) \tag {4}
$$

可以验证，当输出单元激活函数采⽤ sigmoid 或 tanh 的 S 型激活函数，⼆次代价函数在梯度收敛⾄ 0 时 (如果真实值为 0)，存在收敛速度慢⽽导致的训练速度慢的问题。

• 最⼤ (对数) 似然代价函数或者最⼩负 (对数) 似然代价函数，具体形式为：

$$
\underset {\theta} {\operatorname {a r g m i n}} - \mathcal {L} (\theta \mid \boldsymbol {y}, \hat {\boldsymbol {y}}) \tag {5}
$$

似然 $\mathcal { L } ( \boldsymbol { \theta } \mid \boldsymbol { y } , \hat { \boldsymbol { y } } )$ 可以表⽰成联合概率：

$$
P (t, \boldsymbol {z} \mid \theta) = P (t \mid \boldsymbol {z}, \theta) P (\boldsymbol {z} \mid \theta) \tag {6}
$$

– 如果输出单元是⽤于伯努利输出分布的 sigmoid 单元，可以得到对应的代价函数：

$$
J (\theta) = \underset {\theta} {\operatorname {a r g m i n}} - \mathcal {L} (\theta \mid \boldsymbol {y}, \hat {\boldsymbol {y}}) = - \frac {1}{m} \sum_ {i = 1} ^ {m} \left(\boldsymbol {y} ^ {(i)} \log \hat {\boldsymbol {y}} ^ {(i)} + (1 - \boldsymbol {y} ^ {(i)}) \log (1 - \hat {\boldsymbol {y}} ^ {(i)})\right) \tag {7}
$$

梯度的计算：以单个样本为例，假设输出单元 $\hat { y } = g ( z )$ ， $g$ 为输出单元的激活函数， $_ { z }$ 为 $\theta$ 的函数。可以计算梯度：

$$
\frac {\partial J (\theta)}{\partial \boldsymbol {z}} = - \left(\frac {\boldsymbol {y}}{g (\boldsymbol {z})} - \frac {(1 - \boldsymbol {y})}{1 - g (\boldsymbol {z})}\right) g ^ {\prime} (\boldsymbol {z}) \tag {8}
$$

如果 $g$ 为 sigmoid 函数，可以进⼀步化简：

$$
J (\theta) = - \boldsymbol {y} \boldsymbol {z} + \log \left(1 + e ^ {z}\right) \tag {9}
$$

$$
\frac {\partial \mathrm {J} (\theta)}{\partial z} = \sigma (z) - y \tag {10}
$$

$\sigma ( z ) - \pmb { y }$ 表⽰真实值与输出值之间的误差。当误差越⼤时，梯度就越⼤，θ 的调整就越快，训练速度就越快。当输出神经元的激活函数是线性时 (如 ReLU 函数)，二次代价函数是一种合适的选择；当输出神经元的激活函数是 S 型函数时 (如 sigmoid 、tanh 函数)，选择交叉熵代价函数则比较合理。

– 如果输出单元是⽤于多元伯努利输出分布的 softmax 单元，可以得到对应的代价函数：

$$
J (\theta) = \underset {\theta} {\operatorname {a r g m i n}} - \mathcal {L} (\theta \mid \boldsymbol {y}, \hat {\boldsymbol {y}}) = - \frac {1}{m} \sum_ {i = 1} ^ {m} \left(\boldsymbol {y} ^ {(i)} \log \hat {\boldsymbol {y}} ^ {(i)}\right) \tag {11}
$$

其中对每⼀个 $\hat { y }$ 有 $\begin{array} { r } { \hat { y } _ { k } = \frac { \exp ( z _ { k } ) } { \sum _ { j } \exp ( z _ { j } ) } . } \end{array}$ 。因此可以进⼀步展开为：

$$
J (\theta) = - \frac {1}{m} \sum_ {i = 1} ^ {m} \sum_ {k = 0} ^ {\mathrm {K} - 1} \left(y _ {k} ^ {(i)} \log \hat {y} _ {k} ^ {(i)}\right) \tag {12}
$$

梯度的计算：以单个样本为例，假设输出单元 $\hat { y } = g ( z )$ ， $g$ 为输出单元的激活函数，则此时代价函数为 $\begin{array} { r } { J ( \theta ) = - \sum _ { k = 0 } ^ { \mathrm { K } - 1 } ( y _ { k } \log \hat { y } _ { k } ) , } \end{array}$ ⾸先，对 softmax 函数求导：

1. 当 $j = i$ 时：

$$
\begin{array}{l} \frac {\partial \hat {y} _ {j}}{\partial z _ {i}} = \frac {\partial}{\partial z _ {i}} \left(\frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}}\right) \\ = \frac {\left(e ^ {z _ {j}}\right) ^ {\prime} \cdot \sum_ {k} e ^ {z _ {k}} - e ^ {z _ {j}} \cdot e ^ {z _ {j}}}{\left(\sum_ {k} e ^ {z _ {k}}\right) ^ {2}} \\ = \frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}} - \frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}} \cdot \frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}} \tag {13} \\ = \hat {y} _ {j} (1 - \hat {y} _ {j}) \\ = \hat {y} _ {j} - \hat {y} _ {j} \hat {y} _ {j} \\ \end{array}
$$

2. 当 $j \neq i$ 时：

$$
\begin{array}{l} \frac {\partial \hat {y} _ {j}}{\partial z _ {i}} = \frac {\partial}{\partial z _ {i}} \left(\frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}}\right) \\ = \frac {0 \cdot \sum_ {k} e ^ {z _ {k}} - e ^ {z _ {j}} \cdot e ^ {z _ {i}}}{\left(\sum_ {k} e ^ {z _ {k}}\right) ^ {2}} \\ = - \frac {e ^ {z _ {j}}}{\sum_ {k} e ^ {z _ {k}}} \cdot \frac {e ^ {z _ {i}}}{\sum_ {k} e ^ {z _ {k}}} \tag {14} \\ = - \hat {y} _ {j} \hat {y} _ {i} \\ = 0 - \hat {y} _ {j} \hat {y} _ {i} \\ \end{array}
$$

然后，进⼀步计算：

$$
\begin{array}{l} \frac {\partial J (\theta)}{\partial z _ {j}} = - \sum_ {k} y _ {k} \frac {\partial}{\partial z _ {j}} (\log \hat {y} _ {k}) \\ = - \sum_ {k} y _ {k} \frac {1}{\hat {y} _ {k}} \frac {\partial \hat {y} _ {k}}{\partial z _ {j}} (\text {拆 分 求 导}) \\ = - y _ {j} \frac {1}{\hat {y} _ {j}} \cdot \hat {y} _ {j} (1 - \hat {y} _ {j}) - \sum_ {k \neq j} y _ {k} \frac {1}{\hat {y} _ {k}} \cdot (- \hat {y} _ {j} \hat {y} _ {k}) \tag {15} \\ = - y _ {j} (1 - \hat {y} _ {j}) + \hat {y} _ {j} \sum_ {k \neq j} y _ {k} (\text {合 并}) \\ = \hat {y} _ {j} - y _ {j} \\ \end{array}
$$

# 2.4 架构设计

架构 (Architecture) ⼀词指⽹络的整体结构：它应该具有多少单元，以及这些单元应该如何连接。

在实践中，神经⽹络具有多样性。

⽤于计算机视觉的卷积神经⽹络的特殊架构在第九章中介绍。前馈⽹络也可以推⼴到序列处理的循环神经⽹络，但也有它们⾃⼰的架构考虑，将在第⼗章中介绍。

# 3 反向传播算法

# 3.1 单个神经元的训练

单个神经元的结构如图 3 所⽰，假设训练样本 $( { \pmb x } , y )$ ，在图 3 左， $_ { \pmb { x } }$ 是输⼊向量，通过⼀个激励函数 $h _ { w , b ( x ) }$ 得到⼀个输出 $a$ ，a 再通过代价函数得到 J。激励函数以使⽤ sigmoid 为例:

$$
\begin{array}{l} f (\boldsymbol {W}, b, \boldsymbol {x}) = a = \operatorname {s i g m o i d} \left(\sum_ {i} x _ {i} w _ {i} + b\right) \tag {16} \\ J (\pmb {W}, b, \pmb {x}, y) = \frac {1}{2} \| y - a \| ^ {2} \\ \end{array}
$$

![](images/0ae8a6c2f98c06bdf2889a9cb2289d5a18f52d67fcf5c6a04a4a91f7bb8b0d15.jpg)

![](images/8910259620c109248d8f26fbe4bff487b9e8cbf0b62c23054adc1e1326941176.jpg)  
图 3. 单个神经元⽤于训练的⽰意图

将激励函数拆成两部分，第⼀部分通过仿射求和得到 $\begin{array} { r } { z = \sum _ { i } x _ { i } w _ { i } + b = \sum _ { i } w _ { i } x _ { i } + b } \end{array}$ ，第⼆部分通过 sigmoid 得到 $a _ { \circ }$

1. 训练过程中，要求代价函数 $J$ 关于 $\textbf { \em w }$ 和 $b$ 的偏导数。先求 $J$ 关于中间变量 $a$ 和 $z$ 的偏导：

$$
\delta^ {(a)} = \frac {\partial}{\partial a} J (\boldsymbol {w}, b, \boldsymbol {x}, y) = - (y - a) \tag {17}
$$

$$
\delta^ {(z)} = \frac {\partial}{\partial z} J (\boldsymbol {w}, b, \boldsymbol {x}, y) = \frac {\partial J}{\partial a} \frac {\partial a}{\partial z} = \delta^ {(a)} a (1 - a)
$$

其中 sigmoid 的导数为 $a ( 1 - a )$ ；

2. 再根据链导法则，可以求得 $J$ 关于 $\textbf { \em w }$ 和 $b$ 的偏导数，即得 $\textbf { \em w }$ 和 $b$ 的梯度。

$$
\nabla_ {\boldsymbol {w}} J (\boldsymbol {w}, b, \boldsymbol {x}, y) = \frac {\partial}{\partial w} J = \frac {\partial J}{\partial z} \frac {\partial z}{\partial \boldsymbol {w}} = \boldsymbol {x} \delta^ {(z)} \tag {18}
$$

$$
\nabla_ {b} J (\boldsymbol {w}, b, \boldsymbol {x}, y) = \frac {\partial}{\partial b} J = \frac {\partial J}{\partial z} \frac {\partial z}{\partial b} = \delta^ {(z)}
$$

在这个过程中，先求 $\frac { \partial J } { \partial a }$ ，进⼀步求 $\frac { \partial J } { \partial z }$ ，最后求得 $\frac { \partial J } { \partial w }$ 和 $\frac { \partial J } { \partial b }$ 。结合上图及链导法则，可以看出这是⼀个将代价函数的增量 ∂J ⾃后向前传播的过程，因此称为反向传播 (Back Propagation)。

# 3.2 多层神经网络的训练

在描述多层神经⽹络时，我们不再仔细描述某⼀层内部节点，⽽是描述层与层之间的关系。如图 4，为⽅便标记，在描述多层⽹络时，我们将第 $i$ 层记作下标 $_ { i \circ }$ 。在本书中，第 $i$ 层⽤ $\mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } }$ 和 $a ^ { l }$ 两种⽅式表⽰，视情况⽽⽤。假设第 $l + 1$ 层的输⼊和输出分别是 $\mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \beta } \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } \mathbf { \alpha } }$ 和 $\mathbf { \pmb { a } } _ { l + 1 }$ ，参数为 $W _ { l }$ 和 $b _ { l }$ ，其中 $W _ { l }$ 的维数为 $( n _ { i n } , n _ { o u t } )$ 。仿射结果为中间变量 $z _ { l + 1 }$ 。其中第⼀层的输出 $\mathbf { \delta } _ { a _ { 1 } } = \mathbf { \delta } _ { x }$ ，为整个⽹络的输⼊，最后⼀层的输出 ${ \pmb a } _ { L }$ 是代价函数的输⼊。

$$
\boldsymbol {z} _ {l + 1} = \boldsymbol {W} _ {l} ^ {\top} \boldsymbol {a} _ {l} + \boldsymbol {b} _ {l} \tag {19}
$$

$$
\boldsymbol {a} _ {l + 1} = \operatorname {s i g m o i d} (\boldsymbol {z} _ {l + 1})
$$

![](images/8f21026894dafeeadcda7b318a427728a0a520b75df796306b9f67c15bee7805.jpg)  
图 4. 多层神经⽹络训练的⽰意图

在实际神经⽹络中，⽹络层的输⼊ $\mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textless ~ } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathrm { ~ \textless ~ } a _ { l }$ 的维数通常表⽰为 $( n _ { s a m p } , n _ { i n } )$ ，其中第⼀维 $n _ { s a m p }$ 为输⼊样本的数量。于是，计算公式可以写作：

$$
\boldsymbol {z} _ {l + 1} = \boldsymbol {a} _ {l} \boldsymbol {W} _ {l} + \boldsymbol {b} _ {l} \tag {20}
$$

对多层⽹络的训练需要计算代价函数 $J$ 对每⼀层的参数求偏导。后向传播过程变为：

1. 求 $J$ 对 ${ \pmb a } _ { L }$ 的偏导 $\delta _ { L } ^ { ( a ) }$ ；

2. 在第 $l + 1$ 层，将误差信号从 $\mathbf { \pmb { a } } _ { l + 1 }$ 传递到 $z _ { l + 1 }$ ；

$$
\frac {\partial \boldsymbol {a} _ {l + 1}}{\partial \boldsymbol {z} _ {l + 1}} = \boldsymbol {a} _ {l + 1} (1 - \boldsymbol {a} _ {l + 1}) \tag {21}
$$

3. 将误差信号从第 $l + 1$ 层向第 $l$ 层传播；

4. 对第 $l$ 层计算得到 $J$ 对 $\mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } }$ 和 $z _ { l }$ 的偏导数；

$$
\delta_ {l} ^ {(a)} = \frac {\partial J}{\partial \boldsymbol {a} _ {l}} = \left\{ \begin{array}{l l} - (\boldsymbol {y} - \boldsymbol {a} _ {l}), & \text {i f} l = L \\ \frac {\partial J}{\partial z _ {l + 1}} \frac {\partial z _ {l + 1}}{\partial \boldsymbol {a} _ {l}} = \delta_ {l + 1} ^ {(z)} \left(\boldsymbol {W} _ {l}\right) ^ {\top}, & \text {o t h e r w i s e} \end{array} \right. \tag {22}
$$

$$
\delta_ {l} ^ {(z)} = \frac {\partial J}{\partial \boldsymbol {z} _ {l}} = \frac {\partial J}{\partial \boldsymbol {a} _ {l}} \frac {\partial \boldsymbol {a} _ {l}}{\partial \boldsymbol {z} _ {l}} = \delta_ {l} ^ {(\boldsymbol {a})} \boldsymbol {a} _ {l + 1} (1 - \boldsymbol {a} _ {l + 1})
$$

5. 对第 l 层计算得到 $J$ 对参数 $W _ { l }$ 和 $b _ { l }$ 的梯度。

$$
\nabla_ {\boldsymbol {W} _ {l}} J (\boldsymbol {W}, \boldsymbol {b}, \boldsymbol {x}, \boldsymbol {y}) = \frac {\partial}{\partial \boldsymbol {W} _ {l}} J = \frac {\partial J}{\partial \boldsymbol {z} _ {l + 1}} \frac {\partial \boldsymbol {z} _ {l + 1}}{\partial \boldsymbol {W} _ {l}} = (\boldsymbol {a} _ {l}) ^ {\top} \delta_ {l + 1} ^ {(z)} \tag {23}
$$

$$
\nabla_ {\boldsymbol {b} _ {l}} J (\boldsymbol {W}, \boldsymbol {b}, \boldsymbol {x}, \boldsymbol {y}) = \frac {\partial}{\partial \boldsymbol {b} _ {l}} J = \frac {\partial J}{\partial \boldsymbol {z} _ {l + 1}} \frac {\partial \boldsymbol {z} _ {l + 1}}{\partial \boldsymbol {b} _ {l}} = \delta_ {l + 1} ^ {(z)}
$$

为具体实现深度前馈⽹络，需要⾸先定义以下模块：

# 3.2.1 定义权重初始化方法

[4]: class std_normal:   
""   
""   
def __init__(self, gain=0.01): self_gain = gain   
def __call__(self, weight_shape): return self_gain \* np.random.randint(*weight_shape)   
class he.uniform:   
He Uniform(-b,b) W b=sqrt(6/n_in) 8   
""   
def __init__(self): pass   
def __call__(self, weight_shape): n_in, n_out $=$ weight_shape b $=$ np.sqrt(6/n_in) return np.random.uniform(-b,b,size=weight_shape)   
class WeightInitializer(object):   
def __init__(self,mode="he.uniform"): self_mode $=$ mode # 8 r $=$ r"([a-zA-Z]\*)=([\^,])\*" mode_str $=$ self.mode(lower() kwargs $=$ dict([[i,eval(j)) for (i,j) in re.findall(r,mode_str)]) if "std_normal"in mode_str: self.init_fn $=$ std_normal(**kwargs) elif "he.uniform" in mode_str: self.init_fn $=$ he.uniform(**kwargs)   
def __call__(self,weight_shape): W $=$ self.init_fn(weight_shape) return W

# 3.2.2 定义激活函数 (见前文描述)

# 3.2.3 定义优化方法

```python
[5]:   
```
```
sgd 8
```
class OptimizerBase(ABC):
    def __init__(self):
        pass
    def __call__(self, params, params_grad, params_name):
        ...
    params W
    params_grad
    params_name 
```

```python
```
return self.update.params, params_grad, params_name)
@abstractmethod
def update(self, params, params_grad, params_name):
    raise NotImplementedError
class SGD(OptimizerBase):
    ...
    sgd
    ...
    def __init__(self, lr=0.01):
        super().__init_()
        self.lr = lr
    def __str__(self):
        return "SGD(lr=\{})".format(selfhyperparams["lr")] 
```

# 3.2.4 定义网络层的框架

[6]: class LayerBase(ABC):

```python
def __init__(self, optimizer=None):
    self.X = []
    self_gradients = {}
    self.params = {}
    self.acti_fn = None
    selfOptimizer = OptimizerInitializer(optimizer)()
@abstractmethod
def __init__(params(self, **kwargs)):
    raise NotImplementedError 
```

```python
@abstractmethod   
def forward(self, X, **kwargs):   
    ....   
    ....   
    raise NotImplementedError   
@abstractmethod   
def backward(self, out, **kwargs):   
    ....   
    ....   
    raise NotImplementedError   
def flush_gradients(self):   
    ....   
    ....   
    self.X = []   
for k, v in self_gradients.items():   
        self_gradients[k] = np.zeros_like(v)   
def update(self):   
    ....   
    ....   
    for k, v in self_gradients.items(): if k in self.params: self.params[k] = self_optimizer(self.params[k], v, k) 
```

```python
class FullyConnected(LayerBase):
    ...
    a = g(x * W + b) x a
    ...
    def __init__(self, n_out, acti_fn, init_w, optimizer=None):
        ...
        acti_fn str
        init_w str
        n_out optimizer
        ...
        super().__init__(optimizer)
        self.n_in = None # int
        self.n_out = n_out # int
        self.acti_fn = ActivationInitializer(acti_fn())
        self.init_w = init_w
        self.initweights = WeightInitializer(mode=init_w)
        self.is_initializer = False # bool
    def __init_parameters(self):
        b = np.zeros((1, self.n_out))
        W = self.initweights((self.n_in, self.n_out))
        self.params = {"W": W, "b": b}
        self_gradients = {"W": np.zeros_like(W), "b": np.zeros_like(b)}
        self.is_initializer = True
    def forward(self, X, retain Derived=True): 
```

```python
X n_samples, n_in float
retain Derived bool
```
if not self.is Initialized: # 
    self.n_in = X.shape[1] 
    self._init.params() 
W = self.params["W"]
b = self.params["b"]
z = X @ W + b 
a = self.acti_fn.forward(z) 
if retain Derived: 
    self.X.append(X) 
return a
def backward(self, dLda, retain_grads=True):
    dLda n_samples, n_out float
retain_grads bool
```
if not isinstance(dLda, list):
    dLda = [dLda]
dx = []
X = self.x
for da, x in zip(dLda, X):
    dx, dw, db = self._bwd(da, x)
    dX.append(dx)
    if retain_grads:
        self/gradients["W"] += dw
        self/gradients["b"] += db
return dX[0] if len(X) == 1 else dX
def_bwd(self, dLda, X):
    W = self.params["W"]
b = self.params["b"]
Z = X @ W + b
dZ = dLda * self.acti_fn.grad(Z)
dX = dZ @ W.T
dw = X.T @ dZ
db = dZ.sum(axis=0, keepdims=True)
return dX, dW, db
@property
def hyperparams(self):
    return {
        "layer": "FullyConnected",
        "init_w": self.init_w,
        "n_in": self.n_in,
        "n_out": self.n_out,
        "acti_fn": str(self.acti_fn),
        "optimizer": {
            "hyperparams": self optimizer.hyperparams,
        },
    }
} 
```

```python
"components": { k: v for k, v in self.params.items() } } 
```

[8]: class Softmax(LayerBase):   
```python
Softmax
```
def __init__(self, dim=-1, optimizer=None):
    super().__init__(optimizer)
    self.dim = dim
    self.n_in = None
    self.is Initialized = False
def __init_parameters(self):
    self.params = {}
    self_gradients = {}
    self.is Initialized = True
def forward(self, X, retain Derived=True):
    '''Softmax
    '''if not self.is Initialized:
        self.n_in = X.shape[1]
        self._init_parameters()
        Y = self._fwd(X)
        if retain Derived:
            self.X.append(X)
        return Y
def __fwd(self, X):
    e_X = np.exp(X - np.max(X, axisself.dim, keepdims=True))
    return e_X / e_X.sum(axisself.dim, keepdims=True)
def backward(self, dLdy):
    '''Softmax
    '''if not isinstance(dLdy, list):
        dLdy = [dLdy]
        dX = []
        X = self.X
    for dy, x in zip(dLdy, X):
        dx = self._bwd(dy, x)
        dX.append(dx)
    return dX[0] if len(X) == 1 else dX
def __bwd(self, dLdy, X):
    dX = []
    for dy, x in zip(dLdy, X):
        dxi = []
        for dyi, xi in zip(*np.atleast_2d(dy, x)):
            yi = self._fwd(xi.reshape(1, -1)).reshape(-1, 1)
            dyidxi = np.diagflat(yi) - yi @ yi.T
            dxi.append(dyi @ dyidxi)
            dX.append(dxi)
    return np.array(dX).reshape(*X.shape) 
```

```txt
@property   
def hyperparams(self): return { "layer": "SoftmaxLayer", "n_in": self.n_in, "n_out": self.n_in, "optimizer": { "hyperparams": self optimizer.hyperparams, }, 
```

# 3.2.5 定义代价函数

[9]: class ObjectiveBase(ABC):   
```python
def __init__(self):
    super().__init__()
@abstractmethod
def loss(self, y_true, y_pred):
    raise NotImplementedError
@abstractmethod
def grad(self, y_true, y_pred, **kwargs):
    raise NotImplementedError
class SquaredError(ObjectiveBase):
    def __init__(self):
        return self.loss(y_true, y_pred)
    def __str__(self):
        return "SquaredError"
@staticmethod
def loss(y_true, y_pred):
    y_true = n (n, m)
    y_pred = n (n, m)
    ((n, _) = y_true.shape
return 0.5 * np.linalg.norm(y_pred - y_true) ** 2 / n 
```

(n,_）=y_true.shape return(y_pred-y_true）\*acti_fn.gradle(z）/n   
classCrossEntropy(ObjectiveBase): 【"" def__init_(self): super()._init_() def__call_(self，y_true，y_pred): return self.loss(y_true，y_pred) def__str_(self): return"CrossEntropy" @staticmethod defloss(y_true，y_pred): y_true n (n,m) y_pred n (n,m) 【"" $(n,.) = y\_ true$ .shape eps $=$ np+finfo(float).eps # np.log(0) cross_entropy $=$ -np-sum(y_true $\ast$ np.log(y_pred $^+$ eps)) / n return cross_entropy   
@staticmethod defgrad(y_true，y_pred): (n,_）=y_true.shape grad=(y_pred-y_true)/n return grad

# 3.2.6 定义深度前馈网络

```python
[10]: def minibatch(X, batchsize=256, shuffle=True):
    "" batch mini batch
    "" N = X.shape[0]
    idx = np.arange(N)
    n_batches = int(np.ceil(N / batchsize))
    if shuffle:
        np.random.shuffle(idx)
    def mb_generation():
        for i in range(n_batches):
            yield idx[i * batchsize : (i + 1) * batchsize]
    return mb_generation(), n_batches 
```

```python
[11]: class DFN(object): def __init__(self, hidden_dims_1=None, hidden_dims_2=None, optimizer="sgd(lr=0.01")", init_w="std_normal", loss=CrossEntropy() 
```

):   
self optimizer $=$ optimizer   
self.init_w $=$ init_w   
self.loss $=$ loss   
self-hidden_dims_1 $=$ hidden_dims_1   
self-hidden_dims_2 $=$ hidden_dims_2   
self.is Initialized $=$ False   
def_set.params(self):   
""   
FC1 $\rightarrow$ Sigmoid $\rightarrow$ FC2 $\rightarrow$ Softmax   
""   
self.layers $=$ OrderedDict()   
self.layers["FC1"] $=$ FullyConnected( n_out= self-hidden_dims_1, acti_fn="sigmoid", init_w $\equiv$ self.init_w, optimizer $\equiv$ selfOptimizer   
）   
self.layers["FC2"] $=$ FullyConnected( n_out= self-hidden_dims_2, acti_fn="affine(slope=1,intercept=0)", init_w $\equiv$ self.init_w, optimizer $\equiv$ selfOptimizer   
）   
self.is Initialized $=$ True   
def forward(self,X_train):   
Xs $=$ {}   
out $=$ X_train   
for k,v in self.layers.items(): Xs[k] $=$ out out $=$ v.forward(out)   
return out, Xs   
def backward(self,grad):   
dXs $=$ {}   
out $=$ grad   
for k,v in reversed(list(self.layers.items)): dXs[k] $=$ out out $=$ v逆转(out)   
return out, dXs   
def update(self):   
""   
""   
for k,v in reversed(list(self.layers.items)): v.update()   
self.flush_gradients()   
def flush_gradients(self,curr_loss=None):   
""   
""   
for k,v in self.layers.items(): v.flush_gradients()

```python
def fit(self, X_train, y_train, n_epochs=20, batch_size=64, verbose=False):
    def "X_train":
        y_train
        n_epochs epoch
        batch_size epoch batch size
        verbose batch
    selfverbose = verbose
    self.n_epochs = n_epochs
    self.batch_size = batch_size
    if not self.is Initialized:
        self.n_features = X_train.shape[1]
        self._set_parameters()
    prev_loss = np.inf
    for i in range(n_epochs):
        loss, epoch_start = 0.0, time.time()
        batch_generator, n_batch = minibatch(X_train, self.batch_size, shuffle=True)
        for j, batch IDX in enumerate(batch.generator):
            batch_len, batch_start = len(batch IDX), time.time()
            X_batch, y_batch = X_train[batch IDX], y_train[batch IDX]
            out, _ = self.forward(X_batch)
            y_pred_batch = softmax(out)
            batch_loss = self.loss(y_batch, y_pred_batch)
            grad = self.lossGrad(y_batch, y_pred_batch)
            _, _ = self.backup(grad)
            self.update()
            loss += batch_loss
            if selfverbose:
                fstr = "\t[Batch {}]{/{}] Train loss: {:.3f} ({:.1f}s/batch)"print(fstr.format(j + 1, n_batch, batch_loss, time.time() - batch_start))
                loss /= n_batch
                fstr = "[Epoch {}) Avg. loss: {:.3f} Delta: {:.3f} ({:.2f)m/epoch)"print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0)) 
            prev_loss = loss
def evaluate(self, X_test, y_test, batch_size=128):
    acc = 0.0
    batch.generator, n_batch = minibatch(X_test, batch_size, shuffle=True)
    for j, batch IDX in enumerate(batch.generator):
        batch_len, batch_start = len(batch IDX), time.time()
        X_batch, y_batch = X_batch[batch IDX], y_test[batch IDX]
        y_pred_batch, _ = self.forward(X_batch)
        y_pred_batch = np.argmax(y_pred_batch, axis=1)
        y_batch = np.argmax(y_batch, axis=1)
        acc += np.sum(y_pred_batch == y_batch)
    return acc / X_test.shape[0]
@property
def hyperparams(self):
    return {
        "init_w": self.init_w,
        "loss": str(self.loss),
        "optimizer": selfOptimizer,
        "hidden_dims_1": self-hidden_dims_1,
        "hidden_dims_2": self-hidden_dims_2,
        "components": {k: v.params for k, v in self.layers.items())
    } 
```

用自定义 DFN 实现，测试 MNIST 数据集  
```python
[12]: def load_data(path="../data/mnist/mnist.npz"): f = np.load(path) X_train, y_train = f['x_train'], f['y_train'] X_test, y_test = f['x_test'], f['y_test'] f.close() return (X_train, y_train), (X_test, y_test) (X_train, y_train), (X_test, y_test) = load_data() y_train = np.eye(10)[y_train. astype(int)] y_test = np.eye(10)[y_test. astype(int)] X_train = X_train. reshape(-1, X_train.shape[1]*X_train.shape[2]). astype('float32') X_test = X_test. reshape(-1, X_test.shape[1]*X_test.shape[2]). astype('float32') print(X_train.shape, y_train.shape) N = 20000 # 20000 indices = np.random.permutation(range(X_train.shape[0]))[:N] X_train, y_train = X_train[indices], y_train[indices] print(X_train.shape, y_train.shape) X_train /= 255 X_train = (X_train - 0.5) * 2 X_test /= 255 X_test = (X_test - 0.5) * 2 (60000, 784) (60000, 10) (20000, 784) (20000, 10) 
```

```ini
[13]: model = DFN(hidden_dims_1=200, hidden_dims_2=10) 
```

```python
[14]: model.fit(X_train, y_train, n_epochs=20) 
```

```txt
[Epoch 1] Avg. loss: 2.283 Delta: inf (0.02m/epoch)  
[Epoch 2] Avg. loss: 2.204 Delta: 0.078 (0.02m/epoch)  
[Epoch 3] Avg. loss: 1.986 Delta: 0.219 (0.02m/epoch)  
[Epoch 4] Avg. loss: 1.628 Delta: 0.357 (0.02m/epoch)  
[Epoch 5] Avg. loss: 1.292 Delta: 0.336 (0.02m/epoch)  
[Epoch 6] Avg. loss: 1.051 Delta: 0.242 (0.02m/epoch)  
[Epoch 7] Avg. loss: 0.886 Delta: 0.165 (0.02m/epoch)  
[Epoch 8] Avg. loss: 0.772 Delta: 0.114 (0.02m/epoch)  
[Epoch 9] Avg. loss: 0.691 Delta: 0.081 (0.02m/epoch)  
[Epoch 10] Avg. loss: 0.631 Delta: 0.060 (0.02m/epoch)  
[Epoch 11] Avg. loss: 0.585 Delta: 0.046 (0.02m/epoch)  
[Epoch 12] Avg. loss: 0.548 Delta: 0.037 (0.02m/epoch)  
[Epoch 13] Avg. loss: 0.519 Delta: 0.029 (0.02m/epoch)  
[Epoch 14] Avg. loss: 0.494 Delta: 0.025 (0.02m/epoch)  
[Epoch 15] Avg. loss: 0.474 Delta: 0.020 (0.02m/epoch)  
[Epoch 16] Avg. loss: 0.456 Delta: 0.018 (0.02m/epoch)  
[Epoch 17] Avg. loss: 0.441 Delta: 0.015 (0.02m/epoch)  
[Epoch 18] Avg. loss: 0.428 Delta: 0.013 (0.02m/epoch)  
[Epoch 19] Avg. loss: 0.417 Delta: 0.011 (0.02m/epoch)  
[Epoch 20] Avg. loss: 0.406 Delta: 0.011 (0.02m/epoch) 
```

```txt
[15]: print(model.evaluate(X_test, y_test)) 
```

```txt
0.894 
```

# 4 神经网络的万能近似定理

万能近似定理: ⼀个前馈神经⽹络如果具有线性层和⾄少⼀层具有 “挤压” 性质的激活函数（如 sigmoid 等），给定⽹络⾜够数量的隐藏单元，它可以以任意精度来近似任何从⼀个有限维空间到另⼀个有限维空间的 borel 可测函数。

sigmoid 函数的万能近似可视化证明 (以⼀元函数为例)：

1. 我们可以通过两个 sigmoid 函数 $( \pmb { y } = \mathrm { s i g m o i d } ( \pmb { w } ^ { \top } \pmb { x } + \pmb { b } ) )$ ⽣成⼀个 tower，如图：

![](images/e4de1f448dd7eaa2e03fd3db032943802dd6d463ff519af08017b153ff3fdef2.jpg)

2. 我们构造多个这样的 tower 近似任意函数：

![](images/46da3acb0812ee1c99d7fd8c15bf83f1ecf90ed07103e775930191467c8abdac.jpg)

可视化证明可参考：http://neuralnetworksanddeeplearning.com/chap4.html

或者 https://www.cse.iitm.ac.in/~miteshk/CS7015/Slides/Teaching/pdf/Lecture3.pdf

# 5 实例：学习 XOR

我们的⽹络是 $f ( \pmb { x } ; \pmb { W } , c , \pmb { w } , b ) = \pmb { w } ^ { \top } \mathrm { m a x } \{ \mathbf { 0 } , \pmb { W } ^ { \top } \pmb { x } + c \} + b$

[16]:

```python
class XOR(object):   
def __init__(self, hidden_dims_1=None, hidden_dims_2=None, optimizer="sgd(lr=1.0)", init_w="std_normal(gain=1.0)", loss=SquaredError() ): self optimizer = optimizer self.init_w = init_w self.loss = loss self-hidden_dims_1 = hidden_dims_1 self-hidden_dims_2 = hidden_dims_2 self.is Initialized = False def __set_parameters(self): "" FC1 -> Relu -> FC2 "" self.layers = OrderedDict() 
```

```python
self.layers["FC1"] = FullyConnected( n_out= self-hidden_dims_1, acti_fn="relu", init_w= self.init_w, optimizer= selfOptimizer   
)   
self.layers["FC2"] = FullyConnected( n_out= self-hidden_dims_2, acti_fn="affine(slope=1, intercept=0)", init_w= self.init_w, optimizer= selfOptimizer   
)   
self.is Initialized = True   
def forward(self, X_train): Xs = {} out = X_train for k, v in self.layers.items(): Xs[k] = out out = v.forward(out) return out, Xs   
def backward(self, grad): dXs = {} out = grad for k, v in reversed(list(self.layers.items())): dXs[k] = out out = v.backup(out) return out, dXs   
def update(self): "" "" for k, v in reversed(list(self.layers.items())): v.update() self.flush_gradients()   
def flush_gradients(self, curr_loss=None): "" "" for k, v in self.layers.items(): v.flush_gradients()   
def fit(self, X_train, y_train, n_epochs=20001, batch_size=4): "" X_train y_train n_epochs epoch batch_size epoch batch size "" self.n_epochs = n_epochs if not self.is Initialized: self.n_features = X_train.shape[1] self._set.params() prev_loss = np.inf for i in range(n_epochs): 
```

```python
loss, epoch_start = 0.0, time.time()
out, _ = self.forward(X_train)
anti_fn = Affine()
y_pred = anti_fn.forward(out)
loss = self.loss(y_train, y_pred)
grad = self.loss_grad(y_train, y_pred, out, anti_fn)
_, _ = self.backup(grad)
self.update()
if not i%5000:
    fstr = "[Epoch {}
Avg. loss: {:.3f} Delta: {:.3f} ({:.2f}m/epoch)"
print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0))
prev_loss = loss
@property
def hyperparams(self):
    return {
        "init_w": self.init_w,
        "loss": str(self.loss),
        "optimizer": selfOptimizer,
        "hidden_dims_1": self-hidden_dims_1,
        "hidden_dims_2": self-hidden_dims_2,
        "components": {k: v.params for k, v in self.layers.items()} 
```

```python
[17]: X_train = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])
y_train = np.array([[0.0], [1.0], [1.0], [0.0]]) 
```

```python
[20]: model = XOR(hidden_DIMs_1=2, hidden_dims_2=1) 
```

```txt
[21]: model.fit(X_train, y_train) 
```

```txt
[Epoch 1] Avg. loss: 0.086 Delta: inf (0.00m/epoch)  
[Epoch 5001] Avg. loss: 0.000 Delta: 0.086 (0.00m/epoch)  
[Epoch 10001] Avg. loss: 0.000 Delta: 0.000 (0.00m/epoch)  
[Epoch 15001] Avg. loss: 0.000 Delta: 0.000 (0.00m/epoch)  
[Epoch 20001] Avg. loss: 0.000 Delta: 0.000 (0.00m/epoch) 
```

```txt
[22]: print(modelhyperparams) 
```

{'init_w': 'std_normal(gain $= 1.0$ )', 'loss': 'SquaredError', 'optimizer': 'sgd(lr $= 1.0$ )', 'hidden_dims_1': 2, 'hidden_dims_2': 1, 'components': {'FC1': {'W': array([-1.35300239, 0.95949967], [0.88153178, -0.95209678]]), 'b': array([3.76300323e-17, -7.40288739e-03]]}), 'FC2': {'W': array([[1.13438905], [1.0503134]]), 'b': array([-1.1389201e-17]])}}

```python
[23]: import numpy  
import re  
print("numpy:", numpy.__version__)  
print("re:", re.__version__) 
```

```yaml
numpy: 1.14.5  
re: 2.2.1 
```

# 深度学习中的正则化

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

正则化的⽬标是减少模型泛化误差，为此提出了各种⽅法。本篇提出的正则化⽅法主要是考虑当训练误差较小，但泛化误差较大的情况下。

# 1 参数范数惩罚

许多正则化⽅法 (如神经⽹络、线性回归、逻辑回归) 通过对⽬标函数 $J$ 添加⼀个参数范数惩罚 $\Omega ( \theta )$ ，限制模型的学习能⼒。将正则化后的⽬标函数记为 $\tilde { J }$ :

$$
\tilde {J} (\theta ; \boldsymbol {X}, \boldsymbol {y}) = J (\theta ; \boldsymbol {X}, \boldsymbol {y}) + \alpha \Omega (\theta) \tag {1}
$$

其中 $\alpha \in [ 0 , + \infty )$ 是衡量参数范数惩罚程度的超参数。 $\alpha = 0$ 表⽰没有正则化， $\alpha$ 越⼤对应正则化惩罚越⼤。

在神经⽹络中，参数包括每层线性变换的权重和偏置，我们通常只对权重做惩罚而不对偏置做正则惩罚；使⽤向量 $\pmb { w }$ 表⽰应受惩罚影响的权重，⽤向量 $\theta$ 表⽰所有参数。

# 1.1 $L ^ { 2 }$ 正则化

$L ^ { 2 }$ 参数正则化 (也称为岭回归、Tikhonov 正则) 通常被称为权重衰减 (weight decay)，是通过向⽬标函数添加⼀个正则项 $\begin{array} { r } { \Omega ( { \boldsymbol { \theta } } ) = \frac { 1 } { 2 } \| \mathbf { { \boldsymbol { w } } } \| _ { 2 } ^ { 2 } } \end{array}$ ，使权重更加接近原点。

⽬标函数：

$$
\tilde {J} (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) = J (\boldsymbol {w}; \boldsymbol {X}, y) + \frac {\alpha}{2} \boldsymbol {w} ^ {\top} \boldsymbol {w} \tag {2}
$$

计算梯度：

$$
\nabla_ {\boldsymbol {w}} \tilde {J} (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) = \nabla_ {\boldsymbol {w}} J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) + \alpha \boldsymbol {w} \tag {3}
$$

更新权重：

$$
\boldsymbol {w} \leftarrow \boldsymbol {w} - \epsilon (\alpha \boldsymbol {w} + \nabla_ {\boldsymbol {w}} J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y})) = (1 - \epsilon \alpha) \boldsymbol {w} - \epsilon \nabla_ {\boldsymbol {w}} J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) \tag {4}
$$

从上式可以看出，加⼊权重衰减后会导致学习规则的修改，即在每步执⾏梯度更新前先收缩权重 (乘以 $( 1 - \epsilon \alpha )$ )。

以第六章介绍的代价函数 $\begin{array} { r } { J ( \theta ) = - { \frac { 1 } { m } } \sum _ { i = 1 } ^ { m } \left( y ^ { ( i ) } \log \hat { y } ^ { ( i ) } + ( 1 - y ^ { ( i ) } ) \log ( 1 - \hat { y } ^ { ( i ) } ) \right) } \end{array}$ 为例，在增加 $L ^ { 2 }$ 正则化后，代价函数变为：

$$
J _ {\text {r e g u l a r i z e d}} = \underbrace {- \frac {1}{m} \sum_ {i = 1} ^ {m} \left(\boldsymbol {y} ^ {(i)} \log \left(\hat {\boldsymbol {y}} ^ {(i)} + (1 - \boldsymbol {y} ^ {(i)}) \log \left(1 - \hat {\boldsymbol {y}} ^ {(i)}\right)\right) + \underbrace {\frac {1}{m} \frac {\lambda}{2} \sum_ {l} \sum_ {k} \sum_ {j} W _ {k , j} ^ {[ l ] 2}} _ {\text {c r o s s - e n t r o p y c o s t}}\right.} _ {\text {L 2 r e g u l a r i z a t i o n c o s t}} \tag {5}
$$

⽽在反向传播的时候，须加上正则化项的梯度：

$$
\frac {d}{d \boldsymbol {W}} \left(\frac {1}{2} \frac {\lambda}{m} \boldsymbol {W} ^ {2}\right) = \frac {\lambda}{m} \boldsymbol {W} \tag {6}
$$

# 1.2 $L ^ { 1 }$ 正则化

将参数惩罚项 $\Omega ( \theta )$ 由权重衰减项修改为各个参数的绝对值之和，可以得到 $L ^ { 1 }$ 正则化：

$$
\Omega (\theta) = \| \boldsymbol {w} \| _ {1} = \sum_ {i} | w _ {i} | \tag {7}
$$

⽬标函数：

$$
\tilde {J} (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) = J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) + \alpha \| \boldsymbol {w} \| _ {1} \tag {8}
$$

计算梯度：

$$
\nabla_ {\boldsymbol {w}} \tilde {J} (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) = \nabla_ {\boldsymbol {w}} J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y}) + \alpha s g n (\boldsymbol {w}) \tag {9}
$$

其中 $s g n ( x )$ 为符号函数，取各个元素的正负号。

更新权重：

$$
\boldsymbol {w} \leftarrow \boldsymbol {w} - \epsilon (\alpha s g n (\boldsymbol {w}) + \nabla_ {\boldsymbol {w}} J (\boldsymbol {w}; \boldsymbol {X}, \boldsymbol {y})) \tag {10}
$$

同样，在增加 $L ^ { 1 }$ 正则化后，代价函数变为：

$$
J _ {r e g u l a r i z e d} = \underbrace {- \frac {1}{m} \sum_ {i = 1} ^ {m} \left(\boldsymbol {y} ^ {(i)} \log \hat {\boldsymbol {y}} ^ {(i)} + (1 - \boldsymbol {y} ^ {(i)}) \log (1 - \hat {\boldsymbol {y}} ^ {(i)})\right)} _ {\text {c r o s s - e n t r o p y c o s t}} + \underbrace {\frac {1}{m} \frac {\lambda}{2} \sum_ {l} \sum_ {k} \sum_ {j} | W _ {k , j} ^ {[ l ]} |} _ {\text {L 1 r e g u l a r i z a t i o n c o s t}} \tag {11}
$$

⽽在反向传播的时候，须加上正则化项的梯度：

$$
\frac {d}{d \boldsymbol {W}} \left(\frac {\lambda}{m} \| \boldsymbol {W} \|\right) = \frac {\lambda}{m} \operatorname {s g n} (\boldsymbol {W}) \tag {12}
$$

[1]: from abc import ABC, abstractmethod

```python
import numpy as np  
from PIL import Image  
%matplotlib inline  
import matplotlib.pyplot as plt  
import math  
import re  
import time  
import progressbar  
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import StandardScaler 
```

[2]: class RegularizerBase(ABC):

```python
def __init__(self, **kwargs):
    super().__init__()
@abstractmethod
def loss(self, **kwargs):
    raise NotImplementedError
@abstractmethod
def grad(self, **kwargs):
    raise NotImplementedError
class L1Regularizer(RegularizerBase):
    def __init__(self, lambda=0.001):
        super().__init__()
        self.lambd = lambda
    def loss(self, params):
        loss = 0
        pattern = re.compile(r'^W\d+')
        for key, val in params.items():
            if pattern.match(key):
                loss += 0.5 * np.sum(np.abs(val)) * self.lambd
            return loss
    def grad(self, params):
        for key, val in params.items():
            grad = self.lambd * np.sign(val)
            return grad
class L2Regularizer(RegularizerBase):
    def __init__(self, lambda=0.001):
        super().__init__()
        self.lambd = lambda
    def loss(self, params):
        loss = 0 
```

for key, val in params.items(): loss $+ =$ 0.5 \* np.sum(np(square(val)) \* self.lambd return loss   
def grad(self, params): for key, val in params/items(): grad $=$ self.lambd \* val return grad   
class RegularizerInitializer(object): def __init__(self, regular_name="l2"): self.regular_name $=$ regular_name   
def __call__(self): r $=$ r"([a-zA-Z]\*)=([\^,])\*" regular_str $=$ self.regular_name(lower()) kwargs $=$ dict([(i, eval(j)) for (i, j) in re.findall(r, regular_str)]) if "l1" in regular_str.lower(): regular $=$ L1Regularizer(**kwargs) elif "l2" in regular_str.lower(): regular $=$ L2Regularizer(**kwargs) else: raise ValueError("Unrecognized regular: \{\}".format(regular_str)) return regular

我们对第六章介绍的 DFN 引⼊正则项，我们将第六章中介绍的函数存储在 chapter6.py 中。

[3]: from chapter6 import WeightInitializer, ActivationInitializer, LayerBase, CrossEntropy, OrderedDict, softmax   
[4]: class FullyConnected(LayerBase):

```python
a=g(x+W+b) x a
```
def __init__(self, n_out, acti_fn, init_w, optimizer=None):
    acti_fn str
    init_w str
    n_out optimizer
    super().__init__(optimizer)
    self.n_in = None # int
    self.n_out = n_out # int
    self.acti_fn = ActivationInitializer(acti_fn())
    self.init_w = init_w
    self.initweights = WeightInitializer(mode=init_w)
    self.is Initialized = False # bool
def __init_parameters(self):
    b = np.zeros((1, self.n_out))
    W = self.initweights((self.n_in, self.n_out))
    self.params = {"W": W, "b": b}
    self_gradients = {"W": np.zeros_like(W), "b": np.zeros_like(b)}
    self.is Initialized = True
def forward(self, X, retain Derived=True):
    ''' 
```

X n_samples, n_in float   
retain Derived bool   
"" if not self.is Initialized: # self.n_in $\equiv$ X.shape[1] self._init.params() W $=$ self.params["W"] b $=$ self.params["b"] Z $= \mathrm{X}$ @W+b a $=$ self.actif_fn.forward(z) if retain Derived: self.X.append(X) return a   
def backward(self, dLda, retain_grads=True, regular=None):

```python
dLda n_samples, n_out float  
retain_grads bool  
regular  
"..."  
if not isinstance(dLda, list):  
    dLda = [dLda]  
dx = []  
X = self.X  
for da, x in zip(dLda, X):  
    dx, dw, db = self._bwd(da, x, regular)  
dx.append(dx)  
if retain_grads:  
    self/gradients["W"] += dw  
    self/gradients["b"] += db  
return dX[0] if len(X) == 1 else dX 
```

def_bwd(self,dLda,X,regular): W $=$ self.params["W"] b $=$ self.params["b"] Z $= \mathrm{X}\text{@}W + \mathrm{b}$ dZ $=$ dLda \* self.acti_fn.gradle(Z) dX $= \mathrm{dZ}\text{@}W.\mathrm{T}$ dW $= X.T\text{@}DZ$ db $= \mathrm{dZ}$ sum(axis $= 0$ ，keepdims $\equiv$ True) if regular is not None: n $=$ X.shape[O] dw_norm $=$ regular_grad(self.params)/n dw $+ =$ dW_norm return dx,dw,DB

```txt
@property   
def hyperparams(self): return{ "layer": "FullyConnected", "init_w": self.init_w, "n_in": self.n_in, "n_out": self.n_out, "acti_fn": str(self.acti_fn), 
```

```python
"optimizer": { "hyperparams": self optimizer.hyperparams, }, "components": { k: v for k, v in self.params.items() } } 
```

```python
[5]: def minibatch(X, batchsize=256, shuffle=True):
    "" batch mini batch 8
    "" N = X.shape[0]
    idx = np.arange(N)
    n_batches = int(np.ceil(N / batchsize))
    if shuffle:
        np.random.shuffle(idx)
    def mb_generation():
        for i in range(n_batches):
            yield idx[i * batchsize : (i + 1) * batchsize]
    return mb_generation(), n_batches
class DFN(object):
    def __init__(self, hidden_dims_1=None, hidden_dims_2=None, optimizer="sgd(lr=0.01)", init_w="std_normal", regular_ACT=None, loss=CrossEntropy())
    selfOptimizer = optimizer
    self.init_w = init_w
    self.loss = loss
    self.regular_ACT = regular_ACT
    self.regular = None
    self(hidden_dims_1 = hidden_dims_1
    self-hidden_dims_2 = hidden_dims_2
    self.is Initialized = False
def __set_parameters(self):
    "" FC1 -> Sigmoid -> FC2 -> Softmax ""
    "" self.layers = OrderedDict()
    self.layers["FC1"] = FullyConnected(n_out= self-hidden_dims_1, acti_fn="sigmoid",
init_w= self.init_w,
optimizer= selfOptimizer)
    self.layers["FC2"] = FullyConnected(n_out= self-hidden_dims_2,
acti_fn="affine(slope=1, intercept=0)", init_w= self.init_w, 
```

optimizer $\equiv$ self optimizer   
）   
if self.regular_act is not None: self.regular $=$ RegularizerInitializer(self.regular_act()） self.is Initialized $=$ True

```python
def forward(self, X_train):
    Xs = {}
    out = X_train
    for k, v in self.layers:
        Xs[k] = out
        out = v.forward(out) 
```

```python
def backward(self, grad):  
    dXs = {}.  
    out = grad  
    for k, v in reversed(list(self.layers.items())):  
        dXs[k] = out  
        out = v.backward(out, regular=self.regular)  
    return out, dXs 
```

```python
def update(self):
    ""
    ""
    ""
    for k, v in reversed(list(self.layers.items)):
        v.update()
    self.flush_gradients() 
```

```python
def flush_gradients(self, curr_loss=None):
    ""
    ""
    ""
    ""
    for k, v in self.layers.items():
        v.flush_gradients() 
```

```python
def fit(self, X_train, y_train, n_epochs=20, batch_size=64, verbose=False): 
```

```txt
X_train   
y_train   
n_epochs epoch   
batch_size epoch batch s   
verbose batch 
```

```python
selfverbose = verbose
self.n_epochs = n_epochs
self.batch_size = batch_size
if not self.is Initialized:
    self.n_features = X_train.shape[1]
    self._set_parameters()
prev_loss = np.inf
for i in range(n_epochs):
    loss, epoch_start = 0.0, time.time()
    batch_generator, n_batch = minibatch(X_train, self.batch_size, shuffle=True)
    for j, batch IDX in enumerate(batch.generator):
        batch_len, batch_start = len(batch IDX), time.time() 
```

X_batch, y_batch = X_train[batch IDX], y_train[batch IDX] out, $\equiv$ self.forward(X_batch) y_pred_batch $=$ softmax(out) batch_loss $=$ self.loss(y_batch, y_pred_batch) # if self.regular is not None: for _, layerparams in selfhyperparams['components'].items(): assert type(layerparams) is dict batch_loss $+ =$ self.regular.loss(layerparams) grad $=$ self.lossGrad(y_batch, y_pred_batch) _, $\equiv$ self.backup(grad) self.update() loss $+ =$ batch_loss if selfverbose: fstr $=$ "\t[Batch {}]{} Train loss: $\{\therefore .3\mathrm{f}\}$ (\{\:.1f}s/batch)" print(fstr.format(j + 1, n_batch, batch_loss, time.time() - batch_start)) loss $= =$ n_batch fstr $=$ "[Epoch{}]Avg. loss: $\{\therefore .3\mathrm{f}\}$ Delta: $\{\therefore .3\mathrm{f}\}$ (\{\:.2f}m/epoch)" print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0)) prev_loss $=$ loss def evaluate(self, X_test, y_test, batch_size=128): acc $= 0.0$ batch_generator, n_batch $=$ minibatch(X_test, batch_size, shuffle=True) for j, batch IDX in enumerate(batch_generator): batch_len, batch_start $=$ len(batch IDX), time.time() X_batch, y_batch $=$ X_test[batch IDX], y_test[batch IDX] y_pred_batch,_ $=$ self.forward(X_batch) y_pred_batch $=$ np.argmax(y_pred_batch, axis=1) y_batch $=$ np.argmax(y_batch, axis=1) acc $+ =$ np.sum(y_pred_batch $= =$ y_batch) return acc / X_test.shape[0]   
@property   
def hyperparams(self): return { "init_w": self.init_w, "loss": str(self.loss), "optimizer": selfOptimizer, "regular": str(self.regulargact), "hidden_dims_1": self-hidden_dims_1, "hidden_dims_2": self-hidden_dims_2, "components": $\{\mathbf{k}$ : v.params for k, v in self.layers.items()) }

[6]: def load_data(path="../data/mnist/mnist.npz"):   
```python
f = np.load(path)  
X_train, y_train = f['x_train'], f['y_train']  
X_test, y_test = f['x_test'], f['y_test']  
f.close()  
return (X_train, y_train), (X_test, y_test)  
(X_train, y_train), (X_test, y_test) = load_data()  
y_train = np.eye(10)[y_train.astype(int)]  
y_test = np.eye(10)[y_test.astype(int)]  
X_train = X_train.reshape(-1, X_train.shape[1]*X_train.shape[2]).dtype('float32')  
X_test = X_testreshape(-1, X_test.shape[1]*X_test.shape[2]).dtype('float32')  
print(X_train.shape, y_train.shape) 
```

```python
N = 20000 # 20000  
indices = np.random.permutation(range(X_train.shape[0]))[:N]  
X_train, y_train = X_train[indices], y_train[indices]  
print(X_train.shape, y_train.shape)  
X_train /= 255  
X_train = (X_train - 0.5) * 2  
X_test /= 255  
X_test = (X_test - 0.5) * 2 
```

(60000, 784) (60000, 10)

(20000, 784) (20000, 10)

[7]:

```snap
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
```
`` 
```

```txt
[Epoch 1] Avg. loss: 2.286 Delta: inf (0.01m/epoch)  
[Epoch 2] Avg. loss: 2.209 Delta: 0.078 (0.01m/epoch)  
[Epoch 3] Avg. loss: 1.993 Delta: 0.215 (0.01m/epoch)  
[Epoch 4] Avg. loss: 1.640 Delta: 0.353 (0.01m/epoch)  
[Epoch 5] Avg. loss: 1.305 Delta: 0.335 (0.01m/epoch)  
[Epoch 6] Avg. loss: 1.063 Delta: 0.242 (0.01m/epoch)  
[Epoch 7] Avg. loss: 0.898 Delta: 0.166 (0.01m/epoch)  
[Epoch 8] Avg. loss: 0.781 Delta: 0.117 (0.01m/epoch)  
[Epoch 9] Avg. loss: 0.696 Delta: 0.085 (0.01m/epoch)  
[Epoch 10] Avg. loss: 0.634 Delta: 0.062 (0.01m/epoch)  
[Epoch 11] Avg. loss: 0.586 Delta: 0.048 (0.01m/epoch)  
[Epoch 12] Avg. loss: 0.549 Delta: 0.037 (0.01m/epoch)  
[Epoch 13] Avg. loss: 0.518 Delta: 0.031 (0.02m/epoch)  
[Epoch 14] Avg. loss: 0.493 Delta: 0.025 (0.02m/epoch)  
[Epoch 15] Avg. loss: 0.473 Delta: 0.021 (0.01m/epoch)  
[Epoch 16] Avg. loss: 0.454 Delta: 0.018 (0.01m/epoch)  
[Epoch 17] Avg. loss: 0.439 Delta: 0.015 (0.01m/epoch)  
[Epoch 18] Avg. loss: 0.425 Delta: 0.014 (0.01m/epoch)  
[Epoch 19] Avg. loss: 0.414 Delta: 0.012 (0.01m/epoch)  
[Epoch 20] Avg. loss: 0.404 Delta: 0.010 (0.01m/epoch) 
```

[8]:

```python
print("without regularization -- accuracy:{}"format(model.evalate(X_test，y_test)))   
######if show params ##########   
# print("regular", modelhyperparams["regular"], "\nparams:"，model.hyperparams["components']) 
```

```txt
without regularization -- accuracy:0.8961 
```

[9]:

```python
l2
```
model_re = DFN(hidden_dims_1=200, hidden_dims_2=10, regular_ACT="l2(lambd=0.01)") 
model_re.fit(X_train, y_train, n_epochs=20) 
```

```txt
[Epoch 1] Avg. loss: 2.363 Delta: inf (0.02m/epoch)  
[Epoch 2] Avg. loss: 2.284 Delta: 0.079 (0.02m/epoch)  
[Epoch 3] Avg. loss: 2.068 Delta: 0.216 (0.02m/epoch)  
[Epoch 4] Avg. loss: 1.729 Delta: 0.339 (0.02m/epoch)  
[Epoch 5] Avg. loss: 1.428 Delta: 0.301 (0.02m/epoch)  
[Epoch 6] Avg. loss: 1.226 Delta: 0.202 (0.02m/epoch)  
[Epoch 7] Avg. loss: 1.096 Delta: 0.130 (0.02m/epoch)  
[Epoch 8] Avg. loss: 1.013 Delta: 0.083 (0.02m/epoch)  
[Epoch 9] Avg. loss: 0.958 Delta: 0.055 (0.02m/epoch) 
```

```txt
[Epoch 10] Avg. loss: 0.923 Delta: 0.035 (0.01m/epoch)  
[Epoch 11] Avg. loss: 0.899 Delta: 0.024 (0.01m/epoch)  
[Epoch 12] Avg. loss: 0.883 Delta: 0.016 (0.01m/epoch)  
[Epoch 13] Avg. loss: 0.872 Delta: 0.011 (0.01m/epoch)  
[Epoch 14] Avg. loss: 0.865 Delta: 0.007 (0.01m/epoch)  
[Epoch 15] Avg. loss: 0.860 Delta: 0.004 (0.01m/epoch)  
[Epoch 16] Avg. loss: 0.858 Delta: 0.002 (0.01m/epoch)  
[Epoch 17] Avg. loss: 0.858 Delta: 0.001 (0.01m/epoch)  
[Epoch 18] Avg. loss: 0.858 Delta: -0.000 (0.02m/epoch)  
[Epoch 19] Avg. loss: 0.859 Delta: -0.001 (0.01m/epoch)  
[Epoch 20] Avg. loss: 0.860 Delta: -0.001 (0.01m/epoch) 
```

```txt
[10]: print("with L2 regularization -- accuracy:{})".format(model_re.evaluate(X_test, y_test)))  
```python
>>> #if show params ____________  
#print("regular", model_rehyperparams["regular"], "\nparams:", model_re.hyperparams["components")] 
```

```txt
with L2 regularization -- accuracy:0.8958 
```

# 1.3 总结

相比 $L ^ { 2 }$ 正则化， $L ^ { 1 }$ 正则化会产生更稀疏的解。

假设 $\ b { w } ^ { * }$ 为未正则化的⽬标函数取得最优时的权重向量，并假设原⽬标函数有⼆阶导，将 $J ( w )$ 在 $\ b { w } ^ { * }$ 处⼆阶泰勒展开 (最优值点⼀阶导数为 0)：

$$
J (\boldsymbol {w}) \approx J \left(\boldsymbol {w} ^ {*}\right) + \frac {1}{2} \left(\boldsymbol {w} - \boldsymbol {w} ^ {*}\right) ^ {\top} \mathrm {H} \left(\boldsymbol {w} - \boldsymbol {w} ^ {*}\right) \tag {13}
$$

其中 H 是 $J ( w )$ 在 $\ b { w } ^ { * }$ 处的海森矩阵。 $J ( w )$ 最⼩时满⾜上式导数为 0，于是：

$$
\nabla J (\boldsymbol {w}) = \mathrm {H} (\boldsymbol {w} - \boldsymbol {w} ^ {*}) = 0 \tag {14}
$$

我们再考虑 $L ^ { 2 }$ 正则化条件下， $\Omega ( \theta ) = \alpha \frac { 1 } { 2 } \| \pmb { w } \| _ { 2 } ^ { 2 }$ ，则可以得到：

$$
\nabla J (\boldsymbol {w}) = \mathrm {H} (\boldsymbol {w} - \boldsymbol {w} ^ {*}) + \alpha \boldsymbol {w} = 0 \tag {15}
$$

于是，我们可以得到新的最优解 $\tilde { \mathbf { \Gamma } } \tilde { \mathbf { \Gamma } } ^ { v }$ 满⾜：

$$
\tilde {\boldsymbol {w}} = \left(\mathrm {H} + \alpha \boldsymbol {I}\right) ^ {- 1} \mathrm {H} \boldsymbol {w} ^ {*} \tag {16}
$$

如果考 Hessian 矩阵是对⾓正定矩阵，我们得到 $L ^ { 2 }$ 正则化的最优解是 $\begin{array} { r } { \tilde { w } _ { i } = \frac { \mathrm { H } _ { i , i } } { \mathrm { H } _ { i , i } + \alpha } { w } _ { i } ^ { * } } \end{array}$ Hi,i 。如果 $w _ { i } ^ { * } \neq 0$ ，则 $\tilde { w } _ { i } \ne 0$ ，这说明 $L ^ { 2 }$ 正则化不会使参数变得稀疏。

我们再看 $L ^ { 1 }$ 正则化的最优解，同样，我们得到考虑 $L ^ { 1 }$ 正则化条件下的最优解，此时需要满⾜：

$$
\nabla J (\tilde {\boldsymbol {w}}) = \mathrm {H} (\tilde {\boldsymbol {w}} - \boldsymbol {w} ^ {*}) + \alpha s g n (\tilde {\boldsymbol {w}}) = 0 \tag {17}
$$

为了简化讨论，我们假设 H 为对⾓阵，即 $\mathrm { H } = d i a g [ \mathrm { H } _ { 1 , 1 } , \mathrm { H } _ { 2 , 2 } , . . . \mathrm { H } _ { n , n } ] , \mathrm { H } _ { i , i } > 0$ ( 可以⽤ PCA 预处理输⼊特征得到)，此时

$$
\tilde {w} _ {i} = w _ {i} ^ {*} - \frac {\alpha}{\mathrm {H} _ {i , i}} \operatorname {s g n} \left(\tilde {w} _ {i}\right) \tag {18}
$$

从这个式⼦也可以明显看出 $\tilde { \mathbf { \Sigma } } \tilde { \mathbf { \Sigma } } ^ { v }$ 和 $\ b { w } ^ { * }$ 是同号的。所以有：

$$
\tilde {w} _ {i} = w _ {i} ^ {*} - \frac {\alpha}{\mathrm {H} _ {i , i}} \operatorname {s g n} \left(w _ {i} ^ {*}\right) = \operatorname {s g n} \left(w _ {i} ^ {*}\right) \left(\left| w _ {i} ^ {*} \right| - \frac {\alpha}{\mathrm {H} _ {i , i}}\right) \tag {19}
$$

同样，既然 $\tilde { \mathbf { \Gamma } } \tilde { \mathbf { \Gamma } } ^ { v }$ 和 $\ b { w } ^ { * }$ 是同号的，两边同乘 $s g n ( \tilde { \mathbf { \em w } } )$ ，得到：

$$
\left| w _ {i} ^ {*} \right| - \frac {\alpha}{\mathrm {H} _ {i , i}} = \left| \tilde {w} _ {i} \right| \geq 0 \tag {20}
$$

于是刚才的式⼦可以进⼀步写为：

$$
\tilde {w} _ {i} = \operatorname {s g n} \left(w _ {i} ^ {*}\right) \max  \left\{\left| w _ {i} ^ {*} \right| - \frac {\alpha}{\mathrm {H} _ {i , i}}, 0 \right\} \tag {21}
$$

可以看出， $L ^ { 1 }$ 正则化有可能通过⾜够⼤的 $\alpha$ 实现稀疏。

• 正则化策略可以被解释为最⼤后验 (MAP) 贝叶斯推断。(详细内容见第五章)

– $L ^ { 2 }$ 正则化相当于权重是 的 MAP 贝叶斯推断；

– $L ^ { 1 }$ 正则化相当于权重是 Laplace 的 MAP 贝叶斯推断。

# 1.4 作为约束的范数惩罚

考虑参数范数正则化的代价函数：

$$
\tilde {J} (\theta ; \boldsymbol {X}, \boldsymbol {y}) = J (\theta ; \boldsymbol {X}, \boldsymbol {y}) + \alpha \Omega (\theta) \tag {22}
$$

如果想约束 $\Omega ( \theta ) < k$ ， $k$ 是某个常数，可以构造⼴义 Lagrange 函数：

$$
\mathcal {L} (\theta , \alpha ; \boldsymbol {X}, \boldsymbol {y}) = J (\theta ; \boldsymbol {X}, \boldsymbol {y}) + \alpha (\Omega (\theta) - k) \tag {23}
$$

该约束问题的解是：

$$
\theta^ {*} = \arg \min  _ {\theta} \max  _ {\alpha , \alpha \geq 0} \mathcal {L} (\theta , \alpha) \tag {24}
$$

对于该问题，可以通过调节 $\alpha$ 与 $k$ 的值来扩⼤或缩⼩权重的约束区域。较⼤的 $\alpha$ 将得到⼀个较⼩的约束区域；⽽较⼩的 $\alpha$ 将得到⼀个较⼤的约束区域。

另⼀⽅⾯，重新考虑 1.1 和 1.2 中的正则化，正则化式等价于带约束的⽬标函数中的约束项。例如以平⽅损失函数和 $L ^ { 2 }$ 正则化为例，优化模型如下:

$$
J (\boldsymbol {\theta}; \boldsymbol {X}, \boldsymbol {y}) = \sum_ {i = 1} ^ {n} \left(y _ {i} - \theta^ {\top} \mathrm {x} _ {\mathrm {i}}\right) ^ {2} \tag {25}
$$

$$
s. t. \| \boldsymbol {\theta} \| _ {2} ^ {2} <   = C
$$

采⽤拉格朗⽇乘积算⼦法可以转化为⽆约束优化问题，即：

$$
J (\boldsymbol {\theta}; \boldsymbol {X}, \boldsymbol {y}) = \sum_ {i = 1} ^ {n} \left(y _ {i} - \boldsymbol {\theta} ^ {\top} \boldsymbol {x} _ {i}\right) ^ {2} + \lambda \left(\| \boldsymbol {\theta} \| _ {2} ^ {2} - C\right) \tag {26}
$$

# 1.5 欠约束问题

机器学习中许多线性模型，如线性回归和 PCA，都依赖于矩阵 $\boldsymbol { X ^ { \intercal } X }$ 求逆。如果 $\boldsymbol { X ^ { \intercal } X }$ 不可逆，这些⽅法就会失效。这种情况下，正则化的许多形式对应求逆 $X ^ { \top } X + \alpha I$ ，且这个正则化矩阵是可逆的。⼤多数正则化⽅法能够保证应⽤于⽋定问题的迭代⽅法收敛。

例如线性回归的损失函数是平⽅误差之和： $( X \pmb { w } - \pmb { y } ) ^ { \top } ( \pmb { X } \pmb { w } - \pmb { y } )$ 。

我们添加 $L ^ { 2 }$ 正则项后，⽬标函数变为 $\begin{array} { r } { ( X { \pmb w } - { \pmb y } ) ^ { \top } ( X { \pmb w } - { \pmb y } ) + \frac { 1 } { 2 } \alpha { \pmb w } ^ { \top } { \pmb w } \circ } \end{array}$

这将普通⽅程的解从 $\pmb { w } = ( \pmb { X } ^ { \top } \pmb { X } ) ^ { - 1 } \pmb { X } ^ { \top } \pmb { y }$ 变为 $\pmb { w } = ( \pmb { X } ^ { \top } \pmb { X } + \alpha \pmb { I } ) ^ { - 1 } \pmb { X } ^ { \top } \pmb { y } \circ$

# 2 数据增强

# 2.1 数据集增强

数据集增强是解决数据量有限的问题，让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练 (这在对象识别 (object detection) 问题很有效)。

⽅法:

• 类别不改变，平移不变性。⽐如对图像的平移，旋转，缩放。  
• 注⼊噪声，可以使模型对噪声更健壮 (如去噪⾃编码器)。

[11]: class Image(object):

```python
def __init__(self, image):
    self._set_parameters(image)
def _set_parameters(self, image):
    self.img = image
    self.row = image.shape[0] # 
        self.col = image.shape[1] # 
        self.transform = None
def Translation(self, delta_x, delta_y):
    ''''
    delta_x 0 
```

```python
def Resize(self, alpha):
    alpha 1
    self.transform = np.array([[1, 0, delta_x],
                    [0, 1, delta_y],
                    [0, 0, 1]])
def HorMirror(self):
    return
    self.transform = np.array([[alpha, 0, 0],
                    [0, alpha, 0],
                    [0, 0, 1]])
def VerMirror(self):
    return
    self.transform = np.array([[1, 0, 0],
                    [0, -1, self.col-1],
                    [0, 0, 1]])
def Rotate(self, angle):
    return
    angle
    self.transform = np.array([[math.cos(angle), -math.sin(angle), 0],
                    [math.sin(angle), math.cos(angle), 0],
                    [0, 0, 0, 1]])
def operate(self):
    temp = np.zeros(self.img.shape, dtypeself.img.dtype)
    for i in range(self.row):
        for j in range(selfCOLUMN):
            temp_pos = np.array[i, j, 1]
            [x,y,z] = np.dot(self.transform, temp_pos)
            x = int(x)
            y = int(y)
            if x >= self.img or y >= self.img or x < 0 or y < 0:
                temp[i,j,:] = 0
            else:
                temp[i,j,:] = self.img[x,y]
        return temp
def __call__(self, act):
    return 
```

$\mathbf{r} = \mathbf{r}^{\prime \prime}([a - zA - Z]*) = ([\hat{\cdot},])*$ act_str $=$ act(lower()   
kwarges $=$ dict([i,eval(j)) for (i,j) in re.findall(r, act_str)])   
if "translation" in act_str: selfTRANlation(**kwarges)   
elif "resize"in act_str: self Resize(**kwarges)   
elif "hormirror" in act_str: self.HorMirror(**kwarges)   
elif "vermirror" in act_str: self.VerMirror(**kwarges)   
elif "rotate"in act_str: self.Rotate(**kwarges)   
return self.operate()

```python
[12]:   
```
```
```
def load_data(path="../data/mnist/mnist.npz"): 
    f = np.load(path) 
    X_train, y_train = f['x_train'], f['y_train'] 
    X_test, y_test = f['x_test'], f['y_test'] 
    f.close() 
    return (X_train, y_train), (X_test, y_test) 
(X_train, y_train), (X_test, y_test) = load_data() 
```

```python
[13]: img = X_train[0].reshape(28, 28, 1)  
Img = Image(img)  
ax = plt.subplot(121)  
plttight.layout()  
plt.imshow(img.reshape(28, 28))  
plt.title('Original')  
plt.axis('off')  
ax = plt.subplot(122)  
plt.imshow(Img('vermirror').reshape(28, 28))  
plt.title('VerMirror')  
plt.axis('off')  
plt.show() 
```

![](images/10c700740d9b7f8bd43f37b3e3f92cb3ea6800855a84d6b1ddede3c23ce589b9.jpg)

![](images/840f90421e3bbde2cade22415d0ec1cd3ffe21c2ffbf87cae0a6a0894566cd3e.jpg)

# 2.2 噪声鲁棒性

• 将噪声加入到输入，等同于数据集增强。  
• 将噪声加入到权重，能够表现权重的不确定性，这项技术主要⽤于循环神经⽹络。这可以被解释为关于权重的贝叶斯推断的随机实现，贝叶斯学习过程将权重视为不确定的，并且可以通过概率分布表⽰这种不确定性，向权重添加噪声是反映这种不确定性的⼀种实⽤的随机⽅法。  
• 将噪声加入到输出，对噪声建模 (滤波)，标签平滑。由于⼤多数数据集的 $\textbf {  { y } }$ 标签都有⼀定错误，错误的 $\textbf {  { y } }$ 不利于最⼤化 $\log p ( \pmb { y } \mid \pmb { x } )$ ，避免这种情况的⼀种⽅法是显式地对标签上的噪声进⾏建模。

# 3 训练方案

# 3.1 半监督学习

监督学习指训练样本都是带标记的。然⽽在现实中，获取数据是容易的，但是收集到带标记的数据却是⾮常昂贵的。半监督学习指的是既包含部分带标记的样本也有不带标记的样本，通过这些数据来进⾏学习。在半监督学习的框架下， $P ( { \pmb x } )$ 产⽣的未标记样本和 $P ( \pmb { x } , \pmb { y } )$ 中的标记样本都⽤于估计 $P ( \pmb { y } \mid \pmb { x } )$ 。在深度学习的背景下，半监督学习通常指的是学习⼀个表⽰ $h = f ( { \pmb x } )$ ，学习表示的目的是使相同类中的样本有类似的表示。

我们可以构建这样⼀个模型，其中⽣成模型 $P ( { \pmb x } )$ 或 $P ( { \pmb x } , { \pmb y } )$ 与判别模型 $P ( \pmb { y } \mid \pmb { x } )$ 共享参数，⽽不⽤分离⽆监督和监督部分。例如，我们可以这么做深度学习下的半监督学习，在损失函数中同时考虑两部分损失，⼀部分是有监督损失，另⼀部分是⽆监督损失 (⽆监督标签为 Pseudo Label，即直接取⽹络对⽆标签数据的预测的最⼤值为标签)。如果我们还⿎励⽹络学习数据内在的不变性，则可以构造⽆监督代价是对同⼀个输⼊在不同的正则和数据增强条件下的⼀致性。即要求在不同的条件下，模型的估计要⼀致。

# 3.2 多任务学习

多任务学习是基于共享表⽰，把多个相关的任务放在一起学习的⼀种机器学习⽅法。当模型的⼀部分被多个额外的任务共享时，这部分将被约束为良好的值，通常会带来更好的泛化能力。

从深度学习的观点看，底层的先验知识为：能解释数据变化的因素中，某些因素是跨多个任务共享的。

可以考虑对复杂的问题，分解为简单且相互独⽴的⼦问题来单独解决。做单任务学习时，各个任务之间的模型空间是相互独⽴的，但这忽略了问题之间所富含的丰富的关联信息；⽽多任务学习便把多个相关的任务放在⼀起学习，学习过程中通过⼀个在浅层的共享表⽰来互相分享、互相补充学习到的领域相关的信息，互相促进学习，提升泛化的效果。

多任务学习是正则化的⼀种⽅法，对于与主任务相关的任务，可以看作是添加额外信息，数据增强；与主任务不相关的任务，可以看作是引入噪音，从⽽提⾼泛化。

![](images/fdc248b9a4fbc7a0fa75d1d7f98eab1f034721c24642c66a4267943d5868e98c.jpg)  
图 1. 多任务学习框架⽰意图，A, B, C三个任务共享底层。

# 3.3 提前终止

当训练次数过多时会经常遭遇过拟合，此时训练误差会随时间推移减少，⽽验证集误差会再次上升。提前终⽌ (Early Stopping) 是⼀种交叉验证策略，我们将⼀部分训练集作为验证集 (Validation Set)。当我们看到验证集的性能越来越差时，我们⽴即停⽌对该模型的训练。

![](images/36572bc917a2613c086295695db339a304a1e05d9e18d0adc641b0ba49689167.jpg)  
图 2. 学习曲线与提前终⽌。当测试集准确率下降时，可以提前终⽌。

提前终⽌的步骤如下：

• 将训练数据划分为训练集和测试集。  
• 在训练集上训练，并在⼀段时间间隔内在测试集上预测。  
• 当验证集上的误差⾼于上次时⽴即停⽌训练。  
• 使⽤上⼀时刻中所得的权重来作为最终权重。

具体终⽌实现的策略可以多种：

• 策略⼀: 当泛化损失⼤于某个阈值时⽴即停⽌。

• 策略⼆: 假定过拟合仅仅发⽣在训练误差变化缓慢时。  
• 策略三: 当 s 个连续时刻的泛化误差增⼤时停⽌。

⼀般⽽⾔，除⾮⽹络性能的⼩改进⽐训练时间更重要，否则选择第⼀个策略。

将测试集重新融入训练集 为了更好的利⽤所有数据，我们需要在完成提前终⽌的⾸次训练之后进⾏第⼆轮的训练，在第⼆轮中，所有的数据都被包括在内。对此我们有两个基本策略：

• 再次初始化模型，然后使⽤所有数据再次训练，在第⼆轮训练中，我们采⽤第⼀轮提前终⽌训练确定的最佳步数。  
• 保持从第⼀轮训练获得的参数，然后使⽤验证集的数据继续训练，直到验证集的平均损失函数低于提前终⽌过程终⽌时的⽬标值。

提前终⽌具有正则化效果，其真正机制可理解为将优化过程的参数空间限制在初始参数值 $\theta _ { 0 }$ 的小邻域内。考虑平⽅误差的简单线性模型，采⽤梯度下降法，可以证明假如学习率为 $\epsilon$ ，进⾏ $\tau$ 次训练迭代，则 $\textstyle { \frac { 1 } { \epsilon \tau } }$ 等价于权重衰减系数 $\alpha$ 。

[14]:

```python
```
4
```
def early_stopping(valid):
    ...
    valid
    ...
    if len(valid) > 5:
        if valid[-1] < valid[-5] and valid[-2] < valid[-5] and valid[-3] < valid[-5] and valid[-4] < valid[-5]:
            return True
    return False 
```

# 4 模型表示

# 4.1 参数绑定与共享

参数范数惩罚或约束是相对于固定区域或点，如 $L ^ { 2 }$ 正则化是对参数偏离 0 进⾏惩罚。有时我们需要对模型参数之间的相关性进⾏惩罚，使模型参数尽量接近或者相等：

# 参数共享：强迫模型某些参数相等：

• 主要应⽤：卷积神经⽹络 (CNN)  
• 优点：显著降低了 CNN 模型的参数数量 (CNN 模型参数数量经常是千万量级以上)，减少模型所占⽤的内存，并且显著提⾼了⽹络⼤⼩⽽不需要相应的增加训练数据。

# 4.2 稀疏表示

稀疏表⽰也是卷积神经⽹络经常⽤到的正则化⽅法。 $L ^ { 1 }$ 正则化会诱导稀疏的参数，使得许多参数为 0；⽽稀疏表⽰是惩罚神经⽹络的激活单元，稀疏化激活单元。换⾔之，稀疏表⽰是使得每个神经元的输⼊单元变得稀疏，很多输⼊是 0。如下图所⽰，相⽐于全连接层，隐藏层的 $h$ 接受到稀疏的输⼊ x。

![](images/86185b5a6e4bbffa451563521cb815f7390936d5daa839a1cc79d2995b12ac3a.jpg)  
图 3. 稀疏表⽰⽰意图，每个隐藏层神经元最多连接三个输⼊单元。

# 4.3 Bagging 及其他集成方法

整合多个弱分类器，成为一个强大的分类器，这是集合学习的思想。集成学习主要有 Boosting 和 Bagging 两种思路。

# 4.3.1 Bagging 方法

在深度学习中，可以考虑⽤ Bagging 的思路来正则化。Bagging (Bootstrap Aggregating) 是通过重复采样⽣成新数据集 (Bootstrap)，再在新数据集上分别训练弱分类器，将多个弱分类器汇总成强分类器 (Aggregating)，从⽽可以降低泛化误差的技术，具体来说 Bagging 步骤：

• 构造 $k$ 个不同的数据集，每个数据集是从原始数据集中重复采样构成，和原始数据集具有相同数量的样本；  
• 分别⽤这 $k$ 个数据集去训练⽹络，得到 $k$ 个网络模型；  
• 最终输出的结果可以⽤对 $k$ 个⽹络模型的输出⽤加权平均法或者投票法来决定。

其中，我们通常选取的基础弱分类器是 CART 分类器 (见第五章)。⽽每个数据集 $D _ { i }$ 的构造：假设⼀共 $m$ 个样本，则在单个数据集中 (需重复采样样本 $m$ 次)，样本不会被采样到的概率约为 $( 1 - { \textstyle \frac { 1 } { m } } ) ^ { m } \approx { \frac { 1 } { e } } = 3 6 . 8 \%$ 。

![](images/1ff21b06732047e638a31ae1a66b4abf4bf7af5d82cd847ec981f241b13d4e7a.jpg)  
图 4. Bagging ⽅法⽰意图。

这种策略在机器学习中被称为模型平均 (Model Averaging)。模型平均是⼀个减少泛化误差的⾮常强⼤可靠的⽅法，例如我们假设有 $k$ 个回归模型, 每个模型误差是 $\epsilon _ { i }$ ，误差服从零均值、⽅差为 $v$ 、协⽅差为 $c$ 的多维正态分布，则模型平均预测的误差为 $\frac { 1 } { k } \sum _ { i } \epsilon _ { i }$ ，均⽅误差的期望为

$$
\mathbb {E} \left[ \left(\frac {1}{k} \sum_ {i} \epsilon_ {i}\right) ^ {2} \right] = \frac {1}{k ^ {2}} \mathbb {E} \left[ \sum_ {i} \left(\epsilon_ {i} ^ {2} + \sum_ {i \neq j} \epsilon_ {i} \epsilon_ {j}\right) \right] = \frac {1}{k} v + \frac {k - 1}{k} c \tag {27}
$$

可见，在误差完全相关即 $c = v$ 的情况下，均⽅误差为 $v$ ，模型平均没有帮助。在误差完全不相关即 $c = 0$ 时，模型平均的均⽅误差的期望仅为 ${ \scriptstyle { \frac { 1 } { k } } } v$ ，这说明集成平⽅误差的期望随集成规模的增⼤⽽线性减少。

Bagging ⽅法的优缺点：

• 优点：Bagging 利⽤集成学习的优势，其中多个弱学习器的表现优于单个强学习器。它有助于减少⽅差，从⽽帮助我们避免过拟合。  
• 缺点：该模型缺乏可解释性。如果建模不当，则可能存在⾼偏差的问题 (弱分类器很差，集成后预测性能仍然很差)。另⼀个重要的缺点是，尽管 Bagging 可以提⾼准确性，但计算昂贵。尤其在⽹络模型中使⽤，我们的⽹络模型本来就⽐较复杂，参数很多，现在参数又增加了 $k$ 倍，从⽽导致训练这样的⽹络要花更加多的时间和空间。因此⼀般 $k$ 的个数不能太多，⽐如 5 - 10 个就可以了。

# 4.3.2 随机森林

随机森林是对 Bagging 决策树的改进。像 CART 这样的决策树的问题在于它们的贪婪性，他们使⽤最⼩化误差的贪婪算法选择的要分割的特征变量。这样，即使使⽤ Bagging，各个决策树也可以具有很多结构相似性，进⽽它们的预测具有⾼度相关性。

如果来自子模型的预测不相关或充其量是弱相关的，则将多个模型中的预测组合在一起会更好。这是随机森林改动的动机，它更改了学习⼦模型的⽅式。这是⼀个简单的调整。在 CART 中，选择分割点时，允许学习算法浏览所有特征变量和所有变量值，以选择最佳的分割点。随机森林算法更改了此过程，学习算法仅限于要搜索特征的随机样本。

每个⼦模型可以搜索的特征的数⽬ $p$ 是模型的超参数，可以⽤交叉验证优化，默认参数为：

• 分类问题： $p = { \sqrt { n } }$   
• 回归问题： $p = n / 3$

其中 $p$ 是可以在分割点搜索的随机选择特征的数⽬， $n$ 是输⼊特征变量的数⽬。

接下来，描述⼀下随机森林的训练过程：

1. 从训练数据中创建数据⼦集，从全部 $n$ 个特征中随机选择 $p$ 个特征，其中 $p \ll n _ { \mathrm { { c } } }$ 。  
2. 在 $p$ 个特征中，执⾏ CART 的步骤，⽣成⼀棵决策树。  
3. 通过重复步骤 1 ⾄ 2 执⾏ $k$ 次来构建森林，以创建数量为 $k$ 的树。

随机森林的预测过程：

1. 采取测试特征并使⽤每个随机创建的决策树的规则来预测结果并存储预测结果 (⽬标)。  
2. 计算每个预测⽬标的票数。  
3. 将最⾼得票的预测⽬标视为随机森林算法的最终预测。

与其他分类技术相⽐，随机森林的优点：

• 对于分类问题中的应⽤，随机森林将避免过拟合问题。  
• 对于分类和回归任务，可以使⽤相同的随机森林算法。  
• 随机森林可⽤于从训练数据集中识别最重要的特征，换句话说，就是特征⼯程。

# 4.3.3 方法解决过拟合

在 “偏差和⽅差” 中我们介绍到 (第五章)，⼀个分类器的总期望误差是由偏差和⽅差这两部分之和构成的。Bagging ⽅法能够通过减少⽅差分量来降低期望误差值，包含的分类器越多，⽅差减少量就越⼤。

从泛化稳定性的⾓度来看，当学习⽅法不稳定时，即输⼊数据的微⼩变化能导致⽣成差别相当⼤的分类器。正则化技术是通过调整输⼊权重分配和校准输出的思路来缓解该问题的。⽽集成学习提供了另⼀种解决问题的思路，实际上，尽可能地使学习⽅法不稳定，增加集成分类器中的多样性，有助于提⾼分类器性能。当对决策树使⽤ Bagging 技术时，决策树已经是不稳定的，如果不对树进⾏剪枝，经常可以获得更好的性能，⽽这会使决策树变得不稳定。

更多关于集成方法及其衍生会在本章最后补充介绍 ( Boosting，GBDT，XGBoost )。

[15]: from chapter5 import ClassificationTree

[16]:   
barWidgets = [ Training:'，progressbar.Percentage()，'，progressbar.Bar marker $= -$ "，left $= -$ ["right $= -]$ ]) '，progressbar.ETA() ]   
def get_random substets(X,y，n_samples,replacements=True): 1 1   
"""(）""   
n_samples $\equiv$ np.shape(X)[0] # X y   
Xy $\equiv$ np.reshape((X，y.reshape((1，len(y))).T)，axis=1) np.random shuffle(Xy) subsets $=$ [] # 50% subsample_size $\equiv$ int(n_samples//2) if replacements: subsample_size $\equiv$ n_samples for_in range(n_samples): idx $\equiv$ np.random.choice( range(n_samples), size=np.shape(range(subsample_size)), replace $\equiv$ replacements) X $\equiv$ Xy[ix][：,-1] y $\equiv$ Xy[ix][：,-1] subsets.append([X，y]) return subsets   
class Bagging():   
""Bagging   
""def __init__(self，n_estimators=100，max_features=None，min_samples_split $= 2$ min_gain $= 0$ ，max_depth $\coloneqq$ float("inf"))： self.n_estimators $=$ n_estimators # self.min_samples_split $=$ min_samples_split # self.min_gain $=$ min_gain # (） self.max_depth $=$ max_depth # selfProgressbar $\equiv$ progressbar-progressBar(wildts=bar Widgets) # self.trees $=$ [] for_in range(n_estimators):

```python
self.trees.append(
    ClassificationTree(
        min_samples_split = self.min_samples_split,
        min_impurity = min_gain,
        max_depth = self.max_depth))
def fit(self, X, y):
    # 
    subsets = get_random substets(X, y, self.n_estimators) 
    for i in self.progressbar(range(self.n_estimators)):
        X Subset, y Subset = subsets[i]
        # ( )
        self.trees[i].fit(X Subset, y Subset) 
def predict(self, X):
    y_preds = np.empty((X.shape[0], len(self.trees)))
    # 
    for i, tree in enumerate(self.trees):
        # 
        prediction = tree.predict(X)
        y_preds[:, i] = prediction
        y_pred = []
    # 
    for samplepredictions in y_preds:
        y_pred.append(np.sum(samplepredictions.astype('int')).argmax())
    return y_pred 
def score(self, X, y):
    y_pred = self.predict(X)
    accuracy = np.sum(y == y_pred, axis=0) / len(y)
    return accuracy 
```

[17]:

class RandomForest():

```python
def __init__(self, n_estimators=100, max_features=None, min_samples_split=2, min_gain=0, max_depth=float("inf)):
    self.n_estimators = n_estimators
    self.max_features = max_features
    self.min_samples_split = min_samples_split
    self.min_gain = min_gain
    self.max_depth = max_depth
    selfprogressbar = progressbar-progressBar(wildts=bar_wildts)
    #
    self.trees = []
    for _ in range(n_estimators):
        self.trees.append(
            ClassificationTree(
                min_samples_split= self.min_samples_split,
                min_impurity=min_gain,
                max_depth= self.max_depth))
def fit(self, X, y):
    n_features = np.shape(X)[1]
    # max_features sqrt(n_features)
    if not self.max_features:
        self.max_features = int(math.sqrt(n_features))
    # 
```

用自定义的 Bagging，乳腺癌数据集测试  
subsets $=$ get_random substets(X,y,self.n_estimators)   
for i in selfprogressbar(range(self.n_estimators)): X Subset, y Subset $=$ subsets[i] # idx $=$ np.random.choice(range(n_features), size $\equiv$ self.max_features, replace $\equiv$ True) # self.trees[i].featureIndices $=$ idx # X Subset $=$ X Subset[:，idx] # ( self.trees[i].fit(X Subset, y Subset)   
def predict(self,X): y_preds $=$ np.empty((X.shape[0],len(self.trees))) # for i, tree in enumerate(self.trees): # idx $=$ tree.feature Indices # prediction $=$ tree.predict(X[:，idx]) y_preds[:，i] $=$ prediction y_pred $=$ [] # for samplepredictions in y_preds: y_pred.append(np.bincount(samplepredictions. astype('int')).argmax()) return y_pred   
def score(self,X,y): y_pred $=$ self.predict(X) accuracy $=$ np.sum(y $= =$ y_pred, axis $\coloneqq 0$ ) / len(y) return accuracy

[18]:

```python
column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']
data = pd.read_csv('./data/cancer/breast-cancer-wisconsin.data', names=column_names)
data = data.replace(to_replace='?'', value=np.nan) # 
data = data.dropna(how='any') # any
print(data.shape)
# 25%
75%
X_train, X_test, y_train, y_test = train_test_split(data column_names[1:10]), data column_names[10]), test_size=0.25, random_state=1111)
#
print(y_train.value_counts())
# 0 1
print(y_train.shape)
y_train[y_train==2] = 0
y_train[y_train==4] = 1
y_test[y_test==2] = 0
y_test[y_test==4] = 1
#
print(y_train.value_counts())
# 0 1
ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.transform(X_test) 
```

```python
y_train = y_train.as_matrix()  
y_test = y_test.as_matrix() 
```

(683, 11)

2 328

4 184

Name: Class, dtype: int64

(512,)

0 328

1 184

Name: Class, dtype: int64

```python
[19]: model = Bagging(n_estimators=20)  
model.fit(X_train, y_train)  
print(model.score(X_test, y_test)) 
```

Training: $100\%$ [-] Time: 0:00:04

```markdown
0.9473684210526315 
```

用 sklearn 的 Bagging，乳腺癌数据集测试

```python
[20]: from sklearnensemble import BaggingClassifier  
from sklearn import tree  
model = BaggingClassifier-tree.DecisionTreeNodeClassifier(random_state=1))  
model.fit(X_train, y_train)  
model.score(X_test, y_test) 
```

[20]: 0.9473684210526315

用自定义的随机森林，乳腺癌数据集测试

```python
[21]: model = RandomForest(n_estimators=20)  
model.fit(X_train, y_train)  
print(model.score(X_test, y_test)) 
```

Training: $100\%$ [ ] Time: 0:00:01

```markdown
0.9649122807017544 
```

用 sklearn 的随机森林，乳腺癌数据集测试

[22]: from sklearnensemble import RandomForestClassifier model $=$ RandomForestClassifier(random_state $\equiv 1$ ) model.fit(X_train，y_train) model.score(X_test,y_test)

[22]: 0.9415204678362573

# 4.4 Dropout

Dropout 的原理为：在每个迭代过程中，随机选择某些神经元，并且删除它们在⽹络中的前向和后向连接，相当于是 “去掉” 这些神经元。如图 5所⽰，在每批样本训练时，将原始⽹络中部分隐藏层单元 “去掉”。当然，Dropout 并不意味着这些神经元永远的消失了，在下⼀批数据迭代前，我们会把⽹络恢复成最初的全连接⽹络，然后再⽤随机的⽅法去掉部分隐藏层的神经元，接着去迭代更新 W, b。Dropout 思想可以理解为每次训练时放弃部分神经元对剩下的神经元加重训练，使剩下的神经元具有更强的能⼒。

每个迭代过程都会有不同的神经元节点的组合，从⽽导致不同的输出。这可以看成机器学习中的集成⽅法 (Ensemble Technique)。集成模型⼀般优于单⼀模型，因为它们可以捕获更多的随机性；相似地，Dropout 使得神经⽹络模型优于正常的模型。

![](images/006975a55183498bb22633e259b9f52e416697ddcb10caabd5ea3ceae7f605d0.jpg)  
图 5. Dropout ⽰意图，此处 $p$ 为 0.5，训练阶段随机“去掉”⼀半神经元。

# Dropout 的实现步骤：

• 每次加载⼩批量样本，然后随机采样⼆值掩码，对于每个单元，掩码是独⽴采样的。(将一些单元的输出乘零就能有效的删除一个单元)；  
• 传统的 Dropout，在训练阶段，⽤了 Dropout 的层，每个神经元以 $p$ 的概率保留（或以 $1 - p$ 的概率关闭），然后在测试阶段，不执⾏ Dropout，也就是所有神经元都不关闭，但是对训练阶段应⽤了 Dropout 的层上的神经元，为保证强度⼀致其输出激活值要乘以 $p _ { \mathfrak { c } }$ 。原理：为保证训练阶段与测试阶段强度一致，预测时对于每个隐层的输出，都乘以概率 $p$ 。可以从数学期望的⾓度去理解，我们考虑⼀个神经元的输出为 $x$ (没有 Dropout 的情况下)，则它输出的数学期望为 $p x + ( 1 - p ) 0$ ，于是在测试阶段，我们直接把每个输出 $x$ 都变换为 $p x$ ，是可以保持⼀样的数学期望。⽽现在我们在训练阶段应⽤ Dropout 时并没有让神经元 $a$ 的输出激活值除以 $p$ ，因此其期望值为 $p a$ ，在测试阶段如果不⽤ Dropout，所有神经元都保留，则输出期望值为 $x$ ，为了让测试阶段神经元的输出期望值和训练阶段保持⼀致 (这样才能正确评估训练出的模型)，就要给测试阶段的输出激活值乘上 $p$ ，使其输出期望值保持为 $p x$ ；  
• 现在主流的⽅法是 Inverted Dropout，和传统的 Dropout ⽅法有两点不同：在训练阶段，对执⾏了 Dropout 操作的层，其输出激活值要除以p；测试阶段则不执⾏任何操作，既不执⾏ Dropout，也不⽤对神经元的输出乘 $p _ { \circ }$ 。  
• 其余部分，与之前⼀样，运⾏前向传播、反向传播和学习更新。

Dropout 不仅可以应⽤在隐含层，也可以应⽤在输⼊层。选择保留多少单元的概率值 $p$ 是⼀个超参数。通常输⼊单元被保留的概率为 0.8，隐藏单元被保留的概率为 0.5。

# Dropout 优点：

• 计算⽅便，训练过程中使⽤ Dropout 产⽣ $n$ 个 (神经单元数⽬) 随机⼆进制数与状态相乘即可。  
• 适⽤⼴ (⼏乎在所有使⽤分布式表⽰且可以⽤随机梯度下降训练的模型上都表现很好，如前馈神经⽹络、概率模型、受限波尔兹曼机、循环神经⽹络等)。  
• 相⽐其他正则化⽅法 (如权重衰减、过滤器约束和稀疏激活) 更有效，也可与其他形式的正则化合并，得到进⼀步提升。

# Dropout 缺点：

• 不适合宽度太窄的⽹络，否则⼤部分⽹络没有输⼊到输出的路径。  
• 不适合训练数据太⼩（如⼩于 5000）的⽹络，训练数据太⼩时，Dropout 没有其他⽅法表现好。  
• 不适合⾮常⼤的数据集，数据集⼤的时候正则化效果有限 (⼤数据集本⾝的泛化误差就很⼩)，使⽤ Dropout 的代价可能超过正则化的好处。

# Dropout 与 Bagging 的比较

Dropout 模型中的参数 W，b 是共享的，Dropout 下⽹络迭代时，更新的是同⼀组 $W$ ，b ；⽽ Bagging 正则化中每个模型有⾃⼰的⼀套参数，相互之间是独⽴的。当然两种策略都是每次使⽤基于原始数据集得到的分批的数据集来训练模型。

[23]: class Dropout(ABC):

```python
def __init__(self, wrapped_layer, p):
    __________
    wrapped_layer dropout
    p
    __________
    super().__init__()
    self._base_layer = wrapped_layer
    self.p = p
    self._initRIApper_parameters()
def __initRIApper_parameters(self):
    self._wrapper Derived_variables = {"dropout_mask": None}
    self._wrapper_Hyperparameters = {"wrapper": "Dropout", "p": self.p} 
```

```python
def flush_gradients(self):
    base_layer
    self._base_layer.flush_gradients()
def update(self):
    base_layer
    self._base_layer.update()
def forward(self, X, is_train=True):
    X
    is_train bool
    mask = np.ones(X.shape).astype(bool)
if is_train:
    mask = (np.random.randint(*X.shape) < self.p) / self.p
    X = mask * X
self._wrapper Derived_variables["dropout_mask"] = mask
return self._base_layer.forward(X)
def backward(self, dLda):
    return self._base_layer逆转(dLda)
@property
def hyperparams(self):
    hp = self._base_layerhyperparams
hpw = self._wrapper_hyperparams
if "wrappers" in hp:
    hp["wrappers"].append(hpw)
else:
    hp["wrappers"] = [hpw]
return hp 
```

[24]: def minibatch(X, batchsize=256, shuffle=True):   
```python
>>> batch mini batch
>>> N = X.shape[0]
idx = np.arange(N)
n_batches = int(np.ceil(N / batchsize))
if shuffle:
    np.random.shuffle(idx)
def mb_generation():
    for i in range(n_batches):
        yield idx[i * batchsize : (i + 1) * batchsize]
return mb_generation(), n_batches
class DFN(object):
    def __init__(self, hidden_dims_1=None, hidden_dims_2=None, optimizer="sgd(lr=0.01") 
```

```python
init_w="std_normal",  
p=1.0,  
loss=CrossEntropy()  
):  
    selfOptimizer = optimizer  
    self.init_w = init_w  
    self.loss = loss  
    self.p = p  
    self-hidden_dims_1 = hidden_dims_1  
    self-hidden_dims_2 = hidden_dims_2  
    self.is Initialized = False  
def_set.params(self):  
    '''  
    FC1 -> Sigmoid -> FC2 -> Softmax  
    '''  
self.layers = OrderedDict()  
self.layers["FC1"] = Dropout( # dropoutFullyConnected(n_out=softhidden_dims_1, 
acti_fn="sigmoid", 
init_w=soft.init_w, 
optimizer=soft optimerizer), 
self.p)  
self.layers["FC2"] = FullyConnected(n_out=softhidden_dims_2, 
acti_fn="affine(slope=1, intercept=0)", 
init_w=soft.init_w, 
optimizer=soft optimerizer)  
self.is Initialized = True  
def forward(self, X_train, is_train=True):  
Xs = {}.  
out = X_train  
for k, v in self.layers.items():  
Xs[k] = out  
try: # dropout  
out = v.forward(out, is_train=is_train)  
except:  
out = v.forward(out)  
return out, Xs  
def backward(self, grad):  
dXs = {}.  
out = grad  
for k, v in reversed(list(self.layers.items()))):  
dXs[k] = out  
out = v.Backward(out)  
return out, dXs  
def update(self):  
'''  
'''  
for k, v in reversed(list(self.layers.items()))):  
v.update() 
```

```python
def flush_gradients(self, curr_loss=None):
    def flush_gradients(self, curr_loss=None):
        def flush_gradients(self, curr_loss=None):
            def flush_gradients(self, curr_loss=None):
                def flush_gradients(self, curr_loss=None):
                    def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                                def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                        def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush_gradients(self, curr_loss=None):
                            def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def flush NOI = None:
                                def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = None:
                                    def wash = none
                     def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def flush NOI = None:
                        def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = None:
                             def wash = none
                     def flush NOI = None:
                        def flush NOI = none
                        def flush NOI = none
                        def flush NOI = none
                        def flush NOI = none
                        def flush NOI = none
                        def flush NOI = none
                        def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush NOI = none
                       def flush TYPE=0
                       def flush TYPE=1
                       def flush TYPE=2
                       def flush TYPE=3
                       def flush TYPE=4)
                    self.train Generator,
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000
                    self.train size=1000 
```

```python
def hyperparams(self):
    return {
        "init_w": self.init_w,
        "loss": str(self.loss),
        "optimizer": selfOptimizer,
        "hidden_dims_1": self-hidden_dims_1,
        "hidden_dims_2": self-hidden_dims_2,
        "dropout keep ratio": self.p,
        "components": {k: v.hyperparams for k, v in self.layers.items()} 
```

[25]:

```python
```
dropout
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, p=0.5)
model.fit(X_train, y_train, n_epochs=20, batch_size=64) 
```

```txt
[Epoch 1] Avg. loss: 2.286 Delta: inf (0.02m/epoch)  
[Epoch 2] Avg. loss: 2.215 Delta: 0.071 (0.02m/epoch)  
[Epoch 3] Avg. loss: 2.017 Delta: 0.198 (0.02m/epoch)  
[Epoch 4] Avg. loss: 1.681 Delta: 0.335 (0.02m/epoch)  
[Epoch 5] Avg. loss: 1.356 Delta: 0.326 (0.02m/epoch)  
[Epoch 6] Avg. loss: 1.124 Delta: 0.231 (0.02m/epoch)  
[Epoch 7] Avg. loss: 0.965 Delta: 0.160 (0.02m/epoch)  
[Epoch 8] Avg. loss: 0.851 Delta: 0.114 (0.02m/epoch)  
[Epoch 9] Avg. loss: 0.779 Delta: 0.072 (0.02m/epoch)  
[Epoch 10] Avg. loss: 0.718 Delta: 0.061 (0.02m/epoch)  
[Epoch 11] Avg. loss: 0.677 Delta: 0.041 (0.02m/epoch)  
[Epoch 12] Avg. loss: 0.643 Delta: 0.034 (0.02m/epoch)  
[Epoch 13] Avg. loss: 0.615 Delta: 0.027 (0.02m/epoch)  
[Epoch 14] Avg. loss: 0.591 Delta: 0.024 (0.02m/epoch)  
[Epoch 15] Avg. loss: 0.573 Delta: 0.018 (0.02m/epoch)  
[Epoch 16] Avg. loss: 0.554 Delta: 0.020 (0.02m/epoch)  
[Epoch 17] Avg. loss: 0.541 Delta: 0.013 (0.02m/epoch)  
[Epoch 18] Avg. loss: 0.530 Delta: 0.011 (0.02m/epoch)  
[Epoch 19] Avg. loss: 0.525 Delta: 0.005 (0.02m/epoch)  
[Epoch 20] Avg. loss: 0.516 Delta: 0.009 (0.02m/epoch) 
```

[2

```javascript
[6]: print("accuracy:{}".format(model.evaluate(X_test, y_test))) 
```

```txt
accuracy:0.8889 
```

# 5 样本测试

在正则化背景下，通过对抗训练可以减少原有独⽴同分布的测试集的错误率——在对抗扰动的训练集样本上训练⽹络。

主要原因之⼀是⾼度线性，神经⽹络主要是基于线性模块构建的。输⼊改变 ϵ ，则权重为 $\pmb { w }$ 的线性函数将改变 $\epsilon \lVert \mathbf { \boldsymbol { w } } \rVert _ { 1 }$ ，对于⾼维的 $\textbf { \em w }$ 这是⼀个⾮常⼤的数。对抗训练通过⿎励⽹络在训练数据附近的局部区域恒定来限制这⼀个⾼度敏感的局部线性⾏为。

# 6 补充材料

# 6.1 Boosting

在前⾯介绍的 Bagging ⽅法中，主要通过对训练数据集进行随机采样，以重新组合成不同的数据集，利⽤弱学习算法对不同的新数据集进⾏学习，得到⼀系列的预测结果，对这些预测结果做平均或者投票得到最终的预测。

⽽ Boosting ⽅法的主要⽬标是将弱分类器 “提升” 为强分类器，根据前⼀个弱分类器的训练效果对样本分布进⾏调整，再根据新的样本分布训练下⼀个弱分类器，如此迭代，最后将⼀系列弱分类器组合成⼀个强分类器。

![](images/fb0194920bfb2cc4b389843e48645de8cf9197c86218eb7054cb59bdd21b799a.jpg)  
图 6. Boosting ⽅法⽰意图。

这⾥便存在⼏个问题：弱分类器选什么？如何调整样本分布？如何进⾏组合？针对这三个问题的不同回答就可以得到不同的 Boosting ⽅法。不过在具体介绍各种 Boosting ⽅法，我们需要先介绍前向分步加法模型。

# 6.1.1 前向分步加法模型

⾸先是加法模型 (Addtive Model)：

$$
f (x) = \sum_ {k = 1} ^ {K} \beta_ {k} \cdot b (\boldsymbol {x}; \gamma_ {k}) \tag {28}
$$

其中 $b ( \pmb { x } ; \gamma _ { k } )$ 是基函数， $\gamma _ { k }$ 是基函数的参数， $\beta _ { k }$ 是基函数的系数。

前向分步算法 (Forward Stagewise Algorithm)

在给定训练数据和损失函数 $\mathcal { L } ( y , f ( \pmb { x } ) )$ 的情况下，学习加法模型 $f ( { \pmb x } )$ 成为经验风险最⼩化即损失函数最⼩化的问题：

$$
\min  _ {\beta_ {k}, \gamma_ {k}} \sum_ {i = 1} ^ {m} \mathcal {L} \left(y ^ {(i)}, \sum_ {k = 1} ^ {K} \beta_ {k} \cdot b \left(\boldsymbol {x} ^ {(i)}; \gamma_ {k}\right)\right) \tag {29}
$$

通常这是⼀个复杂的优化问题。前向分步算法求解这⼀优化问题的思路是：因为学习的是加法模型，如果能够从前向后，每⼀步只学习⼀个基函数及其系数，逐步逼近优化⽬标函数式，那么就可以简化优化的复杂度。具体地，每步只需优化如下损失函数：

$$
\min  _ {\beta , \gamma} \sum_ {i = 1} ^ {M} \mathcal {L} \left(y ^ {(i)}, \beta \cdot b \left(\boldsymbol {x} ^ {(i)}; \gamma\right)\right) \tag {30}
$$

给定训练数据 $D = \{ ( \pmb { x } ^ { ( 1 ) } , y ^ { ( 1 ) } ) , \cdots , ( \pmb { x } ^ { ( m ) } , y ^ { ( m ) } ) \} , \pmb { x } ^ { ( i ) } \in \mathbb { R } ^ { n } , y ^ { ( i ) } \in \{ - 1 , + 1 \}$ ，损失函数 $\mathcal { L } ( y , f ( \pmb { x } ) )$ 和基函数集 $\{ b ( { \pmb x } ; \gamma ) \}$ 。前向分步算法的步骤如下：

1. 初始化 $f _ { 0 } ( { \pmb x } ) = 0 _ { \circ }$ 。  
2. 极⼩化损失函数 $\begin{array} { r } { ( \beta _ { k } , \gamma _ { k } ) = \arg \operatorname* { m i n } _ { \beta , \gamma } \sum _ { i = 1 } ^ { m } \mathcal { L } ( y ^ { ( i ) } , f _ { k - 1 } ( { \pmb x } ^ { ( i ) } ) + \beta \cdot b ( { \pmb x } ; \gamma ) ) } \end{array}$ 得到参数 $\beta _ { k }$ 和 $\gamma _ { k }$   
3. 更新 $f _ { k } ( { \pmb x } ) = f _ { k - 1 } ( { \pmb x } ) + \beta _ { k } \cdot b ( { \pmb x } ; \gamma _ { k } ) \circ$ 。  
4. 重复步骤 2-3， $k = 1 , 2 , \cdots , K _ { \circ }$ 。  
5. 得到加法模型 $\begin{array} { r } { f ( x ) = f _ { K } ( x ) = \sum _ { k = 1 } ^ { K } \beta _ { k } b ( x ; \gamma _ { k } ) \circ } \end{array}$

这样，前向分步算法将同时求解从 $k = 1$ 到 $K$ 的所有参数 $\beta _ { k } , \gamma _ { k }$ 的优化问题简化为逐次求解各个 $\beta _ { k } , \gamma _ { k }$ 的优化问题。

# 6.1.2 AdaBoost 算法

回到三个问题，AdaBoost 的解决⽅案是什么？

• 弱分类器 (基分类器) 选什么？⼀般选法是决策树桩 (就是只有⼀层的决策树)。  
• 如何调整样本分布？可以先赋予每个训练样本相同的权重；然后⽤弱分类器进⾏训练，每次训练后，对分类错误的样本加⼤权重 (重采样，具体做法后⾯再述)，使得在下⼀次的迭代中更加关注这些样本，如图 6 所⽰。  
• 如何进⾏组合？组合⽅式即为加法模型 $f ( { \pmb x } ) = s g n \left( \sum _ { k = 1 } ^ { K } \alpha _ { k } h _ { k } ( { \pmb x } ) \right) { \mathrm { { c } } }$ 。其中 AdaBoost 的损失函数为指数损失 $\begin{array} { r } { \mathcal { L } ( y , f ( \pmb { x } ) ) = \exp ( - y f ( \pmb { x } ) ) \mathrm { ~ } _ { \mathrm { ~ } } } \end{array}$

# 下面先分析为什么选择指数损失作为损失函数

假设 $f ( { \pmb x } )$ 能使损失达到最⼩，对其求偏导：

$$
\frac {\partial \exp (- y f (\boldsymbol {x}))}{\partial f (\boldsymbol {x})} = - \exp (- f (\boldsymbol {x})) P (y = 1 | \boldsymbol {x}) + \exp (f (\boldsymbol {x})) P (y = - 1 | \boldsymbol {x}) \tag {31}
$$

然后我们令导数为 0，可以求得：

$$
f (\boldsymbol {x}) = \frac {1}{2} \ln \frac {P (y = 1 \mid \boldsymbol {x})}{P (y = - 1 \mid \boldsymbol {x})} \tag {32}
$$

接下来我们可以得到输出：

$$
\begin{array}{l} \operatorname {s g n} (f (\boldsymbol {x})) = \operatorname {s g n} \left(\frac {1}{2} \ln \frac {P (y = 1 \mid \boldsymbol {x})}{P (y = - 1 \mid \boldsymbol {x})}\right) \tag {33} \\ = \left\{ \begin{array}{l} 1, P (y = 1 \mid x) > P (y = - 1 \mid x) \\ - 1, P (y = 1 \mid x) <   P (y = - 1 \mid x) \end{array} \right. \\ \end{array}
$$

这意味着 $s g n ( f ( { \pmb x } ) )$ 达到了贝叶斯最优错误率。换⾔之，如果指数损失函数最⼩化，则分类错误率也将最⼩化。这说明指数损失函数是分类任务 0-1损失函数的⼀致性替代函数。由于这个替代函数是单调连续可微函数，因此⽤它代替 0-1 损失函数作为优化⽬标。

# 基分类器权重 $\alpha$ 的更新

回到迭代过程，第⼀个基分类器 $h _ { 1 }$ 是通过直接将基学习算法⽤于初始训练数据 (初始数据分布) $D _ { 1 }$ ⽽得；此后迭代地⽣成 $h _ { k }$ 和 $\alpha _ { k }$ 。当基分类器$h _ { k }$ 基于分布 $D _ { k }$ 产⽣后，该基分类器的权重 $\alpha _ { k }$ 应当使得 $\alpha _ { k } C _ { k }$ 最⼩化指数损失函数

$$
\begin{array}{l} \min  _ {\alpha_ {k}} \mathcal {L} (y, f _ {k - 1} (\boldsymbol {x}) + \alpha_ {k} \cdot h _ {k} (\boldsymbol {x})) = \min  _ {\alpha_ {k}} \mathbb {E} _ {\boldsymbol {x} \sim D _ {k}} [ \exp (- y (f _ {k - 1} (\boldsymbol {x}) + \alpha_ {k} \cdot h _ {k} (\boldsymbol {x}))) ] \\ = \min  _ {\alpha_ {k}} \mathbb {E} _ {\boldsymbol {x} \sim D _ {k}} [ \exp (- y (\alpha_ {k} \cdot h _ {k} (\boldsymbol {x}))) ] \tag {34} \\ = \exp (- \alpha_ {k}) P _ {\boldsymbol {x} \sim D _ {k}} (y = h _ {k} (\boldsymbol {x})) + \exp (\alpha_ {k}) P _ {\boldsymbol {x} \sim D _ {k}} (y \neq h _ {k} (\boldsymbol {x})) \\ = \exp (- \alpha_ {k}) (1 - \varepsilon_ {k}) + \exp (\alpha_ {k}) \varepsilon_ {k} \\ \end{array}
$$

其中， $\varepsilon _ { k } = P _ { x \sim D _ { k } } ( h _ { k } ( \pmb { x } ) \neq y )$ ，表⽰错误率。我们接下来对该式求导，可以得到：

$$
\frac {\partial \mathcal {L} \left(y , f _ {k - 1} (\boldsymbol {x}) + \alpha_ {k} \cdot h _ {k} (\boldsymbol {x})\right)}{\partial \alpha_ {k}} = - \exp \left(- \alpha_ {k}\right) \left(1 - \varepsilon_ {k}\right) + \exp \left(\alpha_ {k}\right) \varepsilon_ {k} \tag {35}
$$

令导数为 0，有：

$$
\alpha_ {k} = \frac {1}{2} \ln \left(\frac {1 - \varepsilon_ {k}}{\varepsilon_ {k}}\right) \tag {36}
$$

这样我们便得到了在每次迭代，训练完基分类器后，加法模型中基函数的系数。

# 样本分布的更新与迭代过程中训练样本的生成

现在回到第⼆个问题的解答，我们如何调整样本分布。

在获得 $f _ { k - 1 }$ 之后样本的分布将进⾏调整，使下⼀轮基分类器 $h _ { k }$ 能纠正 $f _ { k - 1 }$ 的⼀些错误。理想的 $h _ { k }$ 能纠正 $f _ { k - 1 }$ 的全部错误，即最⼩化：

$$
\begin{array}{l} \mathcal {L} \left(y, f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})\right) = \mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \exp \left(- y f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})\right) \right] \tag {37} \\ = \mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k - 1} (\boldsymbol {x})) \exp (- y h _ {k} (\boldsymbol {x})) ] \\ \end{array}
$$

注意 $y ^ { 2 } = h _ { k } ^ { 2 } ( \pmb { x } ) = 1$ (因为输出为 1 或 -1)，上式可将 $\exp { ( - y h _ { k } ( { \pmb x } ) ) }$ ) 泰勒展开：

$$
\begin{array}{l} \mathcal {L} \left(y, f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})\right) \simeq \mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \exp \left(- y f _ {k - 1} (\boldsymbol {x})\right) \left(1 - y h _ {k} (\boldsymbol {x}) + \frac {y ^ {2} h _ {k} ^ {2} (\boldsymbol {x})}{2}\right) \right] \tag {38} \\ = \mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k - 1} (\boldsymbol {x})) (1 - f (x) h _ {t} (x) + \frac {1}{2}) ] \\ \end{array}
$$

于是，理想的基分类器应满⾜：

$$
\begin{array}{l} h _ {k} (\boldsymbol {x}) = \underset {h} {\arg \min } \mathcal {L} (y, f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})) \\ = \underset {h} {\arg \min } \mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k - 1} (\boldsymbol {x})) y h _ {k} (\boldsymbol {x}) ] \tag {39} \\ = \arg \min  _ {h} \mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \frac {\left(- y f _ {k - 1} (\boldsymbol {x})\right)}{\mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \exp \left(- y f _ {k - 1} (\boldsymbol {x})\right) \right]} y h _ {k} (\boldsymbol {x}) \right] \\ \end{array}
$$

这⾥的 $\mathbb { E } _ { { \pmb { x } } \sim D } [ \exp \left( - y f _ { k - 1 } ( { \pmb { x } } ) \right) ]$ 表⽰⼀个常数。令 $D _ { k }$ 表⽰⼀个分布：

$$
D _ {k} (\boldsymbol {x}) = \frac {\exp (- y f _ {k - 1} (\boldsymbol {x}))}{\mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k - 1} (\boldsymbol {x})) ]} D (\boldsymbol {x}) \tag {40}
$$

因为根据数学期望的定义，这⾥等价于令：

$$
\begin{array}{l} h _ {k} (\boldsymbol {x}) = \underset {h} {\arg \min } \mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \frac {\exp (- y f _ {k - 1} (\boldsymbol {x}))}{\mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k - 1} (\boldsymbol {x})) ]} y h _ {k} (\boldsymbol {x}) \right] \tag {41} \\ = \operatorname * {a r g   m i n} _ {h} \mathbb {E} _ {\boldsymbol {x} \sim D _ {k}} [ y G _ {k} (\boldsymbol {x}) ] \\ \end{array}
$$

由于 $y , h _ { k } \in \{ + 1 , - 1 \}$ ，所以有： $y h _ { k } = 1 - 2 I \left( y \neq h _ { k } \left( \pmb { x } \right) \right) \mathrm { , }$ 。

则理想的基分类器：

$$
h _ {k} (\boldsymbol {x}) = \underset {h} {\arg \min } \mathbb {E} _ {\boldsymbol {x} \sim D _ {k}} [ I (y \neq h _ {k} (\boldsymbol {x})) ] \tag {42}
$$

可见，理想的 $h _ { k } \left( \pmb { x } \right)$ 在分布 $D _ { k }$ 下最⼩化分类误差。因此，基分类器将基于分布 $D _ { k }$ 来训练，且针对 $D _ { k }$ 的分类误差应当⼩于 0.5。考虑到 $D _ { k }$ 和$D _ { k + 1 }$ 的关系有：

$$
\begin{array}{l} D _ {k + 1} \left(\boldsymbol {x}\right) = \frac {\exp \left(- y f _ {k} (\boldsymbol {x})\right)}{\mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \exp \left(- y f _ {k} (\boldsymbol {x})\right) \right]} D \left(\boldsymbol {x}\right) \\ = D (\boldsymbol {x}) \exp (- y f _ {k - 1} (\boldsymbol {x})) \frac {\exp (- y \alpha_ {k} \cdot h _ {k} (\boldsymbol {x}))}{\mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp (- y f _ {k} (\boldsymbol {x})) ]} \\ = D _ {k} (\boldsymbol {x}) \frac {\exp \left(- y \alpha_ {k} \cdot h _ {k} (\boldsymbol {x})\right) \mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp \left(- y f _ {k - 1} (\boldsymbol {x})\right) ]}{\mathbb {E} _ {\boldsymbol {x} \sim D} [ \exp \left(- y f _ {k} (\boldsymbol {x})\right) ]} \tag {43} \\ = \frac {D _ {k} (\boldsymbol {x}) \exp (- y \alpha_ {k} \cdot h _ {k} (\boldsymbol {x}))}{\mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \frac {- y f _ {k - 1} - y \alpha_ {k} h _ {k}}{\mathbb {E} _ {\boldsymbol {x} \sim D} \left[ \exp (- y f _ {k - 1} (\boldsymbol {x})) \right]} \right]} \\ = \frac {D _ {k} (\pmb {x}) \exp \left(- y \alpha_ {k} \cdot h _ {k} (\pmb {x})\right)}{\mathbb {E} _ {\pmb {x} \sim D} [ D _ {k} (\pmb {x}) \exp \left(- y \alpha_ {k} \cdot h _ {k} (\pmb {x})\right) ]} \\ \end{array}
$$

于是，我们便得到了样本分布的迭代更新公式。

# 自定义实现

[27]: # bar widgets = [ 'Training: ', progressbar%.Percentage(), ' ', progressbar.Barmarker $= \text{"} -\text{"}$ , left $= \text{"} \left[ \begin{array}{l l} \end{array} \right]$ ), ' ', progressbar.ETA() ]

[28]: # Adaboost (  )   
class DecisionStump(): def __init__(self): self.polarity $= 1$ # 1 -1 self.feature_index $\equiv$ None # self.threshold $=$ None # self.alpha $=$ None #   
class Adaboost(): "" Adaboost """ def __init__(self, n_estimators=5): self.n_estimators $\equiv$ n_estimators # selfProgressbar $=$ progressbarprogressbar。（widgetst=bar widgets) def fit(self, X, y): n_samples, n_features $\equiv$ np.shape(X) # (D) 1/N w = np.full(n_samples, (1 / n_samples)) self.trees $=$ [] # for _ in selfProgressbar(range(self.n_estimators)): tree $=$ DecisionStump() min_error $=$ float('inf') # # ( ) y for feature_i in range(n_features): feature_values $=$ np-expand_dims(X(:, feature_i], axis=1) unique_values $=$ np.unique feature_values) # for threshold in unique_values: p $= 1$ # 1 prediction $=$ np.ones(np.shape(y)) # -1 prediction[X(:, feature_i] < threshold] $= -1$ # error $=$ sum(w[y != prediction]) # 50%

# error $= 0.8\Rightarrow$ (1 - error) $= 0.2$ # 1 1 0 if error $>0.5$ .. error $= 1$ - error $\mathfrak{p} = -1$ # if error $<$ min_error: tree.polarity $=$ p treethreshold $=$ threshold tree.feature_index $=$ feature_i min_error $=$ error # alpha tree.alpha $= 0.5$ * math.log((1.0-min_error)/(min_error+1e-10)) # 1 predictions $=$ np.ones(np.shape(y)) # negativeidx $=$ (tree.polarity \* X[:, tree.feature_index] $<$ tree.polarity \* tree.threshold) predictions[negative IDX] $= -1$ # w $^{**}$ np.exp(-tree.alpha \* y \* predictions) w/=np.sum(w) # self.trees.append(tree)   
def predict(self,X): n_samples $=$ np.shape(X)[0] y_pred $=$ np.zeros((n_samples，1)) # for tree in self.trees: # 1 predictions $=$ np.ones(np.shape(y_pred)) negativeidx $=$ (tree.polarity \* X[:, tree.feature_index] $<$ tree.polarity \* tree.threshold) predictions[negative IDX] $= -1$ # alpha y_pred $+=$ tree.alpha \* predictions # 1 -1 y_pred $=$ np.sign(y_pred). flatten() return y_pred   
def score(self,X,y): y_pred $=$ self.predict(X) accuracy $=$ np.sum(y $= =$ y_pred, axis=0)/len(y) return accuracy

用自定义的 Adaboost，乳腺癌数据集测试  
```python
[29]: column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class'] data = pd.read_csv('./data/cancer/breast-cancer-wisconsin.data', names=column_names) data = data.replace(to_replace='?', value=np.nan) # data = data.dropna(how='any') # any print(data.shape) # 25% 75% X_train, X_test, y_train, y_test = train_test_split(data[column_names[1:10]], data[col_names[10]], test_size=0.25, random_state=1111) # print(y_train.value_counts()) 
```

print(y_train.shape)   
y_train[y_train $= = 2$ ] $= -1$ y_train[y_train $= = 4$ ] $= 1$ y_test[y_test $= = 2$ ] $= -1$ y_test[y_test $= = 4$ ] $= 1$ #   
print(y_train.value_counts())   
#   
ss $\equiv$ StandardScaler()   
X_train $\equiv$ ss.fit_transform(X_train)   
X_test $\equiv$ ss.transform(X_test)   
y_train $\equiv$ y_train.as_matrix()   
y_test $\equiv$ y_test.as_matrix()

(683, 11)

2 328

4 184

Name: Class, dtype: int64

(512,)

-1 328

1 184

Name: Class, dtype: int64

```python
[30]: model = Adaboost(n_estimators=20)  
model.fit(X_train, y_train)  
print(model.score(X_test, y_test)) 
```

Training: 100% [--- ---] Time: 0:00:00

0.935672514619883

# 用 sklearn 的 Adaboost，乳腺癌数据集测试

```python
[31]: from sklearnensemble import AdaBoostClassifier  
skl_model = AdaBoostClassifier()  
skl_model.fit(X_train, y_train)  
print(skl_model.score(X_test, y_test)) 
```

0.9532163742690059

# 6.1.3 GBDT 算法

# Boosting Tree 算法

回到三个问题，Boosting Tree 的解决⽅案是什么？

• 弱分类器 (基分类器) 选什么？选法是回归树 ( CART，见第五章)。  
• 如何调整样本分布？样本不做修改，但每⼀次迭代的样本标签为真实结果和当前模型预测结果的残差。  
• 如何进⾏组合？组合⽅式即为加法模型 $f ( \pmb { x } ) = \sum _ { k = 1 } ^ { K } h _ { k } ( \pmb { x } )$ ，其中基学习器的系数为 1。如果⽤于回归 GBDT 的损失函数为平⽅损失 (Squareloss) $\mathcal { L } ( y , f ( \pmb { x } ) ) = ( y - f ( \pmb { x } ) ) ^ { 2 }$ ，如果⽤于分类 GBDT 的损失函数为交叉熵 (Cross-entropy)。

# 同样分析损失函数的选择

我们先从回归问题来看，假设在第 $k$ 次迭代时我们已有的可加模型为 $f _ { k - 1 } ( { \pmb x } )$ 。那么在新⼀轮迭代中最好的学习⽬标什么？学习真实结果和当前模型预测结果的残差 (residuals) $r$ ：

$$
r (\boldsymbol {x}) = y - f (\boldsymbol {x}) \tag {44}
$$

我们构造新⼀轮迭代过程中的数据集 $D = \{ ( { \pmb x } ^ { ( 1 ) } , { \pmb y } ^ { ( 1 ) } - f ( { \pmb x } ^ { ( 1 ) } ) ) , \cdots , ( { \pmb x } ^ { ( m ) } , { \pmb y } ^ { ( m ) } - f ( { \pmb x } ^ { ( m ) } ) ) \} , { \pmb x } ^ { ( i ) } \in \mathbb { R } ^ { n } , { \pmb y } ^ { ( i ) } \in \mathbb { R } .$ 。经过新⼀轮迭代训练得到的基学

习器 $C _ { k } ( \pmb { x } )$ 如果是完美学习的，则等于当前的残差项 $r _ { k - 1 } ( \pmb { x } )$ 。这样⼀来，我们的可加模型就变为：

$$
\begin{array}{l} f _ {k} (\boldsymbol {x}) = f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x}) \\ = f _ {k - 1} (\boldsymbol {x}) + r _ {k - 1} (\boldsymbol {x}) \tag {45} \\ = y \\ \end{array}
$$

这样⼀来，我们就可以得到完美的可加模型。那为什么选择平⽅损失，但平⽅损失有个很⼤的问题，对离群点 (Outliers) 呢？⾸先，看⼀下在第 $k$ 次迭代时的损失函数 (优化⽬标)：

$$
\begin{array}{l} \mathcal {L} \left(y, f _ {k} (\boldsymbol {x})\right) = \left(y - f _ {k - 1} (\boldsymbol {x}) - h _ {k} (\boldsymbol {x})\right) ^ {2} \tag {46} \\ = \left(r _ {k - 1} (\boldsymbol {x}) - h _ {k} (\boldsymbol {x})\right) ^ {2} \\ \end{array}
$$

所以，对于回归问题来说，如果是在平⽅损失函数的前提下，每⼀步确实只需要拟合当前模型的残差就可以了。⾄于分类问题求解，后⾯会进⾏介绍。

# GBDT 算法

GBDT 是 Boosting Tree 的改进⽅法。回到三个问题，GBDT 的解决⽅案是什么？

• 弱分类器 (基分类器) 选什么？选法是回归树 ( CART)。  
• 如何调整样本分布？样本不做修改，但每⼀次迭代的样本标签为残差的负梯度。  
• 如何进⾏组合？组合⽅式即为加法模型 $f ( \pmb { x } ) = \sum _ { k = 1 } ^ { K } h _ { k } ( \pmb { x } )$ ，其中基学习器的系数为 1。如果⽤于回归 GBDT 的损失函数为平⽅损失 (Squareloss) ${ \mathcal { L } } ( y , f ( \pmb { x } ) ) \ = \ ( y - f ( \pmb { x } ) ) ^ { 2 }$ ，绝对损失 (Absolute loss)，Huber 损失 (Huber loss)。如果⽤于分类 GBDT 的损失函数为交叉熵(Cross-entropy)。

# 学习目标：残差的负梯度

先考虑第⼆个问题，残差的负梯度是什么？我们回到平⽅损失，假设在第 $k$ 次迭代时我们已有的可加模型为 $f _ { k - 1 } ( { \pmb x } )$ ，于是会有：

$$
\begin{array}{l} \frac {\partial \mathcal {L}}{\partial f _ {k - 1} (\boldsymbol {x})} = \frac {\partial (y - f _ {k - 1} (\boldsymbol {x})) ^ {2}}{\partial f _ {k - 1} (\boldsymbol {x})} \\ = - \left(y - f _ {k - 1} (\boldsymbol {x})\right) \tag {47} \\ = - r _ {k} (\boldsymbol {x}) \\ \end{array}
$$

所以，我们在 Boosting Tree 算法中要学习的⽬标残差就等于负的梯度 项 − ∂L∂f − (x)。所以我们可以考虑将学习⽬标从残差到残差的梯度项。但为 $- \frac { \partial \mathcal { L } } { \partial f _ { k - 1 } \left( \pmb { x } \right) }$ 什么要这么做？

现在，我们从泰勒展开的⾓度来分析。⾸先，回顾⼀阶泰勒展开公式：

$$
f (x) \approx f \left(x _ {0}\right) + f ^ {\prime} \left(x _ {0}\right) \Delta x \tag {48}
$$

我们可以将在第 $k$ 次迭代中已有的可加模型 $f _ { k - 1 } ( { \pmb x } )$ 视作 $x _ { 0 }$ ，将需要学习的基学习器 $h _ { k } ( { \pmb x } )$ 视作 $\Delta x$ 。那么我们的损失函数可以写作：

$$
\mathcal {L} \left(y, f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})\right) \approx \mathcal {L} \left(y, f _ {k - 1} (\boldsymbol {x})\right) + \frac {\partial \mathcal {L}}{\partial f _ {k - 1} (\boldsymbol {x})} h _ {k} (\boldsymbol {x}) \tag {49}
$$

⽽在第 $k - 1$ 次迭代后的损失为 $\mathcal { L } ( y , f _ { k - 1 } ( \pmb { x } ) )$ 。所以，经过第 $k$ 次迭代后，损失的变化为 $\frac { \partial \mathcal { L } } { \partial f _ { k - 1 } \left( \pmb { x } \right) } h _ { k } ( \pmb { x } )$ 。我们是希望损失越来越⼩的，⽽如果令$\begin{array} { r } { h _ { k } ( \pmb { x } ) = - \frac { \partial \mathcal { L } } { \partial f _ { k - 1 } \left( \pmb { x } \right) } } \end{array}$ ，则损失变化量为 $- ( \frac { \partial \mathcal { L } } { \partial f _ { k - 1 } ~ ( x ) } ) ^ { 2 }$ ，这样⼀定是使损失递减。也就是说损失会向着下降的⽅向移动，这也是梯度下降的思想。它和Boosting Tree 中使⽤的残差的区别在于，通过残差是在寻找全局最优值 (每⼀步都试图让结果达到最好)，⽽使⽤残差的梯度是在搜寻局部最优值(每⼀步都试图让结果更好⼀些)。既然如此，使⽤残差的梯度优势在哪？这就要考虑损失函数了。

# 损失函数的使用

在前⾯的描述中，我们对回归问题默认的损失函数是平⽅损失，但平⽅损失有个很⼤的问题，对异常点 (Outliers) 很是敏感。⽐如下⾯这个例⼦，可以看出最后⼀个样本 (异常点) 会在下⼀次迭代中占据主要影响，下⼀个基学习器会过多关注于最后⼀个的异常点。⽽ Boosting Tree 使⽤平⽅损失正是因为这个损失可以帮助获得残差，可如果换个对异常点鲁棒的损失函数呢？这个时候 Boosting Tree 就⽆计可施了。

<table><tr><td>y</td><td>0.5</td><td>1.2</td><td>2</td><td>5</td></tr><tr><td>f(x)</td><td>0.6</td><td>1.4</td><td>1.5</td><td>1.7</td></tr><tr><td>L=(y-f(x))2</td><td>0.005</td><td>0.02</td><td>0.125</td><td>5.445</td></tr></table>

但 GBDT 却可以做到。如果我们将损失函数换做绝对损失：

$$
\mathcal {L} (y, f (\boldsymbol {x})) = | y - f (\boldsymbol {x}) | \tag {50}
$$

其负梯度为： $\begin{array} { r } { - \frac { \partial \mathcal { L } } { \partial f ( \pmb { x } ) } = s g n ( y - f ( \pmb { x } ) ) \circ } \end{array}$

或者我们将其换做 Huber 损失：

$$
\mathcal {L} (y, f (\boldsymbol {x})) = \left\{ \begin{array}{c c} y - f (\boldsymbol {x}), & | y - f (\boldsymbol {x}) | \leq \delta \\ \delta s g n (y - f (\boldsymbol {x})), & | y - f (\boldsymbol {x}) | > \delta \end{array} \right. \tag {51}
$$

其负梯度为：- ∂L∂f(x) $\begin{array} { r } { - \frac { \partial \mathcal { L } } { \partial f ( \pmb { x } ) } = \left\{ \begin{array} { r l r } { \frac { 1 } { 2 } ( y - f ( \pmb { x } ) ) ^ { 2 } , } & { } & { | y - f ( \pmb { x } ) | \leq \delta } \\ { \delta ( | y - f ( \pmb { x } ) | - \frac { \delta } { 2 } ) , } & { } & { | y - f ( \pmb { x } ) | > \delta } \end{array} \right. } \end{array}$

我们可以看⼀下采⽤绝对损失和 Huber 损失时的⽰例：

<table><tr><td>y</td><td>0.5</td><td>1.2</td><td>2</td><td>5</td></tr><tr><td>f(x)</td><td>0.6</td><td>1.4</td><td>1.5</td><td>1.7</td></tr><tr><td>Square loss</td><td>0.005</td><td>0.02</td><td>0.125</td><td>5.445</td></tr><tr><td>Absolute loss</td><td>0.1</td><td>0.2</td><td>0.5</td><td>3.3</td></tr><tr><td>Huber loss(δ=0.5)</td><td>0.005</td><td>0.02</td><td>0.125</td><td>1.525</td></tr></table>

可以看到后两种损失对异常点要鲁棒些，当然使⽤这两种损失后梯度就不等于残差，但梯度仍可以作为⼀种近似。

# Shrinkage 收缩

Shrinkage 收缩指，每次⾛⼀⼩步逐渐逼近结果的效果，要⽐每次迈⼀⼤步很快逼近结果的⽅式更容易得到精确值。就是说它不完全信任每⼀棵残差树，认为每棵树只学到了真实的⼀部分，于是累加的时候只累加⼀⼩部分再多学⼏棵树来弥补不⾜。这个技巧类似于梯度下降⾥的学习率。

实现 Shrinkage 收缩的⼀种简略⽅法是固定每⼀个基学习器的步长 (学习率) $\eta \colon f _ { k } ( { \pmb x } ) = f _ { k - 1 } ( { \pmb x } ) + \eta h _ { k } ( { \pmb x } ) ,$ 。这个形式就回到了最初前向分步加法模型的描述，只是这⾥的基学习器的参数预先给定。

另⼀种⽅法是 Line Search，去寻找最优的步长：

$$
\eta = \arg \min  _ {\eta} \sum_ {i = 1} ^ {m} \mathcal {L} \left(y ^ {(i)}, f _ {k - 1} \left(\boldsymbol {x} ^ {(i)}\right) + \eta h _ {k} \left(\boldsymbol {x} ^ {(i)}\right)\right) \tag {52}
$$

当损失函数为平⽅误差时，显然有：

$$
\begin{array}{l} \eta = \arg \min  _ {\eta} \sum_ {i = 1 \atop m} ^ {m} \left(\left(y ^ {(i)} - f _ {k - 1} \left(\boldsymbol {x} ^ {(i)}\right)\right) - \eta h _ {k} \left(\boldsymbol {x} ^ {(i)}\right)\right) \tag {53} \\ = \underset {\eta} {\arg \min } \sum_ {i = 1} ^ {m} \left(- 2 \eta (y ^ {(i)} - f _ {k - 1} (\pmb {x} ^ {(i)})) + (\eta h _ {k} (\pmb {x} ^ {(i)})) ^ {2}\right) \\ \end{array}
$$

对其求导并令导数为 0，可以得到此时的最优 $\eta$ ：

$$
\eta^ {*} = \frac {\sum_ {i = 1} ^ {m} 2 \left(y ^ {(i)} - f _ {k - 1} \left(\boldsymbol {x} ^ {(i)}\right)\right) h _ {k} \left(\boldsymbol {x} ^ {(i)}\right)}{\sum_ {i = 1} ^ {m} h _ {k} ^ {2} \left(\boldsymbol {x} ^ {(i)}\right)} \tag {54}
$$

# 分类问题下的损失函数

以上我们讨论完了回归问题，现在我们讨论分类问题。⾸先是二分类问题，在第五章我们介绍过概率监督学习 (逻辑回归)，逻辑回归实质上是⽤线性模型去拟合对数⼏率 (log odds)， $\textstyle \log \left( { \frac { p } { 1 - p } } \right)$ 。如果说回归问题是⽤线性模型 (线性可加模型) 直接学习⽬标结果，那分类问题就是⽤线性模型 (线性可加模型) 去学习对数⼏率。所以，分类模型可以表达为：

$$
\hat {y} = P (y = 1 \mid \boldsymbol {x}) = \frac {1}{1 + e ^ {- \sum_ {k} h _ {k} (\boldsymbol {x})}} = \frac {1}{1 + e ^ {- f (\boldsymbol {x})}} \tag {55}
$$

其中 $\hat { y }$ 表⽰分类模型的预测。所以，损失函数就可以表达为交叉熵：

$$
\mathcal {L} (y, f (\boldsymbol {x})) = - y \log \hat {y} - (1 - y) \log (1 - \hat {y}) \tag {56}
$$

在第六章我们介绍过⼆分类交叉熵的求导，所以在这⾥我们有：

$$
- \frac {\partial \mathcal {L} (y , f (\boldsymbol {x}))}{\partial f (\boldsymbol {x})} = y - \hat {y} \tag {57}
$$

可以看到，与回归问题类似，下⼀棵决策树的训练样本为： $\{ ( { \pmb x } , y - \hat { y } ) \}$ ，其所需要拟合的残差为真实标签与预测概率之差。

再看⼀下多分类问题，假设⼀个有 $C$ 个类别，每⼀次迭代的训练实际上是训练了 $C$ 棵树去拟合每⼀个类别。如果⼀共再进⾏ $K$ 次迭代的话，那么训练完之后总共有 $C \times K$ 棵树。

$$
\begin{array}{l} \mathcal {L} (\boldsymbol {y}, f (\boldsymbol {x})) = - \boldsymbol {y} \log \hat {\boldsymbol {y}} \\ = - \sum_ {c = 1} ^ {C} y _ {c} \log \hat {y} _ {c} \tag {58} \\ \end{array}
$$

其中 $\begin{array} { r } { \hat { y } _ { c } = \frac { e ^ { - f ^ { c } ( \pmb { x } ) } } { \sum _ { l = 1 } ^ { C } e ^ { - f ^ { l } ( \pmb { x } ) } } } \end{array}$ −fc(x)e−fl(x)。同样在第六章我们介绍过多分类交叉熵的求导：

$$
- \frac {\partial \mathcal {L} (y , f ^ {c} (\boldsymbol {x}))}{\partial f ^ {c} (\boldsymbol {x})} = y _ {c} - \hat {y} _ {c} \tag {59}
$$

下⼀批基学习器 $C$ 棵决策树) 的训练样本为： $\{ ( { \pmb x } , { \pmb y } - \hat { \pmb y } ) \}$ ，其所需要拟合的残差为真实标签与预测概率之差。

# 自定义实现

[32]: from chapter5 import RegressionTree

```python
[33]: class Loss(ABC): def __init__(self): super().__init__(  @abstractmethod def loss(self, y_true, y_pred): return NotImplementedError() @abstractmethod def grad(self, y, y_pred): raise NotImplementedError() class SquareLoss(Loss): def __init__(self): pass def loss(self, y, y_pred): pass def grad(self, y, y_pred): return - (y - y_pred) def hess(self, y, y_pred): return 1 class CrossEntropyLoss(Loss): def __init__(self): pass def loss(self, y, y_pred): pass def grad(self, y, y_pred): return - (y - y_pred) def hess(self, y, y_pred): return y_pred \* (1-y_pred) 
```

```python
[34]: def softmax(x): e_x = np.exp(x - np.max(x, axis=-1, keepdims=True)) return e_x / e_x.sum(axis=-1, keepdims=True) def line_search(self, y, y_pred, h_pred): Lp = 2 * np.sum((y - y_pred) * h_pred) Lpp = np.sum(h_pred * h_pred) return 1 if np.sum(Lpp) == 0 else Lp / Lpp def to_categorical(x, n_classes=None): "" One-hot "" if not n_classes: n_classes = np.amax(x) + 1 
```

```python
one-hot = np.zeros((x.shape[0], n_classes))
one-hot(np.arange(x.shape[0]), x) = 1
return one-hot
```
class GradientBoostingDecisionTree(object):
    def __init__(self, n_estimators, learning_rate=1, min_samples_split=2,
                   min_impurity=1e-7, max_depth=float("inf"), is_regression=False, line_search=False):
        self.n_estimators = n_estimators    # 
        selfLearning_rate = learning_rate    # 
        self.min_samples_split = min_samples_split    # 
        self.min_impurity = min_impurity    # 
        self.max_depth = max_depth    # 
        self.is_regression = is_regression    # 
        self.line_search = line_search    #   line_search
        selfprogressbar = progressbarprogressbar widget.getter=bar.widget)
        # 
        self.loss = SquareLoss()
        if not self.is_regression:
            self.loss = CrossEntropyLoss()
def fit(self, X, Y):
    # Y one-hot
    if not self.is_regression:
        Y = to_categorical(Y.flatten())
    else:
        Y = Y.reshape(-1, 1) if len(Y.shape) == 1 else Y
        self.out_dims = Y.shape[1]
        self.trees = np.empty((self.n_estimators, self.out_dims), dtype=object)
        Y_pred = np.full(np.shape(Y), np.mean(Y, axis=0))
        selfweights = np.ones((self.n_estimators, self.out_dims))
        selfWeights[1:, :, ] *= self-learning_rate
    # 
    for i in selfProgressbar(range(self.n_estimators)):
        for c in range(self.out_dims):
            tree = RegressionTree(
                min_samples_split= self.min_samples_split,
                min_impurity= self.min_impurity,
                max_depth= self.max_depth
            # 
            if not self.is_regression:
                Y_hat = softmax(Y_pred)
                y, y_pred = Y[:, c], Y_hat[:, c]
            else:
                y, y_pred = Y[:, c], Y_pred[:, c]
            neg_grad = -1 * self.loss.grad(y, y_pred)
            tree.fit(X, neg_grad)
            # 
            h_pred = tree.predict(X)
            # line search
            if self.line_search == True:
                selfweights[i, c] *= line_search(y, y_pred, h_pred)
            # 
            Y_pred[:, c] += npmultiply(selfweights[i, c], h_pred)
            self.trees[i, c] = tree 
```

```python
def predict(self, X):
    Y_pred = np.zeros((X.shape[0], self.out_dims))
    # for c in range(self.out_dims):
        y_pred = np.array()
        for i in range(self.n_estimators):
            update = np.multiply(selfweights[i, c], self.trees[i, c].predict(X))
            y_pred = update if not y_pred.any() else y_pred + update
            Y_pred(:, c] = y_pred
if not self.is_regression:
    # Y_pred = Y_pred.argmax(axis=1)
return Y_pred
def score(self, X, y):
    y_pred = self.predict(X)
accuracy = np.sum(y == y_pred, axis=0) / len(y)
return accuracy
class GradientBoostingRegressor(GradientBoostingDecisionTree):
    def __init__(self, n_estimators=200, learning_rate=1, min_samples_split=2,
                     min_impurity=1e-7, max_depth=float("inf"), is_regression=True, line_search=False):
        super(GradientBoostingRegressor, self).__init__(n_estimators=n_estimators,
                     learning_rate=learning_rate,
                     min_samples_split=min_samples_split,
                     min_impurity=min_impurity,
                     max_depth=max_depth,
                     is_regression=is_regression,
                     line_search=line_search)
class GradientBoostingClassifierGradientBoostingDecisionTree):
    def __init__(self, n_estimators=200, learning_rate=1, min_samples_split=2,
                     min_impurity=1e-7, max_depth=float("inf"), is_regression=False,
                        super(GradientBoostingClassifier, self).__init__(n_estimators=n_estimators,
                        learning_rate=learning_rate,
                        min_samples_split=min_samples_split,
                        min_impurity=min_impurity,
                        max_depth=max_depth,
                        is_regression=is_regression,
                        line_search=line_search) 
```

# 用自定义的 GBDT，乳腺癌数据集测试

```python
[35]: column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class'] data = pd.read_csv('./data/cancer/breast-cancer-wisconsin.data', names=column_names) data = data.replace(to_replace='?', value=np.nan) # data = data.dropna(how='any') # any print(data.shape) # 25% 75% X_train, X_test, y_train, y_test = train_test_split(data[column_names[1:10]], data[col_names[10]], test_size=0.25, random_state=1111) # print(y_train.value_counts()) 
```

print(y_train.shape)   
y_train[y_train $= = 2$ ] $= 0$ y_train[y_train $= = 4$ ] $= 1$ y_test[y_test $= = 2$ ] $= 0$ y_test[y_test $= = 4$ ] $= 1$ #   
print(y_train.value_counts())   
#   
ss $\equiv$ StandardScaler()   
X_train $\equiv$ ss.fit_transform(X_train)   
X_test $\equiv$ ss.transform(X_test)   
y_train $\equiv$ y_train.as_matrix()   
y_test $\equiv$ y_test.as_matrix()

```txt
(683, 11)  
2 328  
4 184  
Name: Class, dtype: int64 (512,)  
0 328  
1 184  
Name: Class, dtype: int64 
```

```python
[36]: model = GradientBoostingClassifier(n_estimators=20)  
model.fit(X_train, y_train)  
print(model.score(X_test, y_test)) 
```

Training: $100\%$ [---] Time: 0:00:12

```markdown
0.9532163742690059 
```

用 sklearn 的 GBDT，乳腺癌数据集测试

```python
[37]: from sklearnensemble import GradientBoostingClassifier  
skl_model = GradientBoostingClassifier()  
skl_model.fit(X_train, y_train)  
print(skl_model.score(X_test, y_test)) 
```

```markdown
0.9473684210526315 
```

# 6.1.4 XGBoost 算法

XGBoost 是 GBDT 的改进。再次回到三个问题，XGBoost 的解决⽅案是什么？

• 弱分类器 (基分类器) 选什么？选法是 XGBoost 回归树 (见后⽂)。  
• 如何调整样本分布？不做更改。  
• 如何进⾏组合？组合⽅式即为加法模型 $f ( \pmb { x } ) = \sum _ { k = 1 } ^ { K } h _ { k } ( \pmb { x } )$ ，其中基学习器的系数为 1。损失函数同 GBDT。但是，在 XGBoost 中，显式地将树模型的复杂度作为正则项加在优化⽬标⾥。

# XGBoost 回归树的学习策略

XGBoost 的损失函数中显⽰地添加了树模型的复杂度作为正则项 $\Omega ( h _ { k } )$ ：

$$
\Omega \left(h _ {k}\right) = \gamma T + \frac {\lambda}{2} \sum_ {j = 1} ^ {T} w _ {j} ^ {2} \tag {60}
$$

其中 $T$ 是基学习器叶⼦节点的数⽬， $w _ { j }$ 是每个叶⼦节点的权重。对叶⼦节点个数进⾏惩罚，相当于在训练过程中做了剪枝。对于样本 $_ { \pmb { x } }$ ，我们⽤$q ( { \pmb x } )$ 表⽰将样本 $_ { \pmb { x } }$ 分到了某个叶节点上，于是 $w _ { q ( \pmb { x } ) }$ 表⽰回归树对样本的预测值。因此基学习器 $h _ { k } = w _ { q ( \pmb { x } ) }$ 。考虑正则项条件下，⽬标函数为：

$$
J (y, f (\boldsymbol {x})) = \mathcal {L} (y, f (\boldsymbol {x})) + \sum_ {k = 1} ^ {K} \Omega \left(h _ {k}\right) \tag {61}
$$

然后我们再考虑学习⽬标，第 k 次迭代时：

$$
\begin{array}{l} J (y, f (\boldsymbol {x})) = \mathcal {L} (y, f _ {k - 1} (\boldsymbol {x}) + h _ {k} (\boldsymbol {x})) + \sum_ {j = 1} ^ {k - 1} \Omega (h _ {j}) + \Omega (h _ {k}) \\ \approx \mathcal {L} (y, f _ {k - 1} (\boldsymbol {x})) + \frac {\partial \mathcal {L}}{\partial f _ {k - 1} (\boldsymbol {x})} h _ {k} (\boldsymbol {x}) + \frac {\partial^ {2} \mathcal {L}}{2 \partial f _ {k - 1} ^ {2} (\boldsymbol {x})} h _ {k} ^ {2} (\boldsymbol {x}) + \sum_ {j = 1} ^ {k - 1} \Omega \left(h _ {j}\right) + \Omega \left(h _ {k}\right) \tag {62} \\ = \mathcal {L} (y, f _ {k - 1} (\boldsymbol {x})) + \frac {\partial \mathcal {L}}{\partial f _ {k - 1} (\boldsymbol {x})} h _ {k} (\boldsymbol {x}) + \frac {\partial^ {2} \mathcal {L}}{2 \partial f _ {k - 1} ^ {2} (\boldsymbol {x})} h _ {k} ^ {2} (\boldsymbol {x}) + \Omega (h _ {k}) + C o n s t \\ \end{array}
$$

其中，从第⼀步到第⼆步⽤到了泰勒⼆阶展开：

$$
f (x) \approx f \left(x _ {0}\right) + f ^ {\prime} \left(x _ {0}\right) \left(x - x _ {0}\right) + \frac {f ^ {\prime \prime} \left(x _ {0}\right)}{2 !} \left(x - x _ {0}\right) \tag {63}
$$

简化⼀下书写，我们令第 i 个样本的：

$$
g _ {i} ^ {\prime} := \frac {\partial \mathcal {L}}{\partial f _ {k - 1} \left(\boldsymbol {x} _ {i}\right)} \tag {64}
$$

$$
h _ {i} ^ {\prime} := \frac {\partial^ {2} \mathcal {L}}{2 \partial f _ {k - 1} ^ {2} (\boldsymbol {x} _ {i})}
$$

于是，损失函数为 (把样本编号信息也标注上)：

$$
\begin{array}{l} J (y, f (\boldsymbol {x})) = \sum_ {i = 1} ^ {m} \left(\mathcal {L} (y, f _ {k - 1} (\boldsymbol {x})) + g _ {i} ^ {\prime} h _ {k} (\boldsymbol {x} _ {i}) + \frac {1}{2} h _ {i} ^ {\prime} h _ {k} ^ {2} (\boldsymbol {x} _ {i})\right) + \Omega (h _ {k} (\boldsymbol {x})) + C o n s t a n t \\ = \sum_ {i = 1} ^ {m} \left(\mathcal {L} \left(y, f _ {k - 1} (\boldsymbol {x})\right) + g _ {i} ^ {\prime} w _ {q \left(\boldsymbol {x} _ {i}\right)} + \frac {1}{2} h _ {i} ^ {\prime} w _ {q \left(\boldsymbol {x} _ {i}\right)} ^ {2}\right) + \gamma T + \frac {\lambda}{2} \sum_ {j = 1} ^ {T} w _ {j} ^ {2} + C o n s t a n t \tag {65} \\ = \sum_ {i = 1} ^ {m} \left(g _ {i} ^ {\prime} w _ {q \left(\boldsymbol {x} _ {i}\right)} + \frac {1}{2} h _ {i} ^ {\prime} w _ {q \left(\boldsymbol {x} _ {i}\right)} ^ {2}\right) + \gamma T + \frac {\lambda}{2} \sum_ {j = 1} ^ {T} w _ {j} ^ {2} + C o n s t a n t ^ {\prime} \\ \end{array}
$$

红⾊项是对样本的累加，蓝⾊项是对叶节点的累加。怎么统⼀起来？定义每个叶节点 $j$ 上的样本集合为： $I _ { j } = \{ i \ | \ q ( { \pmb x } _ { i } ) = j \}$ 。则⽬标函数可以写成按叶节点累加的形式 (优化问题中常数项不影响结果，我们不再考虑)：

$$
\begin{array}{l} J (y, f (\boldsymbol {x})) = \sum_ {j = 1} ^ {T} \left[ \left(\sum_ {i \in I _ {j}} g _ {i} ^ {\prime}\right) w _ {j} + \frac {1}{2} \left(\sum_ {i \in I _ {j}} h _ {i} ^ {\prime} + \lambda\right) w _ {j} ^ {2} \right] + \gamma T \tag {66} \\ = \sum_ {j = 1} ^ {T} \left[ (G _ {j} w _ {j} + \frac {1}{2} (H _ {j} + \lambda) w _ {j} ^ {2} \right] + \gamma T \\ \end{array}
$$

如果确定了树的结构 (即 $q ( { \pmb x } )$ 确定)，为了使⽬标函数最⼩，可以令其导数为 0，解得每个叶节点的最优预测分数为：

$$
w _ {j} ^ {*} = - \frac {G _ {j}}{H _ {j} + \lambda}, \quad j = 1, 2, \dots , T \tag {67}
$$

代⼊⽬标函数，得到最⼩损失为：

$$
J ^ {*} = - \frac {1}{2} \sum_ {j = 1} ^ {T} \frac {G _ {j} ^ {2}}{H _ {j} + \lambda} + \gamma T \tag {68}
$$

当回归树的结构确定时，我们前⾯已经推导出其最优的叶节点分数以及对应的最⼩损失值，问题是怎么确定树的结构？也就是说我们的基学习器是什么样的？⼀种是暴⼒枚举所有可能的树结构，选择损失值最⼩的，但这是 NP 难问题。另⼀种⽅法是贪⼼法，每次尝试分裂⼀个叶节点，计算分裂前后的增益，选择增益最⼤的 (信息增益见第五章)。

$$
J ^ {*} = - \frac {1}{2} \sum_ {j = 1} ^ {T} \frac {G _ {j} ^ {2}}{H _ {j} + \lambda} + \gamma T \tag {69}
$$

标红部分衡量了每个叶⼦节点对总体损失的的贡献，我们希望损失越⼩越好，则标红部分的值越⼤越好。

因此，对⼀个叶⼦节点进⾏分裂，分裂前后的增益定义为：

$$
\begin{array}{l} G a i n = J ^ {*} - \left(J _ {L} ^ {*} + J _ {R} ^ {*}\right) \\ = \left(- \frac {1}{2} \frac {\left(G _ {L} + G _ {R}\right) ^ {2}}{H _ {L} + H _ {G} + \lambda} + \gamma\right) - \left(- \frac {1}{2} \frac {G _ {L} ^ {2}}{H _ {L} + \lambda} + \gamma\right) - \left(- \frac {1}{2} \frac {G _ {R} ^ {2}}{H _ {R} + \lambda} + \gamma\right) \tag {70} \\ = \frac {1}{2} \left(\frac {G _ {L} ^ {2}}{H _ {L} + \lambda} + \frac {G _ {R} ^ {2}}{H _ {R} + \lambda} - \frac {(G _ {L} + G _ {R}) ^ {2}}{H _ {L} + H _ {G} + \lambda}\right) - \gamma \\ \end{array}
$$

这个结果就可以⽤于在实践中评估候选分裂节点是不是应该分裂的划分依据，我们尽量找到使之最⼤的特征值分裂点。

在树学习中，另外⼀个关键问题是如何找到每⼀个特征上的分裂点。直觉的想法是枚举特征上所有可能的分裂点，然后计算上述的增益。这种算法称为 Exact Greedy Algorithm。当然为了有效率的找到最佳分裂节点，算法可以先将该特征的所有取值进⾏排序，之后按顺序取分裂值计算。但是当数据量很⼤时，数据不可能⼀次性的全部读⼊到内存中，或者在分布式计算中，也不可能事先对所有值进⾏排序，且⽆法使⽤所有数据来计算分裂节点之后的树结构的增益分数。

# XGBoost 回归树的节点分裂算法

正如上⾯所说，尽管我们找到了寻找最佳分裂点的指标，但使⽤贪婪算法逐个特征值计算的计算量过⾼。为解决这个问题，有⼏种解决⽅案。

种是近似算法 (Approximate Algo for Split Finding)，近似算法⾸先按照特征取值中统计分布的百分位点确定⼀些候选分裂点，然后算法将连续的值映射到桶 (buckets) 中，接着汇总统计数据，并根据聚合统计数据在候选节点中找到最佳节点。XGBoost 采⽤的近似算法对于每个特征，只考察分位点，减少复杂度。例如，以三分位点举例：

![](images/519135fb9ff206b9207e61d9fe77ea16de91fe95f02d4c89289210998cc48f62.jpg)  
图 7. 只考察分位点的近似算法。

于是，我们找到其中最⼤的信息增益的划分⽅法：

$$
G a i n = \max  \left(G a i n, \frac {1}{2} \left(\frac {G _ {1} ^ {2}}{H _ {1} + \lambda} + \frac {G _ {2 3} ^ {2}}{H _ {2 3} + \lambda} - \frac {(G _ {1 2 3}) ^ {2}}{H _ {1 2 3} + \lambda}\right) - \gamma , \frac {1}{2} \left(\frac {G _ {1 2} ^ {2}}{H _ {1 2} + \lambda} + \frac {G _ {3} ^ {2}}{H _ {3} + \lambda} - \frac {(G _ {1 2 3}) ^ {2}}{H _ {1 2 3} + \lambda}\right) - \gamma\right) \tag {71}
$$

然⽽，这种划分分位点的⽅法在实际中可能效果不是很好。

另⼀种是加权分位数 (Weighted Quantile Sketch)，我们需先构造⼀个集合： $\mathcal { D } _ { j } = \left\{ \left( x _ { i j } , h _ { i j } ^ { \prime } \right) _ { i = 1 , . . . m } \right\}$ ，其中 $x _ { i j }$ 表⽰第 $i$ 个样本的第 $j$ 个特征值， $h _ { i j } ^ { \prime }$ 是第 $i$ 个样本的第 $j$ 个特征的⼆阶梯度统计。我们现在定义⼀个排序函数 $r _ { j }$ ：

$$
r _ {j} (z) = \frac {1}{\sum_ {(x , h ^ {\prime}) \in \mathcal {D} _ {j}} h ^ {\prime}} \sum_ {(x, h ^ {\prime}) \in \mathcal {D} _ {j}, x <   z} h ^ {\prime} \tag {72}
$$

表⽰特征 $j$ 所有可取值中⼩于 $z$ 的特征值的总权重占总的所有可取值的总权重和的⽐例，⽤ $h ^ { \prime }$ 加权。⽬标就是寻找候选分裂点集 $\{ s _ { j 1 } , s _ { j 2 } , \dotsc s _ { j l } \}$ ，有

$$
\left| r _ {j} \left(s _ {j, t}\right) - r _ {j} \left(s _ {j, t + 1}\right) \right| <   \epsilon , \quad s _ {j 1} = \min  _ {i} x _ {i j}, s _ {j l} = \max  _ {i} x _ {i j} \tag {73}
$$

$\epsilon$ 是近似因⼦或者说是扫描步幅，按照步幅 $\epsilon$ 挑选出特征 $j$ 的取值候选点，组成候选点集，这意味着有⼤概 $\frac { 1 } { \epsilon }$ 个候选点。但是，我们为什么要⽤ $h ^ { \prime }$ 加权呢？我们把⽬标函数整理成以下形式：

$$
\begin{array}{l} J (y, f (\boldsymbol {x})) \simeq \sum_ {i = 1} ^ {m} \left[ g _ {i} ^ {\prime} h _ {k} (\boldsymbol {x} _ {i}) + \frac {1}{2} h _ {i} ^ {\prime} h _ {k} ^ {2} (\boldsymbol {x} _ {i}) \right] + \Omega (h _ {k}) + C o n s t a n t \\ = \sum_ {i = 1} ^ {m} \left[ g _ {i} ^ {\prime} h _ {k} \left(\boldsymbol {x} _ {i}\right) + \frac {1}{2} h _ {i} ^ {\prime} h _ {k} ^ {2} \left(\boldsymbol {x} _ {i}\right) + \underbrace {\frac {1}{2} \frac {g _ {i} ^ {\prime 2}}{h _ {i} ^ {\prime}}} _ {\text {添 加 常 数 项}} \right] + \Omega \left(h _ {k}\right) + C o n s t a n t ^ {\prime} \tag {74} \\ = \sum_ {i = 1} ^ {m} \frac {1}{2} h _ {i} ^ {\prime} \left[ h _ {k} (\boldsymbol {x} _ {i}) - \left(- \frac {g _ {i} ^ {\prime}}{h _ {i} ^ {\prime}}\right) \right] ^ {2} + \Omega (h _ {k}) + C o n s t a n t ^ {\prime} \\ \end{array}
$$

最后的代价函数就是⼀个加权平⽅误差，权值为 $h _ { i } ^ { \prime }$ ，标签为 $- \frac { g _ { i } ^ { \prime } } { h _ { i } ^ { \prime } }$ ，所以可以将特征 $j$ 的取值权重看成对应的 $h _ { i } ^ { \prime }$ 。

# XGBoost 的损失函数

最后，如何定义 $\mathcal { L } ( y , f ( \pmb { x } ) ) \div$ 如果是回归模型，可以采⽤平⽅损失；如果是分类模型，可以采⽤交叉熵损失。具体原理同 GBDT。有了 $\mathcal { L } ( y , f ( \pmb { x } ) )$ 0的具体形式，我们便可以得到 $H$ 和 $G$ 。(注：平⽅损失和交叉熵损失的 $G$ 和 $H$ 的推导可以参考第六章，在第六章我们推导了⼀阶导数的获得，⽽⼆阶导数只需要在⼀阶导数上再简单求导⼀次便可。)

# XGBoost 的其它设置

除了上述描述的以外，XGBoost 在实现过程中，还使⽤了包括：

1. 缺失值处理。当有缺失值时，系统将样本分到默认⽅向的叶⼦节点。每个分⽀都有两个默认⽅向，最佳的默认⽅向可以从训练数据中学习到。  
2. 系统优化设计。包括分块并⾏、缓存优化等。关于并⾏问题我们会在⼗⼆章介绍。  
3. 列抽样。这⾥借鉴了随机森林的做法，⽀持对特征采样，不仅能降低过拟合，还能减少计算。  
4. Shrinkage。相当于学习率，这⾥同 GBDT 的做法，主要是为了削弱每棵树的影响，让后⾯有更⼤的学习空间。

[38]: from chapter5 import DecisionTree

[39]: class XGBoostRegressionTree(DecisionTree): XGBoost def __init__(self, min_samples_split $^ { = 2 }$ , min_impurity=1e-7, max_depth=float("inf"), loss=None, gamma $_ { . = 0 }$ ., lambd=0.):

```python
super(XGBoostRegressionTree, self).__init__(min_impurity = min_impurity, min_samples_split = min_samples_split, max_depth = max_depth)  
self_gamma = gamma #  
self.lambd = lambd #  
self.loss = loss # 
```

```python
def _split(self, y):
    # y     y_true     y_pred
    col = int(np.shape(y) [1] / 2)
    y, y_pred = y[:, :col], y[:, col:]
    return y, y_pred
def _gain(self, y, y_pred):
    #
    nominator = np.power((y * self.loss_grad(y, y_pred)).sum(), 2)
    denominator = self.loss.hess(y, y_pred).sum()
    return nominator / (denominator + self.lambd) 
```

```python
def _gain_by_taylor(self, y, y1, y2): # y, y_pred = self._split(y) y1, y1_pred = self._split(y1) y2, y2_pred = self._split(y2) true_gain = self._gain(y1, y1_pred) false_gain = self._gain(y2, y2_pred) gain = self._gain(y, y_pred) # return 0.5 * (true_gain + false_gain - gain) - self.gamma 
```

```python
def _approximate_update(self, y):
    y, y_pred = self._split(y)
    # gradient = self.lossGrad(y, y_pred).sum()
    hessian = self.loss.hess(y, y_pred).sum()
    leaf_approximation = -gradient / (hessian + self.lambd) 
```

```python
def fit(self, X, y):
    self._impurity Calculation = self._gain_by_taylor
    self._leaf_value Calculation = self._approximate_update
    super(XGBoostRegressionTree, self).fit(X, y) 
```

```python
class XGBoost(object):   
```
```
XGBoost
```
def __init__(self, n_estimators=200, learning_rate=0.001, min_samples_split=2, 
            min_impurity=1e-7, max_depth=2, is_regression=False, gamma=0., lambda=0.):
                self.n_estimators = n_estimators    # 
                selfLearning_rate = learning_rate    # 
                self.min_samples_split = min_samples_split    # 
                self.min_impurity = min_impurity    # 
                self.max_depth = max_depth    # 
                self.gamma = gamma    # 
                self.lambd = lambd    # 
                self.is_regression = is_regression    # 
                self_progressbar = progressbarprogressBar(wildts=barWidgets) 
```

```python
def fit(self, X, Y): # Y one-hot if not self.is_regression: Y = to_categorical(Y.flatten()) else: Y = Y.reshape(-1, 1) if len(Y.shape) == 1 else Y self.out_dims = Y.shape[1] self.trees = np.empty((self.n_estimators, self.out_dims), dtype=object) Y_pred = np.zeros(np.shape(Y)) selfweights = np.ones((self.n_estimators, self.out_dims)) selfweights[1:, :, ] *= self_learning_rate # for i in selfProgressbar(range(self.n_estimators)): for c in range(self.out_dims): tree = XGBoostRegressionTree(min_samples_splitself.min_samples_split, min_impurityself.min_impurity, max_depthself.max_depth, lossself.loss, gamma= self.gamma, lambda= self.lambd) # if not self.is_regression: Y_hat = softmax(Y_pred) y, y_pred = Y[:, c], Y_hat(:, c] else: y, y_pred = Y[:, c], Y_pred(:, c] y, y_pred = y.reshape(-1, 1), y_pred.reshape(-1, 1) y_and_ypred = npcondeate((y, y_pred), axis=1) tree.fit(X, y_and_ypred) # h_pred = tree.predict(X) # Y_pred[, c] += npmultiply(selfweights[i, c], h_pred) self.trees[i, c] = tree def predict(self, X): Y_pred = np.zeros((X.shape[0], self.out_dims)) # for c in range(self.out_dims): y_pred = np.array[]) for i in range(self.n_estimators): update = npultipleize(selfweights[i, c], self.trees[i, c].predict(X)) y_pred = update if not y_pred.any() else y_pred + update Y_pred[, c] = y_pred if not self.is_regression: Y_pred = Y_pred.argmax(axis=1) return Y_pred def score(self, X, y): y_pred = self.predict(X) accuracy = np.sum(y == y_pred, axis=0) / len(y) 
```

用自定义的 XGBoost，乳腺癌数据集测试  
return accuracy   
class XGBRegressor(XGBoost): def__init__(self，n_estimators=200，learning_rate $= 1$ ，min_samples_split $= 2$ min_impurity $\coloneqq$ 1e-7,max_depth $\equiv$ float("inf")，is_regression=True, gamma $= 0$ .，lambda $= 0$ ）： super(XGBRegressor，self).__init__(n_estimators=n_estimators, learning_rate $\equiv$ learning_rate, min_samples_split $\equiv$ min_samples_split, min_impurity $\equiv$ min_impurity, max_depth $\equiv$ max_depth, is_regression $\equiv$ is_regression, gamma $\equiv$ gamma, lambda $\equiv$ lambda)   
classXGBClassifier(XGBoost): def__init__(self，n_estimators $= 200$ ，learning_rate $= 1$ ，min_samples_split $= 2$ min_impurity $\equiv$ 1e-7,max_depth $\equiv$ float("inf")，is_regression=False, gamma $= 0$ .，lambda $= 0$ ： super(XGBClassifier，self).__init__(n_estimators=n_estimators, learning_rate $\equiv$ learning_rate, min_samples_split $\equiv$ min_samples_split, min_impurity $\equiv$ min_impurity, max_depth $\equiv$ max_depth, is_regression $\equiv$ is_regression, gamma $\equiv$ gamma, lambda $\equiv$ lambda)

[40]:

```python
column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']
data = pd.read_csv('./data/cancer/breast-cancer-wisconsin.data', names=column_names)
data = data.replace(to_replace='?', value=np.mean) # data = data.dropna(how='any') # any print(data.shape)
# 25%
75%
X_train, X_test, y_train, y_test = train_test_split(data colum_names[1:10], data colum_names[10]), test_size=0.25, random_state=1111)
print(y_train.value_counts())
# 0 1
print(y_train.shape)
y_train[y_train==2] = 0
y_train[y_train==4] = 1
y_test[y_test==2] = 0
y_test[y_test==4] = 1
# print(y_train.value_counts())
# 0 1
ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.transform(X_test)
y_train = y_train.as_matrix() 
```

```python
y_test = y_test.as_matrix() 
```

(683, 11)

2 328

4 184

Name: Class, dtype: int64

(512,)

0 328

1 184

Name: Class, dtype: int64

[41]: model $=$ XGBClassifier(n_estimators=20)

```python
model.fit(X_train，y_train) print(model.score(X_test，y_test)) 
```

Training: 100% [--- ---] Time: 0:00:06

0.9590643274853801

```python
[42]: import numpy  
import PIL  
import matplotlib  
import re  
import pandas  
import progressbar  
import sklearn  
print("numpy:", numpy._version_)  
print("PIL:", PIL._version_)  
print("matplotlib:", matplotlib._version_)  
print("re:", re._version_)  
print("pandas:", pandas._version_)  
print("progressbar:", progressbar._version_)  
print("sklearn:", sklearn._version_) 
```

numpy: 1.14.5

PIL: 6.2.1

matplotlib: 3.1.1

re: 2.2.1

pandas: 0.25.1

progressbar: 2.5

sklearn: 0.21.3

# 深度模型中的优化

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 基本优化算法

整体框架

# 1.1 梯度

# 1.1.1 梯度下降

• 微积分中使⽤梯度表⽰函数增长最快的⽅向，因此，神经⽹络中使⽤负梯度来指⽰⽬标函数下降最快的⽅向。

– 梯度实际上是损失函数对⽹络中每个参数的偏导所组成的向量；  
– 梯度仅仅指⽰了对于每个参数各⾃增长最快的⽅向，因此，梯度⽆法保证全局方向就是函数为了达到最⼩值应该前进的⽅向；  
– 使⽤梯度的具体计算⽅法即反向传播。

• 梯度下降是⼀种优化算法，通过迭代的⽅式寻找使模型目标函数达到最小值时的最优参数 (也称最速下降法)：

– 当⽬标函数是凸函数时，梯度下降的解是全局最优解，但在⼀般情况下，梯度下降无法保证全局最优；  
– 梯度下降最常⽤的形式是批量梯度下降法 (Batch Gradient Descent，BGD)，其做法是在更新参数时使⽤所有的样本来进⾏更新。

• 反过来，如果求解目标函数达到最大值时的最优参数，就需要⽤梯度上升法进⾏迭代。  
• 负梯度中的每⼀项可以认为传达了两个信息：

– 正负号在告诉输⼊向量应该调⼤还是调⼩ (正调⼤，负调⼩)；  
– 每⼀项的相对⼤⼩表明每个参数对函数值达到最值的影响程度。

# 1.1.2 随机梯度下降

⾸先，梯度下降法沿着梯度的反⽅向进⾏搜索，利⽤了函数的⼀阶导数信息。基本的梯度下降法每次使⽤所有训练样本的平均损失来更新参数。因此，经典的梯度下降在每次对模型参数进⾏更新时，需要遍历所有数据。当训练样本的数量很⼤时，这需要消耗相当⼤的计算资源，在实际应⽤中基本不可⾏。

⽽随机梯度下降 (Stochastic Gradient Descent，SGD) 是随机抽取⼀批样本 (Batch)，以此为根据来更新参数。随机梯度下降每次使⽤ $m$ 个样本的损失来近似平均损失，更新规则：

$$
g \leftarrow \frac {1}{m} \nabla_ {\theta} \sum_ {i} J \left(f \left(\boldsymbol {x} ^ {(i)}; \theta\right), y ^ {(i)}\right) \tag {1}
$$

$$
\theta \leftarrow \theta - \epsilon g
$$

随机梯度下降法存在的问题：

• 随机梯度下降 (SGD) 放弃了梯度的准确性，仅采⽤⼀部分样本来估计当前的梯度。因此 SGD 对梯度的估计常常出现偏差，造成⽬标函数收敛不稳定，甚⾄不收敛的情况。  
• ⽆论是经典的梯度下降还是随机梯度下降，都可能陷⼊局部极值点。除此之外，SGD 还可能遇到 “峡谷” 和 “鞍点” 两种情况。

– 峡谷类似⼀个带有坡度的狭长⼩道，左右两侧是 “峭壁”；在峡谷中，准确的梯度⽅向应该沿着坡的⽅向向下，但粗糙的梯度估计使其稍有偏离就撞向两侧的峭壁，然后在两个峭壁间来回震荡。  
– 鞍点的形状类似⼀个马鞍，⼀个⽅向两头翘，⼀个⽅向两头垂，⽽中间区域近似平地；⼀旦优化的过程中不慎落⼊鞍点，优化很可能就会停滞下来。

SGD 的改进遵循两个⽅向：惯性保持和环境感知。

• 惯性保持指的是加⼊动量：动量 (Momentum) 方法。  
• 环境感知指的是根据不同参数的⼀些经验性判断，自适应地确定每个参数的学习速率：自适应学习率的优化算法。

![](images/6dc0686384ab5d1a3262ea3cbfa8acca0b0270d406a7d03310b91badbb22d890.jpg)  
(i) 梯度下降法和随机梯度下降法迭代过程

![](images/aefe089394f4335592ba52166bf3cf4a88b96fb8a3135b7b4a0931683c2a6ce4.jpg)  
(ii) 随机梯度下降法存在的问题，峡⾕与鞍点  
图 1. 随机梯度下降法

```python
[1]: from abc import ABC, abstractmethod import numpy as np 
```

```python
[2]: class OptimizerBase(ABC): def __init__(self): pass def __call__(self): return self.update.params, params_grad, params_name) @abstractmethod def update(self, params, params_grad, params_name): "" parameters W parameters_grad parameters_name raise NotImplementedError 
```

```python
[3]: class SGD(OptimizerBase):   
```
sgd
```
def __init__(self, lr=0.001):
    super().__init__
    self.lr = lr
    self-cache = {}
def __str__(self):
    return "SGD(lr=\{)" .format(selfhyperparams["lr")] 
```

# 1.2 动量

# 1.2.1 Momentum 算法

引⼊动量 (Momentum) ⽅法⼀⽅⾯是为了解决 “峡⾕” 和 “鞍点” 问题，另⼀⽅⾯也可以⽤于 SGD 加速，特别是针对高曲率、小幅但是方向一致的梯度。

如果把原始的 SGD 想象成⼀个纸团在重⼒作⽤向下滚动，由于质量小受到⼭壁弹⼒的⼲扰⼤，导致来回震荡。或者在鞍点处因为质量小速度很快减为 0，导致⽆法离开这块平地。动量⽅法相当于把纸团换成了铁球。不容易受到外⼒的⼲扰，轨迹更加稳定，同时因为在鞍点处因为惯性的作⽤，更有可能离开平地。

# 参数更新公式

$$
v \leftarrow \alpha v - \epsilon \nabla_ {\theta} \left(\frac {1}{m} \sum_ {i = 1} ^ {m} J \left(f \left(\boldsymbol {x} ^ {(i)}; \theta\right), y ^ {(i)}\right)\right) \tag {2}
$$

$$
\theta \leftarrow \theta + v
$$

• 从形式上看，动量算法引⼊了变量 $v$ 充当速度⾓⾊，以及相关的超参数 $\alpha$ ，决定了之前的梯度贡献衰减得有多快；  
• 原始 SGD 每次更新的步长只是梯度乘以学习率。现在，步长还取决于历史梯度序列的⼤⼩和排列。当许多连续的梯度指向相同的方向时，步长会被不断增大。

速度 $v$ 累积了当前梯度元素 $\begin{array} { r } { \nabla _ { \boldsymbol { \theta } } \big ( \frac { 1 } { m } \sum _ { i = 1 } ^ { m } J ( f ( \mathbf { x } ^ { ( i ) } ; \boldsymbol { \theta } ) , y ^ { ( i ) } ) \big ) } \end{array}$ ，相对于 $\epsilon$ ，如果 $\alpha$ 越⼤，之前梯度对现在⽅向的影响也越⼤。实践中， $\alpha$ ⼀般取值为0.5，0.9 和 $0 . 9 9 _ { \varsigma }$ 。

当前迭代点的下降⽅向不仅仅取决于当前的梯度，还受到前面所有迭代点的影响。动量⽅法以⼀种廉价的⽅式模拟了⼆阶梯度 (⽜顿法)。

# 1.2.2 NAG 算法

Nesterov 提出了⼀个针对动量算法的改进措施。前⾯的动量算法是把历史的梯度和当前的梯度进⾏合并，来计算下降的⽅向。⽽ Nesterov 提出，让迭代点先按照历史梯度⾛⼀步，然后再合并。更新规则如下，改变主要在于梯度的计算上：

$$
v \leftarrow \alpha v - \epsilon \nabla_ {\theta} \left(\frac {1}{m} \sum_ {i = 1} ^ {m} J \left(f \left(\boldsymbol {x} ^ {(i)}; \theta + \alpha v\right), y ^ {(i)}\right)\right) \tag {3}
$$

$$
\theta \leftarrow \theta + v
$$

参数 $\alpha$ 和 ϵ 发挥了和标准动量⽅法中类似的作⽤，Nesterov 动量和标准动量之间的区别在于梯度的计算上。NAG 把梯度计算放在对参数施加当前速度之后，这个 “提前量” 的设计让算法有了对前⽅环境 “预判” 的能⼒，可以理解为 Nesterov 动量往标准动量⽅法中添加了⼀个校正因⼦。在凸优化问题使⽤批量梯度下降的情况下，Nesterov 动量将 $k$ 步之后额外误差收敛率从 $\mathrm O \big ( \frac { 1 } { k } \big )$ 提⾼到 $\mathrm { O } ( { \textstyle { \frac { 1 } { k ^ { 2 } } } } )$ ，对 SGD 没有改进收敛率。

如图 2 所⽰，左图显⽰了 Momentum ⽅法的轨迹，右图显⽰了 Nesterov ⽅法的轨迹。

![](images/87518d30bc8be1bbfbcdb4fdf7861eb2d5198a24c4771cfe0cae98a3c0d5abd0.jpg)

![](images/1b77448874167ed4cd005cc0e924c26206af26a6eae1ddf1958ecaa29bebe85d.jpg)  
图 2. 动量⽅法的轨迹。蓝⾊线为历史的梯度，⿊⾊线为当前的梯度，红⾊线为实际轨迹。

[4]:

```python
```
SGD momentum
```
class Momentum(OptimizerBase):
    def __init__(self, lr=0.001, momentum=0.0, **kwargs):
        ....
    lr     float (default: 0.001)
    momentum   Momentum   alpha
    ....
    super().__init__(self.lr = lr
    self.momentum = momentum
    self.cache = {}
    def __str__(self):
        return "Momentum(lr={}, momentum={})".format(self.lr, self.momentum)
    def update(self, param, param_grad, param_name): 
```

C $=$ self.cache   
lr,momentum $\equiv$ self.lr,self.momentum   
if param_name not in C: # save v C[param_name] $=$ np.zeros_like(param_grad) update $=$ momentum \* C[param_name] - lr \* param_grad self.cache[param_name] $=$ update return param $^+$ update   
@property   
def hyperparams(self):   
return { "op": "Momentum", "lr":self.lr, "momentum":self.momentum

# 1.3 自适应学习率

由于 SGD 中随机采样 Batch 会引⼊噪声源，在极⼩点处梯度并不会消失。因此，随着梯度的降低，有必要逐步减⼩学习率。

# 1.3.1 AdaGrad 算法

算法的思想是独⽴地适应模型的每个参数：一直较大偏导的参数相应有一个较小的学习率，初始学习率会下降的较快；而一直小偏导的参数则对应一个较大的学习率，初始学习率会下降的较慢。具体来说，每个参数的学习率会缩放各参数反⽐于其历史梯度平方值总和的平方根，更新公式：

$$
g \leftarrow \frac {1}{m} \nabla_ {\theta} \sum_ {i} J (f (\boldsymbol {x} ^ {(i)}; \theta), y ^ {(i)})
$$

$$
r \leftarrow r + g \odot g \tag {4}
$$

$$
\theta \leftarrow \theta - \frac {\epsilon}{\delta + \sqrt {r}} \odot g
$$

$r$ 为累积平方梯度。学习率相当于 $\frac { \epsilon } { \delta + \sqrt { r } }$ ，对于更新不频繁的参数，单次步长更⼤；对于更新频繁的参数，步长较⼩，使得学习到的参数更稳定，不⾄于被单个样本影响太多。

AdaGrad 算法存在的问题，历史梯度在分母上的累积会越来越大，所以学习率会越来越小，使得在中后期⽹络的学习能⼒越来越弱。

[5]:

```python
class AdaGrad(OptimizerBase): def __init__(self, lr=0.001, eps=1e-7, **kwargs): "" lr float (default: 0.001) eps delta 0 "" super().__init__(self.lr = lr self.eps = eps self.cache = {} def __str__(self): return "AdaGrad(lr=\{}, eps=\{)" format(self.lr, self.eps) def update(self, param, param_grad, param_name): C = self.cache lr, eps = selfhyperparams["lr"], selfhyperparams["eps"] if param_name not in C: # r C[param_name] = np.zeros_like(param_grad) C[param_name] += param_grad ** 2 update = lr * param_grad / (np.sqrt(C[param_name]) + eps) 
```

```python
self.cache = C
return param - update
@property
def hyperparams(self):
    return {
        "op": "AdaGrad",
        "lr": self.lr,
        "eps": self.eps
    } 
```

# 1.3.2 RMSProp 算法

RMSProp 主要是为了解决 AdaGrad ⽅法中学习率过度衰减的问题—— AdaGrad 根据平⽅梯度的整个历史来收缩学习率，可能使得学习率在达到局部最⼩值之前就变得太⼩⽽难以继续训练。RMSProp 使⽤指数衰减平均 (递归定义) 以丢弃遥远的历史，使其能够在找到某个 “凸” 结构后快速收敛。此外，RMSProp 还加⼊了⼀个超参数 $\rho$ ⽤于控制衰减速率：

$$
g \gets \frac {1}{m} \nabla_ {\theta} \sum_ {i} J (f (\boldsymbol {x} ^ {(i)}; \theta), y ^ {(i)})
$$

$$
r \leftarrow \rho r + (1 - \rho) g \odot g \tag {5}
$$

$$
\theta \leftarrow \theta - \frac {\epsilon}{\sqrt {\delta + r}} \odot g
$$

RMSProp 建议的初始值：全局学习率 $\epsilon = 1 e - 3$ ，衰减速率 $\rho = 0 . 9 _ { \circ }$

[6]:

```python
class RMSProp(OptimizerBase):   
def __init__(self, lr=0.001, decay=0.9, eps=1e-7, **kwargs):   
    ""   
    lr float (default: 0.001)  
    eps delta 0  
    decay   
    ""   
    super().__init__(self.lr = lr  
    self.eps = eps  
    self.decay = decay  
    self.cache = {}  
def __str__(self):  
    return "RMSProp(lr={}, eps={}, decay={})".format(self.lr, self.eps, self.decay)  
def update(self, param, param_grad, param_name):  
    C = self.cache  
    lr, eps = selfhyperparams["lr"], self.hyperparams["eps"]  
    decay = self.hyperparams["decay"]  
    if param_name not in C: # r  
        C[var_name] = np.zeros_like(param_grad)  
        C[var_name] = decay * C[var_name] + (1 - decay) * param_grad ** 2  
    update = lr * param_grad / (np.sqrt(C[var_name]) + eps)  
    self.cache = C  
    return param - update  
@property  
def hyperparams(self):  
    return { 
```

```python
"op": "RMSProp",  
"lr": self.lr,  
"eps": self.eps,  
"decay": self.decay 
```

# 1.3.3 AdaDelta 算法

AdaDelta 和 RMSProp ⼀样使⽤指数衰减平均 (递归定义) 以丢弃遥远的历史，但 AdaDelta 算法没有学习率这⼀超参数。AdaDelta 算法维护⼀个额外的变量 $\Delta \theta$ ，来计算⾃变量变化量按元素平⽅的指数加权移动平均：

$$
g \leftarrow \frac {1}{m} \nabla_ {\theta} \sum_ {i} J (f (\boldsymbol {x} ^ {(i)}; \theta), y ^ {(i)})
$$

$$
r \leftarrow \rho r + (1 - \rho) g \odot g
$$

$$
g ^ {\prime} \leftarrow \frac {\sqrt {\delta + \Delta \theta}}{\sqrt {\delta + r}} \odot g \tag {6}
$$

$$
\theta \gets \theta - g ^ {\prime}
$$

$$
\Delta \theta \gets \rho \Delta \theta + (1 - \rho) g ^ {\prime} \odot g ^ {\prime}
$$

可以看到，如不考虑 $\delta$ 的影响，AdaDelta 算法与 RMSProp 算法的不同之处在于使⽤ $\sqrt { \Delta \theta }$ 来替代超参数 $\epsilon _ { \circ }$

[7]: class AdaDelta(OptimizerBase):   
```python
def __init__(self, lr=0.001, decay=0.95, eps=1e-7, **kwargs):  
    '''  
lr float (default: 0.001)  
eps delta 0  
decay  
'''  
super().__init_(self.lr = lr)  
self.eps = eps  
self.decay = decay  
self.cache = {}.  
def __str__(self):  
return "AdaDelta(eps={}, decay={})".format(self.eps, self.decay)  
def update(self, param, param_grad, param_name):  
C = self.cache  
eps = selfhyperparams["eps"]  
decay = selfhyperparams["decay"]  
if param_name not in C: # r, delta_theta  
C[param_name] = {  
    "r": np.zeros_like(param_grad),  
    "d": np.zeros_like(param_grad)  
}  
C[param_name][r"] = decay * C[param_name][r"] + (1 - decay) * param_grad ** 2  
update = (np.sqrt(C[param_name][d"] + eps)) * param_grad / (np.sqrt(C[param_name][r"] + eps)  
C[param_name][d"] = decay * C[param_name][d"] + (1 - decay) * update ** 2  
self.cache = C  
return param - update  
@property  
def hyperparams(self):  
return {  
    "op": "AdaDelta", 
```

```txt
"eps": self.eps, "decay": self.decay} 
```

# 1.3.4 Adam 算法

Adam 在 RMSProp ⽅法的基础上更进⼀步：除了加⼊历史梯度平方的指数衰减平均 (s) 外，还保留了历史梯度的指数衰减平均 $( r )$ ，相当于动量。Adam ⾏为就像⼀个带有摩擦⼒的⼩球，在误差⾯上倾向于平坦的极⼩值。

$$
g \leftarrow \frac {1}{m} \nabla_ {\theta} \sum_ {i} J (f (\boldsymbol {x} ^ {(i)}; \theta), y ^ {(i)})
$$

$$
t \leftarrow t + 1
$$

$$
r \gets \rho_ {1} r + (1 - \rho_ {1}) g
$$

$$
s \leftarrow \rho_ {2} s + (1 - \rho_ {2}) g \odot g
$$

$$
\hat {r} \leftarrow \frac {r}{1 - \rho_ {1} ^ {t}} \tag {7}
$$

$$
\hat {s} \gets \frac {s}{1 - \rho_ {2} ^ {t}}
$$

$$
\Delta \theta \gets - \epsilon \frac {\hat {r}}{\sqrt {\hat {s}} + \delta}
$$

$$
\theta \leftarrow \theta + \Delta \theta
$$

# 偏差修正

这⾥的 $s$ 和 $r$ 初始化为 0，且 $\rho _ { 1 }$ 和 $\rho _ { 2 }$ 推荐的初始值都很接近 1 (0.9 和 0.999)。注意到，在时间步 t 我们得到 $\begin{array} { r } { r _ { t } = \left( 1 - \rho _ { 1 } \right) \sum _ { i = 1 } ^ { t } \rho _ { 1 } ^ { t - i } g _ { i } } \end{array}$ ，将过去各时间步⼩批量随机梯度的权值相加，得到 $\textstyle \left( 1 - \rho _ { 1 } \right) \sum _ { i = 1 } ^ { t } \rho _ { 1 } ^ { t - i } = 1 - \rho _ { 1 } ^ { t }$ 。可以看出，当 $t$ 较⼩时，过去各时间步⼩批量随机梯度权值之和会较⼩。假设取 $\rho _ { 1 } = 0 . 9$ ，可以得到 $t = 1$ 时 $r _ { 1 } = 0 . 1 g _ { 1 }$ 。因此我们需要偏差修正 (见式 7 第 5，6 ⾏)，使过去各时间步⼩批量随机梯度权值之和为 1。

[8]: class Adam(OptimizerBase):   
```python
def __init__(  
    self,  
    lr=0.001,  
    decay1=0.9,  
    decay2=0.999,  
    eps=1e-7,  
**kwargs  
):  
    '''  
lr float (default: 0.01)  
eps delta 0  
decay1 (default: 0.9)  
decay2 (default: 0.999)  
'''  
super().__init__(  
self.lr = lr  
self.decay1 = decay1  
self.decay2 = decay2  
self.eps = eps  
self.cache = {}  
def __str__(self):  
return "Adam(lr {}, decay1 {}, decay2 {}, eps {})".format(  
    self.lr, self.decay1, self.decay2, self.eps)  
)  
def update(self, param, param_grad, param_name):  
C = self.cache  
d1, d2 = selfhyperparams["decay1"], selfhyperparams["decay2"]  
lr, eps = selfhyperparams["lr"], self.hyperparams["eps"]  
if param_name not in C: 
```

使用上述优化算法，MNIST 数据集测试  
```python
C[param_name] = { "t": 0, "mean": np.zeros_like(param_grad), "var": np.zeros_like(param_grad), } t = C[param_name][t"] + 1 mean = C[param_name]["mean"] var = C[param_name]["var"] C[param_name][t"] = t C[param_name]["mean"] = d1 * mean + (1 - d1) * param_grad C[param_name]["var"] = d2 * var + (1 - d2) * param_grad ** 2 self.cache = C m_hat = C[param_name]["mean"] / (1 - d1 ** t) v_hat = C[param_name]["var"] / (1 - d2 ** t) update = lr * m_hat / (np.sqrt(v_hat) + eps) return param - update   
@property   
def hyperparams(self): return { "op": "Adam", "lr": self.lr, "eps": self.eps, "decay1": self.decay1, "decay2": self.decay2 } 
```

[9]: from chapter6 import DFN   
```python
[10]:   
```
```
```
def load_data(path="../data/mnist/mnist.npz"): 
    f = np.load(path) 
    X_train, y_train = f['x_train'], f['y_train'] 
    X_test, y_test = f['x_test'], f['y_test'] 
    f.close() 
    return (X_train, y_train), (X_test, y_test) 
(X_train, y_train), (X_test, y_test) = load_data()
y_train = np.eye(10)[y_train.astype(int)] 
y_test = np.eye(10)[y_test.astype(int)] 
X_train = X_train.reshape(-1, X_train.shape[1]*X_train.shape[2]).dtype('float32')
X_test = X_testreshape(-1, X_test.shape[1]*X_test.shape[2]).dtype('float32') 
print(X_train.shape, y_train.shape) 
N = 20000 # 20000 
indices = np.random.permutation(range(X_train.shape[0]))[:N] 
X_train, y_train = X_train[indices], y_train[indices] 
print(X_train.shape, y_train.shape) 
X_train /= 255 
X_train = (X_train - 0.5) * 2 
X_test /= 255 
X_test = (X_test - 0.5) * 2 
```

```txt
(60000, 784) (60000, 10) 
```

```txt
(20000, 784) (20000, 10) 
```

[11]:

```python
```
SGD
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="sgd(lr=0.01") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False) 
print("sgd -- accuracy:{}".format(model.evalu(e(X_test, y_test))) 
```

```txt
sgd -- accuracy:0.8951 
```

[12]:

```python
"Momentum"
"Momentum
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="momentum(lr=0.01, momentum=0.95)") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False)
print("momentum -- accuracy:{})".format(model.evalu(e(X_test, y_test))) 
```

```txt
momentum -- accuracy:0.9604 
```

[13]:

```txt
```
AdaGrad
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="adagrad(lr=0.01, eps=1e-7") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False) 
print("adagrad -- accuracy:{}" format(model.evaluate(X_test, y_test))) 
```

```batch
adagrad -- accuracy:0.9503 
```

[14]:

```txt
```
RMSProp
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="rmsprop(lr=0.001, eps=1e-7, decay=0.95)") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False) 
print("rmsprop -- accuracy:{})".format(model.evaluate(X_test, y_test))) 
```

```txt
rmsprop -- accuracy:0.9614 
```

[15]:

```txt
```
AdaDelta
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="adadelta(eps=1e-7, decay=0.95)") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False)
print("adadelta -- accuracy:{}" format(model.evaluate(X_test, y_test))) 
```

```batch
adadelta -- accuracy:0.9624 
```

[16]:

```python
```
Adam
```
model = DFN(hidden_dims_1=200, hidden_dims_2=10, optimizer="adam(lr=0.001, decay1=0.9, decay2=0.999, eps=1e-7)") 
model.fit(X_train, y_train, n_epochs=20, batch_size=64, epoverbose=False) 
print("adam -- accuracy:{}" format(model.evalu(e(X_test, y_test))) 
```

```txt
adam -- accuracy:0.9667 
```

# 1.4 二阶近似方法

# 1.4.1 牛顿法

梯度下降使⽤的梯度信息实际上是一阶导数，⽽⽜顿法除了⼀阶导数外，还会使⽤二阶导数的信息。根据导数的定义，⼀阶导描述的是函数值的变化率，即斜率；⼆阶导描述的则是斜率的变化率，即曲线的弯曲程度——曲率。为简单起见，我们从泰勒展开说起：

$$
f (x) \approx f \left(x _ {0}\right) + f ^ {\prime} (x) \left(x - x _ {0}\right) + \frac {f ^ {\prime \prime} (x)}{2} \left(x - x _ {0}\right) ^ {2} \tag {8}
$$

我们可以通过 $x _ { 0 }$ 去估计 $x _ { \mathrm { ~ ~ } }$ 。⽜顿法的思想也从中⽽来，我们可以通过在现有极⼩值点估计值的附近对 $f ( x )$ 做⼆阶泰勒展开，进⽽找到极⼩值的下⼀个估计值。设 $x _ { k }$ 为当前的极⼩点估计值，则：

$$
f (x) \approx f \left(x _ {k}\right) + f ^ {\prime} \left(x _ {k}\right) \left(x - x _ {k}\right) + \frac {f ^ {\prime \prime} \left(x _ {k}\right)}{2} \left(x - x _ {k}\right) ^ {2} \tag {9}
$$

由极值的必要条件可知，新的极⼩值应该满⾜： $f ^ { \prime } ( x ) = 0 _ { \circ }$ 。于是：

$$
f \left(x _ {k}\right) + \frac {f ^ {\prime \prime} (x)}{2} \left(x - x _ {k}\right) ^ {2} = 0 \tag {10}
$$

进⽽得到新的极⼩值点：

$$
x = x _ {k} - \frac {f ^ {\prime} \left(x _ {k}\right)}{f ^ {\prime \prime} \left(x _ {k}\right)} \tag {11}
$$

这样⼀来，我们就可以构造序列 $\{ x _ { k } \}$ 来逼近 $f ( x )$ 的极⼩点。

我们推⼴到⾼维下的 $x$ (维数为 $n$ )，⼆阶泰勒展开可以写作：

$$
f (\boldsymbol {x}) \approx f (\boldsymbol {x} _ {k}) + \nabla f (\boldsymbol {x} _ {k}) (\boldsymbol {x} - \boldsymbol {x} _ {k}) + \frac {1}{2} (\boldsymbol {x} - \boldsymbol {x} _ {k}) ^ {\top} \nabla^ {2} f (\boldsymbol {x} _ {k}) (\boldsymbol {x} - \boldsymbol {x} _ {k}) \tag {12}
$$

其中：

$$
\nabla^ {2} f (\boldsymbol {x}) = \left[ \begin{array}{c c c c} \frac {\partial^ {2} f}{\partial x _ {1} ^ {2}} & \frac {\partial^ {2} f}{\partial x _ {1} \partial x _ {2}} & \dots & \frac {\partial^ {2} f}{\partial x _ {1} \partial x _ {n}} \\ \frac {\partial^ {2} f}{\partial x _ {2} \partial x _ {1}} & \frac {\partial^ {2} f}{\partial x _ {2} ^ {2}} & \dots & \frac {\partial^ {2} f}{\partial x _ {2} \partial x _ {n}} \\ & & \ddots & \\ \frac {\partial^ {2} f}{\partial x _ {n} \partial x _ {1}} & \frac {\partial^ {2} f}{\partial x _ {n} \partial x _ {2}} & \dots & \frac {\partial^ {2} f}{\partial x _ {n} ^ {2}} \end{array} \right] \tag {13}
$$

我们通常称 $\nabla f$ 为 $f$ 的梯度向量，同时记 $\nabla ^ { 2 } f$ 为 $\operatorname { H } ( f )$ ，称为海森矩阵，它是个对称矩阵。同样地，我们根据极值必要条件，可得 $\nabla f ( { \pmb x } ) = 0 \mathrm { _ { c } }$ 。在泰勒展开等式两边同时作⽤⼀个梯度算⼦，可以得到：

$$
\nabla f _ {k} + \mathrm {H} _ {k} (\boldsymbol {x} - \boldsymbol {x} _ {k}) = 0 \tag {14}
$$

如果矩阵 $\mathrm { H } _ { k }$ ⾮奇异，则可以得到：

$$
\boldsymbol {x} = \boldsymbol {x} _ {k} - \mathrm {H} _ {k} ^ {- 1} \nabla f _ {k} \tag {15}
$$

于是可以得到迭代公式：

$$
\boldsymbol {x} _ {k + 1} = \boldsymbol {x} _ {k} - \mathrm {H} _ {k} ^ {- 1} \nabla f _ {k}, \quad k = 0, 1, \dots \tag {16}
$$

同样地，我们考虑损失函数下的问题，同样进⾏⼆阶泰勒展开：

$$
J (\theta) \approx J \left(\theta_ {0}\right) + \left(\theta - \theta_ {0}\right) ^ {\top} \nabla_ {\theta} J \left(\theta_ {0}\right) + \frac {1}{2} \left(\theta - \theta_ {0}\right) ^ {\top} \mathrm {H} \left(\theta - \theta_ {0}\right) \tag {17}
$$

于是，迭代公式为：

$$
\boldsymbol {\theta} _ {k + 1} = \boldsymbol {\theta} _ {k} - \mathrm {H} _ {k} ^ {- 1} \nabla J _ {k}, \quad k = 0, 1, \dots \tag {18}
$$

具体来说，更新公式为：

$$
g \leftarrow \frac {1}{m} \nabla_ {\theta} \sum_ {i} J (f (\boldsymbol {x} ^ {(i)}; \theta), y ^ {(i)})
$$

$$
\mathrm {H} \leftarrow \frac {1}{m} \nabla_ {\theta} ^ {2} \sum_ {i} J \left(f \left(\boldsymbol {x} ^ {(i)}; \theta\right), y ^ {(i)}\right) \tag {19}
$$

$$
\Delta \theta \gets - \mathrm {H} ^ {- 1} g
$$

$$
\theta \leftarrow \theta + \Delta \theta
$$

当⽬标函数是⼆次函数时，则⼆次泰勒展开函数和原⽬标函数完全相同，对应此时的⼆次求导下的海森矩阵退化为常数矩阵。经过⼀次迭代后就可到达原⽬标函数的极⼩点，因此⽜顿法是具有⼆次收敛性。⽽对⾮⼆次函数，如果函数的⼆次性态较强，或者迭代点进⼊极⼩点的邻域，此时⽜顿法也很快的。

# 几何理解

⽜顿法就是⽤⼀个二次曲面去拟合当前所处位置的局部曲⾯；⽽梯度下降法是⽤⼀个平⾯去拟合当前的局部曲⾯。

通常情况下，⼆次曲⾯的拟合会⽐平⾯更好，所以⽜顿法选择的下降路径会更符合真实的最优下降路径。

# 通俗理解

找⼀条最短的路径⾛到⼀个盆地的最底部，梯度下降法每次只从当前所处位置选⼀个坡度最⼤的⽅向⾛⼀步；⽜顿法在选择⽅向时，不仅会考虑坡度是否够⼤，还会考虑⾛了⼀步之后，坡度是否会变得更大 (考虑梯度变化的趋势)。所以，⽜顿法⽐梯度下降法看得更远，能更快地⾛到最底部。

• 优点

– 收敛速度快，能⽤更少的迭代次数找到最优解。

• 缺点

– 每⼀步都需要求解⽬标函数的 Hessian 矩阵的逆矩阵，计算复杂。  
– ⽜顿法是局部收敛的，当初始点选择不当时，往往导致不收敛。  
– ⼆阶 Hessian 矩阵必须可逆，否则算法进⾏困难。

# 1.4.2 拟牛顿法

⽜顿法虽然收敛快，但是需要计算海森矩阵，同时还要保证海森矩阵⾮奇异，这使得⽜顿法失效。为了克服这两个问题，便提出来拟⽜顿法。其基本思想是：不用二阶偏导数，而是在 “拟牛顿” 的条件下优化目标函数，直接构造出可以近似海森矩阵 (或海森矩阵的逆) 的正定对称阵。

# 拟牛顿条件

回到前⾯描述的⼆阶泰勒展开，在第 $k + 1$ 次迭代进⾏展开：

$$
f (\boldsymbol {x}) \approx f \left(\boldsymbol {x} _ {k + 1}\right) + \nabla f \left(\boldsymbol {x} _ {k + 1}\right) \left(\boldsymbol {x} - \boldsymbol {x} _ {k + 1}\right) + \frac {1}{2} \left(\boldsymbol {x} - \boldsymbol {x} _ {k + 1}\right) ^ {\top} \mathrm {H} _ {k + 1} \left(\boldsymbol {x} - \boldsymbol {x} _ {k + 1}\right) \tag {20}
$$

两边同时作⽤梯度算⼦ $\nabla$ ，得到：

$$
\nabla f (\boldsymbol {x}) \approx \nabla f \left(\boldsymbol {x} _ {k + 1}\right) + \mathrm {H} _ {k + 1} \left(\boldsymbol {x} - \boldsymbol {x} _ {k + 1}\right) \tag {21}
$$

令 ${ \pmb x } = { \pmb x } _ { k }$ ：

$$
\nabla f \left(\boldsymbol {x} _ {k + 1}\right) - \nabla f (\boldsymbol {x}) \approx \mathrm {H} _ {k + 1} \left(\boldsymbol {x} _ {k + 1} - \boldsymbol {x} _ {k}\right) \tag {22}
$$

现在，我们简化标记，令 $\begin{array} { r } { \pmb { s } _ { k } = \pmb { x } _ { k + 1 } - \pmb { x } _ { k } , \pmb { y } _ { k } = \nabla f ( \pmb { x } _ { k + 1 } ) - \nabla f ( \pmb { x } ) } \end{array}$ 。于是有：

$$
\boldsymbol {y} _ {k} \approx \mathrm {H} _ {k + 1} \boldsymbol {s} _ {k} \quad \text {或 者} \quad \boldsymbol {s} _ {k} \approx \mathrm {H} _ {k + 1} ^ {- 1} \boldsymbol {y} _ {k} \tag {23}
$$

这便是拟⽜顿条件，它对迭代过程中的 $\mathrm { H } _ { k + 1 }$ 做了约束。在迭代过程中，我们会⽤矩阵 $\textbf {  { B } }$ 去近似海森矩阵 H，⽤矩阵 $\pmb { D }$ 去近似海森矩阵的逆 $\mathrm { H } ^ { - 1 }$ 。那么我们可以进⼀步写成：

$$
\boldsymbol {y} _ {k} = \boldsymbol {B} _ {k + 1} \boldsymbol {s} _ {k} \quad \text {或 者} \quad \boldsymbol {s} _ {k} = \boldsymbol {D} _ {k + 1} \boldsymbol {y} _ {k} \tag {24}
$$

# DFP 算法

DFP 算法的核⼼是：通过迭代的⽅法，对 $\mathrm { H } ^ { - 1 }$ 近似。迭代过程为：

$$
\boldsymbol {D} _ {k + 1} = \boldsymbol {D} _ {k} + \Delta \boldsymbol {D} _ {k}, \quad k = 0, 1 \dots \tag {25}
$$

其中 $D _ { 0 }$ 通常取单位矩阵，⽽ $\Delta \pmb { D } _ { k }$ ⼀般⽤ “待定法” 计算。具体来说，设校正矩阵 $\Delta D _ { k } = \alpha \pmb { u } \pmb { u } ^ { \top } + \beta \pmb { v } \pmb { v } ^ { \top }$ ，其中 $\alpha$ 和 $\beta$ 是待定参数。这样的待定法可以保证 $\Delta \pmb { D } _ { k }$ 的对称性。

我们将 “待定法” ⽤到海森矩阵的近似中：

$$
\begin{array}{l} \boldsymbol {s} _ {k} = \left(\boldsymbol {D} _ {k} + \alpha \boldsymbol {u} \boldsymbol {u} ^ {\top} + \beta \boldsymbol {v} \boldsymbol {v} ^ {\top}\right) \boldsymbol {y} _ {k} \\ = \boldsymbol {D} _ {k} \boldsymbol {y} _ {k} + \boldsymbol {u} \left(\alpha \boldsymbol {u} ^ {\top} \boldsymbol {y} _ {k}\right) + \boldsymbol {v} \left(\beta \boldsymbol {v} ^ {\top} \boldsymbol {y} _ {k}\right) \tag {26} \\ = \boldsymbol {D} _ {k} \boldsymbol {y} _ {k} + (\alpha \boldsymbol {u} ^ {\top} \boldsymbol {y} _ {k}) \boldsymbol {u} + (\beta \boldsymbol {v} ^ {\top} \boldsymbol {y} _ {k}) \boldsymbol {v} \\ \end{array}
$$

$\alpha { \pmb u } ^ { \top } { \pmb y } _ { k }$ 和 $\beta \pmb { v } ^ { \top } \pmb { y } _ { k }$ 既是常数，我们可以简单赋值为 1 和 -1。于是，我们可以得到：

$$
\alpha = \frac {1}{\boldsymbol {u} ^ {\top} \boldsymbol {y} _ {k}} \tag {27}
$$

$$
\beta = - \frac {1}{\boldsymbol {v} ^ {\top} \boldsymbol {y} _ {k}}
$$

将 $\alpha$ 和 $\beta$ 代⼊回去，可以得到： $\pmb { u } - \pmb { v } = \pmb { s } _ { k } - D _ { k } \pmb { y } _ { k }$ 。于是，我们不妨取 ${ \pmb u } = { \pmb s } _ { k }$ ， $\pmb { v } = \pmb { D } _ { k } \pmb { y } _ { k }$ 。再代⼊回上述表达式中，得到：

$$
\alpha = \frac {1}{\boldsymbol {s} _ {k} ^ {\top} \boldsymbol {y} _ {k}} \tag {28}
$$

$$
\beta = - \frac {1}{\left(\boldsymbol {D} _ {k} \boldsymbol {y} _ {k}\right) ^ {\top} \boldsymbol {y} _ {k}} = - \frac {1}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {D} _ {k} \boldsymbol {y} _ {k}}
$$

最后，我们得到校正矩阵的形式：

$$
\Delta \boldsymbol {D} _ {k} = \frac {\boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {s} _ {k} ^ {\top} \boldsymbol {y} _ {k}} - \frac {\boldsymbol {D} _ {k} \boldsymbol {y} _ {k} \boldsymbol {y} _ {k} ^ {\top} \boldsymbol {D} _ {k}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {D} _ {k} \boldsymbol {y} _ {k}} \tag {29}
$$

于是，我们得到 DFP 算法的步骤：

• 根据 $- { \cal D } _ { k } g _ { k }$ 得到搜索⽅向 $\scriptstyle d _ { k }$ ，再考虑步长 $\lambda _ { k }$ (可以⽤ Line Search 获得) 得到 $\mathbf { \pmb { s } } _ { k } = \lambda _ { k } \pmb { d } _ { k }$ 。这样便得到新⼀次迭代的 $\pmb { x } _ { k + 1 }$   
• 计算 $\nabla f ( \pmb { x } _ { k } )$ ( 如果 $| | \nabla f ( \pmb { x } _ { k } ) | | < \epsilon$ 则结束)。进⼀步计算 ${ \pmb y } _ { k }$ 和 $\Delta \pmb { D } _ { k }$ ，从⽽得到 $D _ { k + 1 }$ 。

# BFGS 算法

BFGS 算法的思路同 DFP 算法，区别在于近似海森矩阵 $\mathrm { H } _ { \circ }$ 。设校正矩阵 $\Delta B _ { k } = \alpha \pmb { u } \pmb { u } ^ { \top } + \beta \pmb { v } \pmb { v } ^ { \top }$ 。可以化简得：

$$
\boldsymbol {y} _ {k} = \boldsymbol {B} _ {k} \boldsymbol {s} _ {k} + (\alpha \boldsymbol {u} ^ {\top} \boldsymbol {s} _ {k}) \boldsymbol {u} + (\beta \boldsymbol {v} ^ {\top} \boldsymbol {s} _ {k}) \boldsymbol {v} \tag {30}
$$

令 $\alpha \pmb { u } ^ { \top } \pmb { s } _ { k } = 1$ 以及 $\beta \pmb { v } ^ { \top } \pmb { s } _ { k } = - 1$ 。同时，取 $\mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathrm  ~ \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \mu } _ { \mathbf { \mu } } \mathrm { ~ \mathbf { \mu } _ { \mathbf { \mu } } \mathbf { \Lambda } _ { \mathbf { \mu } } \mathrm { ~ \mu } _ { \mathbf { \mu } } } \mathrm { ~ \mathbf { \Lambda } _ { \mu } } \mathrm { ~ \mathbf { \Lambda } _ { \mu } } \mathrm { ~ \mathbf { \Lambda } _ { \mu } }$ ， $\pmb { v } = \pmb { B } _ { k } \pmb { s } _ { k }$ 。可得：

$$
\alpha = \frac {1}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} \tag {31}
$$

$$
\beta = - \frac {1}{\left(\boldsymbol {B} _ {k} \boldsymbol {s} _ {k}\right) ^ {\top} \boldsymbol {s} _ {k}} = - \frac {1}{\boldsymbol {s} _ {k} ^ {\top} \boldsymbol {B} _ {k} \boldsymbol {s} _ {k}} \tag {31}
$$

所以，校正矩阵的形式为：

$$
\Delta \boldsymbol {B} _ {k} = \frac {\boldsymbol {y} _ {k} \boldsymbol {y} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} - \frac {\boldsymbol {B} _ {k} \boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top} \boldsymbol {B} _ {k}}{\boldsymbol {s} _ {k} ^ {\top} \boldsymbol {B} _ {k} \boldsymbol {s} _ {k}} \tag {32}
$$

于是，我们得到 BFGS 算法的步骤：

• 根据 $- B _ { k } ^ { - 1 } \pmb { g } _ { k }$ 得到搜索⽅向 $\scriptstyle d _ { k }$ ，再考虑步长 $\lambda _ { k }$ 得到 $\mathbf { \pmb { s } } _ { k } = \lambda _ { k } \pmb { d } _ { k }$ 。这样便得到新⼀次迭代的 $\mathbf { \boldsymbol { x } } _ { k + 1 }$ 。  
• 计算 $\nabla f ( \pmb { x } _ { k } )$ ( 如果 $| | \nabla f ( \pmb { x } _ { k } ) | | < \epsilon$ 则结束)。进⼀步计算 ${ \pmb y } _ { k }$ 和 $\Delta \mathbfit { B } _ { k }$ ，从⽽得到 $B _ { k + 1 }$ 。

如何计算 $- B _ { k } ^ { - 1 } g _ { k }$

这⾥需要注意的是如何计算 $- B _ { k } ^ { - 1 } \pmb { g } _ { k } \circ$ 。⼀种⽅法是解线性⽅程组 $B _ { k } d _ { k } = - { \pmb g } _ { k }$ 。另⼀种⽅法是借⽤ Sherman-Morrison 公式。

Sherman-Morrison 公式：

假设 $\ b { A } \in \mathbb { R } ^ { n \times n }$ 为⾮奇异矩阵， $\ b { x } , \ b { y } \in \mathbb { R } ^ { n }$ ，如果 $\ b { 1 } + \pmb { y } ^ { \top } \pmb { A x } \neq 0$ ，则有：

$$
\left(\boldsymbol {A} + \boldsymbol {x} \boldsymbol {y} ^ {\top}\right) ^ {- 1} = \boldsymbol {A} ^ {- 1} - \frac {\boldsymbol {A} ^ {- 1} \boldsymbol {x} \boldsymbol {y} ^ {\top} \boldsymbol {A} ^ {- 1}}{1 + \boldsymbol {y} ^ {\top} \boldsymbol {A} \boldsymbol {x}} \tag {33}
$$

现在，我们⽤ Sherman-Morrison 公式，可以直接获得 $B _ { k + 1 } ^ { - 1 }$ 和 $B _ { k } ^ { - 1 }$ 间的递推关系。然后我们将 $B _ { k } ^ { - 1 }$ 表⽰为 $D _ { k } ^ { - 1 }$ ，这样就不⽤计算取逆操作。⾸先，我们看⼀下递推结果：

$$
\boldsymbol {B} _ {k + 1} ^ {- 1} = \left(I - \frac {\boldsymbol {s} _ {k} \boldsymbol {y} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) \boldsymbol {B} _ {k} ^ {- 1} \left(I - \frac {\boldsymbol {y} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) + \frac {\boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} \tag {34}
$$

然后我们简单说⼀下证明思路，考虑原本的递推式为：

$$
\boldsymbol {B} _ {k + 1} = \boldsymbol {B} _ {k} + \frac {\boldsymbol {y} _ {k} \boldsymbol {y} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} - \frac {\boldsymbol {B} _ {k} \boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top} \boldsymbol {B} _ {k}}{\boldsymbol {s} _ {k} ^ {\top} \boldsymbol {B} _ {k} \boldsymbol {s} _ {k}} \tag {35}
$$

1. ⾸先，令 $\begin{array} { r } { \mathrm { H } _ { k } = B _ { k } + \frac { { y } _ { k } { y } _ { k } ^ { \top } } { { y } _ { k } ^ { \top } s _ { k } } , } \end{array}$ 我们再⽤ Sherman-Morrison 公式，可以得到 $B _ { k + 1 } ^ { - 1 }$ 的表达式。  
2. 再⼀次对 $\mathrm { H } _ { k }$ 使⽤ Sherman-Morrison 公式得到 $\mathrm { H } _ { k } ^ { - 1 }$ 的表达式。

3. 最后我们将 $\mathrm { H } _ { k } ^ { - 1 }$ 的表达式代回 $B _ { k + 1 } ^ { - 1 }$ 的表达式中得到 $B _ { k + 1 } ^ { - 1 }$ 与 $B _ { k } ^ { - 1 }$ 的递推式。

我们令 $B _ { k } ^ { - 1 }$ 表⽰为 $D _ { k } ^ { - 1 }$ ，递推式如下：

$$
\boldsymbol {D} _ {k + 1} = \left(I - \frac {\boldsymbol {s} _ {k} \boldsymbol {y} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) \boldsymbol {D} _ {k} \left(I - \frac {\boldsymbol {y} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) + \frac {\boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} \tag {36}
$$

最后，我们看⼀下此时 BFGS 算法的步骤：

• 根据 $- { \cal D } _ { k } g _ { k }$ 得到搜索⽅向 $\scriptstyle d _ { k }$ ，再考虑步长 $\lambda _ { k }$ 得到 $\mathbf { \pmb { s } } _ { k } = \lambda _ { k } \pmb { d } _ { k }$ 。这样便得到新⼀次迭代的 $\mathbf { \boldsymbol { x } } _ { k + 1 }$ 。  
• 计算 $\nabla f ( \pmb { x } _ { k } )$ ( 如果 $\| \nabla f ( \pmb { x } _ { k } ) \| < \epsilon$ 则结束)。进⼀步计算 ${ \pmb y } _ { k }$ ，从⽽得到 $D _ { k + 1 }$ 。

# L-BFGS 算法

前⾯的两个算法要构造 $n \times n$ 的矩阵 $\mathit { \Pi } _ { n }$ 为特征维数)，存储矩阵 (每次迭代都要存储⼀个矩阵) 仍需要耗费很多的资源。但考虑矩阵 $\scriptstyle D _ { k }$ 的对称性，存储时只需存储⼀半矩阵数据。但是否可以还减少存储消耗？

这便有了 L-BFGS 算法 (Limited-memory BFGS)。其基本思想是：不再存储完整的矩阵 $D _ { k }$ ，⽽是存储计算过程中的 $\mathbf { \delta } _ { s _ { i } }$ ， ${ \bf { \nabla } } \mathbf { \mathbf { { y } } } _ { i }$ 。需要矩阵 $D _ { k }$ 时，利⽤向量计算得到。我们修改迭代公式：

$$
\boldsymbol {D} _ {k + 1} = \left(I - \frac {\boldsymbol {s} _ {k} \boldsymbol {y} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) \boldsymbol {D} _ {k} \left(I - \frac {\boldsymbol {y} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}}\right) + \frac {\boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top}}{\boldsymbol {y} _ {k} ^ {\top} \boldsymbol {s} _ {k}} \tag {37}
$$

如果令 $\begin{array} { r } { \rho _ { k } = \frac { 1 } { \pmb { y } _ { k } ^ { \top } s _ { k } } } \end{array}$ ， $V _ { k } = I - \rho _ { k } \pmb { y } _ { k } \pmb { s } _ { k } ^ { \top }$ ，则上式可以写作：

$$
\boldsymbol {D} _ {k + 1} = \boldsymbol {V} _ {k} ^ {\top} \boldsymbol {D} _ {k} \boldsymbol {V} _ {k} + \rho_ {k} \boldsymbol {s} _ {k} \boldsymbol {s} _ {k} ^ {\top} \tag {38}
$$

我们看⼀下 $D _ { k + 1 }$ 的⽣成，假设初始矩阵 $D _ { 0 }$ 为单位阵 $I$ ：

$$
\boldsymbol {D} _ {1} = \boldsymbol {V} _ {0} ^ {\top} \boldsymbol {D} _ {0} \boldsymbol {V} _ {0} + \rho_ {0} \boldsymbol {s} _ {0} \boldsymbol {s} _ {0} ^ {\top} \tag {39}
$$

$$
\boldsymbol {D} _ {2} = \boldsymbol {V} _ {1} ^ {\top} \boldsymbol {D} _ {1} \boldsymbol {V} _ {1} + \rho_ {1} \boldsymbol {s} _ {1} \boldsymbol {s} _ {1} ^ {\top} = \boldsymbol {V} _ {1} ^ {\top} \boldsymbol {V} _ {0} ^ {\top} \boldsymbol {D} _ {0} \boldsymbol {V} _ {0} \boldsymbol {V} _ {1} + \boldsymbol {V} _ {1} ^ {\top} \rho_ {0} \boldsymbol {s} _ {0} \boldsymbol {s} _ {0} ^ {\top} \boldsymbol {V} _ {1} + \rho_ {1} \boldsymbol {s} _ {1} \boldsymbol {s} _ {1} ^ {\top}
$$

更⼀般地，我们得到迭代公式：

$$
\begin{array}{l} \boldsymbol {D} _ {k + 1} = \left(\boldsymbol {V} _ {k} ^ {\top} \boldsymbol {V} _ {k - 1} ^ {\top} \dots \boldsymbol {V} _ {0} ^ {\top}\right) \boldsymbol {D} _ {0} \left(\boldsymbol {V} _ {0} \dots \boldsymbol {V} _ {k - 1} \boldsymbol {V} _ {k}\right) \\ + (\pmb {V} _ {k} ^ {\top} \pmb {V} _ {k - 1} ^ {\top} \dots \pmb {V} _ {1} ^ {\top}) (\rho_ {0} \pmb {s} _ {0} \pmb {s} _ {0} ^ {\top}) (\pmb {V} _ {1} \dots \pmb {V} _ {k - 1} \pmb {V} _ {k}) \\ + \left(\boldsymbol {V} _ {k} ^ {\top} \boldsymbol {V} _ {k - 1} ^ {\top} \dots \boldsymbol {V} _ {2} ^ {\top}\right) \left(\rho_ {1} \boldsymbol {s} _ {1} \boldsymbol {s} _ {1} ^ {\top}\right) \left(\boldsymbol {V} _ {2} \dots \boldsymbol {V} _ {k - 1} \boldsymbol {V} _ {k}\right) \tag {40} \\ + \dots \\ + \boldsymbol {V} _ {k} ^ {\top} \left(\rho_ {k - 1} \boldsymbol {s} _ {k - 1} \boldsymbol {s} _ {k - 1} ^ {\top}\right) \boldsymbol {V} _ {k} \\ + \rho_ {k - 1} \boldsymbol {s} _ {k - 1} \boldsymbol {s} _ {k - 1} ^ {\top} \\ \end{array}
$$

# 2 优化策略

# 2.1 参数初始化

神经⽹络的训练过程中的参数学习是基于梯度下降法进⾏优化的。梯度下降法需要在开始训练时给每⼀个参数赋⼀个初始值。这个初始值的选取⼗分关键。⼀般希望数据和参数的均值都为 0，输入和输出数据的方差一致。在实际应⽤中，参数服从⾼斯分布或者均匀分布都是⽐较有效的初始化⽅式。

初始参数需要在不同单元间破坏对称性。如果具有相同激活函数的两个隐藏单元连接到相同的输⼊，那么这些单元必须具有不同的初始参数。如果它们具有相同的初始参数，然后应⽤到确定性损失和模型的确定性学习算法将一直以相同的方式更新这两个单元。

更大的初始权重具有更强的破坏对称性的作⽤，但也会在前向传播或反向传播中产⽣爆炸的值。如在循环⽹络中，很⼤的权重也可能导致混沌。因此，⼀般不要全零初始化或者具有较⼤数的随机初始化。

初始化策略有：

# 1、随机初始化方法

• 正态化的随机初始化 (Random Normal)：它是从以 0 为中⼼，标准差为 std 的正态分布中抽取样本。  
• 标准化的随机初始化 (Random Uniform)：它是从 [ 1,1] 中的均匀分布中抽取样本。

# 2、Glorot 初始化方法

Glorot 初始化，也称为 Xavier 初始化。⾸先，我们考虑隐藏层 $z = W ^ { \top } x$ 以及 $\pmb { a } = \sigma ( z )$ ，Glorot 初始化认为⼀个好的初始化应该在各个层的激活值 $^ { a }$ 的⽅差保持⼀致，即对于第 $i$ 层和第 $j$ 层，有 $\mathrm { V a r } ( a ^ { i } ) = \mathrm { V a r } ( a ^ { j } )$ ，同时各个层对状态 $_ z$ 的梯度的⽅差要保持⼀致，即 $\begin{array} { r } { \mathrm { V a r } ( \frac { \partial J } { \partial z ^ { i } } ) = \mathrm { V a r } ( \frac { \partial J } { \partial z ^ { j } } ) } \end{array}$ 。我们先分析⼀边，我们视每个神经元为⼀个特征。假设单层神经元上的特征的⽅差⼀样，即 $\operatorname { V a r } ( x _ { k } ) = \operatorname { V a r } ( { \pmb x } )$ ，每⼀层的输⼊ $^ { a }$ 均值为 0，且初始时 $_ { z }$ 落在激活函数的线性区域，即 $\sigma ^ { \prime } ( z _ { l } ) \approx 1$ ， $l = \{ 1 , . . . , m \}$ ， $m$ 为该层神经元数⽬。于是：

$$
\begin{array}{l} \operatorname {V a r} \left(a _ {l} ^ {i}\right) = \operatorname {V a r} \left(\sigma \left(z _ {l} ^ {i}\right)\right) \\ = \operatorname {V a r} \left(z _ {l} ^ {i}\right) \\ = \operatorname {V a r} \left(\sum_ {k = 1} ^ {n} W _ {l k} * a _ {k} ^ {i - 1}\right) \tag {41} \\ = \sum_ {k = 1} ^ {n} \operatorname {V a r} \left(W _ {l k} * a _ {k} ^ {i - 1}\right) \\ = n \operatorname {V a r} (\mathrm {W} _ {l k}) \operatorname {V a r} (a _ {k} ^ {i - 1}) \\ = n \operatorname {V a r} (\boldsymbol {W}) \operatorname {V a r} (a ^ {i - 1}) \\ \end{array}
$$

由于 $\mathrm { V a r } ( { \bf a } _ { i } ) = \mathrm { V a r } ( { \bf a } _ { i - 1 } )$ ，故 $n \operatorname { V a r } ( \mathbf { W } ) = 1$ 。于是考虑⼀边的情况下， $\textstyle \operatorname { V a r } ( W ) = { \frac { 1 } { n } }$ ， $n$ 为输⼊神经元 (特征) 数⽬。同样考虑另⼀边，得到$\textstyle \operatorname { V a r } ( W ) = { \frac { 1 } { m } }$ ， $m$ 为输出神经元 (特征) 数⽬。我们综合考虑⼆者，得到 $\textstyle \operatorname { V a r } ( W ) = { \frac { 2 } { n + m } }$ 。

• 正态分布的 Glorot 初始化 (Glorot Normal)：它是从以 0 为中⼼，标准差为 std = √ 2fan +fan $\begin{array} { r } { s t d = \sqrt { \frac { 2 } { f a n _ { i n } + f a n _ { o u t } } } } \end{array}$ 的截断正态分布中抽取样本，其中 $f a n _ { i n }$ 是权值张量中的输⼊单位的数量， $f a n _ { o u t }$ 是权值张量中的输出单位的数量。  
• 均匀分布的 Glorot 初始化 (Glorot Uniform)：它是从 [−limit, limit] 中的均匀分布中抽取样本，其中 limit = √ 6fanin +fanout $\begin{array} { r } { l i m i t = \sqrt { \frac { 6 } { f a n _ { i n } + f a n _ { o u t } } } } \end{array}$ (将均匀分布的⽅差代⼊计算可得)， $f a n _ { i n }$ 是权值张量中的输⼊单位的数量， $f a n _ { o u t }$ 是权值张量中的输出单位的数量。

# 3、Kaiming 初始化方法

Kaiming 初始化，也称为 He 初始化，也称之为 MSRA 初始化。前⾯的 Glorot 初始化要求了激活函数关于 0 对称，因此不适⽤于 ReLU。Kaiming初始化的想法是⼀个好的初始化应该在各个层的状态值 $_ z$ 的⽅差保持⼀致，即对于第 i 层和第 $j$ 层，有 $\mathrm { V a r } ( z ^ { i } ) = \mathrm { V a r } ( z ^ { j } )$ 。这边只假设初始化的均值为 0，即 $\mathbb { E } ( W ) = 0$ ：

$$
\begin{array}{l} \operatorname {V a r} \left(z ^ {i}\right) = n \operatorname {V a r} \left(\boldsymbol {W} ^ {\top} a ^ {i - 1}\right) \\ = n \left[ \mathbb {E} \left(\boldsymbol {W} ^ {\top} a ^ {i - 1}\right) ^ {2} - \left(\mathbb {E} \left(\boldsymbol {W} ^ {\top} a ^ {i - 1}\right)\right) ^ {2} \right] \\ = n \left[ \mathbb {E} \left(\boldsymbol {W} ^ {2}\right) \mathbb {E} \left(\left(a ^ {i - 1}\right) ^ {2}\right) - \left(\mathbb {E} (\boldsymbol {W})\right) ^ {2} \left(\mathbb {E} \left(a ^ {i - 1}\right)\right) ^ {2} \right] \tag {42} \\ = n \mathbb {E} \left(\boldsymbol {W} ^ {2}\right) \mathbb {E} \left(\left(a ^ {i - 1}\right) ^ {2}\right) \\ = n \operatorname {V a r} (\boldsymbol {W}) \mathbb {E} \left(\left(a ^ {i - 1}\right) ^ {2}\right) \\ \end{array}
$$

⽽再计算 $\mathbb { E } ( ( a ^ { i - 1 } ) ^ { 2 } )$ ，需要注意的是，由于 $\mathbb { E } ( W ) = 0$ 且 $W$ 与 $a ^ { i - 1 }$ 独⽴，故 $\mathbb { E } ( z ^ { i } ) = 0$ ：

$$
\begin{array}{l} \mathbb {E} \left(a ^ {i - 1}\right) ^ {2} = \mathbb {E} \left(g \left(z ^ {i - 1}\right)\right) ^ {2} \\ = \int_ {- \infty} ^ {\infty} p (z ^ {i - 1}) \left(g \left(z ^ {i - 1}\right)\right) ^ {2} d z ^ {i - 1} \\ = \int_ {- \infty} ^ {0} p (z ^ {i - 1}) (g (z ^ {i - 1})) ^ {2} d z ^ {i - 1} + \int_ {0} ^ {\infty} p (z ^ {i - 1}) (g (z ^ {i - 1})) ^ {2} d z ^ {i - 1} \\ = 0 + \int_ {0} ^ {\infty} p \left(z ^ {i - 1}\right) \left(z ^ {i - 1}\right) ^ {2} d z ^ {i - 1} \tag {43} \\ = \frac {1}{2} \int_ {- \infty} ^ {\infty} p (z ^ {i - 1}) \left(z ^ {i - 1}\right) ^ {2} d z ^ {i - 1} \\ = \frac {1}{2} \mathbb {E} (z ^ {i - 1}) ^ {2} \\ = \frac {1}{2} \operatorname {V a r} \left(z ^ {i - 1}\right) \\ \end{array}
$$

于是我们得到 $\begin{array} { r } { \mathrm { V a r } ( z ^ { i } ) = \frac { 1 } { 2 } n \mathrm { V a r } ( { \pmb W } ) \mathrm { V a r } ( z ^ { i - 1 } ) } \end{array}$ ，由于 $\operatorname { V a r } ( z ^ { i } ) = \operatorname { V a r } ( z ^ { i - 1 } )$ ，可以得到 $\textstyle \operatorname { V a r } ( W ) = { \frac { 2 } { n } }$

• 正态分布的 Kaiming 初始化 (He Normal)：它是从以 0 为中⼼，标准差为 std = √ 2fan $\begin{array} { r } { s t d = \sqrt { \frac { 2 } { f a n _ { i n } } } } \end{array}$ 的截断正态分布中抽取样本，其中 $f a n _ { i n }$ 是权值张量中的输⼊单位的数量。  
• 均匀分布的 Kaiming 初始化 (He Uniform)：它是从 [−limit, limit] 中的均匀分布中抽取样本，其中 $\begin{array} { r } { l i m i t = \sqrt { \frac { 6 } { f a n _ { i n } } } } \end{array}$ fanin ， $f a n _ { i n }$ 是权值张量中的输⼊单位的数量。

# 4、Batch Normalization 初始化方法

Batch Normalization 会在后⽂介绍，使⽤ BN 时，减少了⽹络对参数初始值尺度的依赖，此时使⽤较⼩的标准差 (如 0.01) 进⾏初始化即可。

# 5、Pre-Train 初始化方法

借助预训练模型中参数作为新任务参数初始化的⽅式是⼀种简便易⾏且⼗分有效的模型参数初始化⽅法，这也是⽬前的主流⽅法之⼀。

```python
[17]: def calc_fan(weight_shape):  
    ""  
    fan-in fan-out  
weight_shape  
""  
if len(weight_shape) == 2: # 2  
    fan_in, fan_out = weight_shape  
else:  
    raise ValueError("Unrecognized weight dimension: {}.format(weight_shape))  
return fan_in, fan_out 
```

```txt
[18]: def random.uniform(weight_shape, b=1.0): W-Uniform(-b, b) weight_shape return np.random.uniform(-b, b, size=weight_shape) 
```

```python
[19]: def random_normal(weight_shape, std=1.0): W--- TruncatedNormal(O, std) weight_shape std return truncated_normal(0, std, weight_shape) 
```

```javascript
[20]: def he.uniform(weight_shape): W-Uniform(-b,b) b=sqrt(6/fan_in) ReLU 
```

```python
weight_shape
```
```
fan_in, fan_out = calc_fan(weight_shape)
b = np.sqrt(6 / fan_in)
return np.random.uniform(-b, b, size=weight_shape) 
```

[21]: def he_normal(weight_shape): W- TruncatedNormal(0, std) std=2/fan_in ReLU weight_shape fan_in, fan_out = calc_fan(weight_shape) std $=$ np.sqrt(2 / fan_in) return truncated_normal(0, std, weight_shape)

```txt
[22]: def glorot.uniform(weight_shape, gain=1.0): W-Uniform(-b,b) b=gain\*sqrt(6/(fan_in+fan_out)) tanh sigmoid weight_shape fan_in, fan_out = calc_fan(weight_shape) b = gain \* np.sqrt(6 / (fan_in + fan_out)) return np.random.uniform(-b,b,size=weight_shape) 
```

```python
[23]: def glorot_normal(weight_shape, gain=1.0): W--- TruncatedNormal(0, std) std=gain 2*2/(fan_in+fan_out) tanh sigmoid weight_shape   
"   
fan_in, fan_out = calc_fan(weight_shape) std = gain \* np.sqrt(2 / (fan_in + fan_out))   
return truncated_normal(0, std, weight_shape) 
```

```python
[24]: def truncated_normal(mean, std, out_shape): mean std out_shape samples = np.random.normal(loc=mean, scale=std, size=out_shape) reject = npistical_or(samples >= mean + 2 * std, samples <= mean - 2 * std) while any(reject(flatten)): resamples = np.random.normal(loc=mean, scale=std, size=reject-sum()) samples[reject] = resamples reject = npistical_or(samples >= mean + 2 * std, samples <= mean - 2 * std) return samples 
```

# 3 批标准化

批标准化 (Batch Normalization) 并不是⼀个优化算法，⽽是⼀个自适应的重参数化的⽅法，试图解决训练非常深的模型的困难。

BatchNorm 是基于 SGD 的，因为深层神经网络在非线性变换前的激活输⼊值随着⽹络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动(Covariate Shift)。之所以训练收敛慢，⼀般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近 (如对于 sigmoid 函数来说，激活输⼊值是⼤的负值或正值)，所以这导致反向传播时低层神经⽹络的梯度消失。

BatchNorm 是通过⼀定的规范化⼿段，把每层神经⽹络任意神经元这个输⼊值的分布强⾏拉回到均值为 0、方差为 1 的标准正态分布，把越来越偏的分布拉回标准分布，这样使得激活输⼊值落在非线性函数对输入比较敏感的区域，避免梯度消失问题产⽣，梯度变⼤使得学习收敛速度快。

BatchNorm 训练阶段的实现包括两个步骤：

• 对于某个神经元，如果 Batch 为 $m$ 个样本，⾸先计算在当前神经元处的均值 $\mu$ 与⽅差 $\sigma _ { \mathrm { ~ e ~ } }$ 。再对数据进⾏规范化，使得输⼊每个特征的分布均值为 0，⽅差为 1。再将输⼊经过⾮线性函数。  
• 步骤⼀让每⼀层⽹络的输⼊数据分布都变得稳定，但却导致了数据表达能⼒的缺失，因为通过变换操作改变了原有数据的信息表达。因此，引⼊参数 scale γ 和 ozset $\beta$ ，再对规范化后的数据进⾏线性变换，恢复数据本身的表达能力。

具体如下：

$$
\mu \leftarrow \frac {1}{m} \sum_ {i = 1} ^ {m} \boldsymbol {x} ^ {(i)}
$$

$$
\sigma^ {2} \gets \frac {1}{m} \sum_ {i = 1} ^ {m} (\pmb {x} ^ {(i)} - \mu) ^ {2}
$$

$$
\hat {\boldsymbol {x}} ^ {(i)} \leftarrow \frac {\boldsymbol {x} ^ {(i)} - \mu}{\sqrt {\sigma^ {2} + \epsilon}} \tag {44}
$$

$$
\hat {\boldsymbol {z}} ^ {(i)} \leftarrow \gamma \hat {\boldsymbol {x}} ^ {(i)} + \beta
$$

$$
\boldsymbol {a} ^ {(i)} \leftarrow f (\hat {\boldsymbol {z}} ^ {(i)})
$$

测试阶段使⽤训练阶段整个样本的统计量来对测试数据归⼀化。训练阶段保留每组 Batch 的 $\mu _ { b a t c h }$ 和 $\sigma _ { b a t c h }$ ，于是可以得到均值与⽅差的无偏估计。如下：

$$
\mu \leftarrow \mathbb {E} \left(\mu_ {\text {b a t c h}}\right)
$$

$$
\sigma^ {2} \leftarrow \frac {m}{m - 1} \mathbb {E} \left(\sigma_ {\text {b a t c h}} ^ {2}\right) \tag {45}
$$

# 反向传播过程：

• ⾸先，可以计算得出：

$$
\frac {\partial J}{\partial \gamma} = \frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}} \cdot \frac {\partial \hat {\boldsymbol {z}} ^ {(i)}}{\partial \gamma} = \boxed {\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}} \cdot \hat {\boldsymbol {x}} ^ {(i)}} \tag {46}
$$

$$
\frac {\partial J}{\partial \beta} = \frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}} \cdot \frac {\partial \hat {\boldsymbol {z}} ^ {(i)}}{\partial \beta} = \boxed {\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}}} \tag {47}
$$

$$
\frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} = \frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}} \cdot \frac {\partial \hat {\boldsymbol {z}} ^ {(i)}}{\partial \hat {\boldsymbol {x}} ^ {(i)}} = \boxed {\frac {\partial J}{\partial \hat {\boldsymbol {z}} ^ {(i)}} \cdot \gamma} \tag {48}
$$

然后，根据

$$
\left\{ \begin{array}{l} \frac {\partial \hat {\boldsymbol {x}} ^ {(i)}}{\partial \mu} = \frac {1}{\sqrt {\sigma^ {2} + \epsilon}} \cdot (- 1) \\ \frac {\partial \sigma^ {2}}{\partial \mu} = \frac {1}{m} \sum_ {i = 1} ^ {m} 2 \cdot \left(\boldsymbol {x} ^ {(i)} - \mu\right) \cdot (- 1) \\ \frac {\partial \hat {\boldsymbol {x}}}{\partial \sigma^ {2}} = \sum_ {i = 1} ^ {m} \left(\boldsymbol {x} ^ {(i)} - \mu\right) \cdot (- 0. 5) \cdot \left(\sigma^ {2} + \epsilon\right) ^ {- 0. 5 - 1} \end{array} \right. \tag {49}
$$

可以得到：

$$
\frac {\partial J}{\partial \sigma^ {2}} = \boxed {\frac {\partial J}{\partial \hat {\boldsymbol {x}}} \cdot \frac {\partial \hat {\boldsymbol {x}}}{\partial \sigma^ {2}}} \tag {50}
$$

以及：

$$
\begin{array}{l} \frac {\partial J}{\partial \mu} = \left(\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {- 1}{\sqrt {\sigma^ {2} + \epsilon}}\right) + \left(\frac {\partial J}{\partial \sigma^ {2}} \cdot \frac {1}{m} \sum_ {i = 1} ^ {m} - 2 (\boldsymbol {x} ^ {(i)} - \mu)\right) \\ = \left(\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {- 1}{\sqrt {\sigma^ {2} + \epsilon}}\right) + \left(\frac {\partial J}{\partial \sigma^ {2}} \cdot (- 2) \cdot \left(\frac {1}{m} \sum_ {i = 1} ^ {m} \boldsymbol {x} ^ {(i)} - \frac {1}{m} \sum_ {i = 1} ^ {m} \mu\right)\right) \\ = \left(\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {- 1}{\sqrt {\sigma^ {2} + \epsilon}}\right) + \left(\frac {\partial J}{\partial \sigma^ {2}} \cdot (- 2) \cdot \left(\mu - \frac {m \cdot \mu}{m}\right)\right) \tag {51} \\ = \boxed {\sum_ {i = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {- 1}{\sqrt {\sigma^ {2} + \epsilon}}} \\ \end{array}
$$

再根据

$$
\left\{ \begin{array}{l} \frac {\partial \hat {\boldsymbol {x}} ^ {(i)}}{\partial \boldsymbol {x} ^ {(i)}} = \frac {1}{\sqrt {\sigma^ {2} + \epsilon}} \\ \frac {\partial \mu}{\partial \boldsymbol {x} ^ {(i)}} = \frac {1}{m} \\ \frac {\partial \sigma^ {2}}{\partial \boldsymbol {x} ^ {(i)}} = \frac {2 (\boldsymbol {x} ^ {(i)} - \mu)}{m} \end{array} \right. \tag {52}
$$

计算得出：

$$
\begin{array}{l} \frac {\partial J}{\partial \boldsymbol {x} ^ {(i)}} = \left(\frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {1}{\sqrt {\sigma^ {2} + \epsilon}}\right) + \left(\frac {\partial J}{\partial \mu} \cdot \frac {1}{m}\right) + \left(\frac {\partial J}{\partial \sigma^ {2}} \cdot \frac {2 (\boldsymbol {x} ^ {(i)} - \mu)}{m}\right) \\ = \left(\frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot \frac {1}{\sqrt {\sigma^ {2} + \epsilon}}\right) + \left(\frac {1}{m} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} \cdot \frac {- 1}{\sqrt {\sigma^ {2} + \epsilon}}\right) - \left(0. 5 \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} \cdot (\boldsymbol {x} ^ {(j)} - \mu) \cdot (\sigma^ {2} + \epsilon) ^ {- 1. 5} \cdot \frac {2 (\boldsymbol {x} ^ {(i)} - \mu)}{m}\right) \\ = \left(\frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot (\sigma^ {2} + \epsilon) ^ {- 0. 5}\right) - \left(\frac {(\sigma^ {2} + \epsilon) ^ {- 0 . 5}}{m} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}}\right) - \left(\frac {(\sigma^ {2} + \epsilon) ^ {- 0 . 5}}{m} \cdot \frac {\boldsymbol {x} ^ {(i)} - \mu}{\sqrt {\sigma^ {2} + \epsilon}} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} \cdot \frac {(\boldsymbol {x} ^ {(j)} - \mu)}{\sqrt {\sigma^ {2} + \epsilon}}\right) \tag {53} \\ = \left(\frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} \cdot (\sigma^ {2} + \epsilon) ^ {- 0. 5}\right) - \left(\frac {(\sigma^ {2} + \epsilon) ^ {- 0 . 5}}{m} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}}\right) - \left(\frac {(\sigma^ {2} + \epsilon) ^ {- 0 . 5}}{m} \cdot \hat {\boldsymbol {x}} ^ {(i)} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} \cdot \hat {\boldsymbol {x}} ^ {(j)}\right) \\ = \boxed { \begin{array}{c} m \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(i)}} - \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} - \hat {\boldsymbol {x}} ^ {(i)} \sum_ {j = 1} ^ {m} \frac {\partial J}{\partial \hat {\boldsymbol {x}} ^ {(j)}} \cdot \hat {\boldsymbol {x}} ^ {(j)} \\ \hline m \sqrt {\sigma^ {2} + \epsilon} \end{array} } \\ \end{array}
$$

[25]: from chapter6 import LayerBase, CrossEntropy, OrderedDict, softmax, FullyConnected   
[26]: class BatchNorm1D(LayerBase):

```python
def __init__(self, momentum=0.9, epsilon=1e-5, optimizer=None):
    ""momentum 1 Batch running_mean running_var
        float (default: 0.9)
    epsilon 0 float (default: 1e-5)
    optimizer
    super()).__init__(optimizer)
    self.n_in = None
    self.n_out = None
    self.epsilon = epsilon
    self.momentum = momentum
    self.params = {
        "scalar": None,
        "intercept": None,
        "running_var": None,
        "running_mean": None,
    }
    self.is Initialized = False
def __init_parameters(self):
   Scaler = np.random.randint(self.n_in) 
```

intercept $=$ np.zeros(self.n_in)   
running_mean $=$ np.zeros(self.n_in)   
running_var $=$ np.ones(self.n_in)   
self.params $=$ { "scalar":scalar, "intercept":intercept, "running_mean": running_mean, "running_var": running_var,   
}   
self_gradients $=$ { "scalar":np.zeros_like(scaler), "intercept":np.zeros_like(intercept),   
}   
self.is Initialized $=$ True   
def reset_runting/stats(self): self.params["running_mean"] $=$ np.zeros(self.n_in)   
self.params["running_var"] $=$ np.ones(self.n_in)   
def forward(self,X,is_train $\equiv$ True, retain Derived=True): "" Batch BN [train]:Y $=$ Scaler\*norm(X)+intercept norm(X)=(X-means)/(sqrt(var(X)+epsilon)) [test]:Y $=$ Scaler\*running_norm(X)+intercept running_norm(X)= (X - running_mean)/sqrt(runng_var + epsilon) X n_samples,n_in float is_train bool retain Derived bool "" if not self.is Initialized: self.n_in $=$ self.n_out $=$ X.shape[1] self._init_parameters() epsi,momentum $=$ self.hyperparams["epsilon"],self.hyperparams["momentum"] rm,rv $=$ self.params["running_mean"],self.params["running_var"] scalar,intercept $=$ self.params["scalar"],self.params["intercept"] X_mean,X_var $=$ self.params["running_mean"],self.params["running_var"] if is_train and retain Derived: X_mean,X_var $=$ X.mean(axis=0),X.var(axis=0) self.params["running_mean"] $=$ momentum \*rm+(1.0-momentum)\*X_mean self.params["running_var"] $=$ momentum \*rv+(1.0-momentum)\*X_var if retain Derived: self.X.append(X) X_hat $=$ (X-X_mean)/np.sqrt(X_var+epsilon) y $=$ Scaler \*X_hat $+$ intercept return y   
def backward(self,dLda, retain_grads $\equiv$ True): "" BN dLda n_samples,n_out float retain_grads bool "" if not isinstance(dLda, list):

dLda = [dLda] $\mathrm{dX} = []$ $\mathbf{X} = \mathbf{\sigma}$ self.X  
for da, x in zip(dLda, X):  
    dx, dScaler, dIntercept = self._bwd(da, x)  
    dX.append(dx)  
    if retain_grads:  
        self/gradients["scalar"] += dScaler  
        self/gradients["intercept"] += dIntercept  
return dX[0] if len(X) == 1 else dX  
def _bwd(self, dLda, X):  
   Scaler = self.params["scalar"]  
    epsi = self.hyperparams["epsilon"]  
    n_ex, n_in = X.shape  
    X_mean, X_var = X.mean(axis=0), X.var(axis=0)  
    X_hat = (X - X_mean) / np.sqrt(X_var + epsi)  
    dIntercept = dLda.sum(axis=0)  
    dScaler = np.sum(dLda * X_hat, axis=0)  
    dX_hat = dLda *Scaler  
    dX = (n_ex * dX_hat - dX_hat.sum(axis=0) - X_hat * (dX_hat * X_hat).sum(axis=0)) / (n_ex * np.sqrt(X_var + epsi))  
    return dX, dScaler, dIntercept  
@property  
def hyperparams(self):  
    return {  
        "layer": "BatchNorm1D",  
        "acti_fn": None,  
        "n_in": self.n_in,  
        "n_out": self.n_out,  
        "epsilon": self.eps,  
        "momentum": self.momentum,  
        "optimizer": {  
            "cache": self optimizer.cache,  
            "hyperparams": selfOptimizer.hyperparams,},  
        }

引入 BatchNorm，MNIST 数据集测试  
```python
[27]: def load_data(path="../data/mnist/mnist.npz"): f = np.load(path) X_train, y_train = f['x_train'], f['y_train'] X_test, y_test = f['x_test'], f['y_test'] f.close() return (X_train, y_train), (X_test, y_test) (X_train, y_train), (X_test, y_test) = load_data() y_train = np.eye(10)[y_train. astype(int)] y_test = np.eye(10)[y_test. astype(int)] X_train = X_train.reshape(-1, X_train.shape[1]*X_train.shape[2]). astype('float32') X_test = X_test.reshape(-1, X_test.shape[1]*X_test.shape[2]). astype('float32') print(X_train.shape, y_train.shape) N = 20000 # 20000 indices = np.random.permutation(range(X_train.shape[0]))[:N] X_train, y_train = X_train[indices], y_train[indices] print(X_train.shape, y_train.shape) X_train /= 255 
```

```c
X_train = (X_train - 0.5) * 2  
X_test /= 255  
X_test = (X_test - 0.5) * 2 
```

(60000, 784) (60000, 10)

(20000, 784) (20000, 10)

[28]: def minibatch(X, batchsiz $\mathord { : } = 2 5 6$ , shuffle=True):   
```python
>>> batch mini batch
>>> N = X.shape[0]
idx = np.arange(N)
n_batches = int(np.ceil(N / batchsize))
if shuffle:
    np.random.shuffle(idx)
def mb_generation():
    for i in range(n_batches):
        yield idx[i * batchsize : (i + 1) * batchsize]
return mb_generation(), n_batches 
```

class DFN(object):   
```python
def __init__(  
    self,  
    hidden_dims_1=None,  
    hidden_dims_2=None,  
    optimizer="sgd(lr=0.01)",  
    init_w="std_normal",  
    loss=CrossEntropy()  
):  
    self optimizer = optimizer  
    self.init_w = init_w  
    self.loss = loss  
    self-hidden_dims_1 = hidden_dims_1  
    self-hidden_dims_2 = hidden_dims_2  
    self.is Initialized = False  
def __set_parameters(self):  
    ""  
    FC1 -> Sigmoid -> BN -> FC2 -> Softmax  
    ""  
self.layers = OrderedDict()  
self.layers["FC1"] = FullyConnected(  
        n_out=self-hidden_dims_1,  
        acti_fn="sigmoid",  
        init_w= self.init_w,  
        optimizer= selfOptimizer)  
self.layers["BN"] = BatchNorm1D(optimizerself optimizer)  
self.layers["FC2"] = FullyConnected(  
        n_out= self-hidden_dims_2,  
        acti_fn="affine(slope=1, intercept=0)",  
        init_w= self.init_w,  
        optimizer= self optimizer)  
self.is Initialized = True 
```

```python
def forward(self, X_train, is_train=True):
    Xs = {}
    out = X_train
    for k, v in self.layers.items():
        Xs[k] = out
        try:  # BN
            out = v.forward(out, is_train=is_train)
            except:
                out = v.forward(out)
            return out, Xs
def backward(self, grad):
    dXs = {}
    out = grad
    for k, v in reversed(list(self.layers.items)):
        dXs[k] = out
        out = v.backup(out)
    return out, dXs
def update(self):
    ""
    ""
    for k, v in reversed(list(self.layers.items)):
        v.update()
        self.flush_gradients()
def flush_gradients(self, curr_loss=None):
    ""
    for k, v in self.layers.items():
        v.flush_gradients()
def fit(self, X_train, y_train, n_epochs=20, batch_size=64, verbose=False):
    ""
    X_train
    y_train
    n_epochs epoch
    batch_size epoch batch size
    verbose batch
    ""
    selfverbose = verbose
    self.n_epochs = n_epochs
    self.batch_size = batch_size
    if not self.is Initialized:
        self.n_features = X_train.shape[1]
        self._set.params()
    prev_loss = np.inf
    for i in range(n_epochs):
        loss, epoch_start = 0.0, time.time()
        batch_generator, n_batch = minibatch(X_train, self.batch_size, shuffle=True)
        for j, batch_idx in enumerate(batch.generator):
            batch_len, batch_start = len(batch_idx), time.time()
            X_batch, y_batch = X_train[qdx], y_batch[qdx]
            out, _ = self.forward(X_batch, is_train=True)
            y_pred_batch = softmax(out) 
```

```python
batch_loss = self.loss(y_batch, y_pred_batch)  
grad = self.lossGrad(y_batch, y_pred_batch)  
_, _ = self.Backward(grad)  
self.update()  
loss += batch_loss  
if selfverbose:  
    fstr = "\t[Batch {}]{()} Train loss: {:.3f} ({:.1f}s/batch)"  
    print(fstr.format(j + 1, n_batch, batch_loss, time.time() - batch_start))  
    loss /= n_batch  
    fstr = "[Epoch {}) Avg. loss: {:.3f} Delta: {:.3f} ({:.2f)m/epoch)"  
    print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0))  
    prev_loss = loss  
def evaluate(self, X_test, y_test, batch_size=128):  
    acc = 0.0  
    batch_generator, n_batch = minibatch(X_test, batch_size, shuffle=True)  
    for j, batch IDX in enumerate(batch_generator):  
        batch_len, batch_start = len(batch IDX), time.time()  
        X_batch, y_batch = X_test[batch IDX], y_test[batch IDX]  
        y_pred_batch, _ = self.forward(X_batch, is_train=False)  
        y_pred_batch = np.argmax(y_pred_batch, axis=1)  
        y_batch = np.argmax(y_batch, axis=1)  
        acc += np.sum(y_pred_batch == y_batch)  
    return acc / X_test.shape[0]  
@property  
def hyperparams(self):  
    return {  
        "init_w": self.init_w,  
        "loss": str(self.loss),  
        "optimizer": selfOptimizer,  
        "hidden_dims_1": self-hidden_dims_1,  
        "hidden_dims_2": self-hidden_dims_2,  
        "components": {k: v.params for k, v in self.layers.items()}  
    } 
```

[29]: model $=$ DFN(hidden_dims_1=200, hidden_dims_2=10) model.fit(X_train，y_train，n_epochs $\coloneqq 20$ ，batch_size $\coloneqq 64$ ）

```txt
[Epoch 1] Avg. loss: 0.979 Delta: inf (0.01m/epoch)  
[Epoch 2] Avg. loss: 0.473 Delta: 0.506 (0.01m/epoch)  
[Epoch 3] Avg. loss: 0.395 Delta: 0.078 (0.01m/epoch)  
[Epoch 4] Avg. loss: 0.362 Delta: 0.033 (0.01m/epoch)  
[Epoch 5] Avg. loss: 0.342 Delta: 0.019 (0.02m/epoch)  
[Epoch 6] Avg. loss: 0.326 Delta: 0.016 (0.01m/epoch)  
[Epoch 7] Avg. loss: 0.315 Delta: 0.011 (0.02m/epoch)  
[Epoch 8] Avg. loss: 0.307 Delta: 0.008 (0.01m/epoch)  
[Epoch 9] Avg. loss: 0.299 Delta: 0.008 (0.01m/epoch)  
[Epoch 10] Avg. loss: 0.292 Delta: 0.008 (0.02m/epoch)  
[Epoch 11] Avg. loss: 0.287 Delta: 0.005 (0.02m/epoch)  
[Epoch 12] Avg. loss: 0.280 Delta: 0.007 (0.02m/epoch)  
[Epoch 13] Avg. loss: 0.275 Delta: 0.005 (0.01m/epoch)  
[Epoch 14] Avg. loss: 0.270 Delta: 0.005 (0.01m/epoch)  
[Epoch 15] Avg. loss: 0.262 Delta: 0.008 (0.02m/epoch)  
[Epoch 16] Avg. loss: 0.254 Delta: 0.008 (0.02m/epoch)  
[Epoch 17] Avg. loss: 0.249 Delta: 0.005 (0.01m/epoch)  
[Epoch 18] Avg. loss: 0.244 Delta: 0.005 (0.02m/epoch)  
[Epoch 19] Avg. loss: 0.234 Delta: 0.010 (0.01m/epoch)  
[Epoch 20] Avg. loss: 0.232 Delta: 0.002 (0.01m/epoch) 
```

```snap
[30]: print("accuracy:{}".format(model.evaluate(X_test，y_test))) 
```

```txt
accuracy:0.9258 
```

# 4 坐标下降

坐标下降 (Coordinate Descent) 是⼀种⾮梯度优化算法。算法在每次迭代中，在当前点处沿一个坐标方向进⾏一维搜索以求得⼀个函数的局部极⼩值。在整个过程中循环使用不同的坐标方向。如我们相对某个单⼀变量 $x _ { i }$ 最⼩化 $f ( x )$ ，然后再相对另⼀个变量 $x _ { j }$ 计算，反复循环所有的变量，会保证到达 (局部) 极⼩值。这种做法被称为坐标下降，因为我们一次优化一个坐标。

对于不可拆分的函数⽽⾔，算法可能⽆法在较⼩的迭代步数中求得最优解。如果当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是⼀个很好的⽅法。但在稀疏矩阵上的计算速度⾮常快，同时也是 Lasso 回归最快的解法。

# 5 Polyak 平均

Polyak 平均会平均优化算法在参数空间访问轨迹中的⼏个点。如果 t 次迭代梯度下降访问了点 $\smash { \theta ^ { ( 1 ) } \ldots \theta ^ { ( t ) } }$ ，那么 Polyak 平均算法输出的是：

$$
\hat {\theta} ^ {(t)} = \frac {1}{t} \sum_ {i} \theta^ {(i)} \tag {54}
$$

在梯度下降应⽤于某些问题，⽐如凸问题时，这种⽅法具有较强的收敛保证。当 Polyak 平均于非凸问题时，通常会⽤指数衰减计算平均值：

$$
\hat {\theta} ^ {(t)} = \alpha \hat {\theta} ^ {(t - 1)} + (1 - \alpha) \theta^ {(t)} \tag {55}
$$

滑动平均 (Exponential Moving Average)，或者叫做指数加权平均，可以⽤来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关。

对于 SGD，在训练过程仍然使⽤原来不带滑动平均的权重，在测试过程中使⽤带滑动平均的权重作为神经⽹络的权重，这样在测试数据上效果更好，带滑动平均的权重更新更加平滑。

# 6 监督预训练

如果模型太复杂难以优化，或是如果任务非常困难，直接训练模型来解决特定任务的挑战可能太⼤。训练模型来求解一个简化的问题，然后转移到最后的问题，有时也会更有效些。这些在直接训练⽬标模型求解⽬标问题之前，训练简单模型求解简化问题的⽅法统称为预训练。

贪心算法 (Greedy Algorithm) 将问题分解成许多部分，然后独立地在每个部分求解最优值。结合各个最佳的部分不能保证得到⼀个最佳的完整解，但贪⼼算法计算上⽐求解最优联合解的算法⾼效得多，并且贪⼼算法的解在不是最优的情况下，往往也是可以接受的。贪⼼算法也可以紧接⼀个精调 (fine-tuning) 阶段，联合优化算法搜索全问题的最优解。使⽤贪⼼解初始化联合优化算法，可以极⼤地加速算法，并提⾼寻找到的解的质量。

⼀个与监督预训练有关的⽅法扩展了迁移学习的想法，另⼀条相关的⼯作线是 FitNets 方法。

# 7 设计有助于优化的模型

改进优化的最好⽅法并不总是改进优化算法，相反，在深度学习中的许多改进来⾃设计易于优化的模型。在实践中，选择一族容易优化的模型⽐使⽤⼀个强⼤的优化算法重要。

现代神经⽹络的设计选择体现在层之间的线性变换，几乎处处可导的激活函数，和大部分定义域都有明显的梯度，特别是创新的模型，⽐如 LSTM，整流线性单元和 maxout 单元都⽐先前的模型，⽐如 sigmoid 单元的深度⽹络，使⽤更多的线性函数，使得这些模型都有简化优化的作⽤。现代神经⽹络的设计⽅案旨在使其局部梯度信息合理地对应着移动向一个遥远的解。

```python
[32]: import numpy print("numpy:", numpy._version_) 
```

```txt
numpy: 1.14.5 
```

# 卷积⽹络

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

卷积⽹络是指那些⾄少在⽹络的⼀层中使⽤卷积运算来替代一般的矩阵乘法运算的神经⽹络。

# 1 卷积运算

卷积操作是指对不同的数据窗口数据 (图像) ⽤一组固定的权重 (滤波矩阵，可以看做⼀个恒定的滤波器 Filter) 逐个元素相乘再求和 (做内积)。

也可以⽤如下⽅式理解，如果想要低噪声估计，⼀种可⾏的⽅法是对得到的测量结果进行平均。可以认为时间上越近的测量结果越相关，所以采⽤⼀种加权平均的⽅法，对于最近的测量结果赋予更高的权重。

采⽤⼀个加权函数 $w ( a )$ 来实现，其中 $a$ 表⽰测量结果距当前时刻的时间间隔： $\begin{array} { r } { s ( t ) = \int x ( a ) w ( t - a ) d a \circ } \end{array}$ 。这就是卷积操作，可以⽤星号表⽰： $s ( t ) =$ $( x { * } w ) ( t )$ 。其中 $x$ 是输⼊ (Input)； $w$ 是核 (Kernel 或 Filter)；输出的 $s$ 是特征映射或特征图 (Feature Map) 或称输出 (Output)。

# 二维卷积运算

上⾯我们介绍了卷积运算的思想，但我们通常在卷积层中会使⽤更加直观的互相关 (Cross-correlation) 运算。例如，在⼆维卷积层中，⼀个⼆维输⼊数组 $I$ 和⼀个⼆维核数组 $K$ 通过互相关运算输出⼀个⼆维数组 $O$ 。如图所⽰，输⼊是⼀个⾼和宽均为 3 的⼆维数组，核数组 (也称卷积核或过滤器) 的⾼和宽分别为 2。因此，我们可以说输⼊数组形状为 (3, 3)，卷积核窗⼜ (又称卷积窗⼜) 的形状为 (2, 2)。

![](images/6fe11918424963ea7b0b20cbae6217a5f0980f56c0c5fdd32c84b94a9f4db839.jpg)  
图 1. ⼆维卷积运算。输⼊的红⾊区域与核的红⾊区域通过运算得到输出的左上⾓红⾊区域。

红⾊区域显⽰了第⼀个输出元素的计算过程： $0 \times 0 + 1 \times 1 + 3 \times 2 + 4 \times 3 = 1 9$ 。

其他输出元素的计算过程同样可得：

$$
1 \times 0 + 2 \times 1 + 4 \times 2 + 5 \times 3 = 2 5,
$$

$$
3 \times 0 + 4 \times 1 + 6 \times 2 + 7 \times 3 = 3 7, \tag {1}
$$

$$
4 \times 0 + 5 \times 1 + 7 \times 2 + 8 \times 3 = 4 3.
$$

# 卷积背后的直觉

我们将卷积操作⽅式展开成前馈⽹络的形式，如图 2 所⽰，左图为原本的前馈⽹络，右图为卷积操作。在第六章介绍的深度前馈⽹络中，权重矩阵中的每一个元素只会使用一次，不会在不同的输⼊位置上共享参数。⽽在卷积操作中，卷积核的每一个元素都作用在输入的每一位置上。这个设计保证了我们只需要学习⼀个参数集合，⽽不⽤对每⼀位置去学习⼀个单独的参数。

![](images/70cbe18dd04a957f103229335a18b535bd10a1ce6a6939599192e10bdbd3b384.jpg)

![](images/54b35524d58a91b1d4085285ad1e680e36b94a12803efd7452b9af436ce6beed.jpg)  
图 2. 卷积操作展开为深度前馈⽹络形式 (见第六章)，左图为前馈⽹络，右图为卷积⽹络展开。

这便是卷积的直觉，稀疏交互 (Sparse Interactions) 与参数共享 (Parameter Sharing)。前馈⽹络中每⼀个输出单元与每⼀个输⼊单元都产⽣交互，如果有 $m$ 个输⼊和 $n$ 个输出，那么矩阵乘法需要 $m \times n$ 个参数并且相应算法的时间复杂度为 $O ( m \times n )$ ；卷积操作中如果我们限制每⼀个输出拥有的连接数为 $k$ ，那么稀疏的连接⽅法只需要 $k \times n$ 个参数以及 $O ( k \times n )$ 的运⾏时间。

# 2 池化

在得到卷积特征后，下⼀步就是⽤来做分类。理论上，可以⽤提取到的所有特征训练分类器，但⽤所有特征的计算量开销会很⼤，⽽且也会使分类器倾向于过拟合。

为了解决这个问题，考虑到要描述⼀个⼤图像，⼀个⾃然的⽅法是在不同位置处对特征进⾏汇总统计。例如，可以计算在图像中某⼀区域的⼀个特定特征的平均值 (或最⼤值)，这样概括统计出来的数据，其规模 (相⽐使⽤提取到的所有特征) 就低得多，同时也可以改进分类结果 (使模型不易过拟合)。这样的聚集操作称为 “池化”。池化可以保留显著特征，降低特征规模。

# 池化运算

池化函数是使⽤某⼀位置的相邻输出的总体统计特征来代替⽹络在该位置的输出。

• 最大池化函数 (Max Pooling) 给出相邻矩形区域内的最⼤值；  
• 平均池化 (Average Pooling) 计算相邻矩形区域内的平均值；  
• 其他常⽤的池化函数包括 $L ^ { 2 }$ 范数以及基于距中⼼像素距离的加权平均函数。

如图 3 所⽰，我们展⽰最⼤池化的运算过程：

$$
\begin{array}{l} \max  (0, 1, 3, 4) = 4, \\ \max  (2, 0, 5, 0) = 5, \\ \max  (6, 7, 0, 0) = 7, \\ \max  (8, 0, 0, 0) = 8. \\ \end{array}
$$

(2)

![](images/af9cb128aed23e47e6894c5e83de418aae314628f672ceba0fcdac571e19d6ab.jpg)

![](images/30afcace6f96cf4885b1789c35af05432d01c7d36605ead2f6e8d5cf06957490.jpg)  
图 3. 最⼤池化运算。输⼊的红⾊区域经过池化得到输出的左上⾓红⾊区域。

不管采⽤什么样的池化函数，当输⼊作出少量平移时，池化能够帮助输⼊的表⽰近似不变。平移的不变性是指当我们对输⼊进⾏少量平移时，经过池化函数后的⼤多数输出并不会发⽣改变。局部平移不变性是⼀个很有⽤的性质，尤其是当我们关心某个特征是否出现而不关心它出现的具体位置时，后⽂我们会对这⼀性质进⼀步描述。

# 卷积与池化作为一种无限强的先验：

先验的强或者弱取决于先验中概率密度的集中程度：弱先验具有较⾼的熵值，例如⽅差很⼤的⾼斯分布，这样的先验允许数据对于参数的改变具有或多或少的⾃由性；强先验具有较低的熵值，例如⽅差很⼩的⾼斯分布，这样的先验在决定参数最终取值时起着更加积极的作⽤；⽆限强的先验需要对⼀些参数的概率置零并且完全禁⽌对这些参数赋值，⽆论数据对于这些参数的值给出了多⼤的⽀持。因此，我们可以把卷积的使⽤当作是对⽹络中⼀层的参数引⼊了⼀个⽆限强的先验概率分布，要求该层学到的函数只能包含局部连接关系并且对平移具有等变性。

# 3 深度学习框架下的卷积：

# 3.1 多个并行卷积

通常指由多个并⾏卷积组成的运算，可以在每个位置提取多种类型的特征。

图 4. 多个并⾏卷积。输⼊的红⾊区域分别与两个核经过计算分别得到输出的左上⾓红⾊区域。  
![](images/189236908bf32afffd4212d7b548e39870d99f72c5213649db2c575368417721.jpg)  
如图 4 所⽰，我们可以⽤两组卷积核去提取不同的特征。

# 3.2 输入值与核

输⼊通常也不仅仅是实值的⽹格，⽽是由⼀系列向量的⽹格，如⼀幅彩⾊图像在每⼀个像素点都会有红绿蓝三种颜⾊的亮度。当处理图像时，通常把卷积的输⼊输出都看作是 3 维的张量，其中⼀个索引⽤于标明不同的通道 (例如 RGB)，另外两个索引标明在每个通道上的空间坐标。我们可以将输⼊图像数组写作 V，它的每⼀个元素是 $\mathsf { V } _ { \mathrm { i , j , k } }$ ，表⽰处在通道 $k$ 中第 $i$ ⾏第 $j$ 列的值。如下图所⽰，V 有 3 个通道，每个通道的形状均为 (3, 3)。此时，我们还要定义卷积核数组 K，它的每⼀个元素是 ${ \sf K } _ { \mathrm { i , j , k , l } }$ ，表⽰处在第 l 组卷积核通道 $k$ 中第 $i$ ⾏第 $j$ 列的值。如图 5 所⽰，我们假设卷积核窗⼜的形状为 (2,2)，因为输⼊通道为 3，于是我们要对每个通道都定义⼀个卷积核，同时我们构造两组卷积核实现并⾏卷积，所以 K 的形状为(2, 2, 3, 2)。

![](images/67ebf8244436411d7fb7867e651421227d8fdd9dc55dfecb916208b3340f921b.jpg)  
图 5. 输⼊数组的通道数为 3 (如图像数据)。⽤两组卷积核 (红⾊、橙⾊) 学习特征，⽽每组卷积核与输⼊运算再得到输出。

我们再看⼀下是如何获得输出 Z 值的，我们⽤ 1 组卷积核，并且以输⼊为 2 通道为例，如下图 6， $\begin{array} { r } { Z _ { \mathrm { i , j , l } } = \sum _ { \mathfrak { m } , \mathfrak { n } , \mathfrak { k } } \mathsf { V } _ { \mathrm { i + m , j + \mathfrak { n } , k } } \mathsf { K } _ { \mathfrak { m } , \mathfrak { n } , \mathfrak { k } , \mathfrak { l } } \circ } \end{array}$ 。

![](images/96a64565806cf3ac7f0a0fcbd660d44ba17a76429adac11742ab6fdc9345b12a.jpg)  
图 6. 输⼊数组的通道数为 2。展⽰⽤⼀组卷积核学习特征，卷积核的每个通道与输⼊的对应通道进⾏运算。再将各个通道的结果相加得到输出。

# 3.3 填充 (Padding)

假设输⼊图⽚的⼤⼩为 $( m , n )$ ，⽽卷积核的⼤⼩为 $( f , f )$ ，则卷积后的输出图⽚⼤⼩为 $( m - f + 1 , n - f + 1 )$ )，由此带来两个问题：

• 每次卷积运算后，输出图⽚的尺⼨缩⼩。  
• 原始图⽚的⾓落、边缘区像素点在输出中采⽤较少，输出图⽚丢失很多边缘位置的信息。

因此可以在进⾏卷积操作前，对原始图⽚在边界上进⾏填充 (Padding)，以增加矩阵的⼤⼩，通常将 0 作为填充值。

设每个⽅向扩展像素点数量为 $p$ ，则填充后原始图⽚的⼤⼩为 $( m + 2 p , n + 2 p )$ ，卷积核⼤⼩保持 $( f , f )$ 不变，则输出图⽚⼤⼩ $( m + 2 p - f + 1 , n +$ $2 p { - } f + 1 )$ 。常⽤填充的⽅法有：

• 有效 (valid) 卷积，不填充，直接卷积，结果⼤⼩为 $( m - f + 1 , n - f + 1 )$ 。

• 相同 (same) 卷积，⽤ 0 填充，并使得卷积后结果⼤⼩与输⼊⼀致，这样 $p = ( f { - } 1 ) / 2$ 。  
• 全 (full) 卷积，通过填充，使得输出尺⼨为 $( m + f - 1 , n + f - 1 )$ 。

我们将之前的例⼦⽤ $p = 1$ 填充，如图 7 所⽰。

![](images/0b55b213f9ac5aa563b67be454a6821921c04ec442502bf2d57d801327dcf164.jpg)  
图 7. $p = 1$ 填充，将 (3, 3) 的输⼊填充为 (5, 5)。再与核运算得到输出。

# 3.4 卷积步幅 (Stride)

除了需要通过填充来避免信息损失，有时也需要通过设置步幅 (Stride) 来压缩⼀部分信息。步幅表⽰核在原始图⽚的⽔平⽅向和垂直⽅向上每次移动的距离。使⽤卷积步幅，跳过核中的⼀些位置 (看作对输出的下采样) 来降低计算的开销。如图 8 所⽰，在⾼上步幅为 3、在宽上步幅为 2 的卷积操作。当输出第⼀列第⼆个元素时，卷积窗⼜向下滑动了 3 ⾏，⽽在输出第⼀⾏第⼆个元素时卷积窗⼜向右滑动了 2 列。通常我们设置在⽔平⽅向和垂直⽅向的步幅⼀样，如果步幅设为 $s$ ，则输出尺⼨为 $\frac { \ d m + 2 p - f } { \ d s } + 1 ]$ , $\textstyle { \lfloor { \frac { n + 2 p - f } { s } } + 1 \rfloor } ,$ )。

![](images/c85cc67b38b2a3a9ded332feb607ae6d0dc7009d12c16bbd0916d91c9138d766.jpg)  
图 8. 考虑步幅下的卷积运算，在⾼上步幅为 3、在宽上步幅为 2。核第⼆步与输⼊的红⾊区域运算得到输出的右上⾓红⾊区域，第三步与输⼊的橙⾊区域运算得到输出的左下⾓橙⾊区域。

# 4 更多的卷积策略

# 4.1 深度可分离卷积 (Depthwise Separable Convolution)

如图所⽰，对输⼊ $3 \times 3 \times 2$ 的数组，经过 4 组 $2 \times 2 \times 2$ 的卷积核，得到 $2 \times 2 \times 4$ 的输出。这⾥我们⼀共需要 $2 \times 2 \times 2 \times 4 = 3 2$ 个参数。我们使⽤深度可分离卷积，它将卷积过程分成两个步骤。第⼀步，在 Depthwise Convolution，输⼊有⼏个通道就设⼏个卷积核，如图 9 所⽰，输⼊⼀共 2 个通道，对每个通道分配⼀个卷积核，这⾥的每个卷积核只处理⼀个通道 (对⽐原始卷积过程每组卷积核处理所有通道)；第⼆步，在 Pointwise Convolution，由于在上⼀步不同通道间没有联系，因此这⼀步⽤ $1 \times 1$ 的卷积核组来获得不同通道间的联系。我们可以看出，在深度可分离卷积中，我们⼀共需要$2 \times 2 { \times } 2 + 1 { \times } 1 { \times } 2 { \times } 4 { = } 1 6$ 个参数。

更形式化的，我们假设：

• 输⼊尺⼨： $( \mathrm { H } _ { i n } , \mathrm { W } _ { i n } , c _ { 1 } )$   
• 卷积核尺⼨： $( \mathrm { K } , \mathrm { K } , c _ { 1 } )$   
• 输出尺⼨： $\left( \mathrm { H } _ { o u t } , \mathrm { W } _ { o u t } , c _ { 2 } \right)$

我们需要的标准卷积核参数量为 $\mathrm { K } \times \mathrm { K } \times c _ { 1 } \times c _ { 2 }$ 。在深度可分离卷积中，第⼀步需要的参数量为 $\mathrm { K } \times \mathrm { K } \times 1 \times c _ { 1 }$ ，第⼆步需要的参数为 $1 \times 1 \times c _ { 1 } \times c _ { 2 }$ ，⼀共 $\mathrm { K } \times \mathrm { K } \times 1 \times c _ { 1 } + 1 \times 1 \times c _ { 1 } \times c _ { 2 } \circ$ 。所以深度可分离卷积参数量是标准卷积的 $\textstyle { \frac { 1 } { c _ { 2 } } } + { \frac { 1 } { \mathrm { K } ^ { 2 } } }$ 。

![](images/6ac14de66059364f996faffa21d19ad244e3be83cc2d9f60de27596084a92acb.jpg)

![](images/4a7f8eb07f9e84ec279b29619b43bbba4c3468f497e74975c49f914260e1d864.jpg)  
图 9. 上⽅显⽰了原始的卷积过程，构造四组通道数为 2 的卷积核组，经过运算得到输出。下⽅显⽰了深度可分离卷积，先经过⼀组卷积核，再经过四组通道数为 2 但更⼩的卷积核组。

# 4.2 分组卷积 (Group Convolution)

如图 10 所⽰，我们先考虑标准卷积，对输⼊为 $3 { \times } 3 { \times } 4$ 的数组，经过 2 组 $2 \times 2 \times 4$ 的卷积核，得到 $2 \times 2 \times 2$ 的输出。这⾥我们⼀共需要 $2 \times 2 \times 4 \times 2 { = } 3 2$ 个参数。我们将输⼊数组依据通道分为 2 组，每组需要 $2 \times 2 \times 2$ 的卷积核就可以得到 $2 \times 2 \times 1$ 的输出，拼接在⼀起同样得到 $2 \times 2 \times 2$ 的输出。在这个分组卷积中，我们⼀共需要 $2 \times 2 { \times } 2 { \times } 2 = 1 6$ 个参数。

更形式化的，我们假设：

• 输⼊尺⼨： $( \mathrm { H } _ { i n } , \mathrm { W } _ { i n } , c _ { 1 } )$   
• 卷积核尺⼨： $( \mathrm { K } , \mathrm { K } , c _ { 1 } )$   
• 输出尺⼨： $\left( \mathrm { H } _ { o u t } , \mathrm { W } _ { o u t } , c _ { 2 } \right)$

我们需要的标准卷积核参数量为 $\mathrm { K } \times \mathrm { K } \times c _ { 1 } \times c _ { 2 }$ 。在分组卷积中，假设被分为 $g$ 组，则每⼀组输⼊的尺⼨为 $( \mathrm { H } _ { i n } , \mathrm { W } _ { i n } , c _ { 1 } / g )$ ，对应该组需要的卷积核组的尺⼨为 $( \mathrm { K } , \mathrm { K } , c _ { 1 } / g , c _ { 2 } / g )$ ，输出尺⼨为 $( \mathrm { H } _ { o u t } , \mathrm { W } _ { o u t } , c _ { 2 } / g )$ 。最后，将 $g$ 组的结果拼接在⼀起，最终得到 $\left( \mathrm { H } _ { o u t } , \mathrm { W } _ { o u t } , c _ { 2 } \right)$ ⼤⼩的输出。在这个过程中，分组卷积需要的卷积核参数量为 $\mathrm { K } \times \mathrm { K } \times ( c _ { 1 } / g ) \times ( c _ { 2 } / g ) \times g$ ，是标准卷积的 $\textstyle { \frac { 1 } { g } }$ 。

![](images/335c58fa78d4e8c86506e4ac855f3957f7bbc14e1a03596265aeb6747a21c842.jpg)  
图 10. 上⽅显⽰了原始的卷积过程，构造两组通道数为 4 的卷积核组，经过运算得到输出。下⽅显⽰了分组卷积，将原始输⼊分为两组，每组通道数为 2。再分别经过⼀组通道数为 2 的卷积核。将分别得到的结果拼接得到最终输出。

# 4.3 扩张卷积 (Dilated Convolution)

扩张卷积，也称空洞卷积，它引⼊的参数被称为扩张率 (Dilation rate)，其定义了核内值之间的间距。如图 11 所⽰，图中扩张速率为 2 的 $3 { \times } 3$ 内核将具有与 $5 \times 5$ 内核相同的视野，但只使⽤ 9 个参数。这种⽅法能以相同的计算成本，提供更⼤的感受野。在需要更⼤的观察范围，且⽆法承

受多个卷积或更⼤的内核，可以⽤它。

如果输⼊图⽚的⼤⼩为 $( m , n )$ ，⽽卷积核的⼤⼩为 $( f , f )$ ，每个⽅向扩展像素点数量为 $p$ ，步幅设为 $s$ ，则标准卷积输出尺⼨为 ( $\lfloor { \frac { m + 2 p - f } { s } } + 1 \rfloor$ ⌋, $\lfloor { \frac { n + 2 p - f } { s } } + \rfloor$ 1⌋)。如果扩张率为 ，则扩张卷积输出尺⼨为 , 。 S s$r$ $\begin{array} { r } { \varrho \lfloor \frac { m + 2 p - [ f + ( f - 1 ) ( r - 1 ) ] } { s } + 1 \rfloor } \end{array}$ $\begin{array} { r } { \lfloor \frac { n + 2 p - [ f + ( f - 1 ) ( r - 1 ) ] } { s } + 1 \rfloor ) } \end{array}$

![](images/71c88a1b844360a332445a850337976795f76db7ddf9cc4d426ce6add61cfae6.jpg)  
图 11. 分别显⽰了不考虑扩张率 (默认为 1)，以及考虑扩张率 (为 2 和 3) 的效果。

```python
[1]: import numpy as np  
import time  
import sys  
sys.path.append('../')  
from method optimizer import OptimizerInitializer  
from method.weight import WeightInitializer  
from method.activation import ActivationInitializer  
from chapter6 import LayerBase, CrossEntropy, FullyConnected, minibatch, softmax  
from collections import OrderedDict 
```

[2]:   
"   
Padding   
"   
def calc_pad_dims Sameconv_2D(X_shape, out_dim, kernel_shape, stride, dilation=1):   
"   
padding (Stride) (Dilation rate) padding X_shape (n_samples, in_rows, in_cols, in_ch) out_dim (out_rows, out_cols) kernel_shape (fr, fc) stride int dilation int default $= 1$ d = dilation fr, fc = kernel_shape out_rows, out_cols = out_dim n_ex, in_rows, in_cols, in_ch = X_shape # _fr, _fc = fr + (fr-1) \* (d-1), fc + (fc-1) \* (d-1)

```python
# padding
pr = int((stride * (out_rows-1) + _fr - in_rows) / 2)
pc = int((stride * (out_cols-1) + _fc - in_cols) / 2)
# (right/bottom) 0
out_rows1 = int(1 + (in_rows + 2 * pr - _fr) / stride)
out_cols1 = int(1 + (in_cols + 2 * pc - _fc) / stride)
pr1, pr2 = pr, pr
if out_rows1 == out_rows - 1:
    pr1, pr2 = pr, pr + 1
elif out_rows1 != out_rows:
    raise AssertionError
pc1, pc2 = pc, pc
if out_cols1 == out_cols - 1:
    pc1, pc2 = pc, pc + 1
elif out_cols1 != out_cols:
    raise AssertionError
# X Padding (left, right, up, down)
return (pr1, pr2, pc1, pc2)
def pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
    def pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
        pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
            pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X, pad, kernel_shape=None, stride=None, dilation=1):
                    pad2D(X. p = pad2D(X. p)
if isinstance(p, int):
    p = (p, p, p, p)
if isinstance(p, tuple):
    X_pad = np_pad(
        X,
        pad_width=((0,0), (p[0], p[1]), (p[2], p[3]), (0,0)), 
        mode="constant",
        constant_values=0,
    )
# 'same' padding
if p == "same" and kernel_shape and stride is not None:
    p = calc_pad_dims Sameconv_2D(
        X.shape, X.shape[1:3], kernel_shape, stride, dilation=dilation
    )
    X_pad, p = pad2D(X, p)
if p == "valid":
    p = (0,0,0,0)
X_pad, p = pad2D(X, p)
return X_pad, p 
```

```txt
[3]: def conv2D(X, W, stride, pad, dilation=1): 
```

```txt
X (n_samples, in_rows, in_cols, in_ch)  
W (kernel Rows, kernel_Cols, in_ch, out_ch)  
stride int  
pad padding 4-tuple, int, 'same' 'valid' (left, right, up, down) 0  
int pad 0  
same (same)  
valid (valid)  
dilation int default=1  
Z (n_samples, out_rows, out_cols, out_ch)  
```
s, d = stride, dilation  
X_pad, p = pad2D(X, pad, W.shape[:2], stride=s, dilation=d)  
pr1, pr2, pc1, pc2 = p  
fr, fc, in_ch, out_ch = W.shape  
n_samp, in_rows, in_cols, in_ch = X.shape  
#  
_fr, _fc = fr + (fr-1) * (d-1), fc + (fc-1) * (d-1)  
out_rows = int((in_rows + pr1 + pr2 - _fr) / s + 1)  
out_cols = int((in_rows + pc1 + pc2 - _fc) / s + 1)  
Z = np.zeros((n_pad, out_rows, out_cols, out_ch))  
for m in range(n_pad):  
    for c in range(out_ch):  
        for i in range(out_rows):  
            for j in range(out_cols):  
                i0, i1 = i * s, (i * s) + fr + (fr-1) * (d-1)  
                j0, j1 = j * s, (j * s) + fc + (fc-1) * (d-1)  
                window = X_pad[m, i0 : i1 : d, j0 : j1 : d, :]  
                Z[m, i, j, c] = np.sumwindow * W[:, :, :, :, c])  
return Z 
```

# 5 GEMM 转换

在前⾯介绍的⼆维卷积运算代码中我们会有 4 个 for 循环，这需要很⼤的时间开销，我们能否有更快的计算⽅法？

矩阵乘 (General Matrix Multiplication，GEMM) 是深度学习的核⼼。前⾯的全连接层是通过矩阵乘实现的，卷积层是否也可以这样实现？

卷积核是在输⼊图像上按步长滑动，每次滑动操作在输⼊图像上的对应窗⼜的区域，将卷积核中的各个权值 $w _ { * }$ 与输⼊图像上对应窗⼜中的各个值$x _ { * }$ 相乘，然后相加得到输出特征图上的⼀个值。卷积核对输⼊图像的每⼀次运算，可以看作是两个向量的内积，这意味着卷积操作完全可以转化为矩阵的乘法来实现。

我们将卷积层的卷积操作转化为卷积核的权值矩阵与输⼊数组转化的输⼊矩阵进⾏相乘。我们现在假设：

• 卷积核组： $( c _ { 2 } , c _ { 1 } , \mathrm { K , K } )$ ，单组卷积核 Kernel 的⼤⼩为 $( c _ { 1 } , \mathrm { K } , \mathrm { K } )$ ；  
• 输⼊数组： $\left( { { c _ { 1 } } , { { \mathrm { H } } _ { i n } } , { { \mathrm { W } } _ { i n } } } \right)$ ；

转化如图 12 所⽰：图中单组卷积核 Kernel 在输⼊图像上滑动得到各个 $\mathrm { P a t c h } _ { * }$ ，Patch 的⼤⼩同卷积核。我们将 Kernel 和 Patch 均展开成⼀维向量。假设有 $n _ { k } ( n _ { k } = c _ { 2 } )$ ) 组卷积核，并且每组卷积核在输⼊上所有的滑动可以得到 $n _ { p }$ 个 Patch，于是可以得到输⼊矩阵 $( l _ { c o l } , n _ { p } )$ 以及权值矩阵$( n _ { k } , l _ { c o l } )$ 。

• 权值矩阵： $( c _ { 2 } , c _ { 1 } \times \mathrm { K } \times \mathrm { K } )$ ；  
• 输⼊矩阵： $( c _ { 1 } \times \mathrm { K } \times \mathrm { K } , \mathrm { H } _ { o u t } \times \mathrm { W } _ { o u t } )$

![](images/a6ae33d616628c01b438bc8c72669de506fa2b76630464837673cfb1366b2263.jpg)  
图 12. im2col 操作过程。⼀组卷积核在三维图像上滑动的过程，可以视作卷积核与输⼊图像上不同的块分别做运算。基于块可以将输⼊图像数组转化为 $( l _ { c o l } , n _ { p } )$ 。如果有 $n _ { k }$ 组卷积核，也将卷积核组转化为 $( n _ { k } , l _ { c o l } )$ 。

再具体看⼀下 Kernel 和 Patch 的展开过程。对于 Kernel，我们可以依图 13 所⽰展开，图中所⽰为 1 组卷积核有 3 个通道，将卷积核先依通道再依⾏依次放⼊。

![](images/ec2290cbd8de705c78aaaed3357fbddea988bec2cc934658302825c2bc396fee.jpg)  
图 13. im2col 操作中过程，将单个卷积核组 (三维) 展开成⼀列向量的实现过程。

Patch 的展开过程同样。⽽每个 Patch 是 Kernel 在输⼊上滑动得到的，如果我们记 Patch 的右上⾓在图像中坐标为 $( : , i , j )$ ，则 Patch 中的元素为：$\{ x _ { c , i : i + h , j : j + h } \} , c = 1 , . . . , c _ { 1 } , h = \mathrm { K }$ ，⽽ $( i , j )$ 的取值 $i = 1 , . . . , \mathrm { H } _ { o u t } , j = 1 , . . . , \mathrm { W } _ { o u t } ,$ 。如果考虑扩张卷积，则元素可以写作： $\{ x _ { c , i : r : i + r h , j : r : j + r h } \}$ 。

[4]:

```txt
```
conv2D GEMM X W 2D
X (kernel_rows*kernel_cols*in_ch, n_samples*out_rows*out_cols)
W (out_ch, kernel_rows*kernel_cols*in_ch)
```
def _im2colIndices(X_shape, fr, fc, p, s, d=1):
    '''(c,h_in,w_in)
i i (kernel_rows*kernel_cols*in_ch, out_rows*out_cols)
j j (kernel_rows*kernel_cols*in_ch, out_rows*out_cols)
k c (kernel_rows*kernel_cols*in_ch, 1)
```
pr1, pr2, pc1, pc2 = p
n_ex, n_in, in_rows, in_cols = X_shape
# 
    _fr, _fc = fr + (fr-1) * (d-1), fc + (fc-1) * (d-1)
out_rows = int((in_rows + pr1 + pr2 - _fr) / s + 1)
out_cols = int((in_rows + pc1 + pc2 - _fc) / s + 1)
# i0/i1/j0/j1 i j k i0/j0 i1/j1
i0 = nprepeat(np.arange(hr), fc)
i0 = nptile(i0, n_in) * d
i1 = s * np-repeat(np.arange(out_rows), out_cols) 
```

```python
j0 = nptile(np.arange(fc), fr * n_in) * d
j1 = s * nptile(np.arange(out_cols), out_rows)
i = i0.reshape(-1, 1) + i1.reshape(1, -1)
j = j0.reshape(-1, 1) + j1reshape(1, -1)
k = np.reduce(np.arange(n_in), fr * fc).reshape(-1, 1)
return k, i, j
def im2col(X, W_shape, pad, stride, dilation=1):
    return X.shape
    return im2col
X (n_samples, in Rows, inCOLs, in_ch) 0 (padding)
W_shape (kernel Rows, kernel_COLs, in_ch, out_ch)
pad padding 4-tuple, int, 'same' 'valid'
    (left, right, up, down) 0
    int pad 0
    same (same)
    valid (valid)
stride int
dilation default=1
X_col (kernel Rows*kernel_COLs*n_in, n_samples*out_rows*out_cols)
p 4-tuple
    return X.shape
    fr, fc, n_in, n_out = W_shape
s, p, d = stride, pad, dilation
n_samp, in_rows, in_COLs, n_in = X.shape
X_pad, p = pad2D(X, p, W_shape[:2], stride=s, dilation=d)
pr1, pr2, pc1, pc2 = p
# X_pad = X_pad.transpose(0, 3, 1, 2)
k, i, j = _im2colIndices((n_samp, n_in, in_rows, in_COLs), fr, fc, p, s, d)
# X_col.shape = (n_samples, kernel Rows*kernel_COLs*n_in, out_rows*out_cols)
X_col = X_pad(:, k, i, j]
X_col = X_col.transpose(1, 2, 0).reshape(hr * fc * n_in, -1)
return X_col, p
def conv2D_gemm(X, W, stride=0, pad='same', dilation=1):
    return X.shape
    return "im2col"
X (n_samples, in Rows, in_COLs, in_ch)
W (kernel Rows, kernel_COLs, in_ch, out_ch)
stride int
pad padding 4-tuple, int, 'same' 'valid'
    (left, right, up, down) 0
int pad 0
same (same)
valid (valid)
dilation default=1
Z (n_samples, out Rows, out_COLs, out_ch)
"..." 
```

```python
s, d = stride, dilation
_, p = pad2D(X, pad, W.shape[:2], s, dilation=dilation)
pr1, pr2, pc1, pc2 = p
fr, fc, in_ch, out_ch = W.shape
n_samp, in_rows, in_cols, in_ch = X.shape
#
_fr, _fc = fr + (fr-1) * (d-1), fc + (fc-1) * (d-1)
#
out_rows = int((in_rows + pr1 + pr2 - _fr) / s + 1)
out_cols = int((in_cols + pc1 + pc2 - _fc) / s + 1)
#
X_W_2D
X_col, _ = im2col(X, W.shape, p, s, d)
W_col = W.transpose(3, 2, 0, 1).reshape(out_ch, -1)
Z = (W_col @ X_col).reshape(out_ch, out_rows, out_cols, n_samp).transpose(3, 1, 2, 0)
return Z 
```

# 6 卷积网络的训练

卷积的内部实现实际上是矩阵相乘，因此，卷积的反向传播过程实际上跟普通的全连接是类似的。

# 6.1 卷积网络示意图

CNN 的基本层包括卷积层和池化层，⼆者通常⼀起使⽤ (⼀个池化层紧跟⼀个卷积层之后)。这两层包括三个级联的函数：卷积，激励函数 (如sigmoid 函数)，池化。其前向传播和后向传播的⽰意图如下：

![](images/796c91777241f50803e459764194be480e2837e73eb1afdabdca595c4f2bee51.jpg)

![](images/98250c4ba81bc607b4489b84d4187b123ce054c4fbb5da07c9b7c87c97ef0897.jpg)  
图 14. 卷积⽹络的前向传播与反向传播⽰意图 (这⾥输⼊为⼀维向量，即⼀维卷积)。

# 6.2 单层卷积层/池化层

# 6.2.1 卷积函数的导数及反向传播

从⼀维卷积⼊⼿，假设⼀个卷积过程的输⼊向量是 $_ { \pmb { x } }$ ，输出向量是 $\textbf {  { y } }$ ，参数向量 (卷积算⼦) 是 $\pmb { w }$ 。从输⼊到输出的过程为：

$$
\boldsymbol {y} = \boldsymbol {x} * \boldsymbol {w} \tag {3}
$$

其中 $\textbf {  { y } }$ 的长度为 $| \pmb { y } |$ ， $\textbf {  { y } }$ 中每⼀个元素的计算⽅法为：

$$
y _ {n} = (\boldsymbol {x} * \boldsymbol {w}) [ n ] = \sum_ {k = 1} ^ {| \boldsymbol {w} |} x _ {n + k - 1} w _ {k} = w ^ {\top} x _ {n: n + | w | - 1} \tag {4}
$$

![](images/520138c35bec93b7079851355235166b2d9da2490428d5f2895ec8225867a155.jpg)  
图 15. 卷积函数的前向传播与反向传播⽰意图 (⼀维卷积)。

$\textbf {  { y } }$ 中的元素与 $_ { \pmb { x } }$ 中的元素有如下导数关系：

$$
\frac {\partial y _ {n - k + 1}}{\partial x _ {n}} = w _ {k}, \quad \frac {\partial y _ {n}}{\partial w _ {k}} = x _ {n + k - 1}, \quad \text {f o r} 1 \leq k \leq | w | \tag {5}
$$

进⼀步可以得到 $J$ 关于 $\pmb { w }$ 和 $_ { \pmb { x } }$ 的导数：

$$
\delta_ {n} ^ {\left(\boldsymbol {x}\right)} = \frac {\partial J}{\partial \boldsymbol {y}} \frac {\partial \boldsymbol {y}}{\partial x _ {n}} = \sum_ {k = 1} ^ {| \boldsymbol {w} |} \frac {\partial J}{\partial y _ {n - k + 1}} \frac {\partial y _ {n - k + 1}}{\partial x _ {n}} = \sum_ {k = 1} ^ {| \boldsymbol {w} |} \delta_ {n - k + 1} ^ {\left(\boldsymbol {y}\right)} w _ {k} = \left(\delta^ {\left(\boldsymbol {y}\right)} * \operatorname {f l i p} (\boldsymbol {w})\right) [ n ]
$$

$$
\delta^ {(\boldsymbol {x})} = \delta^ {(\boldsymbol {y})} * \operatorname {f l i p} (\boldsymbol {w}) \tag {6}
$$

$$
\frac {\partial}{\partial w _ {k}} J = \frac {\partial J}{\partial \boldsymbol {y}} \frac {\partial \boldsymbol {y}}{\partial w _ {k}} = \sum_ {n = 1} ^ {| \boldsymbol {y} |} \frac {\partial J}{\partial y _ {n}} \frac {\partial y _ {n}}{\partial w _ {k}} = \sum_ {n = 1} ^ {| \boldsymbol {y} |} \delta_ {n} ^ {(\boldsymbol {y})} x _ {n + k - 1} = (\delta^ {(\boldsymbol {y})} * \boldsymbol {x}) [ k ] \tag {6}
$$

$$
\frac {\partial}{\partial \boldsymbol {w}} J = \delta^ {(y)} * \boldsymbol {x}
$$

因此，通过 $\delta ^ { ( y ) }$ 与 $\mathrm { { f i p } } ( { \pmb w } )$ 可得到 $J$ 关于 $_ { \pmb { x } }$ 的导数 $\delta ^ { ( x ) }$ ，通过 $\delta ^ { ( y ) }$ 与 $_ { \pmb { x } }$ 可计算出 $\pmb { w }$ 的梯度 $\frac { \partial } { \partial w } J _ { \circ }$

如果考虑偏置和激活函数，则前向传播时， $\textbf {  { y } }$ 经过激活函数 $g$ 得到 ${ \pmb a } = g ( { \pmb y } ) = g ( { \pmb x } * { \pmb w } + { \pmb b } )$ ；反向传播时， $\delta ^ { ( { \pmb y } ) } = \delta ^ { ( { \pmb a } ) } \odot g ^ { \prime } ( { \pmb y } )$ 。于是 $\delta ^ { ( \pmb { x } ) } =$ $\delta ^ { ( \pmb { y } ) } \ast \mathrm { H i p } ( \pmb { w } ) \odot g ^ { \prime } ( \pmb { y } ) \circ$ 。

⾄此，我们拆解了卷积核作⽤在输⼊上的导数与反向传播过程。映射到⼆维卷积，这也是得到了⼀个⼆维卷积核作⽤在⼆维输⼊数组上的结论。推导⼆维卷积的导数与反向传播的过程类似。

在实际的卷积核中，我们还需要考虑通道。上⽂介绍的多通道输⼊，后⼀层的每个通道都是由前⼀层的各个通道经过卷积再求和得到的。我们将这个过程可以理解为全连接，节点为⼀个通道的输⼊数组。

![](images/7c10d8c2de8a839fe9d5d487d3769ea42432d88ed3e942a9e3af01304e2bfda0.jpg)  
图 16. 考虑多通道下的卷积运算。输⼊的每个通道先与不同卷积核组相应的卷积核运算，再累加得到输出的对应位置。这个过程可以视作全连接，将单个卷积核视作权重。

[5]: class Conv2D(LayerBase):   
```python
def __init__(  
    self,  
    out_ch,  
    kernel_shape,  
    pad=0,  
    stride=1,  
    dilation=1,  
    acti_fn=None,  
    optimizer=None,  
    init_w="glorot.uniform",  
): 
```

```txt
out_ch int  
kernel_shape 2-tuple  
acti_fn str  
pad padding 4-tuple, int, 'same' 'valid' (left, right, up, down) 0  
int pad 0  
same (same)  
valid (valid)  
stride int  
dilation int default=1  
init_w str  
optimizer str  
```
super().__init__(optimizer) 
```

```python
self_pad = pad
self.in_ch = None
self.out_ch = out_ch
self.Stride = stride
self.dilation = dilation
self_kernel_shape = kernel_shape
self.init_w = init_w
self.initweights = WeightInitializer(mode=init_w)
self.actifn = ActivationInitializer(actifn())
self.params = {"W": None, "b": None}
self.is Initialized = False 
```

```python
def init.params(self):  
    fr, fc = self_kernel_shape  
    W = self.initweights((fr, fc, self.in_ch, self.out_ch))  
    b = np.zeros((1, 1, 1, self.out_ch))  
    self.params = {"W": W, "b": b}  
    self_gradients = {"W": np.zeros_like(W), "b": np.zeros_like(b)}  
    self.derived_variables = {"Y": []}  
    self.is Initialized = True 
```

```python
def forward(self, X, retain Derived=True): 
```

```python
X (n_samples, in_rows, in cols, in_ch)  
retain Derived bool  
a (n_samples, out_rows, out cols, out_ch)  
"''"  
if not self.is Initialized:  
    self.in_ch = X.shape[3]  
    self._init_parameters()  
W = self.params["W"]  
b = self.params["b"]  
n_samp, in_rows, in cols, in_ch = X.shape  
s, p, d = self.Stride, self_pad, self.dilation  
#  
Y = conv2D(X, W, s, p, d) + b  
a = self.acti_fn(Y)  
if retain Derived:  
    self.X.append(X)  
    self.derived_variables["Y"].append(Y)  
return a  
def backward(self, dLda, retain_grads=True):  
    "''"  
dLda (n_samples, out_rows, out cols, out_ch)  
retain_grads bool  
dXs dX (n_samples, in_rows, in cols, in_ch)  
"''"  
if not isinstance(dLda, list):  
    dLda = [dLda]  
W = self.params["W"]  
b = self.params["b"]  
Ys = self.derived_variables["Y"]  
Xs, d = self.X, self.dilation  
(fr, fc), s, p = self_kernel_shape, self.stride, self_pad  
dXs = []  
for X, Y, da in zip(Xs, Ys, dLda):  
    n_samp, out_rows, out cols, out_ch = da.shape  
X_pad, (pr1, pr2, pc1, pc2) = pad2D(X, p, self_kernel_shape, s, d)  
dY = da * self.acti_fn.grad(Y)  
dX = np.zeros_like(X_pad)  
dw, db = np.zeros_like(W), np.zeros_like(b)  
for m in range(n_samp):  
    for i in range(out_rows):  
        for j in range(out cols):  
            for c in range(out_ch):  
                i0, i1 = i * s, (i * s) + fr + (fr-1) * (d-1)  
                j0, j1 = j * s, (j * s) + fc + (fc-1) * (d-1)  
                wc = W[:, :, :, c]  
                kernel = dY[m, i, j, c]  
                window = X_pad[m, i0:i1:d, j0:j1:d, :]  
            db[:, :, :, c] += kernel  
            dw[:, :, :, c] += window * kernel  
            dX[m, i0:i1:d, j0:j1:d, :] += (wc * kernel 
```

```python
) if retain_grads: self_gradients["W"] += dW self_gradients["b"] += db pr2 = None if pr2 == 0 else -pr2 pc2 = None if pc2 == 0 else -pc2 dXs.append(dX[(:, pr1:pr2, pc1:pc2, :]) return dXs[0] if len(Xs) == 1 else dXs   
@property   
def hyperparams(self): return { "layer": "Conv2D", "pad": self_pad, "init_w": self.init_w, "in_ch": self.in_ch, "out_ch": self.out_ch, "stride": self.stride, "dilation": self.dilation, "acti_fn": str(self.acti_fn), "kernel_shape": self.kernel_shape, "optimizer": { "cache": self optimizer.cache, "hyperparams": self.estimator.hyperparams, }, 
```

如果我们使⽤ GEMM 转换实现前向传播和反向传播，权值矩阵 $W$ 形状为 $( c _ { 2 } , c _ { 1 } \times \mathrm { K } \times \mathrm { K } )$ )，输⼊矩阵 $\boldsymbol { X }$ 形状为 $( c _ { 1 } \times \mathrm { K } \times \mathrm { K } , \mathrm { H } _ { o u t } \times \mathrm { W } _ { o u t } ) \circ$ 。

于是 $\pmb { y } = \pmb { W } \pmb { X } + \pmb { b }$ ，b 的形状为 $c _ { 2 }$ 。

我们回顾第六章介绍的 DFN 的反向传播算法，在第 l 个全连接层有：

$$
\boldsymbol {z} _ {l + 1} = \boldsymbol {W} _ {l} \boldsymbol {a} _ {l} + \boldsymbol {b} _ {l} \tag {7}
$$

$$
\boldsymbol {a} _ {l + 1} = g (\boldsymbol {z} _ {l + 1})
$$

我们可以得到：

$$
\left\{ \begin{array}{l} \delta_ {l} ^ {(z)} = \left(\boldsymbol {W} _ {l}\right) ^ {\top} \delta_ {l + 1} ^ {(z)} \odot g ^ {\prime} \left(\boldsymbol {z} _ {l}\right) \\ \nabla_ {\boldsymbol {W} _ {l}} J = \delta_ {l + 1} ^ {(z)} \left(\boldsymbol {a} _ {l}\right) ^ {\top} \\ \nabla_ {\boldsymbol {b} _ {l}} J = \delta_ {l + 1} ^ {(z)} \end{array} \right. \tag {8}
$$

同样的，我们这⾥有：

$$
\left\{ \begin{array}{l} \delta^ {(x)} = \boldsymbol {W} ^ {\top} \delta^ {(a)} \odot g ^ {\prime} (\boldsymbol {y}) \\ \nabla_ {\boldsymbol {W}} J = \delta^ {(y)} \boldsymbol {X} ^ {\top} \\ \nabla_ {\boldsymbol {b}} J = \delta^ {(y)} \end{array} \right. \tag {9}
$$

[6]: def col2im(X_col, X_shape, W_shape, pad, stride, dilation=0):

```txt
col2im " col2im" 2D 4D
X_col X im2col ( ) (Q, Z)
X_shape (n_samples, in_rows, in_cols, in_ch)
W_shape 4-tuple (kernel_rows, kernel_cols, in_ch, out_ch)
pad padding 4-tuple (left, right, up, down) O
stride int
dilation int default=1
img (n_samples, in_rows, in_cols, in_ch) 
```

[7]: class Conv2D_gemm(LayerBase):   
```python
s, d = stride, dilation
pr1, pr2, pc1, pc2 = pad
fr, fc, n_in, n_out = W_shape
n_samp, in_rows, in_cols, n_in = X_shape
X_pad = np.zeros((n_samp, n_in, in_rows + pr1 + pr2, in_cols + pc1 + pc2))
k, i, j = _im2col_values((n_samp, n_in, in_rows, in_cols), fr, fc, pad, s, d)
X_col reshaped = X_col.reshape(n_in * fr * fc, -1, n_samp)
X_col reshaped = X_colreshape.transpose(2, 0, 1)
np.add.at(X_pad, (slice(None), k, i, j), X_col reshaped)
pr2 = None if pr2 == 0 else -pr2
pc2 = None if pc2 == 0 else -pc2
return X_pad[:, :, pr1:pr2, pc1:pc2] 
```

```python
def __init__(  
    self,  
    out_ch,  
    kernel_shape,  
    pad=0,  
    stride=1,  
    dilation=1,  
    acti_fn=None,  
    optimizer=None,  
    init_w="glorot.uniform",  
): 
```

```python
out_ch int  
kernel_shape 2-tuple  
acti_fn str  
pad padding 4-tuple, int, 'same' 'valid' (left, right, up, down) 0  
int pad 0  
same (same)  
valid (valid)  
stride int  
dilation int default=1  
init_w str  
optimizer str  
super().__init__(optimizer)  
self_pad = pad  
self.in_ch = None  
self.out_ch = out_ch  
self.Stride = stride  
self.dilation = dilation  
self_kernel_shape = kernel_shape  
self.init_w = init_w  
self.initweights = WeightInitializer(mode=init_w)  
self.acti_fn = ActivationInitializer(acti_fn())  
self.params = {"W": None, "b": None}  
self.is Initialized = False  
def __init_parameters(self):  
    fr, fc = self_kernel_shape 
```

```python
W = self.initweights((fr, fc, self.in_ch, self.out_ch))  
b = np.zeros((1, 1, 1, self.out_ch))  
self.params = {"W": W, "b": b}  
self/gradients = {"W": np.zeros_like(W), "b": np.zeros_like(b)}  
self.derived_variables = {"Y": []}  
self.is Initialized = True 
```

```python
def forward(self, X, retain Derived=True): 
```

```python
X (n_samples, in_rows, in_cols, in_ch)  
retain Derived bool  
a (n_samples, out_rows, out_cols, out_ch)  
"..."  
if not self.is Initialized:  
    self.in_ch = X.shape[3]  
    self._init.params()  
W = self.params["W"]  
b = self.params["b"]  
n_samp, in_rows, in_cols, in_ch = X.shape  
s, p, d = self.Stride, self_pad, self.dilation  
#  
Y = conv2D_gemm(X, W, s, p, d) + b  
a = self.acti_fn(Y)  
if retain Derived:  
    self.X.append(X)  
    self.derived_variables["Y"].append(Y)  
return a 
```

```python
def backward(self, dLda, retain_grads=True): 
```

```python
dLda (n_samples, out_rows, out_cols, out_ch)  
retain_grads bool  
dX (n_samples, in Rows, in_cols, in_ch)  
```
if not isinstance(dLda, list):
    dLda = [dLda]
dX = []
X = self.X
Y = self.derived_variables["Y"]
for da, x, y in zip(dLda, X, Y):
    dx, dw, db = self._bwd(da, x, y)
dX.append(dx)
if retain_grads:
    self/gradients["W"] += dw
    self/gradients["b"] += db
return dX[0] if len(X) == 1 else dX 
```

```python
d = self.dilation
fr, fc, in_ch, out_ch = W.shape
n_samp, out_rows, out_cols, out_ch = dLda.shape
(fr, fc), s, p = self_kernel_shape, self.Stride, self_pad
dLdy = dLda * self.acti_fn.grad(Y)
dLdy_col = dLdy.transpose(3, 1, 2, 0).reshape(out_ch, -1)
W_col = W.transpose(3, 2, 0, 1).reshape(out_ch, -1).T
X_col, p = im2col(X, W.shape, p, s, d)
dw = (dLdy_col @ X_col.T).reshape(out_ch, in_ch, fr, fc).transpose(2, 3, 1, 0)
db = dLdy_col.sum(axis=1).reshape(1, 1, 1, -1)
dX_col = W_col @ dLdy_col
dX = col2im(dX_col, X.shape, W.shape, p, s, d).transpose(0, 2, 3, 1)
return dX, dW, db
@property
def hyperparams(self):
    return {
        "layer": "Conv2D",
        "pad": self-pad,
        "init_w": self.init_w,
        "in_ch": self.in_ch,
        "out_ch": self.out_ch,
        "stride": self.stride,
        "dilation": self.dilation,
        "acti_fn": str(self.acti_fn),
        "kernel_shape": self_kernel_shape,
        "optimizer": {
            "cache": selfOptimizer_cache,
            "hyperparams": self.estimator_hyperparams,
        },
    } 
```

# 6.2.2 池化函数的导数及后向传播

池化函数是⼀个下采样函数，对于⼤⼩为 $m$ 的池化区域，池化函数及其导数可以定义为：

• 最⼤池化： $g ( x ) = \operatorname* { m a x } ( x )$ ，导数为 ∂xi ∂g 1 if xi = max(x) 0 otherwise   
• 均值池化： $\begin{array} { r } { g ( x ) = \frac { \sum _ { k = 1 } ^ { m } x _ { k } } { m } } \end{array}$ ，导数为 $\begin{array} { r } { \frac { \partial g } { \partial x _ { i } } = \frac { 1 } { m } } \end{array}$ ∂xi   
• p 范数池化： $\begin{array} { r } { g ( x ) = \| x \| _ { p } = ( \sum _ { k = 1 } ^ { m } | x _ { k } | ^ { p } ) ^ { 1 / p } } \end{array}$ ，导数为 $\begin{array} { r } { \frac { \partial g } { \partial x _ { i } } = ( \sum _ { k = 1 } ^ { m } | x _ { k } | ^ { p } ) ^ { 1 / p - 1 } | x _ { i } | ^ { p - 1 } } \end{array}$ ∂xi

下采样的后向传播过程为上采样，其⽰意图为：

![](images/1fccffae92ad60de9a9a8dbcc8202204aff6f54e1609e6a86e4c7bf0c750d3ac.jpg)  
图 17. 池化函数的前向传播与反向传播⽰意图 (⼀维卷积)。

该后向传播过程就是利⽤ $g$ 的导数将误差信号传递到 $g$ 的输⼊。

$$
\delta_ {(n - 1) m + 1: n m} ^ {(\boldsymbol {x})} = \frac {\partial}{\partial x _ {(n - 1) m + 1 : n m}} J = \frac {\partial J}{\partial y _ {n}} \frac {\partial y _ {n}}{\partial x _ {(n - 1) m + 1 : n m}} = \delta_ {n} ^ {(\boldsymbol {y})} g _ {n} ^ {\prime} \tag {10}
$$

$$
\delta^ {(\boldsymbol {x})} = \operatorname {u p s a m p l e} (\delta^ {(\boldsymbol {y})}, g ^ {\prime})
$$

上采样 (upsampling) 具体展⽰如下，假设池化⼤⼩为 2,2，步幅为 2，且 $\delta ^ { ( y ) }$ 第 $k$ 个⼦矩阵为：

$$
\delta_ {k} ^ {(y)} = \left( \begin{array}{l l} 2 & 4 \\ 6 & 8 \end{array} \right) \tag {11}
$$

先将 $\delta _ { k } ^ { ( y ) }$ 还原成：

$$
\left( \begin{array}{c c c c} 0 & 0 & 0 & 0 \\ 0 & 2 & 4 & 0 \\ 0 & 6 & 8 & 0 \\ 0 & 0 & 0 & 0 \end{array} \right) \tag {12}
$$

如果是最⼤池化，假设之前在前向传播时记录的最⼤值位置分别是左上，右上，左下，右下，则转换后的矩阵为：

$$
\left( \begin{array}{c c c c} 2 & 0 & 0 & 4 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \\ 6 & 0 & 0 & 8 \end{array} \right) \tag {13}
$$

如果是均值池化，根据公式可以得到：

$$
\left( \begin{array}{l l l l} 0. 5 & 0. 5 & 1. 0 & 1. 0 \\ 0. 5 & 0. 5 & 1. 0 & 1. 0 \\ 1. 5 & 1. 5 & 2. 0 & 2. 0 \\ 1. 5. & 1. 5 & 2. 0 & 2. 0 \end{array} \right) \tag {14}
$$

[8]: class Pool2D(LayerBase):   
```python
def __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
    __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
        __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
        __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
        __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
        __init__(self, kernel_shape, stride=1, pad=0, mode="max", optimizer=None):
        __init__(mode, pad = pad)
        self.mode = mode
        self.in_ch = None
        self.out_ch = None
        selfstride = stride
        self_kernel_shape = kernel_shape
        self.is_initializer = False
def __init.params(self):
    self.derived_variables = {"out_rows": [], "out_cols":[]} 
    self.is_initializer = True
def forward(self, X, retain Derived=True):
    __________ 
```

```python
X (n_samp, in_rows, in_cols, in_ch)  
retain Derived bool  
Y (n_samp, out_rows, out_cols, out_ch)  
"..."  
if not self.is Initialized:  
    self.in_ch = self.out_ch = X.shape[3]  
    self._init.params()  
n_samp, in_rows, in_cols, nc_in = X.shape  
(fr, fc), s, p = self_kernel_shape, self.stride, self_pad  
X_pad, (pr1, pr2, pc1, pc2) = pad2D(X, p, self_kernel_shape, s)  
out_rows = int((in_rows + pr1 + pr2 - fr) / s + 1)  
out cols = int((in cols + pc1 + pc2 - fc) / s + 1)  
if self_mode == "max":  
    pool_fn = np.max  
elif self_mode == "average":  
    pool_fn = np.mean  
Y = np.zeros((n_samp, out_rows, out_cols, self.out_ch))  
for m in range(n_samp):  
    for i in range(out_rows):  
        for j in range(out_cols):  
            for c in range(self.out_ch):  
                i0, i1 = i * s, (i * s) + fr  
                j0, j1 = j * s, (j * s) + fc  
                xi = X_pad[m, i0:i1, j0:j1, c]  
                Y[m, i, j, c] = pool_fn(xi)  
if retain Derived:  
    self.X.append(X)  
    self.derived_variables["out_rows"].append(out_rows)  
    self DERIVED_variables["out_cols"].append(out_cols)  
return Y  
def backward(self, dLdy, retain_grads=True): 
```

```python
dLdy (n_samples, out_rows, out_cols, out_ch)  
retain_grads bool 
```

```txt
dXs dX (n_samples, in_rows, in_cols, in_ch) 
```

```python
if not isinstance(dLdy, list): dLdy = [dLdy]  
Xs = self.X  
out_rows = selfderived_variables["out_rows"]  
out cols = selfderived_variables["out cols"]  
(fr, fc), s, p = self_kernel_shape, self.Stride, self_pad  
dXs = []  
for X, dy, out_row, out_col in zip(Xs, dLdy, out_rows, out cols): n_samp, in Rows, in cols, nc_in = X.shape  
X_pad, (pr1, pr2, pc1, pc2) = pad2D(X, p, self_kernel_shape, s) dx = np.zeros_like(X_pad)  
for m in range(n_samp): for i in range(out_row): for j in range(out_col): for c in range(self.out_ch): 
```

```python
i0, i1 = i * s, (i * s) + fr
j0, j1 = j * s, (j * s) + fc
if self.mode == "max":
    xi = X[m, i0:i1, j0:j1, c]
    mask = np.zeros_like(xi).astype(bool)
    x, y = np.argmax(xi) [0]
    mask[x, y] = True
    dX[m, i0:i1, j0:j1, c] += mask * dy[m, i, j, c]
elif self.mode == "average":
    frame = np.ones((fr, fc)) * dy[m, i, j, c]
    dX[m, i0:i1, j0:j1, c] += frame / np.prod((fr, fc))
    pr2 = None if pr2 == 0 else -pr2
    pc2 = None if pc2 == 0 else -pc2
    dXs.append(dX[(:, pr1:pr2, pc1:pc2, :])
return dXs[0] if len(Xs) == 1 else dXs
@property
def hyperparams(self):
    return {
        "layer": "Pool2D",
        "acti_fn": None,
        "pad": self_pad,
        "mode": self_mode,
        "in_ch": self.in_ch,
        "out_ch": self.out_ch,
        "stride": selfstride,
        "kernel_shape": self_kernel_shape,
        "optimizer": {
            "cache": selfOptimizer_cache,
            "hyperparams": self.estimator.hyperparams,
        },
    } 
```

# 6.3 多层卷积层/池化层

在第六章介绍了多层神经⽹络反向传播的推导过程。这⾥同前⾯所述，假设损失函数 $J ( W , b , x , y )$ ，第 $l + 1$ 层的输⼊和输出分别是 $\mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathbf { \alpha } _ { \mathbf { \alpha } } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } } \mathrm { ~ \textem ~ } \mathbf { \alpha } _ { \mathbf { \beta } }$ 和 $\mathbf { \pmb { a } } _ { l + 1 }$ ，参数为 $W _ { l }$ 和 $b _ { l }$ ，仿射结果为中间变量 $z _ { l + 1 } = { W _ { l } } { a _ { l } } + { b _ { l } }$ 。其中 $\pmb { a } _ { l + 1 } = g ( \pmb { z } _ { l + 1 } )$ ， $g$ 为激励函数，第⼀层的输出 $\mathbf { \delta } _ { a _ { 1 } } = \mathbf { \delta } _ { x }$ ，为整个⽹络的输⼊，最后⼀层的输出 ${ \pmb a } _ { L }$ 是代价函数的输⼊。计算得到第 $l$ 层 $J$ 对 $z _ { l }$ 的偏导数和 $J$ 对参数 $W _ { l }$ 和 $b _ { l }$ 的梯度。

$$
\left\{ \begin{array}{l} \delta_ {l} ^ {(z)} = \left(\boldsymbol {W} _ {l}\right) ^ {\top} \delta_ {l + 1} ^ {(z)} \odot g ^ {\prime} \left(\boldsymbol {z} _ {l}\right) \\ \nabla_ {\boldsymbol {W} _ {l}} J = \delta_ {l + 1} ^ {(z)} \left(\boldsymbol {a} _ {l}\right) ^ {\top} \\ \nabla_ {\boldsymbol {b} _ {l}} J = \delta_ {l + 1} ^ {(z)} \end{array} \right. \tag {15}
$$

同样的，可以得到在卷积⽹络反向传播中，假设在第 $l + 1$ 层经过卷积操作 (包括激励函数) 或池化 (激励函数为池化函数)。

1. 对第 l 层计算得到 $J$ 对 $z _ { l }$ 的偏导数；

• 如果是卷积层：

$$
\delta_ {l} ^ {(z)} = \delta_ {l + 1} ^ {(z)} * \operatorname {f l i p} \left(\boldsymbol {W} _ {l}\right) \odot g ^ {\prime} \left(\boldsymbol {z} _ {l}\right) \tag {16}
$$

• 如果是池化层：

$$
\delta_ {l} ^ {(z)} = \operatorname {u p s a m p l e} \left(\delta_ {l + 1} ^ {(z)}, g ^ {\prime}\right) \tag {17}
$$

2. 对第 l 层计算得到 $J$ 对参数 $W _ { l }$ 和 $b _ { l }$ 的梯度；

$$
\nabla_ {\boldsymbol {W} _ {l}} J = \delta_ {l + 1} ^ {(z)} * \boldsymbol {a} _ {l} \tag {18}
$$

$$
\nabla_ {\boldsymbol {b} _ {l}} J = \delta_ {l + 1} ^ {(z)}
$$

# 6.4 Flatten 层 $\&$ 全连接层

通过多层卷积层/池化层后我们可以获得很多个特征图 (Feature Map)，这些特征图从不同⾓度得到模型的特征，但是我们⽆法直接⽤这些特征图拿来连接到分类。对于⼀个分类模型，我们既要综合考虑所有的特征图，又要能够连接到分类，可以考虑的⽅案就是将最后得到的特征图 “拍平” (丢到 Flatten 层)，然后把 Flatten 层的输出放到全连接层⾥ (⼀般⾄少 2 层以保证全连接层能够学到拟合函数)。最后采⽤ softmax 对其进⾏分类。

![](images/e1fe6b685c01a3b61a3d9f27f82593549904e2274e92f7fb388f4fd418c1b1b0.jpg)  
图 18. Flatten 层的实现过程：对最后得到的卷积核组依次展开，每个值作为⼀个神经元节点。

如果是将最后⼀层的特征图 Flatten 再放⼊全连接层，会存在的问题是输⼊的参数量过⼤，这会降低训练的速度，同时很容易过拟合。既然是针对这些特征图进⾏分类，那么另外⼀种可以考虑的⽅案是全局平均池化 (Global Average Pooling)。如图所⽰，GAP 的操作是将最后⼀层的特征图取均值。我们得到的 GAP 层中的每个节点对应不同的特征图，连接 GAP 层和最后的密集层的权重编码了每个特征图对预测⽬标分类的贡献。

![](images/47bc1a1769a5ff39b039fd58b388152aad46ed80e409dbb4088367ce01b04053.jpg)  
图 19. GAP 层的实现过程：对最后得到的卷积核组，每个卷积核取其均值作为⼀个神经元节点。

[9]:

```python
class Flatten(LayerBase):   
def __init__(self, keep_dim="first", optimizer=None):   
    keep_dim str(default: 'first')  
    X keep_dim 'first' -> X (X.shape[0], -1)  
    last' -> X (-1, X.shape[0]) 'none' -> X (1,-1)  
    optimizer   
    super().__init__(optimizer)  
    self_keep_dim = keep_dim  
    self._init.params()  
def __init_parameters(self):  
    self.X = []  
    self_gradients = {}  
    self.params = {}  
    self.derived_variables = {"in_dims": []}  
def forward(self, X, retain Derived=True):  
    return X flattened().reshape(1, -1)  
X  
retain Derived bool  
"..."  
if retain Derived:  
    self.derived_variables["in_dims"].append(X.shape)  
if self_keep_dim == "none":  
    return X Flatten().reshape(1, -1) 
```

rs $=$ (X.shape[0], -1) if self_keep_dim $= =$ "first" else (-1, X.shape[-1]) return X.reshape(\*rs)   
def backward(self, dLdy, retain_grads=True): dLdy retain_grads bool dX [] if not isinstance(dLdy, list): dLdy $=$ [dLdy] in_dims $=$ self.derived_variables["in_dims"] dX $=$ [dy.reshape(\*dims) for dy, dims in zip(dLdy, in_dims)] return dX[0] if len(dLdy) $= = 1$ else dX   
@property   
def hyperparams(self): return { "layer": "Flatten", "keep_dim": self_keep_dim, "optimizer": { "cache": selfOptimizer.cache, "hyperparams": self.estimator.hyperparams, },

# 7 平移等变

卷积神经⽹络具有平移不变性 (Translation Invariance) 或称平移等变。平移不变性意味着系统产⽣完全相同的响应 (输出)，不管它的输⼊是如何平移的。

• 卷积：图像经过平移，相应的特征图上的表达也是平移的。如图 20，输⼊图像的左下⾓有⼀个⼈脸，经过卷积后⼈脸的特征 (眼睛，⿐⼦) 也位于特征图的左下⾓。但假如⼈脸特征在图像的左上⾓，那么卷积后对应的特征也在特征图的左上⾓。⽆论⽬标出现在图像中的哪个位置，它都会检测到同样的这些特征，输出同样的响应，所以卷积具有平移不变性。

![](images/9ef182f473a7fa16c79db373fe3a8dd896eebf67818cff2373a026d6bf09fa6f.jpg)

![](images/a16a39f2a8cecca0fae924aaf5cf2c74ad8622e1493203e87417c563c2f20762.jpg)  
图 20. 卷积的平移不变性。

• 池化：如最⼤池化，可以返回感受野中的最⼤值，如果最⼤值被移动了，但仍然在这个感受野中，那么池化层也仍然会输出相同的最⼤值，所以卷积也可能具有平移不变性。

# 8 代表性的卷积神经网络

# 8.1 卷积神经网络 (LeNet)

LeNet [1] 分为卷积层块和全连接层块两个部分。卷积层块⾥的基本单位是卷积层后接最⼤池化层，卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使⽤ $5 \times 5$ 的窗⼜，并在输出上使⽤ sigmoid 激活函数。第⼀个卷积层输出通道数为 6，第⼆个卷积层输出通道数则增加到 16。这是因为卷积层未使⽤ 0 填充，第⼆个卷积层⽐第⼀个卷积层的输⼊的⾼和宽要⼩，所以增加输出通道使两个卷积层的参数尺⼨类似。卷积层块的两个最⼤池化层的窗⼜形状均为 $2 \times 2$ ，且步幅为 2。由于池化窗⼜与步幅形状相同，池化窗⼜在输⼊上每次滑动所覆盖的区域互不重叠，其池化效果为 部分中⽰例所⽰。

卷积层块的输出形状为 (批量⼤⼩, 通道, ⾼, 宽)。当卷积层块的输出传⼊全连接层块时，全连接层块会将⼩批量中每个样本变平 (Flatten)。即将全连接层的输⼊形状将变成⼆维，其中第⼀维是⼩批量中的样本，第⼆维是每个样本变平后的向量表⽰，且向量长度为通道、⾼和宽的乘积。全连接层块含 3 个全连接层，它们的输出个数分别是 120、84 和 10，其中 10 为输出的类别个数，如图所⽰。

我们接下来代码演⽰的是 LeNet 的实现，但与论⽂ [1] 中的实现稍有不同：论⽂ [1] 中的 LeNet ⽹络在池化层之后再进⾏⾮线性处理 (即 sigmoid激活函数)，现在通⽤的操作是经过卷积之后就经过⾮线性处理 (sigmoid 激活函数)，然后再进⾏池化操作。

![](images/8f0359a0f16a2e8585d1acd1c7d9fa8d6b148a0b8d2ea0cd88cd6ed7804c690f.jpg)  
图 21. LeNet ⽹络实现框架。

[1]: Lecun, Y. , Bottou, L. , Bengio, Y. , & Hazner, P. . (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.

[10]: class LeNet(object): def __init__(

```julia
self,  
fc3_out=128,  
fc4_out=84,  
fc5_out=10,  
conv1_pad=0,  
conv2_pad=0,  
conv1_out_ch=6,  
conv2_out_ch=16,  
conv1_stride=1,  
pool1_stride=2,  
conv2_stride=1,  
pool2_stride=2,  
conv1_kernel_shape=(5,5),  
pool1_kernel_shape=(2,2),  
conv2_kernel_shape=(5,5),  
pool2_kernel_shape=(2,2),  
optimizer="adam",  
init_w="glorot_normal",  
loss=CrossEntropy() 
```

):

```python
self optimizer = optimizer
self.init_w = init_w
self.loss = loss
self.fc3_out = fc3_out
self.fc4_out = fc4_out
self.fc5_out = fc5_out
self.conv1_pad = conv1_pad
self.conv2_pad = conv2_pad
self.conv1_stride = conv1_stride
self.conv1_out_ch = conv1_out_ch
self.pool1_stride = pool1_stride
self.conv2_out_ch = conv2_out_ch
self.conv2_stride = conv2_stride
self.pool2_stride = pool2_stride
self.conv2_kernel_shape = conv2_kernel_shape
self.pool2_kernel_shape = pool2_kernel_shape
self.conv1_kernel_shape = conv1_kernel_shape
self.pool1_kernel_shape = pool1_kernel_shape
self.is Initialized = False 
```

```python
def _set.params(self):
    ""
    Conv1 -> Pool1 -> Conv2 -> Pool2 -> Flatten -> FC3 -> FC4 -> FC5 -> Softmax
    self.layers = OrderedDict()
    self.layers["Conv1"] = Conv2D(
        out_ch= self.conv1_out_ch,
        kernel_shape= self.conv1_kernel_shape,
        pad= self.conv1_pad,
        stride= self.conv1_stride,
        acti_fn="sigmoid",
        optimizer= self.train optimizer,
        init_w= self.init_w,
    )
    self.layers["Pool1"] = Pool2D(
        mode="max",
        optimizer= self.train optimizer,
        stride= self.pool1_stride,
    ) 
```

kernel_shape $\equiv$ self.pool1_kernel_shape,   
)   
self.layers["Conv2"] $=$ Conv2D( out_ch $\equiv$ self.conv1_out_ch, kernel_shape $\equiv$ self.conv1_kernel_shape, pad $\equiv$ self.conv1_pad, stride $\equiv$ self.conv1_stride, acti_fn $\equiv$ "sigmoid", optimizer $\equiv$ selfOptimizer, init_w $\equiv$ self.init_w,   
)   
self.layers["Pool2"] $=$ Pool2D( mode $\equiv$ "max", optimizer $\equiv$ selfOptimizer, stride $\equiv$ self.pool2_stride, kernel_shape $\equiv$ self.pool2_kernel_shape,   
)   
self.layers["Flatten"] $=$ Flatten(optimizer $\equiv$ self,optimizer)   
self.layers["FC3"] $=$ FullyConnected( n_out $\equiv$ self.fc3_out, acti_fn $\equiv$ "sigmoid", init_w $\equiv$ self.init_w, optimizer $\equiv$ self OPTIMER   
)   
self.layers["FC4"] $=$ FullyConnected( n_out $\equiv$ self.fc4_out, acti_fn $\equiv$ "sigmoid", init_w $\equiv$ self.init_w, optimizer $\equiv$ self OPTIMER   
)   
self.layers["FC5"] $=$ FullyConnected( n_out $\equiv$ self.fc5_out, acti_fn $\equiv$ "affine(slope=1,intercept=0)", init_w $\equiv$ self.init_w, optimizer $\equiv$ self OPTIMER   
)   
self.is Initialized $=$ True

```python
def forward(self, X_train):
    Xs = {}
    out = X_train
    for k, v in self.layers.items():
        Xs[k] = out
        out = v.forward(out)
    return out, Xs 
```

```python
v.update()   
self.flush_gradients()   
def flush_gradients(self, curr_loss=None):   
""   
for k, v in self.layers.items(): v.flush_gradients()   
def fit(self, X_train, y_train, n_epochs=20, batch_size=64, verbose=False, epoxyverbose=True):   
X_train   
y_train   
n_epochs epoch   
batch_size epoch batch size   
verbose batch   
epoverbose epoch   
""   
selfverbose = verbose   
self.n_epochs = n_epochs   
self.batch_size = batch_size   
if not self.is Initialized: self.n_features = X_train.shape[1]   
self._set_parameters()   
prev_loss = np.inf   
for i in range(n_epochs): loss, epoch_start = 0.0, time.time() batch_generation, n_batch = minibatch(X_train, self.batch_size, shuffle=True) for j, batch IDX in enumerate(batch_generation): batch_len, batch_start = len(batch IDX), time.time() X_batch, y_batch = X_train[batch IDX], y_train[batch IDX] out, _ = self.forward(X_batch) y_pred_batch = softmax(out) batch_loss = self.loss(y_batch, y_pred_batch) grad = self.lossGrad(y_batch, y_pred_batch) _, _ = self.backup(grad) self.update() loss += batch_loss if selfverbose: fstr = "\t[Batch {}]/{}] Train loss: {:3f} ({:.1f}s/batch)" print(fstr.format(j + 1, n_batch, batch_loss, time.time() - batch_start)) loss /= n_batch if epoxyverbose: fstr = "[Epoch {}] Avg. loss: {:3f} Delta: {:3f} ({:.2f)m/epoch)" print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0)) prev_loss = loss   
def evaluate(self, X_test, y_test, batch_size=128): acc = 0.0   
batch_generator, n_batch = minibatch(X_test, batch_size, shuffle=True) for j, batch IDX in enumerate(batch_generator): batch_len, batch_start = len(batch IDX), time.time() X_batch, y_batch = X_test[batch IDX], y_test[batch IDX] y_pred_batch, _ = self.forward(X_batch) y_pred_batch = np.argmax(y_pred_batch, axis=1) y_batch = np.argmax(y_batch, axis=1) acc += np.sum(y_pred_batch == y_batch) 
```

用 LeNet，MNIST 数据集测试  
return acc / X_test.shape[0]   
operty   
hyperparams(self):   
return { "init_w": self.init_w, "loss": str(self.loss), "optimizer": selfOptimizer, "fc3_out": self.fc3_out, "fc4_out": self.fc4_out, "fc5_out": self.fc5_out, "conv1_pad": self.conv1_pad, "conv2_pad": self.conv2_pad, "conv1_stride": self.conv1_stride, "conv1_out_ch": self.conv1_out_ch, "pool1_stride": self.pool1_stride, "conv2_out_ch": self.conv2_out_ch, "conv2_stride": self.conv2_stride, "pool2_stride": self.pool2_stride, "conv2_kernel_shape": self.conv2_kernel_shape, "pool2_kernel_shape": self.pool2_kernel_shape, "conv1_kernel_shape": self.conv1_kernel_shape, "pool1_kernel_shape": self.pool1_kernel_shape, "components": $\{\mathbf{k}$ : v.params for k, v in self.layers.items())}

[11]:

```python
```
10000
```
def load_data(path="../data/mnist/mnist.npz():
    f = np.load(path)
    X_train, y_train = f['x_train'], f['y_train']
    X_test, y_test = f['x_test'], f['y_test']
    f.close()
    return (X_train, y_train), (X_test, y_test)
(X_train, y_train), (X_test, y_test) = load_data()
y_train = np.eye(10)[y_train.astype(int)]
y_test = np.eye(10)[y_test.astype(int)]
X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2], 1).dtype('float32')
X_test = X_testreshape(-1, X_train.shape[1], X_train.shape[2], 1).dtype('float32')
print(X_train.shape, y_train.shape)
N = 10000 # 10000
indices = np.random.permutation(range(X_train.shape[0])[ :N]
X_train, y_train = X_train[indices], y_train[indices]
print(X_train.shape, y_train.shape)
X_train /= 255
X_train = (X_train - 0.5) * 2
X_test /= 255
X_test = (X_test - 0.5) * 2
(60000, 28, 28, 1) (60000, 10)
(10000, 28, 28, 1) (10000, 10) 
```

[12]:

```python
model = LeNet()  
model.fit(X_train, y_train, n_epochs=15, batch_size=64, epoverbose=True)  
print("Test Accuracy:{}".format(model.evalate(X_test, y_test))) 
```

```txt
[Epoch 1] Avg. loss: 2.265 Delta: inf (17.67m/epoch) 
```

[Epoch 2] Avg. loss: 1.369 Delta: 0.896 (17.33m/epoch)

[Epoch 3] Avg. loss: 0.703 Delta: 0.666 (17.33m/epoch)

[Epoch 4] Avg. loss: 0.489 Delta: 0.214 (17.35m/epoch)

[Epoch 5] Avg. loss: 0.389 Delta: 0.100 (17.41m/epoch)

[Epoch 6] Avg. loss: 0.330 Delta: 0.059 (17.31m/epoch)

[Epoch 7] Avg. loss: 0.287 Delta: 0.043 (17.39m/epoch)

[Epoch 8] Avg. loss: 0.255 Delta: 0.032 (17.31m/epoch)

[Epoch 9] Avg. loss: 0.230 Delta: 0.025 (17.30m/epoch)

[Epoch 10] Avg. loss: 0.209 Delta: 0.022 (17.38m/epoch)

[Epoch 11] Avg. loss: 0.192 Delta: 0.017 (17.31m/epoch)

[Epoch 12] Avg. loss: 0.178 Delta: 0.014 (17.31m/epoch)

[Epoch 13] Avg. loss: 0.163 Delta: 0.015 (17.32m/epoch)

[Epoch 14] Avg. loss: 0.155 Delta: 0.008 (17.32m/epoch)

[Epoch 15] Avg. loss: 0.143 Delta: 0.012 (17.32m/epoch)

Test Accuracy:0.959

以下我们再用 GEMM 转换的卷积计算实现 LeNet，比较两者的时间差值。

[13]: class LeNet_gemm(object):

```python
def __init__(  
    self,  
    fc3_out=128,  
    fc4_out=84,  
    fc5_out=10,  
    conv1_pad=0,  
    conv2_pad=0,  
    conv1_out_ch=6,  
    conv2_out_ch=16,  
    conv1_stride=1,  
    pool1_stride=2,  
    conv2_stride=1,  
    pool2_stride=2,  
    conv1_kernel_shape=(5,5),  
    pool1_kernel_shape=(2,2),  
    conv2_kernel_shape=(5,5),  
    pool2_kernel_shape=(2,2),  
    optimizer="adam",  
    init_w="glorot_normal",  
    loss=CrossEntropy()  
):  
    self_optimizer = optimizer  
    self.init_w = init_w  
    self.loss = loss  
    self.fc3_out = fc3_out  
    self.fc4_out = fc4_out  
    self.fc5_out = fc5_out  
    self.conv1_pad = conv1_pad  
    self.conv2_pad = conv2_pad  
    self.conv1_stride = conv1_stride  
    self.conv1_out_ch = conv1_out_ch  
    self.pool1_stride = pool1_stride  
    self.conv2_out_ch = conv2_out_ch  
    self.conv2_stride = conv2_stride  
    self.pool2_stride = pool2_stride  
    self.conv2_kernel_shape = conv2_kernel_shape  
    self.pool2_kernel_shape = pool2_kernel_shape  
    self.conv1_kernel_shape = conv1_kernel_shape  
    self.pool1_kernel_shape = pool1_kernel_shape  
    self.is Initialized = False 
```

```python
def _set.params(self):
    ""
    Conv1 -> Pool1 -> Conv2 -> Pool2 -> Flatten -> FC3 -> FC4 -> FC5 -> Softmax
    ""
    self.layers = OrderedDict()
    self.layers["Conv1"] = Conv2D_gemm(
        out_ch= self.conv1_out_ch,
        kernel_shape= self.conv1_kernel_shape,
        pad= self.conv1_pad,
        stride= self.conv1_stride,
        acti_fn="sigmoid",
        optimizer= selfOptimizer,
        init_w= self.init_w,
    )
    self.layers["Pool1"] = Pool2D(
        mode="max",
        optimizer= selfOptimizer,
        stride= self.pool1_stride,
        kernel_shape= self.pool1_kernel_shape,
    )
    self.layers["Conv2"] = Conv2D_gemm(
        out_ch= self.conv1_out_ch,
        kernel_shape= self.conv1_kernel_shape,
        pad= self.conv1_pad,
        stride= self.conv1_stride,
        acti_fn="sigmoid",
        optimizer= selfOptimizer,
        init_w= self.init_w,
    )
    self.layers["Pool2"] = Pool2D(
        mode="max",
        optimizer= selfOptimizer,
        stride= self.pool2_stride,
        kernel_shape= self.pool2_kernel_shape,
    )
    self.layers["Flatten"] = Flatten(optimizerself optimizer)
    self.layers["FC3"] = FullyConnected( n_out= self.fc3_out,
            acti_fn="sigmoid",
            init_w= self.init_w,
            optimizer= self optimizer
    )
    self.layers["FC4"] = FullyConnected( n_out= self.fc4_out,
            acti_fn="sigmoid",
            init_w= self.init_w,
            optimizer= self optimizer
    )
    self.layers["FC5"] = FullyConnected( n_out= self.fc5_out,
            acti_fn="affine(slope=1, intercept=0)", 
            init_w= self.init_w,
            optimizer= self optimizer
    )
    self.is Initialized = True
def forward(self, X_train): 
```

```python
Xs = {}  
out = X_train  
for k, v in self.layers.items():  
    Xs[k] = out  
    out = v.forward(out)  
return out, Xs  
def backward(self, grad):  
    dXs = {}.  
    out = grad  
    for k, v in reversed(list(self.layers.items()))):  
        dXs[k] = out  
        out = v.forward(out)  
return out, dXs  
def update(self):  
    '''  
    '''  
    for k, v in reversed(list(self.layers.items()))):  
        v.update()  
    self.flush_gradients()  
def flush_gradients(self, curr_loss=None):  
    '''  
    '''  
    for k, v in self.layers.items():  
        v.flush_gradients()  
def fit(self, X_train, y_train, n_epochs=20, batch_size=64, verbose=False, epoxyverbose=True):  
    '''  
    X_train  
    y_train  
    n_epochs epoch  
    batch_size epoch batch size  
    verbose batch  
    epoxy_epoch epoch  
    '''  
    self.loss = verbose  
    self.n_epochs = n_epochs  
    self.batch_size = batch_size  
if not self.is Initialized:  
    self.n_features = X_train.shape[1]  
    self._set_parameters()  
prev_loss = np.inf  
for i in range(n_epochs):  
    loss, epoch_start = 0.0, time.time()  
    batch_generator, n_batch = minibatch(X_train, self.batch_size, shuffle=True)  
    for j, batch IDX in enumerate(batch.generator):  
        batch_len, batch_start = len(batch IDX), time.time()  
        X_batch, y_batch = X_train(batch IDX), y_train(batch IDX)  
        out, _ = self.forward(X_batch)  
        y_pred_batch = softmax(out)  
        batch_loss = self.loss(y_batch, y_pred_batch)  
        grad = self.loss(y_batch, y_pred_batch)  
        _, _ = self.backup(grad)  
    self.update() 
```

```python
loss += batch_loss
if selfverbose:
    fstr = "\t[Batch {}]{()} Train loss: {:.3f} ({:.1f}s/batch)"
print(fstr.format(j + 1, n_batch, batch_loss, time.time() - batch_start))
loss /= n_batch
if epoverbose:
    fstr = "[Epoch {}
Avg. loss: {:.3f} Delta: {:.3f} ({:.2f)m/epoch)"
print(fstr.format(i + 1, loss, prev_loss - loss, (time.time() - epoch_start) / 60.0))
prev_loss = loss
def evaluate(self, X_test, y_test, batch_size=128):
    acc = 0.0
    batch_generator, n_batch = minibatch(X_test, batch_size, shuffle=True)
    for j, batch IDX in enumerate(batch_generator):
        batch_len, batch_start = len(batch IDX), time.time()
        X_batch, y_batch = X_test[batch IDX], y_test[batch IDX]
        y_pred_batch, _ = self.forward(X_batch)
        y_pred_batch = np.argmax(y_pred_batch, axis=1)
        y_batch = np.argmax(y_batch, axis=1)
        acc += np.sum(y_pred_batch == y_batch)
    return acc / X_test.shape[0]
@property
def hyperparams(self):
    return {
        "init_w": self.init_w,
        "loss": str(self.loss),
        "optimizer": self.train optimizer,
        "fc3_out": self.fc3_out,
        "fc4_out": self.fc4_out,
        "fc5_out": self.fc5_out,
        "conv1_pad": self.conv1_pad,
        "conv2_pad": self.conv2_pad,
        "conv1_stride": self.conv1_stride,
        "conv1_out_ch": self.conv1_out_ch,
        "pool1_stride": self.pool1_stride,
        "conv2_out_ch": self.conv2_out_ch,
        "conv2_stride": self.conv2_stride,
        "pool2_stride": self.pool2_stride,
        "conv2_kernel_shape": self.conv2_kernel_shape,
        "pool2_kernel_shape": self.pool2_kernel_shape,
        "conv1_kernel_shape": self.conv1_kernel_shape,
        "pool1_kernel_shape": self.pool1_kernel_shape,
        "components": {k: v.params for k, v in self.layers.items())
    } 
```

```python
[14]: model = LeNet_gemm() model.fit(X_train, y_train, n_epochs=15, batch_size=64, epoverbose=True) print("Test Accuracy:{}" .format(model.evalu(e(X_test, y_test))) 
```

```txt
[Epoch 1] Avg. loss: 2.297 Delta: inf (5.20m/epoch)  
[Epoch 2] Avg. loss: 1.569 Delta: 0.728 (5.24m/epoch)  
[Epoch 3] Avg. loss: 0.751 Delta: 0.818 (5.62m/epoch)  
[Epoch 4] Avg. loss: 0.484 Delta: 0.267 (5.52m/epoch)  
[Epoch 5] Avg. loss: 0.370 Delta: 0.114 (5.61m/epoch)  
[Epoch 6] Avg. loss: 0.310 Delta: 0.059 (5.82m/epoch)  
[Epoch 7] Avg. loss: 0.271 Delta: 0.040 (5.62m/epoch)  
[Epoch 8] Avg. loss: 0.241 Delta: 0.030 (5.28m/epoch)  
[Epoch 9] Avg. loss: 0.217 Delta: 0.024 (5.28m/epoch)  
[Epoch 10] Avg. loss: 0.201 Delta: 0.017 (5.28m/epoch) 
```

```txt
[Epoch 11] Avg. loss: 0.183 Delta: 0.017 (5.30m/epoch)  
[Epoch 12] Avg. loss: 0.170 Delta: 0.013 (5.27m/epoch)  
[Epoch 13] Avg. loss: 0.157 Delta: 0.013 (5.25m/epoch)  
[Epoch 14] Avg. loss: 0.147 Delta: 0.010 (5.26m/epoch)  
[Epoch 15] Avg. loss: 0.138 Delta: 0.009 (5.24m/epoch)  
Test Accuracy: 0.9567 
```

更多的卷积神经网络及其应用将在第十二章呈现

[15]: import numpy

```lua
print("numpy:", numpy.__version__）
```

numpy: 1.14.5

# 实践⽅法论

朱明超

Email: deityrayleigh@gmail.com

Github: github.com/MingchaoZhu/DeepLearning

# 1 实践方法论

到⽬前为⽌，我们⼀直在谈论很多内容，涉及深度学习的理论⽅⾯。但是，理论与实际可⾏之间还存在很⼤差距。⼈们可能需要做出各种选择，包括收集哪种类型的数据，在哪⾥找到该数据，是否应该收集更多数据，更改模型复杂性，更改 (添加/删除) 正则化，改进优化，调试软件实现等等。建议的实⽤设计过程如下：

1. 确定⽬标，决定使⽤什么样的度量指标 (即⽤⼀个单⼀的数字指标来评估你的模型)——这代表了最终⽬标。这个度量指标的选择取决于该系统旨在解决的问题。  
2. 尽快建⽴端到端的工作流程，包括评估所需指标。也就是说，我们在设计⼀个系统时，要考虑 “数据”、“模型” 和 “分析” 三个模块的实现。要尽快保证系统可以正确接受输⼊并预处理 (“数据” 模块)，系统可以以正确的格式⽣成输出 (“模型” 模块)，系统可以计算度量指标并可视化结果 (“分析” 模块)。于是，我们最早在设计 “模型” 模块时，可以先⽤⼀个⾮常简单的模型。接下来，我们就可以只专注于改进 “模型” 模块中的模型，然后就可以⽴即获得最终结果，并检查该改进是否优化了度量指标。  
3. 很好地对系统进⾏检测，以确定性能瓶颈，这需要诊断哪些部分的性能比预期的差，并了解导致性能不佳的原因——过拟合、⽋拟合、建模问题、数据问题、软件实现错误等等。  
4. 根据上述诊断，可以通过添加更多数据、增加模型的容量、调整超参数或通过更好的标注来改善数据质量等等来不断地改进算法。

为此，本章讨论的内容包括如下：

• 性能度量指标  
• 默认的基准模型  
• 确定是否收集更多数据  
• 选择超参数  
• 调试策略

# 2 性能度量指标

如上所述，决定使⽤哪种错误指标⾮常重要，因为这最终将指导你如何取得进展。它应该⾜以代表你要实现的最终⽬标。例如，我们考虑⼀个⼆分类问题–良/恶性乳腺癌肿瘤预测。现在，选择什么合理的指标来代表这⾥的最终⽬标呢？

# 2.1 错误率与准确性

⾸先考虑错误率 (Error rate) 和准确性 (Accuracy)。

• 错误率：分类错误的样本数占样本总数的⽐例 err。  
• 准确性：分类正确的样本数占样本总数的⽐例 $a c c = 1 - e r r$ 。

现在，我们考虑⼀种情况，如果我们有 1000 个样本，其中 995 个是良性的，只有 5 个⼈是恶性的。假设我们只关注预测的错误率与准确性，那么如何设计好的模型？可以设计模型⽆论是什么样本输⼊，全部输出良性。此时的准确性是 $9 9 . 5 \%$ ，是不是很满意呢？但这种模型根本没有⽤。所以说对于数据的类别存在不平衡的情况，不能只看错误率/准确性。

这便引出了查准率、查全率、ROC、AUC。

# 2.2 查准率、查全率与 $\mathbf { F } _ { 1 }$ 值

# 2.2.1 混淆矩阵

⾸先定义混淆矩阵 (Confusion matrix)：

<table><tr><td></td><td>Positive Prediction</td><td>Negative Prediction</td></tr><tr><td>Positive Class</td><td>TP</td><td>FN</td></tr><tr><td>Negative Class</td><td>FP</td><td>TN</td></tr></table>

其中：

• TP (True Positive)：表⽰将正样本预测为正例的数⽬。即真实结果为 1，预测结果也为 1。  
• TN (True Negative)：表⽰将负样本预测为负例的数⽬。即真实结果为 0，预测结果也为 0。  
• FP (False Positive)：表⽰将负样本预测为正例的数⽬。即真实结果为 0，预测结果为 1。  
• FN (False Negative)：表⽰将正样本预测为负例的数⽬。即真实结果为 1，预测结果为 0。

混淆矩阵的⽰例如图 1 所⽰，考虑 8 个样本的真实结果和预测结果，根据定义我们可以得到其混淆矩阵。

<table><tr><td>Class</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>Prediction</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td></tr><tr><td colspan="9"></td></tr><tr><td colspan="4">Positive Prediction (1)</td><td colspan="5">Negative Prediction (0)</td></tr><tr><td>Positive Class (1)</td><td colspan="3">3</td><td colspan="5">2</td></tr><tr><td>Negative Class (0)</td><td colspan="3">1</td><td colspan="5">2</td></tr></table>

图 1. 混淆矩阵⽰例。上⽅显⽰真实类别与预测类别，下⽅显⽰混淆矩阵。

通过混淆矩阵，我们可以获得前⾯描述的错误率和准确性的数学定义：

$$
a c c = \frac {\mathrm {T P} + \mathrm {T N}}{\mathrm {T P} + \mathrm {T N} + \mathrm {F P} + \mathrm {F N}} \tag {1}
$$

$$
e r r = \frac {\mathrm {T P} + \mathrm {F N}}{\mathrm {T P} + \mathrm {T N} + \mathrm {F P} + \mathrm {F N}}
$$

# 2.2.2 查准率和查全率的定义与关联

现在我们定义查准率和查全率：

• 查准率 (Precision)：也叫精度，简记为 P 或 PPV，表⽰预测为正例的样本中 ( $\mathrm { T P } + \mathrm { F P }$ ) 有多少是真正的正样本 ( TP )。

$$
P = \frac {T P}{T P + F P} \tag {2}
$$

• 查全率 (Recall)：也叫召回率，简记为 R 或 TPR，表⽰在实际真正的正样本中 ( $\mathrm { T P } + \mathrm { F N }$ )，预测为正例的样本数 ( TP ) 所占的⽐例。

$$
R = \frac {T P}{T P + F N} \tag {3}
$$

为什么要引⼊这两个指标？

查准率表⽰宁愿漏掉，不可错杀。在识别垃圾邮件中偏向这种思路，因为我们不希望正常邮件 (对应为负样本，通常将占多数的类别视为负类) 被误杀，这样会造成严重的困扰。

查全率表⽰宁愿错杀，不可漏掉。在⾦融风控领域偏向这种思路，我们希望系统能够筛选出所有有风险的⾏为或⽤户 (对应为正样本)，然后交给⼈⼯鉴别，漏掉⼀个可能造成灾难性后果。

![](images/fae1826ab695eec049a2f7e71ec0fc66575fe0df83120673392345cfec4ca251.jpg)  
图 2. 肿瘤恶性/良性分类器⽰例。暗黄⾊⾼斯曲线表⽰真正的恶性肿瘤分布，淡蓝⾊⾼斯曲线表⽰真正的良性肿瘤分布。Positive 区域是⼤于阈值即肿瘤分类器预测为正例的样本。Negative 区域是肿瘤分类器预测为负例的样本。

查准率代表实际检测结果的百分⽐，⽽查全率则代表成功检测到的真实事件的⽐例。如图 2 所⽰，我们构造⼀个肿瘤恶性/良性分类器 (并⾮基于真实数据绘制)。暗黄⾊⾼斯曲线表⽰真正的恶性肿瘤分布，对应所有正例样本数 (暗黄⾊曲线下⽅⾯积) 为 $\mathrm { T P } + \mathrm { F N }$ 。淡蓝⾊⾼斯曲线表⽰真正的良性肿瘤分布，对应所有负例样本数 (淡蓝⾊曲线下⽅⾯积) 为 $\mathrm { F P + T N _ { \circ } }$ 。Positive 区域是⼤于阈值即肿瘤分类器预测为正例的样本 $\mathrm { T P } + \mathrm { F P }$ 。

Negative 区域是肿瘤分类器预测为负例的样本 $\mathrm { T N } + \mathrm { F N } .$ 。于是，查准率 P 表⽰在 Positive 中，肿瘤分类器预测对的⽐重，所以越⼤越好。查全率R 表⽰在暗黄⾊曲线中，落在 Positive 区域的⽐重，所以越⼤越好。

现在，回到最初的问题，考虑如果模型指出所有的肿瘤预测都不是恶性的，那么召回率为 0 (此时⼀个真正的正样本都没预测到)。查准率和查全率通常是⼀对⽭盾的度量。例如，卖⽠的时候，如果希望查准率⾼，那就选择那些最有把握的⽠，但这样有些好⽠就不会被选到，查全率并不⾼；但如果希望查全率⾼，那就将有把握的和模棱两可的⽠都选上，这样虽然查全率⾼，但查准率又下降了。

# 2.2.3 $\mathbf { F } _ { 1 }$ 值

⽽很多时候，我们实际上只希望有⼀个单⼀的指标来判断，⽽不是在两个指标之间进⾏权衡。 $\mathrm { F _ { 1 } }$ 值是 “查准率和查全率” 的调和平均值，它是⼀个⼴为接受的指标：

$$
\mathrm {F} _ {1} = \frac {2 \mathrm {P R}}{\mathrm {P} + \mathrm {R}} \tag {4}
$$

但是， $\mathrm { F _ { 1 } }$ 值会在查准率和查全率上给予同等的权重。在某些情况下，你可能想偏重⼀个，因此我们获得了更⼀般的 $\mathrm { F } _ { \beta }$ 值：

$$
\mathrm {F} _ {\beta} = \left(1 + \beta^ {2}\right) \frac {\mathrm {P R}}{\beta^ {2} \mathrm {P} + \mathrm {R}} \tag {5}
$$

其中 $\beta$ ⽤于调整权重，当 $\beta = 1$ 时两者权重相同，即为 $\mathrm { F _ { 1 } }$ 值。如果认为查准率更重要，则减⼩ $\beta$ ；若认为查全率更重要，则增⼤ $\beta$ 。

# 2.3 PR 曲线

但如果你确实想讨论查准率/查全率的关系时，PR 曲线 (Precision-Recall Curve) 可以提供帮助。PR 曲线是针对不同阈值的查准率 P ( y 轴) 和查全率 R ( x 轴) 的图。算法对样本进⾏分类时都会有置信度，即表⽰该样本是正例的概率，⽐如 $9 9 \%$ 的概率认为样本 A 是正例，或者 $1 5 \%$ 的概率认为样本 B 是正例。通过选择合适的阈值 (⽐如 $5 0 \%$ )，就对样本进⾏划分，概率⼤于阈值 $( 5 0 \%$ ) 的就认为是正例，⼩于阈值 $( 5 0 \% )$ ) 的就是负例。因此，我们考虑选择不同的阈值，并计算不同阈值情况下的查准率和查全率又是如何。具体做法是通过置信度对所有样本进⾏排序，再逐个样本的选择阈值 (以该样本的置信度作为阈值)，在该样本之前的都视作正例，该样本之后的都视作负例。将每⼀个样本分别作为划分阈值，并计算对应的查准率和查全率，就可以绘制 PR 曲线。

![](images/063acb6628510c4d754a9ed1c5ed72d9ebae751d1f8522b770777141f078992d.jpg)  
图 3. PR 曲线⽰意图。实现代码见后⽂代码实现部分。

PR 曲线⽰意图如图 3 所⽰ (实现代码见后⽂)。因为是经过排序后逐个样本作为阈值划分点，可以知道随着划分点的移动，被视作正例的样本逐渐增加，于是查全率是单调递增的 (分母考虑所有的，所以不会变化)。⽽查准率并⾮递减，越来越多的样本被视作正例，则 TP 和 FP 都可能增加，因此查准率可能会振荡，但整体趋势会下降。⼀个好的模型表现是给正样本⾼置信度，负样本低置信度。在此情况下，我们陆续选择置信度作为阈值，好的模型的表现是经过对置信度排序后排在前列的都是正样本，则对应于查全率由 0 到 1 的过程中，查准率⼀直等于 1 或接近 1。

# PR 曲线的注意点：

1. 由于在最后所有的样本都会被视作正例，因此 $\mathrm { F N = 0 }$ ，所以 R=TP/(TP+FN)=1。同时， $\mathrm { F P = }$ 所有的负样本数，因此 P=TP/(TP+FP)= 正样本占所有样本的⽐例，可以知道除⾮样本中负样本数很多，否则 P 不会为 0。如果看到 PR 曲线的终点接近 (1,0) 点，这可能是因为样本中负样本远远多于正样本。  
2. 具有完美表现的模型会绘制坐标 (1,1) 的点，PR 曲线表现为⼀条 y 轴值为 1 的⽔平线段，外加在 $_ \textrm { x }$ 轴值为 1 处的垂直线段 (线段终点由样本中正样本所占⽐例决定)，这表⽰经过置信度排序后正样本都排在了前列。⼀个模型的表现可以由⼀条向坐标 (1,1) 弯曲的曲线表⽰。⽆技能的分类器 (即该分类器没有学习) 将是图上的⼀条⽔平线，其查准率与数据集中正样本数量成⽐例，对于⼀个平衡的数据集⽽⾔将是 0.5。

PR 曲线集中在少数类上 (这⾥我们将少数类作为正样本)，使其成为不平衡⼆元分类模型的有效诊断。同时，当你需要考虑适合你业务需求的阈值时 (阈值可能⾮ 0.5)，使⽤ PR 曲线也是不错的选择。

# 2.4 ROC 曲线与 AUC 值

对于⼆分类的度量，除了上⾯的查准率 P、查全率 R 以及引申的 PR 曲线，我们还可以通过以下度量⽅法。⾸先，需要定义真正例率 (True PositiveRate) 和假正例率 (False Positive Rate)：

• 真正例率：简记为 TPR，表⽰当前被预测为正例的样本中，真正的正样本 ( TP ) 占实际所有的正样本 ( $\mathrm { T P + F N }$ ) 的⽐例。其实也就是查全率或召回率 (表⽰召回的正样本⽐例)。

$$
\mathrm {T P R} = \frac {\mathrm {T P}}{\mathrm {T P} + \mathrm {F N}} \tag {6}
$$

• 假正例率：简记为 FPR，表⽰当前被错误预测为正例的样本中，真正的负样本 ( FP ) 占实际所有的负样本 ( $\mathrm { F P + T N }$ ) 的⽐例。

$$
\mathrm {F P R} = \frac {\mathrm {F P}}{\mathrm {F P} + \mathrm {T N}} \tag {7}
$$

回到图中，真正例率 TPR 意义等同于前⾯描述的查全率 R。假正例率 FPR 表⽰淡蓝⾊曲线中，落在预测正例 Positive 区域的⽐重，所以越⼩越好。

# 2.4.1 ROC 曲线

如果我们以假正例率 FPR 为 $_ \textrm { x }$ 轴，真正例率 TPR 为 y 轴，并且随着与在 PR 曲线中相同思路的阈值改变，我们将得到 ROC 曲线 (ReceiverOperating Characteristic Curve)。⽰意图如图 4 所⽰ (实现代码见后⽂)。

![](images/d64beeb615abc19bdd214c42b489f4998cd6d91c0ba594f5c0031d439401626b.jpg)  
图 4. ROC 曲线⽰意图。实现代码见后⽂代码实现部分。

# ROC 曲线的注意点：

1. 初始时所有样本均视为负例，此时 TP 和 FP 均为 0，故曲线必然经过 (0,0)。最后所有的样本都会被视作正例，此时 FN 和 TN 均为 0，故曲线必然经过 (1,1)。由于阈值点的移动，TP 和 FP 会不断增加，于是 FPR 和 FPR 都是单调递增的 (分母考虑所有的，所以不会变化)。  
2. 可以想象，如果⼀个模型的性能较好，⾃然是 FPR 越⼩、TPR 越⼤，这样越好。所以，理想情况下的 ROC 曲线经过坐标 (0,1) 的点。如果模型的表现较好，我们⾃然希望在 FPR 很⼩的时候 TPR 就⽐较⼤ (可以参考图理解)，因此⼀个模型的表现可以由⼀条向坐标 (0,1) 弯曲的曲线表⽰。再考虑⽆技能的分类器 (即该分类器没有学习)，将是图上的⼀条 $y = x$ 的直线段，因为 TPR 和 FPR 都明显与被视作正例的数⽬成⽐例 (分母是除以各⾃对应的总数，因此没有学习的情况下都是从 0 到 1 沿相同斜率增加)。

# 2.4.2 AUC 值的计算方法

尽管 ROC 曲线是⼀种有⽤的诊断⼯具，但根据两个或多个分类器的曲线⽐较它们可能会具有挑战性。为了得到⼀个描述曲线的数字，我们可以计算 ROC 曲线下的⾯积或称 ROC AUC 值。显然，ROC 曲线的左上⽅程度越多，⾯积越⼤，ROC AUC 值越⾼。

那么如何 计算 AUC 值 呢？

# 梯形法

采⽤⾯积的积分公式，计算曲线下各个⼩矩形的⾯积之和。

# 概率法

现在，我们考虑数据集 $D$ ： $( \pmb { x } _ { 1 } , y _ { 1 } ) , \dots , ( \pmb { x } _ { m } , y _ { m } ) \in \mathbb { R } ^ { n } \times \{ 0 , 1 \}$ ，其中 $\mathbf { \nabla } _ { \mathbf { x } _ { i } }$ 是第 $i$ 个 $n$ 维特征的样本。 $y _ { i }$ 是第 i 个样本的真实类别 (0 或 1)。

对于⼀个新的观测样本 $\mathbf { \boldsymbol { x } } \in \mathbb { R } ^ { n }$ ，我们通过训练后的分类模型为其得到预测概率 ${ \hat { p } } ( { \pmb x } )$ ，表⽰模型对 $_ { \pmb { x } }$ 的标签 $y = 1$ 的置信度。接下来，我们可以选择不同的阈值，然后对每个样本根据置信度和阈值的⽐较将其分类到类别 0 或类别 1。更进⼀步，我们计算真正例率和假正例率，并绘制 ROC 曲线。

假设最终的类别 (0 或 1) 是由阈值 $t \in [ 0 , 1 ]$ 决定，那么真正例率 TPR 可以写作条件概率：

$$
T (t) := P [ \hat {p} (\boldsymbol {x}) > t \mid \boldsymbol {x} \text {属 于 类 别} 1 ] \tag {8}
$$

假正例率 FPR 也可以写作：

$$
F (t) := P [ \hat {p} (\boldsymbol {x}) > t \mid \boldsymbol {x} \text {不 属 于 类 别} 1 ] \tag {9}
$$

简化起见，我们⽤ $y ( \pmb { x } ) = 1$ 表⽰ $_ { \pmb { x } }$ 属于类别 1， $y ( { \pmb x } ) = 0$ 表⽰ $_ { \pmb { x } }$ 不属于类别 1。

ROC 曲线绘制 $t$ 由 1 ⾄ 0 时 $T ( t )$ 和 $F ( t )$ 的关系，于是我们将 $T$ 视作 $F$ 的函数：

$$
\begin{array}{l} \mathrm {A U C} = \int_ {0} ^ {1} T (F _ {0}) \mathrm {d} F _ {0} \\ = \int_ {0} ^ {1} P (\hat {p} (\boldsymbol {x}) > F ^ {- 1} (F _ {0}) \mid y (\boldsymbol {x}) = 1) \mathrm {d} F _ {0} \\ = \int_ {1} ^ {0} P (\hat {p} (\boldsymbol {x}) > F ^ {- 1} (F (t)) \mid y (\boldsymbol {x}) = 1) \cdot \frac {\partial F (t)}{\partial t} d t \\ = \int_ {0} ^ {1} P (\hat {p} (\boldsymbol {x}) > t \mid y (\boldsymbol {x}) = 1) \cdot P (\hat {p} (\boldsymbol {x} ^ {\prime}) = t \mid y (\boldsymbol {x} ^ {\prime}) = 0) d t \\ = \int_ {0} ^ {1} P (\hat {p} (\boldsymbol {x}) > \hat {p} (\boldsymbol {x} ^ {\prime}), \hat {p} (\boldsymbol {x} ^ {\prime}) = t \mid y (\boldsymbol {x}) = 1, y (\boldsymbol {x} ^ {\prime}) = 0) \mathrm {d} t \\ = P (\hat {p} (\boldsymbol {x}) > \hat {p} (\boldsymbol {x} ^ {\prime}) \mid y (\boldsymbol {x}) = 1, y (\boldsymbol {x} ^ {\prime}) = 0) \\ \end{array}
$$

其中，从第三步到第四步是⽤到累积分布函数 $P [ \hat { p } ( { \pmb x } ^ { \prime } ) \leq t | { \ r } _ { y } ( { \pmb x } ^ { \prime } ) = 0 ] = 1 - F ( t )$ 关于 $t$ 的导数为概率密度函数 $P [ \hat { p } ( \pmb { x } ^ { \prime } ) = t | y ( \pmb { x } ^ { \prime } ) = 0 ]$ 。所以，我们可以看出，如果给定⼀个随机选择的观测样本 $_ { \pmb { x } }$ 属于类别 1，以及另⼀个随机选择的观测样本 $\mathbf { { x } ^ { \prime } }$ 属于类别 0，AUC 是分类模型给 $_ { \pmb { x } }$ 的打分要⾼于给负例 $\mathbf { { x } ^ { \prime } }$ 的打分的概率，即 $\hat { p } ( { \pmb x } ) > \hat { p } ( { \pmb x } ^ { \prime } )$ 的条件概率。

这便得到了概率法的做法：随机抽出⼀对样本 (⼀个正样本，⼀个负样本)，然后⽤训练好的分类模型对这两个样本进⾏预测，预测得到正样本的概率⼤于负样本概率的概率。在实现时，我们可以先对预测概率升序排序，然后统计有多少正负样本对满⾜：正样本预测值 $>$ 负样本预测值, 再除以总的正负样本对的数⽬。统计的过程为：构造初始的当前负样本数⽬ $\begin{array} { r } { C o u n t _ { N e g } = 0 } \end{array}$ ，如果样本 $\mathbf { { x } ^ { \prime } }$ 的标签 (真实类别) 为 0，则计⼊当前的负样本数⽬$C o u n t _ { N e g }$ ；如果样本 $_ { \pmb { x } }$ 的标签为 1，则满⾜条件的正负样本对数⽬加上 $C o u n t _ { N e g }$ ，这是因为我们是对概率升序排序，所以⼀定满⾜ $\hat { p } ( { \pmb x } ) > \hat { p } ( { \pmb x } ^ { \prime } )$ ，于是正样本 $_ { \pmb { x } }$ 和 $C o u n t _ { N e g }$ 计数的负样本都是满⾜条件的。这样做的时间复杂度为 $O ( m \log m )$ ， $m$ 为样本数。

# 2.5 覆盖

在⼀些应⽤中，机器学习系统可能会拒绝做出判断。如果机器学习算法能够估计所作判断的置信度，这就会⾮常有⽤，可以帮助机器决定是否要做出判断。如果错误判断会导致严重危害，⽽且操作⼈员又可以偶尔地⼈⼯接管，那么当机器学习系统认为某个样本或数据⽆法操作时，最好的办法是由⼈来做。但是，只有当机器学习系统确实能够⼤量降低需要⼈⼯操作处理的⼯作时，它才是有⽤的。这便是覆盖 (Coverage) 的度量指标：

• 覆盖 (Coverage)：表⽰机器学习系统能够产⽣响应的⽐例。

# 2.6 指标性能的瓶颈

在⼤多数应⽤中，即便拥有了⽆限量的数据，也可能⽆法实现绝对的零误差，这可能是由于特征的表⽰能⼒不⾜或者系统本质上的随机性。系统可能的最⼩误差量称为系统的贝叶斯误差。

指标性能的主要瓶颈通常是训练数据有限。现在，如果从 MNIST 之类的标准数据集转⼊更多实际问题，你就会意识到，获取准确数据要⽐最初看起来要困难得多，⽽且在⼤多数情况下，这并不是免费的。

因此，重要的事情是你需要事先确定好应⽤程序的实际期望误差率，并⽤来指导接下来的设计决策。

# 自定义实现度量指标

```python
[1]: from abc import ABC, abstractmethod  
import pandas as pd  
import numpy as np  
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import StandardScaler  
from chapter5 import Sigmoid, LogisticRegression  
import matplotlib.pyplot as plt  
%matplotlib inline  
import itertools  
import time  
import re  
from scipy.stats import norm 
```

```python
[2]: def cal_conf_matrix(labels, predictions): labels ( ) preds n_sample = len(labels) 
```

```python
result = pd.DataFrame(index=range(0, n_sample), columns='probability', 'label'))  
result['label'] = np.array(labels)  
result['probability'] = np.array(preds)  
cm = np.arange(4).reshape(2, 2)  
cm[0, 0] = len(result[result['label'] == 1] [result['probability'] >= 0.5]) # TP  
cm[0, 1] = len(result[result['label'] == 1] [result['probability'] < 0.5]) # FN  
cm[1, 0] = len(result[result['label'] == 0] [result['probability'] >= 0.5]) # FP  
cm[1, 1] = len(result[result['label'] == 0] [result['probability'] < 0.5]) # TN  
return cm 
```

[3]: def cal_PRF1(labels, preds):   
```python
P R F1
```
cm = cal_conf_matrix(labels, preds)
P = cm[0,0] / (cm[0,0] + cm[1,0])
R = cm[0,0] / (cm[0,0] + cm[0,1])
F1 = 2 * P * R / (P + R)
return P, R, F1 
```

[4]: def cal_PRcurve(labels, preds):   
```python
PR
```
n_sample = len(labels)
result = pd.DataFrame(index=range(0, n_sample), columns=( 'probability', 'label'))
y_pred[y_pred >= 0.5] = 1
y_pred[y_pred < 0.5] = 0
result['label'] = np.array Labels)
result['probability'] = np.array(preds)
result.sort_values('probability', inplace=True, ascending=False)
PandR = pd.DataFrame(index=range(len.labels)), columns=( 'P', 'R'))
for j in range(len(result)):
    # result_j = result.head(n=j+1)
    P = len(result_j[ result_j['label'] == 1]) / float(len(result_j)) # /
    R = len(result_j[ result_j['label'] == 1]) / float(len(result[ result['label'] == 1])) # 
```

[5]: def cal_ROCcurve(labels, preds):   
```python
```
roc
```
```
n_sample = len(labels)
result = pd.DataFrame(index=range(0, n_sample), columns=( 'probability', 'label'))
y_pred[y_pred >= 0.5] = 1
y_pred[y_pred < 0.5] = 0
result['label'] = np.array Labels)
result['probability'] = np.array(preds)
# TPR, FPR
result.sort_values('probability', inplace=True, ascending=False)
TPRandFPR = pd.DataFrame(index=range(len(result)), columns=( 'TPR', 'FPR ))
for j in range(len(result)):
    # result_j=result.head(n=j+1)
    TPR=len(result_j[result_j'[label'] == 1]) / float(len(result[result_j'[label'] == 1])
    FPR=len(result_j[result_j'[label'] == 0]) / float(len(result[result_j'[label'] == 0])
    TPRandFPR.iloc[j] = [TPR, FPR]
return TPRandFPR 
```

[6]:

```python
def timeit(func):
    ""
    ""
def wrapper(*args, **kwargs):
    time_start = time.time()
    result = func(*args, **kwargs)
    time_end = time.time()
    exec_time = time_end - time_start
    print("function" exec time: {time}s".format(function=func.__name__, time=exec_time))
    return result
return wrapper
@timeit
def area_auc(labels, preds):
    ""
AUC
    ""
TPRandFPR = cal_ROCcurve Labels, preds)
# AUC
auc = 0.
prev_x = 0
for x, y in zip(TPRandFPR.FPR, TPRandFPR.TPR):
    if x != prev_x:
        auc += (x - prev_x) * y
        prev_x = x
return auc
@timeit
def naive_auc.labels, preds):
    ""
AUC
    ""
n_pos = sum.labels)
n_neg = len.labels) - n_pos
total_pair = n_pos * n_neg # labels_preds = zip.labels, preds)
labels_preds = sorted.labels_preds, key=lambda x:x[1]) # count_neg = 0 # satisfied_pair = 0 # for i in range(len.labels_preds)):
    if labels_preds[i][0] == 1:
        satisfied_pair += count_neg # else:
            count_neg += 1
return satisfied_pair / float(total_pair) 
```

# 用自定义的度量指标，乳腺癌数据集测试，第五章描述的逻辑回归用于模型训练

[7]:

```python
column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']  
data = pd.read_csv('./data/cancer/breast-cancer-wisconsin/data', names=column_names)  
data = data.replace(to_replace='?', value=np.nan)  
data = data.dropna(how='any')  
print(data.shape)  
# 25% 75%  
X_train, X_test, y_train, y_test = train_test_split(data[column_names[1:10]], data[col_names[10]], test_size=0.25, random_state=1111) 
```

```python
print(y_train.value_counts())
# 0 1
print(y_train.shape)
y_train[y_train==2] = 0
y_train[y_train==4] = 1
y_test[y_test==2] = 0
y_test[y_test==4] = 1
# print(y_train.value_counts())
# 0 1
ss = StandardScaler()
X_train = ss.fit_transform(X_train)
X_test = ss.transform(X_test) 
```

```txt
(683, 11)  
2 328  
4 184  
Name: Class, dtype: int64  
(512,)  
0 328  
1 184  
Name: Class, dtype: int64 
```

```python
[8]: model = LogisticRegression()
# model.fit(X_train, y_train)
# y_pred = model.predict(X_test) 
```

# 自定义混淆矩阵测试

[9]: # cm $=$ cal_conf_matrix(y_test，y_pred) print(cm) # classes $= [0,1]$ plt.figure(figsize $\coloneqq$ (3,3)) plt.imshow(cm，interpolation $\equiv$ 'nearest'，cmap $\equiv$ plt.cm Blues) plt.title('Confusion Matrix') tickmarks $=$ np.arange(len_classes)) plt.xlim(-0.5,1.5) plt.ylim(-0.5,1.5) plt.xticks(tickmarks，classes) plt.yticks(tickmarks，classes) fori,jinitertools.product(range(cm.shape[O]），range(cm.shape[1]): plt.text(j,i，cm[i，j]，horizontalalignment $\equiv$ "center"，verticalalignment $\equiv$ 'center') plt.tight.layout() plt)ylabel('True label') pltxlabel('Predicted label')   
[[50 5]   
[3113]]

```txt
[9]: Text(0.5, 6.80000000000011, 'Predicted label') 
```

![](images/0c9894be4479b7ab76255d38ba25b7452794ee674c8936a4312bcdd66b513c81.jpg)

用 sklearn 实现混淆矩阵测试  
```python
[10]: from sklearn.metrics import confusion_matrix  
y_predcla = y_pred.copy()  
y_predcla[y_predcla>=0.5] = 1  
y_predcla[y_predcla<0.5] = 0  
cm = confusion_matrix(y_test, y_predcla)  
print(cm) 
```

```json
[[113 3] [5 50]] 
```

自定义 P、R、 $\mathbf { F } _ { 1 }$ 值测试  
```prolog
[11]: P, R, F1 = cal_PRF1(y_test, y_pred)  
print(P, R, F1) 
```

```txt
0.9433962264150944 0.90909090909090901 0.9259259259259259 
```

用 sklearn 实现 P、R、 $\mathbf { F } _ { 1 }$ 值测试  
```python
[12]: from sklearn.metrics import precision_score, recall_score, f1_score  
y_predcla = y_pred.copy()  
y_predcla[y_predcla>=0.5] = 1  
y_predcla[y_predcla<0.5] = 0  
print(precision_score(y_test, y_predcla))  
print(recall_score(y_test, y_predcla))  
print(f1_score(y_test, y_predcla)) 
```

```csv
0.9433962264150944  
0.9090909090909091  
0.9259259259259259 
```

自定义 PR 曲线测试  
```python
[13]: # PR  
PandR = cal_PRcurve(y_test, y_pred)  
pltscatter(x = PandR['R'], y = PandR['P'], label = ' (R, P)', color = 'k', s = 5)  
plt.plot(PandR['R'], PandR['P'], color = 'c')  
plt.title('Precision-Recall Curve')  
plt.xlabel([-0.01, 1.01])  
pltylabel([-0.01, 1.01])  
plt.xlabel('Precision')  
plt.legend()  
plt.show() 
```

![](images/dd8a1f3f3b4bccfe54e1143b88c77c94bbe768b5bb9a7cf83cb33771d869c1ea.jpg)

用 sklearn 实现 PR 曲线测试  
[14]: from sklearn.metrics import precision_recall_metric precision, recall, $\underline{\mathbf{\Pi}}_{\cdot} =$ precision_recall_metric(y_test, y_pred) plt.plot(recall, precision, color $= ^{\prime}\mathrm{c}^{\prime}$ , label $= ^{\prime}(R,P)^{\prime}$ ) plt.xlim([-0.01,1.01]) plt.ylim([-0.01,1.01]) pltxlabel('Recall') pltylabel('Precision') plt.legend() plt.show()

![](images/dd4e4ef8d1ad888e7917cab9e033d06ea1e2e0f5b480a4a967fd9874e1c85437.jpg)

自定义 ROC 曲线和 AUC 值测试  
[15]: # ROC AUC area_AUC= area_auc(y_test, y_pred) naive_AUC = naive_auc(y_test, y_pred) TPRandFPR = cal_ROCcurve(y_test, y_pred) pltscatter(x=TPRandFPR['FPR'],y=TPRandFPR['TPR'],label $\equiv$ (FPR,TPR),color $\equiv$ k's=5) plt.plot(TPRandFPR['FPR'], TPRandFPR['TPR'], 'c', label $\equiv$ 'AUC $=$ %0.2f'naive_AUC) pltlegend(loc $\coloneqq$ 'lower right') plt.title('Receiver Operating Characteristic') plt.plot([0,0),(1,1)],'r--') plt.xlim([-0.01,1.01]) plt.ylim([-0.01,01.01]) plt;ylabel('True Positive Rate') pltxlabel('False Positive Rate') plt.show()

```txt
area_auc exec time: 0.4615659713745117s  
naive_auc exec time: 0.00011801719665527344s 
```

![](images/5d699155315bcc419e5249f8ea1e2c653ae97b95684b12b46fb4e07e605ac79f.jpg)

用 sklearn 实现 ROC 曲线和 AUC 值测试  
```python
[16]: from sklearn.metrics import rocurve  
from sklearn.metrics import roc_auc_score  
fpr, tpr, _ = roc_curve(y_test, y_pred)  
roc_auc = roc_auc_score(y_test, y_pred)  
pltscatter(x=fpr, y=tpr, label=' (FPR,TPR)', color='k', s=5)  
plt.plot(fpr, tpr, 'c', label='AUC = %0.2f' % roc_auc)  
pltlegend(loc='lower right')  
plt.title('Receiver Operating Characteristic')  
plt.plot([-0.01, 1.01])  
pltylim([-0.01, 0.01])  
pltylabel('True Positive Rate')  
plt.xlabel('False Positive Rate')  
plt.show() 
```

![](images/9294db392403c73f1bf3c213bcb375ad8653ee5e1368335e4c081777a93e1ff0.jpg)

# 3 默认基准模型

如开始时提到的，尽快建⽴⼀个有效的端到端系统⾮常重要。根据问题的复杂性，我们甚⾄可能选择从⼀个⾮常简单的模型开始，例如逻辑回归。但是，如果你要解决的问题属于 “完全 AI” 的，例如图像分类，语⾳识别等，那么从深度学习模型⼊⼿⼏乎总是更好。

⾸先，你要根据数据的结构选择适合的基准模型。如果你的数据由固定⼤⼩的向量组成，并且你打算执⾏监督学习任务，那么可以使⽤多层感知器。如果你的数据具有固定的拓扑结构，则使⽤卷积神经⽹络可能是最好的⽅法。同样，如果你的数据具有顺序模式，则循环神经⽹络将是理想的起点。然⽽，深度学习在不断发展，默认的算法可能会改变。例如，3-4 年前，AlexNet 将是基于图像任务的理想起点。但是，现在 ResNets 是⼴泛接受的默认选择。

为了训练模型，⼀个合理的起点是使⽤ Adam 优化器。除此之外，具有动量和学习率衰减的 SGD 也被⼴泛使⽤，其中，学习率呈指数衰减直⾄⼀个点，然后每次验证误差稳定时，线性减⼩ 2-10 倍。通常，批标准化可以提供稳定性并允许使⽤更⼤的学习率帮助更快地达到收敛，从⽽提⾼性能。

随着模型复杂度的增加，由于训练数据有限，最终将变得易于过拟合。因此，建议也为模型添加⼀些正则化。常见的选择包括损失函数的 $L ^ { 2 }$ 正则化，Dropout，提前终⽌和批标准化。使⽤批标准化可以不⽤ Dropout。(请详见第七章和第⼋章)

如果你的任务与已有的先前⼯作的⼀些其他任务相似，建议你仅从后者复制模型 (以及权重)，然后将其⽤作任务的初始值。这种训练⽅式称为迁移学习 (Transfer Learning)。例如，在 Kaggle 上的 Dogs Vs Cats 图像分类挑战中，使⽤ ImageNet 上预训练的包含相似图像的模型作为获得最佳性能的起点，⽽不是从头开始训练模型。

最后，某些领域 (如⾃然语⾔处理 (NLP)) 在初始化过程中使⽤⽆监督的学习⽅法会极⼤地受益。在当前应⽤于 NLP 的深度学习趋势中，通常将每

个单词表⽰为词嵌⼊ (向量)，并且存在诸如 word2vec 和 GLoVe 之类的⽆监督学习⽅法来学习这些词嵌⼊ (Word Embedding)。

# 4 确定是否收集更多数据

很多⼈容易犯的错误是，他们不断尝试使⽤不同的算法来提⾼其模型的性能，但简单地改善他们拥有的数据或收集更多数据则可能是最好的改进方法。由于数据是使 AI ⽅案正常⼯作的最重要部分，因此我们现在将对此进⾏更详细的探讨。

那么，你如何决定何时获取更多数据？⾸先，如果模型在训练集上的性能很差，则说明它没有充分利⽤数据中存在的信息，在这种情况下，你需要通过增加层数或增加每层中隐藏单元的数量来增加模型的复杂性。同样，调整超参数是要执⾏的重要步骤。你可能会惊讶于选择正确的超参数对使模型正常⼯作会产⽣多么⼤的影响。例如，学习率是你最重要的也是最需要调整的超参数。为你的问题设置正确的学习率值可以节省⼤量时间。但是，如果你的模型相当复杂并且对优化进⾏了仔细的调整，但性能仍未达到所需的⽔平，则问题可能出在数据的质量上，你必须收集更⼲净的数据。

为了强调数据在现代深度⽹络中的重要性，对于那些可能不知道的⼈来说，深度学习之所以开始受到关注的原因是 ImageNet 竞赛，其中在 2012年，深度学习模型以显着优势远远超过了以前的最佳模型。ImageNet 由数百万个带标签的图像组成，并且创建类似的⼤标签数据集是当今诸如对象检测之类的极为复杂的问题已成为解决问题的原因。

训练误差通常会随着数据集⼤⼩的增加⽽增加。这是因为该模型会发现现在很难准确地适合所有数据点。⽽且，通过增加数据集的⼤⼩，由于模型现在将变得更加通⽤，因此你的验证误差 (dev) 或者测试误差将减少。另外⼀种情况，考虑模型，训练误差低但测试误差⾼的特定情况称为过拟合，是训练深度模型中最常见的问题之⼀，在这种情况下，正则化可能会有所帮助。

# 5 选择超参数

⼤多数深度学习算法具有许多需要正确选择的超参数。不同的超参数控制模型的不同⽅⾯。有些影响内存成本，例如要使⽤的层数，⽽另⼀些影响性能，如 Dropout 的保留概率，学习率，动量等。⼴泛地，有两种选择这些超参数的⽅法。第⼀个是⼿动选择它们，这需要了解超参数的作⽤以及它们如何影响训练和泛化。另⼀种⽅法是⾃动选择超参数，这⼤⼤降低了复杂性，但以计算能⼒为代价。现在，我们将更详细地讨论这两种⽅法：

# 5.1 手动超参数调整

⼿动超参数调整需要⼤量领域知识，并对训练误差，泛化误差，学习理论等有基本的了解。⼿动超参数调整的主要⽬的是通过平衡内存和运⾏时间，实现与任务复杂度匹配的有效容量。影响有效容量的因素是模型的表⽰能⼒，表⽰能⼒指最⼩化训练模型的代价函数以及正则化程度的学习算法的能⼒。

许多超参数以不同的⽅式影响过拟合 (或⽋拟合)。例如，增加某些超参数 (如隐藏单元的数量) 会增加过拟合的可能，⽽增加其他超参数 (如权重衰减) 会减少过拟合的可能。它们中的⼀些是离散的，例如隐藏单元的数量，⽽另⼀些则可能是⼆进制的，例如是否使⽤批标准化。⼀些超参数具有隐式限制它们的界限，例如权重衰减只能减少容量。因此，如果模型⽋拟合，则⽆法通过改变权重衰减使其过拟合。

如前所述，如果你只能调整⼀个超参数，请调整学习率。在正确的学习率下，模型的有效容量是最⾼的，这⾥学习率既不要不太⾼也不要太低。将学习率设置得太低会降低训练速度，甚⾄可能导致算法陷⼊局部极⼩值；设置得太⾼可能会由于剧烈振荡⽽导致训练不稳定。

如果训练误差⾼，通常的⽅法是添加更多的层或更多的隐藏单元以增加容量。如果训练误差低但测试误差⾼，则需要减⼩训练误差和测试误差之间的差距，⽽又不要过多增加训练误差。通常，⼀个充分⼤的且经过良好正则化的模型 (例如，通过使⽤ Dropout，批处理归⼀化，权重衰减等) 效果最佳。实现低泛化的最终⽬标的两种主要⽅法是：向模型添加正则化和增加数据集⼤⼩。下表显⽰了每个超参数如何影响容量：

<table><tr><td>超参数</td><td>容量何时增加</td><td>原因</td><td>注意事项</td></tr><tr><td>隐藏单元数量</td><td>增加</td><td>增加隐藏单元数量会增加模型的表示能力。</td><td>几乎模型每个操作所需的时间和内存代价都会随隐藏单元数量的增加而增加。</td></tr><tr><td>学习率</td><td>调至最优</td><td>不正确的学习速率，不管是太高还是太低都会由于优化失败而导致低有效容量的模型。</td><td></td></tr><tr><td>卷积核宽度</td><td>增加</td><td>增加卷积核宽度会增加模型的参数数量。</td><td>较宽的卷积核导致较窄的输出尺寸，除非使用隐式零填充减少此影响，否则会降低模型容量。较宽的卷积核需要更多的内存存储参数，并会增加运行时间，但较窄的输出会降低内存代价。</td></tr><tr><td>隐式零填充</td><td>增加</td><td>在卷积之前隐式添加零能保持较大尺寸的表示。</td><td>大多数操作的时间和内存代价会增加。</td></tr><tr><td>权重衰减系数</td><td>降低</td><td>降低权重衰减系数使得模型参数可以自由地变大。</td><td></td></tr><tr><td>Dropout 比率</td><td>降低</td><td>较少地丢弃单元可以更多地让单元彼此“协力”来适应训练集。</td><td></td></tr></table>

# 5.2 自动超参数优化算法

超参数调整可以看作是优化过程本⾝，它可以优化⽬标函数 (例如验证)，有时还受到训练时间、内存限制等约束。因此，我们可以设计超参数优化(Hyperparameter Optimization) 算法包装学习算法并选择其超参数。不幸的是，这些 HO 算法有它们⾃⼰的⼀组超参数，但是这些超参数通常更容易选择，我们现在将讨论这些 HO 算法：

# 5.2.1 网格搜索 (Grid Search)

对于⽹格搜索，⾸先选择⼀个你认为适合每个超参数的值范围。然后，为超参数值的每种可能组合训练模型。为简化起见，如果你有 2 个超参数并为每个参数选择⼀个 $N$ 个值的范围，则需要针对所有可能的 $N ^ { 2 }$ 的组合训练模型。通常，你会根据⾃⼰的理解 (或经验) 来设置范围的最⼤值和最⼩值，然后通常以对数刻度在两者之间选择⼀个值。例如，学习率的可能值： $\{ 0 . 1 , 0 . 0 1 , 0 . 0 0 1 \}$ ，隐藏单位数：{50, 100, 200, 400} 等。

此外，⽹格搜索在重复执⾏时效果最佳。例如，如果初始设置的范围是 {0.1, 0, 1}，⽽性能最好的时候值是 1，则可能是该范围设置错误。应该再次检查较⾼的范围，例如 $\{ 1 , 2 , 3 \}$ 。如果此时效果最好的值为 0，则应在 $\{ - 0 . 1 , 0 , 0 . 1 \}$ 之间进⾏更精细的搜索。

⽹格搜索的主要问题是计算成本。如果要调整 $m$ 个超参数，并且每个参数都可以取 $N$ 值，则训练和评估试验的次数将以 ${ \cal O } ( N ^ { m } )$ 形式增长。

# 5.2.2 随机搜索 (Random Search)

⼀种更好、更快的⽅法是随机搜索。在这种情况下，你可以在值的选择上定义⼀些分布，例如，对于⼆进制的⽤⼆项分布，对于离散的⽤多项分布，在对数刻度上⽤均匀分布 (学习率)：

然后，对于每次运⾏，根据每个超参数的分布对其值进⾏随机抽样。事实证明，这⽐⽹格搜索更有效。下图对此进⾏了解释：

![](images/acc6ea7fd4d820d36b49ab72cc11175394bab5ebc884f9dd68a2257708bd743c.jpg)

![](images/90eba2e660c1778c5ec26f5f8cba449ec0dfddcb216a70993187d046334cd3f4.jpg)  
图 5. 左图为⽹格搜索，右图为随机搜索，横轴表⽰重要超参数的值，纵轴表⽰不重要超参数的值。

如图 5 所⽰，左边为⽹格搜索，横轴表⽰重要超参数的值，纵轴表⽰不重要超参数的值。当有超参数对性能度量没有显著影响时 (纵轴)，随机搜索⽐⽹格搜索⾼效。原因体现在没有浪费的实验。例如左图中给定横轴的⼀个超参数值，⽹格会对纵轴超参数的 3 个不同值给出相同结果，其实造成了浪费，这样的结果是虽然做了 9 次实验但本质上只有 3 次有⽤的。但是在右图的随机搜索中，每次超参数通常具有不同值，每次都是独⽴的探索和实验，这样就实质上做了 9 次实验。所以，更清楚地说，随机搜索⽐⽹格搜索更快的主要原因就是它不执⾏任何浪费的计算。

# 5.2.3 基于模型的超参数优化 (Model-based Hyperparameter Optimization)

如上所述，超参数调整可以看作是⼀个优化过程。在简化的设置中，可以针对超参数在验证集上采⽤⼀些可微分的误差度量的梯度，再使⽤梯度下降即可。但是，在⼤多数实际设置中，这种梯度是不可⽤的，可能是因为⾼额的计算代价和存储成本，也可能是压根⼉就不可导。为了弥补这⼀点，你可以对验证误差建模并对该模型执⾏优化。⼀种通⽤⽅法是建⽴贝叶斯回归模型以估计验证误差的期望值以及该估计的不确定性。但贝叶斯超参数优化 (Bayesian Hyperparameter Optimization) 仍处于新⽣阶段，不够可靠。其基本想法是为了找到⽬标函数 $( f ( \theta ) )$ 的最⼤值，这⾥的 $\theta$ 代表⼀组超参数， $f ( \theta )$ 是超参数放⼊⿊盒模型 (⽬标函数) 后的输出 (⽐如这组超参对应的神经⽹络的验证集的准确率)，即 $\theta _ { t } = \arg \operatorname* { m a x } f ( \theta )$ 。第 $t$ 次迭代我们⽣成⼀个 $\theta _ { t }$ ，将 $( \theta _ { t } , f ( \theta _ { t } ) )$ 加到我们已有的观测到的数据集合⾥，然后进⾏下⼀次迭代，得到下⼀个样本 $\theta _ { t + 1 }$ 。现在问题的核⼼是在每次迭代⾥如何选择要观测哪个 $\theta _ { t }$ 。

在贝叶斯优化中 $\theta _ { t }$ 是通过优化另⼀个函数来选择的：采集函数 (Acquisition Function) $\alpha _ { t }$ 。即 $\theta _ { t } = \arg \operatorname* { m a x } \alpha _ { t } ( \theta )$ 。在选下⼀个超参数点 $\theta _ { t }$ 的时候，我们既想要去尝试那些我们之前没有探索过的区域的点 (探索，Exploration)，又想要去根据我们⽬前已经观测到的所有点的预测选择预测值可能⽐较⼤的点 (开发，Exploitation)。为了能很好地平衡两个需求，对于域中⾥⾯任意⼀个点 $\theta _ { t }$ ，我们既需要预测对应的 $f ( \theta _ { t } )$ 的值 (针对开发)，又需要知道对应的 $f ( \theta _ { t } )$ 的不确定性程度 (Uncertainty) (针对探索)。我们通常使⽤代理函数 (Surrogate Function) 同时得到这两个需求，⾸选⽅法是⾼斯过程回归。再通过采集函数基于这两个需求采样下⼀个点。如此迭代。

那么，这⾥我们就需要详细说明⾼斯过程回归，再描述采集函数的⽅法。为了阐述⾼斯过程回归，下⾯会依贝叶斯线性回归、核函数到⾼斯过程回归的顺序进⾏描述。

# 贝叶斯线性回归

在第七章介绍过，线性回归在当噪声服从⾼斯分布的时候，最⼩⼆乘损失最后导出的结果相当于对概率模型应⽤ MLE。⽽进⼀步引⼊参数的先验时，如果先验分布是⾼斯分布，那么 MAP 的结果相当于岭回归的正则化，如果先验是拉普拉斯分布，那么相当于 Lasso 的正则化。这两种⽅案都是点估计⽅法。我们希望利⽤贝叶斯⽅法来求解参数的后验分布。

这⾥线性回归的模型假设为：

$$
f (\boldsymbol {x}) = \boldsymbol {w} ^ {\top} \boldsymbol {x}
$$

$$
y = f (\boldsymbol {x}) + \epsilon \tag {10}
$$

$$
\epsilon \sim N (0, \sigma^ {2})
$$

在贝叶斯⽅法中，需要解决推断和预测两个问题。

# 推断

引⼊⾼斯先验：

$$
p (\boldsymbol {w}) = N \left(\boldsymbol {0}, \boldsymbol {\Sigma} _ {w}\right) \tag {11}
$$

对参数的后验分布进⾏推断：

$$
p (\boldsymbol {w} \mid \boldsymbol {X}, \boldsymbol {y}) = \frac {p (\boldsymbol {w} , \boldsymbol {y} \mid \boldsymbol {X})}{p (\boldsymbol {y} \mid \boldsymbol {X})} = \frac {p (\boldsymbol {y} \mid \boldsymbol {w} , \boldsymbol {X}) p (\boldsymbol {w} \mid \boldsymbol {X})}{\int p (\boldsymbol {y} \mid \boldsymbol {w} , \boldsymbol {X}) p (\boldsymbol {w} \mid \boldsymbol {X}) d \boldsymbol {w}} \tag {12}
$$

分母和参数⽆关，⽽ $p ( \pmb { w } \mid \pmb { X } ) = p ( \pmb { w } )$ ，代⼊先验得到：

$$
p (\boldsymbol {w} \mid \boldsymbol {X}, \boldsymbol {y}) \propto \prod_ {i = 1} ^ {m} p \left(y ^ {(i)} \mid \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) N \left(\boldsymbol {0}, \boldsymbol {\Sigma} _ {w}\right) \tag {13}
$$

⾼斯分布取⾼斯先验的共轭分布依然是⾼斯分布，于是最终得到的后验分布也会是⾼斯分布。当然，我们⾸先看⼀下这⾥的第⼀项：

$$
\begin{array}{l} \prod_ {i = 1} ^ {m} p \left(y ^ {(i)} \mid \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right) = \frac {1}{(2 \pi) ^ {m / 2} \sigma^ {m}} \exp \left(- \frac {1}{2 \sigma^ {2}} \sum_ {i = 1} ^ {m} \left(y ^ {(i)} - \boldsymbol {w} ^ {\top} \boldsymbol {x} ^ {(i)}\right)\right) \\ = \frac {1}{(2 \pi) ^ {m / 2} \sigma^ {m}} \exp \left(- \frac {1}{2} (\boldsymbol {y} - \boldsymbol {X} \boldsymbol {w}) ^ {\top} (\sigma^ {- 2} \boldsymbol {I}) (\boldsymbol {Y} - \boldsymbol {X} \boldsymbol {w})\right) \tag {14} \\ = N (\boldsymbol {X} \boldsymbol {w}, \sigma^ {- 2} \boldsymbol {I}) \\ \end{array}
$$

代回原式：

$$
p (\boldsymbol {w} \mid \boldsymbol {X}, \boldsymbol {y}) \propto \exp \left(- \frac {1}{2} (\boldsymbol {y} - \boldsymbol {X} \boldsymbol {w}) ^ {\top} \left(\sigma^ {- 2} \boldsymbol {I}\right) (\boldsymbol {y} - \boldsymbol {X} \boldsymbol {w}) - \frac {1}{2} \boldsymbol {w} ^ {\top} \boldsymbol {\Sigma} _ {w} ^ {- 1} \boldsymbol {w}\right) \tag {15}
$$

假定最后得到的⾼斯分布记为 $N ( \pmb { \mu } , \pmb { \Sigma } )$ 。于是对于上⾯的分布，采⽤配⽅的⽅式来得到 $\pmb { \mu }$ 和 Σ。

• ⾸先分析指数上⾯的⼆次项：

$$
- \frac {1}{2 \sigma^ {2}} \boldsymbol {w} ^ {\top} \boldsymbol {X} ^ {\top} \boldsymbol {X} \boldsymbol {w} - \frac {1}{2} \boldsymbol {w} ^ {\top} \boldsymbol {\Sigma} _ {w} ^ {- 1} \boldsymbol {w} \quad \Rightarrow \quad \boldsymbol {\Sigma} ^ {- 1} = \sigma^ {- 2} \boldsymbol {X} ^ {\top} \boldsymbol {X} + \boldsymbol {\Sigma} _ {w} ^ {- 1} \triangleq \boldsymbol {A} \tag {16}
$$

• ⾸先分析指数上⾯的⼀次项：

$$
\begin{array}{l} \frac {1}{2 \sigma^ {2}} 2 \boldsymbol {y} ^ {\top} \boldsymbol {X} \boldsymbol {w} = \sigma^ {- 2} \boldsymbol {y} ^ {\top} \boldsymbol {X} \boldsymbol {w} \quad \Rightarrow \quad \boldsymbol {\mu} \boldsymbol {\Sigma} ^ {- 1} = \sigma^ {- 2} \boldsymbol {y} ^ {\top} \boldsymbol {X} \tag {17} \\ \Rightarrow \quad \boldsymbol {\mu} = \sigma^ {- 2} \boldsymbol {A} ^ {- 1} \boldsymbol {y} ^ {\top} \boldsymbol {X} \\ \end{array}
$$

# 预测

给定⼀个 $\mathbf { \boldsymbol { x } } ^ { * }$ ，求解 $y ^ { * }$ ，此时是有 $\begin{array} { r } { f ( \pmb { x } ^ { * } ) = \pmb { w } ^ { \top } \pmb { x } ^ { * } = \pmb { x } ^ { * \top } \pmb { w } , } \end{array}$ 。代⼊参数后验，有 $\pmb { x } ^ { * \top } \pmb { w } = N ( \pmb { x } ^ { * \top } \pmb { \mu } , \pmb { x } ^ { * \top } \pmb { \Sigma } \pmb { x } ^ { * } )$ 。再考虑噪声，得到 $y ^ { * } = f ( { \pmb x } ^ { * } ) + \epsilon$ ：

$$
\begin{array}{l} p \left(y ^ {*} \mid X, \mathbf {y}, \mathbf {x} ^ {*}\right) = \int p \left(y ^ {*} \mid \mathbf {w}, X, \mathbf {y}, \mathbf {x} ^ {*}\right) p \left(\mathbf {w} \mid X, \mathbf {y}, \mathbf {x} ^ {*}\right) d \mathbf {w} \\ = \int p \left(y ^ {*} \mid \boldsymbol {w}, \boldsymbol {x} ^ {*}\right) p \left(\boldsymbol {w} \mid \boldsymbol {X}, \boldsymbol {y}\right) d \boldsymbol {w} \tag {18} \\ = N \left(\boldsymbol {x} ^ {* \top} \boldsymbol {\mu}, \boldsymbol {x} ^ {* \top} \boldsymbol {\Sigma} \boldsymbol {x} ^ {*} + \sigma^ {2}\right) \\ \end{array}
$$

# 核函数

在第五章介绍⽀持向量机时我们简单提过核⽅法，在分类问题中，核⽅法是将低维空间中的严格不可分的数据转化为⾼维空间中线性可分的数据(核函数的应⽤之⼀)。我们⽤⼀个特征转换函数作⽤到低维空间的数据。⽽不可分数据在通过特征变换后，往往需要求得变换后的内积。但是将数据从低维变到⾼维后，我们其实是很难求得变换函数的内积。

现在，我们直接引⼊内积的变换函数：

$$
\forall \boldsymbol {x}, \boldsymbol {x} ^ {\prime} \in \mathcal {X}, \exists \phi \in \mathcal {H}: x \rightarrow z, \quad k (\boldsymbol {x}, \boldsymbol {x} ^ {\prime}) = \phi (\boldsymbol {x}) ^ {\top} \phi (\boldsymbol {x} ^ {\prime}) \tag {19}
$$

称 $k ( \pmb { x } , \pmb { x } ^ { \prime } )$ 为核函数， $\phi$ 为特征转换函数，其中 $\mathcal { H }$ 是 Hilbert 空间 (完备的线性内积空间)。我们直接求解变换后的内积复杂难算，在实际中，通常都是使⽤核函数求解内积。

例如，考虑 RBF 核 $\begin{array} { r } { k ( \pmb { x } , \pmb { x } ^ { \prime } ) = \exp \left( - \frac { ( \pmb { x } - \pmb { x } ^ { \prime } ) ^ { 2 } } { 2 \sigma ^ { 2 } } \right) } \end{array}$ ，便有：

$$
\begin{array}{l} \exp \left(- \frac {\left(\boldsymbol {x} - \boldsymbol {x} ^ {\prime}\right) ^ {2}}{2 \sigma^ {2}}\right) = \exp \left(- \frac {\boldsymbol {x} ^ {2}}{2 \sigma^ {2}}\right) \exp \left(- \frac {\boldsymbol {x} \boldsymbol {x} ^ {\prime}}{\sigma^ {2}}\right) \exp \left(- \frac {\boldsymbol {x} ^ {\prime 2}}{2 \sigma^ {2}}\right) \\ = \exp \left(- \frac {\boldsymbol {x} ^ {2}}{2 \sigma^ {2}}\right) \sum_ {n = 0} ^ {\infty} \frac {\boldsymbol {x} ^ {n} \boldsymbol {x} ^ {\prime n}}{\sigma^ {2 n} n !} \exp \left(- \frac {\boldsymbol {x} ^ {\prime 2}}{2 \sigma^ {2}}\right) \tag {20} \\ = \exp \left(- \frac {\boldsymbol {x} ^ {2}}{2 \sigma^ {2}}\right) \psi^ {\top} (\boldsymbol {x}) \psi \left(\boldsymbol {x} ^ {\prime}\right) \exp \left(- \frac {\boldsymbol {x} ^ {\prime 2}}{2 \sigma^ {2}}\right) \\ = \phi^ {\top} (\boldsymbol {x}) \phi \left(\boldsymbol {x} ^ {\prime}\right) \\ \end{array}
$$

这⾥，我们的复杂的特征转换函数 $\begin{array} { r } { \phi ( \pmb { x } ) = \exp \left( - \frac { \pmb { x } ^ { 2 } } { 2 \sigma ^ { 2 } } \right) \psi ( \pmb { x } ) _ { \circ } } \end{array}$ x2 。2 σ 2

我们常说的核函数其实是正定核函数。正定核函数要求核函数满⾜两个条件：

• 对称性，即 $k ( { \pmb x } , { \pmb x } ^ { \prime } ) = k ( { \pmb x } ^ { \prime } , { \pmb x } ) ,$ 。  
• 正定性，即 $\forall m , \pmb { x } ^ { ( 1 ) } , . . . , \pmb { x } ^ { ( m ) } \in \pmb { \chi }$ ，对应的 Gram 矩阵 $K = [ k ( \pmb { x } ^ { ( i ) } , \pmb { x } ^ { ( j ) } ) ]$ 是半正定的。

# 高斯过程回归 (核贝叶斯线性回归)

贝叶斯线性回归可以通过加⼊核函数的⽅法来解决⾮线性函数的问题，将 $f ( \pmb { x } ) = \pmb { x } ^ { \top } \pmb { w }$ 这个函数变为 $f ( \pmb { x } ) = \phi ( \pmb { x } ) ^ { \top } \pmb { w }$ ，变换到更⾼维的空间，有：

$$
f \left(\boldsymbol {x} ^ {*}\right) = N \left(\phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \sigma^ {- 2} \boldsymbol {A} ^ {- 1} \boldsymbol {\Phi} ^ {\top} \boldsymbol {y}, \phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {A} ^ {- 1} \phi \left(\boldsymbol {x} ^ {*}\right)\right) \tag {21}
$$

其中 $\pmb { A } = \sigma ^ { - 2 } \pmb { \Phi } ^ { \top } \pmb { \Phi } + \pmb { \Sigma } _ { \pmb { w } } ^ { - 1 }$ ， $\pmb { \Phi } = ( \phi ( \pmb { x } ^ { 1 } ) , \phi ( \pmb { x } ^ { 2 } ) . . . \phi ( \pmb { x } ^ { m } ) ) ^ { \top }$ 。为了求解 $A ^ { - 1 }$ ，可以利⽤ Woodbury Formula，即：

$$
(A + U C V) ^ {- 1} = A ^ {- 1} + A ^ {- 1} U \left(C ^ {- 1} + V A ^ {- 1} U\right) ^ {- 1} V A ^ {- 1} \tag {22}
$$

令 $A = \Sigma _ { w } ^ { - 1 } , C = \sigma ^ { - 2 } I$ ，可以得到协⽅差矩阵 $\pmb { \Sigma }$ ：

$$
\boldsymbol {A} ^ {- 1} = \boldsymbol {\Sigma} _ {w} - \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} \left(\sigma^ {2} \boldsymbol {I} + \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi}\right) ^ {- 1} \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Sigma} _ {w} \tag {23}
$$

另⼀⽅⾯，我们可以对 $\pmb { A } = \sigma ^ { - 2 } \pmb { \Phi } ^ { \top } \pmb { \Phi } + \pmb { \Sigma } _ { w } ^ { - 1 }$ 两边变换 (同时左乘/右乘矩阵)，得到均值表达式 $\pmb { \mu }$ ：

$$
\begin{array}{l} \boldsymbol {A} = \sigma^ {- 2} \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Phi} + \boldsymbol {\Sigma} _ {w} ^ {- 1} \\ \Rightarrow \quad A \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} = \sigma^ {- 2} \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Phi} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} + \boldsymbol {\Phi} ^ {\top} = \sigma^ {- 2} \boldsymbol {\Phi} ^ {\top} (\boldsymbol {\Phi} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} + \sigma^ {2} \boldsymbol {I}) \\ \Rightarrow \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} = \sigma^ {- 2} \boldsymbol {A} ^ {- 1} \boldsymbol {\Phi} ^ {\top} \left(\boldsymbol {\Phi} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} + \sigma^ {2} \boldsymbol {I}\right) \tag {24} \\ \Rightarrow \sigma^ {- 2} \boldsymbol {A} ^ {- 1} \boldsymbol {\Phi} ^ {\top} = \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} \left(\boldsymbol {\Phi} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} + \sigma^ {2} \boldsymbol {I}\right) ^ {- 1} \\ \Rightarrow \phi (\boldsymbol {x} ^ {*}) ^ {\top} \sigma^ {- 2} \boldsymbol {A} ^ {- 1} \boldsymbol {\Phi} ^ {\top} \boldsymbol {y} = \phi (\boldsymbol {x} ^ {*}) ^ {\top} \boldsymbol {\Sigma} _ {w} ^ {\top} \boldsymbol {\Phi} (\boldsymbol {\Phi} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi} ^ {\top} + \sigma^ {2} \boldsymbol {I}) ^ {- 1} \boldsymbol {y} \\ \end{array}
$$

我们同时将 $A ^ { - 1 }$ 代回预测过程：

$$
\phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {A} ^ {- 1} \phi \left(\boldsymbol {x} ^ {*}\right) = \phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {\Sigma} _ {w} \phi \left(\boldsymbol {x} ^ {*}\right) - \phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {\Sigma} _ {w} \Phi \left(\sigma^ {2} \boldsymbol {I} + \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Sigma} _ {w} \boldsymbol {\Phi}\right) ^ {- 1} \boldsymbol {\Phi} ^ {\top} \boldsymbol {\Sigma} _ {w} \phi \left(\boldsymbol {x} ^ {*}\right) \tag {25}
$$

我们可以看到，在均值向量和协⽅差中，由这四项构成： $\phi ( \pmb { x } ^ { * } ) ^ { \top } \pmb { \Sigma } _ { w } ^ { \top } \pmb { \Phi }$ ， $\begin{array} { r } { \phi ( \mathbf { x } ^ { * } ) ^ { \top } \Sigma _ { w } \phi ( \mathbf { x } ^ { * } ) } \end{array}$ ， $\phi ( \pmb { x } ^ { * } ) ^ { \top } \pmb { \Sigma } _ { w } \pmb { \Phi }$ ， $\Phi ^ { \top } \Sigma _ { w } \phi ( { \pmb x } ^ { * } ) _ { \circ }$ 。将 $\Phi$ 的表达式代⼊展开，那么它们是有着通式： $\begin{array} { r l } { k ( { \pmb x } , { \pmb x } ^ { \prime } ) = \phi ( { \pmb x } ) ^ { \top } \Sigma _ { w } \phi ( { \pmb x } ^ { \prime } ) = } & { { } \qquad \sqrt { \Sigma _ { w } } \phi ( { \pmb x } ^ { \prime } ) . } \end{array}$ 。其中由于 $\Sigma _ { w }$ 是正定对称的⽅差矩阵，所以，这是⼀个核函数。

$$
\begin{array}{l} \phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {\mu} = k \left(\boldsymbol {x} ^ {*}, \boldsymbol {X}\right) \left[ k (\boldsymbol {X}, \boldsymbol {X}) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} \boldsymbol {y} \\ \phi \left(\boldsymbol {x} ^ {*}\right) ^ {\top} \boldsymbol {\Sigma} \phi \left(\boldsymbol {x} ^ {*}\right) = k \left(\boldsymbol {x} ^ {*}, \boldsymbol {x} ^ {*}\right) - k \left(\boldsymbol {x} ^ {*}, \boldsymbol {X}\right) \left[ k (\boldsymbol {X}, \boldsymbol {X}) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} k \left(\boldsymbol {X}, \boldsymbol {x} ^ {*}\right) + \sigma^ {2} \boldsymbol {I} \tag {26} \\ \end{array}
$$

这样我们就可以和贝叶斯线性回归中进⾏⼀样的预测步骤。

# 函数空间的角度

现在，我们再换个⾓度看⾼斯过程回归。在刚刚的视⾓中，我们是基于概率分布的权重。那现在，我们上升⼀下，直接到函数级别。回顾⼀下最开始的函数定义 (式 10)，那么预测就可以写作：

$$
p \left(y ^ {*} \mid \boldsymbol {X}, \boldsymbol {y}, \boldsymbol {x} ^ {*}\right) = \int_ {f} p \left(y ^ {*} \mid f, \boldsymbol {X}, \boldsymbol {y}, \boldsymbol {x} ^ {*}\right) p (f \mid \boldsymbol {X}, \boldsymbol {y}, \boldsymbol {x} ^ {*}) d f \tag {27}
$$

这⾥可以对⽐⼀下 (式 18)。就数据集来说，取 $f ( \boldsymbol { X } ) \sim N ( \mu ( \boldsymbol { X } ) , k ( \boldsymbol { X } , \boldsymbol { X } ) )$ ， ${ \pmb y } = f ( { \pmb X } ) + \epsilon \sim N ( \mu ( { \pmb X } ) , k ( { \pmb X } , { \pmb X } ) + \sigma ^ { 2 } { \pmb I } ) ,$ 。这⾥体现核函数另⼀个作⽤，平滑。以 RBF 核为例，当 ${ \pmb x } ^ { * } = { \pmb x }$ 时，核函数值最⼤；当两个输⼊样本变得越来越远时，曲线逐渐呈平滑下降趋势。为了实现平滑度，我们会希望这两个样本的协⽅差就等于核函数。

现在预测任务的⽬的是给定⼀个新数据样本序列 $X ^ { * }$ ，得到对应的预测 $\pmb { y } ^ { * } = f ( \pmb { X } ^ { * } ) + \epsilon _ { \circ }$ 。然后，我们便可以写出：

$$
\binom {\boldsymbol {y}} {f \left(\boldsymbol {X} ^ {*}\right)} \sim N \binom \left(\mu (\boldsymbol {X}) \atop \mu \left(\boldsymbol {X} ^ {*}\right)\right), \binom {k \left(\boldsymbol {X}, \boldsymbol {X}\right) + \sigma^ {2} \boldsymbol {I}} {k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right)} \begin{array}{l} k (\boldsymbol {X}, \boldsymbol {X}) + \sigma^ {2} \boldsymbol {I} \\ k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right) \end{array} \begin{array}{l} k \left(\boldsymbol {X}, \boldsymbol {X} ^ {*}\right) \\ k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X} ^ {*}\right) \end{array} \tag {28}
$$

这⾥回顾⼀下⾼斯分布：

$$
\binom {x _ {a}} {x _ {b}} \sim N \left(\binom {\mu_ {a}} {\mu_ {b}}, \binom {\Sigma_ {a a} \quad \Sigma_ {a b}} {\Sigma_ {b a} \quad \Sigma_ {b b}}\right) \tag {29}
$$

则会有：

$$
x _ {b} \mid x _ {a} \sim N \left(\mu_ {b | a}, \Sigma_ {b | a}\right)
$$

$$
\mu_ {b \mid a} = \Sigma_ {b a} \Sigma_ {a a} ^ {- 1} \left(x _ {a} - \mu_ {a}\right) + \mu_ {b} \tag {30}
$$

$$
\Sigma_ {b | a} = \Sigma_ {b b} - \Sigma_ {b a} \Sigma_ {a a} ^ {- 1} \Sigma_ {a b}
$$

于是，我们可以直接写出：

$$
\begin{array}{l} p \left(f \left(\boldsymbol {X} ^ {*}\right) \mid \boldsymbol {X}, \boldsymbol {y}, \boldsymbol {X} ^ {*}\right) = p \left(f \left(\boldsymbol {X} ^ {*}\right) \mid \boldsymbol {y}\right) \tag {31} \\ = N \left(k (\pmb {X} ^ {*}, \pmb {X}) [ k (\pmb {X}, \pmb {X}) + \sigma^ {2} \pmb {I} ] ^ {- 1} (\pmb {y} - \mu (\pmb {X})) + \mu (\pmb {X} ^ {*}), k (\pmb {X} ^ {*}, \pmb {X} ^ {*}) - k (\pmb {X} ^ {*}, \pmb {X}) [ k (\pmb {X}, \pmb {X}) + \sigma^ {2} \pmb {I} ] ^ {- 1} k (\pmb {X}, \pmb {X} ^ {*})\right) \\ \end{array}
$$

我们通常会设均值为 $\mu ( X ) = \mu ( X ^ { * } ) = 0$ ：

$$
p \left(f \left(\boldsymbol {X} ^ {*}\right) \mid \boldsymbol {y}\right) = N \left(k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right) \left[ k \left(\boldsymbol {X}, \boldsymbol {X}\right) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} \boldsymbol {y}, k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X} ^ {*}\right) - k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right) \left[ k \left(\boldsymbol {X}, \boldsymbol {X}\right) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} k \left(\boldsymbol {X}, \boldsymbol {X} ^ {*}\right)\right) \tag {32}
$$

如果再有 $\pmb { y } ^ { * } = f ( \pmb { X } ^ { * } ) + \epsilon$ ：

$$
p (\boldsymbol {y} ^ {*} \mid \boldsymbol {y}) = N \left(k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right) \left[ k (\boldsymbol {X}, \boldsymbol {X}) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} \boldsymbol {y}, k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X} ^ {*}\right) - k \left(\boldsymbol {X} ^ {*}, \boldsymbol {X}\right) \left[ k (\boldsymbol {X}, \boldsymbol {X}) + \sigma^ {2} \boldsymbol {I} \right] ^ {- 1} k \left(\boldsymbol {X}, \boldsymbol {X} ^ {*}\right) + \sigma^ {2} \boldsymbol {I}\right) \tag {33}
$$

于是，我们同样可以做到预测。但可以看到，函数空间的⾓度更加简单易于求解。那么我们看⼀下⾼斯进程回归的基本步骤：

• 选择适当的均值函数 $\mu$ 和核函数 $k$ ，以及噪声 $\sigma$ 。其中核函数的选择尤其重要，根据不同的应⽤选择不同的核，⼀般选法是 RBF ⾼斯核。  
• 对于已有的训练样本 $D$ ，计算核矩阵 $K = k ( \pmb { X } , \pmb { X } )$ 。再考虑待预测的样本 $\scriptstyle { \pmb { x } } ^ { * }$ ，计算 $K _ { * } = k ( { \pmb x } ^ { * } , { \pmb X } )$ 和 $K _ { * * } = k ( x ^ { * } , x ^ { * } )$ 。  
• 计算出 $\pmb { \mu }$ 和 $\pmb { \Sigma }$ ，代⼊预测公式 (⾼斯函数) 中，得到预测值的均值、标准差、置信区间。通常，我们可以将均值就作为预测结果。

最后，我们再考虑⼀个问题，同样是已有⼀些样本点再对新样本做出预测，这和我们在第五章讨论的最⼩⼆乘回归有什么区别？最⼩⼆乘回归最后对新样本点 $\mathbf { \boldsymbol { x } } ^ { * }$ 的预测 $f ( x ^ { * } )$ 是⼀个点估计，⽽在这⾥的 $f ( x ^ { * } )$ 其实是个后验概率分布。既然得到了分布，那么我们同样可以得到预测值的点估计(均值)，但还可以知道这个估计有多少信⼼在⾥⾯。

![](images/03a28ecf7ba07ff04af2672dee13f0eba6fa03ad75fc29067af7ed04ee47c256.jpg)  
图 6. ⾼斯过程回归⽤于指导采样。已知点为图中蓝⾊点，真实曲线为图中蓝⾊虚线。对其采样 4 次，每次采样构造 100 个样本的测试集，基于“样本-预测” 可以绘制⼀条曲线。⿊⾊曲线为进⾏多次采样平均后的曲线。

其另⼀个作⽤可以指导采样。如图 6 所⽰ (实现代码见下⽂)，训练集 $D$ 中就 6 个点 (蓝⾊点)，真实曲线为图中蓝⾊虚线。我们可以构造⼀个 100个样本的测试集。于是，我们便可以得到后验分布，我们从后验分布中随机采样得到每个 $\mathbf { \boldsymbol { x } } ^ { * }$ 的预测结果 (视作标签)。再根据这些样本 (训练集 $+$ 测试集) 以及它们的标签拟合⼀条曲线。在图中我们随机采样 4 次，得到 4 个拟合函数。如果是采样很多次，再取所有的拟合函数的平均值就得到均值曲线 (图中⿊线)。含有已知数据 (训练集数据) 的地⽅，这些函数都很接近 (⽅差很低)；⽽没有数据的时候，变化范围就⽐较⼤ (灰⾊区域表⽰均值上下 2 个标准差)。这样，我们可以在预测值和⽅差之间折中，选择下⼀个采样点。

```python
[18]: def k(xs, xt, sigma=1):   
```
```
```
dx = npexpand_dims(xs, 1) - npexpand_dims(xt, 0)
return np.exp(-(dx**2) / (2*sigma**2))   
def m(x):
    return np.zeros_like(x)   
def f(x):
    coef = [6, -2.5, -2.4, -0.1, 0.2, 0.03]
    y = 0
    for i, coef in enumerate(coefs):
        y += coef * (x ** i) 
```

return y $\mathbf{x} =$ np.array([-4，-1.5，0，1.5，2.5，2.7])   
y $=$ f(x)   
x_star $\equiv$ np.linspace(-8,8,100)   
K=k(x,x)   
K_star $\equiv$ k(x,x_star)   
K_star_star $\equiv$ k(x_star,x_star)   
mu $=$ m(x_star)+K_star.T@np.linalg.pinv(K) $(y - m(y))$ Sigma $=$ K_star_star-K_star.T@np.linalg.pinv(K) $@$ K_star   
y_true $\equiv$ f(x_star)   
plt.style.use('ggplot')   
plt.plot(x_star,y_true，linewidth=2，color='b'，alpha=0.8, linestyle $\coloneqq$ 'dashed'，label $\coloneqq$ Truef(x))   
pltscatter(x,y,s=70,c='b'，marker $\coloneqq$ ',label $\coloneqq$ Training data') stds $=$ np.sqrt(Sigma.diagonal())   
up_lower $=$ mu $^+$ 2*stds   
plt fill_between(x_star，mu+2*stds，mu-2*stds，facecolor $\coloneqq$ 'grey'，alpha=0.3, label $\coloneqq$ Uncertainty')   
Colors $=$ ['c'，'y'，'g'，'m']   
for color in Colors: y_star $\equiv$ np.random.multivariate_normal(mu，Sigma) plt.plot(x_star，y_star，linewidth=1，color=color)   
plt.ylim(-8,8)   
plt.plot(x_star，mu，linewidth=2.5，color $\coloneqq$ 'k'，label $\coloneqq$ Mean')   
plt.legend()   
plt.show()

![](images/a79b34963e7875ed50aeeddb282eea1bfba13f4a5660cc919641c89050006e5c.jpg)

# 采集函数

前⾯我们通过⾼斯过程回归得到均值 $\pmb { \mu }$ 和协⽅差 $\pmb { \Sigma }$ ，这两个可以分别理解为⽤来做开发和探索的信息。然后基于这两个信息我们可以设计不同的采集函数。我们这⾥看⼀个简单的⽅法 Thompson Sampling。

# Thompson Sampling (TS)

第⼀步先从当前的⾼斯过程后验⾥⾯采样得到⼀个函数 (例如在上图中从后验分布中采样了 4 个函数)，不妨记为 $\hat { f } _ { t }$

第⼆步我们要新⽣成的点就是：

$$
\boldsymbol {x} ^ {*} = \arg \max  \hat {f} _ {t} (\boldsymbol {x} ^ {*}) \tag {34}
$$

[19]: class KernelBase(ABC):

```python
def __init__(self):
    super().__init__()
    self.params = {}
    selfhyperparams = {}
@abstractmethod
def __kernel(self, X, Y):
    raise NotImplementedError 
```

```python
def __call__(self, X, Y=None):
    return self._kernel(X, Y)
def __str__(self):
    P, H = self.params, selfhyperparams
    p_str = "", ".join(['{}={}]".format(k, v) for k, v in P.items())
    return "{()}().format(H["op"], p_str)
def summary(self):
    return {
        "op": selfhyperparams["op"]
        "params": self.params,
        "hyperparams": selfhyperparams,
    }
class RBFKernel(KernelBase):
    def __init__(self, sigma=None):
        """
        RBF
        ""
        super().__init__()
        selfhyperparams = {"op": "RBFKernel"}
        self.params = {"sigma": sigma} # sigma np.sqrt(n_features/2) n_features
    def __kernel__(self, X, Y=None):
        """
        X Y RBF Y Y=X
        X (n_samples, n_features)
        Y (m_samples, n_features)
        ""
        X = X.reshape(-1, 1) if X.ndim == 1 else X
        Y = X if Y is None else Y
        Y = Yreshape(-1, 1) if Y.ndim == 1 else Y
        assert X.ndim == 2 and Y.ndim == 2, "X and Y must have 2 dimensions"
        sigma = np.sqrt(X.shape[1] / 2) if self.params["sigma"] is None else self.params["sigma"]
        X, Y = X / sigma, Y / sigma
        D = -2 * X @ Y.T + np.sum(Y**2, axis=1) + np.sum(X**2, axis=1)[:, np.newaxis]
        D[D < 0] = 0
        return np.exp(-0.5 * D)
class KernelInitializer(object):
    def __init__(self, param=None):
        self.params = param
    def __call__(self):
        r = r"([a-zA-Z0-9]*=([^,])*")
        kr_str = self.params.lower()
        kwargs = dict([(i, eval(j)) for (i, j) in re.findall(r, self.params)]
        if "rbf" in kr_str:
            kernel = RBFKernel(**kwargs)
        else:
            raise NotImplementedError("[].format(kr_str)) 
```

return kernel

[20]: class GPRegression:

```python
```
```
def __init__(self, kernel="RBFKernel", sigma=1e-10):
    self_kernel = KernelInitializer(kernel())
    self.params = {"GP_mean": None, "GP_cov": None, "X": None}
    selfhyperparams = {"kernel": str(self_kernel), "sigma": sigma}
def fit(self, X, y):
    '''GP
X      (n_samples, n_features)
y      X      (n_samples)
'''mu = np.zeros(X.shape[0])
Cov = self_kernel(X, X)
self.params["X"] = X
self.params["y"] = y
self.params["GP_cov"] = Cov
self.params["GP_mean"] = mu
def predict(self, X_star, conf_interval=0.95):
    '''X
X_star      (n_samples, n_features)
conf_interval       (0, 1) default=0.95
'''X = self.params["X"]
y = self.params["y"]
K = self.params["GP_cov"]
sigma = self.hyperparams["sigma"]
K_star = self_kernel(X_star, X)
K_star_star = self_kernel(X_star, X_star)
sig = np.eye(K.shape[0]) * sigma
K_y_inv = np.linalg.pinv(K + sig)
mean = K_star @ K_y_inv @ y
cov = K_star_star - K_star @ K_y_inv @ K_star.T
percentile = norm.ppf(conf_interval)
conf = percentile * np.sqrt(np.diag(cov))
return mean, conf, cov 
```

[21]: class BayesianOptimization:

```python
def __init__(self):
    self.model = GPRegression()
def acquisition_function(self, Xsamples):
    mu, _, cov = self.model.predict(Xsamples)
    mu = mu if mu.ndim == 1 else (mu.T)[0]
    ysample = np.random.randint_normal(mu, cov)
    return ysample 
```

```python
def opt_acquisition(self, X, n_samples=20):
    # 
        # 
        Xsamples = np.random.randint(low=1, high=50, size=n_samples*X.shape[1])
        Xsamples = Xsamples.reshape(n_samples, X.shape[1])
        # 
            scores = self.acquisition_function(Xsamples)
            ix = np.argmax(scores) 
            return Xsamples[ix, 0]  
def fit(self, f, X, y):
    # GPR 
    self.model.fit(X, y)
    # 
        for i in range(15):
            x_star = self/opt_acquisition(X) 
            y_star = f(x_star) 
            mean, conf, cov = self.model.predict(np.array([[x_star]])) 
            # 
                X = np.vstack((X, [[x_star]])) 
                y = np.vstack((y, [[y_star]])) 
                # GPR 
                self.model.fit(X, y) 
                ix = np.argmax(y) 
                print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix])) 
    return X[ix], y[ix] 
```

用自定义的度量指标，乳腺癌数据集测试，第七章描述的随机森林用于模型训练

[22]: from chapter7 import RandomForest

```python
[23]: column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class'] data = pd.read_csv('./data/cancer/breast-cancer-wisconsin.data', names=column_names) data = data.replace(to_replace='?'value=np.nan) # data = data.dropna(how='any') # any print(data.shape) # 25% 75% X_train, X_test, y_train, y_test = train_test_split(data column_names[1:10]), data column_names[10]), test_size=0.25, random_state=1111) # print(y_train.value_counts()) # 0 1 print(y_train.shape) y_train[y_train==2] = 0 y_train[y_train==4] = 1 y_test[y_test==2] = 0 y_test[y_test==4] = 1 # print(y_train.value_counts()) # 0 1 ss = StandardScaler() X_train = ss.fit_transform(X_train) X_test = ss.transform(X_test) y_train = y_train.as_matrix() y_test = y_test.as_matrix() 
```

(683, 11)

```txt
2 328   
4 184   
Name: Class, dtype: int64 (512,)   
0 328   
1 184   
Name: Class, dtype: int64 
```

```python
[24]: def func/black_box(k): model = RandomForest(n_estimators=k) model.fit(X_train, y_train) return model.score(X_test, y_test) X0 = np.array([[4]]) y0 = np.array([func/black_box(4)]) print("initial n_estimators=\{},{score}.".format(4,y0[0])) BO = BayesianOptimization() X1, y1 = BO.fit(func/black_box, X0, y0) print("Best n_estimators=\{},{score}.".format(X1, y1))   
initial n_estimators=4, score=0.9122807017543859 Best Result: x=19.000, y=0.965 Best n_estimators=[19], score=[0.96491228] 
```

```python
[25]: import numpy  
import matplotlib  
import re  
import pandas  
import sklearn  
import itertools  
import scipy  
print("numpy:", numpy.__version__)  
print("matplotlib:", matplotlib.__version__)  
print("pandas:", pandas.__version__)  
print("re:", re.__version__)  
print("sklearn:", sklearn.__version__)  
print(" scipy:", scipy.__version__) 
```

```txt
numpy: 1.14.5  
matplotlib: 3.1.1  
pandas: 0.25.1  
re: 2.2.1  
sklearn: 0.21.3  
scipy: 1.3.1 
```